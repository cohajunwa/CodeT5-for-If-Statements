,input_function,expected_if_condition,predicted_if_condition,exact_match,CodeBLEU score,BLEU-4 score
0,"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB>  try : <TAB><TAB>  return self . _read ( count , timeout ) <TAB>  except usb . USBError as e : <TAB><TAB>  if DEBUG_COMM : <TAB><TAB><TAB>  log . info ( <TAB><TAB><TAB><TAB>  "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB><TAB><TAB><TAB>  % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ ] <TAB><TAB>  if ignore_non_errors and is_noerr ( e ) : <TAB><TAB><TAB>  return [ ] <TAB><TAB>  raise ",if ignore_timeouts and is_timeout ( e ) :,if ignore_timeouts and is_noerr(e):,False,50.82248548905353,98.90705000370515
1,"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB>  """"""cache hidden states into memory."""""" <TAB>  if mem_len is None or mem_len == 0 : <TAB><TAB>  return None <TAB>  else : <TAB><TAB>  if reuse_len is not None and reuse_len > 0 : <TAB><TAB><TAB>  curr_out = curr_out [ : reuse_len ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_mem = curr_out [ - mem_len : ] <TAB><TAB>  else : <TAB><TAB><TAB>  new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB>  new_mem . stop_gradient = True <TAB>  return new_mem ",if prev_mem is None :,if prev_mem is None:,False,61.93130572652332,96.64682634007477
2,def filtered ( gen ) : <TAB>  for example in gen : <TAB><TAB>  example_len = length_fn ( example ) <TAB><TAB>  # Checking max length boundary. <TAB><TAB>  if max_length is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  # Checking min length boundary. <TAB><TAB>  if min_length is not None : <TAB><TAB><TAB>  if example_len < min_length : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  # Within bounds. <TAB><TAB>  yield example ,if example_len > max_length :,if example_len > max_length:,False,53.88721024123622,100.00000000000004
3,"def search ( self , query ) : <TAB>  # ""Search.ashx?query="" + query + filterVal <TAB>  if not query : <TAB><TAB>  logger . debug ( "" Empty search query "" ) <TAB><TAB>  return [ ] <TAB>  logger . debug ( ' Searching TuneIn for  "" %s "" ' % query ) <TAB>  args = "" &query= "" + query <TAB>  search_results = self . _tunein ( "" Search.ashx "" , args ) <TAB>  results = [ ] <TAB>  for item in self . _flatten ( search_results ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Only return stations <TAB><TAB><TAB>  self . _stations [ item [ "" guide_id "" ] ] = item <TAB><TAB><TAB>  results . append ( item ) <TAB>  return results ","if item . get ( ""type"" , """" ) == ""audio"" :",if item['guide_id'] not in self._stations:,False,28.557484540887778,91.03438423162028
4,"def _check_script ( self , script , directive ) : <TAB>  for var in compile_script ( script ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Skip variable checks <TAB><TAB><TAB>  return False <TAB><TAB>  if var . can_contain ( "" . "" ) : <TAB><TAB><TAB>  # Yay! Our variable can contain any symbols! <TAB><TAB><TAB>  reason = ( <TAB><TAB><TAB><TAB>  ' At least variable  "" $ {var} ""  can contain untrusted user input ' . format ( <TAB><TAB><TAB><TAB><TAB>  var = var . name <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . add_issue ( directive = [ directive ] + var . providers , reason = reason ) <TAB><TAB><TAB>  return True <TAB>  return False ","if var . must_contain ( ""/"" ) :",if not var.can_contain('^'):,False,38.85940082509086,93.06148745060547
5,"def getAllDataLinkIDs ( ) : <TAB>  linkDataIDs = set ( ) <TAB>  dataType = _forestData . dataTypeBySocket <TAB>  for socketID , linkedIDs in _forestData . linkedSockets . items ( ) : <TAB><TAB>  for linkedID in linkedIDs : <TAB><TAB><TAB>  <IF-STMT>:<TAB># check which one is origin/target <TAB><TAB><TAB><TAB>  linkDataIDs . add ( <TAB><TAB><TAB><TAB><TAB>  ( socketID , linkedID , dataType [ socketID ] , dataType [ linkedID ] ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  linkDataIDs . add ( <TAB><TAB><TAB><TAB><TAB>  ( linkedID , socketID , dataType [ linkedID ] , dataType [ socketID ] ) <TAB><TAB><TAB><TAB>  ) <TAB>  return linkDataIDs ",if socketID [ 1 ] :,if linkedID == socketID:,False,51.858004194465046,95.67435451580818
6,"def _stderr_supports_color ( ) : <TAB>  try : <TAB><TAB>  if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB><TAB><TAB>  if curses : <TAB><TAB><TAB><TAB>  curses . setupterm ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  elif colorama : <TAB><TAB><TAB><TAB>  if sys . stderr is getattr ( <TAB><TAB><TAB><TAB><TAB>  colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB><TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  except Exception : <TAB><TAB>  # Very broad exception handling because it's always better to <TAB><TAB>  # fall back to non-colored logs than to break at startup. <TAB><TAB>  pass <TAB>  return False ","if curses . tigetnum ( ""colors"" ) > 0 :",if sys.stderr is sys.stderr:,False,62.105704536104476,95.52229489809352
7,"def offsets ( self ) : <TAB>  offsets = { } <TAB>  offset_so_far = 0 <TAB>  for name , ty in self . fields . items ( ) : <TAB><TAB>  if isinstance ( ty , SimTypeBottom ) : <TAB><TAB><TAB>  l . warning ( <TAB><TAB><TAB><TAB>  "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB><TAB><TAB><TAB>  "" element size. "" , <TAB><TAB><TAB><TAB>  self . name , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  continue <TAB><TAB>  if not self . _pack : <TAB><TAB><TAB>  align = ty . alignment <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  offset_so_far + = align - offset_so_far % align <TAB><TAB>  offsets [ name ] = offset_so_far <TAB><TAB>  offset_so_far + = ty . size / / self . _arch . byte_width <TAB>  return offsets ",if offset_so_far % align != 0 :,if align > 0:,False,33.04318474317734,96.2160983262748
8,"def Restore ( self ) : <TAB>  picker , obj = self . _window , self . _pObject <TAB>  value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB>  if value is not None : <TAB><TAB>  if issubclass ( picker . __class__ , wx . FileDialog ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = value [ - 1 ] <TAB><TAB>  picker . SetPath ( value ) <TAB><TAB>  return True <TAB>  return False ",if type ( value ) == list :,if value[-1] == 'PONG':,False,48.7298315733533,92.54505840357896
9,"def dt_s_tup_to_string ( dt_s_tup ) : <TAB>  dt_string = dt_s_tup [ 0 ]<TAB># string for identifying the file to parse. <TAB>  if dt_s_tup [ 1 ] > 0 :<TAB># if there are seasons in the model <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dt_string = dt_string [ : 2 ] + "" s "" + dt_string [ 2 : ] <TAB><TAB>  else : <TAB><TAB><TAB>  dt_string = "" s "" + dt_string <TAB>  return dt_string ","if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",if dt_s_tup[1] == 0:,False,35.90236251963598,83.49177951968566
10,"def writer ( stream , items ) : <TAB>  sep = "" "" <TAB>  for item in items : <TAB><TAB>  stream . write ( sep ) <TAB><TAB>  sep = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  item = str ( item ) <TAB><TAB>  if not PY3K : <TAB><TAB><TAB>  if not isinstance ( item , unicode ) : <TAB><TAB><TAB><TAB>  item = str ( item ) <TAB><TAB>  stream . write ( item ) <TAB>  stream . write ( "" \n "" ) ","if not isinstance ( item , str ) :","if not isinstance(item, str):",False,32.639514324903104,100.00000000000004
11,"def _get_result_keys ( self , config ) : <TAB>  result_key = config . get ( "" result_key "" ) <TAB>  if result_key is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result_key = [ result_key ] <TAB><TAB>  result_key = [ jmespath . compile ( rk ) for rk in result_key ] <TAB><TAB>  return result_key ","if not isinstance ( result_key , list ) :","if isinstance(result_key, str):",False,25.86569404478706,95.35484797548452
12,"def _download_build_artifacts ( self , build : Dict [ str , Any ] ) - > None : <TAB>  arch = build [ "" arch_tag "" ] <TAB>  snap_build = self . _lp_load_url ( build [ "" self_link "" ] ) <TAB>  urls = snap_build . getFileUrls ( ) <TAB>  if not urls : <TAB><TAB>  logger . error ( f "" Snap file not available for arch  { arch !r} . "" ) <TAB><TAB>  return <TAB>  for url in urls : <TAB><TAB>  file_name = _get_url_basename ( url ) <TAB><TAB>  self . _download_file ( url = url , dst = file_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . info ( f "" Snapped  { file_name } "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  logger . info ( f "" Fetched  { file_name } "" ) ","if file_name . endswith ( "".snap"" ) :",if os.path.exists(file_name):,False,20.05217458366314,96.039750679562
13,"def _add_custom_statement ( self , custom_statements ) : <TAB>  if custom_statements is None : <TAB><TAB>  return <TAB>  self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB>  if self . resource_policy . get ( "" Statement "" ) is None : <TAB><TAB>  self . resource_policy [ "" Statement "" ] = custom_statements <TAB>  else : <TAB><TAB>  if not isinstance ( custom_statements , list ) : <TAB><TAB><TAB>  custom_statements = [ custom_statements ] <TAB><TAB>  statement = self . resource_policy [ "" Statement "" ] <TAB><TAB>  if not isinstance ( statement , list ) : <TAB><TAB><TAB>  statement = [ statement ] <TAB><TAB>  for s in custom_statements : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  statement . append ( s ) <TAB><TAB>  self . resource_policy [ "" Statement "" ] = statement ",if s not in statement :,if s not in statement:,False,51.79246947255714,100.00000000000004
14,"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB>  """"""Display a failure for a single method / endpoint."""""" <TAB>  display_subsection ( result ) <TAB>  checks = _get_unique_failures ( result . checks ) <TAB>  for idx , check in enumerate ( checks , 1 ) : <TAB><TAB>  message : Optional [ str ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  message = f "" { idx } .  { check . message } "" <TAB><TAB>  else : <TAB><TAB><TAB>  message = None <TAB><TAB>  example = cast ( Case , check . example )<TAB># filtered in `_get_unique_failures` <TAB><TAB>  display_example ( example , check . name , message , result . seed ) <TAB><TAB>  # Display every time except the last check <TAB><TAB>  if idx != len ( checks ) : <TAB><TAB><TAB>  click . echo ( "" \n "" ) ",if check . message :,if check.message:,False,38.471861628174565,98.1333294637598
15,"def build ( opt ) : <TAB>  dpath = os . path . join ( opt [ "" datapath "" ] , "" qangaroo "" ) <TAB>  version = "" v1.1 "" <TAB>  if not build_data . built ( dpath , version_string = version ) : <TAB><TAB>  print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # An older version exists, so remove these outdated files. <TAB><TAB><TAB>  build_data . remove_dir ( dpath ) <TAB><TAB>  build_data . make_dir ( dpath ) <TAB><TAB>  # Download the data. <TAB><TAB>  for downloadable_file in RESOURCES : <TAB><TAB><TAB>  downloadable_file . download_file ( dpath ) <TAB><TAB>  # Mark the data as built. <TAB><TAB>  build_data . mark_done ( dpath , version_string = version ) ",if build_data . built ( dpath ) :,if os.path.exists(dpath):,False,60.30174916474167,97.22282561775998
16,"def call ( self , step_input , states ) : <TAB>  new_states = [ ] <TAB>  for i in range ( self . num_layers ) : <TAB><TAB>  out , new_state = self . lstm_cells [ i ] ( step_input , states [ i ] ) <TAB><TAB>  step_input = ( <TAB><TAB><TAB>  layers . dropout ( <TAB><TAB><TAB><TAB>  out , self . dropout_prob , dropout_implementation = "" upscale_in_train "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else out <TAB><TAB>  ) <TAB><TAB>  new_states . append ( new_state ) <TAB>  return step_input , new_states ",if self . dropout_prob > 0.0,if new_state == new_state:,False,37.72806222523849,94.69501363306031
17,"def jupyter_progress_bar ( min = 0 , max = 1.0 ) : <TAB>  """"""Returns an ipywidget progress bar or None if we can't import it"""""" <TAB>  widgets = wandb . util . get_module ( "" ipywidgets "" ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # TODO: this currently works in iPython but it's deprecated since 4.0 <TAB><TAB><TAB>  from IPython . html import widgets<TAB># type: ignore <TAB><TAB>  assert hasattr ( widgets , "" VBox "" ) <TAB><TAB>  assert hasattr ( widgets , "" Label "" ) <TAB><TAB>  assert hasattr ( widgets , "" FloatProgress "" ) <TAB><TAB>  return ProgressWidget ( widgets , min = min , max = max ) <TAB>  except ( ImportError , AssertionError ) : <TAB><TAB>  return None ",if widgets is None :,if not widgets:,False,38.02352250247078,95.97743145236024
18,"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB>  with self . lock : <TAB><TAB>  self . events [ path ] . append ( events ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not os . path . exists ( path ) : <TAB><TAB><TAB><TAB>  self . watches . pop ( path ) . close ( ) ",if events | pyuv . fs . UV_RENAME :,if path in self.watchers:,False,22.81411766303983,90.24019590462773
19,"def _get_v1_id_from_tags ( self , tags_obj , tag ) : <TAB>  """"""Get image id from array of tags"""""" <TAB>  if isinstance ( tags_obj , dict ) : <TAB><TAB>  try : <TAB><TAB><TAB>  return tags_obj [ tag ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  pass <TAB>  elif isinstance ( tags_obj , [ ] ) : <TAB><TAB>  try : <TAB><TAB><TAB>  for tag_dict in tags_obj : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return tag_dict [ "" layer "" ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  pass <TAB>  return "" "" ","if tag_dict [ ""name"" ] == tag :",if tag_dict['tag'] == tag:,False,31.066124714916526,97.8079828744408
20,"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB>  more_results = True <TAB>  num_results = 0 <TAB>  next_token = None <TAB>  while more_results : <TAB><TAB>  rs = domain . connection . query_with_attributes ( <TAB><TAB><TAB>  domain , query , attr_names , next_token = next_token <TAB><TAB>  ) <TAB><TAB>  for item in rs : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if num_results == max_items : <TAB><TAB><TAB><TAB><TAB>  raise StopIteration <TAB><TAB><TAB>  yield item <TAB><TAB><TAB>  num_results + = 1 <TAB><TAB>  next_token = rs . next_token <TAB><TAB>  more_results = next_token != None ",if max_items :,if item.token == next_token:,False,33.07813141274196,95.98156920867355
21,"def filter ( this , args ) : <TAB>  array = to_object ( this , args . space ) <TAB>  callbackfn = get_arg ( args , 0 ) <TAB>  arr_len = js_arr_length ( array ) <TAB>  if not is_callable ( callbackfn ) : <TAB><TAB>  raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB>  _this = get_arg ( args , 1 ) <TAB>  k = 0 <TAB>  res = [ ] <TAB>  while k < arr_len : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kValue = array . get ( unicode ( k ) ) <TAB><TAB><TAB>  if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) : <TAB><TAB><TAB><TAB>  res . append ( kValue ) <TAB><TAB>  k + = 1 <TAB>  return args . space . ConstructArray ( res ) ",if array . has_property ( unicode ( k ) ) :,"if isinstance(array, (int, float)):",False,21.26971381745987,95.79860154917405
22,"def every_one_is ( self , dst ) : <TAB>  msg = "" all members of  %r  should be  %r , but the  %d th is  %r "" <TAB>  for index , item in enumerate ( self . _src ) : <TAB><TAB>  if self . _range : <TAB><TAB><TAB>  if index < self . _range [ 0 ] or index > self . _range [ 1 ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  error = msg % ( self . _src , dst , index , item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AssertionError ( error ) <TAB>  return True ",if item != dst :,if error:,False,34.236114925123346,94.93534764913447
23,"def schedule_logger ( job_id = None , delete = False ) : <TAB>  if not job_id : <TAB><TAB>  return getLogger ( "" fate_flow_schedule "" ) <TAB>  else : <TAB><TAB>  if delete : <TAB><TAB><TAB>  with LoggerFactory . lock : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  del LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  return True <TAB><TAB>  key = job_id + "" schedule "" <TAB><TAB>  if key in LoggerFactory . schedule_logger_dict : <TAB><TAB><TAB>  return LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB>  return LoggerFactory . get_schedule_logger ( job_id ) ",if job_id in key :,if key in LoggerFactory.schedule_logger_dict:,False,46.5755008325375,96.5786064788774
24,"def Tokenize ( s ) : <TAB>  # type: (str) -> Iterator[Token] <TAB>  for item in TOKEN_RE . findall ( s ) : <TAB><TAB>  # The type checker can't know the true type of item! <TAB><TAB>  item = cast ( TupleStr4 , item ) <TAB><TAB>  if item [ 0 ] : <TAB><TAB><TAB>  typ = "" number "" <TAB><TAB><TAB>  val = item [ 0 ] <TAB><TAB>  elif item [ 1 ] : <TAB><TAB><TAB>  typ = "" name "" <TAB><TAB><TAB>  val = item [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  typ = item [ 2 ] <TAB><TAB><TAB>  val = item [ 2 ] <TAB><TAB>  elif item [ 3 ] : <TAB><TAB><TAB>  typ = item [ 3 ] <TAB><TAB><TAB>  val = item [ 3 ] <TAB><TAB>  yield Token ( typ , val ) ",elif item [ 2 ] :,if 2:,False,33.49868608101158,97.44954270154514
25,"def _read_data_from_all_categories ( self , directory , config , categories ) : <TAB>  lines = [ ] <TAB>  for category in categories : <TAB><TAB>  data_file = os . path . join ( directory , _DATASET_VERSION , category , config ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with open ( data_file ) as f : <TAB><TAB><TAB><TAB>  ls = f . read ( ) . split ( "" \n "" ) <TAB><TAB><TAB><TAB>  for l in ls [ : : - 1 ] : <TAB><TAB><TAB><TAB><TAB>  if not l : <TAB><TAB><TAB><TAB><TAB><TAB>  ls . remove ( l ) <TAB><TAB><TAB><TAB>  lines . extend ( ls ) <TAB>  return lines ",if os . path . exists ( data_file ) :,if os.path.exists(data_file):,False,50.930197934360045,98.36411050430276
26,"def find_handlers ( self , forms ) : <TAB>  handlers = { } <TAB>  for form in forms . itervalues ( ) : <TAB><TAB>  for action_name , _action_label in form . actions : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  handlers [ action_name ] = form <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise HandlerError ( <TAB><TAB><TAB><TAB><TAB>  "" More than one form defines the handler  %s "" % action_name <TAB><TAB><TAB><TAB>  ) <TAB>  return handlers ",if action_name not in handlers :,if action_name == self.action_name and _action_label == self.action,False,47.707048261227555,89.20519483256872
27,"def get_story_task_completed_body ( payload : Dict [ str , Any ] ) - > Optional [ str ] : <TAB>  action = get_action_with_primary_id ( payload ) <TAB>  kwargs = { <TAB><TAB>  "" task_description "" : action [ "" description "" ] , <TAB>  } <TAB>  story_id = action [ "" story_id "" ] <TAB>  for ref in payload [ "" references "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs [ "" name_template "" ] = STORY_NAME_TEMPLATE . format ( <TAB><TAB><TAB><TAB>  name = ref [ "" name "" ] , <TAB><TAB><TAB><TAB>  app_url = ref [ "" app_url "" ] , <TAB><TAB><TAB>  ) <TAB>  if action [ "" changes "" ] [ "" complete "" ] [ "" new "" ] : <TAB><TAB>  return STORY_TASK_COMPLETED_TEMPLATE . format ( * * kwargs ) <TAB>  else : <TAB><TAB>  return None ","if ref [ ""id"" ] == story_id :",if ref['story_id'] == story_id:,False,45.95127124248201,98.23578960641011
28,"def _create_valid_graph ( graph ) : <TAB>  nodes = graph . nodes ( ) <TAB>  for i in range ( len ( nodes ) ) : <TAB><TAB>  for j in range ( len ( nodes ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  edge = ( nodes [ i ] , nodes [ j ] ) <TAB><TAB><TAB>  if graph . has_edge ( edge ) : <TAB><TAB><TAB><TAB>  graph . del_edge ( edge ) <TAB><TAB><TAB>  graph . add_edge ( edge , 1 ) ",if i == j :,if nodes[i][j] == j:,False,50.20195691302369,94.97401976008997
29,"def _post_order ( op ) : <TAB>  if isinstance ( op , tvm . tir . Allocate ) : <TAB><TAB>  lift_stmt [ - 1 ] . append ( op ) <TAB><TAB>  return op . body <TAB>  if isinstance ( op , tvm . tir . AttrStmt ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lift_stmt [ - 1 ] . append ( op ) <TAB><TAB><TAB>  return op . body <TAB><TAB>  if op . attr_key == "" virtual_thread "" : <TAB><TAB><TAB>  return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB><TAB>  return op <TAB>  if isinstance ( op , tvm . tir . For ) : <TAB><TAB>  return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB>  raise RuntimeError ( "" not reached "" ) ","if op . attr_key == ""storage_scope"" :","if isinstance(op, tvm.tir.Allocate):",False,24.605053078088627,92.1647653107793
30,"def format_lazy_import ( names ) : <TAB>  """"""Formats lazy import lines"""""" <TAB>  lines = "" "" <TAB>  for _ , name , asname in names : <TAB><TAB>  pkg , _ , _ = name . partition ( "" . "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line = "" {pkg}  = _LazyModule.load( {pkg!r} ,  {mod!r} ) \n "" <TAB><TAB>  else : <TAB><TAB><TAB>  line = "" {asname}  = _LazyModule.load( {pkg!r} ,  {mod!r} ,  {asname!r} ) \n "" <TAB><TAB>  lines + = line . format ( pkg = pkg , mod = name , asname = asname ) <TAB>  return lines ",if asname is None :,if asname == asname:,False,26.85335703940592,97.60724046619885
31,"def evaluateWord ( self , argument ) : <TAB>  wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB>  if wildcard_count > 0 : <TAB><TAB>  if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB><TAB><TAB>  return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB><TAB>  if wildcard_count == 1 and argument [ 0 ] . endswith ( "" * "" ) : <TAB><TAB><TAB>  return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB><TAB><TAB>  matched = False <TAB><TAB><TAB>  for w in self . words : <TAB><TAB><TAB><TAB>  matched = bool ( re . search ( _regex , w ) ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  return matched <TAB>  return self . GetWord ( argument [ 0 ] ) ",if matched :,if matched:,False,55.320521418590616,98.79291373773354
32,"def setup ( self , ir : "" IR "" , aconf : Config ) - > bool : <TAB>  if self . kind == "" ConsulResolver "" : <TAB><TAB>  self . resolve_with = "" consul "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . post_error ( "" ConsulResolver is required to have a datacenter "" ) <TAB><TAB><TAB>  return False <TAB>  elif self . kind == "" KubernetesServiceResolver "" : <TAB><TAB>  self . resolve_with = "" k8s "" <TAB>  elif self . kind == "" KubernetesEndpointResolver "" : <TAB><TAB>  self . resolve_with = "" k8s "" <TAB>  else : <TAB><TAB>  self . post_error ( f "" Resolver kind  { self . kind }  unknown "" ) <TAB><TAB>  return False <TAB>  return True ","if not self . get ( ""datacenter"" ) :","if self.kind == ""DynamoDBServiceResolver':",False,20.054063876988344,95.15387243327129
33,"def get_success_url ( self ) : <TAB>  """"""Continue to the flow index or redirect according `?back` parameter."""""" <TAB>  if "" back "" in self . request . GET : <TAB><TAB>  back_url = self . request . GET [ "" back "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  back_url = "" / "" <TAB><TAB>  return back_url <TAB>  return reverse ( self . success_url ) ","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :",if not back_url:,False,32.79140623764298,78.63207928392163
34,"def download_main ( <TAB>  download , download_playlist , urls , playlist , output_dir , merge , info_only  ) : <TAB>  for url in urls : <TAB><TAB>  if url . startswith ( "" https:// "" ) : <TAB><TAB><TAB>  url = url [ 8 : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  url = "" http:// "" + url <TAB><TAB>  if playlist : <TAB><TAB><TAB>  download_playlist ( <TAB><TAB><TAB><TAB>  url , output_dir = output_dir , merge = merge , info_only = info_only <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  download ( url , output_dir = output_dir , merge = merge , info_only = info_only ) ","if not url . startswith ( ""http://"" ) :",if url.startswith('http'):,False,23.009111562005344,95.32932487836923
35,"def __str__ ( self ) : <TAB>  buf = [ "" "" ] <TAB>  if self . fileName : <TAB><TAB>  buf . append ( self . fileName + "" : "" ) <TAB>  if self . line != - 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  buf . append ( "" line  "" ) <TAB><TAB>  buf . append ( str ( self . line ) ) <TAB><TAB>  if self . column != - 1 : <TAB><TAB><TAB>  buf . append ( "" : "" + str ( self . column ) ) <TAB><TAB>  buf . append ( "" : "" ) <TAB>  buf . append ( "" "" ) <TAB>  return str ( "" "" ) . join ( buf ) ",if not self . fileName :,if self.line != -1:,False,49.038669090682,93.7410351195334
36,"def parse_bash_set_output ( output ) : <TAB>  """"""Parse Bash-like 'set' output"""""" <TAB>  if not sys . platform . startswith ( "" win "" ) : <TAB><TAB>  # Replace ""\""-continued lines in *Linux* environment dumps. <TAB><TAB>  # Cannot do this on Windows because a ""\"" at the end of the <TAB><TAB>  # line does not imply a continuation. <TAB><TAB>  output = output . replace ( "" \\ \n "" , "" "" ) <TAB>  environ = { } <TAB>  for line in output . splitlines ( 0 ) : <TAB><TAB>  line = line . rstrip ( ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  continue<TAB># skip black lines <TAB><TAB>  item = _ParseBashEnvStr ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  environ [ item [ 0 ] ] = item [ 1 ] <TAB>  return environ ",if item :,if item:,False,64.46410550847315,98.00062233445554
37,"def remove_selected ( self ) : <TAB>  """"""Removes selected items from list."""""" <TAB>  to_delete = [ ] <TAB>  for i in range ( len ( self ) ) : <TAB><TAB>  if self [ i ] . selected : <TAB><TAB><TAB>  to_delete . append ( i ) <TAB>  to_delete . reverse ( ) <TAB>  for i in to_delete : <TAB><TAB>  self . pop ( i ) <TAB>  if len ( to_delete ) > 0 : <TAB><TAB>  first_to_delete = to_delete [ - 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self [ 0 ] . selected = True <TAB><TAB>  elif first_to_delete > 0 : <TAB><TAB><TAB>  self [ first_to_delete - 1 ] . selected = True ",if first_to_delete == 0 and len ( self ) > 0 :,if first_to_delete == 0:,False,43.97009424887083,95.23786203923684
38,"def update ( self , update_tracks = True ) : <TAB>  self . enable_update_metadata_images ( False ) <TAB>  old_album_title = self . metadata [ "" album "" ] <TAB>  self . metadata [ "" album "" ] = config . setting [ "" nat_name "" ] <TAB>  for track in self . tracks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  track . metadata [ "" album "" ] = self . metadata [ "" album "" ] <TAB><TAB>  for file in track . linked_files : <TAB><TAB><TAB>  track . update_file_metadata ( file ) <TAB>  self . enable_update_metadata_images ( True ) <TAB>  super ( ) . update ( update_tracks ) ","if old_album_title == track . metadata [ ""album"" ] :",if track.title == old_album_title:,False,46.877873549476256,94.0204554495223
39,"def on_input ( self , target , message ) : <TAB>  if message . strip ( ) == "" "" : <TAB><TAB>  self . panel ( "" No commit message provided "" ) <TAB><TAB>  return <TAB>  if target : <TAB><TAB>  command = [ "" git "" , "" add "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  command . append ( "" --all "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  command . extend ( ( "" -- "" , target ) ) <TAB><TAB>  self . run_command ( command , functools . partial ( self . add_done , message ) ) <TAB>  else : <TAB><TAB>  self . add_done ( message , "" "" ) ","if target == ""*"" :",if target == None:,False,48.80645570939394,97.5039964784901
40,"def go_to_last_edit_location ( self ) : <TAB>  if self . last_edit_cursor_pos is not None : <TAB><TAB>  filename , position = self . last_edit_cursor_pos <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . last_edit_cursor_pos = None <TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  self . load ( filename ) <TAB><TAB><TAB>  editor = self . get_current_editor ( ) <TAB><TAB><TAB>  if position < editor . document ( ) . characterCount ( ) : <TAB><TAB><TAB><TAB>  editor . set_cursor_position ( position ) ",if not osp . isfile ( filename ) :,if filename is None:,False,22.71078047608628,95.41463068363501
41,"def returnByType ( self , results ) : <TAB>  new_results = { } <TAB>  for r in results : <TAB><TAB>  type_name = r . get ( "" type "" , "" movie "" ) + "" s "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_results [ type_name ] = [ ] <TAB><TAB>  new_results [ type_name ] . append ( r ) <TAB>  # Combine movies, needs a cleaner way.. <TAB>  if "" movies "" in new_results : <TAB><TAB>  new_results [ "" movies "" ] = self . combineOnIMDB ( new_results [ "" movies "" ] ) <TAB>  return new_results ",if type_name not in new_results :,if type_name not in new_results:,False,56.51613824367507,100.00000000000004
42,"def cache_sns_topics_across_accounts ( ) - > bool : <TAB>  function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB>  # First, get list of accounts <TAB>  accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB>  for account_id in accounts_d . keys ( ) : <TAB><TAB>  if config . get ( "" environment "" ) == "" prod "" : <TAB><TAB><TAB>  cache_sns_topics_for_account . delay ( account_id ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cache_sns_topics_for_account . delay ( account_id ) <TAB>  stats . count ( f "" { function } .success "" ) <TAB>  return True ","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",if account_id not in accounts_d:,False,39.17548679166912,91.91418435479639
43,"def get ( self , subject , topic ) : <TAB>  """"""Handles GET requests."""""" <TAB>  if subject in feconf . AVAILABLE_LANDING_PAGES : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . render_template ( "" topic-landing-page.mainpage.html "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise self . PageNotFoundException <TAB>  else : <TAB><TAB>  raise self . PageNotFoundException ",if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,if topic == feconf.AVAILABLE_LANDING_PAGES[subject]:,False,26.267039756026715,96.95490931243769
44,"def callback ( compiled ) : <TAB>  <IF-STMT>: <TAB><TAB>  logger . show_tabulated ( <TAB><TAB><TAB>  "" Compiled "" , showpath ( codepath ) , "" without writing to file. "" <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  with univ_open ( destpath , "" w "" ) as opened : <TAB><TAB><TAB>  writefile ( opened , compiled ) <TAB><TAB>  logger . show_tabulated ( "" Compiled to "" , showpath ( destpath ) , "" . "" ) <TAB>  if self . show : <TAB><TAB>  print ( compiled ) <TAB>  if run : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . execute ( compiled , path = codepath , allow_show = False ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . execute_file ( destpath ) ",if destpath is None :,if not os.path.exists(destpath):,False,20.303070345891737,93.04385598623715
45,"def _find_start_index ( self , string , start , end ) : <TAB>  while True : <TAB><TAB>  index = string . find ( "" { "" , start , end ) - 1 <TAB><TAB>  if index < 0 : <TAB><TAB><TAB>  return - 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return index <TAB><TAB>  start = index + 2 ","if self . _start_index_is_ok ( string , index ) :",if index == -1:,False,42.10054533977721,82.9183442180933
46,"def _get_nlu_target_format ( export_path : Text ) - > Text : <TAB>  guessed_format = loading . guess_format ( export_path ) <TAB>  if guessed_format not in { MARKDOWN , RASA , RASA_YAML } : <TAB><TAB>  if rasa . shared . data . is_likely_json_file ( export_path ) : <TAB><TAB><TAB>  guessed_format = RASA <TAB><TAB>  elif rasa . shared . data . is_likely_markdown_file ( export_path ) : <TAB><TAB><TAB>  guessed_format = MARKDOWN <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  guessed_format = RASA_YAML <TAB>  return guessed_format ",elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,if rasa.shared.data.is_likely_markdown_file(export_path,False,37.548783373492185,95.3413693076388
47,"def moveToThreadNext ( self ) : <TAB>  """"""Move a position to threadNext position."""""" <TAB>  p = self <TAB>  if p . v : <TAB><TAB>  if p . v . children : <TAB><TAB><TAB>  p . moveToFirstChild ( ) <TAB><TAB>  el<IF-STMT>: <TAB><TAB><TAB>  p . moveToNext ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  p . moveToParent ( ) <TAB><TAB><TAB>  while p : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  p . moveToNext ( ) <TAB><TAB><TAB><TAB><TAB>  break<TAB># found <TAB><TAB><TAB><TAB>  p . moveToParent ( ) <TAB><TAB><TAB>  # not found. <TAB>  return p ",if p . hasNext ( ) :,if p.isToThreadNext():,False,51.75152726484289,94.61700803274456
48,"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB>  for attr in attributes : <TAB><TAB>  value = getattr ( obj , attr , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  name = name_fmt % attr <TAB><TAB>  if formatter is not None : <TAB><TAB><TAB>  value = formatter ( attr , value ) <TAB><TAB>  info_add ( name , value ) ",if value is None :,if value is None:,False,52.80623417442995,100.00000000000004
49,"def getElement ( self , aboutUri , namespace , name ) : <TAB>  for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attr = desc . getAttributeNodeNS ( namespace , name ) <TAB><TAB><TAB>  if attr != None : <TAB><TAB><TAB><TAB>  yield attr <TAB><TAB><TAB>  for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB><TAB><TAB><TAB>  yield element ","if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :","if desc.getAttribute(aboutUri, name) == desc.getAttribute(aboutUri",False,45.204380243368924,90.31437505750223
50,def run ( self ) : <TAB>  while not self . completed : <TAB><TAB>  if self . block : <TAB><TAB><TAB>  time . sleep ( self . period ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _completed . wait ( self . period ) <TAB><TAB>  self . counter + = 1 <TAB><TAB>  try : <TAB><TAB><TAB>  self . callback ( self . counter ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dt = time . time ( ) - self . _start_time <TAB><TAB><TAB>  if dt > self . timeout : <TAB><TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  if self . counter == self . count : <TAB><TAB><TAB>  self . stop ( ) ,if self . timeout is not None :,if self.timeout:,False,23.71346133553566,98.03558693673716
51,"def _parse_fixits ( message , titer , line ) : <TAB>  """"""Parses fixit messages."""""" <TAB>  while ( <TAB><TAB>  OutputParser . message_line_re . match ( line ) is None <TAB><TAB>  and OutputParser . note_line_re . match ( line ) is None <TAB>  ) : <TAB><TAB>  message_text = line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  message . fixits . append ( <TAB><TAB><TAB><TAB>  Note ( <TAB><TAB><TAB><TAB><TAB>  message . path , <TAB><TAB><TAB><TAB><TAB>  message . line , <TAB><TAB><TAB><TAB><TAB>  line . find ( message_text ) + 1 , <TAB><TAB><TAB><TAB><TAB>  message_text , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  line = next ( titer ) <TAB>  return line ","if message_text != """" :",if message_text:,False,26.77065865351784,97.85820388268573
52,"def _connect_db ( self , force_reconnect = False ) : <TAB>  thread_id = thread . get_ident ( ) <TAB>  if force_reconnect and thread_id in ENGINES : <TAB><TAB>  del ENGINES [ thread_id ] <TAB>  conn = None <TAB>  try : <TAB><TAB>  engine = ENGINES [ thread_id ] <TAB><TAB>  conn = engine . connect ( ) <TAB><TAB>  _test = conn . execute ( "" SELECT 1 "" ) <TAB><TAB>  _test . fetchall ( ) <TAB>  except ( KeyError , MySQLdb . OperationalError ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  conn . close ( ) <TAB><TAB>  engine = sqla . create_engine ( self . db_url , pool_recycle = 3600 ) <TAB><TAB>  ENGINES [ thread_id ] = engine <TAB><TAB>  conn = engine . connect ( ) <TAB>  return conn ",if conn :,if conn:,False,53.379614784415516,100.00000000000004
53,"def read ( self , n ) : <TAB>  if self . current_frame : <TAB><TAB>  data = self . current_frame . read ( n ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . current_frame = None <TAB><TAB><TAB>  return self . file_read ( n ) <TAB><TAB>  if len ( data ) < n : <TAB><TAB><TAB>  raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB><TAB>  return data <TAB>  else : <TAB><TAB>  return self . file_read ( n ) ",if not data and n != 0 :,if data is None:,False,24.852802566362367,94.34614028569709
54,"def __setLoadCmd ( self ) : <TAB>  base = self . __rawLoadCmd <TAB>  for _ in range ( self . __machHeader . ncmds ) : <TAB><TAB>  command = LOAD_COMMAND . from_buffer_copy ( base ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  segment = SEGMENT_COMMAND . from_buffer_copy ( base ) <TAB><TAB><TAB>  self . __setSections ( segment , base [ 56 : ] , 32 ) <TAB><TAB>  elif command . cmd == MACHOFlags . LC_SEGMENT_64 : <TAB><TAB><TAB>  segment = SEGMENT_COMMAND64 . from_buffer_copy ( base ) <TAB><TAB><TAB>  self . __setSections ( segment , base [ 72 : ] , 64 ) <TAB><TAB>  base = base [ command . cmdsize : ] ",if command . cmd == MACHOFlags . LC_SEGMENT :,if command.cmd == MACHOFlags.LC_SEGMENT_32:,False,50.912274003746404,98.28389493850331
55,"def emit_post_sync_signal ( created_models , verbosity , interactive , db ) : <TAB>  # Emit the post_sync signal for every application. <TAB>  for app in models . get_apps ( ) : <TAB><TAB>  app_name = app . __name__ . split ( "" . "" ) [ - 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Running post-sync handlers for application  %s "" % app_name ) <TAB><TAB>  models . signals . post_syncdb . send ( <TAB><TAB><TAB>  sender = app , <TAB><TAB><TAB>  app = app , <TAB><TAB><TAB>  created_models = created_models , <TAB><TAB><TAB>  verbosity = verbosity , <TAB><TAB><TAB>  interactive = interactive , <TAB><TAB><TAB>  db = db , <TAB><TAB>  ) ",if verbosity >= 2 :,if app_name in models.signals.post_syncdb:,False,34.76506542009915,92.93947041634891
56,"def git_pull ( args ) : <TAB>  if len ( args ) < = 1 : <TAB><TAB>  repo = _get_repo ( ) <TAB><TAB>  _confirm_dangerous ( ) <TAB><TAB>  url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB><TAB>  if url in repo . remotes : <TAB><TAB><TAB>  origin = url <TAB><TAB><TAB>  url = repo . remotes . get ( origin ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  repo . pull ( origin_uri = url ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" No pull URL. "" ) <TAB>  else : <TAB><TAB>  print ( command_help [ "" git pull "" ] ) ",if url :,if url:,False,23.040590908250046,100.00000000000004
57,"def version ( self ) : <TAB>  try : <TAB><TAB>  return self . _version <TAB>  except AttributeError : <TAB><TAB>  for line in self . _get_metadata ( self . PKG_INFO ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _version = safe_version ( line . split ( "" : "" , 1 ) [ 1 ] . strip ( ) ) <TAB><TAB><TAB><TAB>  return self . _version <TAB><TAB>  else : <TAB><TAB><TAB>  tmpl = "" Missing  ' Version: '  header and/or  %s  file "" <TAB><TAB><TAB>  raise ValueError ( tmpl % self . PKG_INFO , self ) ","if line . lower ( ) . startswith ( ""version:"" ) :",if line.startswith('Version:,False,20.175496361654854,92.70709710126195
58,"def increment ( self , metric , labels , delta ) : <TAB>  """"""Increment a value by |delta|."""""" <TAB>  with self . _lock : <TAB><TAB>  key = self . _get_key ( metric . name , labels ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  start_time = self . _store [ key ] . start_time <TAB><TAB><TAB>  value = self . _store [ key ] . value + delta <TAB><TAB>  else : <TAB><TAB><TAB>  start_time = time . time ( ) <TAB><TAB><TAB>  value = metric . default_value + delta <TAB><TAB>  self . _store [ key ] = _StoreValue ( metric , labels , start_time , value ) ",if key in self . _store :,if key in self._store:,False,51.55827614238269,100.00000000000004
59,"def get_current_connections ( session ) : <TAB>  """"""Retrieves open connections using the the given session"""""" <TAB>  # Use Show process list to count the open sesions. <TAB>  res = session . sql ( "" SHOW PROCESSLIST "" ) . execute ( ) <TAB>  rows = res . fetch_all ( ) <TAB>  connections = { } <TAB>  for row in rows : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  connections [ row . get_string ( "" User "" ) ] = [ row . get_string ( "" Host "" ) ] <TAB><TAB>  else : <TAB><TAB><TAB>  connections [ row . get_string ( "" User "" ) ] . append ( row . get_string ( "" Host "" ) ) <TAB>  return connections ","if row . get_string ( ""User"" ) not in connections :",if row.get_string('User'):,False,61.69455305947187,95.62488519605563
60,"def asset ( * paths ) : <TAB>  for path in paths : <TAB><TAB>  fspath = www_root + "" /assets/ "" + path <TAB><TAB>  etag = "" "" <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  etag = asset_etag ( fspath ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  os . stat ( fspath ) <TAB><TAB>  except FileNotFoundError as e : <TAB><TAB><TAB>  if path == paths [ - 1 ] : <TAB><TAB><TAB><TAB>  if not os . path . exists ( fspath + "" .spt "" ) : <TAB><TAB><TAB><TAB><TAB>  tell_sentry ( e , { } ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  tell_sentry ( e , { } ) <TAB><TAB>  return asset_url + path + ( etag and "" ?etag= "" + etag ) ",if env . cache_static :,if os.path.exists(fspath):,False,51.3330135305214,95.3968779356483
61,def thread_loop ( self ) - > None : <TAB>  while not self . stop_event . is_set ( ) : <TAB><TAB>  time . sleep ( 1 ) <TAB><TAB>  new_trials = self . study . trials <TAB><TAB>  with self . lock : <TAB><TAB><TAB>  need_to_add_callback = self . new_trials is None <TAB><TAB><TAB>  self . new_trials = new_trials <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . doc . add_next_tick_callback ( self . update_callback ) ,if need_to_add_callback :,if need_to_add_callback:,False,49.29017403839746,100.00000000000004
62,"def _cache_db_tables_iterator ( tables , cache_alias , db_alias ) : <TAB>  no_tables = not tables <TAB>  cache_aliases = settings . CACHES if cache_alias is None else ( cache_alias , ) <TAB>  db_aliases = settings . DATABASES if db_alias is None else ( db_alias , ) <TAB>  for db_alias in db_aliases : <TAB><TAB>  if no_tables : <TAB><TAB><TAB>  tables = connections [ db_alias ] . introspection . table_names ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for cache_alias in cache_aliases : <TAB><TAB><TAB><TAB>  yield cache_alias , db_alias , tables ",if tables :,if tables:,False,59.43009753703969,100.00000000000004
63,"def remove_subscriber ( self , topic , subscriber ) : <TAB>  if subscriber in self . subscribers [ topic ] : <TAB><TAB>  if hasattr ( subscriber , "" _pyroRelease "" ) : <TAB><TAB><TAB>  subscriber . _pyroRelease ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB><TAB>  proxy . _pyroRelease ( ) <TAB><TAB><TAB><TAB>  del self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  self . subscribers [ topic ] . discard ( subscriber ) ","if hasattr ( subscriber , ""_pyroUri"" ) :","if hasattr(subscriber, '_pyroUri'):",False,51.13631241315986,97.26775427768334
64,"def test_constructor ( job_id ) : <TAB>  with patch ( "" apscheduler.job.Job._modify "" ) as _modify : <TAB><TAB>  scheduler_mock = MagicMock ( BaseScheduler ) <TAB><TAB>  job = Job ( scheduler_mock , id = job_id ) <TAB><TAB>  assert job . _scheduler is scheduler_mock <TAB><TAB>  assert job . _jobstore_alias is None <TAB><TAB>  modify_kwargs = _modify . call_args [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert len ( modify_kwargs [ "" id "" ] ) == 32 <TAB><TAB>  else : <TAB><TAB><TAB>  assert modify_kwargs [ "" id "" ] == job_id ",if job_id is None :,"if not isinstance(modify_kwargs, dict):",False,21.039027948134738,94.43580131589786
65,"def get_connection ( self ) : <TAB>  if self . config . proxy_host != "" "" : <TAB><TAB>  return httplib . HTTPConnection ( self . config . proxy_host , self . config . proxy_port ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return httplib . HTTPSConnection ( self . config . simpledb_host ) <TAB><TAB>  else : <TAB><TAB><TAB>  return httplib . HTTPConnection ( self . config . simpledb_host ) ",if self . config . use_https :,"if self.config.simpledb_host == ""localhost':",False,22.264930593413705,93.40735265004157
66,"def notify_login ( self , ipaddress = "" "" ) : <TAB>  if app . NOTIFY_ON_LOGIN : <TAB><TAB>  update_text = common . notifyStrings [ common . NOTIFY_LOGIN_TEXT ] <TAB><TAB>  title = common . notifyStrings [ common . NOTIFY_LOGIN ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _notify_pht ( title , update_text . format ( ipaddress ) ) ",if update_text and title and ipaddress :,if title:,False,23.81616015490327,92.0749095332902
67,"def _getItemHeight ( self , item , ctrl = None ) : <TAB>  """"""Returns the full height of the item to be inserted in the form"""""" <TAB>  if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB><TAB>  return ctrl . size [ 1 ] <TAB>  if type ( ctrl ) == psychopy . visual . Slider : <TAB><TAB>  # Set radio button layout <TAB><TAB>  if item [ "" layout "" ] == "" horiz "" : <TAB><TAB><TAB>  return 0.03 + ctrl . labelHeight * 3 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # for vertical take into account the nOptions <TAB><TAB><TAB>  return ctrl . labelHeight * len ( item [ "" options "" ] ) ","elif item [ ""layout"" ] == ""vert"" :",if type(ctrl) == psychopy.visual.TextBox2:,False,63.24869667446671,93.07667214613225
68,"def _get_errors_lines ( self ) : <TAB>  """"""Return the number of lines that contains errors to highlight."""""" <TAB>  errors_lines = [ ] <TAB>  block = self . document ( ) . begin ( ) <TAB>  while block . isValid ( ) : <TAB><TAB>  user_data = get_user_data ( block ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  errors_lines . append ( block . blockNumber ( ) ) <TAB><TAB>  block = block . next ( ) <TAB>  return errors_lines ",if user_data . error :,if user_data and user_data.has_error():,False,44.19176319130178,92.79218305419181
69,"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB>  gtk . gdk . threads_enter ( ) <TAB>  try : <TAB><TAB>  self . is_pulsing = False <TAB><TAB>  self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB><TAB>  self . pbar . set_text ( progress ) <TAB><TAB>  if frac > 1 : <TAB><TAB><TAB>  frac = 1.0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frac = 0 <TAB><TAB>  self . pbar . set_fraction ( frac ) <TAB>  finally : <TAB><TAB>  gtk . gdk . threads_leave ( ) ",if frac < 0 :,if frac < 0:,False,51.17915071075082,100.00000000000004
70,"def list_files ( basedir ) : <TAB>  """"""List files in the directory rooted at |basedir|."""""" <TAB>  if not os . path . isdir ( basedir ) : <TAB><TAB>  raise NoSuchDirectory ( basedir ) <TAB>  directories = [ "" "" ] <TAB>  while directories : <TAB><TAB>  d = directories . pop ( ) <TAB><TAB>  for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB><TAB><TAB>  filename = os . path . join ( d , basename ) <TAB><TAB><TAB>  if os . path . isdir ( os . path . join ( basedir , filename ) ) : <TAB><TAB><TAB><TAB>  directories . append ( filename ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield filename ","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",if os.path.isdir(filename):,False,30.247396616267164,92.78067620208321
71,"def assistive ( self ) : <TAB>  """"""Detects if item can be used as assistance"""""" <TAB>  # Make sure we cache results <TAB>  if self . __assistive is None : <TAB><TAB>  assistive = False <TAB><TAB>  # Go through all effects and find first assistive <TAB><TAB>  for effect in self . effects . values ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # If we find one, stop and mark item as assistive <TAB><TAB><TAB><TAB>  assistive = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  self . __assistive = assistive <TAB>  return self . __assistive ",if effect . isAssistance is True :,if effect.assistance == self.__assistance:,False,67.49215420467583,94.67144006983123
72,"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB>  # find the closest unseen from this row/col <TAB>  min_dist = maxint <TAB>  closest_unseen = None <TAB>  for row in range ( self . height ) : <TAB><TAB>  for col in range ( self . width ) : <TAB><TAB><TAB>  if filter is None or ( row , col ) not in filter : <TAB><TAB><TAB><TAB>  if self . map [ row ] [ col ] == UNSEEN : <TAB><TAB><TAB><TAB><TAB>  dist = self . distance ( row1 , col1 , row , col ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  min_dist = dist <TAB><TAB><TAB><TAB><TAB><TAB>  closest_unseen = ( row , col ) <TAB>  return closest_unseen ",if dist < min_dist :,if dist < min_dist:,False,57.41862771177466,100.00000000000004
73,"def _maybe_has_default_route ( self ) : <TAB>  for route in self . iter_routes ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  for iface in self . iter_interfaces ( ) : <TAB><TAB>  for subnet in iface . get ( "" subnets "" , [ ] ) : <TAB><TAB><TAB>  for route in subnet . get ( "" routes "" , [ ] ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if self . _is_default_route ( route ) :,if route.get('name') == 'default':,False,20.57630060921587,84.31620803406186
74,"def data ( self , data ) : <TAB>  if data is None : <TAB><TAB>  raise Exception ( "" Data cannot be None "" ) <TAB>  val = [ ] <TAB>  for d in data : <TAB><TAB>  if isinstance ( d , str ) : <TAB><TAB><TAB>  val . append ( bytes ( d , "" utf-8 "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val . append ( d ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Invalid type, data can only be an str or a bytes not  {} :  {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  type ( data ) , d <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  self . __data = val ","elif isinstance ( d , bytes ) :","if isinstance(d, bytes):",False,61.75969389216246,98.85708129572258
75,"def get_one_segment_function ( data , context , echoerr ) : <TAB>  ext = data [ "" ext "" ] <TAB>  function_name = context [ - 2 ] [ 1 ] . get ( "" function "" ) <TAB>  if function_name : <TAB><TAB>  module , function_name = get_function_strings ( function_name , context , ext ) <TAB><TAB>  func = import_segment ( function_name , data , context , echoerr , module = module ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield func ",if func :,if func:,False,50.84493598824411,97.24282508667405
76,"def generic_visit ( self , node , parents = None ) : <TAB>  parents = ( parents or [ ] ) + [ node ] <TAB>  for field , value in iter_fields ( node ) : <TAB><TAB>  if isinstance ( value , list ) : <TAB><TAB><TAB>  for item in value : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . visit ( item , parents ) <TAB><TAB>  elif isinstance ( value , AST ) : <TAB><TAB><TAB>  self . visit ( value , parents ) ","if isinstance ( item , AST ) :","if isinstance(item, AST):",False,50.99370395923435,100.00000000000004
77,"def find_scintilla_constants ( f ) : <TAB>  lexers = [ ] <TAB>  states = [ ] <TAB>  for name in f . order : <TAB><TAB>  v = f . features [ name ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if v [ "" FeatureType "" ] == "" val "" : <TAB><TAB><TAB><TAB>  if name . startswith ( "" SCE_ "" ) : <TAB><TAB><TAB><TAB><TAB>  states . append ( ( name , v [ "" Value "" ] ) ) <TAB><TAB><TAB><TAB>  elif name . startswith ( "" SCLEX_ "" ) : <TAB><TAB><TAB><TAB><TAB>  lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB>  return ( lexers , states ) ","if v [ ""Category"" ] != ""Deprecated"" :",if v['FeatureType'] == 'SCintilla':,False,50.788897725792445,95.04738326814253
78,"def things ( self , query ) : <TAB>  limit = query . pop ( "" limit "" , 100 ) <TAB>  offset = query . pop ( "" offset "" , 0 ) <TAB>  keys = set ( self . docs ) <TAB>  for k , v in query . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # query keys need to be flattened properly, <TAB><TAB><TAB>  # this corrects any nested keys that have been included <TAB><TAB><TAB>  # in values. <TAB><TAB><TAB>  flat = common . flatten_dict ( v ) [ 0 ] <TAB><TAB><TAB>  k + = "" . "" + web . rstrips ( flat [ 0 ] , "" .key "" ) <TAB><TAB><TAB>  v = flat [ 1 ] <TAB><TAB>  keys = set ( k for k in self . filter_index ( self . index , k , v ) if k in keys ) <TAB>  keys = sorted ( keys ) <TAB>  return keys [ offset : offset + limit ] ","if isinstance ( v , dict ) :",if k not in keys:,False,55.11544593879216,96.9557833631025
79,"def del_ ( self , key ) : <TAB>  initial_hash = hash_ = self . hash ( key ) <TAB>  while True : <TAB><TAB>  if self . _keys [ hash_ ] is self . _empty : <TAB><TAB><TAB>  # That key was never assigned <TAB><TAB><TAB>  return None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # key found, assign with deleted sentinel <TAB><TAB><TAB>  self . _keys [ hash_ ] = self . _deleted <TAB><TAB><TAB>  self . _values [ hash_ ] = self . _deleted <TAB><TAB><TAB>  self . _len - = 1 <TAB><TAB><TAB>  return <TAB><TAB>  hash_ = self . _rehash ( hash_ ) <TAB><TAB>  if initial_hash == hash_ : <TAB><TAB><TAB>  # table is full and wrapped around <TAB><TAB><TAB>  return None ",elif self . _keys [ hash_ ] == key :,if hash_ not in self._keys:,False,59.42047084510962,95.74139579267619
80,"def test_204_invalid_content_length ( self ) : <TAB>  # 204 status with non-zero content length is malformed <TAB>  with ExpectLog ( gen_log , "" .*Response with code 204 should not have body "" ) : <TAB><TAB>  response = self . fetch ( "" /?error=1 "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . skipTest ( "" requires HTTP/1.x "" ) <TAB><TAB>  if self . http_client . configured_class != SimpleAsyncHTTPClient : <TAB><TAB><TAB>  self . skipTest ( "" curl client accepts invalid headers "" ) <TAB><TAB>  self . assertEqual ( response . code , 599 ) ",if not self . http1 :,if not response:,False,38.261520020011226,97.1748903692135
81,"def __str__ ( self ) - > str : <TAB>  text = "" \n "" <TAB>  for k , r in self . result . items ( ) : <TAB><TAB>  text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text + = "" #  {}  (failed) \n "" . format ( k ) <TAB><TAB>  else : <TAB><TAB><TAB>  text + = "" #  {}  (succeeded) \n "" . format ( k ) <TAB><TAB>  text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB><TAB>  for sub_r in r : <TAB><TAB><TAB>  text + = "" ****  {} \n "" . format ( sub_r . name ) <TAB><TAB><TAB>  text + = "" {} \n "" . format ( sub_r ) <TAB>  return text ",if r . failed :,if r is None:,False,19.72779761702183,98.48453278252143
82,"def DeleteTask ( ) : <TAB>  oid = request . form . get ( "" oid "" , "" "" ) <TAB>  if oid : <TAB><TAB>  result = Mongo . coll [ "" Task "" ] . delete_one ( { "" _id "" : ObjectId ( oid ) } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = Mongo . coll [ "" Result "" ] . delete_many ( { "" task_id "" : ObjectId ( oid ) } ) <TAB><TAB><TAB>  if result : <TAB><TAB><TAB><TAB>  return "" success "" <TAB>  return "" fail "" ",if result . deleted_count > 0 :,if result:,False,22.240565468523325,94.86534724457786
83,"def _replace_vars ( self , line , extracted , env_variables ) : <TAB>  for e in extracted : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = env_variables . get ( e ) <TAB><TAB><TAB>  if isinstance ( value , dict ) or isinstance ( value , list ) : <TAB><TAB><TAB><TAB>  value = pprint . pformat ( value ) <TAB><TAB><TAB>  decorated = self . _decorate_var ( e ) <TAB><TAB><TAB>  line = line . replace ( decorated , str ( value ) ) <TAB>  return line ",if e in env_variables :,if e in env_variables:,False,50.98680685092947,100.00000000000004
84,"def should_include ( service ) : <TAB>  for f in filt : <TAB><TAB>  if f == "" status "" : <TAB><TAB><TAB>  state = filt [ f ] <TAB><TAB><TAB>  containers = project . containers ( [ service . name ] , stopped = True ) <TAB><TAB><TAB>  if not has_container_with_state ( containers , state ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif f == "" source "" : <TAB><TAB><TAB>  source = filt [ f ] <TAB><TAB><TAB>  if source == "" image "" or source == "" build "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise UserError ( "" Invalid filter:  %s "" % f ) <TAB>  return True ",if source not in service . options :,"if source == ""image_or_build':",False,43.34626579457473,96.52385217260814
85,def state_callback_loop ( ) : <TAB>  if usercallback : <TAB><TAB>  when = 1 <TAB><TAB>  while ( <TAB><TAB><TAB>  when <TAB><TAB><TAB>  and not self . future_removed . done ( ) <TAB><TAB><TAB>  and not self . session . shutdownstarttime <TAB><TAB>  ) : <TAB><TAB><TAB>  result = usercallback ( self . get_state ( ) ) <TAB><TAB><TAB>  when = ( await result ) if iscoroutine ( result ) else result <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  await sleep ( when ) ,if when > 0.0 and not self . session . shutdownstarttime :,if when > 0:,False,20.455717758467664,94.20221861684851
86,"def __get_new_timeout ( self , timeout ) : <TAB>  """"""When using --timeout_multiplier=#.#"""""" <TAB>  self . __check_scope ( ) <TAB>  try : <TAB><TAB>  timeout_multiplier = float ( self . timeout_multiplier ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  timeout_multiplier = 0.5 <TAB><TAB>  timeout = int ( math . ceil ( timeout_multiplier * timeout ) ) <TAB><TAB>  return timeout <TAB>  except Exception : <TAB><TAB>  # Wrong data type for timeout_multiplier (expecting int or float) <TAB><TAB>  return timeout ",if timeout_multiplier <= 0.5 :,if timeout_multiplier < 0.5:,False,60.18876372305315,98.39874465173874
87,"def readexactly ( self , n ) : <TAB>  buf = b "" "" <TAB>  while n : <TAB><TAB>  yield IORead ( self . s ) <TAB><TAB>  res = self . s . read ( n ) <TAB><TAB>  assert res is not None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield IOReadDone ( self . s ) <TAB><TAB><TAB>  break <TAB><TAB>  buf + = res <TAB><TAB>  n - = len ( res ) <TAB>  return buf ",if not res :,if n == 0:,False,20.200585751706036,95.63957336396375
88,"def contract_rendering_pane ( event ) : <TAB>  """"""Expand the rendering pane."""""" <TAB>  c = event . get ( "" c "" ) <TAB>  if c : <TAB><TAB>  vr = c . frame . top . findChild ( QtWidgets . QWidget , "" viewrendered_pane "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vr . contract ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  # Just open the pane. <TAB><TAB><TAB>  viewrendered ( event ) ",if vr :,if vr:,False,52.72075889493911,100.00000000000004
89,"def translate_headers ( self , environ ) : <TAB>  """"""Translate CGI-environ header names to HTTP header names."""""" <TAB>  for cgiName in environ : <TAB><TAB>  # We assume all incoming header keys are uppercase already. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield self . headerNames [ cgiName ] , environ [ cgiName ] <TAB><TAB>  elif cgiName [ : 5 ] == "" HTTP_ "" : <TAB><TAB><TAB>  # Hackish attempt at recovering original header names. <TAB><TAB><TAB>  translatedHeader = cgiName [ 5 : ] . replace ( "" _ "" , "" - "" ) <TAB><TAB><TAB>  yield translatedHeader , environ [ cgiName ] ",if cgiName in self . headerNames :,if cgiName in self.headerNames:,False,64.91398474070323,100.00000000000004
90,"def get_value_from_string ( self , string_value ) : <TAB>  """"""Return internal representation starting from CFN/user-input value."""""" <TAB>  param_value = self . get_default_value ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  string_value = str ( string_value ) . strip ( ) <TAB><TAB><TAB>  if string_value != "" NONE "" : <TAB><TAB><TAB><TAB>  param_value = int ( string_value ) <TAB>  except ValueError : <TAB><TAB>  self . pcluster_config . warn ( <TAB><TAB><TAB>  "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB><TAB><TAB>  "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB><TAB>  ) <TAB>  return param_value ",if string_value is not None :,if string_value != None:,False,58.999400586789186,98.43015134438294
91,"def monitor_filter ( self ) : <TAB>  """"""Return filtered service objects list"""""" <TAB>  services = self . client . services . list ( filters = { "" label "" : "" com.ouroboros.enable "" } ) <TAB>  monitored_services = [ ] <TAB>  for service in services : <TAB><TAB>  ouro_label = service . attrs [ "" Spec "" ] [ "" Labels "" ] . get ( "" com.ouroboros.enable "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  monitored_services . append ( service ) <TAB>  self . data_manager . monitored_containers [ self . socket ] = len ( monitored_services ) <TAB>  self . data_manager . set ( self . socket ) <TAB>  return monitored_services ","if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",if ouro_label == self.socket:,False,25.78736097977047,86.85366034085337
92,"def nextEditable ( self ) : <TAB>  """"""Moves focus of the cursor to the next editable window"""""" <TAB>  if self . currentEditable is None : <TAB><TAB>  if len ( self . _editableChildren ) : <TAB><TAB><TAB>  self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB>  else : <TAB><TAB>  for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB><TAB><TAB>  if ref in self . _editableChildren : <TAB><TAB><TAB><TAB>  cei = self . _editableChildren . index ( ref ) <TAB><TAB><TAB><TAB>  nei = cei + 1 <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  nei = 0 <TAB><TAB><TAB><TAB>  self . _currentEditableRef = self . _editableChildren [ nei ] <TAB>  return self . currentEditable ",if nei >= len ( self . _editableChildren ) :,if nei >= len(self._editableChildren):,False,59.5495303350289,100.00000000000004
93,"def linkify_cm_by_tp ( self , timeperiods ) : <TAB>  for rm in self : <TAB><TAB>  mtp_name = rm . modulation_period . strip ( ) <TAB><TAB>  # The new member list, in id <TAB><TAB>  mtp = timeperiods . find_by_name ( mtp_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  err = ( <TAB><TAB><TAB><TAB>  "" Error: the business impact modulation  ' %s '  got an unknown  "" <TAB><TAB><TAB><TAB>  "" modulation_period  ' %s ' "" % ( rm . get_name ( ) , mtp_name ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  rm . configuration_errors . append ( err ) <TAB><TAB>  rm . modulation_period = mtp ","if mtp_name != """" and mtp is None :",if mtp is None:,False,57.85777778373662,93.30098592445009
94,def close_open_fds ( keep = None ) :<TAB># noqa <TAB>  keep = [ maybe_fileno ( f ) for f in ( keep or [ ] ) if maybe_fileno ( f ) is not None ] <TAB>  for fd in reversed ( range ( get_fdmax ( default = 2048 ) ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  os . close ( fd ) <TAB><TAB><TAB>  except OSError as exc : <TAB><TAB><TAB><TAB>  if exc . errno != errno . EBADF : <TAB><TAB><TAB><TAB><TAB>  raise ,if fd not in keep :,if fd not in keep:,False,40.28297588260058,97.20609073682621
95,"def _append_child_from_unparsed_xml ( father_node , unparsed_xml ) : <TAB>  """"""Append child xml nodes to a node."""""" <TAB>  dom_tree = parseString ( unparsed_xml ) <TAB>  if dom_tree . hasChildNodes ( ) : <TAB><TAB>  first_child = dom_tree . childNodes [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  child_nodes = first_child . childNodes <TAB><TAB><TAB>  for _ in range ( len ( child_nodes ) ) : <TAB><TAB><TAB><TAB>  childNode = child_nodes . item ( 0 ) <TAB><TAB><TAB><TAB>  father_node . appendChild ( childNode ) <TAB><TAB><TAB>  return <TAB>  raise DistutilsInternalError ( <TAB><TAB>  "" Could not Append append elements to  "" "" the Windows msi descriptor. "" <TAB>  ) ",if first_child . hasChildNodes ( ) :,if first_child:,False,56.86969390243398,97.46302338734337
96,"def process_request ( self , request ) : <TAB>  for old , new in self . names_name : <TAB><TAB>  request . uri = request . uri . replace ( old , new ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  body = six . ensure_str ( request . body ) <TAB><TAB><TAB>  if old in body : <TAB><TAB><TAB><TAB>  request . body = body . replace ( old , new ) <TAB>  return request ",if is_text_payload ( request ) and request . body :,"if hasattr(request, 'body'):",False,25.262060693021603,90.02990259511311
97,"def __init__ ( self , * * options ) : <TAB>  self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB>  self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB>  self . _functions = set ( ) <TAB>  if self . func_name_highlighting : <TAB><TAB>  from pygments . lexers . _luabuiltins import MODULES <TAB><TAB>  for mod , func in MODULES . iteritems ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _functions . update ( func ) <TAB>  RegexLexer . __init__ ( self , * * options ) ",if mod not in self . disabled_modules :,if mod in self._functions:,False,19.40797123629246,96.22246237598999
98,"def GetBestSizeForParentSize ( self , parentSize ) : <TAB>  """"""Finds the best width and height given the parent's width and height."""""" <TAB>  if len ( self . GetChildren ( ) ) == 1 : <TAB><TAB>  win = self . GetChildren ( ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  temp_dc = wx . ClientDC ( self ) <TAB><TAB><TAB>  childSize = win . GetBestSizeForParentSize ( parentSize ) <TAB><TAB><TAB>  clientParentSize = self . _art . GetPanelClientSize ( <TAB><TAB><TAB><TAB>  temp_dc , self , wx . Size ( * parentSize ) , None <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  overallSize = self . _art . GetPanelSize ( <TAB><TAB><TAB><TAB>  temp_dc , self , wx . Size ( * clientParentSize ) , None <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return overallSize <TAB>  return self . GetSize ( ) ","if isinstance ( win , RibbonControl ) :",if win.GetWindow() == wx.Window.CLICKED:,False,38.39238875757871,94.81890560964294
99,"def pid_from_name ( name ) : <TAB>  processes = [ ] <TAB>  for pid in os . listdir ( "" /proc "" ) : <TAB><TAB>  try : <TAB><TAB><TAB>  pid = int ( pid ) <TAB><TAB><TAB>  pname , cmdline = SunProcess . _name_args ( pid ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return pid <TAB><TAB><TAB>  if name in cmdline . split ( "" "" , 1 ) [ 0 ] : <TAB><TAB><TAB><TAB>  return pid <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB>  raise ProcessException ( "" No process with such name:  %s "" % name ) ",if name in pname :,if pname == 'pid':,False,25.770814521252273,97.09885113353843
100,"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB>  for element in file_list : <TAB><TAB>  if idx == num : <TAB><TAB><TAB>  return element <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB><TAB><TAB>  if not isinstance ( i , int ) : <TAB><TAB><TAB><TAB>  return i <TAB><TAB><TAB>  idx = i <TAB><TAB>  else : <TAB><TAB><TAB>  idx + = 1 <TAB>  return idx ",if element [ 3 ] and element [ 4 ] :,if element[1] == 'file':,False,44.55415972432992,95.31959977493081
101,"def scan_block_scalar_indentation ( self ) : <TAB>  # See the specification for details. <TAB>  chunks = [ ] <TAB>  max_indent = 0 <TAB>  end_mark = self . get_mark ( ) <TAB>  while self . peek ( ) in "" \r \n \x85 \u2028 \u2029 "" : <TAB><TAB>  if self . peek ( ) != "" "" : <TAB><TAB><TAB>  chunks . append ( self . scan_line_break ( ) ) <TAB><TAB><TAB>  end_mark = self . get_mark ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . forward ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  max_indent = self . column <TAB>  return chunks , max_indent , end_mark ",if self . column > max_indent :,if self.column > max_indent:,False,29.30610158469513,100.00000000000004
102,"def ant_map ( m ) : <TAB>  tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB>  players = { } <TAB>  for row in m : <TAB><TAB>  tmp + = "" m  "" <TAB><TAB>  for col in row : <TAB><TAB><TAB>  if col == LAND : <TAB><TAB><TAB><TAB>  tmp + = "" . "" <TAB><TAB><TAB>  elif col == BARRIER : <TAB><TAB><TAB><TAB>  tmp + = "" % "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tmp + = "" * "" <TAB><TAB><TAB>  elif col == UNSEEN : <TAB><TAB><TAB><TAB>  tmp + = "" ? "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  players [ col ] = True <TAB><TAB><TAB><TAB>  tmp + = chr ( col + 97 ) <TAB><TAB>  tmp + = "" \n "" <TAB>  tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB>  return tmp ",elif col == FOOD :,if col == LAND:,False,18.313708441148606,97.13191052185874
103,"def prepare_data ( entry ) : <TAB>  branch_wise_entries = { } <TAB>  gross_pay = 0 <TAB>  for d in entry : <TAB><TAB>  gross_pay + = d . gross_pay <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  branch_wise_entries [ d . branch ] [ d . mode_of_payment ] = d . net_pay <TAB><TAB>  else : <TAB><TAB><TAB>  branch_wise_entries . setdefault ( d . branch , { } ) . setdefault ( <TAB><TAB><TAB><TAB>  d . mode_of_payment , d . net_pay <TAB><TAB><TAB>  ) <TAB>  return branch_wise_entries , gross_pay ",if branch_wise_entries . get ( d . branch ) :,if d.branch in branch_wise_entries:,False,18.71415857478885,95.41403015050902
104,"def __init__ ( self , uuid = None , cluster_state = None , children = None , * * kwargs ) : <TAB>  self . uuid = uuid <TAB>  self . cluster_state = cluster_state <TAB>  if self . cluster_state is not None : <TAB><TAB>  self . children = WeakSet ( <TAB><TAB><TAB>  self . cluster_state . tasks . get ( task_id ) <TAB><TAB><TAB>  for task_id in children or ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  self . children = WeakSet ( ) <TAB>  self . _serializer_handlers = { <TAB><TAB>  "" children "" : self . _serializable_children , <TAB><TAB>  "" root "" : self . _serializable_root , <TAB><TAB>  "" parent "" : self . _serializable_parent , <TAB>  } <TAB>  if kwargs : <TAB><TAB>  self . __dict__ . update ( kwargs ) ",if task_id in self . cluster_state . tasks,if not self.children:,False,50.28101458570442,95.25064957812366
105,"def listdir ( self , d ) : <TAB>  try : <TAB><TAB>  return [ <TAB><TAB><TAB>  p <TAB><TAB><TAB>  for p in os . listdir ( d ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  ] <TAB>  except OSError : <TAB><TAB>  return [ ] ","if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )",if p.startswith('.'):,False,17.701495580582392,70.04060667893962
106,"def send_packed_command ( self , command , check_health = True ) : <TAB>  if not self . _sock : <TAB><TAB>  self . connect ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  command = [ command ] <TAB><TAB>  for item in command : <TAB><TAB><TAB>  self . _sock . sendall ( item ) <TAB>  except socket . error as e : <TAB><TAB>  self . disconnect ( ) <TAB><TAB>  if len ( e . args ) == 1 : <TAB><TAB><TAB>  _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  _errno , errmsg = e . args <TAB><TAB>  raise ConnectionError ( <TAB><TAB><TAB>  "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB><TAB>  ) <TAB>  except Exception : <TAB><TAB>  self . disconnect ( ) <TAB><TAB>  raise ","if isinstance ( command , str ) :",if check_health:,False,31.463569092876487,97.0615984442148
107,"def run ( self ) : <TAB>  """"""Start the scanner"""""" <TAB>  logging . info ( "" Dirscanner starting up "" ) <TAB>  self . shutdown = False <TAB>  while not self . shutdown : <TAB><TAB>  # Wait to be woken up or triggered <TAB><TAB>  with self . loop_condition : <TAB><TAB><TAB>  self . loop_condition . wait ( self . dirscan_speed ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . scan ( ) ",if self . dirscan_speed and not self . shutdown :,if self.scan:,False,58.21032207952218,92.51165120258834
108,"def __aexit__ ( <TAB>  self , exc_type : type , exc_value : BaseException , tb : TracebackType  ) - > None : <TAB>  if exc_type is not None : <TAB><TAB>  await self . close ( ) <TAB>  await self . _task <TAB>  while not self . _receive_queue . empty ( ) : <TAB><TAB>  data = await self . _receive_queue . get ( ) <TAB><TAB>  if isinstance ( data , bytes ) : <TAB><TAB><TAB>  self . response_data . extend ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise data ","elif not isinstance ( data , HTTPDisconnect ) :",if exc_type is not None:,False,22.756051903835157,94.04313697291782
109,"def f ( msg ) : <TAB>  text = extractor ( msg ) <TAB>  for px in prefix : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  chunks = text [ len ( px ) : ] . split ( separator ) <TAB><TAB><TAB>  return chunks [ 0 ] , ( chunks [ 1 : ] , ) if pass_args else ( ) <TAB>  return ( ( None , ) , )<TAB># to distinguish with `None` ",if text . startswith ( px ) :,if text.startswith(px):,False,39.679862615827034,95.91116223104595
110,"def _flatten ( * args ) : <TAB>  ahs = set ( ) <TAB>  if len ( args ) > 0 : <TAB><TAB>  for item in args : <TAB><TAB><TAB>  if type ( item ) is ActionHandle : <TAB><TAB><TAB><TAB>  ahs . add ( item ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for ah in item : <TAB><TAB><TAB><TAB><TAB>  if type ( ah ) is not ActionHandle :<TAB># pragma:nocover <TAB><TAB><TAB><TAB><TAB><TAB>  raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB><TAB><TAB><TAB><TAB>  ahs . add ( ah ) <TAB><TAB><TAB>  else :<TAB># pragma:nocover <TAB><TAB><TAB><TAB>  raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB>  return ahs ","elif type ( item ) in ( list , tuple , dict , set ) :","if isinstance(item, (list, tuple)):",False,48.32410832240885,93.16172651338921
111,"def find_class ( self , module , name ) : <TAB>  # Subclasses may override this. <TAB>  sys . audit ( "" pickle.find_class "" , module , name ) <TAB>  if self . proto < 3 and self . fix_imports : <TAB><TAB>  if ( module , name ) in _compat_pickle . NAME_MAPPING : <TAB><TAB><TAB>  module , name = _compat_pickle . NAME_MAPPING [ ( module , name ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module = _compat_pickle . IMPORT_MAPPING [ module ] <TAB>  __import__ ( module , level = 0 ) <TAB>  if self . proto > = 4 : <TAB><TAB>  return _getattribute ( sys . modules [ module ] , name ) [ 0 ] <TAB>  else : <TAB><TAB>  return getattr ( sys . modules [ module ] , name ) ",elif module in _compat_pickle . IMPORT_MAPPING :,if module in _compat_pickle.IMPORT_MAPPING:,False,26.987009094613278,98.83579057291513
112,"def _send_until_done ( self , data ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  return self . connection . send ( data ) <TAB><TAB>  except OpenSSL . SSL . WantWriteError : <TAB><TAB><TAB>  wr = util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise timeout ( ) <TAB><TAB><TAB>  continue <TAB><TAB>  except OpenSSL . SSL . SysCallError as e : <TAB><TAB><TAB>  raise SocketError ( str ( e ) ) ",if not wr :,if wr is None:,False,23.319911026446107,97.3243451808793
113,"def __new__ ( cls , * args , * * kwargs ) : <TAB>  """"""Hack to ensure method defined as async are implemented as such."""""" <TAB>  coroutines = inspect . getmembers ( BaseManager , predicate = inspect . iscoroutinefunction ) <TAB>  for coroutine in coroutines : <TAB><TAB>  implemented_method = getattr ( cls , coroutine [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" The method  %s  must be a coroutine "" % implemented_method ) <TAB>  return super ( ) . __new__ ( cls , * args , * * kwargs ) ",if not inspect . iscoroutinefunction ( implemented_method ) :,if not implemented_method:,False,45.42553292707758,94.52951915189809
114,"def add_directive ( self , name , obj , content = None , arguments = None , * * options ) : <TAB>  if isinstance ( obj , clstypes ) and issubclass ( obj , Directive ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ExtensionError ( <TAB><TAB><TAB><TAB>  "" when adding directive classes, no  "" "" additional arguments may be given "" <TAB><TAB><TAB>  ) <TAB><TAB>  directives . register_directive ( name , directive_dwim ( obj ) ) <TAB>  else : <TAB><TAB>  obj . content = content <TAB><TAB>  obj . arguments = arguments <TAB><TAB>  obj . options = options <TAB><TAB>  directives . register_directive ( name , obj ) ",if content or arguments or options :,if arguments is None:,False,49.84137112831644,96.47295573052098
115,"def create ( self , w ) : <TAB>  if w . use_eventloop : <TAB><TAB>  # does not use dedicated timer thread. <TAB><TAB>  w . timer = _Timer ( max_interval = 10.0 ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Default Timer is set by the pool, as for example, the <TAB><TAB><TAB>  # eventlet pool needs a custom timer implementation. <TAB><TAB><TAB>  w . timer_cls = w . pool_cls . Timer <TAB><TAB>  w . timer = self . instantiate ( <TAB><TAB><TAB>  w . timer_cls , <TAB><TAB><TAB>  max_interval = w . timer_precision , <TAB><TAB><TAB>  on_error = self . on_timer_error , <TAB><TAB><TAB>  on_tick = self . on_timer_tick , <TAB><TAB>  ) ",if not w . timer_cls :,if w.timer_cls is None:,False,66.35620701638415,97.81159254140027
116,"def _config ( _molecule_file , request ) : <TAB>  with open ( _molecule_file ) as f : <TAB><TAB>  d = util . safe_load ( f ) <TAB>  if hasattr ( request , "" param "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d2 = util . safe_load ( request . getfixturevalue ( request . param ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  d2 = request . getfixturevalue ( request . param ) <TAB><TAB>  # print(100, d) <TAB><TAB>  # print(200, d2) <TAB><TAB>  d = util . merge_dicts ( d , d2 ) <TAB><TAB>  # print(300, d) <TAB>  return d ","if isinstance ( request . getfixturevalue ( request . param ) , str ) :","if hasattr(request, 'param'):",False,45.890244774717296,93.35059576055336
117,"def _instrument_model ( self , model ) : <TAB>  for key , value in list ( <TAB><TAB>  model . __dict__ . items ( ) <TAB>  ) :<TAB># avoid ""dictionary keys changed during iteration"" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_layer = self . _instrument ( value ) <TAB><TAB><TAB>  if new_layer is not value : <TAB><TAB><TAB><TAB>  setattr ( model , key , new_layer ) <TAB><TAB>  elif isinstance ( value , list ) : <TAB><TAB><TAB>  for i , item in enumerate ( value ) : <TAB><TAB><TAB><TAB>  if isinstance ( item , tf . keras . layers . Layer ) : <TAB><TAB><TAB><TAB><TAB>  value [ i ] = self . _instrument ( item ) <TAB>  return model ","if isinstance ( value , tf . keras . layers . Layer ) :","if isinstance(value, (int, float)):",False,47.60666138215196,95.02300465755538
118,"def is_accepted_drag_event ( self , event ) : <TAB>  if event . source ( ) == self . table : <TAB><TAB>  return True <TAB>  mime = event . mimeData ( ) <TAB>  if mime . hasUrls ( ) : <TAB><TAB>  for url in mime . urls ( ) : <TAB><TAB><TAB>  # Only support local files. <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  # And only allow supported extensions. <TAB><TAB><TAB>  filename = url . toLocalFile ( ) <TAB><TAB><TAB>  extension = os . path . splitext ( filename ) [ 1 ] . lower ( ) [ 1 : ] <TAB><TAB><TAB>  if extension not in _dictionary_formats ( ) : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  return True <TAB>  return False ",if not url . isLocalFile ( ) :,if url.isLocalFile():,False,55.03747523925263,98.93224022270128
119,"def explain ( self , other , depth = 0 ) : <TAB>  exp = super ( UnionType , self ) . explain ( other , depth ) <TAB>  for ndx , subtype in enumerate ( self . params [ "" allowed_types "" ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exp + = "" \n {} and "" . format ( "" "" . join ( [ "" \t "" ] * depth ) ) <TAB><TAB>  exp + = "" \n "" + subtype . explain ( other , depth = depth + 1 ) <TAB>  return exp ",if ndx > 0 :,if ndx == self.num_types:,False,29.01346960965414,93.66877916507006
120,"def test_k_is_stochastic_parameter ( self ) : <TAB>  # k as stochastic parameter <TAB>  aug = iaa . MedianBlur ( k = iap . Choice ( [ 3 , 5 ] ) ) <TAB>  seen = [ False , False ] <TAB>  for i in sm . xrange ( 100 ) : <TAB><TAB>  observed = aug . augment_image ( self . base_img ) <TAB><TAB>  if np . array_equal ( observed , self . blur3x3 ) : <TAB><TAB><TAB>  seen [ 0 ] + = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  seen [ 1 ] + = True <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( "" Unexpected result in MedianBlur@2 "" ) <TAB><TAB>  if all ( seen ) : <TAB><TAB><TAB>  break <TAB>  assert np . all ( seen ) ","elif np . array_equal ( observed , self . blur5x5 ) :","if np.all(seen, self.blur3x3):",False,26.67632419197718,94.9466967136736
121,"def test_get_message ( self ) : <TAB>  async with self . chat_client : <TAB><TAB>  await self . _create_thread ( ) <TAB><TAB>  async with self . chat_thread_client : <TAB><TAB><TAB>  message_id = await self . _send_message ( ) <TAB><TAB><TAB>  message = await self . chat_thread_client . get_message ( message_id ) <TAB><TAB><TAB>  assert message . id == message_id <TAB><TAB><TAB>  assert message . type == ChatMessageType . TEXT <TAB><TAB><TAB>  assert message . content . message == "" hello world "" <TAB><TAB>  # delete chat threads <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await self . chat_client . delete_chat_thread ( self . thread_id ) ",if not self . is_playback ( ) :,if self.thread_id:,False,50.979511929798264,95.96914747760022
122,"def do_write_property ( self , device , callback = None ) : <TAB>  try : <TAB><TAB>  iocb = ( <TAB><TAB><TAB>  device <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else self . form_iocb ( device , request_type = "" writeProperty "" ) <TAB><TAB>  ) <TAB><TAB>  deferred ( self . request_io , iocb ) <TAB><TAB>  self . requests_in_progress . update ( { iocb : { "" callback "" : callback } } ) <TAB><TAB>  iocb . add_callback ( self . __general_cb ) <TAB>  except Exception as error : <TAB><TAB>  log . exception ( "" exception:  %r "" , error ) ","if isinstance ( device , IOCB )",if self.form_iocb is None:,False,33.744897480516244,94.73055895152643
123,"def fit ( self , dataset , force_retrain ) : <TAB>  if force_retrain : <TAB><TAB>  self . sub_unit_1 [ "" fitted "" ] = True <TAB><TAB>  self . sub_unit_1 [ "" calls "" ] + = 1 <TAB><TAB>  self . sub_unit_2 [ "" fitted "" ] = True <TAB><TAB>  self . sub_unit_2 [ "" calls "" ] + = 1 <TAB>  else : <TAB><TAB>  if not self . sub_unit_1 [ "" fitted "" ] : <TAB><TAB><TAB>  self . sub_unit_1 [ "" fitted "" ] = True <TAB><TAB><TAB>  self . sub_unit_1 [ "" calls "" ] + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . sub_unit_2 [ "" fitted "" ] = True <TAB><TAB><TAB>  self . sub_unit_2 [ "" calls "" ] + = 1 <TAB>  return self ","if not self . sub_unit_2 [ ""fitted"" ] :",if self.sub_unit_1['retrain']:,False,23.144892892749937,96.4396766225622
124,"def _insert_with_loop ( self ) : <TAB>  id_list = [ ] <TAB>  last_id = None <TAB>  return_id_list = self . _return_id_list <TAB>  for row in self . _rows : <TAB><TAB>  last_id = InsertQuery ( self . model_class , row ) . upsert ( self . _upsert ) . execute ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  id_list . append ( last_id ) <TAB>  <IF-STMT>: <TAB><TAB>  return id_list <TAB>  else : <TAB><TAB>  return last_id ",if return_id_list :,if last_id is not None:,False,19.6933950179925,91.33466820552256
125,"def merge_block ( self ) : <TAB>  """"""merges a block in the map"""""" <TAB>  for i in range ( self . block . x ) : <TAB><TAB>  for j in range ( self . block . x ) : <TAB><TAB><TAB>  c = self . block . get ( i , j ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . map [ ( i + self . block . pos . x , j + self . block . pos . y ) ] = c ",if c :,if c is not None:,False,44.61721369445715,96.54006048023358
126,"def configure_plex ( config ) : <TAB>  core . PLEX_SSL = int ( config [ "" Plex "" ] [ "" plex_ssl "" ] ) <TAB>  core . PLEX_HOST = config [ "" Plex "" ] [ "" plex_host "" ] <TAB>  core . PLEX_PORT = config [ "" Plex "" ] [ "" plex_port "" ] <TAB>  core . PLEX_TOKEN = config [ "" Plex "" ] [ "" plex_token "" ] <TAB>  plex_section = config [ "" Plex "" ] [ "" plex_sections "" ] or [ ] <TAB>  if plex_section : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  plex_section = "" , "" . join ( plex_section )<TAB># fix in case this imported as list. <TAB><TAB>  plex_section = [ tuple ( item . split ( "" , "" ) ) for item in plex_section . split ( "" | "" ) ] <TAB>  core . PLEX_SECTION = plex_section ","if isinstance ( plex_section , list ) :",if len(plex_section) > 1:,False,26.167332087478552,95.0325646516386
127,"def select ( self ) : <TAB>  e = xlib . XEvent ( ) <TAB>  while xlib . XPending ( self . _display ) : <TAB><TAB>  xlib . XNextEvent ( self . _display , e ) <TAB><TAB>  # Key events are filtered by the xlib window event <TAB><TAB>  # handler so they get a shot at the prefiltered event. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if xlib . XFilterEvent ( e , e . xany . window ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  dispatch = self . _window_map [ e . xany . window ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  continue <TAB><TAB>  dispatch ( e ) ","if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) :","if xlib.XFilterEvent(e, xlib.XFilter.TYPE_PRESS",False,64.00774596036763,92.22942846312783
128,"def format_message ( self ) : <TAB>  bits = [ self . message ] <TAB>  if self . possibilities : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bits . append ( "" Did you mean  %s ? "" % self . possibilities [ 0 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  possibilities = sorted ( self . possibilities ) <TAB><TAB><TAB>  bits . append ( "" (Possible options:  %s ) "" % "" ,  "" . join ( possibilities ) ) <TAB>  return ""<TAB>"" . join ( bits ) ",if len ( self . possibilities ) == 1 :,if len(self.possibilities) == 1:,False,51.069555337083884,96.80991184556267
129,"def _collect_logs ( model ) : <TAB>  page_token = None <TAB>  all_logs = [ ] <TAB>  while True : <TAB><TAB>  paginated_logs = model . lookup_logs ( now , later , page_token = page_token ) <TAB><TAB>  page_token = paginated_logs . next_page_token <TAB><TAB>  all_logs . extend ( paginated_logs . logs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return all_logs ",if page_token is None :,if page_token is None:,False,51.160026884860656,100.00000000000004
130,"def run ( self ) : <TAB>  while True : <TAB><TAB>  context_id_list_tuple = self . _inflated_addresses . get ( block = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  c_id , inflated_address_list = context_id_list_tuple <TAB><TAB>  inflated_value_map = dict ( inflated_address_list ) <TAB><TAB>  if c_id in self . _contexts : <TAB><TAB><TAB>  self . _contexts [ c_id ] . set_from_tree ( inflated_value_map ) ",if context_id_list_tuple is _SHUTDOWN_SENTINEL :,if context_id_list_tuple is None:,False,47.63258118647447,96.50007639779544
131,"def _setup_prefix ( self ) : <TAB>  # we assume here that our metadata may be nested inside a ""basket"" <TAB>  # of multiple eggs; that's why we use module_path instead of .archive <TAB>  path = self . module_path <TAB>  old = None <TAB>  while path != old : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . egg_name = os . path . basename ( path ) <TAB><TAB><TAB>  self . egg_info = os . path . join ( path , "" EGG-INFO "" ) <TAB><TAB><TAB>  self . egg_root = path <TAB><TAB><TAB>  break <TAB><TAB>  old = path <TAB><TAB>  path , base = os . path . split ( path ) ","if path . lower ( ) . endswith ( "".egg"" ) :",if os.path.isdir(path):,False,41.61429617791752,93.63803805205306
132,"def get_filename ( self , prompt ) : <TAB>  okay = False <TAB>  val = "" "" <TAB>  while not okay : <TAB><TAB>  val = raw_input ( "" %s :  %s "" % ( prompt , val ) ) <TAB><TAB>  val = os . path . expanduser ( val ) <TAB><TAB>  if os . path . isfile ( val ) : <TAB><TAB><TAB>  okay = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = val <TAB><TAB><TAB>  val = self . choose_from_list ( os . listdir ( path ) ) <TAB><TAB><TAB>  if val : <TAB><TAB><TAB><TAB>  val = os . path . join ( path , val ) <TAB><TAB><TAB><TAB>  okay = True <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  val = "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" Invalid value:  %s "" % val ) <TAB><TAB><TAB>  val = "" "" <TAB>  return val ",elif os . path . isdir ( val ) :,if val.startswith('/'):,False,36.55435314790599,96.84016750024547
133,"def versions ( self , sitename , data ) : <TAB>  # handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}} <TAB>  if "" query "" in data : <TAB><TAB>  q = json . loads ( data [ "" query "" ] ) <TAB><TAB>  itemid = self . _get_itemid ( q . get ( "" key "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  key = q [ "" key "" ] <TAB><TAB><TAB>  return json . dumps ( [ self . dummy_edit ( key ) ] ) <TAB>  # if not just go the default way <TAB>  return ConnectionMiddleware . versions ( self , sitename , data ) ",if itemid :,if itemid:,False,37.21696316178091,100.00000000000004
134,"def read_stanza ( self ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  stanza_end = self . _buffer . index ( b "" \n "" ) <TAB><TAB><TAB>  stanza = self . decoder . decode ( self . _buffer [ : stanza_end ] ) <TAB><TAB><TAB>  self . _buffer = self . _buffer [ stanza_end + 1 : ] <TAB><TAB><TAB>  colon = stanza . index ( "" : "" ) <TAB><TAB><TAB>  return stanza [ : colon ] , stanza [ colon + 1 : ] <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  bytes = self . read_bytes ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _buffer + = bytes ",if not bytes :,if bytes is None:,False,20.613067119296456,98.12648140040172
135,def decodeattrs ( attrs ) : <TAB>  names = [ ] <TAB>  for bit in range ( 16 ) : <TAB><TAB>  mask = 1 << bit <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if attrnames . has_key ( mask ) : <TAB><TAB><TAB><TAB>  names . append ( attrnames [ mask ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  names . append ( hex ( mask ) ) <TAB>  return names ,if attrs & mask :,if attrs.get('mask') & mask:,False,23.34674597681786,94.88940114883049
136,"def _set_http_cookie ( ) : <TAB>  if conf . cookie : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  conf . http_headers [ HTTP_HEADER . COOKIE ] = "" ;  "" . join ( <TAB><TAB><TAB><TAB>  map ( lambda x : "" = "" . join ( x ) , conf . cookie . items ( ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  conf . http_headers [ HTTP_HEADER . COOKIE ] = conf . cookie ","if isinstance ( conf . cookie , dict ) :","if isinstance(conf.cookie, dict):",False,50.70007213870005,100.00000000000004
137,"def __ne__ ( self , other ) : <TAB>  if isinstance ( other , WeakMethod ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self is not other <TAB><TAB>  return weakref . ref . __ne__ ( self , other ) or self . _func_ref != other . _func_ref <TAB>  return True ",if not self . _alive or not other . _alive :,"if isinstance(other, WeakMethod):",False,19.571436690858736,87.08777593690505
138,"def update_unread ( self , order_id , reset = False ) : <TAB>  conn = Database . connect_database ( self . PATH ) <TAB>  with conn : <TAB><TAB>  cursor = conn . cursor ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cursor . execute ( <TAB><TAB><TAB><TAB>  """"""UPDATE sales SET unread = unread + 1 WHERE id=?;"""""" , ( order_id , ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  cursor . execute ( """""" UPDATE sales SET unread=0 WHERE id=?; """""" , ( order_id , ) ) <TAB><TAB>  conn . commit ( ) <TAB>  conn . close ( ) ",if reset is False :,if reset:,False,37.53056403359742,98.11050773107927
139,"def _get_field_value ( self , test , key , match ) : <TAB>  if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB>  members = inspect . getmembers ( match ) <TAB><TAB>  for member in members : <TAB><TAB><TAB>  if member [ 0 ] == key : <TAB><TAB><TAB><TAB>  field_value = member [ 1 ] <TAB><TAB><TAB>  elif member [ 0 ] == "" wildcards "" : <TAB><TAB><TAB><TAB>  wildcards = member [ 1 ] <TAB><TAB>  if key == "" nw_src "" : <TAB><TAB><TAB>  field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB>  else : <TAB><TAB>  field_value = match [ key ] <TAB>  return field_value ","elif key == ""nw_dst"" :","if key == ""nw_dst"":",False,37.87674197517832,99.00295018584484
140,"def nested_filter ( self , items , mask ) : <TAB>  keep_current = self . current_mask ( mask ) <TAB>  keep_nested_lookup = self . nested_masks ( mask ) <TAB>  for k , v in items : <TAB><TAB>  keep_nested = keep_nested_lookup . get ( k ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if keep_nested is not None : <TAB><TAB><TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB><TAB><TAB>  yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield k , v ",if k in keep_current :,if keep_current is not None and keep_nested is not None:,False,22.639390256586108,93.301799699609
141,"def goToPrevMarkedHeadline ( self , event = None ) : <TAB>  """"""Select the next marked node."""""" <TAB>  c = self <TAB>  p = c . p <TAB>  if not p : <TAB><TAB>  return <TAB>  p . moveToThreadBack ( ) <TAB>  wrapped = False <TAB>  while 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  elif p : <TAB><TAB><TAB>  p . moveToThreadBack ( ) <TAB><TAB>  elif wrapped : <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  wrapped = True <TAB><TAB><TAB>  p = c . rootPosition ( ) <TAB>  if not p : <TAB><TAB>  g . blue ( "" done "" ) <TAB>  c . treeSelectHelper ( p )<TAB># Sets focus. ",if p and p . isMarked ( ) :,if wrapped:,False,27.61297977820766,95.19167656673315
142,"def sample ( self , * * config ) : <TAB>  """"""Sample a configuration from this search space."""""" <TAB>  ret = { } <TAB>  ret . update ( self . data ) <TAB>  kwspaces = self . kwspaces <TAB>  kwspaces . update ( config ) <TAB>  striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB>  for k , v in kwspaces . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( v , NestedSpace ) : <TAB><TAB><TAB><TAB>  sub_config = _strip_config_space ( config , prefix = k ) <TAB><TAB><TAB><TAB>  ret [ k ] = v . sample ( * * sub_config ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret [ k ] = v <TAB>  return ret ",if k in striped_keys :,if k in striped_keys:,False,50.68258112362823,100.00000000000004
143,"def update_gradients_full ( self , dL_dK , X , X2 = None ) : <TAB>  if self . ARD : <TAB><TAB>  phi1 = self . phi ( X ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  phi2 = self . phi ( X2 ) <TAB><TAB><TAB>  self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi2 ) <TAB>  else : <TAB><TAB>  self . variance . gradient = np . einsum ( "" ij,ij "" , dL_dK , self . _K ( X , X2 ) ) * self . beta ",if X2 is None or X is X2 :,if X2 is None:,False,44.945943111663766,97.23330697523008
144,"def post ( self ) : <TAB>  host_json = json . loads ( request . data ) <TAB>  host_os = host_json . get ( "" os "" ) <TAB>  if host_os : <TAB><TAB>  result = get_monkey_executable ( host_os . get ( "" type "" ) , host_os . get ( "" machine "" ) ) <TAB><TAB>  if result : <TAB><TAB><TAB>  # change resulting from new base path <TAB><TAB><TAB>  executable_filename = result [ "" filename "" ] <TAB><TAB><TAB>  real_path = MonkeyDownload . get_executable_full_path ( executable_filename ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ "" size "" ] = os . path . getsize ( real_path ) <TAB><TAB><TAB><TAB>  return result <TAB>  return { } ",if os . path . isfile ( real_path ) :,if real_path:,False,55.41164525971185,95.44649691730169
145,"def _encode_data ( <TAB>  self , <TAB>  data , <TAB>  content_type ,  ) : <TAB>  if content_type is MULTIPART_CONTENT : <TAB><TAB>  return encode_multipart ( BOUNDARY , data ) <TAB>  else : <TAB><TAB>  # Encode the content so that the byte representation is correct. <TAB><TAB>  match = CONTENT_TYPE_RE . match ( content_type ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  charset = match . group ( 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  charset = settings . DEFAULT_CHARSET <TAB><TAB>  return force_bytes ( data , encoding = charset ) ",if match :,if match:,False,61.99973103814194,100.00000000000004
146,"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB>  tokens = list ( tokens ) <TAB>  i = 0 <TAB>  while "" e "" in tokens [ i + 1 : ] : <TAB><TAB>  i = tokens . index ( "" e "" , i + 1 ) <TAB><TAB>  s = i - 1 <TAB><TAB>  e = i + 1 <TAB><TAB>  if not re . match ( "" [0-9] "" , str ( tokens [ s ] ) ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB><TAB><TAB>  e + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  e + = 1 <TAB><TAB><TAB>  tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB><TAB><TAB>  i - = 1 <TAB>  return tokens ","if re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :","if re.match('[+-]', str(tokens[e])):",False,25.925813513981144,97.0528423999307
147,"def convert_with_key ( self , key , value , replace = True ) : <TAB>  result = self . configurator . convert ( value ) <TAB>  # If the converted value is different, save for next time <TAB>  if value is not result : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self [ key ] = result <TAB><TAB>  if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) : <TAB><TAB><TAB>  result . parent = self <TAB><TAB><TAB>  result . key = key <TAB>  return result ",if replace :,if replace:,False,61.03401331539524,100.00000000000004
148,"def OnListEndLabelEdit ( self , std , extra ) : <TAB>  item = extra [ 0 ] <TAB>  text = item [ 4 ] <TAB>  if text is None : <TAB><TAB>  return <TAB>  item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB>  from bdb import Breakpoint <TAB>  for bplist in Breakpoint . bplist . itervalues ( ) : <TAB><TAB>  for bp in bplist : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if text . strip ( ) . lower ( ) == "" none "" : <TAB><TAB><TAB><TAB><TAB>  text = None <TAB><TAB><TAB><TAB>  bp . cond = text <TAB><TAB><TAB><TAB>  break <TAB>  self . RespondDebuggerData ( ) ",if id ( bp ) == item_id :,if item_id == bp.id:,False,48.96894415966114,96.41464728765877
149,"def add ( self , url : str , future_nzo : NzbObject , when : Optional [ int ] = None ) : <TAB>  """"""Add an URL to the URLGrabber queue, 'when' is seconds from now"""""" <TAB>  if future_nzo and when : <TAB><TAB>  # Always increase counter <TAB><TAB>  future_nzo . url_tries + = 1 <TAB><TAB>  # Too many tries? Cancel <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . fail_to_history ( future_nzo , url , T ( "" Maximum retries "" ) ) <TAB><TAB><TAB>  return <TAB><TAB>  future_nzo . url_wait = time . time ( ) + when <TAB>  self . queue . put ( ( url , future_nzo ) ) ",if future_nzo . url_tries > cfg . max_url_retries ( ) :,if future_nzo.url_tries > self.max_retries:,False,60.19141809483438,95.6734218459453
150,def _is_datetime_string ( series ) : <TAB>  if series . dtype == object : <TAB><TAB>  not_numeric = False <TAB><TAB>  try : <TAB><TAB><TAB>  pd . to_numeric ( series ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  not_numeric = True <TAB><TAB>  datetime_col = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  datetime_col = pd . to_datetime ( series ) <TAB><TAB><TAB>  except Exception as e : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  if datetime_col is not None : <TAB><TAB><TAB>  return True <TAB>  return False ,if not_numeric :,"if not not isinstance(series, pd.DataFrame):",False,22.899842627612692,94.83536035622835
151,"def _getEventAndObservers ( self , event ) : <TAB>  if isinstance ( event , xpath . XPathQuery ) : <TAB><TAB>  # Treat as xpath <TAB><TAB>  observers = self . _xpathObservers <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Treat as event <TAB><TAB><TAB>  observers = self . _eventObservers <TAB><TAB>  else : <TAB><TAB><TAB>  # Treat as xpath <TAB><TAB><TAB>  event = xpath . internQuery ( event ) <TAB><TAB><TAB>  observers = self . _xpathObservers <TAB>  return event , observers ",if self . prefix == event [ : len ( self . prefix ) ] :,"if isinstance(event, (xpath.XPathQuery, xpath.XPathQuery)):",False,51.07619490621921,90.34711207876525
152,"def test_wildcard_import ( ) : <TAB>  bonobo = __import__ ( "" bonobo "" ) <TAB>  assert bonobo . __version__ <TAB>  for name in dir ( bonobo ) : <TAB><TAB>  # ignore attributes starting by underscores <TAB><TAB>  if name . startswith ( "" _ "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  attr = getattr ( bonobo , name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  assert name in bonobo . __all__ ",if inspect . ismodule ( attr ) :,"if not hasattr(attr, 'name'):",False,55.631714926657104,95.06856579576917
153,"def relint_views ( wid = None ) : <TAB>  windows = [ sublime . Window ( wid ) ] if wid else sublime . windows ( ) <TAB>  for window in windows : <TAB><TAB>  for view in window . views ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  hit ( view , "" relint_views "" ) ",if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,if view.type() == 'view':,False,49.94938798864196,80.8713961452202
154,def _check_for_unknown_gender ( self ) : <TAB>  if self . obj . get_gender ( ) == Person . UNKNOWN : <TAB><TAB>  d = GenderDialog ( parent = self . window ) <TAB><TAB>  gender = d . run ( ) <TAB><TAB>  d . destroy ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . obj . set_gender ( gender ) ,if gender >= 0 :,if gender is not None:,False,46.01280112891977,95.54689933959506
155,"def add_to_path ( self , fnames ) : <TAB>  """"""Add fnames to path"""""" <TAB>  indexes = [ ] <TAB>  for path in fnames : <TAB><TAB>  project = self . get_source_project ( path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . parent_widget . emit ( SIGNAL ( "" pythonpath_changed() "" ) ) <TAB><TAB><TAB>  indexes . append ( self . get_index ( path ) ) <TAB>  if indexes : <TAB><TAB>  self . reset_icon_provider ( ) <TAB><TAB>  for index in indexes : <TAB><TAB><TAB>  self . update ( index ) ",if project . add_to_pythonpath ( path ) :,if project is not None and project.is_project_changed():,False,23.225405482074617,92.99724446340817
156,"def validate ( self , value ) : <TAB>  if value . grid_id is not None : <TAB><TAB>  if not isinstance ( value , self . proxy_class ) : <TAB><TAB><TAB>  self . error ( "" FileField only accepts GridFSProxy values "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . error ( "" Invalid GridFSProxy value "" ) ","if not isinstance ( value . grid_id , ObjectId ) :",if value.grid_id is not None and value.grid_id.is_valid,False,21.902222955723275,84.71247412512442
157,"def shortcut ( self , input , ch_out , stride , name , if_first = False ) : <TAB>  ch_in = input . shape [ 1 ] <TAB>  if ch_in != ch_out or stride != 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB><TAB>  else : <TAB><TAB><TAB>  return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB>  else : <TAB><TAB>  return input ",if if_first :,if if_first:,False,56.45465333656918,100.00000000000004
158,"def convert_path ( ctx , tpath ) : <TAB>  for points , code in tpath . iter_segments ( ) : <TAB><TAB>  if code == Path . MOVETO : <TAB><TAB><TAB>  ctx . move_to ( * points ) <TAB><TAB>  elif code == Path . LINETO : <TAB><TAB><TAB>  ctx . line_to ( * points ) <TAB><TAB>  elif code == Path . CURVE3 : <TAB><TAB><TAB>  ctx . curve_to ( <TAB><TAB><TAB><TAB>  points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ctx . curve_to ( * points ) <TAB><TAB>  elif code == Path . CLOSEPOLY : <TAB><TAB><TAB>  ctx . close_path ( ) ",elif code == Path . CURVE4 :,if code == Path.CURVE2:,False,26.166192438313058,97.82113003831395
159,"def _get_build_status ( self , job_name , build_number ) : <TAB>  try : <TAB><TAB>  build_info = self . server . get_build_info ( job_name , build_number ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" building "" <TAB><TAB>  else : <TAB><TAB><TAB>  return "" built "" <TAB>  except jenkins . NotFoundException : <TAB><TAB>  return "" not found "" ","if build_info [ ""building"" ] :",if build_info.build_status == 0:,False,20.665516014763345,92.98983936214204
160,"def _parse_param_value ( name , datatype , default ) : <TAB>  if datatype == "" bool "" : <TAB><TAB>  if default . lower ( ) == "" true "" : <TAB><TAB><TAB>  return True <TAB><TAB>  elif default . lower ( ) == "" false "" : <TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB><TAB><TAB>  raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB>  elif datatype == "" int "" : <TAB><TAB>  if type ( default ) == int : <TAB><TAB><TAB>  return default <TAB><TAB>  else : <TAB><TAB><TAB>  return int ( default , 0 ) <TAB>  elif datatype == "" real "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return default <TAB><TAB>  else : <TAB><TAB><TAB>  return float ( default ) <TAB>  else : <TAB><TAB>  return str ( default ) ",if type ( default ) == float :,if type(default) == float:,False,51.77945293018278,100.00000000000004
161,"def get_fills ( self , exchange_order_id ) : <TAB>  async with aiohttp . ClientSession ( ) as client : <TAB><TAB>  response : aiohttp . ClientResponse = await client . get ( <TAB><TAB><TAB>  f "" { BASE_URL } { FILLS_ROUTE } "" , <TAB><TAB><TAB>  params = { "" orderId "" : exchange_order_id , "" limit "" : 100 } , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  msg = await response . json ( ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  msg = await response . text ( ) <TAB><TAB><TAB>  raise DydxAsyncAPIError ( response . status , msg ) <TAB><TAB>  return await response . json ( ) ",if response . status >= 300 :,if response.status == 200:,False,21.149121979118995,97.9649944160342
162,"def semanticTags ( self , semanticTags ) : <TAB>  if semanticTags is None : <TAB><TAB>  self . __semanticTags = OrderedDict ( ) <TAB>  # check <TAB>  for key , value in list ( semanticTags . items ( ) ) : <TAB><TAB>  if not isinstance ( key , int ) : <TAB><TAB><TAB>  raise TypeError ( "" At least one key is not a valid int position "" ) <TAB><TAB>  if not isinstance ( value , list ) : <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB>  ) <TAB><TAB>  for x in value : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB><TAB>  "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB><TAB>  ) <TAB>  self . __semanticTags = semanticTags ","if not isinstance ( x , str ) :","if x not in (0, 1):",False,68.10721761922892,97.05453569769396
163,"def start_cutting_tool ( self , event , axis , direction ) : <TAB>  toggle = event . EventObject <TAB>  self . cutting = toggle . Value <TAB>  if toggle . Value : <TAB><TAB>  # Disable the other toggles <TAB><TAB>  for child in self . cutsizer . Children : <TAB><TAB><TAB>  child = child . Window <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  child . Value = False <TAB><TAB>  self . cutting_axis = axis <TAB><TAB>  self . cutting_direction = direction <TAB>  else : <TAB><TAB>  self . cutting_axis = None <TAB><TAB>  self . cutting_direction = None <TAB>  self . cutting_dist = None ",if child != toggle :,if child.Value:,False,51.74430337460527,97.4900163034189
164,"def decoration_helper ( self , patched , args , keywargs ) : <TAB>  extra_args = [ ] <TAB>  with contextlib . ExitStack ( ) as exit_stack : <TAB><TAB>  for patching in patched . patchings : <TAB><TAB><TAB>  arg = exit_stack . enter_context ( patching ) <TAB><TAB><TAB>  if patching . attribute_name is not None : <TAB><TAB><TAB><TAB>  keywargs . update ( arg ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  extra_args . append ( arg ) <TAB><TAB>  args + = tuple ( extra_args ) <TAB><TAB>  yield ( args , keywargs ) ",elif patching . new is DEFAULT :,if arg is not None:,False,32.66127775147732,95.7160251324892
165,def decodeattrs ( attrs ) : <TAB>  names = [ ] <TAB>  for bit in range ( 16 ) : <TAB><TAB>  mask = 1 << bit <TAB><TAB>  if attrs & mask : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  names . append ( attrnames [ mask ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  names . append ( hex ( mask ) ) <TAB>  return names ,if attrnames . has_key ( mask ) :,if mask in attrnames:,False,50.8618958711744,92.5941436268822
166,"def pytest_collection_modifyitems ( items ) : <TAB>  for item in items : <TAB><TAB>  if item . nodeid . startswith ( "" tests/params "" ) : <TAB><TAB><TAB>  if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if ""init"" not in item . keywords :","if ""init"" not in item.keywords:",False,28.420407113655756,100.00000000000004
167,"def handle_socket ( self , request ) : <TAB>  conn = request . connection <TAB>  while True : <TAB><TAB>  chunk = conn . recv ( 4 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  slen = struct . unpack ( "" >L "" , chunk ) [ 0 ] <TAB><TAB>  chunk = conn . recv ( slen ) <TAB><TAB>  while len ( chunk ) < slen : <TAB><TAB><TAB>  chunk = chunk + conn . recv ( slen - len ( chunk ) ) <TAB><TAB>  obj = pickle . loads ( chunk ) <TAB><TAB>  record = logging . makeLogRecord ( obj ) <TAB><TAB>  self . log_output + = record . msg + "" \n "" <TAB><TAB>  self . handled . release ( ) ",if len ( chunk ) < 4 :,if not chunk:,False,29.335072545299123,96.29804974005849
168,"def on_source_foreach ( self , model , path , iter , id ) : <TAB>  m_id = model . get_value ( iter , self . COLUMN_ID ) <TAB>  if m_id == id : <TAB><TAB>  if self . _foreach_mode == "" get "" : <TAB><TAB><TAB>  self . _foreach_take = model . get_value ( iter , self . COLUMN_ENABLED ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _foreach_take = iter ","elif self . _foreach_mode == ""set"" :",if self._foreach_take is None:,False,42.40044462764913,92.47871619713341
169,"def parts ( ) : <TAB>  for l in lists . leaves : <TAB><TAB>  head_name = l . get_head_name ( ) <TAB><TAB>  if head_name == "" System`List "" : <TAB><TAB><TAB>  yield l . leaves <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise MessageException ( "" Catenate "" , "" invrp "" , l ) ","elif head_name != ""System`Missing"" :",if head_name == 'System`List':,False,26.383809510917683,89.78404819696911
170,"def __fill_counter_values ( self , command : str ) : <TAB>  result = [ ] <TAB>  regex = r "" (item[0-9]+ \ .counter_value) "" <TAB>  for token in re . split ( regex , command ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  result . append ( str ( self . simulator_config . item_dict [ token ] . value ) ) <TAB><TAB><TAB>  except ( KeyError , ValueError , AttributeError ) : <TAB><TAB><TAB><TAB>  logger . error ( "" Could not get counter value for  "" + token ) <TAB><TAB>  else : <TAB><TAB><TAB>  result . append ( token ) <TAB>  return "" "" . join ( result ) ","if re . match ( regex , token ) is not None :",if token in self.simulator_config.item_dict:,False,29.159657331050127,94.03470489731197
171,"def IMPORTFROM ( self , node ) : <TAB>  <IF-STMT>: <TAB><TAB>  if not self . futuresAllowed : <TAB><TAB><TAB>  self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB>  else : <TAB><TAB>  self . futuresAllowed = False <TAB>  for alias in node . names : <TAB><TAB>  if alias . name == "" * "" : <TAB><TAB><TAB>  self . scope . importStarred = True <TAB><TAB><TAB>  self . report ( messages . ImportStarUsed , node , node . module ) <TAB><TAB><TAB>  continue <TAB><TAB>  name = alias . asname or alias . name <TAB><TAB>  importation = Importation ( name , node ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  importation . used = ( self . scope , node ) <TAB><TAB>  self . addBinding ( node , importation ) ","if node . module == ""__future__"" :",if node.names:,False,27.316830074802922,88.92079240089579
172,"def _split_batch_list ( args , batch_list ) : <TAB>  new_list = [ ] <TAB>  for batch in batch_list . batches : <TAB><TAB>  new_list . append ( batch ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield batch_pb2 . BatchList ( batches = new_list ) <TAB><TAB><TAB>  new_list = [ ] <TAB>  if new_list : <TAB><TAB>  yield batch_pb2 . BatchList ( batches = new_list ) ",if len ( new_list ) == args . batch_size_limit :,if new_list:,False,35.91312555055713,88.60888429538596
173,"def get_branch_or_use_upstream ( branch_name , arg , repo ) : <TAB>  if not branch_name :<TAB># use upstream branch <TAB><TAB>  current_b = repo . current_branch <TAB><TAB>  upstream_b = current_b . upstream <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" No  {0}  branch specified and the current branch has no upstream  "" <TAB><TAB><TAB><TAB>  "" branch set "" . format ( arg ) <TAB><TAB><TAB>  ) <TAB><TAB>  ret = current_b . upstream <TAB>  else : <TAB><TAB>  ret = get_branch ( branch_name , repo ) <TAB>  return ret ",if not upstream_b :,if upstream_b is None:,False,50.806065153150605,94.93223441479526
174,"def __init__ ( self , * * settings ) : <TAB>  default_settings = self . get_default_settings ( ) <TAB>  for name , value in default_settings . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( self , name , value ) <TAB>  for name , value in settings . items ( ) : <TAB><TAB>  if name not in default_settings : <TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB>  "" Invalid setting  ' {} '  for  {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  name , <TAB><TAB><TAB><TAB><TAB>  self . __class__ . __name__ , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  setattr ( self , name , value ) ","if not hasattr ( self , name ) :",if name not in settings:,False,23.18165719185443,96.44467896739773
175,"def _declare ( self , name , obj , included = False , quals = 0 ) : <TAB>  if name in self . _declarations : <TAB><TAB>  prevobj , prevquals = self . _declarations [ name ] <TAB><TAB>  if prevobj is obj and prevquals == quals : <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise api . FFIError ( <TAB><TAB><TAB><TAB>  "" multiple declarations of  %s  (for interactive usage,  "" <TAB><TAB><TAB><TAB>  "" try cdef(xx, override=True)) "" % ( name , ) <TAB><TAB><TAB>  ) <TAB>  assert "" __dotdotdot__ "" not in name . split ( ) <TAB>  self . _declarations [ name ] = ( obj , quals ) <TAB>  if included : <TAB><TAB>  self . _included_declarations . add ( obj ) ",if not self . _override :,if len(self._declarations) > 1:,False,36.54927526123266,95.94442462709019
176,"def include_file ( name , fdir = tmp_dir , b64 = False ) : <TAB>  try : <TAB><TAB>  if fdir is None : <TAB><TAB><TAB>  fdir = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with io . open ( os . path . join ( fdir , name ) , "" rb "" ) as f : <TAB><TAB><TAB><TAB>  return base64 . b64encode ( f . read ( ) ) . decode ( "" utf-8 "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  with io . open ( os . path . join ( fdir , name ) , "" r "" , encoding = "" utf-8 "" ) as f : <TAB><TAB><TAB><TAB>  return f . read ( ) <TAB>  except ( OSError , IOError ) as e : <TAB><TAB>  logger . error ( "" Could not include file  ' {} ' :  {} "" . format ( name , e ) ) ",if b64 :,if b64:,False,51.462571059932614,100.00000000000004
177,"def to_raw_json ( self ) : <TAB>  parts = { } <TAB>  for p in self . parts : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parts [ p [ 0 ] ] = [ ] <TAB><TAB>  parts [ p [ 0 ] ] . append ( { "" value "" : p [ 2 ] , "" parameters "" : p [ 1 ] } ) <TAB>  children = [ x . to_raw_json ( ) for x in self . children ] <TAB>  return { <TAB><TAB>  "" type "" : self . __class__ . __name__ , <TAB><TAB>  "" children "" : children , <TAB><TAB>  "" parts "" : parts , <TAB>  } ",if p [ 0 ] not in parts :,if p[0] not in parts:,False,52.542060675622,100.00000000000004
178,"def process_output ( <TAB>  output : str , filename : str , start_line : int  ) - > Tuple [ Optional [ str ] , bool ] : <TAB>  error_found = False <TAB>  for line in output . splitlines ( ) : <TAB><TAB>  t = get_revealed_type ( line , filename , start_line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return t , error_found <TAB><TAB>  elif "" error: "" in line : <TAB><TAB><TAB>  error_found = True <TAB>  return None , True<TAB># finding no reveal_type is an error ",if t :,if t is not None:,False,27.656850461295335,93.91489353463705
179,"def __init__ ( <TAB>  self , resize_keyboard = None , one_time_keyboard = None , selective = None , row_width = 3  ) : <TAB>  if row_width > self . max_row_keys : <TAB><TAB>  # Todo: Will be replaced with Exception in future releases <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . error ( <TAB><TAB><TAB><TAB>  "" Telegram does not support reply keyboard row width over  %d . "" <TAB><TAB><TAB><TAB>  % self . max_row_keys <TAB><TAB><TAB>  ) <TAB><TAB>  row_width = self . max_row_keys <TAB>  self . resize_keyboard = resize_keyboard <TAB>  self . one_time_keyboard = one_time_keyboard <TAB>  self . selective = selective <TAB>  self . row_width = row_width <TAB>  self . keyboard = [ ] ",if not DISABLE_KEYLEN_ERROR :,if resize_keyboard is None:,False,62.58988231455481,96.7812448894481
180,"def realizeElementExpressions ( innerElement ) : <TAB>  elementHasBeenRealized = False <TAB>  for exp in innerElement . expressions : <TAB><TAB>  if not hasattr ( exp , "" realize "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  # else: <TAB><TAB>  before , during , after = exp . realize ( innerElement ) <TAB><TAB>  elementHasBeenRealized = True <TAB><TAB>  for n in before : <TAB><TAB><TAB>  newStream . append ( n ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newStream . append ( during ) <TAB><TAB>  for n in after : <TAB><TAB><TAB>  newStream . append ( n ) <TAB>  if elementHasBeenRealized is False : <TAB><TAB>  newStream . append ( innerElement ) ",if during is not None :,if during is not None:,False,52.22491739153661,100.00000000000004
181,"def lex_number ( self , pos ) : <TAB>  # numeric literal <TAB>  start = pos <TAB>  found_dot = False <TAB>  while pos < len ( self . string ) and ( <TAB><TAB>  self . string [ pos ] . isdigit ( ) or self . string [ pos ] == "" . "" <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if found_dot is True : <TAB><TAB><TAB><TAB>  raise ValueError ( "" Invalid number. Found multiple  ' . ' "" ) <TAB><TAB><TAB>  found_dot = True <TAB><TAB>  # technically we allow more than one ""."" and let float()'s parsing <TAB><TAB>  # complain later <TAB><TAB>  pos + = 1 <TAB>  val = self . string [ start : pos ] <TAB>  return Token ( TokenType . LNUM , val , len ( val ) ) ","if self . string [ pos ] == ""."" :",if self.string[pos] == '.':,False,34.091829322672815,98.0842528864255
182,"def rename ( src , dst ) : <TAB>  # Try atomic or pseudo-atomic rename <TAB>  if _rename ( src , dst ) : <TAB><TAB>  return <TAB>  # Fall back to ""move away and replace"" <TAB>  try : <TAB><TAB>  os . rename ( src , dst ) <TAB>  except OSError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB><TAB>  old = "" %s - %08x "" % ( dst , random . randint ( 0 , sys . maxsize ) ) <TAB><TAB>  os . rename ( dst , old ) <TAB><TAB>  os . rename ( src , dst ) <TAB><TAB>  try : <TAB><TAB><TAB>  os . unlink ( old ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  pass ",if e . errno != errno . EEXIST :,if e.errno != errno.ENOTTY:,False,33.516773678269196,96.99456277438485
183,"def _the_callback ( widget , event_id ) : <TAB>  point = widget . GetCenter ( ) <TAB>  index = widget . WIDGET_INDEX <TAB>  if hasattr ( callback , "" __call__ "" ) : <TAB><TAB>  if num > 1 : <TAB><TAB><TAB>  args = [ point , index ] <TAB><TAB>  else : <TAB><TAB><TAB>  args = [ point ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args . append ( widget ) <TAB><TAB>  try_callback ( callback , * args ) <TAB>  return ",if pass_widget :,if event_id == 'click':,False,34.62367309274842,95.0034110852832
184,"def run ( self ) : <TAB>  for _ in range ( self . n ) : <TAB><TAB>  error = True <TAB><TAB>  try : <TAB><TAB><TAB>  self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB><TAB><TAB>  error = False <TAB><TAB>  except : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  if self . expect_exception : <TAB><TAB><TAB>  assert error ",if not self . expect_exception :,if error:,False,21.711296681508855,94.42751572235169
185,"def handle ( self , * args : Any , * * options : Any ) - > None : <TAB>  realm = self . get_realm ( options ) <TAB>  if options [ "" all "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise CommandError ( <TAB><TAB><TAB><TAB>  "" You must specify a realm if you choose the --all option. "" <TAB><TAB><TAB>  ) <TAB><TAB>  self . fix_all_users ( realm ) <TAB><TAB>  return <TAB>  self . fix_emails ( realm , options [ "" emails "" ] ) ",if realm is None :,if realm is None:,False,58.9584590969081,100.00000000000004
186,"def recv_tdi ( self , nbits , pos ) : <TAB>  bits = 0 <TAB>  for n in range ( nbits * 2 ) : <TAB><TAB>  yield from self . _wait_for_tck ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bits = ( bits << 1 ) | ( yield self . tdi . o ) <TAB>  return bits ",if ( yield self . tck . o ) == pos :,if self.tdi.o:,False,41.31825478085525,88.54891441671381
187,"def _split_head ( self ) : <TAB>  if not hasattr ( self , "" _severed_head "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tree = self . _tree . copy ( ) <TAB><TAB><TAB>  head = tree . get_heading_text ( ) <TAB><TAB><TAB>  tree . remove_heading ( ) <TAB><TAB><TAB>  self . _severed_head = ( head , tree ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _severed_head = ( None , None ) <TAB>  return self . _severed_head ",if self . _tree :,if self._severed_head is None:,False,48.23767463890239,95.81162082634188
188,"def buildSearchTrie ( self , choices ) : <TAB>  searchtrie = trie . Trie ( ) <TAB>  for choice in choices : <TAB><TAB>  for token in self . tokenizeChoice ( choice ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  searchtrie [ token ] = [ ] <TAB><TAB><TAB>  searchtrie [ token ] . append ( choice ) <TAB>  return searchtrie ",if not searchtrie . has_key ( token ) :,if not token in searchtrie:,False,49.327291858886554,91.13515622302349
189,"def format_sql ( sql , params ) : <TAB>  rv = [ ] <TAB>  if isinstance ( params , dict ) : <TAB><TAB>  # convert sql with named parameters to sql with unnamed parameters <TAB><TAB>  conv = _FormatConverter ( params ) <TAB><TAB>  if params : <TAB><TAB><TAB>  sql = sql_to_string ( sql ) <TAB><TAB><TAB>  sql = sql % conv <TAB><TAB><TAB>  params = conv . params <TAB><TAB>  else : <TAB><TAB><TAB>  params = ( ) <TAB>  for param in params or ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rv . append ( "" NULL "" ) <TAB><TAB>  param = safe_repr ( param ) <TAB><TAB>  rv . append ( param ) <TAB>  return sql , rv ",if param is None :,if param is None:,False,61.01364682869232,100.00000000000004
190,def on_completed2 ( ) : <TAB>  doner [ 0 ] = True <TAB>  if not qr : <TAB><TAB>  if len ( ql ) > 0 : <TAB><TAB><TAB>  observer . on_next ( False ) <TAB><TAB><TAB>  observer . on_completed ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  observer . on_next ( True ) <TAB><TAB><TAB>  observer . on_completed ( ) ,elif donel [ 0 ] :,if not doner:,False,19.04832305601477,94.26473496016362
191,"def notify_digest ( self , frequency , changes ) : <TAB>  notifications = defaultdict ( list ) <TAB>  users = { } <TAB>  for change in changes : <TAB><TAB>  for user in self . get_users ( frequency , change ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  notifications [ user . pk ] . append ( change ) <TAB><TAB><TAB><TAB>  users [ user . pk ] = user <TAB>  for user in users . values ( ) : <TAB><TAB>  self . send_digest ( <TAB><TAB><TAB>  user . profile . language , <TAB><TAB><TAB>  user . email , <TAB><TAB><TAB>  notifications [ user . pk ] , <TAB><TAB><TAB>  subscription = user . current_subscription , <TAB><TAB>  ) ",if change . project is None or user . can_access_project ( change . project ) :,if user.pk not in notifications:,False,43.84550881481727,91.29935938924916
192,"def _any_listener_using ( self , target_group_arn ) : <TAB>  for load_balancer in self . load_balancers . values ( ) : <TAB><TAB>  for listener in load_balancer . listeners . values ( ) : <TAB><TAB><TAB>  for rule in listener . rules : <TAB><TAB><TAB><TAB>  for action in rule . actions : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if action . data . get ( ""target_group_arn"" ) == target_group_arn :",if action.spec.group_arn == target_group_arn:,False,23.388749056414625,92.10311397063535
193,"def train_dict ( self , triples ) : <TAB>  """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB>  # accumulate counter <TAB>  ctr = Counter ( ) <TAB>  ctr . update ( [ ( p [ 0 ] , p [ 1 ] , p [ 2 ] ) for p in triples ] ) <TAB>  # find the most frequent mappings <TAB>  for p , _ in ctr . most_common ( ) : <TAB><TAB>  w , pos , l = p <TAB><TAB>  if ( w , pos ) not in self . composite_dict : <TAB><TAB><TAB>  self . composite_dict [ ( w , pos ) ] = l <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . word_dict [ w ] = l <TAB>  return ",if w not in self . word_dict :,if w not in self.word_dict:,False,59.94546196902457,100.00000000000004
194,"def parse_git_config ( path ) : <TAB>  """"""Parse git config file."""""" <TAB>  config = dict ( ) <TAB>  section = None <TAB>  with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB><TAB>  for line in f : <TAB><TAB><TAB>  line = line . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  section = line [ 1 : - 1 ] . strip ( ) <TAB><TAB><TAB><TAB>  config [ section ] = dict ( ) <TAB><TAB><TAB>  elif section : <TAB><TAB><TAB><TAB>  key , value = line . replace ( "" "" , "" "" ) . split ( "" = "" ) <TAB><TAB><TAB><TAB>  config [ section ] [ key ] = value <TAB>  return config ","if line . startswith ( ""["" ) :",if line.endswith('#'):,False,30.766306003213256,95.64403129334706
195,"def send_signal ( self , pid , signum ) : <TAB>  if pid in self . processes : <TAB><TAB>  process = self . processes [ pid ] <TAB><TAB>  hook_result = self . call_hook ( "" before_signal "" , pid = pid , signum = signum ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( <TAB><TAB><TAB><TAB>  "" before_signal hook didn ' t return True  "" <TAB><TAB><TAB><TAB>  "" => signal  %i  is not sent to  %i "" % ( signum , pid ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  process . send_signal ( signum ) <TAB><TAB>  self . call_hook ( "" after_signal "" , pid = pid , signum = signum ) <TAB>  else : <TAB><TAB>  logger . debug ( "" process  %s  does not exist "" % pid ) ",if signum != signal . SIGKILL and not hook_result :,if hook_result is not None:,False,27.557602504658895,94.35266456999246
196,"def validate_pos_return ( self ) : <TAB>  if self . is_pos and self . is_return : <TAB><TAB>  total_amount_in_payments = 0 <TAB><TAB>  for payment in self . payments : <TAB><TAB><TAB>  total_amount_in_payments + = payment . amount <TAB><TAB>  invoice_total = self . rounded_total or self . grand_total <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( <TAB><TAB><TAB><TAB>  _ ( "" Total payments amount can ' t be greater than  {} "" ) . format ( <TAB><TAB><TAB><TAB><TAB>  - invoice_total <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) ",if total_amount_in_payments < invoice_total :,if total_amount_in_payments > invoice_total:,False,49.87432772017525,94.71179963212833
197,"def delete ( key , inner_key = None ) : <TAB>  if inner_key is not None : <TAB><TAB>  try : <TAB><TAB><TAB>  del cache [ key ] [ inner_key ] <TAB><TAB><TAB>  del use_count [ key ] [ inner_key ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del cache [ key ] <TAB><TAB><TAB><TAB>  del use_count [ key ] <TAB><TAB><TAB>  wrapper . cache_size - = 1 <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  return True <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  wrapper . cache_size - = len ( cache [ key ] ) <TAB><TAB><TAB>  del cache [ key ] <TAB><TAB><TAB>  del use_count [ key ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  return True ",if not cache [ key ] :,if wrapper.cache_size == 0:,False,45.97353180025679,96.75657858295902
198,"def insertionsort ( array ) : <TAB>  size = array . getsize ( ) <TAB>  array . reset ( "" Insertion sort "" ) <TAB>  for i in range ( 1 , size ) : <TAB><TAB>  j = i - 1 <TAB><TAB>  while j > = 0 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  array . swap ( j , j + 1 ) <TAB><TAB><TAB>  j = j - 1 <TAB>  array . message ( "" Sorted "" ) ","if array . compare ( j , j + 1 ) <= 0 :","if array.swap(j, j + 1):",False,46.583901284367734,95.09631010443206
199,"def publish_state ( cls , payload , state ) : <TAB>  try : <TAB><TAB>  if isinstance ( payload , LiveActionDB ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cls . process ( payload ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  worker . get_worker ( ) . process ( payload ) <TAB>  except Exception : <TAB><TAB>  traceback . print_exc ( ) <TAB><TAB>  print ( payload ) ",if state == action_constants . LIVEACTION_STATUS_REQUESTED :,if state == 'running':,False,24.379279605063193,92.07338006341007
200,"def change_opacity_function ( self , new_f ) : <TAB>  self . opacity_function = new_f <TAB>  dr = self . radius / self . num_levels <TAB>  sectors = [ ] <TAB>  for submob in self . submobjects : <TAB><TAB>  if type ( submob ) == AnnularSector : <TAB><TAB><TAB>  sectors . append ( submob ) <TAB>  for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # it's the shadow, don't dim it <TAB><TAB><TAB>  continue <TAB><TAB>  alpha = self . opacity_function ( r ) <TAB><TAB>  submob . set_fill ( opacity = alpha ) ",if type ( submob ) != AnnularSector :,if r == 0:,False,51.293773971251454,95.59186178721738
201,"def is_suppressed_warning ( <TAB>  type : str , subtype : str , suppress_warnings : List [ str ]  ) - > bool : <TAB>  """"""Check the warning is suppressed or not."""""" <TAB>  if type is None : <TAB><TAB>  return False <TAB>  for warning_type in suppress_warnings : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  target , subtarget = warning_type , None <TAB><TAB>  if target == type : <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  subtype is None <TAB><TAB><TAB><TAB>  or subtarget is None <TAB><TAB><TAB><TAB>  or subtarget == subtype <TAB><TAB><TAB><TAB>  or subtarget == "" * "" <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if ""."" in warning_type :",if warning_type.startswith('.'):,False,51.23261563556349,96.29045701042668
202,"def set_many ( self , mapping , timeout = None ) : <TAB>  timeout = self . _normalize_timeout ( timeout ) <TAB>  # Use transaction=False to batch without calling redis MULTI <TAB>  # which is not supported by twemproxy <TAB>  pipe = self . _client . pipeline ( transaction = False ) <TAB>  for key , value in _items ( mapping ) : <TAB><TAB>  dump = self . dump_object ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pipe . set ( name = self . key_prefix + key , value = dump ) <TAB><TAB>  else : <TAB><TAB><TAB>  pipe . setex ( name = self . key_prefix + key , value = dump , time = timeout ) <TAB>  return pipe . execute ( ) ",if timeout == - 1 :,"if isinstance(dump, tuple):",False,59.33007837988279,95.95104404929661
203,"def maybe_relative_path ( path ) : <TAB>  if not os . path . isabs ( path ) : <TAB><TAB>  return path<TAB># already relative <TAB>  dir = path <TAB>  names = [ ] <TAB>  while True : <TAB><TAB>  prevdir = dir <TAB><TAB>  dir , name = os . path . split ( prevdir ) <TAB><TAB>  if dir == prevdir or not dir : <TAB><TAB><TAB>  return path<TAB># failed to make it relative <TAB><TAB>  names . append ( name ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  names . reverse ( ) <TAB><TAB><TAB><TAB>  return os . path . join ( * names ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  pass ","if samefile ( dir , os . curdir ) :",if os.path.isdir(dir):,False,46.83020135150068,92.49903424192337
204,"def word_range ( word ) : <TAB>  for ind in range ( len ( word ) ) : <TAB><TAB>  temp = word [ ind ] <TAB><TAB>  for c in [ chr ( x ) for x in range ( ord ( "" a "" ) , ord ( "" z "" ) + 1 ) ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield word [ : ind ] + c + word [ ind + 1 : ] ",if c != temp :,if c in temp:,False,52.900562463584265,96.88102737173575
205,"def validate ( self ) : <TAB>  self . update_soil_edit ( "" sand_composition "" ) <TAB>  for soil_type in self . soil_types : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( _ ( "" {0}  should be a value between 0 and 100 "" ) . format ( soil_type ) ) <TAB>  if sum ( self . get ( soil_type ) for soil_type in self . soil_types ) != 100 : <TAB><TAB>  frappe . throw ( _ ( "" Soil compositions do not add up to 100 "" ) ) ",if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,if not self.get(soil_type) <= 0:,False,33.03799837995997,90.80565271984986
206,"def on_click ( self , event ) : <TAB>  run = self . _is_running ( ) <TAB>  if event [ "" button "" ] == self . button_activate : <TAB><TAB>  self . py3 . command_run ( [ "" xscreensaver-command "" , "" -activate "" ] ) <TAB>  if event [ "" button "" ] == self . button_toggle : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . py3 . command_run ( [ "" xscreensaver-command "" , "" -exit "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  # Because we want xscreensaver to continue running after <TAB><TAB><TAB>  # exit, we instead use preexec_fn=setpgrp here. <TAB><TAB><TAB>  Popen ( <TAB><TAB><TAB><TAB>  [ "" xscreensaver "" , "" -no-splash "" , "" -no-capture-stderr "" ] , <TAB><TAB><TAB><TAB>  stdout = PIPE , <TAB><TAB><TAB><TAB>  stderr = PIPE , <TAB><TAB><TAB><TAB>  preexec_fn = setpgrp , <TAB><TAB><TAB>  ) ",if run :,if run:,False,60.326021220947204,100.00000000000004
207,"def maybe_relative_path ( path ) : <TAB>  if not os . path . isabs ( path ) : <TAB><TAB>  return path<TAB># already relative <TAB>  dir = path <TAB>  names = [ ] <TAB>  while True : <TAB><TAB>  prevdir = dir <TAB><TAB>  dir , name = os . path . split ( prevdir ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return path<TAB># failed to make it relative <TAB><TAB>  names . append ( name ) <TAB><TAB>  try : <TAB><TAB><TAB>  if samefile ( dir , os . curdir ) : <TAB><TAB><TAB><TAB>  names . reverse ( ) <TAB><TAB><TAB><TAB>  return os . path . join ( * names ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  pass ",if dir == prevdir or not dir :,if dir == os.curdir:,False,43.240307063379305,93.65467327055403
208,"def _format_micros ( self , datestring ) : <TAB>  parts = datestring [ : - 1 ] . split ( "" . "" ) <TAB>  if len ( parts ) == 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return datestring [ : - 1 ] + "" .000000Z "" <TAB><TAB>  else : <TAB><TAB><TAB>  return datestring + "" .000000Z "" <TAB>  else : <TAB><TAB>  micros = parts [ - 1 ] [ : 6 ] if len ( parts [ - 1 ] ) > 6 else parts [ - 1 ] <TAB><TAB>  return "" . "" . join ( parts [ : - 1 ] + [ "" {:06d} "" . format ( int ( micros ) ) ] ) + "" Z "" ","if datestring . endswith ( ""Z"" ) :",if len(parts) == 0:,False,50.17702864104879,83.67449490527959
209,"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB>  with open ( input_filename , "" r "" ) as f1 : <TAB><TAB>  with open ( output_filename , "" w "" ) as f2 : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  line = f1 . readline ( ) <TAB><TAB><TAB><TAB>  if not line : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if line [ 0 ] == "" "" : <TAB><TAB><TAB><TAB><TAB><TAB>  line = line [ 1 : ] <TAB><TAB><TAB><TAB><TAB>  f2 . writelines ( line + "" \n "" ) ","if line != "" "" and line != """" :",if line:,False,29.93318221630133,95.25446638486447
210,"def set ( self , item , data ) : <TAB>  if not type ( item ) is slice : <TAB><TAB>  item = slice ( item , item + len ( data ) , None ) <TAB>  virt_item = self . item2virtitem ( item ) <TAB>  if not virt_item : <TAB><TAB>  return <TAB>  off = 0 <TAB>  for s , n_item in virt_item : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  i = slice ( off , n_item . stop + off - n_item . start , n_item . step ) <TAB><TAB><TAB>  data_slice = data . __getitem__ ( i ) <TAB><TAB><TAB>  s . content . __setitem__ ( n_item , data_slice ) <TAB><TAB><TAB>  off = i . stop <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" TODO XXX "" ) <TAB>  return ","if isinstance ( s , ProgBits ) :",if n_item.start <= off:,False,48.60309753987149,95.94517930521576
211,"def walk ( msg , callback , data ) : <TAB>  partnum = 0 <TAB>  for part in msg . walk ( ) : <TAB><TAB>  # multipart/* are just containers <TAB><TAB>  if part . get_content_maintype ( ) == "" multipart "" : <TAB><TAB><TAB>  continue <TAB><TAB>  ctype = part . get_content_type ( ) <TAB><TAB>  if ctype is None : <TAB><TAB><TAB>  ctype = OCTET_TYPE <TAB><TAB>  filename = part . get_filename ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename = PART_FN_TPL % ( partnum ) <TAB><TAB>  headers = dict ( part ) <TAB><TAB>  LOG . debug ( headers ) <TAB><TAB>  headers [ "" Content-Type "" ] = ctype <TAB><TAB>  payload = util . fully_decoded_payload ( part ) <TAB><TAB>  callback ( data , filename , payload , headers ) <TAB><TAB>  partnum = partnum + 1 ",if not filename :,if filename is None:,False,54.2719566778685,98.24268914665531
212,"def _run_wes ( args ) : <TAB>  """"""Run CWL using a Workflow Execution Service (WES) endpoint"""""" <TAB>  main_file , json_file , project_name = _get_main_and_json ( args . directory ) <TAB>  main_file = _pack_cwl ( main_file ) <TAB>  if args . host and "" stratus "" in args . host : <TAB><TAB>  _run_wes_stratus ( args , main_file , json_file ) <TAB>  else : <TAB><TAB>  opts = [ "" --no-wait "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  opts + = [ "" --host "" , args . host ] <TAB><TAB>  if args . auth : <TAB><TAB><TAB>  opts + = [ "" --auth "" , args . auth ] <TAB><TAB>  cmd = [ "" wes-client "" ] + opts + [ main_file , json_file ] <TAB><TAB>  _run_tool ( cmd ) ",if args . host :,if args.host:,False,51.31715006730718,100.00000000000004
213,"def insertTestData ( self , rows ) : <TAB>  for row in rows : <TAB><TAB>  if isinstance ( row , Worker ) : <TAB><TAB><TAB>  self . workers [ row . id ] = dict ( <TAB><TAB><TAB><TAB>  id = row . id , name = row . name , paused = 0 , graceful = 0 , info = row . info <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  row . id = row . buildermasterid * 10000 + row . workerid <TAB><TAB><TAB>  self . configured [ row . id ] = dict ( <TAB><TAB><TAB><TAB>  buildermasterid = row . buildermasterid , workerid = row . workerid <TAB><TAB><TAB>  ) <TAB><TAB>  elif isinstance ( row , ConnectedWorker ) : <TAB><TAB><TAB>  self . connected [ row . id ] = dict ( masterid = row . masterid , workerid = row . workerid ) ","elif isinstance ( row , ConfiguredWorker ) :","if isinstance(row, Buildermasterid):",False,28.333483654860864,97.82113003831395
214,"def local_shape_to_shape_i ( node ) : <TAB>  if node . op == T . shape : <TAB><TAB>  # This optimization needs ShapeOpt and fgraph.shape_feature <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  shape_feature = node . fgraph . shape_feature <TAB><TAB>  ret = shape_feature . make_vector_shape ( node . inputs [ 0 ] ) <TAB><TAB>  # We need to copy over stack trace from input to output <TAB><TAB>  copy_stack_trace ( node . outputs [ 0 ] , ret ) <TAB><TAB>  return [ ret ] ","if not hasattr ( node . fgraph , ""shape_feature"" ) :",if not node.fgraph:,False,65.14689663863908,92.58693970722764
215,"def get_config ( ) : <TAB>  """"""Get INI parser with version.ini data."""""" <TAB>  # TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`. <TAB>  ini_path = os . path . join ( THIS_DIRECTORY , "" version.ini "" ) <TAB>  <IF-STMT>: <TAB><TAB>  ini_path = os . path . join ( THIS_DIRECTORY , "" ../../version.ini "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" Couldn ' t find version.ini "" ) <TAB>  config = configparser . ConfigParser ( ) <TAB>  config . read ( ini_path ) <TAB>  return config ",if not os . path . exists ( ini_path ) :,if not os.path.exists(ini_path):,False,59.16833348980132,91.12744339353249
216,"def init_weights ( self , pretrained = None ) : <TAB>  if isinstance ( pretrained , str ) : <TAB><TAB>  logger = logging . getLogger ( ) <TAB><TAB>  load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB>  elif pretrained is None : <TAB><TAB>  for m in self . modules ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  kaiming_init ( m ) <TAB><TAB><TAB>  elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) : <TAB><TAB><TAB><TAB>  constant_init ( m , 1 ) <TAB>  else : <TAB><TAB>  raise TypeError ( "" pretrained must be a str or None "" ) ","if isinstance ( m , nn . Conv2d ) :","if isinstance(m, (_BatchNorm, nn.GroupNorm)):",False,54.013359421136784,95.63469826892981
217,"def isValidDateString ( config_param_name , value , valid_value ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return value <TAB><TAB>  day , month , year = value . split ( "" - "" ) <TAB><TAB>  if int ( day ) < 1 or int ( day ) > 31 : <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  if int ( month ) < 1 or int ( month ) > 12 : <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  if int ( year ) < 1900 or int ( year ) > 2013 : <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  return value <TAB>  except Exception : <TAB><TAB>  raise DateStringValueError ( config_param_name , value ) ","if value == ""DD-MM-YYYY"" :",if valid_value:,False,38.26812925669515,96.67601421435211
218,"def from_obj ( cls , py_obj ) : <TAB>  if not isinstance ( py_obj , Image ) : <TAB><TAB>  raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  box_keys = [ ] <TAB><TAB>  if hasattr ( py_obj , "" masks "" ) and py_obj . masks : <TAB><TAB><TAB>  mask_keys = list ( py_obj . masks . keys ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  mask_keys = [ ] <TAB><TAB>  return cls ( box_keys , mask_keys ) ","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :","if hasattr(py_obj, '_boxes'):",False,48.63147941824372,93.8882230444196
219,"def _path_type ( st , lst ) : <TAB>  parts = [ ] <TAB>  if st : <TAB><TAB>  if stat . S_ISREG ( st . st_mode ) : <TAB><TAB><TAB>  parts . append ( "" file "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parts . append ( "" dir "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  parts . append ( "" other "" ) <TAB>  if lst : <TAB><TAB>  if stat . S_ISLNK ( lst . st_mode ) : <TAB><TAB><TAB>  parts . append ( "" link "" ) <TAB>  return "" "" . join ( parts ) ",elif stat . S_ISDIR ( st . st_mode ) :,if st.st_mode == 'dir':,False,49.80288219100622,93.7085479919609
220,"def is_destructive ( queries ) : <TAB>  """"""Returns if any of the queries in *queries* is destructive."""""" <TAB>  keywords = ( "" drop "" , "" shutdown "" , "" delete "" , "" truncate "" , "" alter "" ) <TAB>  for query in sqlparse . split ( queries ) : <TAB><TAB>  if query : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  elif query_starts_with ( <TAB><TAB><TAB><TAB>  query , [ "" update "" ] <TAB><TAB><TAB>  ) is True and not query_has_where_clause ( query ) : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if query_starts_with ( query , keywords ) is True :",if query in keywords:,False,58.03182063868781,93.5566853958026
221,"def _store_gsuite_membership_post ( self ) : <TAB>  """"""Flush storing gsuite memberships."""""" <TAB>  if not self . member_cache : <TAB><TAB>  return <TAB>  self . session . flush ( ) <TAB>  # session.execute automatically flushes <TAB>  if self . membership_items : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # SQLite doesn't support bulk insert <TAB><TAB><TAB>  for item in self . membership_items : <TAB><TAB><TAB><TAB>  stmt = self . dao . TBL_MEMBERSHIP . insert ( item ) <TAB><TAB><TAB><TAB>  self . session . execute ( stmt ) <TAB><TAB>  else : <TAB><TAB><TAB>  stmt = self . dao . TBL_MEMBERSHIP . insert ( self . membership_items ) <TAB><TAB><TAB>  self . session . execute ( stmt ) ","if get_sql_dialect ( self . session ) == ""sqlite"" :",if self.membership_items:,False,54.765820597355585,93.079209454646
222,"def forward ( self , inputs : paddle . Tensor ) : <TAB>  outputs = [ ] <TAB>  blocks = self . block ( inputs ) <TAB>  route = None <TAB>  for i , block in enumerate ( blocks ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB><TAB>  route , tip = self . yolo_blocks [ i ] ( block ) <TAB><TAB>  block_out = self . block_outputs [ i ] ( tip ) <TAB><TAB>  outputs . append ( block_out ) <TAB><TAB>  if i < 2 : <TAB><TAB><TAB>  route = self . route_blocks_2 [ i ] ( route ) <TAB><TAB><TAB>  route = self . upsample ( route ) <TAB>  return outputs ",if i > 0 :,if route is not None:,False,29.24636364870228,97.21015417051196
223,"def deep_dict ( self , root = None ) : <TAB>  if root is None : <TAB><TAB>  root = self <TAB>  result = { } <TAB>  for key , value in root . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ key ] = self . deep_dict ( root = self . __class__ . _get_next ( key , root ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  result [ key ] = value <TAB>  return result ","if isinstance ( value , dict ) :",if key not in self.__class__._get_next:,False,46.28092643830405,88.16030175303034
224,"def _parse_param_list ( self , content ) : <TAB>  r = Reader ( content ) <TAB>  params = [ ] <TAB>  while not r . eof ( ) : <TAB><TAB>  header = r . read ( ) . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  arg_name , arg_type = header . split ( ""  :  "" ) [ : 2 ] <TAB><TAB>  else : <TAB><TAB><TAB>  arg_name , arg_type = header , "" "" <TAB><TAB>  desc = r . read_to_next_unindented_line ( ) <TAB><TAB>  desc = dedent_lines ( desc ) <TAB><TAB>  params . append ( ( arg_name , arg_type , desc ) ) <TAB>  return params ","if "" : "" in header :",if header.startswith(':,False,24.755840569937895,96.6763387341068
225,"def _ungroup ( sequence , groups = None ) : <TAB>  for v in sequence : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if groups is not None : <TAB><TAB><TAB><TAB>  groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB><TAB><TAB>  for v in _ungroup ( v , groups ) : <TAB><TAB><TAB><TAB>  yield v <TAB><TAB>  else : <TAB><TAB><TAB>  yield v ","if isinstance ( v , ( list , tuple ) ) :","if isinstance(v, list):",False,49.667391186187,95.25569586411326
226,"def _add_resource_group ( obj ) : <TAB>  if isinstance ( obj , list ) : <TAB><TAB>  for array_item in obj : <TAB><TAB><TAB>  _add_resource_group ( array_item ) <TAB>  elif isinstance ( obj , dict ) : <TAB><TAB>  try : <TAB><TAB><TAB>  if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB><TAB><TAB><TAB>  if obj [ "" id "" ] : <TAB><TAB><TAB><TAB><TAB>  obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB><TAB>  except ( KeyError , IndexError , TypeError ) : <TAB><TAB><TAB>  pass <TAB><TAB>  for item_key in obj : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  _add_resource_group ( obj [ item_key ] ) ","if item_key != ""sourceVault"" :",if item_key in obj:,False,50.733461412324296,97.3491308807328
227,"def haslayer ( self , cls ) : <TAB>  """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB>  if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB><TAB>  return 1 <TAB>  for f in self . packetfields : <TAB><TAB>  fvalue_gen = self . getfieldval ( f . name ) <TAB><TAB>  if fvalue_gen is None : <TAB><TAB><TAB>  continue <TAB><TAB>  if not f . islist : <TAB><TAB><TAB>  fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB><TAB>  for fvalue in fvalue_gen : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret = fvalue . haslayer ( cls ) <TAB><TAB><TAB><TAB>  if ret : <TAB><TAB><TAB><TAB><TAB>  return ret <TAB>  return self . payload . haslayer ( cls ) ","if isinstance ( fvalue , Packet ) :",if fvalue.type == 'layer':,False,61.97484513898175,97.19112682875344
228,"def _post_attachment ( self , message , channel , color , sub_fields = None ) : <TAB>  if channel is None : <TAB><TAB>  message_channels = self . channels <TAB>  else : <TAB><TAB>  message_channels = [ channel ] <TAB>  for message_channel in message_channels : <TAB><TAB>  attachment = { <TAB><TAB><TAB>  "" fallback "" : message , <TAB><TAB><TAB>  "" text "" : message , <TAB><TAB><TAB>  "" color "" : color , <TAB><TAB>  } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attachment [ "" fields "" ] = sub_fields <TAB><TAB>  self . slack_client . api_call ( <TAB><TAB><TAB>  "" chat.postMessage "" , <TAB><TAB><TAB>  channel = message_channel , <TAB><TAB><TAB>  attachments = [ attachment ] , <TAB><TAB><TAB>  as_user = True , <TAB><TAB>  ) ",if sub_fields is not None :,if sub_fields is not None:,False,51.939179041841,100.00000000000004
229,"def create ( cls , repository , args ) : <TAB>  key = cls ( ) <TAB>  passphrase = os . environ . get ( "" ATTIC_PASSPHRASE "" ) <TAB>  if passphrase is not None : <TAB><TAB>  passphrase2 = passphrase <TAB>  else : <TAB><TAB>  passphrase , passphrase2 = 1 , 2 <TAB>  while passphrase != passphrase2 : <TAB><TAB>  passphrase = getpass ( "" Enter passphrase:  "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Passphrase must not be blank "" ) <TAB><TAB><TAB>  continue <TAB><TAB>  passphrase2 = getpass ( "" Enter same passphrase again:  "" ) <TAB><TAB>  if passphrase != passphrase2 : <TAB><TAB><TAB>  print ( "" Passphrases do not match "" ) <TAB>  key . init ( repository , passphrase ) <TAB>  if passphrase : <TAB><TAB>  print ( "" Remember your passphrase. Your data will be inaccessible without it. "" ) <TAB>  return key ",if not passphrase :,if not passphrase:,False,58.424413265320375,100.00000000000004
230,"def _generate_create_date ( self ) : <TAB>  if self . timezone is not None : <TAB><TAB>  # First, assume correct capitalization <TAB><TAB>  tzinfo = tz . gettz ( self . timezone ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Fall back to uppercase <TAB><TAB><TAB>  tzinfo = tz . gettz ( self . timezone . upper ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise util . CommandError ( "" Can ' t locate timezone:  %s "" % self . timezone ) <TAB><TAB>  create_date = ( <TAB><TAB><TAB>  datetime . datetime . utcnow ( ) . replace ( tzinfo = tz . tzutc ( ) ) . astimezone ( tzinfo ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  create_date = datetime . datetime . now ( ) <TAB>  return create_date ",if tzinfo is None :,if tzinfo is None:,False,52.24260610180929,95.79273416619387
231,"def _read_header_lines ( fp ) : <TAB>  """"""Read lines with headers until the start of body"""""" <TAB>  lines = deque ( ) <TAB>  for line in fp : <TAB><TAB>  if is_empty ( line ) : <TAB><TAB><TAB>  break <TAB><TAB>  # tricky case if it's not a header and not an empty line <TAB><TAB>  # usually means that user forgot to separate the body and newlines <TAB><TAB>  # so ""unread"" this line here, what means to treat it like a body <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fp . seek ( fp . tell ( ) - len ( line ) ) <TAB><TAB><TAB>  break <TAB><TAB>  lines . append ( line ) <TAB>  return lines ",if not _RE_HEADER . match ( line ) :,if len(line) > 0:,False,73.93670519792035,94.89222918668153
232,"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB>  uris = data . get_uris ( ) <TAB>  files = [ ] <TAB>  for uri in uris : <TAB><TAB>  try : <TAB><TAB><TAB>  uri_tuple = GLib . filename_from_uri ( uri ) <TAB><TAB>  except : <TAB><TAB><TAB>  continue <TAB><TAB>  uri , unused = uri_tuple <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if utils . is_media_file ( uri ) == True : <TAB><TAB><TAB><TAB>  files . append ( uri ) <TAB>  if len ( files ) == 0 : <TAB><TAB>  return <TAB>  open_dropped_files ( files ) ",if os . path . exists ( uri ) == True :,if uri not in unused:,False,20.982114624910032,93.94041024857138
233,"def remove_importlib ( frame , options ) : <TAB>  if frame is None : <TAB><TAB>  return None <TAB>  for child in frame . children : <TAB><TAB>  remove_importlib ( child , options = options ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # remove this node, moving the self_time and children up to the parent <TAB><TAB><TAB>  frame . self_time + = child . self_time <TAB><TAB><TAB>  frame . add_children ( child . children , after = child ) <TAB><TAB><TAB>  child . remove_from_parent ( ) <TAB>  return frame ","if ""<frozen importlib._bootstrap"" in child . file_path :",if child.parent is not None:,False,59.45541796544265,90.94633594121659
234,"def __call__ ( self , graph ) : <TAB>  for layer_name , data in self . params : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  node = graph . get_node ( layer_name ) <TAB><TAB><TAB>  node . data = self . adjust_parameters ( node , data ) <TAB><TAB>  else : <TAB><TAB><TAB>  print_stderr ( "" Ignoring parameters for non-existent layer:  %s "" % layer_name ) <TAB>  return graph ",if layer_name in graph :,if layer_name in graph.get_nodes():,False,52.98928514903088,94.15090610231867
235,"def test_with_three_points ( self ) : <TAB>  cba = ia . Polygon ( [ ( 1 , 2 ) , ( 3 , 4 ) , ( 5 , 5 ) ] ) <TAB>  for i , xy in enumerate ( cba ) : <TAB><TAB>  assert i in [ 0 , 1 , 2 ] <TAB><TAB>  if i == 0 : <TAB><TAB><TAB>  assert np . allclose ( xy , ( 1 , 2 ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert np . allclose ( xy , ( 3 , 4 ) ) <TAB><TAB>  elif i == 2 : <TAB><TAB><TAB>  assert np . allclose ( xy , ( 5 , 5 ) ) <TAB>  assert i == 2 ",elif i == 1 :,if i == 1:,False,51.68345987003286,98.59341533613703
236,"def _serve ( self ) : <TAB>  self . _conn = self . manager . request ( REQUEST_DNS_LISTENER , self . domain ) <TAB>  conn = MsgPackMessages ( self . _conn ) <TAB>  while self . active : <TAB><TAB>  request = conn . recv ( ) <TAB><TAB>  if not request : <TAB><TAB><TAB>  logger . warning ( "" DNS: Recieved empty request. Shutdown "" ) <TAB><TAB><TAB>  self . stop ( ) <TAB><TAB><TAB>  break <TAB><TAB>  now = time . time ( ) <TAB><TAB>  response = self . handler . process ( request ) <TAB><TAB>  if not response : <TAB><TAB><TAB>  response = [ ] <TAB><TAB>  used = time . time ( ) - now <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( "" DNS: Slow processing speed ( %s )s "" , used ) <TAB><TAB>  conn . send ( response ) ",if used > 1 :,if used < self.interval:,False,23.199173550268632,97.70015252663742
237,"def read ( cls , fp , * * kwargs ) : <TAB>  major_version , minor_version , count = read_fmt ( "" 2HI "" , fp ) <TAB>  items = [ ] <TAB>  for _ in range ( count ) : <TAB><TAB>  length = read_fmt ( "" I "" , fp ) [ 0 ] - 4 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with io . BytesIO ( fp . read ( length ) ) as f : <TAB><TAB><TAB><TAB>  items . append ( Annotation . read ( f ) ) <TAB>  return cls ( major_version = major_version , minor_version = minor_version , items = items ) ",if length > 0 :,if length:,False,35.464758163898814,97.78806241438383
238,"def save_uploaded_files ( ) : <TAB>  files = [ ] <TAB>  unzip = bool ( request . form . get ( "" unzip "" ) in [ "" true "" , "" on "" ] ) <TAB>  for uploaded_file in request . files . getlist ( "" files "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with zipfile . ZipFile ( uploaded_file , "" r "" ) as zf : <TAB><TAB><TAB><TAB>  for info in zf . infolist ( ) : <TAB><TAB><TAB><TAB><TAB>  name = info . filename <TAB><TAB><TAB><TAB><TAB>  size = info . file_size <TAB><TAB><TAB><TAB><TAB>  data = zf . read ( name ) <TAB><TAB><TAB><TAB><TAB>  if size > 0 : <TAB><TAB><TAB><TAB><TAB><TAB>  files . append ( save_file ( data , filename = name . split ( "" / "" ) [ - 1 ] ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  files . append ( save_file ( uploaded_file ) ) <TAB>  return files ",if unzip and zipfile . is_zipfile ( uploaded_file ) :,if unzip:,False,49.78988491170965,94.78933670510702
239,"def analyze_string_content ( self , string , line_num , filename ) : <TAB>  output = { } <TAB>  if self . keyword_exclude and self . keyword_exclude . search ( string ) : <TAB><TAB>  return output <TAB>  for identifier in self . secret_generator ( <TAB><TAB>  string , <TAB><TAB>  filetype = determine_file_type ( filename ) , <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  secret = PotentialSecret ( <TAB><TAB><TAB>  self . secret_type , <TAB><TAB><TAB>  filename , <TAB><TAB><TAB>  identifier , <TAB><TAB><TAB>  line_num , <TAB><TAB>  ) <TAB><TAB>  output [ secret ] = secret <TAB>  return output ",if self . is_secret_false_positive ( identifier ) :,if filetype == 'none':,False,41.6466067833722,93.47568337950109
240,"def _validate_and_set_default_hyperparameters ( self ) : <TAB>  """"""Placeholder docstring"""""" <TAB>  # Check if all the required hyperparameters are set. If there is a default value <TAB>  # for one, set it. <TAB>  for name , definition in self . hyperparameter_definitions . items ( ) : <TAB><TAB>  if name not in self . hyperparam_dict : <TAB><TAB><TAB>  spec = definition [ "" spec "" ] <TAB><TAB><TAB>  if "" DefaultValue "" in spec : <TAB><TAB><TAB><TAB>  self . hyperparam_dict [ name ] = spec [ "" DefaultValue "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ValueError ( "" Required hyperparameter:  %s  is not set "" % name ) ","elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :",if not self.has_default_value:,False,64.30048224228635,92.68515206016946
241,"def get_code ( self , fullname = None ) : <TAB>  fullname = self . _fix_name ( fullname ) <TAB>  if self . code is None : <TAB><TAB>  mod_type = self . etc [ 2 ] <TAB><TAB>  if mod_type == imp . PY_SOURCE : <TAB><TAB><TAB>  source = self . get_source ( fullname ) <TAB><TAB><TAB>  self . code = compile ( source , self . filename , "" exec "" ) <TAB><TAB>  elif mod_type == imp . PY_COMPILED : <TAB><TAB><TAB>  self . _reopen ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . code = read_code ( self . file ) <TAB><TAB><TAB>  finally : <TAB><TAB><TAB><TAB>  self . file . close ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . code = self . _get_delegate ( ) . get_code ( ) <TAB>  return self . code ",elif mod_type == imp . PKG_DIRECTORY :,if self.code is None:,False,27.270403043761316,95.32212854455821
242,"def eigh_abstract_eval ( operand , lower ) : <TAB>  if isinstance ( operand , ShapedArray ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Argument to symmetric eigendecomposition must have shape [..., n, n], "" <TAB><TAB><TAB><TAB>  "" got shape  {} "" . format ( operand . shape ) <TAB><TAB><TAB>  ) <TAB><TAB>  batch_dims = operand . shape [ : - 2 ] <TAB><TAB>  n = operand . shape [ - 1 ] <TAB><TAB>  v = ShapedArray ( batch_dims + ( n , n ) , operand . dtype ) <TAB><TAB>  w = ShapedArray ( batch_dims + ( n , ) , lax . lax . _complex_basetype ( operand . dtype ) ) <TAB>  else : <TAB><TAB>  v , w = operand , operand <TAB>  return v , w ",if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,"if not isinstance(operand, (int, long)):",False,49.556269754567616,89.14215781368165
243,"def conninfo_parse ( dsn ) : <TAB>  ret = { } <TAB>  length = len ( dsn ) <TAB>  i = 0 <TAB>  while i < length : <TAB><TAB>  if dsn [ i ] . isspace ( ) : <TAB><TAB><TAB>  i + = 1 <TAB><TAB><TAB>  continue <TAB><TAB>  param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  param = param_match . group ( 1 ) <TAB><TAB>  i + = param_match . end ( ) <TAB><TAB>  if i > = length : <TAB><TAB><TAB>  return <TAB><TAB>  value , end = read_param_value ( dsn [ i : ] ) <TAB><TAB>  if value is None : <TAB><TAB><TAB>  return <TAB><TAB>  i + = end <TAB><TAB>  ret [ param ] = value <TAB>  return ret ",if not param_match :,if param_match is None:,False,20.885595921675286,97.94642728696623
244,"def load_weights_from_unsupervised ( self , unsupervised_model ) : <TAB>  update_state_dict = copy . deepcopy ( self . network . state_dict ( ) ) <TAB>  for param , weights in unsupervised_model . network . state_dict ( ) . items ( ) : <TAB><TAB>  if param . startswith ( "" encoder "" ) : <TAB><TAB><TAB>  # Convert encoder's layers name to match <TAB><TAB><TAB>  new_param = "" tabnet. "" + param <TAB><TAB>  else : <TAB><TAB><TAB>  new_param = param <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # update only common layers <TAB><TAB><TAB>  update_state_dict [ new_param ] = weights <TAB>  self . network . load_state_dict ( update_state_dict ) ",if self . network . state_dict ( ) . get ( new_param ) is not None :,if new_param not in update_state_dict:,False,56.073191762457874,91.91364953008275
245,"def viewer_setup ( self ) : <TAB>  for key , value in DEFAULT_CAMERA_CONFIG . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  getattr ( self . viewer . cam , key ) [ : ] = value <TAB><TAB>  else : <TAB><TAB><TAB>  setattr ( self . viewer . cam , key , value ) ","if isinstance ( value , np . ndarray ) :",if key.startswith('viewer_'):,False,35.59662256895878,91.3961635365097
246,"def colormap_changed ( change ) : <TAB>  if change [ "" new "" ] : <TAB><TAB>  cmap_colors = [ <TAB><TAB><TAB>  color [ 1 : ] for color in cmap . step . __dict__ [ "" _schemes "" ] [ colormap . value ] <TAB><TAB>  ] <TAB><TAB>  palette . value = "" ,  "" . join ( cmap_colors ) <TAB><TAB>  colorbar = getattr ( cmap . step , colormap . value ) <TAB><TAB>  colorbar_output = self . colorbar_widget <TAB><TAB>  with colorbar_output : <TAB><TAB><TAB>  colorbar_output . clear_output ( ) <TAB><TAB><TAB>  display ( colorbar ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  labels = [ f "" Class  { i + 1 } "" for i in range ( len ( palette . value . split ( "" , "" ) ) ) ] <TAB><TAB><TAB>  legend_labels . value = "" ,  "" . join ( labels ) ","if len ( palette . value ) > 0 and "","" in palette . value :",if change['new']:,False,22.552550202159004,93.06616836792458
247,"def invalidate ( self , layers = None ) : <TAB>  if layers is None : <TAB><TAB>  layers = Layer . AllLayers <TAB>  if layers : <TAB><TAB>  layers = set ( layers ) <TAB><TAB>  self . invalidLayers . update ( layers ) <TAB><TAB>  blockRenderers = [ <TAB><TAB><TAB>  br <TAB><TAB><TAB>  for br in self . blockRenderers <TAB><TAB><TAB>  if br . layer is Layer . Blocks or br . layer not in layers <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . forgetDisplayLists ( ) <TAB><TAB>  self . blockRenderers = blockRenderers <TAB><TAB>  if self . renderer . showRedraw and Layer . Blocks in layers : <TAB><TAB><TAB>  self . needsRedisplay = True ",if len ( blockRenderers ) < len ( self . blockRenderers ) :,if len(blockRenderers) == 0:,False,23.314722820451358,95.77198291114503
248,"def fromstring ( cls , input ) : <TAB>  productions = [ ] <TAB>  for linenum , line in enumerate ( input . split ( "" \n "" ) ) : <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  productions + = _read_dependency_production ( line ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  raise ValueError ( "" Unable to parse line  %s :  %s "" % ( linenum , line ) ) <TAB>  if len ( productions ) == 0 : <TAB><TAB>  raise ValueError ( "" No productions found! "" ) <TAB>  return DependencyGrammar ( productions ) ","if line . startswith ( ""#"" ) or line == """" :",if line.startswith('#'):,False,21.48330616338058,93.96766761918012
249,"def repl ( m , base_path , rel_path = None ) : <TAB>  if m . group ( "" comments "" ) : <TAB><TAB>  tag = m . group ( "" comments "" ) <TAB>  else : <TAB><TAB>  tag = m . group ( "" open "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tag + = RE_TAG_LINK_ATTR . sub ( <TAB><TAB><TAB><TAB>  lambda m2 : repl_absolute ( m2 , base_path ) , m . group ( "" attr "" ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  tag + = RE_TAG_LINK_ATTR . sub ( <TAB><TAB><TAB><TAB>  lambda m2 : repl_relative ( m2 , base_path , rel_path ) , m . group ( "" attr "" ) <TAB><TAB><TAB>  ) <TAB><TAB>  tag + = m . group ( "" close "" ) <TAB>  return tag ",if rel_path is None :,if rel_path is None:,False,24.1866470002927,100.00000000000004
250,"def encode ( path ) : <TAB>  if isinstance ( path , str_cls ) : <TAB><TAB>  try : <TAB><TAB><TAB>  path = path . encode ( fs_encoding , "" strict "" ) <TAB><TAB>  except UnicodeEncodeError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  path = path . encode ( fs_fallback_encoding , "" strict "" ) <TAB>  return path ",if not platform . is_linux ( ) :,if path == fs_fallback_encoding:,False,27.352230644200148,92.23815984306266
251,"def __iter__ ( self ) : <TAB>  base_iterator = super ( ProcessIterable , self ) . __iter__ ( ) <TAB>  if getattr ( self . queryset , "" _coerced "" , False ) : <TAB><TAB>  for process in base_iterator : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  process = coerce_to_related_instance ( <TAB><TAB><TAB><TAB><TAB>  process , process . flow_class . process_class <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  yield process <TAB>  else : <TAB><TAB>  for process in base_iterator : <TAB><TAB><TAB>  yield process ","if isinstance ( process , self . queryset . model ) :","if isinstance(process, Process):",False,41.921777714988075,96.426615275116
252,"def footnotes_under ( n : Element ) - > Iterator [ nodes . footnote ] : <TAB>  if isinstance ( n , nodes . footnote ) : <TAB><TAB>  yield n <TAB>  else : <TAB><TAB>  for c in n . children : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  elif isinstance ( c , nodes . Element ) : <TAB><TAB><TAB><TAB>  yield from footnotes_under ( c ) ","if isinstance ( c , addnodes . start_of_file ) :",if c.type == nodes.footnote:,False,46.771412684503154,90.00277601854154
253,"def _process_submissions ( self ) - > None : <TAB>  """"""Process all submissions which have not been processed yet."""""" <TAB>  while self . _to_be_processed : <TAB><TAB>  job = self . _to_be_processed [ 0 ] <TAB><TAB>  job . process ( )<TAB># trigger computation <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  heapq . heappush ( <TAB><TAB><TAB><TAB>  self . _steady_priority_queue , <TAB><TAB><TAB><TAB>  OrderedJobs ( job . release_time , self . _order , job ) , <TAB><TAB><TAB>  ) <TAB><TAB>  self . _to_be_processed . popleft ( )<TAB># remove right after it is added to the heap queue <TAB><TAB>  self . _order + = 1 ",if not self . batch_mode :,if self._to_be_processed:,False,41.644748016535935,91.68880236824137
254,"def valid_localparts ( strip_delimiters = False ) : <TAB>  for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB>  # strip line, skip over empty lines <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  if line == "" "" : <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over comments or empty lines <TAB><TAB>  match = COMMENT . match ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over localparts with delimiters <TAB><TAB>  if strip_delimiters : <TAB><TAB><TAB>  if "" , "" in line or "" ; "" in line : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield line ",if match :,if not match:,False,61.00102458613124,98.71621564653425
255,"def _get_payload_hash ( self , method , data = None ) : <TAB>  if method in ( "" POST "" , "" PUT "" ) : <TAB><TAB>  if data : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # File upload; don't try to read the entire payload <TAB><TAB><TAB><TAB>  return UNSIGNED_PAYLOAD <TAB><TAB><TAB>  return _hash ( data ) <TAB><TAB>  else : <TAB><TAB><TAB>  return UNSIGNED_PAYLOAD <TAB>  else : <TAB><TAB>  return _hash ( "" "" ) ","if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :",if method == 'POST':,False,42.052893067987654,85.97036018891875
256,"def get_download_info ( self ) : <TAB>  try : <TAB><TAB>  download_info = self . api . get_download_info ( self . game ) <TAB><TAB>  result = True <TAB>  except NoDownloadLinkFound as e : <TAB><TAB>  print ( e ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  Config . unset ( "" current_download "" ) <TAB><TAB>  GLib . idle_add ( <TAB><TAB><TAB>  self . parent . parent . show_error , <TAB><TAB><TAB>  _ ( "" Download error "" ) , <TAB><TAB><TAB>  _ ( <TAB><TAB><TAB><TAB>  "" There was an error when trying to fetch the download link! \n {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  e <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) , <TAB><TAB>  ) <TAB><TAB>  download_info = False <TAB><TAB>  result = False <TAB>  return result , download_info ","if Config . get ( ""current_download"" ) == self . game . id :",if download_info:,False,53.06579241168067,93.38477303484923
257,"def find_id ( self , doc_id ) : <TAB>  self . _lock . acquire ( ) <TAB>  try : <TAB><TAB>  doc = self . _docs . get ( doc_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  doc = copy . deepcopy ( doc ) <TAB><TAB><TAB>  doc [ "" id "" ] = doc_id <TAB><TAB><TAB>  return doc <TAB>  finally : <TAB><TAB>  self . _lock . release ( ) ",if doc :,if doc is not None:,False,22.12427997651795,96.34320912002212
258,"def assign_art ( self , session , task ) : <TAB>  """"""Place the discovered art in the filesystem."""""" <TAB>  if task in self . art_candidates : <TAB><TAB>  candidate = self . art_candidates . pop ( task ) <TAB><TAB>  self . _set_art ( task . album , candidate , not self . src_removed ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  task . prune ( candidate . path ) ",if self . src_removed :,if task.is_selected():,False,28.254317251505373,93.04297965654035
259,"def _replace_named ( self , named , replace_scalar ) : <TAB>  for item in named : <TAB><TAB>  for name , value in self . _get_replaced_named ( item , replace_scalar ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise DataError ( "" Argument names must be strings. "" ) <TAB><TAB><TAB>  yield name , value ",if not is_string ( name ) :,"if not isinstance(name, str):",False,23.402589403927276,94.40469740636364
260,"def qtTypeIdent ( conn , * args ) : <TAB>  # We're not using the conn object at the moment, but - we will <TAB>  # modify the <TAB>  # logic to use the server version specific keywords later. <TAB>  res = None <TAB>  value = None <TAB>  for val in args : <TAB><TAB>  # DataType doesn't have len function then convert it to string <TAB><TAB>  if not hasattr ( val , "" __len__ "" ) : <TAB><TAB><TAB>  val = str ( val ) <TAB><TAB>  if len ( val ) == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  value = val <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = value . replace ( ' "" ' , ' "" "" ' ) <TAB><TAB><TAB>  value = ' "" ' + value + ' "" ' <TAB><TAB>  res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB>  return res ","if Driver . needsQuoting ( val , True ) :",if value.startswith(' '):,False,40.20982505116249,96.68234281897494
261,"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB>  for n in tileable_graph : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  tiled_n = get_tiled ( n ) <TAB><TAB>  if has_unknown_shape ( tiled_n ) : <TAB><TAB><TAB>  if any ( c . key not in chunk_result for c in tiled_n . chunks ) : <TAB><TAB><TAB><TAB>  # some of the chunks has been fused <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  new_nsplits = self . get_tileable_nsplits ( n , chunk_result = chunk_result ) <TAB><TAB><TAB>  for node in ( n , tiled_n ) : <TAB><TAB><TAB><TAB>  node . _update_shape ( tuple ( sum ( nsplit ) for nsplit in new_nsplits ) ) <TAB><TAB><TAB>  tiled_n . _nsplits = new_nsplits ",if n . op in failed_ops :,if n.shape == failed_ops:,False,60.38066408476549,98.2763368409405
262,"def _read_filter ( self , data ) : <TAB>  if data : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . inner_sha . update ( data ) <TAB><TAB>  if self . expected_inner_md5sum : <TAB><TAB><TAB>  self . inner_md5 . update ( data ) <TAB>  return data ",if self . expected_inner_sha256 :,if self.expected_inner_sha:,False,26.284931020878883,97.15003449158377
263,"def find_previous_editable ( self , * args ) : <TAB>  if self . editw == 0 : <TAB><TAB>  if self . _active_page > 0 : <TAB><TAB><TAB>  self . switch_page ( self . _active_page - 1 ) <TAB>  if not self . editw == 0 : <TAB><TAB>  # remember that xrange does not return the 'last' value, <TAB><TAB>  # so go to -1, not 0! (fence post error in reverse) <TAB><TAB>  for n in range ( self . editw - 1 , - 1 , - 1 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . editw = n <TAB><TAB><TAB><TAB>  break ",if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,if n == self.editw:,False,63.57605889589271,85.38398502314713
264,"def _get_event_for_message ( self , message_id ) : <TAB>  with self . event_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  "" Event for message[ {} ] should have been created before accessing "" . format ( <TAB><TAB><TAB><TAB><TAB>  message_id <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  return self . _events [ message_id ] ",if message_id not in self . _events :,if not self._events.has_key(message_id):,False,27.148176243953724,92.2651280173069
265,"def _get_deepest ( self , t ) : <TAB>  if isinstance ( t , list ) : <TAB><TAB>  if len ( t ) == 1 : <TAB><TAB><TAB>  return t [ 0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  for part in t : <TAB><TAB><TAB><TAB>  res = self . _get_deepest ( part ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return res <TAB><TAB><TAB>  return None <TAB>  return None ",if res :,if res is not None:,False,23.479263177421128,96.89788960943177
266,"def _get_notify ( self , action_node ) : <TAB>  if action_node . name not in self . _skip_notify_tasks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB><TAB><TAB>  return task_notify <TAB><TAB>  elif self . _chain_notify : <TAB><TAB><TAB>  return self . _chain_notify <TAB>  return None ",if action_node . notify :,if action_node.notify is not None:,False,49.080407138784665,96.2518143306129
267,"def __init__ ( self , centered = None , shape_params = ( ) ) : <TAB>  assert centered is None or isinstance ( centered , ( float , torch . Tensor ) ) <TAB>  assert isinstance ( shape_params , ( tuple , list ) ) <TAB>  assert all ( isinstance ( name , str ) for name in shape_params ) <TAB>  if is_validation_enabled ( ) : <TAB><TAB>  if isinstance ( centered , float ) : <TAB><TAB><TAB>  assert 0 < = centered and centered < = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert ( 0 < = centered ) . all ( ) <TAB><TAB><TAB>  assert ( centered < = 1 ) . all ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  assert centered is None <TAB>  self . centered = centered <TAB>  self . shape_params = shape_params ","elif isinstance ( centered , torch . Tensor ) :","if isinstance(centered, (float, torch.Tensor)):",False,26.764053712530167,96.35732560906915
268,"def collect ( self ) : <TAB>  for nickname in self . squid_hosts . keys ( ) : <TAB><TAB>  squid_host = self . squid_hosts [ nickname ] <TAB><TAB>  fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB><TAB>  if fulldata is not None : <TAB><TAB><TAB>  fulldata = fulldata . splitlines ( ) <TAB><TAB><TAB>  for data in fulldata : <TAB><TAB><TAB><TAB>  matches = self . stat_pattern . match ( data ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . publish_counter ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB><TAB><TAB><TAB><TAB>  ) ",if matches :,if matches:,False,52.01507454319555,100.00000000000004
269,"def test_len ( self ) : <TAB>  eq = self . assertEqual <TAB>  eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB>  for size in range ( 15 ) : <TAB><TAB>  if size == 0 : <TAB><TAB><TAB>  bsize = 0 <TAB><TAB>  elif size < = 3 : <TAB><TAB><TAB>  bsize = 4 <TAB><TAB>  elif size < = 6 : <TAB><TAB><TAB>  bsize = 8 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bsize = 12 <TAB><TAB>  elif size < = 12 : <TAB><TAB><TAB>  bsize = 16 <TAB><TAB>  else : <TAB><TAB><TAB>  bsize = 20 <TAB><TAB>  eq ( base64MIME . base64_len ( "" x "" * size ) , bsize ) ",elif size <= 9 :,if size <= 6:,False,27.963075551222545,97.73217726427006
270,"def wait_for_initial_conf ( self , timeout = 1.0 ) : <TAB>  logger . info ( "" Waiting for initial configuration "" ) <TAB>  cur_timeout = timeout <TAB>  # Arbiter do not already set our have_conf param <TAB>  while not self . new_conf and not self . interrupted : <TAB><TAB>  elapsed , _ , _ = self . handleRequests ( cur_timeout ) <TAB><TAB>  if elapsed : <TAB><TAB><TAB>  cur_timeout - = elapsed <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  cur_timeout = timeout <TAB><TAB>  sys . stdout . write ( "" . "" ) <TAB><TAB>  sys . stdout . flush ( ) ",if cur_timeout > 0 :,if cur_timeout < 0:,False,58.37441643483866,98.62437671704521
271,"def __init__ ( self , querylist = None ) : <TAB>  self . query_id = - 1 <TAB>  if querylist is None : <TAB><TAB>  self . querylist = [ ] <TAB>  else : <TAB><TAB>  self . querylist = querylist <TAB><TAB>  for query in self . querylist : <TAB><TAB><TAB>  if self . query_id == - 1 : <TAB><TAB><TAB><TAB>  self . query_id = query . query_id <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise ValueError ( "" query in list must be same query_id "" ) ",if self . query_id != query . query_id :,if self.query_id != query.query_id:,False,56.34299209967121,96.14862184869322
272,"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB>  s = self <TAB>  if Symbol . debug_lookup : <TAB><TAB>  Symbol . debug_print ( "" searching in self: "" ) <TAB><TAB>  print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB>  while True : <TAB><TAB>  if matchSelf : <TAB><TAB><TAB>  yield s <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield from s . children_recurse_anon <TAB><TAB>  else : <TAB><TAB><TAB>  yield from s . _children <TAB><TAB>  if s . siblingAbove is None : <TAB><TAB><TAB>  break <TAB><TAB>  s = s . siblingAbove <TAB><TAB>  if Symbol . debug_lookup : <TAB><TAB><TAB>  Symbol . debug_print ( "" searching in sibling: "" ) <TAB><TAB><TAB>  print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) ",if recurseInAnon :,if s.children_recurse_anon:,False,35.38013448093365,96.73412661057202
273,"def get_default_params ( problem_type : str , penalty : str ) : <TAB>  # TODO: get seed from seeds provider <TAB>  if problem_type == REGRESSION : <TAB><TAB>  default_params = { "" C "" : None , "" random_state "" : 0 , "" fit_intercept "" : True } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  default_params [ "" solver "" ] = "" auto "" <TAB>  else : <TAB><TAB>  default_params = { <TAB><TAB><TAB>  "" C "" : None , <TAB><TAB><TAB>  "" random_state "" : 0 , <TAB><TAB><TAB>  "" solver "" : _get_solver ( problem_type ) , <TAB><TAB><TAB>  "" n_jobs "" : - 1 , <TAB><TAB><TAB>  "" fit_intercept "" : True , <TAB><TAB>  } <TAB>  model_params = list ( default_params . keys ( ) ) <TAB>  return model_params , default_params ",if penalty == L2 :,if problem_type == REGRESSION:,False,54.34890923364244,95.84494960194156
274,"def _UploadDirectory ( local_dir : str , gcs_bucket : storage . Bucket , gcs_dir : str ) : <TAB>  """"""Upload the contents of a local directory to a GCS Bucket."""""" <TAB>  for file_name in os . listdir ( local_dir ) : <TAB><TAB>  path = os . path . join ( local_dir , file_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logging . info ( "" Skipping  %s  as it ' s not a file. "" , path ) <TAB><TAB><TAB>  continue <TAB><TAB>  logging . info ( "" Uploading:  %s "" , path ) <TAB><TAB>  gcs_blob = gcs_bucket . blob ( f "" { gcs_dir } / { file_name } "" ) <TAB><TAB>  gcs_blob . upload_from_filename ( path ) ",if not os . path . isfile ( path ) :,if os.path.isfile(path):,False,36.31928143901655,97.0822658765238
275,"def decode_query_ids ( self , trans , conditional ) : <TAB>  if conditional . operator == "" and "" : <TAB><TAB>  self . decode_query_ids ( trans , conditional . left ) <TAB><TAB>  self . decode_query_ids ( trans , conditional . right ) <TAB>  else : <TAB><TAB>  left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB><TAB>  if left_base in self . FIELDS : <TAB><TAB><TAB>  field = self . FIELDS [ left_base ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  conditional . right = trans . security . decode_id ( conditional . right ) ",if field . id_decode :,if field.id == conditional.id:,False,34.877782717344196,96.26851899038972
276,"def data_dir ( self ) - > Path : <TAB>  try : <TAB><TAB>  from appdirs import user_data_dir <TAB>  except ImportError : <TAB><TAB>  # linux <TAB><TAB>  path = Path . home ( ) / "" .local "" / "" share "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return path / "" dephell "" <TAB><TAB>  # mac os <TAB><TAB>  path = Path . home ( ) / "" Library "" / "" Application Support "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return path / "" dephell "" <TAB><TAB>  self . pip_main ( [ "" install "" , "" appdirs "" ] ) <TAB><TAB>  from appdirs import user_data_dir <TAB>  return Path ( user_data_dir ( "" dephell "" ) ) ",if path . exists ( ) :,if os.path.exists(path):,False,43.93544097671845,95.0779497326706
277,"def setGameCard ( self , isGameCard = False ) : <TAB>  if isGameCard : <TAB><TAB>  targetValue = 1 <TAB>  else : <TAB><TAB>  targetValue = 0 <TAB>  for nca in self : <TAB><TAB>  if isinstance ( nca , Nca ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  Print . info ( "" writing isGameCard for  %s ,  %d "" % ( str ( nca . _path ) , targetValue ) ) <TAB><TAB><TAB>  nca . header . setIsGameCard ( targetValue ) ",if nca . header . getIsGameCard ( ) == targetValue :,if nca._path == nca._path:,False,48.475270826075736,94.17240443258358
278,"def check_apns_certificate ( ss ) : <TAB>  mode = "" start "" <TAB>  for s in ss . split ( "" \n "" ) : <TAB><TAB>  if mode == "" start "" : <TAB><TAB><TAB>  if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB>  mode = "" key "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB>  mode = "" end "" <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB><TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB>  "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB>  ) <TAB>  if mode != "" end "" : <TAB><TAB>  raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","elif mode == ""key"" :",if s.startswith('Proc-Type'):,False,34.15686325762611,95.20457805223724
279,"def register_aggregate_groups ( conn , * groups ) : <TAB>  seen = set ( ) <TAB>  for group in groups : <TAB><TAB>  klasses = AGGREGATE_COLLECTION [ group ] <TAB><TAB>  for klass in klasses : <TAB><TAB><TAB>  name = getattr ( klass , "" name "" , klass . __name__ ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  seen . add ( name ) <TAB><TAB><TAB><TAB>  conn . create_aggregate ( name , - 1 , klass ) ",if name not in seen :,if name not in seen:,False,52.36805261924313,97.44419619641211
280,"def _impl ( inputs , input_types ) : <TAB>  data = inputs [ 0 ] <TAB>  axis = None <TAB>  keepdims = False <TAB>  if len ( inputs ) > 2 :<TAB># default, torch have only data, axis=None, keepdims=False <TAB><TAB>  if isinstance ( inputs [ 1 ] , int ) : <TAB><TAB><TAB>  axis = int ( inputs [ 1 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  axis = inputs [ 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  axis = list ( _infer_shape ( inputs [ 1 ] ) ) <TAB><TAB>  keepdims = bool ( inputs [ 2 ] ) <TAB>  return get_relay_op ( name ) ( data , axis = axis , keepdims = keepdims ) ",elif _is_int_seq ( inputs [ 1 ] ) :,if axis is None:,False,52.42070401780523,91.9450397560028
281,"def walks_generator ( ) : <TAB>  if filelist is not None : <TAB><TAB>  bucket = [ ] <TAB><TAB>  for filename in filelist : <TAB><TAB><TAB>  with io . open ( filename ) as inf : <TAB><TAB><TAB><TAB>  for line in inf : <TAB><TAB><TAB><TAB><TAB>  walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( "" "" ) ] <TAB><TAB><TAB><TAB><TAB>  bucket . append ( walk ) <TAB><TAB><TAB><TAB><TAB>  if len ( bucket ) == batch_size : <TAB><TAB><TAB><TAB><TAB><TAB>  yield bucket <TAB><TAB><TAB><TAB><TAB><TAB>  bucket = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield bucket <TAB>  else : <TAB><TAB>  for _ in range ( epoch ) : <TAB><TAB><TAB>  for nodes in graph . node_batch_iter ( batch_size ) : <TAB><TAB><TAB><TAB>  walks = graph . random_walk ( nodes , walk_len ) <TAB><TAB><TAB><TAB>  yield walks ",if len ( bucket ) :,if len(bucket) > 0:,False,32.99260970204861,98.87080405765961
282,"def _calculate_runtimes ( states ) : <TAB>  results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB>  for state , resultset in states . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Count the pass vs failures <TAB><TAB><TAB>  if resultset [ "" result "" ] : <TAB><TAB><TAB><TAB>  results [ "" num_passed_states "" ] + = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results [ "" num_failed_states "" ] + = 1 <TAB><TAB><TAB>  # Count durations <TAB><TAB><TAB>  results [ "" runtime "" ] + = resultset [ "" duration "" ] <TAB>  log . debug ( "" Parsed state metrics:  {} "" . format ( results ) ) <TAB>  return results ","if isinstance ( resultset , dict ) and ""duration"" in resultset :",if state == 'pass':,False,41.297671831879335,94.02429920641237
283,"def _replicator_primary_device ( ) - > snt_replicator . Replicator : <TAB>  # NOTE: The explicit device list is required since currently Replicator <TAB>  # only considers CPU and GPU devices. This means on TPU by default we only <TAB>  # mirror on the local CPU. <TAB>  for device_type in ( "" TPU "" , "" GPU "" , "" CPU "" ) : <TAB><TAB>  devices = tf . config . experimental . list_logical_devices ( device_type = device_type ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  devices = [ d . name for d in devices ] <TAB><TAB><TAB>  logging . info ( "" Replicating over  %s "" , devices ) <TAB><TAB><TAB>  return snt_replicator . Replicator ( devices = devices ) <TAB>  assert False , "" No TPU/GPU or CPU found "" ",if devices :,if devices:,False,25.09229088012479,100.00000000000004
284,"def get_tag_values ( self , event ) : <TAB>  http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB>  if not http : <TAB><TAB>  return [ ] <TAB>  if not http . headers : <TAB><TAB>  return [ ] <TAB>  headers = http . headers <TAB>  # XXX: transitional support for workers <TAB>  if isinstance ( headers , dict ) : <TAB><TAB>  headers = headers . items ( ) <TAB>  output = [ ] <TAB>  for key , value in headers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  ua = Parse ( value ) <TAB><TAB>  if not ua : <TAB><TAB><TAB>  continue <TAB><TAB>  result = self . get_tag_from_ua ( ua ) <TAB><TAB>  if result : <TAB><TAB><TAB>  output . append ( result ) <TAB>  return output ","if key != ""User-Agent"" :",if key == 'tag':,False,53.21753000273803,97.24920852471709
285,"def general ( metadata , value ) : <TAB>  if metadata . get ( "" commands "" ) and value : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = quote ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  v = value <TAB><TAB>  return u "" {0} {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB>  else : <TAB><TAB>  if not value : <TAB><TAB><TAB>  return None <TAB><TAB>  el<IF-STMT>: <TAB><TAB><TAB>  return quote ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  return value ","if not metadata . get ( ""nargs"" ) :",if metadata.get('commands') and value:,False,19.308118920283125,89.25739056774614
286,"def _actions_read ( self , c ) : <TAB>  self . action_input . handle_read ( c ) <TAB>  if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB><TAB>  # take action <TAB><TAB>  if self . action_input . selected_index == 0 :<TAB># Cancel <TAB><TAB><TAB>  self . back_to_parent ( ) <TAB><TAB>  elif self . action_input . selected_index == 1 :<TAB># Apply <TAB><TAB><TAB>  self . _apply_prefs ( ) <TAB><TAB><TAB>  client . core . get_config ( ) . addCallback ( self . _update_preferences ) <TAB><TAB>  <IF-STMT>:<TAB># OK <TAB><TAB><TAB>  self . _apply_prefs ( ) <TAB><TAB><TAB>  self . back_to_parent ( ) ",elif self . action_input . selected_index == 2 :,"if c in [curses.KEY_ENTER, curses.KEY_ENTER2, curses",False,51.65900322021544,87.10918156929318
287,def logic ( ) : <TAB>  if reset == 1 : <TAB><TAB>  lfsr . next = 1 <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # lfsr.next[24:1] = lfsr[23:0] <TAB><TAB><TAB>  lfsr . next = lfsr << 1 <TAB><TAB><TAB>  lfsr . next [ 0 ] = lfsr [ 23 ] ^ lfsr [ 22 ] ^ lfsr [ 21 ] ^ lfsr [ 16 ] ,if enable :,if reset == 0:,False,49.516374304744964,95.30446225172675
288,"def action_delete ( self , request , attachments ) : <TAB>  deleted_attachments = [ ] <TAB>  desynced_posts = [ ] <TAB>  for attachment in attachments : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  deleted_attachments . append ( attachment . pk ) <TAB><TAB><TAB>  desynced_posts . append ( attachment . post_id ) <TAB>  if desynced_posts : <TAB><TAB>  with transaction . atomic ( ) : <TAB><TAB><TAB>  for post in Post . objects . filter ( id__in = desynced_posts ) : <TAB><TAB><TAB><TAB>  self . delete_from_cache ( post , deleted_attachments ) <TAB>  for attachment in attachments : <TAB><TAB>  attachment . delete ( ) <TAB>  message = _ ( "" Selected attachments have been deleted. "" ) <TAB>  messages . success ( request , message ) ",if attachment . post :,if attachment.pk:,False,51.991322041025654,98.79655867558668
289,"def __getitem__ ( self , index ) : <TAB>  if self . _check ( ) : <TAB><TAB>  if isinstance ( index , int ) : <TAB><TAB><TAB>  if index < 0 or index > = len ( self . features ) : <TAB><TAB><TAB><TAB>  raise IndexError ( index ) <TAB><TAB><TAB>  if self . features [ index ] is None : <TAB><TAB><TAB><TAB>  feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB><TAB><TAB><TAB>  if feature : <TAB><TAB><TAB><TAB><TAB>  ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB><TAB><TAB><TAB><TAB>  self . features [ index ] = FEATURE [ feature ] <TAB><TAB><TAB>  return self . features [ index ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  indices = index . indices ( len ( self . features ) ) <TAB><TAB><TAB>  return [ self . __getitem__ ( i ) for i in range ( * indices ) ] ","elif isinstance ( index , slice ) :","if isinstance(index, FeatureSet):",False,31.27001022960785,98.23621484436937
290,"def _skip_start ( self ) : <TAB>  start , stop = self . start , self . stop <TAB>  for chunk in self . app_iter : <TAB><TAB>  self . _pos + = len ( chunk ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  elif self . _pos == start : <TAB><TAB><TAB>  return b "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  chunk = chunk [ start - self . _pos : ] <TAB><TAB><TAB>  if stop is not None and self . _pos > stop : <TAB><TAB><TAB><TAB>  chunk = chunk [ : stop - self . _pos ] <TAB><TAB><TAB><TAB>  assert len ( chunk ) == stop - start <TAB><TAB><TAB>  return chunk <TAB>  else : <TAB><TAB>  raise StopIteration ( ) ",if self . _pos < start :,if self._pos >= len(chunk):,False,26.252560187748713,96.7139310752562
291,"def get_files ( d ) : <TAB>  f = [ ] <TAB>  for root , dirs , files in os . walk ( d ) : <TAB><TAB>  for name in files : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB><TAB><TAB><TAB>  f . append ( os . path . join ( root , name ) ) <TAB>  return f ","if ""meta-environment"" in root or ""cross-canadian"" in root :",if name.startswith('.py') or name.endswith('.py') or,False,53.37626964557687,89.32543346478657
292,"def _load_windows_store_certs ( self , storename , purpose ) : <TAB>  certs = bytearray ( ) <TAB>  try : <TAB><TAB>  for cert , encoding , trust in enum_certificates ( storename ) : <TAB><TAB><TAB>  # CA certs are never PKCS#7 encoded <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if trust is True or purpose . oid in trust : <TAB><TAB><TAB><TAB><TAB>  certs . extend ( cert ) <TAB>  except PermissionError : <TAB><TAB>  warnings . warn ( "" unable to enumerate Windows certificate store "" ) <TAB>  if certs : <TAB><TAB>  self . load_verify_locations ( cadata = certs ) <TAB>  return certs ","if encoding == ""x509_asn"" :",if encoding == 'PKCS#7':,False,59.64111730676185,96.4547964068384
293,"def test_tokenizer_identifier_with_correct_config ( self ) : <TAB>  for tokenizer_class in [ BertTokenizer , BertTokenizerFast , AutoTokenizer ] : <TAB><TAB>  tokenizer = tokenizer_class . from_pretrained ( "" wietsedv/bert-base-dutch-cased "" ) <TAB><TAB>  self . assertIsInstance ( tokenizer , ( BertTokenizer , BertTokenizerFast ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( tokenizer . basic_tokenizer . do_lower_case , False ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( tokenizer . do_lower_case , False ) <TAB><TAB>  self . assertEqual ( tokenizer . model_max_length , 512 ) ","if isinstance ( tokenizer , BertTokenizer ) :",if tokenizer.basic_tokenizer:,False,21.24919349999501,95.53114985367728
294,"def run ( self ) : <TAB>  global WAITING_BEFORE_START <TAB>  time . sleep ( WAITING_BEFORE_START ) <TAB>  while self . keep_alive : <TAB><TAB>  path_id , module , resolve = self . queue_receive . get ( ) <TAB><TAB>  if path_id is None : <TAB><TAB><TAB>  continue <TAB><TAB>  self . lock . acquire ( ) <TAB><TAB>  self . modules [ path_id ] = module <TAB><TAB>  self . lock . release ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  resolution = self . _resolve_with_other_modules ( resolve ) <TAB><TAB><TAB>  self . _relations [ path_id ] = [ ] <TAB><TAB><TAB>  for package in resolution : <TAB><TAB><TAB><TAB>  self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB><TAB><TAB>  self . queue_send . put ( ( path_id , module , False , resolution ) ) ",if resolve :,if resolve is not None:,False,35.99102733238568,98.22184656718427
295,"def __new__ ( mcs , name , bases , attrs ) : <TAB>  include_profile = include_trace = include_garbage = True <TAB>  bases = list ( bases ) <TAB>  if name == "" SaltLoggingClass "" : <TAB><TAB>  for base in bases : <TAB><TAB><TAB>  if hasattr ( base , "" trace "" ) : <TAB><TAB><TAB><TAB>  include_trace = False <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  include_garbage = False <TAB>  if include_profile : <TAB><TAB>  bases . append ( LoggingProfileMixin ) <TAB>  if include_trace : <TAB><TAB>  bases . append ( LoggingTraceMixin ) <TAB>  if include_garbage : <TAB><TAB>  bases . append ( LoggingGarbageMixin ) <TAB>  return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs ) ","if hasattr ( base , ""garbage"" ) :","if hasattr(base, 'garbage'):",False,54.7705904002064,97.9664830105524
296,"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB>  res = "" "" <TAB>  if self . has_owner_ : <TAB><TAB>  res + = prefix + ( "" owner:  %s \n "" % self . DebugFormatString ( self . owner_ ) ) <TAB>  cnt = 0 <TAB>  for e in self . entries_ : <TAB><TAB>  elm = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elm = "" ( %d ) "" % cnt <TAB><TAB>  res + = prefix + ( "" entries %s  < \n "" % elm ) <TAB><TAB>  res + = e . __str__ ( prefix + ""<TAB>"" , printElemNumber ) <TAB><TAB>  res + = prefix + "" > \n "" <TAB><TAB>  cnt + = 1 <TAB>  return res ",if printElemNumber :,if e.is_visible():,False,18.743625258153113,93.7525338927732
297,"def parse_tag ( self ) : <TAB>  buf = [ ] <TAB>  escaped = False <TAB>  for c in self . get_next_chars ( ) : <TAB><TAB>  if escaped : <TAB><TAB><TAB>  buf . append ( c ) <TAB><TAB>  elif c == "" \\ "" : <TAB><TAB><TAB>  escaped = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" "" . join ( buf ) <TAB><TAB>  else : <TAB><TAB><TAB>  buf . append ( c ) <TAB>  raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) ) ","elif c == "">"" :","if c == '""':",False,43.98652928164104,95.74235376449839
298,"def get_batches ( train_nodes , train_labels , batch_size = 64 , shuffle = True ) : <TAB>  if shuffle : <TAB><TAB>  random . shuffle ( train_nodes ) <TAB>  total = train_nodes . shape [ 0 ] <TAB>  for i in range ( 0 , total , batch_size ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cur_nodes = train_nodes [ i : i + batch_size ] <TAB><TAB><TAB>  cur_labels = train_labels [ cur_nodes ] <TAB><TAB><TAB>  yield cur_nodes , cur_labels ",if i + batch_size <= total :,if train_nodes[i + batch_size] > 0:,False,49.165684189983004,93.5466807170957
299,"def _get_all_info_lines ( data ) : <TAB>  infos = [ ] <TAB>  for row in data : <TAB><TAB>  splitrow = row . split ( ) <TAB><TAB>  if len ( splitrow ) > 0 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  infos . append ( "" "" . join ( splitrow [ 1 : ] ) ) <TAB>  return infos ","if splitrow [ 0 ] == ""INFO:"" :",if splitrow[0] == 'INFO':,False,51.40459834524758,94.86652395302238
300,"def _validate_client_public_key ( self , username , key_data ) : <TAB>  """"""Validate a client public key for the specified user"""""" <TAB>  try : <TAB><TAB>  key = decode_ssh_public_key ( key_data ) <TAB>  except KeyImportError : <TAB><TAB>  return None <TAB>  options = None <TAB>  if self . _client_keys : <TAB><TAB>  options = self . _client_keys . validate ( key , self . _peer_addr ) <TAB>  if options is None : <TAB><TAB>  result = self . _owner . validate_public_key ( username , key ) <TAB><TAB>  if asyncio . iscoroutine ( result ) : <TAB><TAB><TAB>  result = yield from result <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  options = { } <TAB>  self . _key_options = options <TAB>  return key ",if not result :,if result is not None:,False,37.82782960910218,97.77514122758403
301,"def attach_related_versions ( addons , addon_dict = None ) : <TAB>  if addon_dict is None : <TAB><TAB>  addon_dict = { addon . id : addon for addon in addons } <TAB>  all_ids = set ( filter ( None , ( addon . _current_version_id for addon in addons ) ) ) <TAB>  versions = list ( Version . objects . filter ( id__in = all_ids ) . order_by ( ) ) <TAB>  for version in versions : <TAB><TAB>  try : <TAB><TAB><TAB>  addon = addon_dict [ version . addon_id ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  log . info ( "" Version  %s  has an invalid add-on id. "" % version . id ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  addon . _current_version = version <TAB><TAB>  version . addon = addon ",if addon . _current_version_id == version . id :,"if not isinstance(addon, Version):",False,36.53994447759884,93.979450930321
302,"def move_view ( obj , evt ) : <TAB>  position = obj . GetCurrentCursorPosition ( ) <TAB>  for other_axis , axis_number in self . _axis_names . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  ipw3d = getattr ( self , "" ipw_3d_ %s "" % other_axis ) <TAB><TAB>  ipw3d . ipw . slice_position = position [ axis_number ] ",if other_axis == axis_name :,if axis_number == 0:,False,47.771150307355825,92.83876954037211
303,"def func_wrapper ( * args , * * kwargs ) : <TAB>  warnings . simplefilter ( "" always "" , DeprecationWarning )<TAB># turn off filter <TAB>  for old , new in arg_mapping . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  f "" Keyword argument  ' { old } '  has been  "" <TAB><TAB><TAB><TAB>  f "" deprecated in favour of  ' { new } ' .  "" <TAB><TAB><TAB><TAB>  f "" ' { old } '  will be removed in a future version. "" , <TAB><TAB><TAB><TAB>  category = DeprecationWarning , <TAB><TAB><TAB><TAB>  stacklevel = 2 , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  val = kwargs . pop ( old ) <TAB><TAB><TAB>  kwargs [ new ] = val <TAB>  # reset filter <TAB>  warnings . simplefilter ( "" default "" , DeprecationWarning ) <TAB>  return func ( * args , * * kwargs ) ",if old in kwargs :,if old != new:,False,17.84031004643228,96.48328316970675
304,"def inner_connection_checker ( self , * args , * * kwargs ) : <TAB>  LOG . debug ( "" in _connection_checker "" ) <TAB>  for attempts in range ( 5 ) : <TAB><TAB>  try : <TAB><TAB><TAB>  return func ( self , * args , * * kwargs ) <TAB><TAB>  except exception . VolumeBackendAPIException as e : <TAB><TAB><TAB>  pattern = re . compile ( r "" .*Session id expired$ "" ) <TAB><TAB><TAB>  matches = pattern . match ( six . text_type ( e ) ) <TAB><TAB><TAB>  if matches : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  LOG . debug ( "" Session might have expired. "" ""  Trying to relogin "" ) <TAB><TAB><TAB><TAB><TAB>  self . _login ( ) <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  LOG . error ( "" Re-throwing Exception  %s "" , e ) <TAB><TAB><TAB>  raise ",if attempts < 4 :,if matches[1] == 0:,False,21.39314997609069,96.80772233971524
305,"def set ( self , pcount ) : <TAB>  """"""Set channel prefetch_count setting."""""" <TAB>  if pcount != self . prev : <TAB><TAB>  new_value = pcount <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  "" QoS: Disabled: prefetch_count exceeds  %r "" , PREFETCH_COUNT_MAX <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  new_value = 0 <TAB><TAB>  logger . debug ( "" basic.qos: prefetch_count-> %s "" , new_value ) <TAB><TAB>  self . callback ( prefetch_count = new_value ) <TAB><TAB>  self . prev = pcount <TAB>  return pcount ",if pcount > PREFETCH_COUNT_MAX :,if new_value > PREFETCH_COUNT_MAX:,False,40.663658371452904,97.61989713904586
306,"def _build_gcs_object_key ( self , key ) : <TAB>  if self . platform_specific_separator : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gcs_object_key = os . path . join ( <TAB><TAB><TAB><TAB>  self . prefix , self . _convert_key_to_filepath ( key ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gcs_object_key = "" / "" . join ( ( self . prefix , self . _convert_key_to_filepath ( key ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB>  return gcs_object_key ",if self . prefix :,if self.prefix:,False,24.110574715541578,97.65282437541332
307,"def number_operators ( self , a , b , skip = [ ] ) : <TAB>  dict = { "" a "" : a , "" b "" : b } <TAB>  for name , expr in self . binops . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = "" __ %s __ "" % name <TAB><TAB><TAB>  if hasattr ( a , name ) : <TAB><TAB><TAB><TAB>  res = eval ( expr , dict ) <TAB><TAB><TAB><TAB>  self . binop_test ( a , b , res , expr , name ) <TAB>  for name , expr in self . unops . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = "" __ %s __ "" % name <TAB><TAB><TAB>  if hasattr ( a , name ) : <TAB><TAB><TAB><TAB>  res = eval ( expr , dict ) <TAB><TAB><TAB><TAB>  self . unop_test ( a , res , expr , name ) ",if name not in skip :,if skip:,False,31.062819521736905,95.74606128115533
308,def isCurveMonotonic ( set_ ) : <TAB>  for i in range ( len ( set_ ) - 1 ) : <TAB><TAB>  # ==== added by zli ======= <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  # ==== added by zli ======= <TAB><TAB>  # ==== added by zli ======= <TAB><TAB>  # if set_[i][1] > set_[i + 1][1]: <TAB><TAB>  if set_ [ i ] [ 1 ] > = set_ [ i + 1 ] [ 1 ] : <TAB><TAB><TAB>  # ==== added by zli ======= <TAB><TAB><TAB>  return False <TAB>  return True ,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,if set_[i][0] < set_[i][0]:,False,61.49356311149301,96.81474642505779
309,"def show_topics ( ) : <TAB>  """"""prints all available miscellaneous help topics."""""" <TAB>  print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB>  for pp in PAGEPATHS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  content = os . listdir ( pp ) <TAB><TAB>  for pn in content : <TAB><TAB><TAB>  if "" . "" in pn : <TAB><TAB><TAB><TAB>  name = pn [ : pn . index ( "" . "" ) ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  name = pn <TAB><TAB><TAB>  print ( name ) ",if not os . path . isdir ( pp ) :,if pp == pp:,False,29.458453939939112,94.45192349632663
310,"def test_send_error ( self ) : <TAB>  allow_transfer_encoding_codes = ( 205 , 304 ) <TAB>  for code in ( 101 , 102 , 204 , 205 , 304 ) : <TAB><TAB>  self . con . request ( "" SEND_ERROR "" , "" / {} "" . format ( code ) ) <TAB><TAB>  res = self . con . getresponse ( ) <TAB><TAB>  self . assertEqual ( code , res . status ) <TAB><TAB>  self . assertEqual ( None , res . getheader ( "" Content-Length "" ) ) <TAB><TAB>  self . assertEqual ( None , res . getheader ( "" Content-Type "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( None , res . getheader ( "" Transfer-Encoding "" ) ) <TAB><TAB>  data = res . read ( ) <TAB><TAB>  self . assertEqual ( b "" "" , data ) ",if code not in allow_transfer_encoding_codes :,if allow_transfer_encoding_codes:,False,25.96997723000199,97.9077121482564
311,"def _length_hint ( obj ) : <TAB>  """"""Returns the length hint of an object."""""" <TAB>  try : <TAB><TAB>  return len ( obj ) <TAB>  except ( AttributeError , TypeError ) : <TAB><TAB>  try : <TAB><TAB><TAB>  get_hint = type ( obj ) . __length_hint__ <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  return None <TAB><TAB>  try : <TAB><TAB><TAB>  hint = get_hint ( obj ) <TAB><TAB>  except TypeError : <TAB><TAB><TAB>  return None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  return hint ","if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 :",if hint is None:,False,51.978579726289745,91.21566977412574
312,"def _rmtree ( self , path ) : <TAB>  # Essentially a stripped down version of shutil.rmtree.  We can't <TAB>  # use globals because they may be None'ed out at shutdown. <TAB>  for name in self . _listdir ( path ) : <TAB><TAB>  fullname = self . _path_join ( path , name ) <TAB><TAB>  try : <TAB><TAB><TAB>  isdir = self . _isdir ( fullname ) <TAB><TAB>  except self . _os_error : <TAB><TAB><TAB>  isdir = False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _rmtree ( fullname ) <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . _remove ( fullname ) <TAB><TAB><TAB>  except self . _os_error : <TAB><TAB><TAB><TAB>  pass <TAB>  try : <TAB><TAB>  self . _rmdir ( path ) <TAB>  except self . _os_error : <TAB><TAB>  pass ",if isdir :,if isdir:,False,39.34407602834844,100.00000000000004
313,"def get_sources ( self , sources = None ) : <TAB>  """"""Returns all sources from this provider."""""" <TAB>  self . _load ( ) <TAB>  if sources is None : <TAB><TAB>  sources = list ( self . data . keys ( ) ) <TAB>  elif not isinstance ( sources , ( list , tuple ) ) : <TAB><TAB>  sources = [ sources ] <TAB>  for source in sources : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise KeyError ( <TAB><TAB><TAB><TAB>  "" Invalid data key:  {} . Valid keys are:  {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  source , "" ,  "" . join ( str ( k ) for k in self . data ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return { k : self . data [ k ] for k in sources } ",if source not in self . data :,"if not isinstance(source, str):",False,28.957437240735384,96.49141040437375
314,"def do_shorts ( <TAB>  opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ]  ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB>  while optstring != "" "" : <TAB><TAB>  opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB><TAB>  if short_has_arg ( opt , shortopts ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if not args : <TAB><TAB><TAB><TAB><TAB>  raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB><TAB><TAB><TAB>  optstring , args = args [ 0 ] , args [ 1 : ] <TAB><TAB><TAB>  optarg , optstring = optstring , "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  optarg = "" "" <TAB><TAB>  opts . append ( ( "" - "" + opt , optarg ) ) <TAB>  return opts , args ","if optstring == """" :",if opt not in shortopts:,False,30.427634865176717,97.45447262459398
315,"def _sanitize_dict ( self , config_dict , allow_val_change = None , ignore_keys : set = None ) : <TAB>  sanitized = { } <TAB>  for k , v in six . iteritems ( config_dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  k , v = self . _sanitize ( k , v , allow_val_change ) <TAB><TAB>  sanitized [ k ] = v <TAB>  return sanitized ",if ignore_keys and k in ignore_keys :,if k in ignore_keys:,False,47.24003130105214,95.4086929178798
316,def x ( data ) : <TAB>  count = 0 <TAB>  while count < 10 : <TAB><TAB>  data . start_example ( SOME_LABEL ) <TAB><TAB>  b = data . draw_bits ( 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  count + = 1 <TAB><TAB>  data . stop_example ( discard = not b ) <TAB>  data . mark_interesting ( ) ,if b :,if b:,False,19.940390628799506,100.00000000000004
317,"def prompt_for_resume ( config ) : <TAB>  logger = logging . getLogger ( "" changeme "" ) <TAB>  logger . error ( <TAB><TAB>  "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB>  ) <TAB>  answer = "" "" <TAB>  while not ( answer == "" R "" or answer == "" F "" ) : <TAB><TAB>  prompt = "" (R/F)>  "" <TAB><TAB>  answer = "" "" <TAB><TAB>  try : <TAB><TAB><TAB>  answer = raw_input ( prompt ) <TAB><TAB>  except NameError : <TAB><TAB><TAB>  answer = input ( prompt ) <TAB><TAB>  if answer . upper ( ) == "" F "" : <TAB><TAB><TAB>  logger . debug ( "" Forcing a fresh scan "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( "" Resuming previous scan "" ) <TAB><TAB><TAB>  config . resume = True <TAB>  return config . resume ","elif answer . upper ( ) == ""R"" :",if config.resume:,False,35.28973100348104,95.19897722000356
318,"def _evaluate_local_single ( self , iterator ) : <TAB>  for batch in iterator : <TAB><TAB>  in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB><TAB>  with function . no_backprop_mode ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  results = self . calc_local ( * in_arrays ) <TAB><TAB><TAB>  elif isinstance ( in_arrays , dict ) : <TAB><TAB><TAB><TAB>  results = self . calc_local ( * * in_arrays ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results = self . calc_local ( in_arrays ) <TAB><TAB>  if self . _progress_hook : <TAB><TAB><TAB>  self . _progress_hook ( batch ) <TAB><TAB>  yield results ","if isinstance ( in_arrays , tuple ) :","if isinstance(in_arrays, list):",False,47.957959306947565,98.89740890659164
319,"def _send_until_done ( self , data ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  return self . connection . send ( data ) <TAB><TAB>  except OpenSSL . SSL . WantWriteError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise timeout ( ) <TAB><TAB><TAB>  continue <TAB><TAB>  except OpenSSL . SSL . SysCallError as e : <TAB><TAB><TAB>  raise SocketError ( str ( e ) ) ","if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :",if self.connection.timeout:,False,21.68399304378343,84.82322238763089
320,"def _read_jtl_chunk ( self , jtl ) : <TAB>  data = jtl . read ( 1024 * 1024 * 10 ) <TAB>  if data : <TAB><TAB>  parts = data . rsplit ( "" \n "" , 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ready_chunk = self . buffer + parts [ 0 ] + "" \n "" <TAB><TAB><TAB>  self . buffer = parts [ 1 ] <TAB><TAB><TAB>  df = string_to_df ( ready_chunk ) <TAB><TAB><TAB>  self . stat_queue . put ( df ) <TAB><TAB><TAB>  return df <TAB><TAB>  else : <TAB><TAB><TAB>  self . buffer + = parts [ 0 ] <TAB>  else : <TAB><TAB>  if self . jmeter_finished : <TAB><TAB><TAB>  self . agg_finished = True <TAB><TAB>  jtl . readline ( ) <TAB>  return None ",if len ( parts ) > 1 :,if len(parts) == 2:,False,26.12263189010176,98.09379109130822
321,"def __new__ ( mcl , classname , bases , dictionary ) : <TAB>  slots = list ( dictionary . get ( "" __slots__ "" , [ ] ) ) <TAB>  for getter_name in [ key for key in dictionary if key . startswith ( "" get_ "" ) ] : <TAB><TAB>  name = getter_name <TAB><TAB>  slots . append ( "" __ "" + name ) <TAB><TAB>  getter = dictionary . pop ( getter_name ) <TAB><TAB>  setter = dictionary . get ( setter_name , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del dictionary [ setter_name ] <TAB><TAB>  dictionary [ name ] = property ( getter . setter ) <TAB><TAB>  dictionary [ "" __slots__ "" ] = tuple ( slots ) <TAB><TAB>  return super ( ) . __new__ ( mcl , classname , bases , dictionary ) ","if setter is not None and isinstance ( setter , collections . Callable ) :",if setter is not None:,False,31.119884351901362,95.28691608098104
322,"def tex_coords ( self ) : <TAB>  """"""Array of texture coordinate data."""""" <TAB>  if "" multi_tex_coords "" not in self . domain . attribute_names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  domain = self . domain <TAB><TAB><TAB>  attribute = domain . attribute_names [ "" tex_coords "" ] <TAB><TAB><TAB>  self . _tex_coords_cache = attribute . get_region ( <TAB><TAB><TAB><TAB>  attribute . buffer , self . start , self . count <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . _tex_coords_cache_version = domain . _version <TAB><TAB>  region = self . _tex_coords_cache <TAB><TAB>  region . invalidate ( ) <TAB><TAB>  return region . array <TAB>  else : <TAB><TAB>  return None ",if self . _tex_coords_cache_version != self . domain . _version :,if self.count > 0:,False,47.99806062535554,92.48191445872332
323,"def index ( self , sub , start = 0 ) : <TAB>  """"""Returns the index of the closing bracket"""""" <TAB>  br = "" ([ { < "" [ "" )]}> "" . index ( sub ) ] <TAB>  count = 0 <TAB>  for i in range ( start , len ( self . string ) ) : <TAB><TAB>  char = self . string [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  count + = 1 <TAB><TAB>  elif char == sub : <TAB><TAB><TAB>  if count > 0 : <TAB><TAB><TAB><TAB>  count - = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return i <TAB>  err = "" Closing bracket  {!r}  missing in string  {!r} "" . format ( <TAB><TAB>  sub , "" "" . join ( self . original ) <TAB>  ) <TAB>  raise ParseError ( err ) ",if char == br :,if char == br:,False,50.825105855195275,100.00000000000004
324,"def test_createFile ( self ) : <TAB>  text = "" This is a test! "" <TAB>  path = tempfile . mktemp ( ) <TAB>  try : <TAB><TAB>  koDoc = self . _koDocFromPath ( path , load = False ) <TAB><TAB>  koDoc . buffer = text <TAB><TAB>  koDoc . save ( 0 ) <TAB><TAB>  del koDoc <TAB><TAB>  koDoc2 = self . _koDocFromPath ( path ) <TAB><TAB>  assert koDoc2 . buffer == text <TAB>  finally : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . unlink ( path )<TAB># clean up ",if os . path . exists ( path ) :,if os.path.exists(path):,False,21.400097902375403,97.06004651328584
325,"def __editScopeHasEdit ( self , attributeHistory ) : <TAB>  with attributeHistory . context : <TAB><TAB>  tweak = GafferScene . EditScopeAlgo . acquireParameterEdit ( <TAB><TAB><TAB>  attributeHistory . scene . node ( ) , <TAB><TAB><TAB>  attributeHistory . context [ "" scene:path "" ] , <TAB><TAB><TAB>  attributeHistory . attributeName , <TAB><TAB><TAB>  IECoreScene . ShaderNetwork . Parameter ( "" "" , self . __parameter ) , <TAB><TAB><TAB>  createIfNecessary = False , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  return tweak [ "" enabled "" ] . getValue ( ) ",if tweak is None :,if not tweak:,False,21.57277271488612,97.40963917434563
326,"def mail_migrator ( app , schema_editor ) : <TAB>  Event_SettingsStore = app . get_model ( "" pretixbase "" , "" Event_SettingsStore "" ) <TAB>  for ss in Event_SettingsStore . objects . filter ( <TAB><TAB>  key__in = [ <TAB><TAB><TAB>  "" mail_text_order_approved "" , <TAB><TAB><TAB>  "" mail_text_order_placed "" , <TAB><TAB><TAB>  "" mail_text_order_placed_require_approval "" , <TAB><TAB>  ] <TAB>  ) : <TAB><TAB>  chgd = ss . value . replace ( "" {date} "" , "" {expire_date} "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ss . value = chgd <TAB><TAB><TAB>  ss . save ( ) <TAB><TAB><TAB>  cache . delete ( "" hierarkey_ {} _ {} "" . format ( "" event "" , ss . object_id ) ) ",if chgd != ss . value :,if chgd != None:,False,29.267879069522213,98.11156465269006
327,"def __get_limits ( self ) : <TAB>  dimension = len ( self . __tree . get_root ( ) . data ) <TAB>  nodes = self . __get_all_nodes ( ) <TAB>  max , min = [ float ( "" -inf "" ) ] * dimension , [ float ( "" +inf "" ) ] * dimension <TAB>  for node in nodes : <TAB><TAB>  for d in range ( dimension ) : <TAB><TAB><TAB>  if max [ d ] < node . data [ d ] : <TAB><TAB><TAB><TAB>  max [ d ] = node . data [ d ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  min [ d ] = node . data [ d ] <TAB>  return min , max ",if min [ d ] > node . data [ d ] :,if min[d] > max[d]:,False,32.24626508361701,97.6718847684911
328,"def get_complete_position ( self , context : UserContext ) - > int : <TAB>  # Check member prefix pattern. <TAB>  for prefix_pattern in convert2list ( <TAB><TAB>  self . get_filetype_var ( context [ "" filetype "" ] , "" prefix_patterns "" ) <TAB>  ) : <TAB><TAB>  m = re . search ( self . _object_pattern + prefix_pattern + r "" \ w*$ "" , context [ "" input "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  self . _prefix = re . sub ( r "" \ w*$ "" , "" "" , m . group ( 0 ) ) <TAB><TAB>  m = re . search ( r "" \ w*$ "" , context [ "" input "" ] ) <TAB><TAB>  if m : <TAB><TAB><TAB>  return m . start ( ) <TAB>  return - 1 ","if m is None or prefix_pattern == """" :",if m is None:,False,19.68775164039677,95.24907619293305
329,"def _stderr_supports_color ( ) : <TAB>  try : <TAB><TAB>  if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB><TAB><TAB>  if curses : <TAB><TAB><TAB><TAB>  curses . setupterm ( ) <TAB><TAB><TAB><TAB>  if curses . tigetnum ( "" colors "" ) > 0 : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if sys . stderr is getattr ( <TAB><TAB><TAB><TAB><TAB>  colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB><TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  except Exception : <TAB><TAB>  # Very broad exception handling because it's always better to <TAB><TAB>  # fall back to non-colored logs than to break at startup. <TAB><TAB>  pass <TAB>  return False ",elif colorama :,if sys.platform == 'win32':,False,62.73924017172767,96.6831480469334
330,"def setLabelColumnWidth ( self , panel , width ) : <TAB>  for child in panel . GetChildren ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size = child . GetSize ( ) <TAB><TAB><TAB>  size [ 0 ] = width <TAB><TAB><TAB>  child . SetBestSize ( size ) ","if isinstance ( child , wx . lib . stattext . GenStaticText ) :",if child.GetLabel() == panel.GetLabel():,False,43.40742052686194,86.60681097246683
331,"def update ( self , other ) : <TAB>  if other . M is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . items . update ( other . items ) <TAB><TAB>  else : <TAB><TAB><TAB>  for i in other . items : <TAB><TAB><TAB><TAB>  self . add ( i ) <TAB><TAB>  return <TAB>  <IF-STMT>: <TAB><TAB>  self . convert ( ) <TAB>  self . M = array . array ( "" B "" , list ( map ( max , list ( zip ( self . M , other . M ) ) ) ) ) ",if self . M is None :,"if isinstance(other.items, list):",False,42.78065134904464,91.12894161015065
332,"def on_end_epoch ( self , state ) : <TAB>  if self . write_epoch_metrics : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . writer . add_text ( <TAB><TAB><TAB><TAB>  "" epoch "" , <TAB><TAB><TAB><TAB>  "" <h4>Epoch  {} </h4> "" . format ( state [ torchbearer . EPOCH ] ) <TAB><TAB><TAB><TAB>  + self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB><TAB><TAB><TAB>  1 , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . writer . add_text ( <TAB><TAB><TAB><TAB>  "" epoch "" , <TAB><TAB><TAB><TAB>  self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB><TAB><TAB><TAB>  state [ torchbearer . EPOCH ] , <TAB><TAB><TAB>  ) ",if self . visdom :,if state[torchbearer.EPOCH] > 1:,False,35.664287966939476,96.41738402102266
333,"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB>  """"""Check if the conversation is in need for a user message."""""" <TAB>  tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB>  for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  elif e . get ( "" event "" ) == ActionExecuted . type_name : <TAB><TAB><TAB>  return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB>  return False ","if e . get ( ""event"" ) == UserUttered . type_name :",if e.get('event') == ActionExecuted.type_name:,False,58.673332059424865,95.9975189050171
334,"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB>  assert nw_id != self . nw_id_unknown <TAB>  ret = [ ] <TAB>  for port in self . get_ports ( dpid ) : <TAB><TAB>  nw_id_ = port . network_id <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if nw_id_ == nw_id : <TAB><TAB><TAB>  ret . append ( port . port_no ) <TAB><TAB>  elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB><TAB><TAB>  ret . append ( port . port_no ) <TAB>  return ret ",if port . port_no == in_port :,if nw_id_ == in_port:,False,33.801012826493235,96.87815749662438
335,"def next_month ( billing_cycle_anchor : datetime , dt : datetime ) - > datetime : <TAB>  estimated_months = round ( ( dt - billing_cycle_anchor ) . days * 12.0 / 365 ) <TAB>  for months in range ( max ( estimated_months - 1 , 0 ) , estimated_months + 2 ) : <TAB><TAB>  proposed_next_month = add_months ( billing_cycle_anchor , months ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return proposed_next_month <TAB>  raise AssertionError ( <TAB><TAB>  "" Something wrong in next_month calculation with  "" <TAB><TAB>  f "" billing_cycle_anchor:  { billing_cycle_anchor } , dt:  { dt } "" <TAB>  ) ",if 20 < ( proposed_next_month - dt ) . days < 40 :,if proposed_next_month is not None:,False,48.754213531100945,92.97503555770034
336,"def wait_complete ( self ) : <TAB>  """"""Wait for futures complete done."""""" <TAB>  for future in concurrent . futures . as_completed ( self . _futures . keys ( ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  error = future . exception ( ) <TAB><TAB>  except concurrent . futures . CancelledError : <TAB><TAB><TAB>  break <TAB><TAB>  name = self . _futures [ future ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  err_msg = ' Extracting  "" {0} "" , got:  {1} ' . format ( name , error ) <TAB><TAB><TAB>  logger . error ( err_msg ) ",if error is not None :,if error:,False,29.382334452958375,95.85529420605961
337,"def _accept_with ( cls , orm , target ) : <TAB>  if target is orm . mapper : <TAB><TAB>  return mapperlib . Mapper <TAB>  elif isinstance ( target , type ) : <TAB><TAB>  if issubclass ( target , mapperlib . Mapper ) : <TAB><TAB><TAB>  return target <TAB><TAB>  else : <TAB><TAB><TAB>  mapper = _mapper_or_none ( target ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return mapper <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return _MapperEventsHold ( target ) <TAB>  else : <TAB><TAB>  return target ",if mapper is not None :,if mapper is not None:,False,52.141555525834505,100.00000000000004
338,"def gvariant_args ( args : List [ Any ] ) - > str : <TAB>  """"""Convert args into gvariant."""""" <TAB>  gvariant = "" "" <TAB>  for arg in args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB><TAB>  elif isinstance ( arg , ( int , float ) ) : <TAB><TAB><TAB>  gvariant + = f "" { arg } "" <TAB><TAB>  elif isinstance ( arg , str ) : <TAB><TAB><TAB>  gvariant + = f ' "" { arg } "" ' <TAB><TAB>  else : <TAB><TAB><TAB>  gvariant + = f "" { arg !s} "" <TAB>  return gvariant . lstrip ( ) ","if isinstance ( arg , bool ) :","if isinstance(arg, str):",False,42.474801814587295,96.8690798650169
339,"def _list_cases ( suite ) : <TAB>  for test in suite : <TAB><TAB>  if isinstance ( test , unittest . TestSuite ) : <TAB><TAB><TAB>  _list_cases ( test ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if support . match_test ( test ) : <TAB><TAB><TAB><TAB>  print ( test . id ( ) ) ","elif isinstance ( test , unittest . TestCase ) :",if support.match_suite(test):,False,25.252033792628236,91.65354276318958
340,def get_and_set_all_disambiguation ( self ) : <TAB>  all_disambiguations = [ ] <TAB>  for page in self . pages : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB><TAB>  if page . relations . disambiguation_links is not None : <TAB><TAB><TAB>  all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB>  return set ( all_disambiguations ) ,if page . relations . disambiguation_links_norm is not None :,if page.relations.disambiguation_links_norm is not None:,False,53.172434934431415,100.00000000000004
341,"def test_decode_invalid ( self ) : <TAB>  testcases = [ <TAB><TAB>  ( b "" xn--w& "" , "" strict "" , UnicodeError ( ) ) , <TAB><TAB>  ( b "" xn--w& "" , "" ignore "" , "" xn- "" ) , <TAB>  ] <TAB>  for puny , errors , expected in testcases : <TAB><TAB>  with self . subTest ( puny = puny , errors = errors ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertRaises ( UnicodeError , puny . decode , "" punycode "" , errors ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . assertEqual ( puny . decode ( "" punycode "" , errors ) , expected ) ","if isinstance ( expected , Exception ) :",if errors == 'strict':,False,19.60200429385478,95.81853963778035
342,"def find_globs ( walker , patterns , matches ) : <TAB>  for root , dirs , files in walker : <TAB><TAB>  for d in dirs : <TAB><TAB><TAB>  d = join ( root , d ) <TAB><TAB><TAB>  for pattern in patterns : <TAB><TAB><TAB><TAB>  for p in Path ( d ) . glob ( pattern ) : <TAB><TAB><TAB><TAB><TAB>  matches . add ( str ( p ) ) <TAB><TAB>  sub_files = set ( ) <TAB><TAB>  for p in matches : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for f in files : <TAB><TAB><TAB><TAB><TAB>  sub_files . add ( join ( root , f ) ) <TAB><TAB>  matches . update ( sub_files ) ",if root . startswith ( p ) :,if p.startswith('.py'):,False,50.06341128720756,96.85386712858174
343,"def parse_stack_trace ( self , it , line ) : <TAB>  """"""Iterate over lines and parse stack traces."""""" <TAB>  events = [ ] <TAB>  stack_traces = [ ] <TAB>  while self . stack_trace_re . match ( line ) : <TAB><TAB>  event = self . parse_stack_trace_line ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  events . append ( event ) <TAB><TAB>  stack_traces . append ( line ) <TAB><TAB>  line = get_next ( it ) <TAB>  events . reverse ( ) <TAB>  return stack_traces , events , line ",if event :,if event is not None:,False,33.871408584989545,97.11656816119613
344,"def process ( self ) : <TAB>  """"""Do processing necessary, storing result in feature."""""" <TAB>  summation = 0<TAB># count of all <TAB>  histo = self . data [ "" flat.notes.quarterLengthHistogram "" ] <TAB>  if not histo : <TAB><TAB>  raise NativeFeatureException ( "" input lacks notes "" ) <TAB>  maxKey = 0<TAB># max found for any one key <TAB>  for key in histo : <TAB><TAB>  # all defined keys should be greater than zero, but just in case <TAB><TAB>  if histo [ key ] > 0 : <TAB><TAB><TAB>  summation + = histo [ key ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  maxKey = histo [ key ] <TAB>  self . feature . vector [ 0 ] = maxKey / summation ",if histo [ key ] >= maxKey :,if histo[key] > maxKey:,False,30.634037361388387,94.68502401215812
345,"def load_resource ( name ) : <TAB>  """"""return file contents for files within the package root folder"""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return sublime . load_resource ( "" Packages/Markdown Preview/ {0} "" . format ( name ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  filename = os . path . join ( <TAB><TAB><TAB><TAB>  sublime . packages_path ( ) , INSTALLED_DIRECTORY , os . path . normpath ( name ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return load_utf8 ( filename ) <TAB>  except : <TAB><TAB>  print ( "" Error while load_resource( ' %s ' ) "" % name ) <TAB><TAB>  traceback . print_exc ( ) <TAB><TAB>  return "" "" ",if is_ST3 ( ) :,if os.path.exists(name):,False,58.42085465038514,94.45588275182986
346,"def get_password ( self , service , repo_url ) : <TAB>  if self . is_unlocked : <TAB><TAB>  asyncio . set_event_loop ( asyncio . new_event_loop ( ) ) <TAB><TAB>  collection = secretstorage . get_default_collection ( self . connection ) <TAB><TAB>  attributes = { "" application "" : "" Vorta "" , "" service "" : service , "" repo_url "" : repo_url } <TAB><TAB>  items = list ( collection . search_items ( attributes ) ) <TAB><TAB>  logger . debug ( "" Found  %i  passwords matching repo URL. "" , len ( items ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return items [ 0 ] . get_secret ( ) . decode ( "" utf-8 "" ) <TAB>  return None ",if len ( items ) > 0 :,if items:,False,25.18132542000212,96.17288698432722
347,"def get_files ( d ) : <TAB>  res = [ ] <TAB>  for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB>  if not p : <TAB><TAB><TAB>  continue <TAB><TAB>  ( pth , fname ) = os . path . split ( p ) <TAB><TAB>  if fname == "" output "" : <TAB><TAB><TAB>  continue <TAB><TAB>  if fname == "" PureMVC_Python_1_0 "" : <TAB><TAB><TAB>  continue <TAB><TAB>  if fname [ - 4 : ] == "" .pyc "" :<TAB># ehmm.. no. <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  get_dir ( p ) <TAB><TAB>  else : <TAB><TAB><TAB>  res . append ( p ) <TAB>  return res ",if os . path . isdir ( p ) :,if os.path.isdir(pth):,False,50.21656986245495,95.40606766046832
348,"def test_nic_names ( self ) : <TAB>  p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB>  out = p . communicate ( ) [ 0 ] <TAB>  if PY3 : <TAB><TAB>  out = str ( out , sys . stdout . encoding ) <TAB>  nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB>  for nic in nics : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if nic not in out : <TAB><TAB><TAB>  self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic ) ","if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :",if nic in out:,False,21.650147953375527,84.86385001386492
349,"def vexop_to_simop ( op , extended = True , fp = True ) : <TAB>  res = operations . get ( op ) <TAB>  if res is None and extended : <TAB><TAB>  attrs = op_attrs ( op ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB><TAB>  res = SimIROp ( op , * * attrs ) <TAB>  if res is None : <TAB><TAB>  raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB>  if res . _float and not fp : <TAB><TAB>  raise UnsupportedIROpError ( "" Floating point support disabled "" ) <TAB>  return res ",if attrs is None :,if attrs is None:,False,49.42947087111522,100.00000000000004
350,"def rule_builder_add_value ( self , value , screenshot_name = None ) : <TAB>  rule_builder = self . components . rule_builder <TAB>  rule_builder . menu_button_column . wait_for_and_click ( ) <TAB>  with self . rule_builder_rule_editor ( "" add-column-value "" ) as editor_element : <TAB><TAB>  filter_input = editor_element . find_element_by_css_selector ( "" input[type= ' text ' ] "" ) <TAB><TAB>  filter_input . clear ( ) <TAB><TAB>  filter_input . send_keys ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . screenshot ( screenshot_name ) ",if screenshot_name :,if screenshot_name:,False,50.77867302937575,97.33831041780684
351,"def make_open_socket ( self ) : <TAB>  s = socket . socket ( ) <TAB>  try : <TAB><TAB>  s . bind ( DEFAULT_BIND_ADDR_TUPLE ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Windows and linux (with psutil) doesn't show as open until <TAB><TAB><TAB>  # we call listen (linux with lsof accepts either) <TAB><TAB><TAB>  s . listen ( 1 ) <TAB><TAB>  self . assert_open ( s , s . fileno ( ) ) <TAB>  except : <TAB><TAB>  s . close ( ) <TAB><TAB>  s = None <TAB><TAB>  raise <TAB>  return s ",if WIN or greentest . LINUX :,if sys.platform == 'win32':,False,62.93500143323506,95.71266717839754
352,"def handle_ray_task_error ( e ) : <TAB>  for s in e . traceback_str . split ( "" \n "" ) [ : : - 1 ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  raise getattr ( builtins , s . split ( "" : "" ) [ 0 ] ) ( "" "" . join ( s . split ( "" : "" ) [ 1 : ] ) ) <TAB><TAB><TAB>  except AttributeError as att_err : <TAB><TAB><TAB><TAB>  if "" module "" in str ( att_err ) and builtins . __name__ in str ( att_err ) : <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  raise att_err <TAB>  raise e ","if ""Error"" in s or ""Exception"" in s :",if s.endswith(':,False,21.439152201952627,93.37751461284772
353,"def compare_multiple_events ( i , expected_results , actual_results ) : <TAB>  events_in_a_row = [ ] <TAB>  j = i <TAB>  while j < len ( expected_results ) and isinstance ( <TAB><TAB>  actual_results [ j ] , actual_results [ i ] . __class__ <TAB>  ) : <TAB><TAB>  events_in_a_row . append ( actual_results [ j ] ) <TAB><TAB>  j + = 1 <TAB>  message = "" "" <TAB>  for event in events_in_a_row : <TAB><TAB>  for k in range ( i , j ) : <TAB><TAB><TAB>  passed , message = compare_events ( expected_results [ k ] , event ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  expected_results [ k ] = None <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  return i , False , message <TAB>  return j , True , "" "" ",if passed :,if passed:,False,48.58701615702035,100.00000000000004
354,"def ListSubscriptions ( self , params ) : <TAB>  queryreturn = sqlQuery ( """""" SELECT label, address, enabled FROM subscriptions """""" ) <TAB>  data = ' { "" subscriptions "" :[ ' <TAB>  for row in queryreturn : <TAB><TAB>  label , address , enabled = row <TAB><TAB>  label = shared . fixPotentiallyInvalidUTF8Data ( label ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data + = "" , "" <TAB><TAB>  data + = json . dumps ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" label "" : label . encode ( "" base64 "" ) , <TAB><TAB><TAB><TAB>  "" address "" : address , <TAB><TAB><TAB><TAB>  "" enabled "" : enabled == 1 , <TAB><TAB><TAB>  } , <TAB><TAB><TAB>  indent = 4 , <TAB><TAB><TAB>  separators = ( "" , "" , "" :  "" ) , <TAB><TAB>  ) <TAB>  data + = "" ]} "" <TAB>  return data ",if len ( data ) > 20 :,if enabled:,False,50.55211780089205,97.09962050630799
355,"def compile ( self , args ) : <TAB>  compiled_args = { } <TAB>  for key , value in six . iteritems ( args ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  compiled_args [ key ] = str ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  compiled_args [ key ] = sjson_dumps ( value ) <TAB>  return self . _minified_code % compiled_args ",if key in self . clean_args :,"if isinstance(value, str):",False,45.967813841411065,92.22742557555142
356,"def insert ( self , pack_id , data ) : <TAB>  if ( pack_id not in self . queue ) and pack_id > self . begin_id : <TAB><TAB>  self . queue [ pack_id ] = PacketInfo ( data ) <TAB><TAB>  if self . end_id == pack_id : <TAB><TAB><TAB>  self . end_id = pack_id + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  eid = self . end_id <TAB><TAB><TAB>  while eid < pack_id : <TAB><TAB><TAB><TAB>  self . miss_queue . add ( eid ) <TAB><TAB><TAB><TAB>  eid + = 1 <TAB><TAB><TAB>  self . end_id = pack_id + 1 <TAB><TAB>  else : <TAB><TAB><TAB>  self . miss_queue . remove ( pack_id ) ",elif self . end_id < pack_id :,if pack_id < self.end_id:,False,23.952266587160082,98.01562507759247
357,"def _target_generator ( self ) : <TAB>  # since we do not have predictions yet, so we ignore sampling here <TAB>  if self . _internal_target_generator is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  from . . . . model_zoo . ssd . target import SSDTargetGenerator <TAB><TAB>  self . _internal_target_generator = SSDTargetGenerator ( <TAB><TAB><TAB>  iou_thresh = self . _iou_thresh , <TAB><TAB><TAB>  stds = self . _box_norm , <TAB><TAB><TAB>  negative_mining_ratio = - 1 , <TAB><TAB><TAB>  * * self . _kwargs <TAB><TAB>  ) <TAB><TAB>  return self . _internal_target_generator <TAB>  else : <TAB><TAB>  return self . _internal_target_generator ",if self . _anchors_none :,if self._internal_target_generator is None:,False,39.20976925627308,94.60854224855947
358,"def test_heapsort ( self ) : <TAB>  # Exercise everything with repeated heapsort checks <TAB>  for trial in range ( 100 ) : <TAB><TAB>  size = random . randrange ( 50 ) <TAB><TAB>  data = [ random . randrange ( 25 ) for i in range ( size ) ] <TAB><TAB>  <IF-STMT>:<TAB># Half of the time, use heapify <TAB><TAB><TAB>  heap = data [ : ] <TAB><TAB><TAB>  self . module . heapify ( heap ) <TAB><TAB>  else :<TAB># The rest of the time, use heappush <TAB><TAB><TAB>  heap = [ ] <TAB><TAB><TAB>  for item in data : <TAB><TAB><TAB><TAB>  self . module . heappush ( heap , item ) <TAB><TAB>  heap_sorted = [ self . module . heappop ( heap ) for i in range ( size ) ] <TAB><TAB>  self . assertEqual ( heap_sorted , sorted ( data ) ) ",if trial & 1 :,if trial == 0:,False,35.64811975808975,94.55083592676141
359,"def wait ( self , timeout = None ) : <TAB>  if self . returncode is None : <TAB><TAB>  if timeout is None : <TAB><TAB><TAB>  msecs = _subprocess . INFINITE <TAB><TAB>  else : <TAB><TAB><TAB>  msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB><TAB>  res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB><TAB><TAB>  if code == TERMINATE : <TAB><TAB><TAB><TAB>  code = - signal . SIGTERM <TAB><TAB><TAB>  self . returncode = code <TAB>  return self . returncode ",if res == _subprocess . WAIT_OBJECT_0 :,if res == _subprocess.SUCCESS:,False,51.8050892882766,95.31043780159209
360,"def _on_change ( self ) : <TAB>  changed = False <TAB>  self . save ( ) <TAB>  for key , value in self . data . items ( ) : <TAB><TAB>  if isinstance ( value , bool ) : <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB>  if value != 1 : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  elif len ( value ) != 0 : <TAB><TAB><TAB>  changed = True <TAB><TAB><TAB>  break <TAB>  self . _reset_button . disabled = not changed ",elif value is None :,if key == 'value':,False,47.40228747082513,97.06144928668601
361,"def isnotsurplus ( self , item : T ) - > bool : <TAB>  if not self . matchers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . mismatch_description . append_text ( <TAB><TAB><TAB><TAB>  "" not matched:  "" <TAB><TAB><TAB>  ) . append_description_of ( item ) <TAB><TAB>  return False <TAB>  return True ",if self . mismatch_description :,if item.is_surplus():,False,23.230836896266695,92.23201988042354
362,"def resolve_env_secrets ( config , environ ) : <TAB>  """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB>  if isinstance ( config , dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB><TAB>  elif list ( config . keys ( ) ) == [ "" $file "" ] : <TAB><TAB><TAB>  return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  return { <TAB><TAB><TAB><TAB>  key : resolve_env_secrets ( value , environ ) <TAB><TAB><TAB><TAB>  for key , value in config . items ( ) <TAB><TAB><TAB>  } <TAB>  elif isinstance ( config , list ) : <TAB><TAB>  return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB>  else : <TAB><TAB>  return config ","if list ( config . keys ( ) ) == [ ""$env"" ] :","if list(config.keys()) == [""$env"":",False,28.635799584151876,99.08470910604608
363,"def __open__ ( filename , * args , * * kwargs ) : <TAB>  if os . path . isfile ( filename ) : <TAB><TAB>  return __realopen__ ( filename , * args , * * kwargs ) <TAB>  if not os . path . isabs ( filename ) : <TAB><TAB>  datafilename = __papplet__ . dataPath ( filename ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return __realopen__ ( datafilename , * args , * * kwargs ) <TAB><TAB>  sketchfilename = __papplet__ . sketchPath ( filename ) <TAB>  if os . path . isfile ( sketchfilename ) : <TAB><TAB>  return __realopen__ ( sketchfilename , * args , * * kwargs ) <TAB>  # Fail naturally <TAB>  return __realopen__ ( filename , * args , * * kwargs ) ",if os . path . isfile ( datafilename ) :,if os.path.isfile(datafilename):,False,42.942942834701356,100.00000000000004
364,def run ( self ) : <TAB>  while not self . completed : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  time . sleep ( self . period ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _completed . wait ( self . period ) <TAB><TAB>  self . counter + = 1 <TAB><TAB>  try : <TAB><TAB><TAB>  self . callback ( self . counter ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  if self . timeout is not None : <TAB><TAB><TAB>  dt = time . time ( ) - self . _start_time <TAB><TAB><TAB>  if dt > self . timeout : <TAB><TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  if self . counter == self . count : <TAB><TAB><TAB>  self . stop ( ) ,if self . block :,if self.completed:,False,25.003515945642363,98.90705000370515
365,"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB>  if not path : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise NoSuchSettingsPath ( ) <TAB><TAB>  return <TAB>  if config is not None or defaults is not None : <TAB><TAB>  if config is None : <TAB><TAB><TAB>  config = self . _config <TAB><TAB>  if defaults is None : <TAB><TAB><TAB>  defaults = dict ( self . _map . parents ) <TAB><TAB>  chain = HierarchicalChainMap ( config , defaults ) <TAB>  else : <TAB><TAB>  chain = self . _map <TAB>  try : <TAB><TAB>  chain . del_by_path ( path ) <TAB><TAB>  self . _mark_dirty ( ) <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise NoSuchSettingsPath ( ) <TAB><TAB>  pass ",if error_on_path :,if error_on_path:,False,35.97129549527007,96.85191576974238
366,"def structured_dot_grad ( sparse_A , dense_B , ga ) : <TAB>  if sparse_A . type . format in ( "" csc "" , "" csr "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sdgcsx = sdg_csc <TAB><TAB><TAB>  CSx = CSC <TAB><TAB>  else : <TAB><TAB><TAB>  sdgcsx = sdg_csr <TAB><TAB><TAB>  CSx = CSR <TAB><TAB>  g_A_data = sdgcsx ( csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , dense_B , ga ) <TAB><TAB>  return CSx ( <TAB><TAB><TAB>  g_A_data , csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , csm_shape ( sparse_A ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise NotImplementedError ( ) ","if sparse_A . type . format == ""csc"" :","if sparse_A.type.format == ""csc':",False,47.290898988614664,98.46648406087203
367,"def step_async ( self , actions ) : <TAB>  listify = True <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  listify = False <TAB>  except TypeError : <TAB><TAB>  pass <TAB>  if not listify : <TAB><TAB>  self . actions = actions <TAB>  else : <TAB><TAB>  assert ( <TAB><TAB><TAB>  self . num_envs == 1 <TAB><TAB>  ) , f "" actions  { actions }  is either not a list or has a wrong size - cannot match to  { self . num_envs }  environments "" <TAB><TAB>  self . actions = [ actions ] ",if len ( actions ) == self . num_envs :,if actions is None:,False,44.624077517945715,92.32881396645764
368,"def tempFailureRetry ( func , * args , * * kwargs ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  return func ( * args , * * kwargs ) <TAB><TAB>  except ( os . error , IOError ) as ex : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise ",if ex . errno == errno . EINTR :,if ex.errno == errno.EAGAIN:,False,19.597959605893333,97.85826525822034
369,"def test_learning_always_changes_generation ( chars , order ) : <TAB>  learner = LStar ( lambda s : len ( s ) == 1 and s [ 0 ] in chars ) <TAB>  for c in order : <TAB><TAB>  prev = learner . generation <TAB><TAB>  s = bytes ( [ c ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  learner . learn ( s ) <TAB><TAB><TAB>  assert learner . generation > prev ",if learner . dfa . matches ( s ) != learner . member ( s ) :,if s[0] == c:,False,22.050923978317467,86.37593931465207
370,"def test_costs_5D_noisy_names ( signal_bkps_5D_noisy , cost_name ) : <TAB>  signal , bkps = signal_bkps_5D_noisy <TAB>  cost = cost_factory ( cost_name ) <TAB>  cost . fit ( signal ) <TAB>  cost . error ( 0 , 100 ) <TAB>  cost . error ( 100 , signal . shape [ 0 ] ) <TAB>  cost . error ( 10 , 50 ) <TAB>  cost . sum_of_costs ( bkps ) <TAB>  with pytest . raises ( NotEnoughPoints ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cost . min_size = 4 <TAB><TAB><TAB>  cost . error ( 1 , 2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  cost . error ( 1 , 2 ) ","if cost_name == ""cosine"" :","if isinstance(cost, (int, float)):",False,45.552748975953406,94.2671690802805
371,"def remove_empty_dirs ( dirname ) : <TAB>  logger . debug ( "" remove_empty_dirs  ' %s ' "" % ( dirname ) ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dirname = dirname . encode ( "" utf-8 "" ) <TAB><TAB>  os . removedirs ( dirname ) <TAB><TAB>  logger . debug ( "" remove_empty_dirs  ' %s '  done "" % ( dirname ) ) <TAB>  except OSError as exc :<TAB># Python >2.5 <TAB><TAB>  if exc . errno == errno . ENOTEMPTY : <TAB><TAB><TAB>  logger . debug ( "" remove_empty_dirs  ' %s '  not empty "" % ( dirname ) ) <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  raise <TAB>  except Exception as e : <TAB><TAB>  logger . exception ( e ) <TAB><TAB>  logger . error ( "" remove_empty_dirs exception:  "" + dirname ) <TAB><TAB>  raise e ","if not isinstance ( dirname , str ) :","if isinstance(dirname, unicode):",False,39.46581472959282,92.30132420976372
372,"def get_unique_attribute ( self , name : str ) : <TAB>  feat = None <TAB>  for f in self . features : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if feat is not None : <TAB><TAB><TAB><TAB>  raise RuntimeError ( "" The attribute was not unique. "" ) <TAB><TAB><TAB>  feat = f <TAB>  if feat is None : <TAB><TAB>  raise RuntimeError ( "" The attribute did not exist "" ) <TAB>  return getattr ( feat , name ) ","if self . _return_feature ( f ) and hasattr ( f , name ) :",if f.name == name:,False,50.12771913891933,87.7026558591294
373,"def get_allocated_address ( <TAB>  self , config : ActorPoolConfig , allocated : allocated_type  ) - > str : <TAB>  addresses = config . get_external_addresses ( label = self . label ) <TAB>  for addr in addresses : <TAB><TAB>  occupied = False <TAB><TAB>  for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB><TAB><TAB>  if strategy == self : <TAB><TAB><TAB><TAB>  occupied = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return addr <TAB>  raise NoIdleSlot ( <TAB><TAB>  f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB>  ) ",if not occupied :,if occupied:,False,53.41776931764743,98.69880961903824
374,"def __deepcopy__ ( self , memo ) : <TAB>  cls = self . __class__ <TAB>  result = cls . __new__ ( cls ) <TAB>  memo [ id ( self ) ] = result <TAB>  for key , value in self . __dict__ . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( result , key , copy . copy ( value ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  setattr ( result , key , copy . deepcopy ( value , memo ) ) <TAB>  return result ",if key in cls . dynamic_methods :,if key not in memo:,False,21.181046384401473,94.93376266076777
375,def restore_forward ( model ) : <TAB>  for child in model . children ( ) : <TAB><TAB>  # leaf node <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  child . forward = child . old_forward <TAB><TAB><TAB>  child . old_forward = None <TAB><TAB>  else : <TAB><TAB><TAB>  restore_forward ( child ) ,"if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :","if hasattr(child, 'old_forward'):",False,51.28747197407746,86.25611358490323
376,"def add ( self , obj , allow_duplicates = False ) : <TAB>  if allow_duplicates or obj not in self . _constants : <TAB><TAB>  self . _constant_pool . append ( obj ) <TAB><TAB>  self . _constants [ obj ] = len ( self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _constant_pool . append ( None ) ","if obj . __class__ in ( Double , Long ) :",if obj not in self._constants:,False,34.70056599385064,87.90813087016514
377,"def find_file_copyright_notices ( fname ) : <TAB>  ret = set ( ) <TAB>  f = open ( fname ) <TAB>  lines = f . readlines ( ) <TAB>  for l in lines [ : 80 ] :<TAB># hmmm, assume copyright to be in first 80 lines <TAB><TAB>  idx = l . lower ( ) . find ( "" copyright "" ) <TAB><TAB>  if idx < 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  copyright = l [ idx + 9 : ] . strip ( ) <TAB><TAB>  if not copyright : <TAB><TAB><TAB>  continue <TAB><TAB>  copyright = sanitise ( copyright ) <TAB><TAB>  # hmm, do a quick check to see if there's a year, <TAB><TAB>  # if not, skip it <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  ret . add ( copyright ) <TAB>  return ret ","if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :",if not copyright or copyright == 'John':,False,59.895143759692104,89.60908331835938
378,"def callback ( lexer , match , context ) : <TAB>  text = match . group ( ) <TAB>  extra = "" "" <TAB>  if start : <TAB><TAB>  context . next_indent = len ( text ) <TAB><TAB>  if context . next_indent < context . indent : <TAB><TAB><TAB>  while context . next_indent < context . indent : <TAB><TAB><TAB><TAB>  context . indent = context . indent_stack . pop ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  extra = text [ context . indent : ] <TAB><TAB><TAB><TAB>  text = text [ : context . indent ] <TAB>  else : <TAB><TAB>  context . next_indent + = len ( text ) <TAB>  if text : <TAB><TAB>  yield match . start ( ) , TokenClass , text <TAB>  if extra : <TAB><TAB>  yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB>  context . pos = match . end ( ) ",if context . next_indent > context . indent :,if context.indent:,False,33.98118833712706,97.54898134281068
379,"def queries ( self ) : <TAB>  if DEV : <TAB><TAB>  cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB><TAB>  if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB><TAB><TAB>  if not cmd . stdout . strip ( ) : <TAB><TAB><TAB><TAB>  log_cmd = ShellCommand ( <TAB><TAB><TAB><TAB><TAB>  "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  print ( cmd . stdout ) <TAB><TAB><TAB><TAB>  pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB>  return ( ) ","if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",if log_cmd.run():,False,23.116546361252826,93.37846843883673
380,"def nodes ( self ) : <TAB>  if not self . _nodes : <TAB><TAB>  nodes = self . cluster_group . instances ( ) <TAB><TAB>  self . _nodes = [ ] <TAB><TAB>  master = self . master_node <TAB><TAB>  nodeid = 1 <TAB><TAB>  for node in nodes : <TAB><TAB><TAB>  if node . state not in [ "" pending "" , "" running "" ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _nodes . insert ( 0 , master ) <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  self . _nodes . append ( Node ( node , self . key_location , "" node %.3d "" % nodeid ) ) <TAB><TAB><TAB>  nodeid + = 1 <TAB>  else : <TAB><TAB>  for node in self . _nodes : <TAB><TAB><TAB>  log . debug ( "" refreshing instance  %s "" % node . id ) <TAB><TAB><TAB>  node . update ( ) <TAB>  return self . _nodes ",if node . id == master . id :,if nodeid == master.nodeid:,False,22.881899575002983,97.53439566685739
381,"def match ( cls , agent_name , guid , uri , media = None ) : <TAB>  # Retrieve `Agent` for provided `guid` <TAB>  agent = Agents . get ( agent_name ) <TAB>  if agent is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # First occurrence of unsupported agent <TAB><TAB><TAB>  log . warn ( "" Unsupported metadata agent:  %s "" % agent_name ) <TAB><TAB><TAB>  # Mark unsupported agent as ""seen"" <TAB><TAB><TAB>  unsupported_agents [ agent_name ] = True <TAB><TAB><TAB>  return False <TAB><TAB>  # Duplicate occurrence of unsupported agent <TAB><TAB>  log . warn ( <TAB><TAB><TAB>  "" Unsupported metadata agent:  %s "" % agent_name , extra = { "" duplicate "" : True } <TAB><TAB>  ) <TAB><TAB>  return False <TAB>  # Fill `guid` with details from agent <TAB>  return agent . fill ( guid , uri , media ) ",if agent_name not in unsupported_agents :,if agent_name not in unsupported_agents:,False,59.630654148402975,100.00000000000004
382,"def __createRandom ( plug ) : <TAB>  node = plug . node ( ) <TAB>  parentNode = node . ancestor ( Gaffer . Node ) <TAB>  with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB><TAB>  randomNode = Gaffer . Random ( ) <TAB><TAB>  parentNode . addChild ( randomNode ) <TAB><TAB>  if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) : <TAB><TAB><TAB>  plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  plug . setInput ( randomNode [ "" outColor "" ] ) <TAB>  GafferUI . NodeEditor . acquire ( randomNode ) ","elif isinstance ( plug , Gaffer . Color3fPlug ) :","if isinstance(plug, Gaffer.ColorPlug):",False,25.643852072580486,96.82470863604556
383,"def post_arrow ( self , arr : pa . Table , graph_type : str , opts : str = "" "" ) : <TAB>  dataset_id = self . dataset_id <TAB>  tok = self . token <TAB>  sub_path = f "" api/v2/upload/datasets/ { dataset_id } / { graph_type } /arrow "" <TAB>  try : <TAB><TAB>  resp = self . post_arrow_generic ( sub_path , tok , arr , opts ) <TAB><TAB>  out = resp . json ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( "" No success indicator in server response "" ) <TAB><TAB>  return out <TAB>  except Exception as e : <TAB><TAB>  logger . error ( "" Failed to post arrow to  %s "" , sub_path , exc_info = True ) <TAB><TAB>  raise e ","if not ( ""success"" in out ) or not out [ ""success"" ] :",if not out:,False,24.28240363948317,92.54403275865327
384,"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB>  """"""Return XML element converting dicts recursively."""""" <TAB>  elem = Element ( tag , * * kwargs ) <TAB>  for key , val in dictionary . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  child = dict_to_XML ( "" layer "" , val , name = key ) <TAB><TAB>  elif isinstance ( val , MutableMapping ) : <TAB><TAB><TAB>  child = dict_to_XML ( key , val ) <TAB><TAB>  else : <TAB><TAB><TAB>  if tag == "" config "" : <TAB><TAB><TAB><TAB>  child = Element ( "" variable "" , name = key ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  child = Element ( key ) <TAB><TAB><TAB>  child . text = str ( val ) <TAB><TAB>  elem . append ( child ) <TAB>  return elem ","if tag == ""layers"" :","if isinstance(val, Layer):",False,48.90181239638056,96.9417365644611
385,"def apply_incpaths_ml ( self ) : <TAB>  inc_lst = self . includes . split ( ) <TAB>  lst = self . incpaths_lst <TAB>  for dir in inc_lst : <TAB><TAB>  node = self . path . find_dir ( dir ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  error ( "" node not found:  "" + str ( dir ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if not node in lst : <TAB><TAB><TAB>  lst . append ( node ) <TAB><TAB>  self . bld_incpaths_lst . append ( node ) ",if not node :,if not node:,False,56.4316166273479,100.00000000000004
386,"def _table_reprfunc ( self , row , col , val ) : <TAB>  if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB><TAB>  if isinstance ( val , compat . string_types ) : <TAB><TAB><TAB>  return ""<TAB>%s "" % val <TAB><TAB>  elif val < 1024 * * 2 : <TAB><TAB><TAB>  return ""<TAB>%.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ""<TAB>%.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  return ""<TAB>%.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB>  if col in ( 0 , "" "" ) : <TAB><TAB>  return str ( val ) <TAB>  else : <TAB><TAB>  return ""<TAB>%s "" % val ",elif val < 1024 ** 3 :,if val < 1024 * * 2:,False,18.269944398514983,88.39100560015459
387,"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB>  """"""cache hidden states into memory."""""" <TAB>  if mem_len is None or mem_len == 0 : <TAB><TAB>  return None <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  curr_out = curr_out [ : reuse_len ] <TAB><TAB>  if prev_mem is None : <TAB><TAB><TAB>  new_mem = curr_out [ - mem_len : ] <TAB><TAB>  else : <TAB><TAB><TAB>  new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB>  new_mem . stop_gradient = True <TAB>  return new_mem ",if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None:,False,54.35142746561185,93.94819738367357
388,"def GROUP_CONCAT ( builder , distinct , expr , sep = None ) : <TAB>  assert distinct in ( None , True , False ) <TAB>  result = distinct and "" GROUP_CONCAT(DISTINCT  "" or "" GROUP_CONCAT( "" , builder ( expr ) <TAB>  if sep is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = result , ""  SEPARATOR  "" , builder ( sep ) <TAB><TAB>  else : <TAB><TAB><TAB>  result = result , "" ,  "" , builder ( sep ) <TAB>  return result , "" ) "" ","if builder . provider . dialect == ""MySQL"" :",if sep == '.':,False,46.591399686196965,92.4348689221955
389,"def __init__ ( self , * args , * * kwargs ) : <TAB>  super ( ) . __init__ ( * args , * * kwargs ) <TAB>  self . custom_fields = [ ] <TAB>  self . obj_type = ContentType . objects . get_for_model ( self . model ) <TAB>  # Add all applicable CustomFields to the form <TAB>  custom_fields = CustomField . objects . filter ( content_types = self . obj_type ) <TAB>  for cf in custom_fields : <TAB><TAB>  # Annotate non-required custom fields as nullable <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . nullable_fields . append ( cf . name ) <TAB><TAB>  self . fields [ cf . name ] = cf . to_form_field ( <TAB><TAB><TAB>  set_initial = False , enforce_required = False <TAB><TAB>  ) <TAB><TAB>  # Annotate this as a custom field <TAB><TAB>  self . custom_fields . append ( cf . name ) ",if not cf . required :,if not cf.nullable:,False,52.041570874026434,98.95720039677974
390,"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB>  if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB><TAB>  return None <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  if possible_child_hash not in self . items : <TAB><TAB><TAB>  return False <TAB><TAB>  possible_child_hash = self . items [ possible_child_hash ] . previous_hash ",if possible_child_hash == item_hash :,if self.items[possible_child_hash].hash == item_hash:,False,49.79380410646965,93.915861931286
391,"def validate ( self ) : <TAB>  self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB>  for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB><TAB>  self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . validate_unordered_batch ( batch_in , batch_out ) <TAB><TAB>  else : <TAB><TAB><TAB>  for in_data , out_data in zip ( batch_in , batch_out ) : <TAB><TAB><TAB><TAB>  self . assertEqual ( in_data . shape , out_data . shape ) <TAB><TAB><TAB><TAB>  if not self . use_parallel_executor : <TAB><TAB><TAB><TAB><TAB>  self . assertTrue ( ( in_data == out_data ) . all ( ) ) ",if self . use_parallel_executor and not self . use_double_buffer :,if self.use_unordered_batch:,False,24.11375867104095,94.48596430948638
392,"def add_cells ( self , cells ) : <TAB>  for cell in cells : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  id = len ( self . cell_id_map ) <TAB><TAB><TAB>  self . cell_id_map [ cell ] = id <TAB><TAB><TAB>  self . id_cell_map [ id ] = cell ",if cell not in self . cell_id_map :,if cell not in self.cell_id_map:,False,53.38865583856543,100.00000000000004
393,"def _verify_out ( marker = "" >> "" ) : <TAB>  if shared : <TAB><TAB>  self . assertIn ( "" libapp_lib.dylib "" , self . client . out ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIn ( "" libapp_lib.a "" , self . client . out ) <TAB><TAB>  else :<TAB># Incremental build not the same msg <TAB><TAB><TAB>  self . assertIn ( "" Built target app_lib "" , self . client . out ) <TAB>  out = str ( self . client . out ) . splitlines ( ) <TAB>  for k , v in vals . items ( ) : <TAB><TAB>  self . assertIn ( "" %s %s :  %s "" % ( marker , k , v ) , out ) ","if marker == "">>"" :",if shared:,False,51.27122058866234,94.91733317585435
394,"def Visit_expr ( self , node ) :<TAB># pylint: disable=invalid-name <TAB>  # expr ::= xor_expr ('|' xor_expr)* <TAB>  for child in node . children : <TAB><TAB>  self . Visit ( child ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _AppendTokenSubtype ( child , format_token . Subtype . BINARY_OPERATOR ) ","if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :","if isinstance(child, format_token.Subtype.BINARY_OPERATOR):",False,13.950249068428588,85.44774594037443
395,"def fill_members ( self ) : <TAB>  if self . _get_retrieve ( ) : <TAB><TAB>  after = self . after . id if self . after else None <TAB><TAB>  data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB><TAB>  if not data : <TAB><TAB><TAB>  # no data, terminate <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . limit = 0<TAB># terminate loop <TAB><TAB>  self . after = Object ( id = int ( data [ - 1 ] [ "" user "" ] [ "" id "" ] ) ) <TAB><TAB>  for element in reversed ( data ) : <TAB><TAB><TAB>  await self . members . put ( self . create_member ( element ) ) ",if len ( data ) < 1000 :,if len(data) == 0:,False,50.89353448861622,94.04032280502136
396,"def assert_warns ( expected ) : <TAB>  with warnings . catch_warnings ( record = True ) as w : <TAB><TAB>  warnings . simplefilter ( "" always "" ) <TAB><TAB>  yield <TAB>  # Python 2 does not raise warnings multiple times from the same stack <TAB>  # frame. <TAB>  if sys . version_info > = ( 3 , 0 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  exc_name = expected . __name__ <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  exc_name = str ( expected ) <TAB><TAB><TAB>  raise AssertionError ( "" %s  not triggerred "" % exc_name ) ","if not any ( isinstance ( m . message , expected ) for m in w ) :",if expected is not None:,False,60.40491270122281,91.20073836023383
397,"def __init__ ( self , measures ) : <TAB>  """"""Constructs a ContingencyMeasures given a NgramAssocMeasures class"""""" <TAB>  self . __class__ . __name__ = "" Contingency "" + measures . __class__ . __name__ <TAB>  for k in dir ( measures ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  v = getattr ( measures , k ) <TAB><TAB>  if not k . startswith ( "" _ "" ) : <TAB><TAB><TAB>  v = self . _make_contingency_fn ( measures , v ) <TAB><TAB>  setattr ( self , k , v ) ","if k . startswith ( ""__"" ) :",if k.startswith('_'):,False,49.77182516775302,96.85903563112639
398,"def _omit_keywords ( self , context ) : <TAB>  omitted_kws = 0 <TAB>  for event , elem in context : <TAB><TAB>  # Teardowns aren't omitted to allow checking suite teardown status. <TAB><TAB>  omit = elem . tag == "" kw "" and elem . get ( "" type "" ) != "" teardown "" <TAB><TAB>  start = event == "" start "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  omitted_kws + = 1 <TAB><TAB>  if not omitted_kws : <TAB><TAB><TAB>  yield event , elem <TAB><TAB>  elif not start : <TAB><TAB><TAB>  elem . clear ( ) <TAB><TAB>  if omit and not start : <TAB><TAB><TAB>  omitted_kws - = 1 ",if omit and start :,if omit and start:,False,59.01784976067768,100.00000000000004
399,"def read_block ( buffer , i ) : <TAB>  offset = i * BLOCK_LENGTH % config . CAPTURE_BUFFER <TAB>  while True : <TAB><TAB>  if buffer [ offset ] == BLOCK_MARKER . END : <TAB><TAB><TAB>  return None <TAB><TAB>  while buffer [ offset ] == BLOCK_MARKER . WRITE : <TAB><TAB><TAB>  time . sleep ( SHORT_SENSOR_SLEEP_TIME ) <TAB><TAB>  buffer [ offset ] = BLOCK_MARKER . READ <TAB><TAB>  buffer . seek ( offset + 1 ) <TAB><TAB>  length = struct . unpack ( "" =H "" , buffer . read ( 2 ) ) [ 0 ] <TAB><TAB>  retval = buffer . read ( length ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  buffer [ offset ] = BLOCK_MARKER . NOP <TAB>  return retval ",if buffer [ offset ] == BLOCK_MARKER . READ :,if retval == BLOCK_MARKER.EOF:,False,30.890330661041602,96.32775883357203
400,def _start ( self ) : <TAB>  try : <TAB><TAB>  instance_info = self . _get_instance_info ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _multipass_cmd . start ( instance_name = self . instance_name ) <TAB>  except errors . ProviderInfoError as instance_error : <TAB><TAB>  # Until we have proper multipass error codes to know if this <TAB><TAB>  # was a communication error we should keep this error tracking <TAB><TAB>  # and generation here. <TAB><TAB>  raise errors . ProviderInstanceNotFoundError ( <TAB><TAB><TAB>  instance_name = self . instance_name <TAB><TAB>  ) from instance_error ,if not instance_info . is_running ( ) :,if instance_info is not None:,False,64.01771014560403,94.52311577257224
401,"def _river_driver ( self ) : <TAB>  if self . _cached_river_driver : <TAB><TAB>  return self . _cached_river_driver <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _cached_river_driver = MsSqlDriver ( <TAB><TAB><TAB><TAB>  self . workflow , self . wokflow_object_class , self . field_name <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _cached_river_driver = OrmDriver ( <TAB><TAB><TAB><TAB>  self . workflow , self . wokflow_object_class , self . field_name <TAB><TAB><TAB>  ) <TAB><TAB>  return self . _cached_river_driver ",if app_config . IS_MSSQL :,if self.is_sql_driver:,False,49.98627992072816,96.04255223374746
402,"def __LazyMap__ ( self , attr ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  debug_attr_print ( <TAB><TAB><TAB><TAB>  "" %s .__LazyMap__( %s ) added something "" % ( self . _username_ , attr ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return 1 <TAB>  except AttributeError : <TAB><TAB>  return 0 ",if self . _LazyAddAttr_ ( attr ) :,if self._username_ in attr:,False,22.468373088895348,94.95793284310427
403,"def prepare ( self , data = None , user = None ) : <TAB>  """"""Prepare activation for execution."""""" <TAB>  super ( ManagedStartViewActivation , self ) . prepare . original ( ) <TAB>  self . task . owner = user <TAB>  management_form_class = self . get_management_form_class ( ) <TAB>  self . management_form = management_form_class ( data = data , instance = self . task ) <TAB>  if data : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise FlowRuntimeError ( <TAB><TAB><TAB><TAB>  "" Activation metadata is broken  {} "" . format ( self . management_form . errors ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . task = self . management_form . save ( commit = False ) ",if not self . management_form . is_valid ( ) :,if self.management_form.errors:,False,27.938112699736532,95.4170574734323
404,"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB>  while self : <TAB><TAB>  if self . __Token : <TAB><TAB><TAB>  x = 1 <TAB><TAB>  elif not IfList : <TAB><TAB><TAB>  if self < = 2 : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  RegionSizeGuid = 3 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  RegionLayoutLine = 5 <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  RegionLayoutLine = self . CurrentLineNumber <TAB>  return 1 ",if not RegionSizeGuid :,if self.CurrentLineNumber == 0:,False,24.065817833213636,95.10537257851983
405,"def _get_completion ( self , document ) : <TAB>  try : <TAB><TAB>  completion_header = document . xpath ( "" //div[@id= ' complete_day ' ] "" ) [ 0 ] <TAB><TAB>  completion_message = completion_header . getchildren ( ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  elif "" day_complete_message "" in completion_message . classes : <TAB><TAB><TAB>  return True <TAB>  except IndexError : <TAB><TAB>  return False<TAB># Who knows, probably not my diary. ","if ""day_incomplete_message"" in completion_message . classes :","if ""day_complete_message"" in completion_message.classes:",False,57.289350923834824,91.53868999158016
406,"def run ( self ) : <TAB>  DISPATCH_SYNC = components . interfaces . nsIEventTarget . DISPATCH_SYNC <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  for match in findlib2 . find_all_matches ( self . regex , self . text ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  self . target . dispatch ( lambda : self . callback ( match ) , DISPATCH_SYNC ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB>  self . target . dispatch ( lambda : self . callback ( None ) , DISPATCH_SYNC ) <TAB>  finally : <TAB><TAB>  self . callback = None <TAB><TAB>  self . target = None ",if self . _stopped :,if not self.target:,False,18.96424782668697,91.4901884715261
407,"def to_key ( literal_or_identifier ) : <TAB>  """"""returns string representation of this object"""""" <TAB>  if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB>  return literal_or_identifier [ "" name "" ] <TAB>  elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB>  k = literal_or_identifier [ "" value "" ] <TAB><TAB>  if isinstance ( k , float ) : <TAB><TAB><TAB>  return unicode ( float_repr ( k ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return compose_regex ( k ) <TAB><TAB>  elif isinstance ( k , bool ) : <TAB><TAB><TAB>  return "" true "" if k else "" false "" <TAB><TAB>  elif k is None : <TAB><TAB><TAB>  return "" null "" <TAB><TAB>  else : <TAB><TAB><TAB>  return unicode ( k ) ","elif ""regex"" in literal_or_identifier :","if isinstance(k, basestring):",False,27.71222331115038,95.31235798358198
408,"def process_image_pre_creation ( sender , instance : Image , * * kwargs ) : <TAB>  # FIXME(winkidney): May have issue on determining if it <TAB>  #  is created or not <TAB>  if instance . pk is not None : <TAB><TAB>  return <TAB>  for plugin in _plugin_instances : <TAB><TAB>  process_fn = getattr ( plugin , "" process_image_pre_creation "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  process_fn ( <TAB><TAB><TAB><TAB>  django_settings = settings , <TAB><TAB><TAB><TAB>  image_instance = instance , <TAB><TAB><TAB>  ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  logging . exception ( <TAB><TAB><TAB><TAB>  "" Error occurs while trying to access plugin ' s pin_pre_save  "" <TAB><TAB><TAB><TAB>  "" for plugin  %s "" % plugin <TAB><TAB><TAB>  ) ",if process_fn is None :,if process_fn is None:,False,20.907870601989192,98.31506205930559
409,"def check_screenshots ( self ) : <TAB>  # If we arrive here, there have not been any failures yet <TAB>  if self . interactive : <TAB><TAB>  self . _commit_screenshots ( ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _validate_screenshots ( ) <TAB><TAB><TAB>  # Always commit the screenshots here. They can be used for the next test run. <TAB><TAB><TAB>  # If reference screenshots were already present and there was a mismatch, it should <TAB><TAB><TAB>  # have failed above. <TAB><TAB><TAB>  self . _commit_screenshots ( ) <TAB><TAB>  elif self . allow_missing_screenshots : <TAB><TAB><TAB>  warnings . warn ( "" No committed reference screenshots available. Ignoring. "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . fail ( <TAB><TAB><TAB><TAB>  "" No committed reference screenshots available. Run interactive first. "" <TAB><TAB><TAB>  ) ",if self . _has_reference_screenshots ( ) :,if self.allow_missing_screenshots:,False,49.57902471960844,96.71660026586692
410,"def on_task_abort ( self , task , config ) : <TAB>  if "" abort "" in config : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  log . debug ( "" sending abort notification "" ) <TAB><TAB>  self . send_notification ( <TAB><TAB><TAB>  config [ "" abort "" ] [ "" title "" ] , <TAB><TAB><TAB>  config [ "" abort "" ] [ "" message "" ] , <TAB><TAB><TAB>  config [ "" abort "" ] [ "" via "" ] , <TAB><TAB><TAB>  template_renderer = task . render , <TAB><TAB>  ) ",if task . silent_abort :,if not config['abort']['enabled']:,False,45.34691920177902,94.18187437492526
411,"def block_users ( self , user_ids ) : <TAB>  broken_items = [ ] <TAB>  self . logger . info ( "" Going to block  %d  users. "" % len ( user_ids ) ) <TAB>  for user_id in tqdm ( user_ids ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . error_delay ( ) <TAB><TAB><TAB>  broken_items = user_ids [ user_ids . index ( user_id ) : ] <TAB><TAB><TAB>  break <TAB>  self . logger . info ( "" DONE: Total blocked  %d  users. "" % self . total [ "" blocks "" ] ) <TAB>  return broken_items ",if not self . block ( user_id ) :,if user_id in user_ids:,False,35.922105788357406,94.64332917033451
412,"def find_widget_by_id ( self , id , parent = None ) : <TAB>  """"""Recursively searches for widget with specified ID"""""" <TAB>  if parent == None : <TAB><TAB>  if id in self : <TAB><TAB><TAB>  return self [ id ]<TAB># Do things fast if possible <TAB><TAB>  parent = self [ "" editor "" ] <TAB>  for c in parent . get_children ( ) : <TAB><TAB>  if hasattr ( c , "" get_id "" ) : <TAB><TAB><TAB>  if c . get_id ( ) == id : <TAB><TAB><TAB><TAB>  return c <TAB><TAB>  if isinstance ( c , Gtk . Container ) : <TAB><TAB><TAB>  r = self . find_widget_by_id ( id , c ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return r <TAB>  return None ",if not r is None :,if r is not None:,False,39.27839521709564,96.52589783408432
413,"def addClasses ( self , name ) : <TAB>  # Result: void - None <TAB>  # In: name: string <TAB>  for n in name . split ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  k , method = n . split ( "" . "" ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  k = n <TAB><TAB><TAB>  method = None <TAB><TAB>  self . classes [ k ] = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . methods . setdefault ( k , { } ) [ method ] = 1 ",if method is not None :,if method is not None:,False,27.804432806529267,100.00000000000004
414,"def Read ( self , lex_mode ) : <TAB>  while True : <TAB><TAB>  t = self . _Read ( lex_mode ) <TAB><TAB>  self . was_line_cont = t . id == Id . Ignored_LineCont <TAB><TAB>  # TODO: Change to ALL IGNORED types, once you have SPACE_TOK.  This means <TAB><TAB>  # we don't have to handle them in the VS_1/VS_2/etc. states. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  # log('Read() Returning %s', t) <TAB>  return t ",if t . id != Id . Ignored_LineCont :,if self.was_line_cont:,False,69.3098578499277,92.86322511716506
415,"def _dir_guildfile ( dir , ctx ) : <TAB>  from guild import guildfile <TAB>  try : <TAB><TAB>  return guildfile . for_dir ( dir ) <TAB>  except guildfile . NoModels : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  help_suffix = ""  or  ' %s '  for help "" % click_util . cmd_help ( ctx ) <TAB><TAB>  else : <TAB><TAB><TAB>  help_suffix = "" "" <TAB><TAB>  cli . error ( <TAB><TAB><TAB>  "" %s  does not contain a Guild file (guild.yml) \n "" <TAB><TAB><TAB>  "" Try specifying a project path or package name %s . "" <TAB><TAB><TAB>  % ( cwd_desc ( dir ) , help_suffix ) <TAB><TAB>  ) <TAB>  except guildfile . GuildfileError as e : <TAB><TAB>  cli . error ( str ( e ) ) ",if ctx :,if ctx:,False,60.54227896320339,98.41594060321069
416,"def check_response ( self , response ) : <TAB>  """"""Specialized version of check_response()."""""" <TAB>  for line in response : <TAB><TAB>  # Skip blank lines: <TAB><TAB>  if not line . strip ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  elif line . startswith ( b "" Benutzer/Passwort Fehler "" ) : <TAB><TAB><TAB>  raise BadLogin ( line ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise FailedPost ( "" Server returned  ' %s ' "" % six . ensure_text ( line ) ) ","if line . startswith ( b""OK"" ) :","if line.startswith(b""Benutzer/Passwort""):",False,51.17766464342165,95.28965942163973
417,"def ParseResponses ( <TAB>  self , <TAB>  knowledge_base : rdf_client . KnowledgeBase , <TAB>  responses : Iterable [ rdfvalue . RDFValue ] ,  ) - > Iterator [ rdf_client . User ] : <TAB>  for response in responses : <TAB><TAB>  if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB><TAB><TAB>  raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB><TAB>  # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  homedir = response . pathspec . path <TAB><TAB><TAB>  username = os . path . basename ( homedir ) <TAB><TAB><TAB>  if username not in self . _ignore_users : <TAB><TAB><TAB><TAB>  yield rdf_client . User ( username = username , homedir = homedir ) ",if stat . S_ISDIR ( int ( response . st_mode ) ) :,if response.st_mode == 'int':,False,47.30106920938918,94.37354355798219
418,"def __call__ ( self , x , uttid = None ) : <TAB>  if self . utt2spk is not None : <TAB><TAB>  spk = self . utt2spk [ uttid ] <TAB>  else : <TAB><TAB>  spk = uttid <TAB>  if not self . reverse : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = np . add ( x , self . bias [ spk ] ) <TAB><TAB>  if self . norm_vars : <TAB><TAB><TAB>  x = np . multiply ( x , self . scale [ spk ] ) <TAB>  else : <TAB><TAB>  if self . norm_vars : <TAB><TAB><TAB>  x = np . divide ( x , self . scale [ spk ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = np . subtract ( x , self . bias [ spk ] ) <TAB>  return x ",if self . norm_means :,if self.norm_vars:,False,27.64622727009466,95.45401357651029
419,"def hasFixtures ( self , ctx_callback = None ) : <TAB>  context = self . context <TAB>  if context is None : <TAB><TAB>  return False <TAB>  if self . implementsAnyFixture ( context , ctx_callback = ctx_callback ) : <TAB><TAB>  return True <TAB>  # My context doesn't have any, but its ancestors might <TAB>  factory = self . factory <TAB>  if factory : <TAB><TAB>  ancestors = factory . context . get ( self , [ ] ) <TAB><TAB>  for ancestor in ancestors : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :",if ancestor.is_fixture(context):,False,59.08998168609565,91.68525994326555
420,def UpdateControlState ( self ) : <TAB>  active = self . demoModules . GetActiveID ( ) <TAB>  # Update the radio/restore buttons <TAB>  for moduleID in self . radioButtons : <TAB><TAB>  btn = self . radioButtons [ moduleID ] <TAB><TAB>  if moduleID == active : <TAB><TAB><TAB>  btn . SetValue ( True ) <TAB><TAB>  else : <TAB><TAB><TAB>  btn . SetValue ( False ) <TAB><TAB>  if self . demoModules . Exists ( moduleID ) : <TAB><TAB><TAB>  btn . Enable ( True ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . btnRestore . Enable ( True ) <TAB><TAB>  else : <TAB><TAB><TAB>  btn . Enable ( False ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . btnRestore . Enable ( False ) ,if moduleID == modModified :,if self.btnRestore.Enabled():,False,52.149307303512636,94.22445110013001
421,"def ignore_proxy_host ( self ) : <TAB>  """"""Check if self.host is in the $no_proxy ignore list."""""" <TAB>  if urllib . proxy_bypass ( self . host ) : <TAB><TAB>  return True <TAB>  no_proxy = os . environ . get ( "" no_proxy "" ) <TAB>  if no_proxy : <TAB><TAB>  entries = [ parse_host_port ( x ) for x in no_proxy . split ( "" , "" ) ] <TAB><TAB>  for host , port in entries : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if host . lower ( ) == self . host and port == self . port :,if host == self.host and port == self.port:,False,59.30225710143087,96.81699921487841
422,"def run ( self , _ ) : <TAB>  view = self . view <TAB>  if not view . settings ( ) . get ( "" terminus_view "" ) : <TAB><TAB>  return <TAB>  terminal = Terminal . from_id ( view . id ( ) ) <TAB>  if terminal : <TAB><TAB>  terminal . close ( ) <TAB><TAB>  panel_name = terminal . panel_name <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  window = panel_window ( view ) <TAB><TAB><TAB>  if window : <TAB><TAB><TAB><TAB>  window . destroy_output_panel ( panel_name ) <TAB><TAB>  else : <TAB><TAB><TAB>  view . close ( ) ",if panel_name :,if panel_name:,False,50.615247996633016,100.00000000000004
423,"def get_docname_for_node ( self , node : Node ) - > str : <TAB>  while node : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . env . path2doc ( node [ "" source "" ] ) <TAB><TAB>  elif isinstance ( node , addnodes . start_of_file ) : <TAB><TAB><TAB>  return node [ "" docname "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  node = node . parent <TAB>  return None<TAB># never reached here. only for type hinting ","if isinstance ( node , nodes . document ) :","if isinstance(node, addnodes.path2doc):",False,42.26669152379962,93.60090517806464
424,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  self . add_version ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 0:,False,51.452429171598,100.00000000000004
425,"def _maybe_female ( self , path_elements , female , strict ) : <TAB>  if female : <TAB><TAB>  if self . has_gender_differences : <TAB><TAB><TAB>  elements = path_elements + [ "" female "" ] <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise <TAB><TAB>  el<IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB>  return self . _get_file ( path_elements , "" .png "" , strict = strict ) ",if strict :,if self.species_id not in path_elements:,False,51.335256085759674,92.02532238038697
426,"def OnKeyUp ( self , event ) : <TAB>  if self . _properties . modifiable : <TAB><TAB>  if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB><TAB><TAB>  self . _cancel_editing ( ) <TAB><TAB>  elif event . GetKeyCode ( ) == wx . WXK_RETURN : <TAB><TAB><TAB>  self . _update_value ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . SetValue ( "" "" ) <TAB>  if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB><TAB>  # Don't send skip event if enter key is pressed <TAB><TAB>  # On some platforms this event is sent too late and causes crash <TAB><TAB>  event . Skip ( ) ",elif event . GetKeyCode ( ) == wx . WXK_DELETE :,if self._properties.editing:,False,65.23663607102858,92.74367602827843
427,"def sync_up_to_new_location ( self , worker_ip ) : <TAB>  if worker_ip != self . worker_ip : <TAB><TAB>  logger . debug ( "" Setting new worker IP to  %s "" , worker_ip ) <TAB><TAB>  self . set_worker_ip ( worker_ip ) <TAB><TAB>  self . reset ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( "" Sync up to new location skipped. This should not occur. "" ) <TAB>  else : <TAB><TAB>  logger . warning ( "" Sync attempted to same IP  %s . "" , worker_ip ) ",if not self . sync_up ( ) :,if self.is_new_location_changed():,False,34.22015382703116,94.09659213447998
428,"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB>  links = { <TAB><TAB>  "" torrent "" : "" "" , <TAB><TAB>  "" magnet "" : "" "" , <TAB>  } <TAB>  try : <TAB><TAB>  data = self . session . get ( url ) . text <TAB><TAB>  with bs4_parser ( data ) as html : <TAB><TAB><TAB>  downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for download in downloads . findAll ( "" a "" ) : <TAB><TAB><TAB><TAB><TAB>  link = download [ "" href "" ] <TAB><TAB><TAB><TAB><TAB>  if link . startswith ( "" magnet "" ) : <TAB><TAB><TAB><TAB><TAB><TAB>  links [ "" magnet "" ] = link <TAB><TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB><TAB>  links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB>  except Exception : <TAB><TAB>  pass <TAB>  return links [ download_type ] ",if downloads :,if downloads:,False,50.62224337203609,100.00000000000004
429,"def force_ipv4 ( self , * args ) : <TAB>  """"""only ipv4 localhost in /etc/hosts"""""" <TAB>  logg . debug ( "" checking /etc/hosts for  ' ::1 localhost ' "" ) <TAB>  lines = [ ] <TAB>  for line in open ( self . etc_hosts ( ) ) : <TAB><TAB>  if "" ::1 "" in line : <TAB><TAB><TAB>  newline = re . sub ( "" \\ slocalhost \\ s "" , "" "" , line ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  logg . info ( "" /etc/hosts:  ' %s '  =>  ' %s ' "" , line . rstrip ( ) , newline . rstrip ( ) ) <TAB><TAB><TAB><TAB>  line = newline <TAB><TAB>  lines . append ( line ) <TAB>  f = open ( self . etc_hosts ( ) , "" w "" ) <TAB>  for line in lines : <TAB><TAB>  f . write ( line ) <TAB>  f . close ( ) ",if line != newline :,if newline:,False,47.32701932359713,95.14539409029355
430,"def prepare ( self ) : <TAB>  # Maybe the brok is a old daemon one or was already prepared <TAB>  # if so, the data is already ok <TAB>  if hasattr ( self , "" prepared "" ) and not self . prepared : <TAB><TAB>  self . data = SafeUnpickler . loads ( self . data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . data [ "" instance_id "" ] = self . instance_id <TAB>  self . prepared = True ","if hasattr ( self , ""instance_id"" ) :",if self.instance_id:,False,42.4754729078658,91.76014635606268
431,"def _test_compute_q0 ( self ) : <TAB>  # Stub code to search a logq space and figure out logq0 by eyeballing <TAB>  # results. This code does not run with the tests. Remove underscore to run. <TAB>  sigma = 15 <TAB>  order = 250 <TAB>  logqs = np . arange ( - 290 , - 270 , 1 ) <TAB>  count = 0 <TAB>  for logq in logqs : <TAB><TAB>  count + = 1 <TAB><TAB>  sys . stdout . write ( <TAB><TAB><TAB>  "" \t %0.5g :  %0.10g "" % ( logq , pate . rdp_gaussian ( logq , sigma , order ) ) <TAB><TAB>  ) <TAB><TAB>  sys . stdout . flush ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" "" ) ",if count % 5 == 0 :,if count == 0:,False,41.08459671916369,95.95643979720668
432,"def valid_fieldnames ( fieldnames ) : <TAB>  """"""check if fieldnames are valid"""""" <TAB>  for fieldname in fieldnames : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  elif fieldname in fieldname_map and fieldname_map [ fieldname ] == "" source "" : <TAB><TAB><TAB>  return True <TAB>  return False ","if fieldname in canonical_field_names and fieldname == ""source"" :",if fieldname in fieldname_map and fieldname in fieldname_map:,False,28.53427323873621,87.97878096116915
433,"def ns_provide ( self , id_ ) : <TAB>  global controllers , layouts <TAB>  if id_ == "" _leo_viewrendered "" : <TAB><TAB>  c = self . c <TAB><TAB>  vr = controllers . get ( c . hash ( ) ) or ViewRenderedController ( c ) <TAB><TAB>  h = c . hash ( ) <TAB><TAB>  controllers [ h ] = vr <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  layouts [ h ] = c . db . get ( "" viewrendered_default_layouts "" , ( None , None ) ) <TAB><TAB>  # return ViewRenderedController(self.c) <TAB><TAB>  return vr ",if not layouts . get ( h ) :,if h not in layouts:,False,48.24935343926347,95.18131265850306
434,"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB>  if not path : <TAB><TAB>  if error_on_path : <TAB><TAB><TAB>  raise NoSuchSettingsPath ( ) <TAB><TAB>  return <TAB>  if config is not None or defaults is not None : <TAB><TAB>  if config is None : <TAB><TAB><TAB>  config = self . _config <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  defaults = dict ( self . _map . parents ) <TAB><TAB>  chain = HierarchicalChainMap ( config , defaults ) <TAB>  else : <TAB><TAB>  chain = self . _map <TAB>  try : <TAB><TAB>  chain . del_by_path ( path ) <TAB><TAB>  self . _mark_dirty ( ) <TAB>  except KeyError : <TAB><TAB>  if error_on_path : <TAB><TAB><TAB>  raise NoSuchSettingsPath ( ) <TAB><TAB>  pass ",if defaults is None :,if defaults is None:,False,58.252497956515704,100.00000000000004
435,"def _mongo_query_and ( self , queries ) : <TAB>  if len ( queries ) == 1 : <TAB><TAB>  return queries [ 0 ] <TAB>  query = { } <TAB>  for q in queries : <TAB><TAB>  for k , v in q . items ( ) : <TAB><TAB><TAB>  if k not in query : <TAB><TAB><TAB><TAB>  query [ k ] = { } <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # TODO check exists of k in query, may be it should be update <TAB><TAB><TAB><TAB>  query [ k ] = v <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  query [ k ] . update ( v ) <TAB>  return query ","if isinstance ( v , list ) :",if k not in query:,False,60.16114712094367,96.23806077027889
436,"def write ( self , data ) : <TAB>  self . size - = len ( data ) <TAB>  passon = None <TAB>  if self . size > 0 : <TAB><TAB>  self . data . append ( data ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data , passon = data [ : self . size ] , data [ self . size : ] <TAB><TAB>  else : <TAB><TAB><TAB>  passon = b "" "" <TAB><TAB>  if data : <TAB><TAB><TAB>  self . data . append ( data ) <TAB>  return passon ",if self . size :,if self.size > 0:,False,21.557598832810985,97.61815118639947
437,"def updateVar ( name , data , mode = None ) : <TAB>  if mode : <TAB><TAB>  if mode == "" append "" : <TAB><TAB><TAB>  core . config . globalVariables [ name ] . append ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  core . config . globalVariables [ name ] . add ( data ) <TAB>  else : <TAB><TAB>  core . config . globalVariables [ name ] = data ","elif mode == ""add"" :","if mode == ""add':",False,47.464763727457125,94.4837875694948
438,"def vi_pos_back_short ( line , index = 0 , count = 1 ) : <TAB>  line = vi_list ( line ) <TAB>  try : <TAB><TAB>  for i in range ( count ) : <TAB><TAB><TAB>  index - = 1 <TAB><TAB><TAB>  while vi_is_space ( line [ index ] ) : <TAB><TAB><TAB><TAB>  index - = 1 <TAB><TAB><TAB>  in_word = vi_is_word ( line [ index ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  while vi_is_word ( line [ index ] ) : <TAB><TAB><TAB><TAB><TAB>  index - = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  while not vi_is_word_or_space ( line [ index ] ) : <TAB><TAB><TAB><TAB><TAB>  index - = 1 <TAB><TAB>  return index + 1 <TAB>  except IndexError : <TAB><TAB>  return 0 ",if in_word :,if in_word:,False,36.930195353795746,100.00000000000004
439,"def _truncate_to_length ( generator , len_map = None ) : <TAB>  for example in generator : <TAB><TAB>  example = list ( example ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for key , max_len in len_map . items ( ) : <TAB><TAB><TAB><TAB>  example_len = example [ key ] . shape <TAB><TAB><TAB><TAB>  if example_len > max_len : <TAB><TAB><TAB><TAB><TAB>  example [ key ] = np . resize ( example [ key ] , max_len ) <TAB><TAB>  yield tuple ( example ) ",if len_map is not None :,if len_map is not None:,False,52.368303312702366,100.00000000000004
440,"def decorate ( f ) : <TAB>  # call-signature of f is exposed via __wrapped__. <TAB>  # we want it to mimic Obj.__init__ <TAB>  f . __wrapped__ = Obj . __init__ <TAB>  f . _uses_signature = Obj <TAB>  # Supplement the docstring of f with information from Obj <TAB>  if Obj . __doc__ : <TAB><TAB>  doclines = Obj . __doc__ . splitlines ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  doc = f . __doc__ + "" \n "" . join ( doclines [ 1 : ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  doc = "" \n "" . join ( doclines ) <TAB><TAB>  try : <TAB><TAB><TAB>  f . __doc__ = doc <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  # __doc__ is not modifiable for classes in Python < 3.3 <TAB><TAB><TAB>  pass <TAB>  return f ",if f . __doc__ :,if doclines[0] == '\n':,False,41.27375113814624,95.96633474985981
441,"def IncrementErrorCount ( self , category ) : <TAB>  """"""Bumps the module's error statistic."""""" <TAB>  self . error_count + = 1 <TAB>  if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB><TAB>  if self . counting != "" detailed "" : <TAB><TAB><TAB>  category = category . split ( "" / "" ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . errors_by_category [ category ] = 0 <TAB><TAB>  self . errors_by_category [ category ] + = 1 ",if category not in self . errors_by_category :,if category not in self.errors_by_category:,False,21.03583252848083,100.00000000000004
442,"def _delete_fields ( self , data ) : <TAB>  data = self . _del ( <TAB><TAB>  data , [ "" speaker_ids "" , "" track_id "" , "" microlocation_id "" , "" session_type_id "" ] <TAB>  ) <TAB>  # convert datetime fields <TAB>  for _ in [ "" start_time_tz "" , "" end_time_tz "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data [ _ ] = SESSION_POST [ _ [ 0 : - 3 ] ] . from_str ( data [ _ ] ) <TAB><TAB><TAB>  data [ _ [ 0 : - 3 ] ] = data . pop ( _ ) <TAB>  return data ",if _ in data :,if _ in SESSION_POST:,False,51.097520254488174,93.18000935695781
443,"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB>  count = 0 <TAB>  letters = "" "" <TAB>  strings = [ ] <TAB>  for char in word : <TAB><TAB>  if char in char_set : <TAB><TAB><TAB>  letters + = char <TAB><TAB><TAB>  count + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  strings . append ( letters ) <TAB><TAB><TAB>  letters = "" "" <TAB><TAB><TAB>  count = 0 <TAB>  <IF-STMT>: <TAB><TAB>  strings . append ( letters ) <TAB>  return strings ",if count > threshold :,if count < threshold:,False,22.456719945597527,95.56591576051645
444,"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB>  """"""Check if the function argument list has a dictionary as an arg."""""" <TAB>  if _IsArgumentToFunction ( token ) : <TAB><TAB>  while token : <TAB><TAB><TAB>  if token . value == "" { "" : <TAB><TAB><TAB><TAB>  length = token . matching_bracket . total_length - token . total_length <TAB><TAB><TAB><TAB>  return length + self . stack [ - 2 ] . indent > self . column_limit <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  if token . OpensScope ( ) : <TAB><TAB><TAB><TAB>  token = token . matching_bracket <TAB><TAB><TAB>  token = token . next_token <TAB>  return False ",if token . ClosesScope ( ) :,if length == 0:,False,54.18832483274464,95.7125519355891
445,"def check_apns_certificate ( ss ) : <TAB>  mode = "" start "" <TAB>  for s in ss . split ( "" \n "" ) : <TAB><TAB>  if mode == "" start "" : <TAB><TAB><TAB>  if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB>  mode = "" key "" <TAB><TAB>  elif mode == "" key "" : <TAB><TAB><TAB>  if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB>  mode = "" end "" <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB>  "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB>  ) <TAB>  if mode != "" end "" : <TAB><TAB>  raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :","if mode not in (""start"", ""key""):",False,43.57304317383137,93.75886325651359
446,"def main ( self ) : <TAB>  self . model . clear ( ) <TAB>  self . callman . unregister_all ( ) <TAB>  active_handle = self . get_active ( "" Person "" ) <TAB>  if active_handle : <TAB><TAB>  active = self . dbstate . db . get_person_from_handle ( active_handle ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . callman . register_obj ( active ) <TAB><TAB><TAB>  self . display_citations ( active ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . set_has_data ( False ) <TAB>  else : <TAB><TAB>  self . set_has_data ( False ) ",if active :,if active:,False,51.087493251915774,100.00000000000004
447,"def _validate ( self ) - > None : <TAB>  # Paren validation and such <TAB>  super ( Tuple , self ) . _validate ( ) <TAB>  if len ( self . elements ) == 0 : <TAB><TAB>  <IF-STMT>:<TAB># assumes len(lpar) == len(rpar), via superclass <TAB><TAB><TAB>  raise CSTValidationError ( <TAB><TAB><TAB><TAB>  "" A zero-length tuple must be wrapped in parentheses. "" <TAB><TAB><TAB>  ) ",if len ( self . lpar ) == 0 :,if len(self.elements) == 0:,False,22.761479884631992,94.34284474672504
448,"def _session_from_arg ( self , session_obj , lock_type = None ) : <TAB>  if not isinstance ( session_obj , self . ISession ) : <TAB><TAB>  vm = self . _machine_from_arg ( session_obj ) <TAB><TAB>  lock_type = lock_type or self . LockType . null <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return vm . create_session ( lock_type ) <TAB><TAB>  return None <TAB>  return session_obj ",if vm :,if vm:,False,52.44055017601661,100.00000000000004
449,"def _decorator ( cls ) : <TAB>  for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB><TAB>  if name not in cls . __dict__ : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not private and name . startswith ( "" _ "" ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  if name in butnot : <TAB><TAB><TAB>  continue <TAB><TAB>  setattr ( cls , name , decorator ( meth ) ) <TAB>  return cls ","if name != ""__init__"" :","if name in (type(meth) , type(self.class)):",False,25.94284342092631,89.8928609703994
450,"def pdb ( message = "" "" ) : <TAB>  """"""Fall into pdb."""""" <TAB>  import pdb<TAB># Required: we have just defined pdb as a function! <TAB>  if app and not app . useIpython : <TAB><TAB>  # from leo.core.leoQt import QtCore <TAB><TAB>  # This is more portable. <TAB><TAB>  try : <TAB><TAB><TAB>  import PyQt5 . QtCore as QtCore <TAB><TAB>  except ImportError : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  import PyQt4 . QtCore as QtCore <TAB><TAB><TAB>  except ImportError : <TAB><TAB><TAB><TAB>  QtCore = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # pylint: disable=no-member <TAB><TAB><TAB>  QtCore . pyqtRemoveInputHook ( ) <TAB>  if message : <TAB><TAB>  print ( message ) <TAB>  pdb . set_trace ( ) ",if QtCore :,if sys.platform == 'win32':,False,48.6517740055815,94.89483968409239
451,"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB>  """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB>  for b in buckets : <TAB><TAB>  if b . get ( "" Logging "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB><TAB>  if not self_log and b [ "" Name "" ] . startswith ( "" cf-templates- "" ) : <TAB><TAB><TAB>  yield ( b [ "" Name "" ] , "" "" ) ",if self_log :,if b['Logging']['TargetPrefix']:,False,57.02499081920408,95.97660525319591
452,"def prepare_fields ( self ) : <TAB>  # See clean() <TAB>  for k , v in self . fields . items ( ) : <TAB><TAB>  v . _required = v . required <TAB><TAB>  v . required = False <TAB><TAB>  v . widget . is_required = False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v . _required = v . one_required <TAB><TAB><TAB>  v . one_required = False <TAB><TAB><TAB>  v . widget . enabled_locales = self . locales ","if isinstance ( v , I18nFormField ) :",if v.one_required:,False,25.932815161711375,94.79275881580503
453,"def __pack__ ( self ) : <TAB>  new_values = [ ] <TAB>  for i in xrange ( len ( self . __unpacked_data_elms__ ) ) : <TAB><TAB>  for key in self . __keys__ [ i ] : <TAB><TAB><TAB>  new_val = getattr ( self , key ) <TAB><TAB><TAB>  old_val = self . __unpacked_data_elms__ [ i ] <TAB><TAB><TAB>  # In the case of Unions, when the first changed value <TAB><TAB><TAB>  # is picked the loop is exited <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  new_values . append ( new_val ) <TAB>  return struct . pack ( self . __format__ , * new_values ) ",if new_val != old_val :,if new_val == old_val:,False,62.8005403442336,98.82484493883118
454,"def run ( self ) : <TAB>  pwd_found = [ ] <TAB>  if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB><TAB>  main_vault_directory = os . path . join ( <TAB><TAB><TAB>  constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for vault_directory in os . listdir ( main_vault_directory ) : <TAB><TAB><TAB><TAB>  cred = constant . user_dpapi . decrypt_vault ( <TAB><TAB><TAB><TAB><TAB>  os . path . join ( main_vault_directory , vault_directory ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  if cred : <TAB><TAB><TAB><TAB><TAB>  pwd_found . append ( cred ) <TAB>  return pwd_found ",if os . path . exists ( main_vault_directory ) :,if os.path.exists(main_vault_directory):,False,23.498841887755972,100.00000000000004
455,"def on_revision_plugin_revision_pre_save ( * * kwargs ) : <TAB>  instance = kwargs [ "" instance "" ] <TAB>  if kwargs . get ( "" created "" , False ) : <TAB><TAB>  update_previous_revision = ( <TAB><TAB><TAB>  not instance . previous_revision <TAB><TAB><TAB>  and instance . plugin <TAB><TAB><TAB>  and instance . plugin . current_revision <TAB><TAB><TAB>  and instance . plugin . current_revision != instance <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  instance . previous_revision = instance . plugin . current_revision <TAB>  if not instance . revision_number : <TAB><TAB>  try : <TAB><TAB><TAB>  previous_revision = instance . plugin . revision_set . latest ( ) <TAB><TAB><TAB>  instance . revision_number = previous_revision . revision_number + 1 <TAB><TAB>  except RevisionPluginRevision . DoesNotExist : <TAB><TAB><TAB>  instance . revision_number = 1 ",if update_previous_revision :,if update_previous_revision:,False,49.62102274712235,100.00000000000004
456,"def __setattr__ ( self , name , value ) : <TAB>  super ( ) . __setattr__ ( name , value ) <TAB>  field = self . _fields . get ( name ) <TAB>  if field : <TAB><TAB>  self . check_field_type ( field , value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( f "" cannot set immutable  { name }  on  { self !r} "" ) ",if name in self . __ast_frozen_fields__ :,if not self._immutable:,False,15.412363505508225,88.6584987078526
457,"def _check_for_req_data ( data ) : <TAB>  required_args = [ "" columns "" ] <TAB>  for arg in required_args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True , make_json_response ( <TAB><TAB><TAB><TAB>  status = 400 , <TAB><TAB><TAB><TAB>  success = 0 , <TAB><TAB><TAB><TAB>  errormsg = gettext ( "" Could not find required parameter ( {} ). "" ) . format ( arg ) , <TAB><TAB><TAB>  ) <TAB>  return False , "" "" ","if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :",if arg in data:,False,48.86632397481028,84.0824348521301
458,"def train_dict ( self , triples ) : <TAB>  """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB>  # accumulate counter <TAB>  ctr = Counter ( ) <TAB>  ctr . update ( [ ( p [ 0 ] , p [ 1 ] , p [ 2 ] ) for p in triples ] ) <TAB>  # find the most frequent mappings <TAB>  for p , _ in ctr . most_common ( ) : <TAB><TAB>  w , pos , l = p <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . composite_dict [ ( w , pos ) ] = l <TAB><TAB>  if w not in self . word_dict : <TAB><TAB><TAB>  self . word_dict [ w ] = l <TAB>  return ","if ( w , pos ) not in self . composite_dict :",if w not in self.composite_dict:,False,60.03147870623593,96.80698463816965
459,"def render ( type_ , obj , context ) : <TAB>  if type_ == "" foreign_key "" : <TAB><TAB>  return None <TAB>  if type_ == "" column "" : <TAB><TAB>  if obj . name == "" y "" : <TAB><TAB><TAB>  return None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  return "" col( %s ) "" % obj . name <TAB>  if type_ == "" type "" and isinstance ( obj , MySpecialType ) : <TAB><TAB>  context . imports . add ( "" from mypackage import MySpecialType "" ) <TAB><TAB>  return "" MySpecialType() "" <TAB>  return "" render: %s "" % type_ ","elif obj . name == ""q"" :","if obj.name == ""y':",False,18.013689341640113,96.82199422808971
460,"def test_knows_when_stepping_back_possible ( self ) : <TAB>  iterator = bidirectional_iterator . BidirectionalIterator ( [ 0 , 1 , 2 , 3 ] ) <TAB>  commands = [ 0 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 0 ] <TAB>  command_count = 0 <TAB>  results = [ ] <TAB>  for _ in iterator : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  iterator . step_back_on_next_iteration ( ) <TAB><TAB>  results . append ( iterator . can_step_back ( ) ) <TAB><TAB>  command_count + = 1 <TAB>  assert results == [ False , True , False , True , True , True , False , True , True , True ] ",if commands [ command_count ] :,if command_count < len(commands):,False,18.118707651818156,95.73380718128425
461,"def flask_debug_true ( context ) : <TAB>  if context . is_module_imported_like ( "" flask "" ) : <TAB><TAB>  if context . call_function_name_qual . endswith ( "" .run "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return bandit . Issue ( <TAB><TAB><TAB><TAB><TAB>  severity = bandit . HIGH , <TAB><TAB><TAB><TAB><TAB>  confidence = bandit . MEDIUM , <TAB><TAB><TAB><TAB><TAB>  text = "" A Flask app appears to be run with debug=True,  "" <TAB><TAB><TAB><TAB><TAB>  "" which exposes the Werkzeug debugger and allows  "" <TAB><TAB><TAB><TAB><TAB>  "" the execution of arbitrary code. "" , <TAB><TAB><TAB><TAB><TAB>  lineno = context . get_lineno_for_call_arg ( "" debug "" ) , <TAB><TAB><TAB><TAB>  ) ","if context . check_call_arg_value ( ""debug"" , ""True"" ) :",if context.is_module_imported_like('flask'):,False,63.946478325831904,94.16215374701738
462,"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB>  if self . _should_meta_profile : <TAB><TAB>  end_time = timezone . now ( ) <TAB><TAB>  exception_raised = exc_type is not None <TAB><TAB>  if exception_raised : <TAB><TAB><TAB>  Logger . error ( <TAB><TAB><TAB><TAB>  "" Exception when performing meta profiling, dumping trace below "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  traceback . print_exception ( exc_type , exc_val , exc_tb ) <TAB><TAB>  request = getattr ( DataCollector ( ) . local , "" request "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  curr = request . meta_time or 0 <TAB><TAB><TAB>  request . meta_time = curr + _time_taken ( self . start_time , end_time ) ",if request :,if request:,False,58.32120128262226,100.00000000000004
463,"def get_job_offer ( ja_list ) : <TAB>  ja_joff_map = { } <TAB>  offers = frappe . get_all ( <TAB><TAB>  "" Job Offer "" , <TAB><TAB>  filters = [ [ "" job_applicant "" , "" IN "" , ja_list ] ] , <TAB><TAB>  fields = [ "" name "" , "" job_applicant "" , "" status "" , "" offer_date "" , "" designation "" ] , <TAB>  ) <TAB>  for offer in offers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ja_joff_map [ offer . job_applicant ] = [ offer ] <TAB><TAB>  else : <TAB><TAB><TAB>  ja_joff_map [ offer . job_applicant ] . append ( offer ) <TAB>  return ja_joff_map ",if offer . job_applicant not in ja_joff_map . keys ( ) :,if offer.job_applicant not in ja_joff_map:,False,32.778659530999526,97.34034038352327
464,"def _get_deepest ( self , t ) : <TAB>  if isinstance ( t , list ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return t [ 0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  for part in t : <TAB><TAB><TAB><TAB>  res = self . _get_deepest ( part ) <TAB><TAB><TAB><TAB>  if res : <TAB><TAB><TAB><TAB><TAB>  return res <TAB><TAB><TAB>  return None <TAB>  return None ",if len ( t ) == 1 :,if len(t) == 1:,False,51.31540162974484,100.00000000000004
465,"def test_main ( self ) : <TAB>  root = os . path . dirname ( mutagen . __path__ [ 0 ] ) <TAB>  skip = [ os . path . join ( root , "" docs "" ) , os . path . join ( root , "" venv "" ) ] <TAB>  for dirpath , dirnames , filenames in os . walk ( root ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for filename in filenames : <TAB><TAB><TAB>  if filename . endswith ( "" .py "" ) : <TAB><TAB><TAB><TAB>  path = os . path . join ( dirpath , filename ) <TAB><TAB><TAB><TAB>  self . _check_encoding ( path ) ",if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,if dirnames == skip:,False,47.22566259571629,87.01015494215349
466,"def xview ( self , mode = None , value = None , units = None ) : <TAB>  if type ( value ) == str : <TAB><TAB>  value = float ( value ) <TAB>  if mode is None : <TAB><TAB>  return self . hsb . get ( ) <TAB>  elif mode == "" moveto "" : <TAB><TAB>  frameWidth = self . innerframe . winfo_reqwidth ( ) <TAB><TAB>  self . _startX = value * float ( frameWidth ) <TAB>  else :<TAB># mode == 'scroll' <TAB><TAB>  clipperWidth = self . _clipper . winfo_width ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  jump = int ( clipperWidth * self . _jfraction ) <TAB><TAB>  else : <TAB><TAB><TAB>  jump = clipperWidth <TAB><TAB>  self . _startX = self . _startX + value * jump <TAB>  self . reposition ( ) ","if units == ""units"" :",if mode == 'jfraction':,False,50.98557401734448,95.72944878489143
467,"def test_training_script_with_max_history_set ( tmpdir ) : <TAB>  train_dialogue_model ( <TAB><TAB>  DEFAULT_DOMAIN_PATH , <TAB><TAB>  DEFAULT_STORIES_FILE , <TAB><TAB>  tmpdir . strpath , <TAB><TAB>  interpreter = RegexInterpreter ( ) , <TAB><TAB>  policy_config = "" data/test_config/max_hist_config.yml "" , <TAB><TAB>  kwargs = { } , <TAB>  ) <TAB>  agent = Agent . load ( tmpdir . strpath ) <TAB>  for policy in agent . policy_ensemble . policies : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if type ( policy ) == FormPolicy : <TAB><TAB><TAB><TAB>  assert policy . featurizer . max_history == 2 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  assert policy . featurizer . max_history == 5 ","if hasattr ( policy . featurizer , ""max_history"" ) :",if policy.type(policy) == Policy:,False,26.73711951657282,94.86976068324182
468,"def generate_auto_complete ( self , base , iterable_var ) : <TAB>  sugg = [ ] <TAB>  for entry in iterable_var : <TAB><TAB>  compare_entry = entry <TAB><TAB>  compare_base = base <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  compare_entry = compare_entry . lower ( ) <TAB><TAB><TAB>  compare_base = compare_base . lower ( ) <TAB><TAB>  if self . compare_entries ( compare_entry , compare_base ) : <TAB><TAB><TAB>  if entry not in sugg : <TAB><TAB><TAB><TAB>  sugg . append ( entry ) <TAB>  return sugg ",if self . settings . get ( IGNORE_CASE_SETTING ) :,if compare_base:,False,22.449123473341885,92.2655696977264
469,"def marker_expr ( remaining ) : <TAB>  if remaining and remaining [ 0 ] == "" ( "" : <TAB><TAB>  result , remaining = marker ( remaining [ 1 : ] . lstrip ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise SyntaxError ( "" unterminated parenthesis:  %s "" % remaining ) <TAB><TAB>  remaining = remaining [ 1 : ] . lstrip ( ) <TAB>  else : <TAB><TAB>  lhs , remaining = marker_var ( remaining ) <TAB><TAB>  while remaining : <TAB><TAB><TAB>  m = MARKER_OP . match ( remaining ) <TAB><TAB><TAB>  if not m : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  op = m . groups ( ) [ 0 ] <TAB><TAB><TAB>  remaining = remaining [ m . end ( ) : ] <TAB><TAB><TAB>  rhs , remaining = marker_var ( remaining ) <TAB><TAB><TAB>  lhs = { "" op "" : op , "" lhs "" : lhs , "" rhs "" : rhs } <TAB><TAB>  result = lhs <TAB>  return result , remaining ","if remaining [ 0 ] != "")"" :",if remaining and remaining[0] == '(':,False,49.381248833850236,96.79627181262953
470,"def __repr__ ( self ) : <TAB>  """"""Dump the class data in the format of a .netrc file."""""" <TAB>  rep = "" "" <TAB>  for host in self . hosts . keys ( ) : <TAB><TAB>  attrs = self . hosts [ host ] <TAB><TAB>  rep = rep + "" machine  "" + host + "" \n \t login  "" + repr ( attrs [ 0 ] ) + "" \n "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rep = rep + "" account  "" + repr ( attrs [ 1 ] ) <TAB><TAB>  rep = rep + "" \t password  "" + repr ( attrs [ 2 ] ) + "" \n "" <TAB>  for macro in self . macros . keys ( ) : <TAB><TAB>  rep = rep + "" macdef  "" + macro + "" \n "" <TAB><TAB>  for line in self . macros [ macro ] : <TAB><TAB><TAB>  rep = rep + line <TAB><TAB>  rep = rep + "" \n "" <TAB>  return rep ",if attrs [ 1 ] :,if attrs[1] and attrs[2] and (attrs[3]):,False,35.27217794648635,92.11536858679324
471,"def _parse_policies ( self , policies_yaml ) : <TAB>  for item in policies_yaml : <TAB><TAB>  id_ = required_key ( item , "" id "" ) <TAB><TAB>  controls_ids = required_key ( item , "" controls "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if controls_ids != "" all "" : <TAB><TAB><TAB><TAB>  msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB><TAB><TAB><TAB><TAB>  id_ = id_ , controls = str ( controls_ids ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  raise ValueError ( msg ) <TAB><TAB>  self . policies [ id_ ] = controls_ids ","if not isinstance ( controls_ids , list ) :",if controls_ids:,False,38.4075226318942,95.56533205782284
472,"def __set__ ( self , obj , value ) :<TAB># noqa <TAB>  if ( <TAB><TAB>  value is not None <TAB><TAB>  and self . field . _currency_field . null <TAB><TAB>  and not isinstance ( value , MONEY_CLASSES + ( Decimal , ) ) <TAB>  ) : <TAB><TAB>  # For nullable fields we need either both NULL amount and currency or both NOT NULL <TAB><TAB>  raise ValueError ( "" Missing currency value "" ) <TAB>  if isinstance ( value , BaseExpression ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = self . prepare_value ( obj , value . value ) <TAB><TAB>  elif not isinstance ( value , Func ) : <TAB><TAB><TAB>  validate_money_expression ( obj , value ) <TAB><TAB><TAB>  prepare_expression ( value ) <TAB>  else : <TAB><TAB>  value = self . prepare_value ( obj , value ) <TAB>  obj . __dict__ [ self . field . name ] = value ","if isinstance ( value , Value ) :","if isinstance(value, Decimal):",False,19.568478326867194,97.20851178624828
473,"def Children ( self ) : <TAB>  """"""Returns a list of all of this object's owned (strong) children."""""" <TAB>  children = [ ] <TAB>  for property , attributes in self . _schema . iteritems ( ) : <TAB><TAB>  ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not is_list : <TAB><TAB><TAB><TAB>  children . append ( self . _properties [ property ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  children . extend ( self . _properties [ property ] ) <TAB>  return children ",if is_strong and property in self . _properties :,if is_strong:,False,31.228435966486256,95.07690062219825
474,"def next_item ( self , direction ) : <TAB>  """"""Selects next menu item, based on self._direction"""""" <TAB>  start , i = - 1 , 0 <TAB>  try : <TAB><TAB>  start = self . items . index ( self . _selected ) <TAB><TAB>  i = start + direction <TAB>  except : <TAB><TAB>  pass <TAB>  while True : <TAB><TAB>  if i == start : <TAB><TAB><TAB>  # Cannot find valid menu item <TAB><TAB><TAB>  self . select ( start ) <TAB><TAB><TAB>  break <TAB><TAB>  if i > = len ( self . items ) : <TAB><TAB><TAB>  i = 0 <TAB><TAB><TAB>  continue <TAB><TAB>  if i < 0 : <TAB><TAB><TAB>  i = len ( self . items ) - 1 <TAB><TAB><TAB>  continue <TAB><TAB>  if self . select ( i ) : <TAB><TAB><TAB>  break <TAB><TAB>  i + = direction <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  start = 0 ",if start < 0 :,if i == -1:,False,56.47416252520028,96.97179169124105
475,"def setup_displace ( self ) : <TAB>  self . displace_mod = None <TAB>  self . displace_strength = 0.020 <TAB>  for mod in self . obj . modifiers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . displace_mod = mod <TAB><TAB><TAB>  self . displace_strength = mod . strength <TAB>  if not self . displace_mod : <TAB><TAB>  bpy . ops . object . modifier_add ( type = "" DISPLACE "" ) <TAB><TAB>  self . displace_mod = self . obj . modifiers [ - 1 ] <TAB><TAB>  self . displace_mod . show_expanded = False <TAB><TAB>  self . displace_mod . strength = self . displace_strength <TAB><TAB>  self . displace_mod . show_render = False <TAB><TAB>  self . displace_mod . show_viewport = False ","if mod . type == ""DISPLACE"" :","if mod.type == ""DISPLACE':",False,18.45681944364494,97.15153405845149
476,"def set_json_body ( cls , request_builder ) : <TAB>  old_body = request_builder . info . pop ( "" data "" , { } ) <TAB>  if isinstance ( old_body , abc . Mapping ) : <TAB><TAB>  body = request_builder . info . setdefault ( "" json "" , { } ) <TAB><TAB>  for path in old_body : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cls . _sequence_path_resolver ( path , old_body [ path ] , body ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  body [ path ] = old_body [ path ] <TAB>  else : <TAB><TAB>  request_builder . info . setdefault ( "" json "" , old_body ) ","if isinstance ( path , tuple ) :",if path in cls._sequence_path_resolver:,False,47.09417059917955,94.35349940469257
477,"def build ( opt ) : <TAB>  dpath = os . path . join ( opt [ "" datapath "" ] , "" DBLL "" ) <TAB>  version = None <TAB>  if not build_data . built ( dpath , version_string = version ) : <TAB><TAB>  print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # An older version exists, so remove these outdated files. <TAB><TAB><TAB>  build_data . remove_dir ( dpath ) <TAB><TAB>  build_data . make_dir ( dpath ) <TAB><TAB>  # Download the data. <TAB><TAB>  for downloadable_file in RESOURCES : <TAB><TAB><TAB>  downloadable_file . download_file ( dpath ) <TAB><TAB>  # Mark the data as built. <TAB><TAB>  build_data . mark_done ( dpath , version_string = version ) ",if build_data . built ( dpath ) :,if version is None:,False,57.89734801034052,95.73571347008684
478,"def test_prefix_lm ( self ) : <TAB>  num_tries = 100 <TAB>  original = "" This is a long test with lots of words to see if it works ok. "" <TAB>  dataset = tf . data . Dataset . from_tensor_slices ( { "" text "" : [ original ] * num_tries } ) <TAB>  dataset = prep . prefix_lm ( dataset ) <TAB>  for data in test_utils . dataset_as_text ( dataset ) : <TAB><TAB>  inputs = data [ "" inputs "" ] . replace ( "" prefix:  "" , "" "" ) <TAB><TAB>  targets = data [ "" targets "" ] <TAB><TAB>  reconstructed = "" "" . join ( inputs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  reconstructed + = "" "" <TAB><TAB>  reconstructed + = "" "" . join ( targets ) <TAB><TAB>  self . assertEqual ( reconstructed , original ) ",if inputs :,if targets:,False,30.834425809333084,98.80232434995159
479,"def leading_whitespace ( self , inputstring ) : <TAB>  """"""Get leading whitespace."""""" <TAB>  leading_ws = [ ] <TAB>  for i , c in enumerate ( inputstring ) : <TAB><TAB>  if c in legal_indent_chars : <TAB><TAB><TAB>  leading_ws . append ( c ) <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . indchar = c <TAB><TAB>  elif c != self . indchar : <TAB><TAB><TAB>  self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB>  return "" "" . join ( leading_ws ) ",if self . indchar is None :,if c in self.indchar:,False,48.89469023684523,97.1984081740988
480,"def __init__ ( self , text ) : <TAB>  self . mappings = { } <TAB>  self . attributes = collections . defaultdict ( set ) <TAB>  for stanza in _ParseTextProperties ( text ) : <TAB><TAB>  processor_id , single_values , multiple_values = self . _ParseStanza ( stanza ) <TAB><TAB>  if processor_id is None :<TAB># can be 0 <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logging . warn ( "" Processor id  %s  seen twice in  %s "" , processor_id , text ) <TAB><TAB><TAB>  continue <TAB><TAB>  self . mappings [ processor_id ] = single_values <TAB><TAB>  for key , value in multiple_values . items ( ) : <TAB><TAB><TAB>  self . attributes [ key ] . add ( value ) ",if processor_id in self . mappings :,if processor_id in self.mappings:,False,53.98249875651222,97.87805119482678
481,"def __iter__ ( self ) : <TAB>  for chunk in self . source : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . wait_counter = 0 <TAB><TAB><TAB>  yield chunk <TAB><TAB>  elif self . wait_counter < self . wait_cntr_max : <TAB><TAB><TAB>  self . wait_counter + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB><TAB><TAB><TAB>  "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  break <TAB><TAB>  time . sleep ( self . poll_period ) ",if chunk is not None :,if chunk.data_type == 'data':,False,56.51998843399988,96.10564921148762
482,"def download ( self , prefetch = False ) : <TAB>  while self . running : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ( path , start , end ) = self . prefetch_queue . get ( <TAB><TAB><TAB><TAB><TAB>  True , 1 <TAB><TAB><TAB><TAB>  )<TAB># 1 second time-out <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ( path , start , end ) = self . download_queue . get ( <TAB><TAB><TAB><TAB><TAB>  True , 1 <TAB><TAB><TAB><TAB>  )<TAB># 1 second time-out <TAB><TAB><TAB>  self . download_data ( path , start , end ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . prefetch_queue . task_done ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . download_queue . task_done ( ) <TAB><TAB>  except Queue . Empty : <TAB><TAB><TAB>  pass ",if prefetch :,if prefetch:,False,49.27127396335003,95.35714168859455
483,"def process_messages ( self , found_files , messages ) : <TAB>  for message in messages : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  message . to_absolute_path ( self . config . workdir ) <TAB><TAB>  else : <TAB><TAB><TAB>  message . to_relative_path ( self . config . workdir ) <TAB>  if self . config . blending : <TAB><TAB>  messages = blender . blend ( messages ) <TAB>  filepaths = found_files . iter_module_paths ( abspath = False ) <TAB>  return postfilter . filter_messages ( filepaths , self . config . workdir , messages ) ",if self . config . absolute_paths :,"if isinstance(message, File):",False,49.88292060183884,94.421476960294
484,"def set_indentation_params ( self , ispythonsource , guess = 1 ) : <TAB>  if guess and ispythonsource : <TAB><TAB>  i = self . guess_indent ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . indentwidth = i <TAB><TAB>  if self . indentwidth != self . tabwidth : <TAB><TAB><TAB>  self . usetabs = 0 <TAB>  self . editwin . set_tabwidth ( self . tabwidth ) ",if 2 <= i <= 8 :,if i > 0:,False,27.107814244963507,92.56183077468604
485,"def to_tree ( self , tagname = None , value = None , namespace = None ) : <TAB>  namespace = getattr ( self , "" namespace "" , namespace ) <TAB>  if value is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tagname = "" { %s } %s "" % ( namespace , tagname ) <TAB><TAB>  el = Element ( tagname ) <TAB><TAB>  el . text = safe_string ( value ) <TAB><TAB>  return el ",if namespace is not None :,if tagname is not None:,False,51.081892736913204,97.82092189509319
486,"def execute ( self , argv : List ) - > bool : <TAB>  if not argv : <TAB><TAB>  print ( "" ERROR: You must give at least one module to download. "" ) <TAB><TAB>  return False <TAB>  for _arg in argv : <TAB><TAB>  result = module_server . search_module ( _arg ) <TAB><TAB>  CacheUpdater ( "" hub_download "" , _arg ) . start ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  url = result [ 0 ] [ "" url "" ] <TAB><TAB><TAB>  with log . ProgressBar ( "" Download  {} "" . format ( url ) ) as bar : <TAB><TAB><TAB><TAB>  for file , ds , ts in utils . download_with_progress ( url ) : <TAB><TAB><TAB><TAB><TAB>  bar . update ( float ( ds ) / ts ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" ERROR: Could not find a HubModule named  {} "" . format ( _arg ) ) <TAB>  return True ",if result :,if result:,False,59.42573159408373,100.00000000000004
487,"def visit_type_type ( self , t : TypeType ) - > ProperType : <TAB>  if isinstance ( self . s , TypeType ) : <TAB><TAB>  typ = self . meet ( t . item , self . s . item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  typ = TypeType . make_normalized ( typ , line = t . line ) <TAB><TAB>  return typ <TAB>  elif isinstance ( self . s , Instance ) and self . s . type . fullname == "" builtins.type "" : <TAB><TAB>  return t <TAB>  elif isinstance ( self . s , CallableType ) : <TAB><TAB>  return self . meet ( t , self . s ) <TAB>  else : <TAB><TAB>  return self . default ( self . s ) ","if not isinstance ( typ , NoneType ) :","if isinstance(typ, TypeType):",False,22.777129925530375,97.27764925584593
488,"def run ( self , paths = [ ] ) : <TAB>  items = [ ] <TAB>  for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB><TAB>  items . append ( item . name ( ) ) <TAB>  if len ( items ) > 0 : <TAB><TAB>  sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sublime . status_message ( "" Items copied "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  sublime . status_message ( "" Item copied "" ) ",if len ( items ) > 1 :,if len(items) == 0:,False,51.094082844480205,96.85451587663262
489,"def get_icon ( self ) : <TAB>  if self . icon is not None : <TAB><TAB>  # Load it from an absolute filename <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return GdkPixbuf . Pixbuf . new_from_file_at_size ( self . icon , 24 , 24 ) <TAB><TAB><TAB>  except GObject . GError as ge : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  # Load it from the current icon theme <TAB><TAB>  ( icon_name , extension ) = os . path . splitext ( os . path . basename ( self . icon ) ) <TAB><TAB>  theme = Gtk . IconTheme ( ) <TAB><TAB>  if theme . has_icon ( icon_name ) : <TAB><TAB><TAB>  return theme . load_icon ( icon_name , 24 , 0 ) ",if os . path . exists ( self . icon ) :,if os.path.isfile(self.icon):,False,59.07334267010553,98.87760724645923
490,"def setup_logger ( ) : <TAB>  """"""Set up logger and add stdout handler"""""" <TAB>  logging . setLoggerClass ( IPDLogger ) <TAB>  logger = logging . getLogger ( "" icloudpd "" ) <TAB>  has_stdout_handler = False <TAB>  for handler in logger . handlers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  has_stdout_handler = True <TAB>  if not has_stdout_handler : <TAB><TAB>  formatter = logging . Formatter ( <TAB><TAB><TAB>  fmt = "" %(asctime)s %(levelname)-8s %(message)s "" , datefmt = "" % Y- % m- %d % H: % M: % S "" <TAB><TAB>  ) <TAB><TAB>  stdout_handler = logging . StreamHandler ( stream = sys . stdout ) <TAB><TAB>  stdout_handler . setFormatter ( formatter ) <TAB><TAB>  stdout_handler . name = "" stdoutLogger "" <TAB><TAB>  logger . addHandler ( stdout_handler ) <TAB>  return logger ","if handler . name == ""stdoutLogger"" :",if handler.name == 'stdout':,False,54.880281657074946,98.12728331939451
491,"def process_extra_fields ( self ) : <TAB>  if self . instance . pk is not None : <TAB><TAB>  if self . cleaned_data . get ( "" initialize "" , None ) : <TAB><TAB><TAB>  self . instance . initialize ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . instance . update_from_templates ( ) ","if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :",if self.instance.templates is not None:,False,22.79882420128234,79.26405594357584
492,"def testFunctions ( self ) : <TAB>  from zim . formats . wiki import match_url , is_url <TAB>  for input , input_is_url , tail in self . examples : <TAB><TAB>  if input_is_url : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( match_url ( input ) , input [ : - len ( tail ) ] ) <TAB><TAB><TAB><TAB>  self . assertFalse ( is_url ( input ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . assertEqual ( match_url ( input ) , input ) <TAB><TAB><TAB><TAB>  self . assertTrue ( is_url ( input ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( match_url ( input ) , None ) <TAB><TAB><TAB>  self . assertFalse ( is_url ( input ) ) ",if tail :,if tail:,False,50.99257257763751,98.47129374822478
493,"def _SetUser ( self , users ) : <TAB>  for user in users . items ( ) : <TAB><TAB>  username = user [ 0 ] <TAB><TAB>  settings = user [ 1 ] <TAB><TAB>  room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB><TAB>  file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" joined "" in settings [ "" event "" ] : <TAB><TAB><TAB><TAB>  self . _client . userlist . addUser ( username , room , file_ ) <TAB><TAB><TAB>  elif "" left "" in settings [ "" event "" ] : <TAB><TAB><TAB><TAB>  self . _client . removeUser ( username ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _client . userlist . modUser ( username , room , file_ ) ","if ""event"" in settings :",if settings['event']:,False,23.307174763925477,97.2850320827999
494,"def restoreTerminals ( self , state ) : <TAB>  for name in list ( self . terminals . keys ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . removeTerminal ( name ) <TAB>  for name , opts in state . items ( ) : <TAB><TAB>  if name in self . terminals : <TAB><TAB><TAB>  term = self [ name ] <TAB><TAB><TAB>  term . setOpts ( * * opts ) <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  opts = strDict ( opts ) <TAB><TAB><TAB>  self . addTerminal ( name , * * opts ) <TAB><TAB>  except : <TAB><TAB><TAB>  printExc ( "" Error restoring terminal  %s  ( %s ): "" % ( str ( name ) , str ( opts ) ) ) ",if name not in state :,if name in state:,False,47.91159588640968,98.78127806202085
495,"def htmlify ( path , text ) : <TAB>  fname = os . path . basename ( path ) <TAB>  if any ( ( fnmatch . fnmatchcase ( fname , p ) for p in _patterns ) ) : <TAB><TAB>  # Get file_id, skip if not in database <TAB><TAB>  sql = "" SELECT files.id FROM files WHERE path = ? LIMIT 1 "" <TAB><TAB>  row = _conn . execute ( sql , ( path , ) ) . fetchone ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ClangHtmlifier ( _tree , _conn , path , text , row [ 0 ] ) <TAB>  return None ",if row :,if row:,False,62.30760839346272,100.00000000000004
496,"def autoformat_filter_conv2d ( fsize , in_depth , out_depth ) : <TAB>  if isinstance ( fsize , int ) : <TAB><TAB>  return [ fsize , fsize , in_depth , out_depth ] <TAB>  elif isinstance ( fsize , ( tuple , list , tf . TensorShape ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ fsize [ 0 ] , fsize [ 1 ] , in_depth , out_depth ] <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" filter length error:  "" <TAB><TAB><TAB><TAB>  + str ( len ( fsize ) ) <TAB><TAB><TAB><TAB>  + "" , only a length of 2 is supported. "" <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise Exception ( "" filter format error:  "" + str ( type ( fsize ) ) ) ",if len ( fsize ) == 2 :,if len(fsize) == 2:,False,31.905455606649397,100.00000000000004
497,"def _rle_encode ( string ) : <TAB>  new = b "" "" <TAB>  count = 0 <TAB>  for cur in string : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  count + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  if count : <TAB><TAB><TAB><TAB>  new + = b "" \0 "" + bytes ( [ count ] ) <TAB><TAB><TAB><TAB>  count = 0 <TAB><TAB><TAB>  new + = bytes ( [ cur ] ) <TAB>  return new ",if not cur :,if cur == b'':,False,21.053226784932622,96.22184702341828
498,"def is_clean ( self ) : <TAB>  acceptable_statuses = { "" external "" , "" unversioned "" } <TAB>  root = self . _capture_output ( "" status "" , "" --quiet "" ) <TAB>  for elem in root . findall ( "" ./target/entry "" ) : <TAB><TAB>  status = elem . find ( "" ./wc-status "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  log . debug ( "" Path  %s  is  %s "" , elem . get ( "" path "" ) , status . get ( "" item "" ) ) <TAB><TAB>  return False <TAB>  return True ","if status . get ( ""item"" , None ) in acceptable_statuses :",if status is None:,False,21.353890722926728,90.99861471378807
499,"def process ( self , body , message ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  ' Received an unexpected type  "" %s ""  for payload. ' % type ( body ) <TAB><TAB><TAB>  ) <TAB><TAB>  response = self . _handler . pre_ack_process ( body ) <TAB><TAB>  self . _dispatcher . dispatch ( self . _process_message , response ) <TAB>  except : <TAB><TAB>  LOG . exception ( "" %s  failed to process message:  %s "" , self . __class__ . __name__ , body ) <TAB>  finally : <TAB><TAB>  # At this point we will always ack a message. <TAB><TAB>  message . ack ( ) ","if not isinstance ( body , self . _handler . message_type ) :","if not isinstance(body, (str, unicode)):",False,57.05878127310451,94.1501096898958
500,"def page_file ( self , page ) : <TAB>  try : <TAB><TAB>  page = self . notebook . get_page ( page ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return page . source <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  except PageNotFoundError : <TAB><TAB>  return None ","if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :",if page:,False,18.251304847463214,81.17526569199238
501,"def _optimize ( self , solutions ) : <TAB>  best_a = None <TAB>  best_silhouette = None <TAB>  best_k = None <TAB>  for a , silhouette , k in solutions ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  elif silhouette < = best_silhouette : <TAB><TAB><TAB>  break <TAB><TAB>  best_silhouette = silhouette <TAB><TAB>  best_a = a <TAB><TAB>  best_k = k <TAB>  return best_a , best_silhouette , best_k ",if best_silhouette is None :,if a == k:,False,31.74052245056141,95.3682814403816
502,"def _cancel_tasks_for_partitions ( self , to_cancel_partitions ) : <TAB>  # type: (Iterable[str]) -> None <TAB>  with self . _lock : <TAB><TAB>  _LOGGER . debug ( <TAB><TAB><TAB>  "" EventProcessor  %r  tries to cancel partitions  %r "" , <TAB><TAB><TAB>  self . _id , <TAB><TAB><TAB>  to_cancel_partitions , <TAB><TAB>  ) <TAB><TAB>  for partition_id in to_cancel_partitions : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _consumers [ partition_id ] . stop = True <TAB><TAB><TAB><TAB>  _LOGGER . info ( <TAB><TAB><TAB><TAB><TAB>  "" EventProcessor  %r  has cancelled partition  %r "" , <TAB><TAB><TAB><TAB><TAB>  self . _id , <TAB><TAB><TAB><TAB><TAB>  partition_id , <TAB><TAB><TAB><TAB>  ) ",if partition_id in self . _consumers :,if partition_id in self._consumers:,False,34.9697249104934,100.00000000000004
503,"def get_intersect_all ( self , refine = False ) : <TAB>  result = None <TAB>  for source , parts in self . _per_source . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = parts <TAB><TAB>  else : <TAB><TAB><TAB>  result . intersection_update ( parts ) <TAB>  if not result : <TAB><TAB>  return None <TAB>  elif len ( result ) == 1 : <TAB><TAB>  return list ( result ) [ 0 ] . item <TAB>  else : <TAB><TAB>  solids = [ p . item for p in result ] <TAB><TAB>  solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB><TAB>  if refine : <TAB><TAB><TAB>  solid = solid . removeSplitter ( ) <TAB><TAB>  return solid ",if result is None :,if source == source:,False,48.79244984032618,97.31895814186073
504,"def geli_detach ( self , pool , clear = False ) : <TAB>  failed = 0 <TAB>  for ed in self . middleware . call_sync ( <TAB><TAB>  "" datastore.query "" , <TAB><TAB>  "" storage.encrypteddisk "" , <TAB><TAB>  [ ( "" encrypted_volume "" , "" = "" , pool [ "" id "" ] ) ] , <TAB>  ) : <TAB><TAB>  dev = ed [ "" encrypted_provider "" ] <TAB><TAB>  try : <TAB><TAB><TAB>  self . geli_detach_single ( dev ) <TAB><TAB>  except Exception as ee : <TAB><TAB><TAB>  self . logger . warn ( str ( ee ) ) <TAB><TAB><TAB>  failed + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . geli_clear ( dev ) <TAB><TAB><TAB>  except Exception as e : <TAB><TAB><TAB><TAB>  self . logger . warn ( "" Failed to clear  %s :  %s "" , dev , e ) <TAB>  return failed ",if clear :,if clear:,False,22.793967830902993,100.00000000000004
505,def compute_lengths ( batch_sizes ) : <TAB>  tmp_batch_sizes = np . copy ( batch_sizes ) <TAB>  lengths = [ ] <TAB>  while True : <TAB><TAB>  c = np . count_nonzero ( tmp_batch_sizes > 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  lengths . append ( c ) <TAB><TAB>  tmp_batch_sizes = np . array ( [ b - 1 for b in tmp_batch_sizes ] ) <TAB>  return np . array ( lengths ) ,if c == 0 :,if c == 0:,False,57.01875156578951,100.00000000000004
506,"def _render_raw_list ( bytes_items ) : <TAB>  flatten_items = [ ] <TAB>  for item in bytes_items : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flatten_items . append ( b "" "" ) <TAB><TAB>  elif isinstance ( item , bytes ) : <TAB><TAB><TAB>  flatten_items . append ( item ) <TAB><TAB>  elif isinstance ( item , int ) : <TAB><TAB><TAB>  flatten_items . append ( str ( item ) . encode ( ) ) <TAB><TAB>  elif isinstance ( item , list ) : <TAB><TAB><TAB>  flatten_items . append ( _render_raw_list ( item ) ) <TAB>  return b "" \n "" . join ( flatten_items ) ",if item is None :,"if isinstance(item, str):",False,40.49862567619556,96.12517041730742
507,"def update ( self , new_config ) : <TAB>  jsonschema . validate ( new_config , self . schema ) <TAB>  config = { } <TAB>  for k , v in new_config . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  config [ k ] = self [ k ] <TAB><TAB>  else : <TAB><TAB><TAB>  config [ k ] = v <TAB>  self . _config = config <TAB>  self . changed ( ) ","if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :",if k in self:,False,42.13152008665525,83.89444224979127
508,"def _encode_numpy ( values , uniques = None , encode = False , check_unknown = True ) : <TAB>  # only used in _encode below, see docstring there for details <TAB>  if uniques is None : <TAB><TAB>  if encode : <TAB><TAB><TAB>  uniques , encoded = np . unique ( values , return_inverse = True ) <TAB><TAB><TAB>  return uniques , encoded <TAB><TAB>  else : <TAB><TAB><TAB>  # unique sorts <TAB><TAB><TAB>  return np . unique ( values ) <TAB>  if encode : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  diff = _encode_check_unknown ( values , uniques ) <TAB><TAB><TAB>  if diff : <TAB><TAB><TAB><TAB>  raise ValueError ( "" y contains previously unseen labels:  %s "" % str ( diff ) ) <TAB><TAB>  encoded = np . searchsorted ( uniques , values ) <TAB><TAB>  return uniques , encoded <TAB>  else : <TAB><TAB>  return uniques ",if check_unknown :,if check_unknown:,False,58.88455131237799,100.00000000000004
509,"def restore_dtype_and_merge ( arr , input_dtype ) : <TAB>  if isinstance ( arr , list ) : <TAB><TAB>  arr = [ restore_dtype_and_merge ( arr_i , input_dtype ) for arr_i in arr ] <TAB><TAB>  shapes = [ arr_i . shape for arr_i in arr ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  arr = np . array ( arr ) <TAB>  if ia . is_np_array ( arr ) : <TAB><TAB>  arr = iadt . restore_dtypes_ ( arr , input_dtype ) <TAB>  return arr ",if len ( set ( shapes ) ) == 1 :,"if isinstance(arr, np.ndarray):",False,27.481824318868863,92.86707930616083
510,"def proc_minute ( d ) : <TAB>  if expanded [ 0 ] [ 0 ] != "" * "" : <TAB><TAB>  diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB><TAB>  if diff_min is not None and diff_min != 0 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB><TAB><TAB>  return True , d <TAB>  return False , d ",if is_prev :,if diff_min < 0:,False,55.07436603520728,96.36720390465862
511,"def _populate_tree ( self , element , d ) : <TAB>  """"""Populates an etree with attributes & elements, given a dict."""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _populate_dict ( element , k , v ) <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  self . _populate_list ( element , k , v ) <TAB><TAB>  elif isinstance ( v , bool ) : <TAB><TAB><TAB>  self . _populate_bool ( element , k , v ) <TAB><TAB>  elif isinstance ( v , basestring ) : <TAB><TAB><TAB>  self . _populate_str ( element , k , v ) <TAB><TAB>  elif type ( v ) in [ int , float , long , complex ] : <TAB><TAB><TAB>  self . _populate_number ( element , k , v ) ","if isinstance ( v , dict ) :","if isinstance(v, dict):",False,31.71516463506221,100.00000000000004
512,"def __createItemAttribute ( self , item , function , preload ) : <TAB>  """"""Create the new widget, add it, and remove the old one"""""" <TAB>  try : <TAB><TAB>  self . __stack . addWidget ( function ( item , preload ) ) <TAB><TAB>  # Remove the widget <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  oldWidget = self . __stack . widget ( 0 ) <TAB><TAB><TAB>  self . __stack . removeWidget ( oldWidget ) <TAB><TAB><TAB>  oldWidget . setParent ( QtWidgets . QWidget ( ) ) <TAB>  except Exception as e : <TAB><TAB>  list ( map ( logger . warning , cuegui . Utils . exceptionOutput ( e ) ) ) ",if self . __stack . count ( ) > 1 :,if self.__stack.widget():,False,61.06478251437333,96.8047756165767
513,"def download_main ( <TAB>  download , download_playlist , urls , playlist , output_dir , merge , info_only  ) : <TAB>  for url in urls : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  url = url [ 8 : ] <TAB><TAB>  if not url . startswith ( "" http:// "" ) : <TAB><TAB><TAB>  url = "" http:// "" + url <TAB><TAB>  if playlist : <TAB><TAB><TAB>  download_playlist ( <TAB><TAB><TAB><TAB>  url , output_dir = output_dir , merge = merge , info_only = info_only <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  download ( url , output_dir = output_dir , merge = merge , info_only = info_only ) ","if url . startswith ( ""https://"" ) :",if url.startswith('http'):,False,50.722889402697156,96.5049229511256
514,"def add_enc_zero ( obj , enc_zero ) : <TAB>  if isinstance ( obj , np . ndarray ) : <TAB><TAB>  return obj + enc_zero <TAB>  elif isinstance ( obj , Iterable ) : <TAB><TAB>  return type ( obj ) ( <TAB><TAB><TAB>  EncryptModeCalculator . add_enc_zero ( o , enc_zero ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else o + enc_zero <TAB><TAB><TAB>  for o in obj <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return obj + enc_zero ","if isinstance ( o , Iterable )","if isinstance(obj, (np.ndarray, np.ndarray)):",False,25.152604249260623,91.26097011170009
515,"def ensemble ( self , pairs , other_preds ) : <TAB>  """"""Ensemble the dict with statistical model predictions."""""" <TAB>  lemmas = [ ] <TAB>  assert len ( pairs ) == len ( other_preds ) <TAB>  for p , pred in zip ( pairs , other_preds ) : <TAB><TAB>  w , pos = p <TAB><TAB>  if ( w , pos ) in self . composite_dict : <TAB><TAB><TAB>  lemma = self . composite_dict [ ( w , pos ) ] <TAB><TAB>  elif w in self . word_dict : <TAB><TAB><TAB>  lemma = self . word_dict [ w ] <TAB><TAB>  else : <TAB><TAB><TAB>  lemma = pred <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lemma = w <TAB><TAB>  lemmas . append ( lemma ) <TAB>  return lemmas ",if lemma is None :,if not lemma:,False,28.853270552930958,98.01472286928092
516,"def replace_to_6hex ( color ) : <TAB>  """"""Validate and replace 3hex colors to 6hex ones."""""" <TAB>  if match ( r "" ^#(?:[0-9a-fA-F] {3} ) { 1,2}$ "" , color ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  color = "" # {0} {0} {1} {1} {2} {2} "" . format ( color [ 1 ] , color [ 2 ] , color [ 3 ] ) <TAB><TAB>  return color <TAB>  else : <TAB><TAB>  exit ( _ ( "" Invalid color  {} "" ) . format ( color ) ) ",if len ( color ) == 4 :,"if color[0] == r""^#(?:[0-9a-fA-F",False,16.859007444527705,89.81888434934162
517,"def computeMachineName ( self ) : <TAB>  """"""Return the name of the current machine, i.e, HOSTNAME."""""" <TAB>  # This is prepended to leoSettings.leo or myLeoSettings.leo <TAB>  # to give the machine-specific setting name. <TAB>  # How can this be worth doing?? <TAB>  try : <TAB><TAB>  import os <TAB><TAB>  name = os . getenv ( "" HOSTNAME "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = os . getenv ( "" COMPUTERNAME "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  import socket <TAB><TAB><TAB>  name = socket . gethostname ( ) <TAB>  except Exception : <TAB><TAB>  name = "" "" <TAB>  return name ",if not name :,if name is None:,False,64.38212603480518,95.1857286732127
518,"def _git_dirty_working_directory ( q , include_untracked ) : <TAB>  try : <TAB><TAB>  cmd = [ "" git "" , "" status "" , "" --porcelain "" ] <TAB><TAB>  if include_untracked : <TAB><TAB><TAB>  cmd + = [ "" --untracked-files=normal "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  cmd + = [ "" --untracked-files=no "" ] <TAB><TAB>  status = _run_git_cmd ( cmd ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  q . put ( bool ( status ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  q . put ( None ) <TAB>  except ( subprocess . CalledProcessError , OSError , FileNotFoundError ) : <TAB><TAB>  q . put ( None ) ",if status is not None :,if status:,False,21.239545368741904,97.68130517628924
519,"def runAndWaitWork ( server , work ) : <TAB>  work . touch ( ) <TAB>  thr = threading . Thread ( target = workThread , args = ( server , work ) ) <TAB>  thr . setDaemon ( True ) <TAB>  thr . start ( ) <TAB>  # Wait around for done or timeout <TAB>  while True : <TAB><TAB>  if work . isTimedOut ( ) : <TAB><TAB><TAB>  break <TAB><TAB>  # If the thread is done, lets get out. <TAB><TAB>  if not thr . isAlive ( ) : <TAB><TAB><TAB>  break <TAB><TAB>  # If our parent, or some thread closes stdin, <TAB><TAB>  # time to pack up and go. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  time . sleep ( 2 ) ",if sys . stdin . closed :,if not thr.isAlive():,False,65.98204027127126,96.35872791622214
520,"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB>  try : <TAB><TAB>  return self . _read ( count , timeout ) <TAB>  except usb . USBError as e : <TAB><TAB>  if DEBUG_COMM : <TAB><TAB><TAB>  log . info ( <TAB><TAB><TAB><TAB>  "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB><TAB><TAB><TAB>  % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  if ignore_timeouts and is_timeout ( e ) : <TAB><TAB><TAB>  return [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ ] <TAB><TAB>  raise ",if ignore_non_errors and is_noerr ( e ) :,if ignore_non_errors and is_timeout(e):,False,50.82248548905353,98.90705000370515
521,"def PrintHeader ( self ) :<TAB># print the header array <TAB>  if self . draw == False : <TAB><TAB>  return <TAB>  for val in self . parent . header : <TAB><TAB>  self . SetPrintFont ( val [ "" Font "" ] ) <TAB><TAB>  header_indent = val [ "" Indent "" ] * self . pwidth <TAB><TAB>  text = val [ "" Text "" ] <TAB><TAB>  htype = val [ "" Type "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  addtext = self . GetDate ( ) <TAB><TAB>  elif htype == "" Date & Time "" : <TAB><TAB><TAB>  addtext = self . GetDateTime ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  addtext = "" "" <TAB><TAB>  self . OutTextPageWidth ( <TAB><TAB><TAB>  text + addtext , self . pheader_margin , val [ "" Align "" ] , header_indent , True <TAB><TAB>  ) ","if htype == ""Date"" :","if htype == ""Date & Time"" or htype == ""Date & Time"" or",False,12.129020766793982,92.7767627774166
522,"def get_intersect_all ( self , refine = False ) : <TAB>  result = None <TAB>  for source , parts in self . _per_source . items ( ) : <TAB><TAB>  if result is None : <TAB><TAB><TAB>  result = parts <TAB><TAB>  else : <TAB><TAB><TAB>  result . intersection_update ( parts ) <TAB>  if not result : <TAB><TAB>  return None <TAB>  elif len ( result ) == 1 : <TAB><TAB>  return list ( result ) [ 0 ] . item <TAB>  else : <TAB><TAB>  solids = [ p . item for p in result ] <TAB><TAB>  solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  solid = solid . removeSplitter ( ) <TAB><TAB>  return solid ",if refine :,if refine:,False,51.718220847332994,100.00000000000004
523,"def captured_updateNode ( self , context ) : <TAB>  if not self . updating_name_from_pointer : <TAB><TAB>  font_datablock = self . get_bpy_data_from_name ( self . fontname , bpy . data . fonts ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . font_pointer = font_datablock <TAB><TAB><TAB>  updateNode ( self , context ) ",if font_datablock :,if font_datablock is not None:,False,29.892908723297058,95.59054761834716
524,"def __add__ ( self , other ) : <TAB>  if isinstance ( other , Vector2 ) : <TAB><TAB>  # Vector + Vector -> Vector <TAB><TAB>  # Vector + Point -> Point <TAB><TAB>  # Point + Point -> Vector <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _class = Vector2 <TAB><TAB>  else : <TAB><TAB><TAB>  _class = Point2 <TAB><TAB>  return _class ( self . x + other . x , self . y + other . y ) <TAB>  else : <TAB><TAB>  assert hasattr ( other , "" __len__ "" ) and len ( other ) == 2 <TAB><TAB>  return Vector2 ( self . x + other [ 0 ] , self . y + other [ 1 ] ) ",if self . __class__ is other . __class__ :,"if isinstance(other, Vector2):",False,56.22663997047166,91.90442578691639
525,"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB>  """"""Take a nested dict and return a flat dict of setting values."""""" <TAB>  setting_values = { } <TAB>  for field in form . c : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setting_values . update ( <TAB><TAB><TAB><TAB>  self . _flatten_settings_from_form ( <TAB><TAB><TAB><TAB><TAB>  settings , field , form_values [ field . _name ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  elif field . _name in settings : <TAB><TAB><TAB>  setting_values [ field . _name ] = form_values [ field . _name ] <TAB>  return setting_values ","if isinstance ( field , _ContainerMixin ) :","if hasattr(field, '_name'):",False,59.47419086461674,96.83913242971008
526,"def add_include_dirs ( self , args ) : <TAB>  ids = [ ] <TAB>  for a in args : <TAB><TAB>  # FIXME same hack, forcibly unpack from holder. <TAB><TAB>  if hasattr ( a , "" includedirs "" ) : <TAB><TAB><TAB>  a = a . includedirs <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise InvalidArguments ( <TAB><TAB><TAB><TAB>  "" Include directory to be added is not an include directory object. "" <TAB><TAB><TAB>  ) <TAB><TAB>  ids . append ( a ) <TAB>  self . include_dirs + = ids ","if not isinstance ( a , IncludeDirs ) :","if not isinstance(a, include.Directory):",False,64.77109841238622,97.17095724139516
527,"def _clip_array ( array , config ) : <TAB>  if "" threshold "" in config . keys ( ) : <TAB><TAB>  threshold = config [ "" threshold "" ] <TAB>  else : <TAB><TAB>  abs_array = np . max ( np . abs ( array ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return array <TAB><TAB>  threshold = np . percentile ( np . abs ( array ) , 99.99 ) <TAB>  return np . clip ( array , - threshold , threshold ) ",if abs_array < 1.0 :,if abs_array < 0:,False,46.984987326258825,95.10681678400222
528,def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB>  index [ v ] = len ( stack ) <TAB>  stack . append ( v ) <TAB>  boundaries . append ( index [ v ] ) <TAB>  for w in edges [ v ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield from dfs ( w ) <TAB><TAB>  elif w not in identified : <TAB><TAB><TAB>  while index [ w ] < boundaries [ - 1 ] : <TAB><TAB><TAB><TAB>  boundaries . pop ( ) <TAB>  if boundaries [ - 1 ] == index [ v ] : <TAB><TAB>  boundaries . pop ( ) <TAB><TAB>  scc = set ( stack [ index [ v ] : ] ) <TAB><TAB>  del stack [ index [ v ] : ] <TAB><TAB>  identified . update ( scc ) <TAB><TAB>  yield scc ,if w not in index :,if w in identified:,False,37.87247073324976,95.24093838385049
529,"def create_balancer ( <TAB>  self , name , members , protocol = "" http "" , port = 80 , algorithm = DEFAULT_ALGORITHM  ) : <TAB>  balancer = self . ex_create_balancer_nowait ( name , members , protocol , port , algorithm ) <TAB>  timeout = 60 * 20 <TAB>  waittime = 0 <TAB>  interval = 2 * 15 <TAB>  if balancer . id is not None : <TAB><TAB>  return balancer <TAB>  else : <TAB><TAB>  while waittime < timeout : <TAB><TAB><TAB>  balancers = self . list_balancers ( ) <TAB><TAB><TAB>  for i in balancers : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return i <TAB><TAB><TAB>  waittime + = interval <TAB><TAB><TAB>  time . sleep ( interval ) <TAB>  raise Exception ( "" Failed to get id "" ) ",if i . name == balancer . name and i . id is not None :,if i.id == name:,False,26.052129900990305,94.40604526832188
530,"def handle ( self , scope : Scope , receive : Receive , send : Send ) - > None : <TAB>  if self . methods and scope [ "" method "" ] not in self . methods : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise HTTPException ( status_code = 405 ) <TAB><TAB>  else : <TAB><TAB><TAB>  response = PlainTextResponse ( "" Method Not Allowed "" , status_code = 405 ) <TAB><TAB>  await response ( scope , receive , send ) <TAB>  else : <TAB><TAB>  await self . app ( scope , receive , send ) ","if ""app"" in scope :",if scope['method'] == 'none':,False,47.82260349352572,94.1959978761776
531,"def convert ( data ) : <TAB>  result = [ ] <TAB>  for d in data : <TAB><TAB>  # noinspection PyCompatibility <TAB><TAB>  if isinstance ( d , tuple ) and len ( d ) == 2 : <TAB><TAB><TAB>  result . append ( ( d [ 0 ] , None , d [ 1 ] ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( d ) <TAB>  return result ","elif isinstance ( d , basestring ) :","if isinstance(d, list):",False,51.01479584960038,95.47309878401474
532,"def register_adapters ( ) : <TAB>  global adapters_registered <TAB>  if adapters_registered is True : <TAB><TAB>  return <TAB>  try : <TAB><TAB>  import pkg_resources <TAB><TAB>  packageDir = pkg_resources . resource_filename ( "" pyamf "" , "" adapters "" ) <TAB>  except : <TAB><TAB>  packageDir = os . path . dirname ( __file__ ) <TAB>  for f in glob . glob ( os . path . join ( packageDir , "" *.py "" ) ) : <TAB><TAB>  mod = os . path . basename ( f ) . split ( os . path . extsep , 1 ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  register_adapter ( mod [ 1 : ] . replace ( "" _ "" , "" . "" ) , PackageImporter ( mod ) ) <TAB><TAB>  except ImportError : <TAB><TAB><TAB>  pass <TAB>  adapters_registered = True ","if mod == ""__init__"" or not mod . startswith ( ""_"" ) :",if mod == 'adapters':,False,22.541327211571332,92.6554329073541
533,"def load_modules ( <TAB>  to_load , load , attr , modules_dict , excluded_aliases , loading_message = None  ) : <TAB>  if loading_message : <TAB><TAB>  print ( loading_message ) <TAB>  for name in to_load : <TAB><TAB>  module = load ( name ) <TAB><TAB>  if module is None or not hasattr ( module , attr ) : <TAB><TAB><TAB>  continue <TAB><TAB>  cls = getattr ( module , attr ) <TAB><TAB>  if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if hasattr ( module , "" aliases "" ) : <TAB><TAB><TAB>  for alias in module . aliases ( ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  modules_dict [ alias ] = module <TAB><TAB>  else : <TAB><TAB><TAB>  modules_dict [ name ] = module <TAB>  if loading_message : <TAB><TAB>  print ( ) ",if alias not in excluded_aliases :,if alias not in excluded_aliases:,False,55.35038642936183,100.00000000000004
534,"def clean_items ( event , items , variations ) : <TAB>  for item in items : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB><TAB>  if item . has_variations : <TAB><TAB><TAB>  if not any ( var . item == item for var in variations ) : <TAB><TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB><TAB>  _ ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" One or more items has variations but none of these are in the variations list. "" <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  ) ",if event != item . event :,if not any(item.item == item for item in variations):,False,65.28565089332835,93.01753721390318
535,"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB>  for element in file_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return element <TAB><TAB>  if element [ 3 ] and element [ 4 ] : <TAB><TAB><TAB>  i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB><TAB><TAB>  if not isinstance ( i , int ) : <TAB><TAB><TAB><TAB>  return i <TAB><TAB><TAB>  idx = i <TAB><TAB>  else : <TAB><TAB><TAB>  idx + = 1 <TAB>  return idx ",if idx == num :,if idx == 0:,False,46.296940136563016,98.57740601266778
536,"def check ( chip , xeddb , chipdb ) : <TAB>  all_inst = [ ] <TAB>  undoc = [ ] <TAB>  for inst in xeddb . recs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if inst . undocumented : <TAB><TAB><TAB><TAB>  undoc . append ( inst ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  all_inst . append ( inst ) <TAB>  return ( all_inst , undoc ) ",if inst . isa_set in chipdb [ chip ] :,if inst.doc == chipdb.doc:,False,48.21171986883244,92.67490567184534
537,"def get_all_topic_src_files ( self ) : <TAB>  """"""Retrieves the file paths of all the topics in directory"""""" <TAB>  topic_full_paths = [ ] <TAB>  topic_names = os . listdir ( self . topic_dir ) <TAB>  for topic_name in topic_names : <TAB><TAB>  # Do not try to load hidden files. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  topic_full_path = os . path . join ( self . topic_dir , topic_name ) <TAB><TAB><TAB>  # Ignore the JSON Index as it is stored with topic files. <TAB><TAB><TAB>  if topic_full_path != self . index_file : <TAB><TAB><TAB><TAB>  topic_full_paths . append ( topic_full_path ) <TAB>  return topic_full_paths ","if not topic_name . startswith ( ""."" ) :","if os.path.isfile(self.topic_dir, topic_name):",False,68.0230101906624,93.54646628874727
538,"def _get_element ( dom_msi , tag_name , name = None , id_ = None ) : <TAB>  """"""Get a xml element defined on Product."""""" <TAB>  product = dom_msi . getElementsByTagName ( "" Product "" ) [ 0 ] <TAB>  elements = product . getElementsByTagName ( tag_name ) <TAB>  for element in elements : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  element . getAttribute ( "" Name "" ) == name <TAB><TAB><TAB><TAB>  and element . getAttribute ( "" Id "" ) == id_ <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  return element <TAB><TAB>  elif id_ : <TAB><TAB><TAB>  if element . getAttribute ( "" Id "" ) == id_ : <TAB><TAB><TAB><TAB>  return element ",if name and id_ :,if name:,False,53.54917536829797,97.96449892659433
539,"def __init__ ( self , * models ) : <TAB>  super ( ) . __init__ ( ) <TAB>  self . models = ModuleList ( models ) <TAB>  for m in models : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs) "" <TAB><TAB><TAB>  ) <TAB>  self . likelihood = LikelihoodList ( * [ m . likelihood for m in models ] ) ","if not hasattr ( m , ""likelihood"" ) :",if m.likelihood is None:,False,33.97251813708096,92.47592853689086
540,"def _sniff ( filename , oxlitype ) : <TAB>  try : <TAB><TAB>  with open ( filename , "" rb "" ) as fileobj : <TAB><TAB><TAB>  header = fileobj . read ( 4 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  fileobj . read ( 1 )<TAB># skip the version number <TAB><TAB><TAB><TAB>  ftype = fileobj . read ( 1 ) <TAB><TAB><TAB><TAB>  if binascii . hexlify ( ftype ) == oxlitype : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB>  return False <TAB>  except OSError : <TAB><TAB>  return False ","if header == b""OXLI"" :",if header == 'Version':,False,21.36875279611101,95.87630656151681
541,"def convert_port_bindings ( port_bindings ) : <TAB>  result = { } <TAB>  for k , v in six . iteritems ( port_bindings ) : <TAB><TAB>  key = str ( k ) <TAB><TAB>  if "" / "" not in key : <TAB><TAB><TAB>  key + = "" /tcp "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB><TAB>  else : <TAB><TAB><TAB>  result [ key ] = [ _convert_port_binding ( v ) ] <TAB>  return result ","if isinstance ( v , list ) :","if isinstance(v, list):",False,52.113442773961836,100.00000000000004
542,"def input_data ( self ) : <TAB>  gen = self . config . generator <TAB>  # don't try running the generator if we specify an output file explicitly, <TAB>  # otherwise generator may segfault and we end up returning the output file anyway <TAB>  if gen and ( not self . config [ "" out "" ] or not self . config [ "" in "" ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _run_generator ( gen , args = self . config . generator_args ) <TAB><TAB>  if self . _generated [ 0 ] : <TAB><TAB><TAB>  return self . _generated [ 0 ] <TAB>  # in file is optional <TAB>  return ( <TAB><TAB>  self . _normalize ( self . problem . problem_data [ self . config [ "" in "" ] ] ) <TAB><TAB>  if self . config [ "" in "" ] <TAB><TAB>  else b "" "" <TAB>  ) ",if self . _generated is None :,if self.config.generator_args:,False,66.32306759176538,97.21042930911841
543,"def __new__ ( cls , * tasks , * * kwargs ) : <TAB>  # This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z` <TAB>  if not kwargs and tasks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tasks = tasks [ 0 ] if len ( tasks ) == 1 else tasks <TAB><TAB><TAB>  return reduce ( operator . or_ , tasks ) <TAB>  return super ( chain , cls ) . __new__ ( cls , * tasks , * * kwargs ) ",if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,"if isinstance(tasks, tuple):",False,23.71722032756816,88.50728101279874
544,"def get_file_sources ( ) : <TAB>  global _file_sources <TAB>  if _file_sources is None : <TAB><TAB>  from galaxy . files import ConfiguredFileSources <TAB><TAB>  file_sources = None <TAB><TAB>  if os . path . exists ( "" file_sources.json "" ) : <TAB><TAB><TAB>  file_sources_as_dict = None <TAB><TAB><TAB>  with open ( "" file_sources.json "" , "" r "" ) as f : <TAB><TAB><TAB><TAB>  file_sources_as_dict = json . load ( f ) <TAB><TAB><TAB>  if file_sources_as_dict is not None : <TAB><TAB><TAB><TAB>  file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ConfiguredFileSources . from_dict ( [ ] ) <TAB><TAB>  _file_sources = file_sources <TAB>  return _file_sources ",if file_sources is None :,if file_sources is None:,False,51.831369750510014,100.00000000000004
545,"def InitializeColours ( self ) : <TAB>  """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB>  curr = self . _colourData . GetColour ( ) <TAB>  self . _colourSelection = - 1 <TAB>  for i in range ( 16 ) : <TAB><TAB>  c = self . _colourData . GetCustomColour ( i ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _customColours [ i ] = wx . WHITE <TAB><TAB>  if c == curr : <TAB><TAB><TAB>  self . _colourSelection = i ",if c . IsOk ( ) :,if c == wx.BLACK:,False,31.892834890763282,94.32548480253662
546,"def convert_obj_into_marshallable ( self , obj ) : <TAB>  if isinstance ( obj , self . marshalable_types ) : <TAB><TAB>  return obj <TAB>  if isinstance ( obj , array . array ) : <TAB><TAB>  if obj . typecode == "" c "" : <TAB><TAB><TAB>  return obj . tostring ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return obj . tounicode ( ) <TAB><TAB>  return obj . tolist ( ) <TAB>  return self . class_to_dict ( obj ) ","if obj . typecode == ""u"" :","if isinstance(obj, basestring):",False,24.359956662454483,93.21255477147334
547,"def run ( self ) : <TAB>  self . run_command ( "" egg_info "" ) <TAB>  from glob import glob <TAB>  for pattern in self . match : <TAB><TAB>  pattern = self . distribution . get_name ( ) + "" * "" + pattern <TAB><TAB>  files = glob ( os . path . join ( self . dist_dir , pattern ) ) <TAB><TAB>  files = [ ( os . path . getmtime ( f ) , f ) for f in files ] <TAB><TAB>  files . sort ( ) <TAB><TAB>  files . reverse ( ) <TAB><TAB>  log . info ( "" %d  file(s) matching  %s "" , len ( files ) , pattern ) <TAB><TAB>  files = files [ self . keep : ] <TAB><TAB>  for ( t , f ) in files : <TAB><TAB><TAB>  log . info ( "" Deleting  %s "" , f ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . unlink ( f ) ",if not self . dry_run :,if t == os.W_OK:,False,29.628288895859413,96.38648747377216
548,"def render_token_list ( self , tokens ) : <TAB>  result = [ ] <TAB>  vars = [ ] <TAB>  for token in tokens : <TAB><TAB>  if token . token_type == TOKEN_TEXT : <TAB><TAB><TAB>  result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( "" %% ( %s )s "" % token . contents ) <TAB><TAB><TAB>  vars . append ( token . contents ) <TAB>  return "" "" . join ( result ) , vars ",elif token . token_type == TOKEN_VAR :,if token.token_type == TOKEN_COMMENT:,False,51.10032683438388,96.74192712380358
549,"def _handle_raise ( self , values , is_NAs , origins ) : <TAB>  for is_NA , origin in zip ( is_NAs , origins ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg = ( <TAB><TAB><TAB><TAB>  "" Missing values detected. If you want rows with missing  "" <TAB><TAB><TAB><TAB>  "" values to be automatically deleted in a list-wise  "" <TAB><TAB><TAB><TAB>  "" manner (not recommended), please set dropna=True in  "" <TAB><TAB><TAB><TAB>  "" the Bambi Model initialization. "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  raise PatsyError ( msg , origin ) <TAB>  return values ",if np . any ( is_NA ) :,if values is None:,False,61.84508888682989,94.96372354471045
550,"def add_node_data ( node_array , ntwk ) : <TAB>  node_ntwk = nx . Graph ( ) <TAB>  newdata = { } <TAB>  for idx , data in ntwk . nodes ( data = True ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newdata [ "" value "" ] = node_array [ int ( idx ) - 1 ] <TAB><TAB><TAB>  data . update ( newdata ) <TAB><TAB><TAB>  node_ntwk . add_node ( int ( idx ) , * * data ) <TAB>  return node_ntwk ",if not int ( idx ) == 0 :,if idx < len(node_array):,False,29.728964144401022,93.70022852185787
551,"def safe_parse_date ( date_hdr ) : <TAB>  """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB>  try : <TAB><TAB>  if "" ; "" in date_hdr : <TAB><TAB><TAB>  date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB><TAB>  msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  else : <TAB><TAB><TAB>  return msg_ts <TAB>  except ( ValueError , TypeError , OverflowError ) : <TAB><TAB>  return None ",if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,if msg_ts < 0:,False,26.66052439337373,86.2953296435021
552,"def _route_db ( self , model , * * hints ) : <TAB>  chosen_db = None <TAB>  for router in self . routers : <TAB><TAB>  try : <TAB><TAB><TAB>  method = getattr ( router , action ) <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  # If the router doesn't have a method, skip to the next one. <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  chosen_db = method ( model , * * hints ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return chosen_db <TAB>  try : <TAB><TAB>  return hints [ "" instance "" ] . _state . db or DEFAULT_DB_ALIAS <TAB>  except KeyError : <TAB><TAB>  return DEFAULT_DB_ALIAS ",if chosen_db :,if chosen_db is not None:,False,57.4107962906734,97.83725519337358
553,"def get_keys ( struct , ignore_first_level = False ) : <TAB>  res = [ ] <TAB>  if isinstance ( struct , dict ) : <TAB><TAB>  if not ignore_first_level : <TAB><TAB><TAB>  keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB><TAB><TAB>  res . extend ( keys ) <TAB><TAB>  for key in struct : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB>  elif isinstance ( struct , list ) : <TAB><TAB>  for item in struct : <TAB><TAB><TAB>  res . extend ( get_keys ( item ) ) <TAB>  return res ",if key in IGNORED_KEYS :,if key in IGNORED_FIRST_LEVEL:,False,51.83536253755931,98.171260883257
554,"def launch_app ( self , fs_id ) : <TAB>  if fs_id in self . app_infos : <TAB><TAB>  row = self . get_row_by_fsid ( fs_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  app_info = self . app_infos [ fs_id ] <TAB><TAB>  filepath = os . path . join ( row [ SAVEDIR_COL ] , row [ SAVENAME_COL ] ) <TAB><TAB>  gfile = Gio . File . new_for_path ( filepath ) <TAB><TAB>  app_info . launch ( <TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB>  gfile , <TAB><TAB><TAB>  ] , <TAB><TAB><TAB>  None , <TAB><TAB>  ) <TAB><TAB>  self . app_infos . pop ( fs_id , None ) ",if not row :,if not row:,False,51.03019981942012,100.00000000000004
555,"def create_skipfile ( files_changed , skipfile ) : <TAB>  # File is likely to contain some garbage values at start, <TAB>  # only the corresponding json should be parsed. <TAB>  json_pattern = re . compile ( r "" ^ \ { .* \ } "" ) <TAB>  for line in files_changed . readlines ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for filename in json . loads ( line ) : <TAB><TAB><TAB><TAB>  if "" /COMMIT_MSG "" in filename : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  skipfile . write ( "" +*/ %s \n "" % filename ) <TAB>  skipfile . write ( "" -* \n "" ) ","if re . match ( json_pattern , line ) :","if re.search(json_pattern, line):",False,38.91731037773457,98.68238253530389
556,"def zscore ( self , client , request , N ) : <TAB>  check_input ( request , N != 2 ) <TAB>  key = request [ 1 ] <TAB>  db = client . db <TAB>  value = db . get ( key ) <TAB>  if value is None : <TAB><TAB>  client . reply_bulk ( None ) <TAB>  elif not isinstance ( value , self . zset_type ) : <TAB><TAB>  client . reply_wrongtype ( ) <TAB>  else : <TAB><TAB>  score = value . score ( request [ 2 ] , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  score = str ( score ) . encode ( "" utf-8 "" ) <TAB><TAB>  client . reply_bulk ( score ) ",if score is not None :,if score is not None:,False,51.86263213955385,100.00000000000004
557,"def _list_cases ( suite ) : <TAB>  for test in suite : <TAB><TAB>  if isinstance ( test , unittest . TestSuite ) : <TAB><TAB><TAB>  _list_cases ( test ) <TAB><TAB>  elif isinstance ( test , unittest . TestCase ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  print ( test . id ( ) ) ",if support . match_test ( test ) :,"if test.id() == 'test' and (not isinstance(test, unittest.",False,21.901477490549176,84.53757135446132
558,"def Run ( self ) : <TAB>  """"""The main run method of the client."""""" <TAB>  for thread in self . _threads . values ( ) : <TAB><TAB>  thread . start ( ) <TAB>  logging . info ( START_STRING ) <TAB>  while True : <TAB><TAB>  dead_threads = [ tn for ( tn , t ) in self . _threads . items ( ) if not t . isAlive ( ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise FatalError ( <TAB><TAB><TAB><TAB>  "" These threads are dead:  %r . Shutting down... "" % dead_threads <TAB><TAB><TAB>  ) <TAB><TAB>  time . sleep ( 10 ) ",if dead_threads :,if dead_threads:,False,56.62879649285932,100.00000000000004
559,"def _slice_queryset ( queryset , order_by , per_page , start ) : <TAB>  page_len = int ( per_page ) + 1 <TAB>  if start : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filter_name = "" %s __lte "" % order_by [ 1 : ] <TAB><TAB>  else : <TAB><TAB><TAB>  filter_name = "" %s __gte "" % order_by <TAB><TAB>  return queryset . filter ( * * { filter_name : start } ) [ : page_len ] <TAB>  return queryset [ : page_len ] ","if order_by . startswith ( ""-"" ) :",if page_len > 1:,False,42.37624284815355,92.68605383552718
560,"def compute_timer_precision ( timer ) : <TAB>  precision = None <TAB>  points = 0 <TAB>  timeout = timeout_timer ( ) + 1.0 <TAB>  previous = timer ( ) <TAB>  while timeout_timer ( ) < timeout or points < 5 : <TAB><TAB>  for _ in XRANGE ( 10 ) : <TAB><TAB><TAB>  t1 = timer ( ) <TAB><TAB><TAB>  t2 = timer ( ) <TAB><TAB><TAB>  dt = t2 - t1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  dt = t2 - previous <TAB><TAB><TAB>  if dt < = 0.0 : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  if precision is not None : <TAB><TAB><TAB>  precision = min ( precision , dt ) <TAB><TAB>  else : <TAB><TAB><TAB>  precision = dt <TAB><TAB>  points + = 1 <TAB><TAB>  previous = timer ( ) <TAB>  return precision ",if 0 < dt :,if dt <= 0.0:,False,30.754856140690567,98.11132534849867
561,"def findWorkingDir ( ) : <TAB>  frozen = getattr ( sys , "" frozen "" , "" "" ) <TAB>  if not frozen : <TAB><TAB>  path = os . path . dirname ( __file__ ) <TAB>  elif frozen in ( "" dll "" , "" console_exe "" , "" windows_exe "" , "" macosx_app "" ) : <TAB><TAB>  path = os . path . dirname ( <TAB><TAB><TAB>  os . path . dirname ( os . path . dirname ( os . path . dirname ( __file__ ) ) ) <TAB><TAB>  ) <TAB>  elif frozen :<TAB># needed for PyInstaller <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = getattr ( sys , "" _MEIPASS "" , "" "" )<TAB># --onefile <TAB><TAB>  else : <TAB><TAB><TAB>  path = os . path . dirname ( sys . executable )<TAB># --onedir <TAB>  else : <TAB><TAB>  path = "" "" <TAB>  return path ","if getattr ( sys , ""_MEIPASS"" , """" ) is not None :",if sys.platform == 'win32':,False,49.60486594741737,91.37589202664883
562,"def CreateDataType ( vmodlName , wsdlName , parent , version , props ) : <TAB>  with _lazyLock : <TAB><TAB>  dic = [ vmodlName , wsdlName , parent , version , props ] <TAB><TAB>  names = vmodlName . split ( "" . "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vmodlName = "" . "" . join ( name [ 0 ] . lower ( ) + name [ 1 : ] for name in names ) <TAB><TAB>  _AddToDependencyMap ( names ) <TAB><TAB>  typeNs = GetWsdlNamespace ( version ) <TAB><TAB>  _dataDefMap [ vmodlName ] = dic <TAB><TAB>  _wsdlDefMap [ ( typeNs , wsdlName ) ] = dic <TAB><TAB>  _wsdlTypeMapNSs . add ( typeNs ) ",if _allowCapitalizedNames :,if len(names) > 1:,False,38.6331230386248,95.59423179144767
563,"def ParseResponses ( <TAB>  self , <TAB>  knowledge_base : rdf_client . KnowledgeBase , <TAB>  responses : Iterable [ rdfvalue . RDFValue ] ,  ) - > Iterator [ rdf_client . User ] : <TAB>  for response in responses : <TAB><TAB>  if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB><TAB><TAB>  raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB><TAB>  # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB><TAB>  if stat . S_ISDIR ( int ( response . st_mode ) ) : <TAB><TAB><TAB>  homedir = response . pathspec . path <TAB><TAB><TAB>  username = os . path . basename ( homedir ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield rdf_client . User ( username = username , homedir = homedir ) ",if username not in self . _ignore_users :,if username == knowledge_base.username:,False,45.99967781078673,96.12354407851385
564,"def process_question ( qtxt ) : <TAB>  question = "" "" <TAB>  skip = False <TAB>  for letter in qtxt : <TAB><TAB>  if letter == "" < "" : <TAB><TAB><TAB>  skip = True <TAB><TAB>  if letter == "" > "" : <TAB><TAB><TAB>  skip = False <TAB><TAB>  if skip : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if letter == "" "" : <TAB><TAB><TAB><TAB>  letter = "" _ "" <TAB><TAB><TAB>  question + = letter . lower ( ) <TAB>  return question ","if letter . isalnum ( ) or letter == "" "" :",if letter.lower() == '-':,False,48.961151963205296,94.75866996609105
565,"def process_all ( self , lines , times = 1 ) : <TAB>  gap = False <TAB>  for _ in range ( times ) : <TAB><TAB>  for line in lines : <TAB><TAB><TAB>  if gap : <TAB><TAB><TAB><TAB>  self . write ( "" "" ) <TAB><TAB><TAB>  self . process ( line ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  gap = True <TAB>  return 0 ",if not is_command ( line ) :,if self.process_all(line):,False,46.16425807292755,95.00142014089772
566,"def _get ( self , domain ) : <TAB>  with self . lock : <TAB><TAB>  try : <TAB><TAB><TAB>  record = self . cache [ domain ] <TAB><TAB><TAB>  time_now = time . time ( ) <TAB><TAB><TAB>  if time_now - record [ "" update "" ] > self . ttl : <TAB><TAB><TAB><TAB>  record = None <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  record = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB><TAB>  # self.cache[domain] = record <TAB><TAB>  return record ",if not record :,if not self.cache.has_key(domain):,False,49.00673572980557,94.31596099214646
567,"def gen_constant_folding ( cw ) : <TAB>  types = [ "" Int32 "" , "" Double "" , "" BigInteger "" , "" Complex "" ] <TAB>  for cur_type in types : <TAB><TAB>  cw . enter_block ( "" if (constLeft.Value.GetType() == typeof( %s )) "" % ( cur_type , ) ) <TAB><TAB>  cw . enter_block ( "" switch (_op) "" ) <TAB><TAB>  for op in ops : <TAB><TAB><TAB>  gen = getattr ( op , "" genConstantFolding "" , None ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  gen ( cw , cur_type ) <TAB><TAB>  cw . exit_block ( ) <TAB><TAB>  cw . exit_block ( ) ",if gen is not None :,if gen is not None:,False,52.04885322896791,100.00000000000004
568,"def unreferenced_dummy ( self ) : <TAB>  for g , base in zip ( self . evgroups , self . evbases ) : <TAB><TAB>  for ind , j in enumerate ( g ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  debug_print ( <TAB><TAB><TAB><TAB><TAB>  "" replacing unreferenced  %d %s  with dummy "" % ( ( base + ind ) , g [ ind ] ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  g [ ind ] = "" dummy "" <TAB><TAB><TAB><TAB>  self . evnum [ base + ind ] = "" dummy "" ",if not self . indexobj [ base + ind ] :,if j == base:,False,46.01916209867388,94.03198143980786
569,"def handle_signature ( self , sig : str , signode : desc_signature ) - > Tuple [ str , str ] : <TAB>  for cls in self . __class__ . __mro__ : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  "" PyDecoratorMixin is deprecated.  "" <TAB><TAB><TAB><TAB>  "" Please check the implementation of  %s "" % cls , <TAB><TAB><TAB><TAB>  RemovedInSphinx50Warning , <TAB><TAB><TAB><TAB>  stacklevel = 2 , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  warnings . warn ( <TAB><TAB><TAB>  "" PyDecoratorMixin is deprecated "" , RemovedInSphinx50Warning , stacklevel = 2 <TAB><TAB>  ) <TAB>  ret = super ( ) . handle_signature ( sig , signode )<TAB># type: ignore <TAB>  signode . insert ( 0 , addnodes . desc_addname ( "" @ "" , "" @ "" ) ) <TAB>  return ret ","if cls . __name__ != ""DirectiveAdapter"" :",if cls.__name__ == sig:,False,32.82397331640565,96.65728444095342
570,"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB>  path . responses = [ ] <TAB>  n = 0 <TAB>  while response : <TAB><TAB>  path . responses . append ( response ) <TAB><TAB>  yield from response . iter_lines ( decode_unicode = True ) <TAB><TAB>  src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  n + = 1 <TAB><TAB>  if n > max_next : <TAB><TAB><TAB>  vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB><TAB><TAB>  break <TAB><TAB>  vd . status ( f "" fetching next page from  { src } "" ) <TAB><TAB>  response = requests . get ( src , stream = True ) ",if not src :,if not src:,False,40.971697913514404,100.00000000000004
571,"def ordered_indices ( self ) : <TAB>  with data_utils . numpy_seed ( self . seed , self . epoch ) : <TAB><TAB>  # Used to store the order of indices of each dataset to use <TAB><TAB>  indices = [ <TAB><TAB><TAB>  np . random . permutation ( len ( dataset ) ) for dataset in self . datasets . values ( ) <TAB><TAB>  ] <TAB><TAB>  # Keep track of which samples we've  used for each dataset <TAB><TAB>  counters = [ 0 for _ in self . datasets ] <TAB><TAB>  sampled_indices = [ <TAB><TAB><TAB>  self . _sample ( indices , counters ) for _ in range ( self . total_num_instances ) <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sampled_indices . sort ( key = lambda i : self . num_tokens ( i ) ) <TAB><TAB>  return np . array ( sampled_indices , dtype = np . int64 ) ",if self . sort_indices :,if self.num_tokens:,False,65.29642686068522,98.21313376160184
572,"def _build_columns ( self ) : <TAB>  self . columns = [ Column ( ) for col in self . keys ] <TAB>  for row in self : <TAB><TAB>  for ( col_idx , col_val ) in enumerate ( row ) : <TAB><TAB><TAB>  col = self . columns [ col_idx ] <TAB><TAB><TAB>  col . append ( col_val ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  col . is_quantity = False <TAB>  for ( idx , key_name ) in enumerate ( self . keys ) : <TAB><TAB>  self . columns [ idx ] . name = key_name <TAB>  self . x = Column ( ) <TAB>  self . ys = [ ] ",if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,if col.is_quantity:,False,23.59088569430505,89.75456833252359
573,"def tearDown ( self ) : <TAB>  subprocess_list = self . subprocess_list <TAB>  processes = subprocess_list . processes <TAB>  self . schedule . reset ( ) <TAB>  del self . schedule <TAB>  for proc in processes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  terminate_process ( proc . pid , kill_children = True , slow_stop = True ) <TAB>  subprocess_list . cleanup ( ) <TAB>  processes = subprocess_list . processes <TAB>  if processes : <TAB><TAB>  for proc in processes : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  terminate_process ( proc . pid , kill_children = True , slow_stop = False ) <TAB><TAB>  subprocess_list . cleanup ( ) <TAB>  processes = subprocess_list . processes <TAB>  if processes : <TAB><TAB>  log . warning ( "" Processes left running:  %s "" , processes ) ",if proc . is_alive ( ) :,if proc.pid:,False,44.99410396453442,93.05975381011928
574,"def colorNetwork ( cls , network , nodesInNetwork , nodeByID = None ) : <TAB>  for node in nodesInNetwork : <TAB><TAB>  node . use_custom_color = True <TAB><TAB>  neededCopies = sum ( socket . execution . neededCopies for socket in node . outputs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  color = ( 0.7 , 0.9 , 0.7 ) <TAB><TAB>  else : <TAB><TAB><TAB>  color = ( 1.0 , 0.3 , 0.3 ) <TAB><TAB>  node . color = color ",if neededCopies == 0 :,if neededCopies == 0:,False,52.142961781815686,100.00000000000004
575,"def _init_warmup_scheduler ( self , optimizer , states ) : <TAB>  updates_so_far = states . get ( "" number_training_updates "" , 0 ) <TAB>  if self . warmup_updates > 0 and ( <TAB><TAB>  updates_so_far < = self . warmup_updates or self . hard_reset <TAB>  ) : <TAB><TAB>  self . warmup_scheduler = optim . lr_scheduler . LambdaLR ( optimizer , self . _warmup_lr ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . warmup_scheduler . load_state_dict ( states [ "" warmup_scheduler "" ] ) <TAB>  else : <TAB><TAB>  self . warmup_scheduler = None ","if states . get ( ""warmup_scheduler"" ) :",if self.warmup_scheduler is not None:,False,20.559781172065264,94.36154781487471
576,"def inner ( self , * iargs , * * ikwargs ) : <TAB>  try : <TAB><TAB>  return getattr ( super ( VEXResilienceMixin , self ) , func ) ( * iargs , * * ikwargs ) <TAB>  except excs as e : <TAB><TAB>  for exc , handler in zip ( excs , handlers ) : <TAB><TAB><TAB>  if isinstance ( e , exc ) : <TAB><TAB><TAB><TAB>  v = getattr ( self , handler ) ( * iargs , * * ikwargs ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB><TAB>  return v <TAB><TAB>  assert False , "" this should be unreachable if Python is working correctly "" ",if v is raiseme :,if v is not None:,False,50.28662254154261,98.06574698915615
577,"def unwrap_envelope ( self , data , many ) : <TAB>  if many : <TAB><TAB>  if data [ "" items "" ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . context [ "" total "" ] = len ( data ) <TAB><TAB><TAB><TAB>  return data <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . context [ "" total "" ] = data [ "" total "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  self . context [ "" total "" ] = 0 <TAB><TAB><TAB>  data = { "" items "" : [ ] } <TAB><TAB>  return data [ "" items "" ] <TAB>  return data ","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :",if self.context.get('total'):,False,45.135198408247525,93.20230595697456
578,"def __subclasscheck__ ( self , cls ) : <TAB>  if self . __origin__ is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  "" Parameterized generics cannot be used with class  "" "" or instance checks "" <TAB><TAB><TAB>  ) <TAB><TAB>  return False <TAB>  if self is Generic : <TAB><TAB>  raise TypeError ( <TAB><TAB><TAB>  "" Class  %r  cannot be used with class  "" "" or instance checks "" % self <TAB><TAB>  ) <TAB>  return super ( ) . __subclasscheck__ ( cls ) ","if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :",if self.__origin__ is not None:,False,34.28354821053453,83.2201124989556
579,"def __init__ ( self , pyversions , coverage_service ) : <TAB>  build_matrix = "" "" <TAB>  for version in pyversions : <TAB><TAB>  build_matrix + = "" \n<TAB>  {} , "" . format ( <TAB><TAB><TAB>  version <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else "" py {} "" . format ( "" "" . join ( version . split ( "" . "" ) ) ) <TAB><TAB>  ) <TAB>  coverage_package = "" "" <TAB>  if coverage_service : <TAB><TAB>  coverage_package + = "" \n<TAB>  {} "" . format ( coverage_service . package ) <TAB>  coverage_package + = "" \n "" <TAB>  super ( Tox , self ) . __init__ ( <TAB><TAB>  "" tox.ini "" , <TAB><TAB>  TEMPLATE . format ( build_matrix = build_matrix , coverage_package = coverage_package ) , <TAB>  ) ","if version . startswith ( ""pypy"" )",if version == '.':,False,48.27210474830091,96.5663928856317
580,"def _get_app ( self , body = None ) : <TAB>  app = self . _app <TAB>  if app is None : <TAB><TAB>  try : <TAB><TAB><TAB>  tasks = self . tasks . tasks<TAB># is a group <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  tasks = self . tasks <TAB><TAB>  if len ( tasks ) : <TAB><TAB><TAB>  app = tasks [ 0 ] . _app <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  app = body . _app <TAB>  return app if app is not None else current_app ",if app is None and body is not None :,if body is not None:,False,35.35483329715966,95.45109789227834
581,"def logic ( ) : <TAB>  for v in [ True , False , None , 0 , True , None , None , 1 ] : <TAB><TAB>  yield clk . posedge <TAB><TAB>  xd . next = v <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yd . next = zd . next = None <TAB><TAB>  elif v : <TAB><TAB><TAB>  yd . next = zd . next = 11 <TAB><TAB>  else : <TAB><TAB><TAB>  yd . next = zd . next = 0 ",if v is None :,if v:,False,23.96445063296899,97.31241401892878
582,"def run ( self ) : <TAB>  eid = self . start_episode ( ) <TAB>  obs = self . env . reset ( ) <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  action = self . env . action_space . sample ( ) <TAB><TAB><TAB>  self . log_action ( eid , obs , action ) <TAB><TAB>  else : <TAB><TAB><TAB>  action = self . get_action ( eid , obs ) <TAB><TAB>  obs , reward , done , info = self . env . step ( action ) <TAB><TAB>  self . log_returns ( eid , reward , info = info ) <TAB><TAB>  if done : <TAB><TAB><TAB>  self . end_episode ( eid , obs ) <TAB><TAB><TAB>  obs = self . env . reset ( ) <TAB><TAB><TAB>  eid = self . start_episode ( ) ",if random . random ( ) < self . off_pol_frac :,if self.env.action_space:,False,48.11828925896962,94.29695920280147
583,"def tearDown ( self ) : <TAB>  os . chdir ( self . orig_working_dir ) <TAB>  sys . argv = self . orig_argv <TAB>  sys . stdout = self . orig_stdout <TAB>  sys . stderr = self . orig_stderr <TAB>  for dirname in [ "" lv_LV "" , "" ja_JP "" ] : <TAB><TAB>  locale_dir = os . path . join ( self . datadir , "" project "" , "" i18n "" , dirname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shutil . rmtree ( locale_dir ) ",if os . path . isdir ( locale_dir ) :,if os.path.exists(locale_dir):,False,51.0142870526778,98.21085431604638
584,"def sentry_set_scope ( process_context , entity , project , email = None , url = None ) : <TAB>  # Using GLOBAL_HUB means these tags will persist between threads. <TAB>  # Normally there is one hub per thread. <TAB>  with sentry_sdk . hub . GLOBAL_HUB . configure_scope ( ) as scope : <TAB><TAB>  scope . set_tag ( "" process_context "" , process_context ) <TAB><TAB>  scope . set_tag ( "" entity "" , entity ) <TAB><TAB>  scope . set_tag ( "" project "" , project ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  scope . user = { "" email "" : email } <TAB><TAB>  if url : <TAB><TAB><TAB>  scope . set_tag ( "" url "" , url ) ",if email :,if email:,False,61.70821527710125,100.00000000000004
585,"def getDataMax ( self ) : <TAB>  result = - Double . MAX_VALUE <TAB>  nCurves = self . chart . getNCurves ( ) <TAB>  for i in range ( nCurves ) : <TAB><TAB>  c = self . getSystemCurve ( i ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if c . getYAxis ( ) == Y_AXIS : <TAB><TAB><TAB>  nPoints = c . getNPoints ( ) <TAB><TAB><TAB>  for j in range ( nPoints ) : <TAB><TAB><TAB><TAB>  result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB>  if result == - Double . MAX_VALUE : <TAB><TAB>  return Double . NaN <TAB>  return result ",if not c . isVisible ( ) :,if c is None:,False,41.87449372690405,93.36464944811829
586,"def handle_starttag ( self , tag , attrs ) : <TAB>  if tag == "" link "" and ( "" rel "" , "" icon "" ) in attrs or ( "" rel "" , "" shortcut icon "" ) in attrs : <TAB><TAB>  href = None <TAB><TAB>  icon_type = None <TAB><TAB>  for attr , value in attrs : <TAB><TAB><TAB>  if attr == "" href "" : <TAB><TAB><TAB><TAB>  href = value <TAB><TAB><TAB>  elif attr == "" type "" : <TAB><TAB><TAB><TAB>  icon_type = value <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  mimetype = extension_to_mimetype ( href . rpartition ( "" . "" ) [ 2 ] ) <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  icon_type = mimetype <TAB><TAB><TAB>  if icon_type : <TAB><TAB><TAB><TAB>  self . icons . append ( ( href , icon_type ) ) ",if href :,if href:,False,51.54225691858968,100.00000000000004
587,"def get_version ( version_file = STATIC_VERSION_FILE ) : <TAB>  version_info = get_static_version_info ( version_file ) <TAB>  version = version_info [ "" version "" ] <TAB>  if version == "" __use_git__ "" : <TAB><TAB>  version = get_version_from_git ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  version = get_version_from_git_archive ( version_info ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  version = Version ( "" unknown "" , None , None ) <TAB><TAB>  return pep440_format ( version ) <TAB>  else : <TAB><TAB>  return version ",if not version :,if version == None:,False,21.817554824259055,94.3907924399026
588,"def _Sleep ( self , seconds ) : <TAB>  if threading . current_thread ( ) is not self . _worker_thread : <TAB><TAB>  return self . _original_sleep ( seconds ) <TAB>  self . _time + = seconds <TAB>  self . _budget - = seconds <TAB>  while self . _budget < 0 : <TAB><TAB>  self . _worker_thread_turn . clear ( ) <TAB><TAB>  self . _owner_thread_turn . set ( ) <TAB><TAB>  self . _worker_thread_turn . wait ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise FakeTimeline . _WorkerThreadExit ( ) ",if self . _worker_thread_done :,if self._budget == 0:,False,19.228686254495837,95.94612366592149
589,"def validate_attributes ( self ) : <TAB>  if not ( self . has_variants or self . variant_of ) : <TAB><TAB>  return <TAB>  if not self . variant_based_on : <TAB><TAB>  self . variant_based_on = "" Item Attribute "" <TAB>  if self . variant_based_on == "" Item Attribute "" : <TAB><TAB>  attributes = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( _ ( "" Attribute table is mandatory "" ) ) <TAB><TAB>  for d in self . attributes : <TAB><TAB><TAB>  if d . attribute in attributes : <TAB><TAB><TAB><TAB>  frappe . throw ( <TAB><TAB><TAB><TAB><TAB>  _ ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" Attribute  {0}  selected multiple times in Attributes Table "" <TAB><TAB><TAB><TAB><TAB>  ) . format ( d . attribute ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  attributes . append ( d . attribute ) ",if not self . attributes :,if not self.attributes:,False,56.38795912765264,100.00000000000004
590,"def check_digest_auth ( user , passwd ) : <TAB>  """"""Check user authentication using HTTP Digest auth"""""" <TAB>  if request . headers . get ( "" Authorization "" ) : <TAB><TAB>  credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB><TAB>  if not credentails : <TAB><TAB><TAB>  return <TAB><TAB>  response_hash = response ( <TAB><TAB><TAB>  credentails , <TAB><TAB><TAB>  passwd , <TAB><TAB><TAB>  dict ( <TAB><TAB><TAB><TAB>  uri = request . script_root + request . path , <TAB><TAB><TAB><TAB>  body = request . data , <TAB><TAB><TAB><TAB>  method = request . method , <TAB><TAB><TAB>  ) , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  return False ","if credentails . get ( ""response"" ) == response_hash :",if response_hash == user:,False,31.984409305879698,94.9940775542194
591,"def _get_index_type ( return_index_type , ctx ) : <TAB>  if return_index_type is None :<TAB># pragma: no cover <TAB><TAB>  if ctx . running_mode == RunningMode . local : <TAB><TAB><TAB>  return_index_type = "" object "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return_index_type = "" filename "" <TAB><TAB>  else : <TAB><TAB><TAB>  return_index_type = "" bytes "" <TAB>  return return_index_type ",elif ctx . running_mode == RunningMode . local_cluster :,if ctx.running_mode == RunningMode.filename:,False,44.163622389504255,93.28340704326047
592,"def iter_event_handlers ( <TAB>  self , <TAB>  resource : resources_ . Resource , <TAB>  event : bodies . RawEvent ,  ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB>  warnings . warn ( <TAB><TAB>  "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB><TAB>  "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB><TAB>  DeprecationWarning , <TAB>  ) <TAB>  cause = _create_watching_cause ( resource , event ) <TAB>  for handler in self . _handlers : <TAB><TAB>  if not isinstance ( handler , handlers . ResourceWatchingHandler ) : <TAB><TAB><TAB>  pass <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield handler ","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",if cause is not None:,False,24.860170804821816,88.97752305546489
593,"def subprocess_post_check ( <TAB>  completed_process : subprocess . CompletedProcess , raise_error : bool = True  ) - > None : <TAB>  if completed_process . returncode : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB><TAB>  if completed_process . stderr is not None : <TAB><TAB><TAB>  print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB><TAB>  if raise_error : <TAB><TAB><TAB>  raise PipxError ( <TAB><TAB><TAB><TAB>  f "" { ' ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  logger . info ( f "" { ' ' . join ( completed_process . args ) !r}  failed "" ) ",if completed_process . stdout is not None :,if completed_process.stdout is not None:,False,20.416812520068373,100.00000000000004
594,"def __pow__ ( self , power ) : <TAB>  if power == 1 : <TAB><TAB>  return self <TAB>  if power == - 1 : <TAB><TAB>  # HACK: break cycle <TAB><TAB>  from cirq . devices import line_qubit <TAB><TAB>  decomposed = protocols . decompose_once_with_qubits ( <TAB><TAB><TAB>  self , qubits = line_qubit . LineQid . for_gate ( self ) , default = None <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return NotImplemented <TAB><TAB>  inverse_decomposed = protocols . inverse ( decomposed , None ) <TAB><TAB>  if inverse_decomposed is None : <TAB><TAB><TAB>  return NotImplemented <TAB><TAB>  return _InverseCompositeGate ( self ) <TAB>  return NotImplemented ",if decomposed is None :,if decomposed is None:,False,51.050008627897206,98.22289660879709
595,"def tearDown ( self ) : <TAB>  """"""Close the application after tests"""""" <TAB>  # set it back to it's old position so not to annoy users :-) <TAB>  self . old_pos = self . dlg . rectangle <TAB>  # close the application <TAB>  self . dlg . menu_select ( "" File->Exit "" ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . app . UntitledNotepad [ "" Do&n ' t Save "" ] . click ( ) <TAB><TAB><TAB>  self . app . UntitledNotepad . wait_not ( "" visible "" ) <TAB>  except Exception : <TAB><TAB>  pass <TAB>  finally : <TAB><TAB>  self . app . kill ( ) ","if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :",if self.app.is_running():,False,65.35207790421967,91.87297749669662
596,"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB>  <IF-STMT>: <TAB><TAB>  if log : <TAB><TAB><TAB>  log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB><TAB>  proc . terminate ( ) <TAB><TAB>  timeout_time = time . time ( ) + timeout <TAB><TAB>  while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB><TAB><TAB>  time . sleep ( 0.02 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if log : <TAB><TAB><TAB><TAB>  log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB><TAB><TAB>  proc . kill ( ) <TAB>  return proc . returncode ",if proc . poll ( ) is None :,if proc.poll() is None:,False,43.437851276743345,95.24479248604167
597,"def validate ( self , detection , expectation ) : <TAB>  config = SigmaConfiguration ( ) <TAB>  self . basic_rule [ "" detection "" ] = detection <TAB>  with patch ( "" yaml.safe_load_all "" , return_value = [ self . basic_rule ] ) : <TAB><TAB>  parser = SigmaCollectionParser ( "" any sigma io "" , config , None ) <TAB><TAB>  backend = SQLiteBackend ( config , self . table ) <TAB><TAB>  assert len ( parser . parsers ) == 1 <TAB><TAB>  for p in parser . parsers : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( expectation , backend . generate ( p ) ) <TAB><TAB><TAB>  elif isinstance ( expectation , Exception ) : <TAB><TAB><TAB><TAB>  self . assertRaises ( type ( expectation ) , backend . generate , p ) ","if isinstance ( expectation , str ) :","if isinstance(p, SigmaCollectionParser):",False,25.60384241729876,97.98429922026527
598,"def makelist ( d ) : <TAB>  """"""Convert d into a list if all the keys of d are integers."""""" <TAB>  if isinstance ( d , dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ makelist ( d [ k ] ) for k in sorted ( d , key = int ) ] <TAB><TAB>  else : <TAB><TAB><TAB>  return web . storage ( ( k , makelist ( v ) ) for k , v in d . items ( ) ) <TAB>  else : <TAB><TAB>  return d ",if all ( isint ( k ) for k in d ) :,"if isinstance(d, int):",False,34.824128438215155,92.18202281668201
599,"def __share_local_dir ( self , lpath , rpath , fast ) : <TAB>  result = const . ENoError <TAB>  for walk in self . __walk_normal_file ( lpath ) : <TAB><TAB>  ( dirpath , dirnames , filenames ) = walk <TAB><TAB>  for filename in filenames : <TAB><TAB><TAB>  rpart = os . path . relpath ( dirpath , lpath ) <TAB><TAB><TAB>  if rpart == "" . "" : <TAB><TAB><TAB><TAB>  rpart = "" "" <TAB><TAB><TAB>  subr = self . __share_local_file ( <TAB><TAB><TAB><TAB>  joinpath ( dirpath , filename ) , <TAB><TAB><TAB><TAB>  posixpath . join ( rpath , rpart , filename ) , <TAB><TAB><TAB><TAB>  fast , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result = subr <TAB>  return result ",if subr != const . ENoError :,if subr is not const.ENoError:,False,50.81891957208629,98.58272448466258
600,"def _targets ( self , sigmaparser ) : <TAB>  # build list of matching target mappings <TAB>  targets = set ( ) <TAB>  for condfield in self . conditions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rulefieldvalues = sigmaparser . values [ condfield ] <TAB><TAB><TAB>  for condvalue in self . conditions [ condfield ] : <TAB><TAB><TAB><TAB>  if condvalue in rulefieldvalues : <TAB><TAB><TAB><TAB><TAB>  targets . update ( self . conditions [ condfield ] [ condvalue ] ) <TAB>  return targets ",if condfield in sigmaparser . values :,if condfield in sigmaparser.values:,False,32.47392453932717,100.00000000000004
601,"def _wrapped_view ( request , * args , * * kwargs ) : <TAB>  # based on authority/decorators.py <TAB>  user = request . user <TAB>  if user . is_authenticated ( ) : <TAB><TAB>  obj = _resolve_lookup ( obj_lookup , kwargs ) <TAB><TAB>  perm_obj = _resolve_lookup ( perm_obj_lookup , kwargs ) <TAB><TAB>  granted = access . has_perm_or_owns ( user , perm , obj , perm_obj , owner_attr ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return view_func ( request , * args , * * kwargs ) <TAB>  # In all other cases, permission denied <TAB>  return HttpResponseForbidden ( ) ",if granted or user . has_perm ( perm ) :,if granted:,False,12.87944230088981,94.02707987013319
602,"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB>  cleaned_parts = [ ] <TAB>  for earlier in earlier_parts : <TAB><TAB>  earlier_part = earlier [ "" part "" ] <TAB><TAB>  earlier_step = earlier [ "" step "" ] <TAB><TAB>  found = False <TAB><TAB>  for current in current_parts : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  found = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if not found : <TAB><TAB><TAB>  cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB>  self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB>  for expected in expected_parts : <TAB><TAB>  self . assertThat ( cleaned_parts , Contains ( expected ) , hint ) ","if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :",if current.part == earlier_part and current.step == earlier_step:,False,21.83552231450706,92.87884993076705
603,"def show_image ( self , wnd_name , img ) : <TAB>  if wnd_name in self . named_windows : <TAB><TAB>  if self . named_windows [ wnd_name ] == 0 : <TAB><TAB><TAB>  self . named_windows [ wnd_name ] = 1 <TAB><TAB><TAB>  self . on_create_window ( wnd_name ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . capture_mouse ( wnd_name ) <TAB><TAB>  self . on_show_image ( wnd_name , img ) <TAB>  else : <TAB><TAB>  print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" ) ",if wnd_name in self . capture_mouse_windows :,"if self.on_show_window(wnd_name, img):",False,23.37889104039427,93.23825579436837
604,"def readlines ( self , hint = None ) : <TAB>  # Again, allow hint but ignore <TAB>  body = self . _get_body ( ) <TAB>  rest = body [ self . position : ] <TAB>  self . position = len ( body ) <TAB>  result = [ ] <TAB>  while 1 : <TAB><TAB>  next = rest . find ( "" \r \n "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( rest ) <TAB><TAB><TAB>  break <TAB><TAB>  result . append ( rest [ : next + 2 ] ) <TAB><TAB>  rest = rest [ next + 2 : ] <TAB>  return result ",if next == - 1 :,if next == -1:,False,54.13635490934776,100.00000000000004
605,"def __lt__ ( self , other ) : <TAB>  olen = len ( other ) <TAB>  for i in range ( olen ) : <TAB><TAB>  try : <TAB><TAB><TAB>  c = self [ i ] < other [ i ] <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  # self must be shorter <TAB><TAB><TAB>  return True <TAB><TAB>  if c : <TAB><TAB><TAB>  return c <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB>  return len ( self ) < olen ",elif other [ i ] < self [ i ] :,if c == other:,False,52.019703147417374,92.49077629952401
606,"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB>  provider = backend . name <TAB>  social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB>  if social : <TAB><TAB>  if user and social . user != user : <TAB><TAB><TAB>  msg = "" This account is already in use. "" <TAB><TAB><TAB>  raise AuthAlreadyAssociated ( backend , msg ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  user = social . user <TAB>  return { <TAB><TAB>  "" social "" : social , <TAB><TAB>  "" user "" : user , <TAB><TAB>  "" is_new "" : user is None , <TAB><TAB>  "" new_association "" : social is None , <TAB>  } ",elif not user :,if user is None:,False,50.95657050909965,97.34800916330724
607,"def markUVs ( self , indices = None ) : <TAB>  if isinstance ( indices , tuple ) : <TAB><TAB>  indices = indices [ 0 ] <TAB>  ntexco = len ( self . texco ) <TAB>  if indices is None : <TAB><TAB>  self . utexc = True <TAB>  else : <TAB><TAB>  if self . utexc is False : <TAB><TAB><TAB>  self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . utexc [ indices ] = True ",if self . utexc is not True :,if indices is not None:,False,44.32389758098134,94.92558851004794
608,"def destination ( self , type , name , arglist ) : <TAB>  classname = "" ResFunction "" <TAB>  listname = "" functions "" <TAB>  if arglist : <TAB><TAB>  t , n , m = arglist [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  classname = "" ResMethod "" <TAB><TAB><TAB>  listname = "" resmethods "" <TAB>  return classname , listname ","if t == ""Handle"" and m == ""InMode"" :",if t == type:,False,22.10687331235487,88.73365790798407
609,"def select ( self , regions , register ) : <TAB>  self . view . sel ( ) . clear ( ) <TAB>  to_store = [ ] <TAB>  for r in regions : <TAB><TAB>  self . view . sel ( ) . add ( r ) <TAB><TAB>  if register : <TAB><TAB><TAB>  to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB>  if register : <TAB><TAB>  text = "" "" . join ( to_store ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = text + "" \n "" <TAB><TAB>  state = State ( self . view ) <TAB><TAB>  state . registers [ register ] = [ text ] ","if not text . endswith ( ""\n"" ) :",if text != '':,False,35.55993245129808,93.966906163856
610,"def _skip_start ( self ) : <TAB>  start , stop = self . start , self . stop <TAB>  for chunk in self . app_iter : <TAB><TAB>  self . _pos + = len ( chunk ) <TAB><TAB>  if self . _pos < start : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return b "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  chunk = chunk [ start - self . _pos : ] <TAB><TAB><TAB>  if stop is not None and self . _pos > stop : <TAB><TAB><TAB><TAB>  chunk = chunk [ : stop - self . _pos ] <TAB><TAB><TAB><TAB>  assert len ( chunk ) == stop - start <TAB><TAB><TAB>  return chunk <TAB>  else : <TAB><TAB>  raise StopIteration ( ) ",elif self . _pos == start :,if start is None:,False,25.657841652275277,95.87022316549444
611,"def start ( self ) : <TAB>  self . on_config_change ( ) <TAB>  self . start_config_watch ( ) <TAB>  try : <TAB><TAB>  if self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" tcp "" ] . lower ( ) == "" on "" : <TAB><TAB><TAB>  self . startTCP ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . startUDP ( ) <TAB>  except socket . error as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shutdown ( <TAB><TAB><TAB><TAB>  "" \n [DNS] Unable to start DNS server on port  {} : port already in use "" . format ( <TAB><TAB><TAB><TAB><TAB>  self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" port "" ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) ","if ""Address already in use"" in e :",if e.errno == errno.EADDRINUSE:,False,37.33031065032584,96.03327042349544
612,"def ignore ( self , other ) : <TAB>  if isinstance ( other , Suppress ) : <TAB><TAB>  if other not in self . ignoreExprs : <TAB><TAB><TAB>  super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB>  else : <TAB><TAB>  super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB>  return self ",if self . expr is not None :,if self.ignoreExprs:,False,22.304297212742956,87.7707588640587
613,"def test_relative_deploy_path_override ( ) : <TAB>  s = Site ( TEST_SITE_ROOT ) <TAB>  s . load ( ) <TAB>  res = s . content . resource_from_relative_path ( <TAB><TAB>  "" blog/2010/december/merry-christmas.html "" <TAB>  ) <TAB>  res . relative_deploy_path = "" blog/2010/december/happy-holidays.html "" <TAB>  for page in s . content . walk_resources ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert page . relative_deploy_path == "" blog/2010/december/happy-holidays.html "" <TAB><TAB>  else : <TAB><TAB><TAB>  assert page . relative_deploy_path == Folder ( page . relative_path ) ",if res . source_file == page . source_file :,if page.is_main_page():,False,21.411092802193725,93.65079564074851
614,"def _parser ( cls , buf ) : <TAB>  tlvs = [ ] <TAB>  while buf : <TAB><TAB>  tlv_type = LLDPBasicTLV . get_type ( buf ) <TAB><TAB>  tlv = cls . _tlv_parsers [ tlv_type ] ( buf ) <TAB><TAB>  tlvs . append ( tlv ) <TAB><TAB>  offset = LLDP_TLV_SIZE + tlv . len <TAB><TAB>  buf = buf [ offset : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  assert len ( buf ) > 0 <TAB>  lldp_pkt = cls ( tlvs ) <TAB>  assert lldp_pkt . _tlvs_len_valid ( ) <TAB>  assert lldp_pkt . _tlvs_valid ( ) <TAB>  return lldp_pkt , None , buf ",if tlv . tlv_type == LLDP_TLV_END :,if offset >= LLDP_TLV_SIZE:,False,27.950132372281715,94.91818872330445
615,"def _do_pull ( self , repo , pull_kwargs , silent , ignore_pull_failures ) : <TAB>  try : <TAB><TAB>  output = self . client . pull ( repo , * * pull_kwargs ) <TAB><TAB>  if silent : <TAB><TAB><TAB>  with open ( os . devnull , "" w "" ) as devnull : <TAB><TAB><TAB><TAB>  yield from stream_output ( output , devnull ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield from stream_output ( output , sys . stdout ) <TAB>  except ( StreamOutputError , NotFound ) as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB><TAB>  else : <TAB><TAB><TAB>  log . error ( str ( e ) ) ",if not ignore_pull_failures :,if ignore_pull_failures:,False,45.1358610361563,98.70554757786368
616,def _collect_bytecode ( ordered_code ) : <TAB>  bytecode_blocks = [ ] <TAB>  stack = [ ordered_code ] <TAB>  while stack : <TAB><TAB>  code = stack . pop ( ) <TAB><TAB>  bytecode_blocks . append ( code . co_code ) <TAB><TAB>  for const in code . co_consts : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  stack . append ( const ) <TAB>  return bytecode_blocks ,"if isinstance ( const , blocks . OrderedCode ) :",if const.co_code == ordered_code:,False,20.25540389062596,91.27817854136181
617,"def displayhook ( value ) : <TAB>  if value is None : <TAB><TAB>  return <TAB>  builtins = modules [ "" builtins "" ] <TAB>  # Set '_' to None to avoid recursion <TAB>  builtins . _ = None <TAB>  text = repr ( value ) <TAB>  try : <TAB><TAB>  local_stdout = stdout <TAB>  except NameError as e : <TAB><TAB>  raise RuntimeError ( "" lost sys.stdout "" ) from e <TAB>  try : <TAB><TAB>  local_stdout . write ( text ) <TAB>  except UnicodeEncodeError : <TAB><TAB>  bytes = text . encode ( local_stdout . encoding , "" backslashreplace "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  local_stdout . buffer . write ( bytes ) <TAB><TAB>  else : <TAB><TAB><TAB>  text = bytes . decode ( local_stdout . encoding , "" strict "" ) <TAB><TAB><TAB>  local_stdout . write ( text ) <TAB>  local_stdout . write ( "" \n "" ) <TAB>  builtins . _ = value ","if hasattr ( local_stdout , ""buffer"" ) :",if bytes:,False,55.96756504544677,95.50819866434092
618,"def _analyze ( self ) : <TAB>  lines = open ( self . log_path , "" r "" ) . readlines ( ) <TAB>  prev_line = None <TAB>  for line in lines : <TAB><TAB>  if line . startswith ( "" ERROR: "" ) and prev_line and prev_line . startswith ( "" = "" ) : <TAB><TAB><TAB>  self . errors . append ( line [ len ( "" ERROR: "" ) : ] . strip ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . failures . append ( line [ len ( "" FAIL: "" ) : ] . strip ( ) ) <TAB><TAB>  prev_line = line ","elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :",if line.startswith('FAIL:,False,49.60273493393161,86.14479738042587
619,"def _flush ( self ) : <TAB>  if self . _data : <TAB><TAB>  if self . _last is not None : <TAB><TAB><TAB>  text = "" "" . join ( self . _data ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  assert self . _last . tail is None , "" internal error (tail) "" <TAB><TAB><TAB><TAB>  self . _last . tail = text <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  assert self . _last . text is None , "" internal error (text) "" <TAB><TAB><TAB><TAB>  self . _last . text = text <TAB><TAB>  self . _data = [ ] ",if self . _tail :,if text:,False,27.070577574668796,97.06115610786557
620,"def write ( self , chunk ) : <TAB>  consumer = self . _current_consumer <TAB>  server_side = consumer . server_side <TAB>  if server_side : <TAB><TAB>  server_side . data_received ( chunk ) <TAB>  else : <TAB><TAB>  consumer . message + = chunk <TAB><TAB>  assert consumer . in_parser . execute ( chunk , len ( chunk ) ) == len ( chunk ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  consumer . finished ( ) ",if consumer . in_parser . is_message_complete ( ) :,if consumer.finished():,False,19.13416903239313,92.01310853198252
621,"def _api_change_cat ( name , output , kwargs ) : <TAB>  """"""API: accepts output, value(=nzo_id), value2(=category)"""""" <TAB>  value = kwargs . get ( "" value "" ) <TAB>  value2 = kwargs . get ( "" value2 "" ) <TAB>  if value and value2 : <TAB><TAB>  nzo_id = value <TAB><TAB>  cat = value2 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cat = None <TAB><TAB>  result = sabnzbd . NzbQueue . change_cat ( nzo_id , cat ) <TAB><TAB>  return report ( output , keyword = "" status "" , data = bool ( result > 0 ) ) <TAB>  else : <TAB><TAB>  return report ( output , _MSG_NO_VALUE ) ","if cat == ""None"" :",if cat is None:,False,22.69324819375539,96.72862032546522
622,"def get_allocated_address ( <TAB>  self , config : ActorPoolConfig , allocated : allocated_type  ) - > str : <TAB>  addresses = config . get_external_addresses ( label = self . label ) <TAB>  for addr in addresses : <TAB><TAB>  occupied = False <TAB><TAB>  for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  occupied = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if not occupied : <TAB><TAB><TAB>  return addr <TAB>  raise NoIdleSlot ( <TAB><TAB>  f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB>  ) ",if strategy == self :,if strategy.is_active(address):,False,52.57703671262362,95.66908092674872
623,"def schedule_logger ( job_id = None , delete = False ) : <TAB>  if not job_id : <TAB><TAB>  return getLogger ( "" fate_flow_schedule "" ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with LoggerFactory . lock : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  if job_id in key : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  del LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  return True <TAB><TAB>  key = job_id + "" schedule "" <TAB><TAB>  if key in LoggerFactory . schedule_logger_dict : <TAB><TAB><TAB>  return LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB>  return LoggerFactory . get_schedule_logger ( job_id ) ",if delete :,if delete:,False,52.19082539408474,100.00000000000004
624,"def quick_load ( tool_file , async_load = True ) : <TAB>  try : <TAB><TAB>  tool = self . load_tool ( tool_file , tool_cache_data_dir ) <TAB><TAB>  self . __add_tool ( tool , load_panel_dict , elems ) <TAB><TAB>  # Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file. <TAB><TAB>  key = "" tool_ %s "" % str ( tool . id ) <TAB><TAB>  integrated_elems [ key ] = tool <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _load_tool_panel ( ) <TAB><TAB><TAB>  self . _save_integrated_tool_panel ( ) <TAB><TAB>  return tool . id <TAB>  except Exception : <TAB><TAB>  log . exception ( "" Failed to load potential tool  %s . "" , tool_file ) <TAB><TAB>  return None ",if async_load :,if async_load:,False,65.72599246186954,100.00000000000004
625,"def _get_default_ordering ( self ) : <TAB>  try : <TAB><TAB>  ordering = super ( DocumentChangeList , self ) . _get_default_ordering ( ) <TAB>  except AttributeError : <TAB><TAB>  ordering = [ ] <TAB><TAB>  if self . model_admin . ordering : <TAB><TAB><TAB>  ordering = self . model_admin . ordering <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ordering = self . lookup_opts . ordering <TAB>  return ordering ",elif self . lookup_opts . ordering :,if self.lookup_opts.ordering:,False,30.50957876433432,97.97945634141097
626,"def names ( self , persistent = None ) : <TAB>  u = set ( ) <TAB>  result = [ ] <TAB>  for s in [ <TAB><TAB>  self . __storage ( None ) , <TAB><TAB>  self . __storage ( self . __category ) , <TAB>  ] : <TAB><TAB>  for b in s : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if b . name . startswith ( "" __ "" ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if b . name not in u : <TAB><TAB><TAB><TAB>  result . append ( b . name ) <TAB><TAB><TAB><TAB>  u . add ( b . name ) <TAB>  return result ",if persistent is not None and b . persistent != persistent :,if b.name.startswith('_'):,False,46.977241105372556,94.46325110429488
627,"def common_check_get_messages_query ( <TAB>  self , query_params : Dict [ str , object ] , expected : str  ) - > None : <TAB>  user_profile = self . example_user ( "" hamlet "" ) <TAB>  request = POSTRequestMock ( query_params , user_profile ) <TAB>  with queries_captured ( ) as queries : <TAB><TAB>  get_messages_backend ( request , user_profile ) <TAB>  for query in queries : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sql = str ( query [ "" sql "" ] ) . replace ( ""  /* get_messages */ "" , "" "" ) <TAB><TAB><TAB>  self . assertEqual ( sql , expected ) <TAB><TAB><TAB>  return <TAB>  raise AssertionError ( "" get_messages query not found "" ) ","if ""/* get_messages */"" in query [ ""sql"" ] :",if query['type'] == 'GET':,False,47.79719107505488,91.89586782359035
628,"def _activate_only_current_top_active ( ) : <TAB>  for i in range ( 0 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  current_sequence ( ) . tracks [ i ] . active = True <TAB><TAB>  else : <TAB><TAB><TAB>  current_sequence ( ) . tracks [ i ] . active = False <TAB>  gui . tline_column . widget . queue_draw ( ) ",if i == current_sequence ( ) . get_first_active_track ( ) . id :,if current_sequence().tracks[i].active:,False,44.79531593050984,87.75692243549246
629,"def http_wrapper ( self , url , postdata = { } ) : <TAB>  try : <TAB><TAB>  if postdata != { } : <TAB><TAB><TAB>  f = urllib . urlopen ( url , postdata ) <TAB><TAB>  else : <TAB><TAB><TAB>  f = urllib . urlopen ( url ) <TAB><TAB>  response = f . read ( ) <TAB>  except : <TAB><TAB>  import traceback <TAB><TAB>  import logging , sys <TAB><TAB>  cla , exc , tb = sys . exc_info ( ) <TAB><TAB>  logging . error ( url ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logging . error ( "" with post data "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  logging . error ( "" without post data "" ) <TAB><TAB>  logging . error ( exc . args ) <TAB><TAB>  logging . error ( traceback . format_tb ( tb ) ) <TAB><TAB>  response = "" "" <TAB>  return response ",if postdata :,if exc.args[0] == 'POST':,False,25.073654664864918,95.85486183404723
630,"def frequent_thread_switches ( ) : <TAB>  """"""Make concurrency bugs more likely to manifest."""""" <TAB>  interval = None <TAB>  <IF-STMT>: <TAB><TAB>  if hasattr ( sys , "" getswitchinterval "" ) : <TAB><TAB><TAB>  interval = sys . getswitchinterval ( ) <TAB><TAB><TAB>  sys . setswitchinterval ( 1e-6 ) <TAB><TAB>  else : <TAB><TAB><TAB>  interval = sys . getcheckinterval ( ) <TAB><TAB><TAB>  sys . setcheckinterval ( 1 ) <TAB>  try : <TAB><TAB>  yield <TAB>  finally : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if hasattr ( sys , "" setswitchinterval "" ) : <TAB><TAB><TAB><TAB>  sys . setswitchinterval ( interval ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  sys . setcheckinterval ( interval ) ","if not sys . platform . startswith ( ""java"" ) :",if sys.platform == 'win32':,False,24.76957616532766,89.39841672493509
631,"def iter_filters ( filters , block_end = False ) : <TAB>  queue = deque ( filters ) <TAB>  while queue : <TAB><TAB>  f = queue . popleft ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if block_end : <TAB><TAB><TAB><TAB>  queue . appendleft ( None ) <TAB><TAB><TAB>  for gf in f . filters : <TAB><TAB><TAB><TAB>  queue . appendleft ( gf ) <TAB><TAB>  yield f ","if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :",if f.filters is not None:,False,25.893647119941416,85.28613726676396
632,"def smartsplit ( code ) : <TAB>  """"""Split `code` at "" symbol, only if it is not escaped."""""" <TAB>  strings = [ ] <TAB>  pos = 0 <TAB>  while pos < len ( code ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  word = "" ""<TAB># new word <TAB><TAB><TAB>  pos + = 1 <TAB><TAB><TAB>  while pos < len ( code ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  if code [ pos ] == "" \\ "" : <TAB><TAB><TAB><TAB><TAB>  word + = "" \\ "" <TAB><TAB><TAB><TAB><TAB>  pos + = 1 <TAB><TAB><TAB><TAB>  word + = code [ pos ] <TAB><TAB><TAB><TAB>  pos + = 1 <TAB><TAB><TAB>  strings . append ( ' "" %s "" ' % word ) <TAB><TAB>  pos + = 1 <TAB>  return strings ","if code [ pos ] == '""' :","if code[pos] == ""'"":",False,29.778358884057383,94.40351629698608
633,"def get_folder_content ( cls , name ) : <TAB>  """"""Return (folders, files) for the given folder in the root dir."""""" <TAB>  folders = set ( ) <TAB>  files = set ( ) <TAB>  for path in cls . LAYOUT : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  parts = path . split ( "" / "" ) <TAB><TAB>  if len ( parts ) == 2 : <TAB><TAB><TAB>  files . add ( parts [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  folders . add ( parts [ 1 ] ) <TAB>  folders = list ( folders ) <TAB>  folders . sort ( ) <TAB>  files = list ( files ) <TAB>  files . sort ( ) <TAB>  return ( folders , files ) ","if not path . startswith ( name + ""/"" ) :",if path.startswith('/'):,False,33.01406704495044,95.76802500385976
634,"def array_for ( self , i ) : <TAB>  if 0 < = i < self . _cnt : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _tail <TAB><TAB>  node = self . _root <TAB><TAB>  level = self . _shift <TAB><TAB>  while level > 0 : <TAB><TAB><TAB>  assert isinstance ( node , Node ) <TAB><TAB><TAB>  node = node . _array [ ( i >> level ) & 0x01F ] <TAB><TAB><TAB>  level - = 5 <TAB><TAB>  assert isinstance ( node , Node ) <TAB><TAB>  return node . _array <TAB>  affirm ( False , u "" Index out of Range "" ) ",if i >= self . tailoff ( ) :,if i == self._tail:,False,22.515380553934822,96.10873372932238
635,"def __or__ ( self , other ) - > "" MultiVector "" : <TAB>  r """"""``self | other``, the inner product :math:`M \cdot N`"""""" <TAB>  other , mv = self . _checkOther ( other ) <TAB>  if mv : <TAB><TAB>  newValue = self . layout . imt_func ( self . value , other . value ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  obj = self . __array__ ( ) <TAB><TAB><TAB>  return obj | other <TAB><TAB>  # l * M = M * l = 0 for scalar l <TAB><TAB>  return self . _newMV ( dtype = np . result_type ( self . value . dtype , other ) ) <TAB>  return self . _newMV ( newValue ) ","if isinstance ( other , np . ndarray ) :",if other is NotImplemented:,False,57.258459279874394,95.41323781562757
636,"def parse_bzr_stats ( status ) : <TAB>  stats = RepoStats ( ) <TAB>  statustype = "" changed "" <TAB>  for statusline in status : <TAB><TAB>  if statusline [ : 2 ] == ""<TAB>"" : <TAB><TAB><TAB>  setattr ( stats , statustype , getattr ( stats , statustype ) + 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  statustype = "" staged "" <TAB><TAB>  elif statusline == "" unknown: "" : <TAB><TAB><TAB>  statustype = "" new "" <TAB><TAB>  else :<TAB># removed, missing, renamed, modified or kind changed <TAB><TAB><TAB>  statustype = "" changed "" <TAB>  return stats ","elif statusline == ""added:"" :","if statusline == ""staged:",False,31.869553631080755,91.87624131347576
637,"def write ( self , timestamps , actualValues , predictedValues , predictionStep = 1 ) : <TAB>  assert len ( timestamps ) == len ( actualValues ) == len ( predictedValues ) <TAB>  for index in range ( len ( self . names ) ) : <TAB><TAB>  timestamp = timestamps [ index ] <TAB><TAB>  actual = actualValues [ index ] <TAB><TAB>  prediction = predictedValues [ index ] <TAB><TAB>  writer = self . outputWriters [ index ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  outputRow = [ timestamp , actual , prediction ] <TAB><TAB><TAB>  writer . writerow ( outputRow ) <TAB><TAB><TAB>  self . lineCounts [ index ] + = 1 ",if timestamp is not None :,if writer:,False,20.485867714647572,96.62880260795073
638,"def clean ( self ) : <TAB>  """"""Delete old files in ""tmp""."""""" <TAB>  now = time . time ( ) <TAB>  for entry in os . listdir ( os . path . join ( self . _path , "" tmp "" ) ) : <TAB><TAB>  path = os . path . join ( self . _path , "" tmp "" , entry ) <TAB><TAB>  <IF-STMT>:<TAB># 60 * 60 * 36 <TAB><TAB><TAB>  os . remove ( path ) ",if now - os . path . getatime ( path ) > 129600 :,if now - now + 60 * 60 * 60:,False,48.69774328750546,90.33407603280632
639,"def _get_info ( self , path ) : <TAB>  info = OrderedDict ( ) <TAB>  if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB><TAB>  stdout = None <TAB><TAB>  try : <TAB><TAB><TAB>  stdout , stderr = Popen ( <TAB><TAB><TAB><TAB>  [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB><TAB><TAB><TAB>  stdout = PIPE , <TAB><TAB><TAB><TAB>  stderr = PIPE , <TAB><TAB><TAB>  ) . communicate ( ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for line in stdout . splitlines ( ) : <TAB><TAB><TAB><TAB><TAB>  line = u ( line ) . split ( "" :  "" , 1 ) <TAB><TAB><TAB><TAB><TAB>  if len ( line ) == 2 : <TAB><TAB><TAB><TAB><TAB><TAB>  info [ line [ 0 ] ] = line [ 1 ] <TAB>  return info ",if stdout :,if stdout:,False,50.79224530242992,100.00000000000004
640,"def add ( meta_list , info_list = None ) : <TAB>  if not info_list : <TAB><TAB>  info_list = meta_list <TAB>  if not isinstance ( meta_list , ( list , tuple ) ) : <TAB><TAB>  meta_list = ( meta_list , ) <TAB>  if not isinstance ( info_list , ( list , tuple ) ) : <TAB><TAB>  info_list = ( info_list , ) <TAB>  for info_f in info_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for meta_f in meta_list : <TAB><TAB><TAB><TAB>  metadata [ meta_f ] = info [ info_f ] <TAB><TAB><TAB>  break ",if info . get ( info_f ) is not None :,if info_f in info:,False,27.145126326114877,94.59757271514545
641,"def _compute_log_r ( model_trace , guide_trace ) : <TAB>  log_r = MultiFrameTensor ( ) <TAB>  stacks = get_plate_stacks ( model_trace ) <TAB>  for name , model_site in model_trace . nodes . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log_r_term = model_site [ "" log_prob "" ] <TAB><TAB><TAB>  if not model_site [ "" is_observed "" ] : <TAB><TAB><TAB><TAB>  log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB><TAB><TAB>  log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB>  return log_r ","if model_site [ ""type"" ] == ""sample"" :",if model_site['is_observed']:,False,49.54091635393142,95.01819190856426
642,"def pickline ( file , key , casefold = 1 ) : <TAB>  try : <TAB><TAB>  f = open ( file , "" r "" ) <TAB>  except IOError : <TAB><TAB>  return None <TAB>  pat = re . escape ( key ) + "" : "" <TAB>  prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB>  while 1 : <TAB><TAB>  line = f . readline ( ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  break <TAB><TAB>  if prog . match ( line ) : <TAB><TAB><TAB>  text = line [ len ( key ) + 1 : ] <TAB><TAB><TAB>  while 1 : <TAB><TAB><TAB><TAB>  line = f . readline ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  text = text + line <TAB><TAB><TAB>  return text . strip ( ) <TAB>  return None ",if not line or not line [ 0 ] . isspace ( ) :,if not line:,False,26.12393430867041,95.54834036174223
643,"def build_iterator ( data , infinite = True ) : <TAB>  """"""Build the iterator for inputs."""""" <TAB>  index = 0 <TAB>  size = len ( data [ 0 ] ) <TAB>  while True : <TAB><TAB>  if index + batch_size > size : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  index = 0 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return <TAB><TAB>  yield data [ 0 ] [ index : index + batch_size ] , data [ 1 ] [ index : index + batch_size ] <TAB><TAB>  index + = batch_size ",if infinite :,if infinite:,False,31.313839305141272,100.00000000000004
644,"def checkall ( g , bg , dst_nodes , include_dst_in_src = True ) : <TAB>  for etype in g . etypes : <TAB><TAB>  ntype = g . to_canonical_etype ( etype ) [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  check ( g , bg , ntype , etype , dst_nodes [ ntype ] , include_dst_in_src ) <TAB><TAB>  else : <TAB><TAB><TAB>  check ( g , bg , ntype , etype , None , include_dst_in_src ) ",if dst_nodes is not None and ntype in dst_nodes :,if ntype in dst_nodes:,False,26.60864393723219,93.95709453115727
645,"def minimalBases ( classes ) : <TAB>  """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB>  if not __python3 :<TAB># pragma: no cover <TAB><TAB>  classes = [ c for c in classes if c is not ClassType ] <TAB>  candidates = [ ] <TAB>  for m in classes : <TAB><TAB>  for n in classes : <TAB><TAB><TAB>  if issubclass ( n , m ) and m is not n : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  # m has no subclasses in 'classes' <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  candidates . remove ( m )<TAB># ensure that we're later in the list <TAB><TAB><TAB>  candidates . append ( m ) <TAB>  return candidates ",if m in candidates :,if m in candidates:,False,59.29081126013419,95.69202648262076
646,"def __keep_songs_enable ( self , enabled ) : <TAB>  config . set ( "" memory "" , "" queue_keep_songs "" , enabled ) <TAB>  if enabled : <TAB><TAB>  self . queue . set_first_column_type ( CurrentColumn ) <TAB>  else : <TAB><TAB>  for col in self . queue . get_columns ( ) : <TAB><TAB><TAB>  # Remove the CurrentColum if it exists <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . queue . set_first_column_type ( None ) <TAB><TAB><TAB><TAB>  break ","if isinstance ( col , CurrentColumn ) :",if col.get_column_type() == CurrentColumn:,False,58.34207459897341,92.23350367139099
647,"def outlineView_heightOfRowByItem_ ( self , tree , item ) - > float : <TAB>  default_row_height = self . rowHeight <TAB>  if item is self : <TAB><TAB>  return default_row_height <TAB>  heights = [ default_row_height ] <TAB>  for column in self . tableColumns : <TAB><TAB>  value = getattr ( item . attrs [ "" node "" ] , str ( column . identifier ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # if the cell value is a widget, use its height <TAB><TAB><TAB>  heights . append ( value . _impl . native . intrinsicContentSize ( ) . height ) <TAB>  return max ( heights ) ","if isinstance ( value , toga . Widget ) :",if value is not None:,False,56.459983167011366,94.39327152062096
648,"def condition ( self ) : <TAB>  if self . __condition is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Avoid an extra indirection in the common case of only one condition. <TAB><TAB><TAB>  self . __condition = self . flat_conditions [ 0 ] <TAB><TAB>  elif len ( self . flat_conditions ) == 0 : <TAB><TAB><TAB>  # Possible, if unlikely, due to filter predicate rewriting <TAB><TAB><TAB>  self . __condition = lambda _ : True <TAB><TAB>  else : <TAB><TAB><TAB>  self . __condition = lambda x : all ( cond ( x ) for cond in self . flat_conditions ) <TAB>  return self . __condition ",if len ( self . flat_conditions ) == 1 :,if len(self.flat_conditions) == 1:,False,65.43641523793433,100.00000000000004
649,"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB>  delimiter = b "" \n "" <TAB>  if f . tell ( ) == 0 : <TAB><TAB>  return 0 <TAB>  while True : <TAB><TAB>  b = f . read ( block_size ) <TAB><TAB>  if not b : <TAB><TAB><TAB>  return f . tell ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1 ",elif delimiter in b :,if b.index(delimiter) == 0:,False,41.44012612076347,92.14984161841096
650,"def serialize ( self , name = None ) : <TAB>  data = super ( SimpleText , self ) . serialize ( name ) <TAB>  data [ "" contentType "" ] = self . contentType <TAB>  data [ "" content "" ] = self . content <TAB>  if self . width : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise InvalidWidthException ( self . width ) <TAB><TAB>  data [ "" inputOptions "" ] = { } <TAB><TAB>  data [ "" width "" ] = self . width <TAB>  return data ","if self . width not in [ 100 , 50 , 33 , 25 ] :",if self.width < 0:,False,26.06017989544633,90.40396187190518
651,"def inference ( self ) : <TAB>  self . attention_weight_dim = self . input_dims [ 0 ] [ - 1 ] <TAB>  if self . keep_dim : <TAB><TAB>  self . output_dim = copy . deepcopy ( self . input_dims [ 0 ] ) <TAB>  else : <TAB><TAB>  self . output_dim = [ ] <TAB><TAB>  for idx , dim in enumerate ( self . input_dims [ 0 ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . output_dim . append ( dim ) <TAB>  super ( <TAB><TAB>  LinearAttentionConf , self <TAB>  ) . inference ( )<TAB># PUT THIS LINE AT THE END OF inference() ",if idx != len ( self . input_dims [ 0 ] ) - 2 :,if idx == self.output_dim:,False,31.97847726176303,89.68927317397059
652,"def __delete_hook ( self , rpc ) : <TAB>  try : <TAB><TAB>  rpc . check_success ( ) <TAB>  except apiproxy_errors . Error : <TAB><TAB>  return None <TAB>  result = [ ] <TAB>  for status in rpc . response . delete_status_list ( ) : <TAB><TAB>  if status == MemcacheDeleteResponse . DELETED : <TAB><TAB><TAB>  result . append ( DELETE_SUCCESSFUL ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( DELETE_ITEM_MISSING ) <TAB><TAB>  else : <TAB><TAB><TAB>  result . append ( DELETE_NETWORK_FAILURE ) <TAB>  return result ",elif status == MemcacheDeleteResponse . NOT_FOUND :,if status == MemcacheDeleteResponse.ITEM_MISSING:,False,51.462112563879934,95.9950344190019
653,def identify_page_at_cursor ( self ) : <TAB>  for region in self . view . sel ( ) : <TAB><TAB>  text_on_cursor = None <TAB><TAB>  pos = region . begin ( ) <TAB><TAB>  scope_region = self . view . extract_scope ( pos ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text_on_cursor = self . view . substr ( scope_region ) <TAB><TAB><TAB>  return text_on_cursor . strip ( string . punctuation ) <TAB>  return None ,if not scope_region . empty ( ) :,if scope_region:,False,28.978104228331535,94.17073784501208
654,"def from_elem ( cls , parent , when_elem ) : <TAB>  """"""Loads the proper when by attributes of elem"""""" <TAB>  when_value = when_elem . get ( "" value "" , None ) <TAB>  <IF-STMT>: <TAB><TAB>  return ValueToolOutputActionConditionalWhen ( parent , when_elem , when_value ) <TAB>  else : <TAB><TAB>  when_value = when_elem . get ( "" datatype_isinstance "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return DatatypeIsInstanceToolOutputActionConditionalWhen ( <TAB><TAB><TAB><TAB>  parent , when_elem , when_value <TAB><TAB><TAB>  ) <TAB>  raise TypeError ( "" When type not implemented "" ) ",if when_value is not None :,if when_value is not None:,False,28.09958351309118,95.19880387922267
655,"def test_insert_entity_empty_string_rk ( <TAB>  self , tables_cosmos_account_name , tables_primary_cosmos_account_key  ) : <TAB>  # Arrange <TAB>  await self . _set_up ( tables_cosmos_account_name , tables_primary_cosmos_account_key ) <TAB>  try : <TAB><TAB>  entity = { "" PartitionKey "" : "" pk "" , "" RowKey "" : "" "" } <TAB><TAB>  # Act <TAB><TAB>  with pytest . raises ( HttpResponseError ) : <TAB><TAB><TAB>  await self . table . create_entity ( entity = entity ) <TAB><TAB><TAB>  # Assert <TAB><TAB>  #  assert resp is None <TAB>  finally : <TAB><TAB>  await self . _tear_down ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sleep ( SLEEP_DELAY ) ",if self . is_live :,if self.table.is_primary_entity_created():,False,51.74923746303415,94.88920384008742
656,"def provider_uris ( self ) : <TAB>  login_urls = { } <TAB>  continue_url = self . request . get ( "" continue_url "" ) <TAB>  for provider in self . provider_info : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  login_url = self . uri_for ( <TAB><TAB><TAB><TAB>  "" social-login "" , provider_name = provider , continue_url = continue_url <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  login_url = self . uri_for ( "" social-login "" , provider_name = provider ) <TAB><TAB>  login_urls [ provider ] = login_url <TAB>  return login_urls ",if continue_url :,if continue_url:,False,50.965170612793955,100.00000000000004
657,"def expand_extensions ( existing ) : <TAB>  for name in extension_names : <TAB><TAB>  ext = ( <TAB><TAB><TAB>  im ( "" lizard_ext.lizard "" + name . lower ( ) ) . LizardExtension ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else name <TAB><TAB>  ) <TAB><TAB>  existing . insert ( <TAB><TAB><TAB>  len ( existing ) if not hasattr ( ext , "" ordering_index "" ) else ext . ordering_index , <TAB><TAB><TAB>  ext , <TAB><TAB>  ) <TAB>  return existing ","if isinstance ( name , str )",if ext.name == name.lower():,False,42.34425507479628,92.56520750004512
658,"def wrapper ( self , * args , * * kwargs ) : <TAB>  if not self . request . path . endswith ( "" / "" ) : <TAB><TAB>  if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB><TAB><TAB>  uri = self . request . path + "" / "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  uri + = "" ? "" + self . request . query <TAB><TAB><TAB>  self . redirect ( uri , permanent = True ) <TAB><TAB><TAB>  return <TAB><TAB>  raise HTTPError ( 404 ) <TAB>  return method ( self , * args , * * kwargs ) ",if self . request . query :,if self.request.query:,False,45.15247048498123,100.00000000000004
659,"def subword_map_by_joiner ( subwords , marker = SubwordMarker . JOINER ) : <TAB>  """"""Return word id for each subword token (annotate by joiner)."""""" <TAB>  flags = [ 0 ] * len ( subwords ) <TAB>  for i , tok in enumerate ( subwords ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flags [ i ] = 1 <TAB><TAB>  if tok . startswith ( marker ) : <TAB><TAB><TAB>  assert i > = 1 and flags [ i - 1 ] != 1 , "" Sentence ` {} ` not correct! "" . format ( <TAB><TAB><TAB><TAB>  "" "" . join ( subwords ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  flags [ i - 1 ] = 1 <TAB>  marker_acc = list ( accumulate ( [ 0 ] + flags [ : - 1 ] ) ) <TAB>  word_group = [ ( i - maker_sofar ) for i , maker_sofar in enumerate ( marker_acc ) ] <TAB>  return word_group ",if tok . endswith ( marker ) :,if tok.startswith(marker):,False,34.28313696958998,97.59657743262079
660,"def next_item ( self , direction ) : <TAB>  """"""Selects next menu item, based on self._direction"""""" <TAB>  start , i = - 1 , 0 <TAB>  try : <TAB><TAB>  start = self . items . index ( self . _selected ) <TAB><TAB>  i = start + direction <TAB>  except : <TAB><TAB>  pass <TAB>  while True : <TAB><TAB>  if i == start : <TAB><TAB><TAB>  # Cannot find valid menu item <TAB><TAB><TAB>  self . select ( start ) <TAB><TAB><TAB>  break <TAB><TAB>  if i > = len ( self . items ) : <TAB><TAB><TAB>  i = 0 <TAB><TAB><TAB>  continue <TAB><TAB>  if i < 0 : <TAB><TAB><TAB>  i = len ( self . items ) - 1 <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  i + = direction <TAB><TAB>  if start < 0 : <TAB><TAB><TAB>  start = 0 ",if self . select ( i ) :,if i > len(self.items):,False,56.686323930326935,96.18008150940719
661,"def get_config ( cls ) : <TAB>  # FIXME: Replace this as soon as we have a config module <TAB>  config = { } <TAB>  # Try to get iflytek_yuyin config from config <TAB>  profile_path = dingdangpath . config ( "" profile.yml "" ) <TAB>  if os . path . exists ( profile_path ) : <TAB><TAB>  with open ( profile_path , "" r "" ) as f : <TAB><TAB><TAB>  profile = yaml . safe_load ( f ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if "" vid "" in profile [ "" iflytek_yuyin "" ] : <TAB><TAB><TAB><TAB><TAB>  config [ "" vid "" ] = profile [ "" iflytek_yuyin "" ] [ "" vid "" ] <TAB>  return config ","if ""iflytek_yuyin"" in profile :",if profile:,False,37.70848551651413,96.17468275571285
662,"def get_signed_in_user ( test_case ) : <TAB>  playback = not ( test_case . is_live or test_case . in_recording ) <TAB>  if playback : <TAB><TAB>  return MOCKED_USER_NAME <TAB>  else : <TAB><TAB>  account_info = test_case . cmd ( "" account show "" ) . get_output_in_json ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return account_info [ "" user "" ] [ "" name "" ] <TAB>  return None ","if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :",if account_info and 'user' in account_info:,False,33.49278852749799,88.36678060841037
663,"def rename_project ( self , project , new_name ) : <TAB>  """"""Rename project, update the related projects if necessary"""""" <TAB>  old_name = project . name <TAB>  for proj in self . projects : <TAB><TAB>  relproj = proj . get_related_projects ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  relproj [ relproj . index ( old_name ) ] = new_name <TAB><TAB><TAB>  proj . set_related_projects ( relproj ) <TAB>  project . rename ( new_name ) <TAB>  self . save ( ) ",if old_name in relproj :,if relproj:,False,45.3392583703732,96.12108647264937
664,"def test_call_extern_c_fn ( self ) : <TAB>  global memcmp <TAB>  memcmp = cffi_support . ExternCFunction ( <TAB><TAB>  "" memcmp "" , <TAB><TAB>  ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB>  ) <TAB>  @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB>  def fn ( context , a , b ) : <TAB><TAB>  if a . is_null != b . is_null : <TAB><TAB><TAB>  return False <TAB><TAB>  if a is None : <TAB><TAB><TAB>  return True <TAB><TAB>  if len ( a ) != b . len : <TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  return memcmp ( a . ptr , b . ptr , a . len ) == 0 ",if a . ptr == b . ptr :,if len(a) == 0:,False,55.36952390121341,96.4133023050949
665,"def parse_variable ( self ) : <TAB>  begin = self . _pos <TAB>  while True : <TAB><TAB>  ch = self . read ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ScriptVariable ( self . _text [ begin : self . _pos - 1 ] ) <TAB><TAB>  elif ch is None : <TAB><TAB><TAB>  self . __raise_eof ( ) <TAB><TAB>  elif not isidentif ( ch ) and ch != "" : "" : <TAB><TAB><TAB>  self . __raise_char ( ch ) ","if ch == ""%"" :",if ch == '\n':,False,48.60560350556153,96.85451587663262
666,"def h_file ( self ) : <TAB>  filename = self . abspath ( ) <TAB>  st = os . stat ( filename ) <TAB>  cache = self . ctx . hashes_md5_tstamp <TAB>  if filename in cache and cache [ filename ] [ 0 ] == st . st_mtime : <TAB><TAB>  return cache [ filename ] [ 1 ] <TAB>  if STRONGEST : <TAB><TAB>  ret = Utils . h_file ( filename ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise IOError ( "" Not a file "" ) <TAB><TAB>  ret = Utils . md5 ( str ( ( st . st_mtime , st . st_size ) ) . encode ( ) ) . digest ( ) <TAB>  cache [ filename ] = ( st . st_mtime , ret ) <TAB>  return ret ",if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,"if not isinstance(st, (str, int)):",False,33.685278463868606,92.8076809620378
667,"def add_widgets ( self , * widgets_or_spacings ) : <TAB>  """"""Add widgets/spacing to dialog vertical layout"""""" <TAB>  layout = self . layout ( ) <TAB>  for widget_or_spacing in widgets_or_spacings : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  layout . addSpacing ( widget_or_spacing ) <TAB><TAB>  else : <TAB><TAB><TAB>  layout . addWidget ( widget_or_spacing ) ","if isinstance ( widget_or_spacing , int ) :","if isinstance(widget_or_spacing, (int, float)):",False,53.395096451310266,94.96111052858863
668,"def _str_index ( self ) : <TAB>  idx = self [ "" index "" ] <TAB>  out = [ ] <TAB>  if len ( idx ) == 0 : <TAB><TAB>  return out <TAB>  out + = [ "" .. index::  %s "" % idx . get ( "" default "" , "" "" ) ] <TAB>  for section , references in idx . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  elif section == "" refguide "" : <TAB><TAB><TAB>  out + = [ ""<TAB>single:  %s "" % ( "" ,  "" . join ( references ) ) ] <TAB><TAB>  else : <TAB><TAB><TAB>  out + = [ ""<TAB> %s :  %s "" % ( section , "" , "" . join ( references ) ) ] <TAB>  return out ","if section == ""default"" :","if section == ""default':",False,14.02904889167999,94.4879709568752
669,"def dictify_CPPDEFINES ( env ) : <TAB>  cppdefines = env . get ( "" CPPDEFINES "" , { } ) <TAB>  if cppdefines is None : <TAB><TAB>  return { } <TAB>  if SCons . Util . is_Sequence ( cppdefines ) : <TAB><TAB>  result = { } <TAB><TAB>  for c in cppdefines : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ c [ 0 ] ] = c [ 1 ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  result [ c ] = None <TAB><TAB>  return result <TAB>  if not SCons . Util . is_Dict ( cppdefines ) : <TAB><TAB>  return { cppdefines : None } <TAB>  return cppdefines ",if SCons . Util . is_Sequence ( c ) :,if c[0] == 'CPPDEFINES':,False,47.84991746924185,94.08642175454159
670,"def decoder ( s ) : <TAB>  r = [ ] <TAB>  decode = [ ] <TAB>  for c in s : <TAB><TAB>  if c == "" & "" and not decode : <TAB><TAB><TAB>  decode . append ( "" & "" ) <TAB><TAB>  elif c == "" - "" and decode : <TAB><TAB><TAB>  if len ( decode ) == 1 : <TAB><TAB><TAB><TAB>  r . append ( "" & "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB><TAB><TAB>  decode = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  decode . append ( c ) <TAB><TAB>  else : <TAB><TAB><TAB>  r . append ( c ) <TAB>  if decode : <TAB><TAB>  r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB>  bin_str = "" "" . join ( r ) <TAB>  return ( bin_str , len ( s ) ) ",elif decode :,if c in decode:,False,40.9359351627011,98.39899080494247
671,"def optimize ( self , graph : Graph ) : <TAB>  MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB>  flag_changed = False <TAB>  for v in traverse . listup_variables ( graph ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  height , width = TextureShape . get ( v ) <TAB><TAB>  if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB><TAB><TAB>  continue <TAB><TAB>  if not v . has_attribute ( SplitTarget ) : <TAB><TAB><TAB>  flag_changed = True <TAB><TAB><TAB>  v . attributes . add ( SplitTarget ( ) ) <TAB>  return graph , flag_changed ",if not Placeholder . check_resolved ( v . size ) :,if v.type == 'texture':,False,26.313646574047635,93.7410872318772
672,"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB>  n , r = 0 , 0 <TAB>  for op in _gen_opnds ( ii ) : <TAB><TAB>  if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ "" v "" ] ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  return n == 1 and r == 1 ",elif op_gprv ( op ) :,"if op_mem(op) and op.oc1 in [""v""], """,False,54.273519291262986,88.14927996096065
673,"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB>  """"""Return standard location of genome directories."""""" <TAB>  if galaxy_dir : <TAB><TAB>  refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB><TAB>  seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB><TAB>  if seq_file and os . path . exists ( seq_file ) : <TAB><TAB><TAB>  return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB>  else : <TAB><TAB>  gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return gdirs [ 0 ] ",if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) :,if len(gdirs) == 1:,False,41.00372147756041,93.84757914670442
674,"def __modules ( self ) : <TAB>  raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB>  for line in StringIO ( raw_output ) : <TAB><TAB>  line = line and line . strip ( ) <TAB><TAB>  if not line or line . startswith ( "" - "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  line_modules = line . split ( ) <TAB><TAB>  for module in line_modules : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB><TAB><TAB>  module_parts = module . split ( "" / "" ) <TAB><TAB><TAB>  module_version = None <TAB><TAB><TAB>  if len ( module_parts ) == 2 : <TAB><TAB><TAB><TAB>  module_version = module_parts [ 1 ] <TAB><TAB><TAB>  module_name = module_parts [ 0 ] <TAB><TAB><TAB>  yield module_name , module_version ",if module . endswith ( self . default_indicator ) :,if module.endswith(self.default_indicator):,False,52.06319403413555,98.75866337844765
675,"def save ( self ) : <TAB>  updates = self . cinder_obj_get_changes ( ) <TAB>  if updates : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  metadata = updates . pop ( "" metadata "" , None ) <TAB><TAB><TAB>  self . metadata = db . backup_metadata_update ( <TAB><TAB><TAB><TAB>  self . _context , self . id , metadata , True <TAB><TAB><TAB>  ) <TAB><TAB>  updates . pop ( "" parent "" , None ) <TAB><TAB>  db . backup_update ( self . _context , self . id , updates ) <TAB>  self . obj_reset_changes ( ) ","if ""metadata"" in updates :",if self.metadata is not None:,False,47.413632964985574,95.6613463336073
676,"def test_set_tag ( association_obj , sagemaker_session ) : <TAB>  tag = { "" Key "" : "" foo "" , "" Value "" : "" bar "" } <TAB>  association_obj . set_tag ( tag ) <TAB>  while True : <TAB><TAB>  actual_tags = sagemaker_session . sagemaker_client . list_tags ( <TAB><TAB><TAB>  ResourceArn = association_obj . source_arn <TAB><TAB>  ) [ "" Tags "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  time . sleep ( 5 ) <TAB>  # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB>  # length of actual tags will be greater than 1 <TAB>  assert len ( actual_tags ) > 0 <TAB>  assert actual_tags [ 0 ] == tag ",if actual_tags :,if not actual_tags:,False,63.26709925793721,98.71621564653425
677,"def test_error_stream ( environ , start_response ) : <TAB>  writer = start_response ( "" 200 OK "" , [ ] ) <TAB>  wsgi_errors = environ [ "" wsgi.errors "" ] <TAB>  error_msg = None <TAB>  for method in [ <TAB><TAB>  "" flush "" , <TAB><TAB>  "" write "" , <TAB><TAB>  "" writelines "" , <TAB>  ] : <TAB><TAB>  if not hasattr ( wsgi_errors , method ) : <TAB><TAB><TAB>  error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB><TAB>  if error_msg : <TAB><TAB><TAB>  break <TAB>  return_msg = error_msg or "" success "" <TAB>  writer ( return_msg ) <TAB>  return [ ] ","if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :","if not callable(wsgi_errors, method):",False,25.911945396244928,94.63365279437666
678,"def current_dict ( cursor_offset , line ) : <TAB>  """"""If in dictionary completion, return the dict that should be used"""""" <TAB>  for m in current_dict_re . finditer ( line ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return LinePart ( m . start ( 1 ) , m . end ( 1 ) , m . group ( 1 ) ) <TAB>  return None ",if m . start ( 2 ) <= cursor_offset and m . end ( 2 ) >= cursor_offset :,if m.group(0) == cursor_offset:,False,34.66531931278539,84.47683969801845
679,"def show_file_browser ( self ) : <TAB>  """"""Show/hide the file browser."""""" <TAB>  if self . show_file_browser_action . isChecked ( ) : <TAB><TAB>  sizes = self . panel . sizes ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sizes [ 0 ] = sum ( sizes ) / / 4 <TAB><TAB><TAB>  self . panel . setSizes ( sizes ) <TAB><TAB>  self . file_browser . show ( ) <TAB>  else : <TAB><TAB>  self . file_browser . hide ( ) ",if sizes [ 0 ] == 0 :,if sizes:,False,20.039176534404582,94.79407370283515
680,"def run ( self , paths = [ ] ) : <TAB>  items = [ ] <TAB>  for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB><TAB>  items . append ( item . nameEncoded ( ) ) <TAB>  if len ( items ) > 0 : <TAB><TAB>  sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sublime . status_message ( "" Items copied "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  sublime . status_message ( "" Item copied "" ) ",if len ( items ) > 1 :,if len(items) == 0:,False,51.094082844480205,96.85451587663262
681,"def prepend ( self , value ) : <TAB>  """"""prepend value to nodes"""""" <TAB>  root , root_text = self . _get_root ( value ) <TAB>  for i , tag in enumerate ( self ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tag . text = "" "" <TAB><TAB>  if len ( root ) > 0 : <TAB><TAB><TAB>  root [ - 1 ] . tail = tag . text <TAB><TAB><TAB>  tag . text = root_text <TAB><TAB>  else : <TAB><TAB><TAB>  tag . text = root_text + tag . text <TAB><TAB>  if i > 0 : <TAB><TAB><TAB>  root = deepcopy ( list ( root ) ) <TAB><TAB>  tag [ : 0 ] = root <TAB><TAB>  root = tag [ : len ( root ) ] <TAB>  return self ",if not tag . text :,if tag.text == root_text:,False,25.432589691959084,95.15146366440811
682,"def getLabel ( self , address = None ) : <TAB>  if address is None : <TAB><TAB>  address = self . address <TAB>  label = address <TAB>  if shared . config . has_section ( address ) : <TAB><TAB>  label = shared . config . get ( address , "" label "" ) <TAB>  queryreturn = sqlQuery ( """""" select label from addressbook where address=? """""" , address ) <TAB>  <IF-STMT>: <TAB><TAB>  for row in queryreturn : <TAB><TAB><TAB>  ( label , ) = row <TAB>  else : <TAB><TAB>  queryreturn = sqlQuery ( <TAB><TAB><TAB>  """"""select label from subscriptions where address=?"""""" , address <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for row in queryreturn : <TAB><TAB><TAB><TAB>  ( label , ) = row <TAB>  return label ",if queryreturn != [ ] :,if label is None:,False,27.057331083768315,93.77160090090463
683,"def _parse ( self , engine ) : <TAB>  """"""Parse the layer."""""" <TAB>  if isinstance ( self . args , dict ) : <TAB><TAB>  if "" axis "" in self . args : <TAB><TAB><TAB>  self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB>  if not isinstance ( self . axis , int ) : <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB>  if not isinstance ( self . momentum , ( int , float ) ) : <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if ""momentum"" in self . args :","if ""momentum"" in self.args:",False,47.39786887011127,100.00000000000004
684,"def urlquote ( * args , * * kwargs ) : <TAB>  new_kwargs = dict ( kwargs ) <TAB>  if not PY3 : <TAB><TAB>  new_kwargs = dict ( kwargs ) <TAB><TAB>  if "" encoding "" in new_kwargs : <TAB><TAB><TAB>  del new_kwargs [ "" encoding "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del new_kwargs [ "" errors "" ] <TAB>  return quote ( * args , * * new_kwargs ) ","if ""errors"" in kwargs :","if ""errors"" in new_kwargs:",False,45.646525448893335,97.12974955244601
685,"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB>  try : <TAB><TAB>  if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] : <TAB><TAB><TAB>  self . _FORM_VISIT_LIST . pop ( )<TAB># Remove the current form. if it is at the end of the list <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # take no action if it looks as if someone has already set the next form. <TAB><TAB><TAB>  self . setNextForm ( <TAB><TAB><TAB><TAB>  self . _FORM_VISIT_LIST . pop ( ) <TAB><TAB><TAB>  )<TAB># Switch to the previous form if one exists <TAB>  except IndexError : <TAB><TAB>  self . setNextForm ( backup ) ",if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM :,if self._FORM_VISIT_LIST:,False,56.53439836602018,90.33174277404852
686,"def iter_chars_to_words ( self , chars ) : <TAB>  current_word = [ ] <TAB>  for char in chars : <TAB><TAB>  if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB><TAB><TAB>  if current_word : <TAB><TAB><TAB><TAB>  yield current_word <TAB><TAB><TAB><TAB>  current_word = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield current_word <TAB><TAB><TAB>  current_word = [ char ] <TAB><TAB>  else : <TAB><TAB><TAB>  current_word . append ( char ) <TAB>  if current_word : <TAB><TAB>  yield current_word ","elif current_word and self . char_begins_new_word ( current_word , char ) :",if char in current_word:,False,27.340604983999523,89.62536472021493
687,"def get ( self ) : <TAB>  """"""return a secret by name"""""" <TAB>  results = self . _get ( "" secrets "" , self . name ) <TAB>  results [ "" decoded "" ] = { } <TAB>  results [ "" exists "" ] = False <TAB>  if results [ "" returncode "" ] == 0 and results [ "" results "" ] [ 0 ] : <TAB><TAB>  results [ "" exists "" ] = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" data "" in results [ "" results "" ] [ 0 ] : <TAB><TAB><TAB><TAB>  for sname , value in results [ "" results "" ] [ 0 ] [ "" data "" ] . items ( ) : <TAB><TAB><TAB><TAB><TAB>  results [ "" decoded "" ] [ sname ] = base64 . b64decode ( value ) <TAB>  if results [ "" returncode "" ] != 0 and ' "" %s ""  not found ' % self . name in results [ "" stderr "" ] : <TAB><TAB>  results [ "" returncode "" ] = 0 <TAB>  return results ",if self . decode :,if results:,False,25.862982009637353,97.21005684008615
688,"def insert_use ( self , edit ) : <TAB>  if self . is_first_use ( ) : <TAB><TAB>  for location in [ r "" ^ \ s*namespace \ s+[ \ w \\ ]+[; { ] "" , r "" < \ ?php "" ] : <TAB><TAB><TAB>  inserted = self . insert_first_use ( location , edit ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  self . insert_use_among_others ( edit ) ",if inserted :,if inserted:,False,28.215253340064876,100.00000000000004
689,"def _new_rsa_key ( spec ) : <TAB>  if "" name "" not in spec : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ( head , tail ) = os . path . split ( spec [ "" key "" ] ) <TAB><TAB><TAB>  spec [ "" path "" ] = head <TAB><TAB><TAB>  spec [ "" name "" ] = tail <TAB><TAB>  else : <TAB><TAB><TAB>  spec [ "" name "" ] = spec [ "" key "" ] <TAB>  return rsa_init ( spec ) ","if ""/"" in spec [ ""key"" ] :",if 'key' in spec:,False,48.240833891149116,92.25802309355078
690,"def mimeData ( self , indexes ) : <TAB>  if len ( indexes ) == 1 : <TAB><TAB>  index = indexes [ 0 ] <TAB><TAB>  model = song = index . data ( Qt . UserRole ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  model = song . album <TAB><TAB><TAB>  except ( ProviderIOError , Exception ) : <TAB><TAB><TAB><TAB>  model = None <TAB><TAB>  return ModelMimeData ( model ) ",if index . column ( ) == Column . album :,if model is None:,False,24.652354639801977,91.49141624054184
691,"def get ( self , url , * * kwargs ) : <TAB>  app , url = self . _prepare_call ( url , kwargs ) <TAB>  if app : <TAB><TAB>  if url . endswith ( "" ping "" ) and self . _first_ping : <TAB><TAB><TAB>  self . _first_ping = False <TAB><TAB><TAB>  return EmptyCapabilitiesResponse ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ErrorApiResponse ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  response = app . get ( url , * * kwargs ) <TAB><TAB><TAB>  return TestingResponse ( response ) <TAB>  else : <TAB><TAB>  return requests . get ( url , * * kwargs ) ","elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :",if not url:,False,20.993932220834125,90.03654406208065
692,"def handle_noargs ( self , * * options ) : <TAB>  self . style = color_style ( ) <TAB>  print ( "" Running Django ' s own validation: "" ) <TAB>  self . validate ( display_num_errors = True ) <TAB>  for model in loading . get_models ( ) : <TAB><TAB>  if hasattr ( model , "" _create_content_base "" ) : <TAB><TAB><TAB>  self . validate_base_model ( model ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . validate_content_type ( model ) ","if hasattr ( model , ""_feincms_content_models"" ) :","if hasattr(model, '_create_content_base'):",False,49.45909197389631,92.21154724801862
693,"def test_rules_widget ( self ) : <TAB>  subreddit = self . reddit . subreddit ( pytest . placeholders . test_subreddit ) <TAB>  widgets = subreddit . widgets <TAB>  with self . use_cassette ( "" TestSubredditWidgets.fetch_widgets "" ) : <TAB><TAB>  rules = None <TAB><TAB>  for widget in widgets . sidebar : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  rules = widget <TAB><TAB><TAB><TAB>  break <TAB><TAB>  assert isinstance ( rules , RulesWidget ) <TAB><TAB>  assert rules == rules <TAB><TAB>  assert rules . id == rules <TAB><TAB>  assert rules . display <TAB><TAB>  assert len ( rules ) > 0 <TAB><TAB>  assert subreddit == rules . subreddit ","if isinstance ( widget , RulesWidget ) :",if widget.type == 'rules':,False,37.184300784109766,96.26492249860684
694,"def __init__ ( self , exception ) : <TAB>  message = str ( exception ) <TAB>  with contextlib . suppress ( IndexError ) : <TAB><TAB>  underlying_exception = exception . args [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  message = ( <TAB><TAB><TAB><TAB>  "" maximum retries exceeded trying to reach the store. \n "" <TAB><TAB><TAB><TAB>  "" Check your network connection, and check the store  "" <TAB><TAB><TAB><TAB>  "" status at  {} "" . format ( _STORE_STATUS_URL ) <TAB><TAB><TAB>  ) <TAB>  super ( ) . __init__ ( message = message ) ","if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :",if underlying_exception.args[0] == _STORE_STATUS_ERROR:,False,45.20717553651299,91.48940869429862
695,"def wrapped ( self , request ) : <TAB>  try : <TAB><TAB>  return self . _finished <TAB>  except AttributeError : <TAB><TAB>  if self . node_ids : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  log . debug ( <TAB><TAB><TAB><TAB><TAB>  "" %s  is still going to be used, not terminating it.  "" <TAB><TAB><TAB><TAB><TAB>  "" Still in use on: \n %s "" , <TAB><TAB><TAB><TAB><TAB>  self , <TAB><TAB><TAB><TAB><TAB>  pprint . pformat ( list ( self . node_ids ) ) , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  return <TAB><TAB>  log . debug ( "" Finish called on  %s "" , self ) <TAB><TAB>  try : <TAB><TAB><TAB>  return func ( request ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . _finished = True ",if not request . session . shouldfail and not request . session . shouldstop :,if self._finished:,False,57.13631052913903,94.78882659922346
696,"def get_min_vertical_scroll ( ) - > int : <TAB>  # Make sure that the cursor line is not below the bottom. <TAB>  # (Calculate how many lines can be shown between the cursor and the .) <TAB>  used_height = 0 <TAB>  prev_lineno = ui_content . cursor_position . y <TAB>  for lineno in range ( ui_content . cursor_position . y , - 1 , - 1 ) : <TAB><TAB>  used_height + = get_line_height ( lineno ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return prev_lineno <TAB><TAB>  else : <TAB><TAB><TAB>  prev_lineno = lineno <TAB>  return 0 ",if used_height > height - scroll_offsets_bottom :,if used_height == 0:,False,27.40460768086379,92.14602791170329
697,"def cookies ( self ) : <TAB>  # strip cookie_suffix from all cookies in the request, return result <TAB>  cookies = flask . Request . cookies . __get__ ( self ) <TAB>  result = { } <TAB>  desuffixed = { } <TAB>  for key , value in cookies . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  desuffixed [ key [ : - len ( self . cookie_suffix ) ] ] = value <TAB><TAB>  else : <TAB><TAB><TAB>  result [ key ] = value <TAB>  result . update ( desuffixed ) <TAB>  return result ",if key . endswith ( self . cookie_suffix ) :,if key.endswith(self.cookie_suffix):,False,36.218132017014774,97.66581194053254
698,"def update_vars ( state1 , state2 ) : <TAB>  ops = [ ] <TAB>  for name in state1 . _fields : <TAB><TAB>  state1_vs = getattr ( state1 , name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ops + = [ <TAB><TAB><TAB><TAB>  tf . assign ( _v1 , _v2 ) <TAB><TAB><TAB><TAB>  for _v1 , _v2 in zip ( state1_vs , getattr ( state2 , name ) ) <TAB><TAB><TAB>  ] <TAB><TAB>  else : <TAB><TAB><TAB>  ops + = [ tf . assign ( state1_vs , getattr ( state2 , name ) ) ] <TAB>  return tf . group ( * ops ) ","if isinstance ( state1_vs , list ) :","if isinstance(state1_vs, (tuple, list)):",False,21.396448305475065,97.05736155274367
699,"def manifest ( self ) : <TAB>  """"""The current manifest dictionary."""""" <TAB>  if self . reload : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return { } <TAB><TAB>  mtime = self . getmtime ( self . manifest_path ) <TAB><TAB>  if self . _mtime is None or mtime > self . _mtime : <TAB><TAB><TAB>  self . _manifest = self . get_manifest ( ) <TAB><TAB><TAB>  self . _mtime = mtime <TAB>  return self . _manifest ",if not self . exists ( self . manifest_path ) :,if not self._manifest:,False,53.92796397558966,93.52962878675373
700,"def csvtitle ( self ) : <TAB>  if isinstance ( self . name , six . string_types ) : <TAB><TAB>  return ' "" ' + self . name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB>  else : <TAB><TAB>  ret = "" "" <TAB><TAB>  for i , name in enumerate ( self . name ) : <TAB><TAB><TAB>  ret = ret + ' "" ' + name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret = ret + char [ "" sep "" ] <TAB><TAB>  return ret ",if i + 1 != len ( self . name ) :,if i == len(self.nick):,False,37.65163048592102,96.15158350654339
701,"def cache_dst ( self ) : <TAB>  final_dst = None <TAB>  final_linenb = None <TAB>  for linenb , assignblk in enumerate ( self ) : <TAB><TAB>  for dst , src in viewitems ( assignblk ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if final_dst is not None : <TAB><TAB><TAB><TAB><TAB>  raise ValueError ( "" Multiple destinations! "" ) <TAB><TAB><TAB><TAB>  final_dst = src <TAB><TAB><TAB><TAB>  final_linenb = linenb <TAB>  self . _dst = final_dst <TAB>  self . _dst_linenb = final_linenb <TAB>  return final_dst ","if dst . is_id ( ""IRDst"" ) :",if dst == self._dst:,False,50.34826085802777,94.4782601299144
702,"def _ProcessName ( self , name , dependencies ) : <TAB>  """"""Retrieve a module name from a node name."""""" <TAB>  module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB>  if dot : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if module_name in dependencies : <TAB><TAB><TAB><TAB>  dependencies [ module_name ] . add ( base_name ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  dependencies [ module_name ] = { base_name } <TAB><TAB>  else : <TAB><TAB><TAB>  # If we have a relative import that did not get qualified (usually due <TAB><TAB><TAB>  # to an empty package_name), don't insert module_name='' into the <TAB><TAB><TAB>  # dependencies; we get a better error message if we filter it out here <TAB><TAB><TAB>  # and fail later on. <TAB><TAB><TAB>  logging . warning ( "" Empty package name:  %s "" , name ) ",if module_name :,if base_name in dependencies:,False,68.83744977860466,97.8284903389716
703,"def get_aa_from_codonre ( re_aa ) : <TAB>  aas = [ ] <TAB>  m = 0 <TAB>  for i in re_aa : <TAB><TAB>  if i == "" [ "" : <TAB><TAB><TAB>  m = - 1 <TAB><TAB><TAB>  aas . append ( "" "" ) <TAB><TAB>  elif i == "" ] "" : <TAB><TAB><TAB>  m = 0 <TAB><TAB><TAB>  continue <TAB><TAB>  elif m == - 1 : <TAB><TAB><TAB>  aas [ - 1 ] = aas [ - 1 ] + i <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  aas . append ( i ) <TAB>  return aas ",elif m == 0 :,if m == 1:,False,29.724099302235757,89.42940400394689
704,"def logic ( ) : <TAB>  count = intbv ( 0 , min = 0 , max = MAXVAL + 1 ) <TAB>  while True : <TAB><TAB>  yield clock . posedge , reset . posedge <TAB><TAB>  if reset == 1 : <TAB><TAB><TAB>  count [ : ] = 0 <TAB><TAB>  else : <TAB><TAB><TAB>  flag . next = 0 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  flag . next = 1 <TAB><TAB><TAB><TAB>  count [ : ] = 0 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  count + = 1 ",if count == MAXVAL :,if reset == 0:,False,33.27769436972413,97.16653392347078
705,"def _history_define_metric ( <TAB>  self , hkey : str  ) - > Optional [ wandb_internal_pb2 . MetricRecord ] : <TAB>  """"""check for hkey match in glob metrics, return defined metric."""""" <TAB>  # Dont define metric for internal metrics <TAB>  if hkey . startswith ( "" _ "" ) : <TAB><TAB>  return None <TAB>  for k , mglob in six . iteritems ( self . _metric_globs ) : <TAB><TAB>  if k . endswith ( "" * "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  m = wandb_internal_pb2 . MetricRecord ( ) <TAB><TAB><TAB><TAB>  m . CopyFrom ( mglob ) <TAB><TAB><TAB><TAB>  m . ClearField ( "" glob_name "" ) <TAB><TAB><TAB><TAB>  m . name = hkey <TAB><TAB><TAB><TAB>  return m <TAB>  return None ",if hkey . startswith ( k [ : - 1 ] ) :,if hkey == k:,False,52.08910034085945,95.64509304052255
706,"def optimize_models ( args , use_cuda , models ) : <TAB>  """"""Optimize ensemble for generation"""""" <TAB>  for model in models : <TAB><TAB>  model . make_generation_fast_ ( <TAB><TAB><TAB>  beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB><TAB><TAB>  need_attn = args . print_alignment , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  model . half ( ) <TAB><TAB>  if use_cuda : <TAB><TAB><TAB>  model . cuda ( ) ",if args . fp16 :,if need_attn:,False,22.35297591304023,97.09797067861027
707,"def _Dynamic_Rollback ( self , transaction , transaction_response ) : <TAB>  txid = transaction . handle ( ) <TAB>  self . __local_tx_lock . acquire ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise apiproxy_errors . ApplicationError ( <TAB><TAB><TAB><TAB>  datastore_pb . Error . BAD_REQUEST , "" Transaction  %d  not found. "" % ( txid , ) <TAB><TAB><TAB>  ) <TAB><TAB>  txdata = self . __transactions [ txid ] <TAB><TAB>  assert ( <TAB><TAB><TAB>  txdata . thread_id == thread . get_ident ( ) <TAB><TAB>  ) , "" Transactions are single-threaded. "" <TAB><TAB>  del self . __transactions [ txid ] <TAB>  finally : <TAB><TAB>  self . __local_tx_lock . release ( ) ",if txid not in self . __transactions :,if txid not in self.__transactions:,False,49.56639269088543,100.00000000000004
708,"def get_job_dirs ( path ) : <TAB>  regex = re . compile ( "" [1-9][0-9]*- "" ) <TAB>  jobdirs = [ ] <TAB>  for d in os . listdir ( path ) : <TAB><TAB>  # skip directories not matching the job result dir pattern <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  d = os . path . join ( options . resultsdir , d ) <TAB><TAB>  if os . path . isdir ( d ) and not os . path . exists ( os . path . join ( d , PUBLISH_FLAGFILE ) ) : <TAB><TAB><TAB>  jobdirs . append ( d ) <TAB>  return jobdirs ",if not regex . match ( d ) :,"if re.search(regex, d):",False,59.81155842761376,96.0465326329024
709,"def traverse ( node , functions = [ ] ) : <TAB>  if hasattr ( node , "" grad_fn "" ) : <TAB><TAB>  node = node . grad_fn <TAB>  if hasattr ( node , "" variable "" ) : <TAB><TAB>  node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB><TAB>  if node : <TAB><TAB><TAB>  node . functions = list ( functions ) <TAB><TAB><TAB>  del functions [ : ] <TAB>  if hasattr ( node , "" next_functions "" ) : <TAB><TAB>  functions . append ( type ( node ) . __name__ ) <TAB><TAB>  for f in node . next_functions : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB><TAB><TAB><TAB>  traverse ( f [ 0 ] , functions ) <TAB>  if hasattr ( node , "" saved_tensors "" ) : <TAB><TAB>  for t in node . saved_tensors : <TAB><TAB><TAB>  traverse ( t ) ",if f [ 0 ] :,if f[0].type == type(f[0].__name__):,False,23.453783227632567,93.67277850864447
710,"def get_all_snap_points ( self , forts ) : <TAB>  points = [ ] <TAB>  radius = Constants . MAX_DISTANCE_FORT_IS_REACHABLE <TAB>  for i in range ( 0 , len ( forts ) ) : <TAB><TAB>  for j in range ( i + 1 , len ( forts ) ) : <TAB><TAB><TAB>  c1 , c2 = self . get_enclosing_circles ( forts [ i ] , forts [ j ] , radius ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  points . append ( ( c1 , c2 , forts [ i ] , forts [ j ] ) ) <TAB>  return points ",if c1 and c2 :,if c1 != c2:,False,48.1269713493077,97.7699327956607
711,"def doDir ( elem ) : <TAB>  for child in elem . childNodes : <TAB><TAB>  if not isinstance ( child , minidom . Element ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if child . tagName == "" Directory "" : <TAB><TAB><TAB>  doDir ( child ) <TAB><TAB>  elif child . tagName == "" Component "" : <TAB><TAB><TAB>  for grandchild in child . childNodes : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  if grandchild . tagName != "" File "" : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if not isinstance ( grandchild , minidom . Element ) :","if grandchild.tagName == ""File':",False,20.31864661912151,95.35317093276915
712,"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB>  w = 0 <TAB>  for ch in s : <TAB><TAB>  if ch == "" "" : <TAB><TAB><TAB>  w + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  return w ","elif ch == ""\t"" :",if w % abs(tab_width) > 0:,False,46.03425620810266,89.43554971599049
713,"def test_avg_group_by ( self ) : <TAB>  ret = ( <TAB><TAB>  await Book . annotate ( avg = Avg ( "" rating "" ) ) <TAB><TAB>  . group_by ( "" author_id "" ) <TAB><TAB>  . values ( "" author_id "" , "" avg "" ) <TAB>  ) <TAB>  for item in ret : <TAB><TAB>  author_id = item . get ( "" author_id "" ) <TAB><TAB>  avg = item . get ( "" avg "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( avg , 4.5 ) <TAB><TAB>  elif author_id == self . a2 . pk : <TAB><TAB><TAB>  self . assertEqual ( avg , 2.0 ) ",if author_id == self . a1 . pk :,if author_id == self.a1.pk:,False,51.18922623136414,100.00000000000004
714,"def open_session ( self , app , request ) : <TAB>  sid = request . cookies . get ( app . session_cookie_name ) <TAB>  if sid : <TAB><TAB>  stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  expiration = stored_session . expiration <TAB><TAB><TAB>  if not expiration . tzinfo : <TAB><TAB><TAB><TAB>  expiration = expiration . replace ( tzinfo = utc ) <TAB><TAB><TAB>  if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB><TAB><TAB><TAB>  return MongoEngineSession ( <TAB><TAB><TAB><TAB><TAB>  initial = stored_session . data , sid = stored_session . sid <TAB><TAB><TAB><TAB>  ) <TAB>  return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) ) ",if stored_session :,if stored_session:,False,50.82424187158172,100.00000000000004
715,"def one_line_description ( self ) : <TAB>  MAX_LINE_LENGTH = 120 <TAB>  desc = util . remove_html_tags ( self . description or "" "" ) <TAB>  desc = re . sub ( "" \ s+ "" , "" "" , desc ) . strip ( ) <TAB>  if not desc : <TAB><TAB>  return _ ( "" No description available "" ) <TAB>  else : <TAB><TAB>  # Decode the description to avoid gPodder bug 1277 <TAB><TAB>  desc = util . convert_bytes ( desc ) . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return desc [ : MAX_LINE_LENGTH ] + "" ... "" <TAB><TAB>  else : <TAB><TAB><TAB>  return desc ",if len ( desc ) > MAX_LINE_LENGTH :,if desc.endswith('\n'):,False,57.00388945560342,94.22345066497186
716,"def setInnerHTML ( self , html ) : <TAB>  log . HTMLClassifier . classify ( <TAB><TAB>  log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB>  ) <TAB>  self . tag . clear ( ) <TAB>  for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB><TAB>  self . tag . append ( node ) <TAB><TAB>  name = getattr ( node , "" name "" , None ) <TAB><TAB>  if name is None : <TAB><TAB><TAB>  continue <TAB><TAB>  handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  handler ( node ) ",if handler :,if handler is not None:,False,22.70396749739807,97.5147286164964
717,def get_supported_period_type_map ( cls ) : <TAB>  if cls . supported_period_map is None : <TAB><TAB>  cls . supported_period_map = { } <TAB><TAB>  cls . supported_period_map . update ( cls . period_type_map ) <TAB><TAB>  try : <TAB><TAB><TAB>  from dateutil import relativedelta <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cls . supported_period_map . update ( cls . optional_period_type_map ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  pass <TAB>  return cls . supported_period_map ,if relativedelta is not None :,if relativedelta.is_aware(relivedelta):,False,47.52605593185385,95.09359813890286
718,"def _compare_single_run ( self , compares_done ) : <TAB>  try : <TAB><TAB>  compare_id , redo = self . in_queue . get ( <TAB><TAB><TAB>  timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB><TAB>  ) <TAB>  except Empty : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if redo : <TAB><TAB><TAB><TAB>  self . db_interface . delete_old_compare_result ( compare_id ) <TAB><TAB><TAB>  compares_done . add ( compare_id ) <TAB><TAB><TAB>  self . _process_compare ( compare_id ) <TAB><TAB><TAB>  if self . callback : <TAB><TAB><TAB><TAB>  self . callback ( ) ","if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :",if compare_id not in compares_done:,False,49.42592702886007,91.51330436816632
719,"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB>  for line in raw_string . splitlines ( ) : <TAB><TAB>  for field_name in field_names : <TAB><TAB><TAB>  field_name = field_name . lower ( ) <TAB><TAB><TAB>  if "" : "" in line : <TAB><TAB><TAB><TAB>  left , right = line . split ( "" : "" , 1 ) <TAB><TAB><TAB><TAB>  left = left . strip ( ) . lower ( ) <TAB><TAB><TAB><TAB>  right = right . strip ( ) <TAB><TAB><TAB><TAB>  if left == field_name and len ( right ) > 0 : <TAB><TAB><TAB><TAB><TAB>  if cant_be_number : <TAB><TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  return right <TAB><TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB><TAB>  return right <TAB>  return None ",if not right . isdigit ( ) :,if left == field_name and right == field_name:,False,25.26020064205704,95.27043145681851
720,"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB>  res = [ ] <TAB>  while True : <TAB><TAB>  res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB><TAB>  if not s . consume ( "" \\ "" ) : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB><TAB><TAB>  res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  s . expect_re ( _escapes_re ) <TAB><TAB><TAB>  res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB>  return "" "" . join ( res ) ",if s . consume_re ( _newline_esc_re ) :,if s.consume_re(_short_re):,False,50.65959580303397,98.18029620437943
721,"def removedir ( self , path ) : <TAB>  # type: (Text) -> None <TAB>  _path = self . validatepath ( path ) <TAB>  if _path == "" / "" : <TAB><TAB>  raise errors . RemoveRootError ( ) <TAB>  with ftp_errors ( self , path ) : <TAB><TAB>  try : <TAB><TAB><TAB>  self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB><TAB>  except error_perm as error : <TAB><TAB><TAB>  code , _ = _parse_ftp_error ( error ) <TAB><TAB><TAB>  if code == "" 550 "" : <TAB><TAB><TAB><TAB>  if self . isfile ( path ) : <TAB><TAB><TAB><TAB><TAB>  raise errors . DirectoryExpected ( path ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise errors . DirectoryNotEmpty ( path ) <TAB><TAB><TAB>  raise<TAB># pragma: no cover ",if not self . isempty ( path ) :,"if code == ""404':",False,27.25336756266864,95.70347645981101
722,"def _normalize_store_path ( self , resource_store ) : <TAB>  if resource_store [ "" type "" ] == "" filesystem "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  resource_store [ "" base_directory "" ] = os . path . join ( <TAB><TAB><TAB><TAB>  self . root_directory , resource_store [ "" base_directory "" ] <TAB><TAB><TAB>  ) <TAB>  return resource_store ","if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :",if resource_store['base_directory'] is not None:,False,42.337854696539225,87.2120773269929
723,"def _apply_nested ( name , val , nested ) : <TAB>  parts = name . split ( "" . "" ) <TAB>  cur = nested <TAB>  for i in range ( 0 , len ( parts ) - 1 ) : <TAB><TAB>  cur = cur . setdefault ( parts [ i ] , { } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  conflicts_with = "" . "" . join ( parts [ 0 : i + 1 ] ) <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" %r  cannot be nested: conflicts with  { %r :  %s } "" <TAB><TAB><TAB><TAB>  % ( name , conflicts_with , cur ) <TAB><TAB><TAB>  ) <TAB>  cur [ parts [ - 1 ] ] = val ","if not isinstance ( cur , dict ) :",if cur is None:,False,27.422228268442982,94.5121558355467
724,"def build_packages ( targeted_packages , distribution_directory , is_dev_build = False ) : <TAB>  # run the build and distribution <TAB>  for package_root in targeted_packages : <TAB><TAB>  service_hierarchy = os . path . join ( os . path . basename ( package_root ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  verify_update_package_requirement ( package_root ) <TAB><TAB>  print ( "" Generating Package Using Python  {} "" . format ( sys . version ) ) <TAB><TAB>  run_check_call ( <TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB>  sys . executable , <TAB><TAB><TAB><TAB>  build_packing_script_location , <TAB><TAB><TAB><TAB>  "" --dest "" , <TAB><TAB><TAB><TAB>  os . path . join ( distribution_directory , service_hierarchy ) , <TAB><TAB><TAB><TAB>  package_root , <TAB><TAB><TAB>  ] , <TAB><TAB><TAB>  root_dir , <TAB><TAB>  ) ",if is_dev_build :,if is_dev_build:,False,56.29417000107306,100.00000000000004
725,"def resolve_root_node_address ( self , root_node ) : <TAB>  if "" [ "" in root_node : <TAB><TAB>  name , numbers = root_node . split ( "" [ "" , maxsplit = 1 ) <TAB><TAB>  number = numbers . split ( "" , "" , maxsplit = 1 ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  number = number . split ( "" - "" ) [ 0 ] <TAB><TAB>  number = re . sub ( "" [^0-9] "" , "" "" , number ) <TAB><TAB>  root_node = name + number <TAB>  return root_node ","if ""-"" in number :",if '-' in number:,False,48.42554749783542,97.0833235429991
726,"def _map_args ( maps : dict , * * kwargs ) : <TAB>  # maps: key=old name, value= new name <TAB>  output = { } <TAB>  for name , val in kwargs . items ( ) : <TAB><TAB>  if name in maps : <TAB><TAB><TAB>  assert isinstance ( maps [ name ] , str ) <TAB><TAB><TAB>  output . update ( { maps [ name ] : val } ) <TAB><TAB>  else : <TAB><TAB><TAB>  output . update ( { name : val } ) <TAB>  for keys in maps . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB>  return output ",if keys not in output . keys ( ) :,if keys not in output:,False,17.587618868675055,96.77972536841753
727,"def next_item ( self , direction ) : <TAB>  """"""Selects next menu item, based on self._direction"""""" <TAB>  start , i = - 1 , 0 <TAB>  try : <TAB><TAB>  start = self . items . index ( self . _selected ) <TAB><TAB>  i = start + direction <TAB>  except : <TAB><TAB>  pass <TAB>  while True : <TAB><TAB>  if i == start : <TAB><TAB><TAB>  # Cannot find valid menu item <TAB><TAB><TAB>  self . select ( start ) <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  i = 0 <TAB><TAB><TAB>  continue <TAB><TAB>  if i < 0 : <TAB><TAB><TAB>  i = len ( self . items ) - 1 <TAB><TAB><TAB>  continue <TAB><TAB>  if self . select ( i ) : <TAB><TAB><TAB>  break <TAB><TAB>  i + = direction <TAB><TAB>  if start < 0 : <TAB><TAB><TAB>  start = 0 ",if i >= len ( self . items ) :,if i > len(self.items):,False,56.72461443578434,98.2045447083021
728,"def detect_reentrancy ( self , contract ) : <TAB>  for function in contract . functions_and_modifiers_declared : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . KEY in function . context : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  self . _explore ( function . entry_point , [ ] ) <TAB><TAB><TAB>  function . context [ self . KEY ] = True ",if function . is_implemented :,if function.entry_point.type == self.RETRIEVAL:,False,49.551789112572386,90.4029373588728
729,"def load_model ( self ) : <TAB>  if not os . path . exists ( self . get_filename ( absolute = True ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return { } , { } <TAB><TAB>  error ( <TAB><TAB><TAB>  "" Model file with pre-trained convolution layers not found. Download it here... "" , <TAB><TAB><TAB>  "" https://github.com/alexjc/neural-enhance/releases/download/v %s / %s "" <TAB><TAB><TAB>  % ( __version__ , self . get_filename ( ) ) , <TAB><TAB>  ) <TAB>  print ( ""   - Loaded file ` {} ` with trained model. "" . format ( self . get_filename ( ) ) ) <TAB>  return pickle . load ( bz2 . open ( self . get_filename ( ) , "" rb "" ) ) ",if args . train :,if not os.path.exists(self.get_filename()):,False,58.239815770513026,92.7232618599497
730,"def get_nonexisting_check_definition_extends ( definition , indexed_oval_defs ) : <TAB>  # TODO: handle multiple levels of referrals. <TAB>  # OVAL checks that go beyond one level of extend_definition won't be properly identified <TAB>  for extdefinition in definition . findall ( "" .// { %s }extend_definition "" % oval_ns ) : <TAB><TAB>  # Verify each extend_definition in the definition <TAB><TAB>  extdefinitionref = extdefinition . get ( "" definition_ref "" ) <TAB><TAB>  # Search the OVAL tree for a definition with the referred ID <TAB><TAB>  referreddefinition = indexed_oval_defs . get ( extdefinitionref ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # There is no oval satisfying the extend_definition referal <TAB><TAB><TAB>  return extdefinitionref <TAB>  return None ",if referreddefinition is None :,if referreddefinition is not None:,False,46.722926646578685,98.70958875144461
731,"def pause ( self ) : <TAB>  if self . is_playing : <TAB><TAB>  self . state = MusicPlayerState . PAUSED <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _current_player . pause ( ) <TAB><TAB>  self . emit ( "" pause "" , player = self , entry = self . current_entry ) <TAB><TAB>  return <TAB>  elif self . is_paused : <TAB><TAB>  return <TAB>  raise ValueError ( "" Cannot pause a MusicPlayer in state  %s "" % self . state ) ",if self . _current_player :,if self._current_player:,False,57.34878042726562,100.00000000000004
732,"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _FORM_VISIT_LIST . pop ( )<TAB># Remove the current form. if it is at the end of the list <TAB><TAB>  if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM : <TAB><TAB><TAB>  # take no action if it looks as if someone has already set the next form. <TAB><TAB><TAB>  self . setNextForm ( <TAB><TAB><TAB><TAB>  self . _FORM_VISIT_LIST . pop ( ) <TAB><TAB><TAB>  )<TAB># Switch to the previous form if one exists <TAB>  except IndexError : <TAB><TAB>  self . setNextForm ( backup ) ",if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,if self._THISFORM.FORM_NAME == backup:,False,53.86342007713032,92.42880778784033
733,"def get_expr_referrers ( schema : s_schema . Schema , obj : so . Object ) - > Dict [ so . Object , str ] : <TAB>  """"""Return schema referrers with refs in expressions."""""" <TAB>  refs = schema . get_referrers_ex ( obj ) <TAB>  result = { } <TAB>  for ( mcls , fn ) , referrers in refs . items ( ) : <TAB><TAB>  field = mcls . get_field ( fn ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . update ( { ref : fn for ref in referrers } ) <TAB>  return result ","if issubclass ( field . type , ( Expression , ExpressionList ) ) :",if field.is_referrers:,False,26.045770094638037,91.50659958581235
734,"def _fields_to_index ( cls ) : <TAB>  fields = [ ] <TAB>  for field in cls . _meta . sorted_fields : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  requires_index = any ( <TAB><TAB><TAB>  ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB><TAB>  ) <TAB><TAB>  if requires_index : <TAB><TAB><TAB>  fields . append ( field ) <TAB>  return fields ",if field . primary_key :,"if not isinstance(field, ForeignKeyField):",False,20.738642094362394,93.70905659158826
735,"def ident_values ( self ) : <TAB>  value = self . _ident_values <TAB>  if value is False : <TAB><TAB>  value = None <TAB><TAB>  # XXX: how will this interact with orig_prefix ? <TAB><TAB>  #<TAB>  not exposing attrs for now if orig_prefix is set. <TAB><TAB>  if not self . orig_prefix : <TAB><TAB><TAB>  wrapped = self . wrapped <TAB><TAB><TAB>  idents = getattr ( wrapped , "" ident_values "" , None ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = [ self . _wrap_hash ( ident ) for ident in idents ] <TAB><TAB><TAB>  ##else: <TAB><TAB><TAB>  ##<TAB>ident = self.ident <TAB><TAB><TAB>  ##<TAB>if ident is not None: <TAB><TAB><TAB>  ##<TAB><TAB>value = [ident] <TAB><TAB>  self . _ident_values = value <TAB>  return value ",if idents :,if idents is not None:,False,62.17513154858463,98.28291419283269
736,"def apply_incpaths_ml ( self ) : <TAB>  inc_lst = self . includes . split ( ) <TAB>  lst = self . incpaths_lst <TAB>  for dir in inc_lst : <TAB><TAB>  node = self . path . find_dir ( dir ) <TAB><TAB>  if not node : <TAB><TAB><TAB>  error ( "" node not found:  "" + str ( dir ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lst . append ( node ) <TAB><TAB>  self . bld_incpaths_lst . append ( node ) ",if not node in lst :,if not node.is_ml_dir(dir):,False,25.23196859254166,93.23890928488603
737,"def application_openFiles_ ( self , nsapp , filenames ) : <TAB>  # logging.info('[osx] file open') <TAB>  # logging.info('[osx] file : %s' % (filenames)) <TAB>  for filename in filenames : <TAB><TAB>  logging . info ( "" [osx] receiving from macOS :  %s "" , filename ) <TAB><TAB>  if os . path . exists ( filename ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sabnzbd . add_nzbfile ( filename , keep = True ) ",if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES :,if os.path.exists(filename):,False,33.68135969004227,86.77663891551082
738,"def check ( self , xp , nout ) : <TAB>  input = xp . asarray ( self . x ) . astype ( numpy . float32 ) <TAB>  with warnings . catch_warnings ( ) : <TAB><TAB>  if self . ignore_warning : <TAB><TAB><TAB>  warnings . simplefilter ( "" ignore "" , self . ignore_warning ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . check_positive ( xp , self . func , input , self . eps , nout ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . check_negative ( xp , self . func , input , self . eps , nout ) ",if self . result :,if self.is_positive(input):,False,49.26573400860449,95.2600618654947
739,"def _set_scheme ( url , newscheme ) : <TAB>  scheme = _get_scheme ( url ) <TAB>  newscheme = newscheme or "" "" <TAB>  newseparator = "" : "" if newscheme in COLON_SEPARATED_SCHEMES else "" :// "" <TAB>  if scheme == "" "" :<TAB># Protocol relative URL. <TAB><TAB>  url = "" %s : %s "" % ( newscheme , url ) <TAB>  elif scheme is None and url :<TAB># No scheme. <TAB><TAB>  url = "" "" . join ( [ newscheme , newseparator , url ] ) <TAB>  elif scheme :<TAB># Existing scheme. <TAB><TAB>  remainder = url [ len ( scheme ) : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  remainder = remainder [ 3 : ] <TAB><TAB>  elif remainder . startswith ( "" : "" ) : <TAB><TAB><TAB>  remainder = remainder [ 1 : ] <TAB><TAB>  url = "" "" . join ( [ newscheme , newseparator , remainder ] ) <TAB>  return url ","if remainder . startswith ( ""://"" ) :",if remainder.startswith(':') and remainder.startswith(':,False,53.245126459988576,90.34051947036046
740,"def parquet ( tables , data_directory , ignore_missing_dependency , * * params ) : <TAB>  try : <TAB><TAB>  import pyarrow as pa<TAB># noqa: F401 <TAB><TAB>  import pyarrow . parquet as pq<TAB># noqa: F401 <TAB>  except ImportError : <TAB><TAB>  msg = "" PyArrow dependency is missing "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( "" Ignored:  %s "" , msg ) <TAB><TAB><TAB>  return 0 <TAB><TAB>  else : <TAB><TAB><TAB>  raise click . ClickException ( msg ) <TAB>  data_directory = Path ( data_directory ) <TAB>  for table , df in read_tables ( tables , data_directory ) : <TAB><TAB>  arrow_table = pa . Table . from_pandas ( df ) <TAB><TAB>  target_path = data_directory / "" {} .parquet "" . format ( table ) <TAB><TAB>  pq . write_table ( arrow_table , str ( target_path ) ) ",if ignore_missing_dependency :,if ignore_missing_dependency:,False,11.501465803612588,96.38437799560133
741,"def h2i ( self , pkt , s ) : <TAB>  t = ( ) <TAB>  if type ( s ) is str : <TAB><TAB>  t = time . strptime ( s ) <TAB><TAB>  t = t [ : 2 ] + t [ 2 : - 3 ] <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y , m , d , h , min , sec , rest , rest , rest = time . gmtime ( time . time ( ) ) <TAB><TAB><TAB>  t = ( y , m , d , h , min , sec ) <TAB><TAB>  else : <TAB><TAB><TAB>  t = s <TAB>  return t ",if not s :,if type(s) is int:,False,22.488050339108696,93.51932270211941
742,"def filter_episodes ( self , batch , cross_entropy ) : <TAB>  """"""Filter the episodes for the cross_entropy method"""""" <TAB>  accumulated_reward = [ sum ( rewards ) for rewards in batch [ "" rewards "" ] ] <TAB>  percentile = cross_entropy * 100 <TAB>  reward_bound = np . percentile ( accumulated_reward , percentile ) <TAB>  # we save the batch with reward above the bound <TAB>  result = { k : [ ] for k in self . data_keys } <TAB>  episode_kept = 0 <TAB>  for i in range ( len ( accumulated_reward ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for k in self . data_keys : <TAB><TAB><TAB><TAB>  result [ k ] . append ( batch [ k ] [ i ] ) <TAB><TAB><TAB>  episode_kept + = 1 <TAB>  return result ",if accumulated_reward [ i ] >= reward_bound :,if reward_bound <= i:,False,60.621793432733504,95.18972165814868
743,"def _readenv ( var , msg ) : <TAB>  match = _ENV_VAR_PAT . match ( var ) <TAB>  if match and match . groups ( ) : <TAB><TAB>  envvar = match . groups ( ) [ 0 ] <TAB><TAB>  if envvar in os . environ : <TAB><TAB><TAB>  value = os . environ [ envvar ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = value . decode ( "" utf8 "" ) <TAB><TAB><TAB>  return value <TAB><TAB>  else : <TAB><TAB><TAB>  raise InvalidConfigException ( <TAB><TAB><TAB><TAB>  "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise InvalidConfigException ( <TAB><TAB><TAB>  "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB><TAB><TAB><TAB>  msg , var , _ENV_VAR_PAT_STR <TAB><TAB><TAB>  ) <TAB><TAB>  ) ",if six . PY2 :,"if isinstance(value, unicode):",False,55.04566442766381,97.32371147670816
744,"def _allocate_nbd ( self ) : <TAB>  if not os . path . exists ( "" /sys/block/nbd0 "" ) : <TAB><TAB>  self . error = _ ( "" nbd unavailable: module not loaded "" ) <TAB><TAB>  return None <TAB>  while True : <TAB><TAB>  if not self . _DEVICES : <TAB><TAB><TAB>  # really want to log this info, not raise <TAB><TAB><TAB>  self . error = _ ( "" No free nbd devices "" ) <TAB><TAB><TAB>  return None <TAB><TAB>  device = self . _DEVICES . pop ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return device ","if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :",if device is None:,False,58.395576832888196,84.30823385598066
745,"def _expand_deps_java_generation ( self ) : <TAB>  """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB>  queue = collections . deque ( self . deps ) <TAB>  keys = set ( ) <TAB>  while queue : <TAB><TAB>  k = queue . popleft ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  keys . add ( k ) <TAB><TAB><TAB>  dep = self . target_database [ k ] <TAB><TAB><TAB>  if "" generate_java "" in dep . attr :<TAB># Has this attribute <TAB><TAB><TAB><TAB>  dep . attr [ "" generate_java "" ] = True <TAB><TAB><TAB><TAB>  queue . extend ( dep . deps ) ",if k not in keys :,if k not in keys:,False,60.325787292599856,97.64481296572748
746,"def load_syntax ( syntax ) : <TAB>  context = _create_scheme ( ) or { } <TAB>  partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB>  scanners = { } <TAB>  for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB><TAB>  scanners [ part_name ] = Scanner ( part_scanner ) <TAB>  formats = [ ] <TAB>  for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB><TAB>  if isinstance ( fstyle , basestring ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  key = fstyle [ 2 : - 2 ] <TAB><TAB><TAB><TAB>  fstyle = context [ key ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  fstyle = fstyle % context <TAB><TAB>  formats . append ( ( fname , fstyle ) ) <TAB>  return partition_scanner , scanners , formats ","if fstyle . startswith ( ""%("" ) and fstyle . endswith ( "")s"" ) :",if fstyle.endswith('.py'):,False,28.345043247488068,93.26296608608007
747,"def rollback ( self ) : <TAB>  for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values . remove ( ) <TAB><TAB>  elif operation == "" update "" : <TAB><TAB><TAB>  old_value , new_value = values <TAB><TAB><TAB>  if new_value . full_filename != old_value . full_filename : <TAB><TAB><TAB><TAB>  os . unlink ( new_value . full_filename ) <TAB><TAB><TAB>  old_value . write ( ) <TAB>  self . _post_xact_cleanup ( ) ","if operation == ""insert"" :","if operation == ""delete':",False,44.22826922022938,96.35550667469607
748,"def _buildOffsets ( offsetDict , localeData , indexStart ) : <TAB>  o = indexStart <TAB>  for key in localeData : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for k in key . split ( "" | "" ) : <TAB><TAB><TAB><TAB>  offsetDict [ k ] = o <TAB><TAB>  else : <TAB><TAB><TAB>  offsetDict [ key ] = o <TAB><TAB>  o + = 1 ","if ""|"" in key :",if key.startswith('|') and key.endswith('|') and (not,False,18.474193902573298,82.82568355663618
749,"def _check_start_pipeline_execution_errors ( <TAB>  graphene_info , execution_params , execution_plan  ) : <TAB>  if execution_params . step_keys : <TAB><TAB>  for step_key in execution_params . step_keys : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise UserFacingGraphQLError ( <TAB><TAB><TAB><TAB><TAB>  graphene_info . schema . type_named ( "" InvalidStepError "" ) ( <TAB><TAB><TAB><TAB><TAB><TAB>  invalid_step_key = step_key <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  ) ",if not execution_plan . has_step ( step_key ) :,if step_key not in graphene_info.schema.type_named('InvalidStep,False,47.15357770517392,91.96422480183486
750,"def __setattr__ ( self , option_name , option_value ) : <TAB>  if option_name in self . _options : <TAB><TAB>  # type checking <TAB><TAB>  sort = self . OPTIONS [ self . arch . name ] [ option_name ] [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _options [ option_name ] = option_value <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  ' Value for option  "" %s ""  must be of type  %s ' % ( option_name , sort ) <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  super ( CFGArchOptions , self ) . __setattr__ ( option_name , option_value ) ","if sort is None or isinstance ( option_value , sort ) :",if sort == 'option':,False,53.64599865167268,91.26885056008423
751,"def value ( self ) : <TAB>  quote = False <TAB>  if self . defects : <TAB><TAB>  quote = True <TAB>  else : <TAB><TAB>  for x in self : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  quote = True <TAB>  if quote : <TAB><TAB>  pre = post = "" "" <TAB><TAB>  if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB><TAB><TAB>  pre = "" "" <TAB><TAB>  if self [ - 1 ] . token_type == "" cfws "" or self [ - 1 ] [ - 1 ] . token_type == "" cfws "" : <TAB><TAB><TAB>  post = "" "" <TAB><TAB>  return pre + quote_string ( self . display_name ) + post <TAB>  else : <TAB><TAB>  return super ( DisplayName , self ) . value ","if x . token_type == ""quoted-string"" :",if x.value == 1:,False,29.630967887490556,93.31589141231738
752,"def __init__ ( self , patch_files , patch_directories ) : <TAB>  files = [ ] <TAB>  files_data = { } <TAB>  for filename_data in patch_files : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename , data = filename_data <TAB><TAB>  else : <TAB><TAB><TAB>  filename = filename_data <TAB><TAB><TAB>  data = None <TAB><TAB>  if not filename . startswith ( os . sep ) : <TAB><TAB><TAB>  filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB><TAB>  files . append ( filename ) <TAB><TAB>  if data : <TAB><TAB><TAB>  files_data [ filename ] = data <TAB>  self . files = files <TAB>  self . files_data = files_data <TAB>  self . directories = patch_directories ","if isinstance ( filename_data , list ) :","if isinstance(filename_data, tuple):",False,50.882193886140215,98.88759619536245
753,"def _evaluateStack ( s ) : <TAB>  op = s . pop ( ) <TAB>  if op in "" +-*/@^ "" : <TAB><TAB>  op2 = _evaluateStack ( s ) <TAB><TAB>  op1 = _evaluateStack ( s ) <TAB><TAB>  result = opn [ op ] ( op1 , op2 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( result ) <TAB><TAB>  return result <TAB>  else : <TAB><TAB>  return op ",if debug_flag :,if result:,False,26.13816709318518,96.19542838518
754,"def reconnect_user ( self , user_id , host_id , server_id ) : <TAB>  if host_id == settings . local . host_id : <TAB><TAB>  return <TAB>  if server_id and self . server . id != server_id : <TAB><TAB>  return <TAB>  for client in self . clients . find ( { "" user_id "" : user_id } ) : <TAB><TAB>  self . clients . update_id ( <TAB><TAB><TAB>  client [ "" id "" ] , <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" ignore_routes "" : True , <TAB><TAB><TAB>  } , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . instance . disconnect_wg ( client [ "" id "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . instance_com . client_kill ( client [ "" id "" ] ) ","if len ( client [ ""id"" ] ) > 32 :",if self.instance:,False,49.059270341591834,94.93476449664753
755,"def _get_library ( self , name , args ) : <TAB>  library_database = self . _library_manager . get_new_connection_to_library_database ( ) <TAB>  try : <TAB><TAB>  last_updated = library_database . get_library_last_updated ( name , args ) <TAB><TAB>  if last_updated : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _library_manager . fetch_keywords ( <TAB><TAB><TAB><TAB><TAB>  name , args , self . _libraries_need_refresh_listener <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return library_database . fetch_library_keywords ( name , args ) <TAB><TAB>  return self . _library_manager . get_and_insert_keywords ( name , args ) <TAB>  finally : <TAB><TAB>  library_database . close ( ) ",if time . time ( ) - last_updated > 10.0 :,if last_updated:,False,48.54079950056534,95.28397144545556
756,"def get_paths ( self , path , commit ) : <TAB>  """"""Return a generator of all filepaths under path at commit."""""" <TAB>  _check_path_is_repo_relative ( path ) <TAB>  git_path = _get_git_path ( path ) <TAB>  tree = self . gl_repo . git_repo [ commit . tree [ git_path ] . id ] <TAB>  assert tree . type == pygit2 . GIT_OBJ_TREE <TAB>  for tree_entry in tree : <TAB><TAB>  tree_entry_path = os . path . join ( path , tree_entry . name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for fp in self . get_paths ( tree_entry_path , commit ) : <TAB><TAB><TAB><TAB>  yield fp <TAB><TAB>  else : <TAB><TAB><TAB>  yield tree_entry_path ","if tree_entry . type == ""tree"" :",if os.path.isdir(tree_entry_path):,False,29.479617034806218,94.7530186480347
757,"def scan_resource_conf ( self , conf ) : <TAB>  if "" properties "" in conf : <TAB><TAB>  if "" attributes "" in conf [ "" properties "" ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB><TAB><TAB><TAB><TAB>  return CheckResult . PASSED <TAB>  return CheckResult . FAILED ","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :","if ""attributes"" in conf:",False,24.009271677316057,88.92274220793567
758,"def _set_parse_context ( self , tag , tag_attrs ) : <TAB>  # special case: script or style parse context <TAB>  if not self . _wb_parse_context : <TAB><TAB>  if tag == "" style "" : <TAB><TAB><TAB>  self . _wb_parse_context = "" style "" <TAB><TAB>  elif tag == "" script "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _wb_parse_context = "" script "" ",if self . _allow_js_type ( tag_attrs ) :,"if tag == ""script':",False,34.252916158656355,89.59569982266845
759,"def modified ( self ) : <TAB>  paths = set ( ) <TAB>  dictionary_list = [ ] <TAB>  for op_list in self . _operations : <TAB><TAB>  if not isinstance ( op_list , list ) : <TAB><TAB><TAB>  op_list = ( op_list , ) <TAB><TAB>  for item in chain ( * op_list ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  dictionary = item . dictionary <TAB><TAB><TAB>  if dictionary . path in paths : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  paths . add ( dictionary . path ) <TAB><TAB><TAB>  dictionary_list . append ( dictionary ) <TAB>  return dictionary_list ",if item is None :,"if not isinstance(item, dict):",False,32.64576886602325,95.91890481420577
760,def preorder ( root ) : <TAB>  res = [ ] <TAB>  if not root : <TAB><TAB>  return res <TAB>  stack = [ ] <TAB>  stack . append ( root ) <TAB>  while stack : <TAB><TAB>  root = stack . pop ( ) <TAB><TAB>  res . append ( root . val ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stack . append ( root . right ) <TAB><TAB>  if root . left : <TAB><TAB><TAB>  stack . append ( root . left ) <TAB>  return res ,if root . right :,if root.right:,False,50.660858297990764,100.00000000000004
761,"def create ( exported_python_target ) : <TAB>  if exported_python_target not in created : <TAB><TAB>  self . context . log . info ( <TAB><TAB><TAB>  "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB><TAB>  ) <TAB><TAB>  subject = self . derived_by_original . get ( <TAB><TAB><TAB>  exported_python_target , exported_python_target <TAB><TAB>  ) <TAB><TAB>  setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB><TAB>  created [ exported_python_target ] = setup_dir <TAB><TAB>  if self . _recursive : <TAB><TAB><TAB>  for dep in dependencies : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  create ( dep ) ",if is_exported_python_target ( dep ) :,if dep.project == exported_python_target:,False,51.584143730516715,96.5959269181438
762,"def test_array_interface ( self , data ) : <TAB>  result = np . array ( data ) <TAB>  np . testing . assert_array_equal ( result [ 0 ] , data [ 0 ] ) <TAB>  result = np . array ( data , dtype = object ) <TAB>  expected = np . array ( list ( data ) , dtype = object ) <TAB>  for a1 , a2 in zip ( result , expected ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert np . isnan ( a1 ) and np . isnan ( a2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  tm . assert_numpy_array_equal ( a2 , a1 ) ",if np . isscalar ( a1 ) :,if a1 is a2:,False,22.0560709190444,95.47176555875959
763,"def valueChanged ( plug ) : <TAB>  changed = plug . getInput ( ) is not None <TAB>  if not changed and isinstance ( plug , Gaffer . ValuePlug ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  changed = not Gaffer . NodeAlgo . isSetToUserDefault ( plug ) <TAB><TAB>  else : <TAB><TAB><TAB>  changed = not plug . isSetToDefault ( ) <TAB>  return changed ",if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,if plug.isSetToUserDefault():,False,47.19237951482217,92.15699279197322
764,"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB>  with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB><TAB>  version = load_version_data ( hive_name , company , tag , tag_key ) <TAB><TAB>  <IF-STMT>:<TAB># if failed to get version bail <TAB><TAB><TAB>  major , minor , _ = version <TAB><TAB><TAB>  arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB><TAB><TAB>  if arch is not None : <TAB><TAB><TAB><TAB>  exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB><TAB><TAB><TAB>  if exe_data is not None : <TAB><TAB><TAB><TAB><TAB>  exe , args = exe_data <TAB><TAB><TAB><TAB><TAB>  return company , major , minor , arch , exe , args ",if version is not None :,if version is None:,False,52.45562649381175,97.70726134517544
765,"def __iter__ ( self ) : <TAB>  for name , value in self . __class__ . __dict__ . items ( ) : <TAB><TAB>  if isinstance ( value , alias_flag_value ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield ( name , self . _has_flag ( value . flag ) ) ","if isinstance ( value , flag_value ) :",if name == 'flag':,False,24.753142561239578,90.78403418022693
766,"def connect ( self ) : <TAB>  self . sock = sockssocket ( ) <TAB>  self . sock . setproxy ( * proxy_args ) <TAB>  if type ( self . timeout ) in ( int , float ) : <TAB><TAB>  self . sock . settimeout ( self . timeout ) <TAB>  self . sock . connect ( ( self . host , self . port ) ) <TAB>  if isinstance ( self , compat_http_client . HTTPSConnection ) : <TAB><TAB>  <IF-STMT>:<TAB># Python > 2.6 <TAB><TAB><TAB>  self . sock = self . _context . wrap_socket ( self . sock , server_hostname = self . host ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . sock = ssl . wrap_socket ( self . sock ) ","if hasattr ( self , ""_context"" ) :","if hasattr(self._context, 'wrap_socket'):",False,48.57794390225195,93.74184168641368
767,"def frequent_thread_switches ( ) : <TAB>  """"""Make concurrency bugs more likely to manifest."""""" <TAB>  interval = None <TAB>  if not sys . platform . startswith ( "" java "" ) : <TAB><TAB>  if hasattr ( sys , "" getswitchinterval "" ) : <TAB><TAB><TAB>  interval = sys . getswitchinterval ( ) <TAB><TAB><TAB>  sys . setswitchinterval ( 1e-6 ) <TAB><TAB>  else : <TAB><TAB><TAB>  interval = sys . getcheckinterval ( ) <TAB><TAB><TAB>  sys . setcheckinterval ( 1 ) <TAB>  try : <TAB><TAB>  yield <TAB>  finally : <TAB><TAB>  if not sys . platform . startswith ( "" java "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sys . setswitchinterval ( interval ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  sys . setcheckinterval ( interval ) ","if hasattr ( sys , ""setswitchinterval"" ) :","if hasattr(sys, 'setswitchinterval'):",False,28.50311103404809,98.07932214753967
768,"def vars ( self ) : <TAB>  ret = [ ] <TAB>  if op . intlist : <TAB><TAB>  varlist = op . intlist <TAB>  else : <TAB><TAB>  varlist = self . discover <TAB><TAB>  for name in varlist : <TAB><TAB><TAB>  if name in ( "" 0 "" , "" 1 "" , "" 2 "" , "" 8 "" , "" CPU0 "" , "" ERR "" , "" LOC "" , "" MIS "" , "" NMI "" ) : <TAB><TAB><TAB><TAB>  varlist . remove ( name ) <TAB><TAB>  if not op . full and len ( varlist ) > 3 : <TAB><TAB><TAB>  varlist = varlist [ - 3 : ] <TAB>  for name in varlist : <TAB><TAB>  if name in self . discover : <TAB><TAB><TAB>  ret . append ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret . append ( self . intmap [ name . lower ( ) ] ) <TAB>  return ret ",elif name . lower ( ) in self . intmap :,if name.lower() in self.intmap:,False,50.85345106395744,97.52723465800457
769,"def deleteDuplicates ( gadgets , callback = None ) : <TAB>  toReturn = [ ] <TAB>  inst = set ( ) <TAB>  count = 0 <TAB>  added = False <TAB>  len_gadgets = len ( gadgets ) <TAB>  for i , gadget in enumerate ( gadgets ) : <TAB><TAB>  inst . add ( gadget . _gadget ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  count = len ( inst ) <TAB><TAB><TAB>  toReturn . append ( gadget ) <TAB><TAB><TAB>  added = True <TAB><TAB>  if callback : <TAB><TAB><TAB>  callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB><TAB><TAB>  added = False <TAB>  return toReturn ",if len ( inst ) > count :,if len(inst) > len(inst):,False,39.69418582976876,97.06106559393454
770,"def ident ( self ) : <TAB>  value = self . _ident <TAB>  if value is False : <TAB><TAB>  value = None <TAB><TAB>  # XXX: how will this interact with orig_prefix ? <TAB><TAB>  #<TAB>  not exposing attrs for now if orig_prefix is set. <TAB><TAB>  if not self . orig_prefix : <TAB><TAB><TAB>  wrapped = self . wrapped <TAB><TAB><TAB>  ident = getattr ( wrapped , "" ident "" , None ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = self . _wrap_hash ( ident ) <TAB><TAB>  self . _ident = value <TAB>  return value ",if ident is not None :,if ident is not None:,False,63.58872061340672,100.00000000000004
771,"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB>  """"""Take a nested dict and return a flat dict of setting values."""""" <TAB>  setting_values = { } <TAB>  for field in form . c : <TAB><TAB>  if isinstance ( field , _ContainerMixin ) : <TAB><TAB><TAB>  setting_values . update ( <TAB><TAB><TAB><TAB>  self . _flatten_settings_from_form ( <TAB><TAB><TAB><TAB><TAB>  settings , field , form_values [ field . _name ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setting_values [ field . _name ] = form_values [ field . _name ] <TAB>  return setting_values ",elif field . _name in settings :,"if hasattr(field, '_name'):",False,57.67094744499198,95.3510727446656
772,"def _decorator ( cls ) : <TAB>  for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB><TAB>  if name not in cls . __dict__ : <TAB><TAB><TAB>  continue <TAB><TAB>  if name != "" __init__ "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  if name in butnot : <TAB><TAB><TAB>  continue <TAB><TAB>  setattr ( cls , name , decorator ( meth ) ) <TAB>  return cls ","if not private and name . startswith ( ""_"" ) :","if name in (__name__, '__init__'):",False,24.38882692399301,89.13486182896413
773,"def _do_cmp ( f1 , f2 ) : <TAB>  bufsize = BUFSIZE <TAB>  with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB><TAB>  while True : <TAB><TAB><TAB>  b1 = fp1 . read ( bufsize ) <TAB><TAB><TAB>  b2 = fp2 . read ( bufsize ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  if not b1 : <TAB><TAB><TAB><TAB>  return True ",if b1 != b2 :,if b1 != b2:,False,50.874431709910674,100.00000000000004
774,"def _memoized ( * args ) : <TAB>  now = time . time ( ) <TAB>  try : <TAB><TAB>  value , last_update = self . cache [ args ] <TAB><TAB>  age = now - last_update <TAB><TAB>  if self . _call_count > self . ctl or age > self . ttl : <TAB><TAB><TAB>  self . _call_count = 0 <TAB><TAB><TAB>  raise AttributeError <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _call_count + = 1 <TAB><TAB>  return value <TAB>  except ( KeyError , AttributeError ) : <TAB><TAB>  value = func ( * args ) <TAB><TAB>  if value : <TAB><TAB><TAB>  self . cache [ args ] = ( value , now ) <TAB><TAB>  return value <TAB>  except TypeError : <TAB><TAB>  return func ( * args ) ",if self . ctl :,if age < self.ctl:,False,29.73139282073668,98.42307799076669
775,"def check ( self , hyperlinks : Dict [ str , Hyperlink ] ) - > Generator [ CheckResult , None , None ] : <TAB>  self . invoke_threads ( ) <TAB>  total_links = 0 <TAB>  for hyperlink in hyperlinks . values ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield CheckResult ( <TAB><TAB><TAB><TAB>  hyperlink . uri , hyperlink . docname , hyperlink . lineno , "" ignored "" , "" "" , 0 <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . wqueue . put ( CheckRequest ( CHECK_IMMEDIATELY , hyperlink ) , False ) <TAB><TAB><TAB>  total_links + = 1 <TAB>  done = 0 <TAB>  while done < total_links : <TAB><TAB>  yield self . rqueue . get ( ) <TAB><TAB>  done + = 1 <TAB>  self . shutdown_threads ( ) ",if self . is_ignored_uri ( hyperlink . uri ) :,if hyperlink.type == Hyperlink.TYPE_IMMEDIATE:,False,20.253098166898706,94.58010687731867
776,"def remove_subscriber ( self , topic , subscriber ) : <TAB>  if subscriber in self . subscribers [ topic ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  subscriber . _pyroRelease ( ) <TAB><TAB>  if hasattr ( subscriber , "" _pyroUri "" ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB><TAB>  proxy . _pyroRelease ( ) <TAB><TAB><TAB><TAB>  del self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  self . subscribers [ topic ] . discard ( subscriber ) ","if hasattr ( subscriber , ""_pyroRelease"" ) :","if hasattr(subscriber, '_pyroRelease'):",False,51.13631241315986,97.26775427768334
777,"def delete_arc ( collection , document , origin , target , type ) : <TAB>  directory = collection <TAB>  real_dir = real_directory ( directory ) <TAB>  mods = ModificationTracker ( ) <TAB>  projectconf = ProjectConfiguration ( real_dir ) <TAB>  document = path_join ( real_dir , document ) <TAB>  with TextAnnotations ( document ) as ann_obj : <TAB><TAB>  # bail as quick as possible if read-only <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AnnotationsIsReadOnlyError ( ann_obj . get_document ( ) ) <TAB><TAB>  _delete_arc_with_ann ( origin , target , type , mods , ann_obj , projectconf ) <TAB><TAB>  mods_json = mods . json_response ( ) <TAB><TAB>  mods_json [ "" annotations "" ] = _json_from_ann ( ann_obj ) <TAB><TAB>  return mods_json ",if ann_obj . _read_only :,if ann_obj.get_document() != document:,False,55.29439820210159,95.76054466941565
778,"def _select_from ( self , parent_path , is_dir , exists , listdir ) : <TAB>  if not is_dir ( parent_path ) : <TAB><TAB>  return <TAB>  with _cached ( listdir ) as listdir : <TAB><TAB>  yielded = set ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  successor_select = self . successor . _select_from <TAB><TAB><TAB>  for starting_point in self . _iterate_directories ( <TAB><TAB><TAB><TAB>  parent_path , is_dir , listdir <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  for p in successor_select ( starting_point , is_dir , exists , listdir ) : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  yield p <TAB><TAB><TAB><TAB><TAB><TAB>  yielded . add ( p ) <TAB><TAB>  finally : <TAB><TAB><TAB>  yielded . clear ( ) ",if p not in yielded :,if p in yielded:,False,50.82429115795165,99.05352064293194
779,"def _fractional_part ( self , n , expr , evaluation ) : <TAB>  n_sympy = n . to_sympy ( ) <TAB>  if n_sympy . is_constant ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  positive_integer_part = ( <TAB><TAB><TAB><TAB>  Expression ( "" Floor "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  result = n - positive_integer_part <TAB><TAB>  else : <TAB><TAB><TAB>  negative_integer_part = ( <TAB><TAB><TAB><TAB>  Expression ( "" Ceiling "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  result = n - negative_integer_part <TAB>  else : <TAB><TAB>  return expr <TAB>  return from_python ( result ) ",if n_sympy >= 0 :,if n_sympy.is_numeric():,False,50.84674894270969,96.86503189636606
780,"def check_bounds ( geometry ) : <TAB>  if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB><TAB>  return list ( map ( check_bounds , geometry ) ) <TAB>  else : <TAB><TAB>  if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Longitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Latitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB>  ) ",if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 :,if geometry[0] < -180 or geometry[0] > -180:,False,65.18592712218482,93.91958676482226
781,"def get_absolute_path ( self , root , path ) : <TAB>  # find the first absolute path that exists <TAB>  self . root = self . roots [ 0 ] <TAB>  for root in self . roots : <TAB><TAB>  abspath = os . path . abspath ( os . path . join ( root , path ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . root = root<TAB># make sure all the other methods in the base class know how to find the file <TAB><TAB><TAB>  break <TAB>  return abspath ",if os . path . exists ( abspath ) :,if abspath == root:,False,43.73087431445297,91.91435373805471
782,"def do_setflow ( self , l = "" "" ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  l = str ( self . flow_slider . GetValue ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  l = l . lower ( ) <TAB><TAB>  flow = int ( l ) <TAB><TAB>  if self . p . online : <TAB><TAB><TAB>  self . p . send_now ( "" M221 S "" + l ) <TAB><TAB><TAB>  self . log ( _ ( "" Setting print flow factor to  %d %% . "" ) % flow ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . logError ( _ ( "" Printer is not online. "" ) ) <TAB>  except Exception as x : <TAB><TAB>  self . logError ( _ ( "" You must enter a flow. ( %s ) "" ) % ( repr ( x ) , ) ) ","if not isinstance ( l , str ) or not len ( l ) :",if l == '':,False,50.52438879801586,93.9735265420582
783,"def sources ( ) : <TAB>  for d in os . listdir ( base ) : <TAB><TAB>  #<TAB><TAB>if d.startswith('talis'): <TAB><TAB>  #<TAB><TAB><TAB>continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if d == "" indcat "" : <TAB><TAB><TAB>  continue <TAB><TAB>  if not os . path . isdir ( base + d ) : <TAB><TAB><TAB>  continue <TAB><TAB>  yield d ","if d . endswith ( ""old"" ) :",if d == 'talis':,False,51.56080149692779,93.9732450651936
784,"def create_accumulator ( self ) - > tf_metric_accumulators . TFCompilableMetricsAccumulator : <TAB>  configs = zip ( self . _metric_configs , self . _loss_configs ) <TAB>  padding_options = None <TAB>  if self . _eval_config is not None : <TAB><TAB>  model_spec = model_util . get_model_spec ( self . _eval_config , self . _model_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  padding_options = model_spec . padding_options <TAB>  return tf_metric_accumulators . TFCompilableMetricsAccumulator ( <TAB><TAB>  padding_options , <TAB><TAB>  [ len ( m ) + len ( l ) for m , l in configs ] , <TAB><TAB>  desired_batch_size = self . _desired_batch_size , <TAB>  ) ","if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :",if model_spec:,False,47.86808341397123,91.44566375139073
785,"def parseImpl ( self , instring , loc , doActions = True ) : <TAB>  try : <TAB><TAB>  loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB>  except ( ParseException , IndexError ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . expr . resultsName : <TAB><TAB><TAB><TAB>  tokens = ParseResults ( [ self . defaultValue ] ) <TAB><TAB><TAB><TAB>  tokens [ self . expr . resultsName ] = self . defaultValue <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  tokens = [ self . defaultValue ] <TAB><TAB>  else : <TAB><TAB><TAB>  tokens = [ ] <TAB>  return loc , tokens ",if self . defaultValue is not self . __optionalNotMatched :,if self.defaultValue:,False,49.14870971613848,95.54164436668854
786,"def handleConnection ( self ) : <TAB>  # connection handshake <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  self . csock . close ( ) <TAB>  except : <TAB><TAB>  ex_t , ex_v , ex_tb = sys . exc_info ( ) <TAB><TAB>  tb = util . formatTraceback ( ex_t , ex_v , ex_tb ) <TAB><TAB>  log . warning ( "" error during connect/handshake:  %s ;  %s "" , ex_v , "" \n "" . join ( tb ) ) <TAB><TAB>  self . csock . close ( ) <TAB>  return False ",if self . daemon . _handshake ( self . csock ) :,if self.csock.connect():,False,26.06764918369003,95.07954336234025
787,"def getProc ( su , innerTarget ) : <TAB>  if len ( su ) == 1 :<TAB># have a one element wedge <TAB><TAB>  proc = ( "" first "" , "" last "" ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  proc = ( "" first "" , "" last "" )<TAB># same element can be first and last <TAB><TAB>  elif su . isFirst ( innerTarget ) : <TAB><TAB><TAB>  proc = ( "" first "" , ) <TAB><TAB>  elif su . isLast ( innerTarget ) : <TAB><TAB><TAB>  proc = ( "" last "" , ) <TAB><TAB>  else : <TAB><TAB><TAB>  proc = ( ) <TAB>  return proc ",if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,if su.isFirst(innerTarget):,False,51.65686417831906,94.53731981046987
788,"def get_color_dtype ( data , column_names ) : <TAB>  has_color = all ( column in data [ "" points "" ] for column in column_names ) <TAB>  if has_color : <TAB><TAB>  color_data_types = [ <TAB><TAB><TAB>  data [ "" points "" ] [ column_name ] . dtype for column_name in column_names <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  f "" Data types of color values are inconsistent: got  { color_data_types } "" <TAB><TAB><TAB>  ) <TAB><TAB>  color_data_type = color_data_types [ 0 ] <TAB>  else : <TAB><TAB>  color_data_type = None <TAB>  return color_data_type ",if len ( set ( color_data_types ) ) > 1 :,if len(color_data_types) != 1:,False,45.900614490108524,97.09300455947347
789,"def close ( self ) : <TAB>  children = [ ] <TAB>  for children_part , line_offset , last_line_offset_leaf in self . children_groups : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  _update_positions ( children_part , line_offset , last_line_offset_leaf ) <TAB><TAB><TAB>  except _PositionUpdatingFinished : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  children + = children_part <TAB>  self . tree_node . children = children <TAB>  # Reset the parents <TAB>  for node in children : <TAB><TAB>  node . parent = self . tree_node ",if line_offset != 0 :,if children_part.type == children_part.type:,False,45.38173744230784,92.82499112044745
790,"def get_multi ( self , keys , index = None ) : <TAB>  with self . _lmdb . begin ( ) as txn : <TAB><TAB>  result = [ ] <TAB><TAB>  for key in keys : <TAB><TAB><TAB>  packed = txn . get ( key . encode ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result . append ( ( key , cbor . loads ( packed ) ) ) <TAB>  return result ",if packed is not None :,if packed is not None:,False,52.43204025883469,100.00000000000004
791,"def get_directory_info ( prefix , pth , recursive ) : <TAB>  res = [ ] <TAB>  directory = os . listdir ( pth ) <TAB>  directory . sort ( ) <TAB>  for p in directory : <TAB><TAB>  if p [ 0 ] != "" . "" : <TAB><TAB><TAB>  subp = os . path . join ( pth , p ) <TAB><TAB><TAB>  p = os . path . join ( prefix , p ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  res . append ( [ p , None ] ) <TAB>  return res ",if recursive and os . path . isdir ( subp ) :,if recursive:,False,29.44096161041755,94.60955401623758
792,"def __schedule ( self , workflow_scheduler_id , workflow_scheduler ) : <TAB>  invocation_ids = self . __active_invocation_ids ( workflow_scheduler_id ) <TAB>  for invocation_id in invocation_ids : <TAB><TAB>  log . debug ( "" Attempting to schedule workflow invocation [ %s ] "" , invocation_id ) <TAB><TAB>  self . __attempt_schedule ( invocation_id , workflow_scheduler ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ",if not self . monitor_running :,if not self.__is_scheduled(invocation_id):,False,24.06987829079331,91.36124646594757
793,"def write ( self , data ) : <TAB>  self . size - = len ( data ) <TAB>  passon = None <TAB>  if self . size > 0 : <TAB><TAB>  self . data . append ( data ) <TAB>  else : <TAB><TAB>  if self . size : <TAB><TAB><TAB>  data , passon = data [ : self . size ] , data [ self . size : ] <TAB><TAB>  else : <TAB><TAB><TAB>  passon = b "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . data . append ( data ) <TAB>  return passon ",if data :,if passon is None:,False,20.62315772916343,96.94008326135823
794,"def __getstate__ ( self ) : <TAB>  try : <TAB><TAB>  store_func , load_func = self . store_function , self . load_function <TAB><TAB>  self . store_function , self . load_function = None , None <TAB><TAB>  # ignore analyses. we re-initialize analyses when restoring from pickling so that we do not lose any newly <TAB><TAB>  # added analyses classes <TAB><TAB>  d = dict ( <TAB><TAB><TAB>  ( k , v ) <TAB><TAB><TAB>  for k , v in self . __dict__ . items ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  not in { <TAB><TAB><TAB><TAB>  "" analyses "" , <TAB><TAB><TAB>  } <TAB><TAB>  ) <TAB><TAB>  return d <TAB>  finally : <TAB><TAB>  self . store_function , self . load_function = store_func , load_func ",if k,"if k not in ('analyses', 'objects'):",False,64.14570639025803,96.12702789907932
795,"def mouse_down ( self , event ) : <TAB>  if event . button == 1 : <TAB><TAB>  if self . scrolling : <TAB><TAB><TAB>  p = event . local <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . scroll_up ( ) <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB>  self . scroll_down ( ) <TAB><TAB><TAB><TAB>  return <TAB>  if event . button == 4 : <TAB><TAB>  self . scroll_up ( ) <TAB>  if event . button == 5 : <TAB><TAB>  self . scroll_down ( ) <TAB>  GridView . mouse_down ( self , event ) ",if self . scroll_up_rect ( ) . collidepoint ( p ) :,if p == 0:,False,23.91730981067076,92.97513191007428
796,"def on_api_command ( self , command , data ) : <TAB>  if command == "" select "" : <TAB><TAB>  if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB><TAB><TAB>  return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB><TAB>  if self . _prompt is None : <TAB><TAB><TAB>  return flask . abort ( 409 , "" No active prompt "" ) <TAB><TAB>  choice = data [ "" choice "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return flask . abort ( <TAB><TAB><TAB><TAB>  400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . _answer_prompt ( choice ) ","if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) :",if not choice.is_valid():,False,26.59861780550068,91.3681966953048
797,"def register_predictors ( self , model_data_arr ) : <TAB>  for integration in self . _get_integrations ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  integration . register_predictors ( model_data_arr ) <TAB><TAB>  else : <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  f "" There is no connection to  { integration . name } . predictor wouldn ' t be registred. "" <TAB><TAB><TAB>  ) ",if integration . check_connection ( ) :,"if hasattr(integration, 'register_predictors'):",False,53.53306731720176,90.40511698915046
798,"def _pack_shears ( shearData ) : <TAB>  shears = list ( ) <TAB>  vidxs = list ( ) <TAB>  for e_idx , entry in enumerate ( shearData ) : <TAB><TAB>  # Should be 3 entries <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shears . extend ( [ float ( "" nan "" ) , float ( "" nan "" ) ] ) <TAB><TAB><TAB>  vidxs . extend ( [ 0 , 0 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  vidx1 , vidx2 , shear1 , shear2 = entry <TAB><TAB><TAB>  shears . extend ( [ shear1 , shear2 ] ) <TAB><TAB><TAB>  vidxs . extend ( [ vidx1 , vidx2 ] ) <TAB>  return ( np . asarray ( shears , dtype = np . float32 ) , np . asarray ( vidxs , dtype = np . uint32 ) ) ",if entry is None :,if e_idx == 3:,False,51.60920161939918,96.36336702044626
799,"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB>  yield "" Core "" , "" 0 "" <TAB>  for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB><TAB>  fpath = _dir / "" settings.json "" <TAB><TAB>  if not fpath . exists ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  with fpath . open ( ) as f : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  data = json . load ( f ) <TAB><TAB><TAB>  except json . JSONDecodeError : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  if not isinstance ( data , dict ) : <TAB><TAB><TAB>  continue <TAB><TAB>  cog_name = _dir . stem <TAB><TAB>  for cog_id , inner in data . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield cog_name , cog_id ","if not isinstance ( inner , dict ) :",if cog_id == cog_name:,False,22.176287899047367,96.49822432948194
800,"def subFeaName ( m , newNames , state ) : <TAB>  try : <TAB><TAB>  int ( m [ 3 ] , 16 ) <TAB>  except : <TAB><TAB>  return m [ 0 ] <TAB>  name = m [ 2 ] <TAB>  if name in newNames : <TAB><TAB>  # print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4])) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" sub  %r  =>  %r "" % ( m [ 0 ] , m [ 1 ] + newNames [ name ] + m [ 4 ] ) ) <TAB><TAB>  state [ "" didChange "" ] = True <TAB><TAB>  return m [ 1 ] + newNames [ name ] + m [ 4 ] <TAB>  return m [ 0 ] ","if name == ""uni0402"" :",if state.didChange:,False,59.01491611973606,96.25446039662985
801,"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB>  if self . _log_graph : <TAB><TAB>  if input_array is None : <TAB><TAB><TAB>  input_array = model . example_input_array <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB><TAB><TAB>  self . experiment . add_graph ( model , input_array ) <TAB><TAB>  else : <TAB><TAB><TAB>  rank_zero_warn ( <TAB><TAB><TAB><TAB>  "" Could not log computational graph since the "" <TAB><TAB><TAB><TAB>  ""  `model.example_input_array` attribute is not set "" <TAB><TAB><TAB><TAB>  ""  or `input_array` was not given "" , <TAB><TAB><TAB><TAB>  UserWarning , <TAB><TAB><TAB>  ) ",if input_array is not None :,if input_array is not None:,False,60.53134036936621,100.00000000000004
802,"def apply ( self , db , person ) : <TAB>  for family_handle in person . get_family_handle_list ( ) : <TAB><TAB>  family = db . get_family_from_handle ( family_handle ) <TAB><TAB>  if family : <TAB><TAB><TAB>  for event_ref in family . get_event_ref_list ( ) : <TAB><TAB><TAB><TAB>  if event_ref : <TAB><TAB><TAB><TAB><TAB>  event = db . get_event_from_handle ( event_ref . ref ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB><TAB>  if not event . get_date_object ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if not event . get_place_handle ( ) :,if not event.get_type() == event.get_type():,False,27.16470904187985,95.33663373347505
803,"def format ( m ) : <TAB>  if m > 1000 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ( str ( int ( m / 1000 ) ) , "" km "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  return ( str ( round ( m / 1000 , 1 ) ) , "" km "" ) <TAB>  return ( str ( m ) , "" m "" ) ",if m % 1000 == 0 :,if m < 1000:,False,23.241834160631885,93.75231646228228
804,"def previous ( self ) : <TAB>  try : <TAB><TAB>  idx = _jump_list_index <TAB><TAB>  next_index = idx + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  next_index = 100 <TAB><TAB>  next_index = min ( len ( _jump_list ) - 1 , next_index ) <TAB><TAB>  _jump_list_index = next_index <TAB><TAB>  return _jump_list [ next_index ] <TAB>  except ( IndexError , KeyError ) as e : <TAB><TAB>  return None ",if next_index > 100 :,if next_index > 100:,False,52.090759644369335,100.00000000000004
805,"def _validate_and_set_default_hyperparameters ( self ) : <TAB>  """"""Placeholder docstring"""""" <TAB>  # Check if all the required hyperparameters are set. If there is a default value <TAB>  # for one, set it. <TAB>  for name , definition in self . hyperparameter_definitions . items ( ) : <TAB><TAB>  if name not in self . hyperparam_dict : <TAB><TAB><TAB>  spec = definition [ "" spec "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . hyperparam_dict [ name ] = spec [ "" DefaultValue "" ] <TAB><TAB><TAB>  elif "" IsRequired "" in spec and spec [ "" IsRequired "" ] : <TAB><TAB><TAB><TAB>  raise ValueError ( "" Required hyperparameter:  %s  is not set "" % name ) ","if ""DefaultValue"" in spec :","if ""DefaultValue"" in spec and spec['DefaultValue']:",False,64.93379952097004,96.80112126347348
806,"def _actions_read ( self , c ) : <TAB>  self . action_input . handle_read ( c ) <TAB>  if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB><TAB>  # take action <TAB><TAB>  if self . action_input . selected_index == 0 :<TAB># Cancel <TAB><TAB><TAB>  self . back_to_parent ( ) <TAB><TAB>  <IF-STMT>:<TAB># Apply <TAB><TAB><TAB>  self . _apply_prefs ( ) <TAB><TAB><TAB>  client . core . get_config ( ) . addCallback ( self . _update_preferences ) <TAB><TAB>  elif self . action_input . selected_index == 2 :<TAB># OK <TAB><TAB><TAB>  self . _apply_prefs ( ) <TAB><TAB><TAB>  self . back_to_parent ( ) ",elif self . action_input . selected_index == 1 :,"if c in [curses.KEY_ENTER, curses.KEY_ENTER2]:",False,51.661706296977506,87.21319271761251
807,"def _split_anonymous_function ( s ) : <TAB>  # Regex is not sufficient to handle differences between anonymous <TAB>  # functions and YAML encoded lists. We perform a sniff test to see <TAB>  # if it might be an anonymous function and then confirm by <TAB>  # decoding it as YAML and testing the result. <TAB>  if s [ : 1 ] == "" [ "" and s [ - 1 : ] == "" ] "" and "" : "" in s : <TAB><TAB>  try : <TAB><TAB><TAB>  l = yaml_util . decode_yaml ( s ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  return None , s [ 1 : - 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return None , s [ 1 : - 1 ] <TAB>  return None ","if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :",if l == 'anonymous':,False,43.34229659860831,85.17015152263215
808,"def test_source_address ( self ) : <TAB>  for addr , is_ipv6 in VALID_SOURCE_ADDRESSES : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( "" No IPv6 support: skipping. "" , NoIPv6Warning ) <TAB><TAB><TAB>  continue <TAB><TAB>  pool = HTTPConnectionPool ( <TAB><TAB><TAB>  self . host , self . port , source_address = addr , retries = False <TAB><TAB>  ) <TAB><TAB>  self . addCleanup ( pool . close ) <TAB><TAB>  r = pool . request ( "" GET "" , "" /source_address "" ) <TAB><TAB>  self . assertEqual ( r . data , b ( addr [ 0 ] ) ) ",if is_ipv6 and not HAS_IPV6_AND_DNS :,if is_ipv6:,False,47.966576661522595,94.0942526772382
809,"def vim_G ( self ) : <TAB>  """"""Put the cursor on the last character of the file."""""" <TAB>  if self . is_text_wrapper ( self . w ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . do ( "" end-of-buffer-extend-selection "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . do ( "" end-of-buffer "" ) <TAB><TAB>  self . done ( ) <TAB>  else : <TAB><TAB>  self . quit ( ) ","if self . state == ""visual"" :",if self.is_text_wrapper(self.w):,False,37.627269820979315,91.30840905273574
810,"def backend_supported ( module , manager , * * kwargs ) : <TAB>  if CollectionNodeModule . backend_supported ( module , manager , * * kwargs ) : <TAB><TAB>  if "" tid "" not in kwargs : <TAB><TAB><TAB>  return True <TAB><TAB>  conn = manager . connection ( did = kwargs [ "" did "" ] ) <TAB><TAB>  template_path = "" partitions/sql/ {0} /# {0} # {1} # "" . format ( <TAB><TAB><TAB>  manager . server_type , manager . version <TAB><TAB>  ) <TAB><TAB>  SQL = render_template ( <TAB><TAB><TAB>  "" / "" . join ( [ template_path , "" backend_support.sql "" ] ) , tid = kwargs [ "" tid "" ] <TAB><TAB>  ) <TAB><TAB>  status , res = conn . execute_scalar ( SQL ) <TAB><TAB>  # check if any errors <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return internal_server_error ( errormsg = res ) <TAB><TAB>  return res ",if not status :,if status != sql.SUCCESS:,False,47.24085537321874,97.23399465427454
811,"def _get_regex_config ( self , data_asset_name : Optional [ str ] = None ) - > dict : <TAB>  regex_config : dict = copy . deepcopy ( self . _default_regex ) <TAB>  asset : Optional [ Asset ] = None <TAB>  if data_asset_name : <TAB><TAB>  asset = self . _get_asset ( data_asset_name = data_asset_name ) <TAB>  if asset is not None : <TAB><TAB>  # Override the defaults <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  regex_config [ "" pattern "" ] = asset . pattern <TAB><TAB>  if asset . group_names : <TAB><TAB><TAB>  regex_config [ "" group_names "" ] = asset . group_names <TAB>  return regex_config ",if asset . pattern :,if asset.pattern:,False,51.05457991672382,100.00000000000004
812,"def resolve ( self , other ) : <TAB>  if other == ANY_TYPE : <TAB><TAB>  return self <TAB>  elif isinstance ( other , ComplexType ) : <TAB><TAB>  f = self . first . resolve ( other . first ) <TAB><TAB>  s = self . second . resolve ( other . second ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ComplexType ( f , s ) <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  elif self == ANY_TYPE : <TAB><TAB>  return other <TAB>  else : <TAB><TAB>  return None ",if f and s :,if f is other:,False,23.529781893174324,97.66581194053254
813,"def collect_pages ( app ) : <TAB>  new_images = { } <TAB>  for full_path , basename in app . builder . images . iteritems ( ) : <TAB><TAB>  base , ext = os . path . splitext ( full_path ) <TAB><TAB>  retina_path = base + "" @2x "" + ext <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_images [ retina_path ] = app . env . images [ retina_path ] [ 1 ] <TAB>  app . builder . images . update ( new_images ) <TAB>  return [ ] ",if retina_path in app . env . images :,if os.path.exists(retina_path):,False,31.30235054455344,93.33996686439266
814,"def has_bad_headers ( self ) : <TAB>  headers = [ self . sender , self . reply_to ] + self . recipients <TAB>  for header in headers : <TAB><TAB>  if _has_newline ( header ) : <TAB><TAB><TAB>  return True <TAB>  if self . subject : <TAB><TAB>  if _has_newline ( self . subject ) : <TAB><TAB><TAB>  for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  if linenum > 0 and line [ 0 ] not in "" \t "" : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  if _has_newline ( line ) : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  if len ( line . strip ( ) ) == 0 : <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if not line :,if line.startswith(' '):,False,52.462308427038465,97.11697000856715
815,"def reader ( ) : <TAB>  try : <TAB><TAB>  imgs = mp4_loader ( video_path , seg_num , seglen , mode ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . error ( <TAB><TAB><TAB><TAB>  "" {}  frame length  {}  less than 1. "" . format ( video_path , len ( imgs ) ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  yield None , None <TAB>  except : <TAB><TAB>  logger . error ( "" Error when loading  {} "" . format ( mp4_path ) ) <TAB><TAB>  yield None , None <TAB>  imgs_ret = imgs_transform ( <TAB><TAB>  imgs , mode , seg_num , seglen , short_size , target_size , img_mean , img_std <TAB>  ) <TAB>  label_ret = video_path <TAB>  yield imgs_ret , label_ret ",if len ( imgs ) < 1 :,if len(imgs) > 1:,False,54.24231372708883,98.88759619536245
816,"def translate_from_sortname ( name , sortname ) : <TAB>  """"""'Translate' the artist name by reversing the sortname."""""" <TAB>  for c in name : <TAB><TAB>  ctg = unicodedata . category ( c ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB><TAB><TAB><TAB>  if separator in sortname : <TAB><TAB><TAB><TAB><TAB>  parts = sortname . split ( separator ) <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  parts = [ sortname ] <TAB><TAB><TAB><TAB>  separator = "" "" <TAB><TAB><TAB>  return separator . join ( map ( _reverse_sortname , parts ) ) <TAB>  return name ","if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :",if ctg == sortname:,False,30.71722222177971,89.46633232772658
817,"def _to_local_path ( path ) : <TAB>  """"""Convert local path to SFTP path"""""" <TAB>  if sys . platform == "" win32 "" :<TAB># pragma: no cover <TAB><TAB>  path = os . fsdecode ( path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = path [ 1 : ] <TAB><TAB>  path = path . replace ( "" / "" , "" \\ "" ) <TAB>  return path ","if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :",if path.startswith('/'):,False,49.131776028711286,81.63008390232523
818,"def __call__ ( self , text : str ) - > str : <TAB>  for t in self . cleaner_types : <TAB><TAB>  if t == "" tacotron "" : <TAB><TAB><TAB>  text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = jaconv . normalize ( text ) <TAB><TAB>  elif t == "" vietnamese "" : <TAB><TAB><TAB>  if vietnamese_cleaners is None : <TAB><TAB><TAB><TAB>  raise RuntimeError ( "" Please install underthesea "" ) <TAB><TAB><TAB>  text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB>  return text ","elif t == ""jaconv"" :","if t == ""normaliz':",False,20.814600364288935,97.084557393556
819,"def cb_syncthing_system_data ( self , daemon , mem , cpu , d_failed , d_total ) : <TAB>  if self . daemon . get_my_id ( ) in self . devices : <TAB><TAB>  # Update my device display <TAB><TAB>  device = self . devices [ self . daemon . get_my_id ( ) ] <TAB><TAB>  device [ "" ram "" ] = sizeof_fmt ( mem ) <TAB><TAB>  device [ "" cpu "" ] = "" %3.2f %% "" % ( cpu ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  device [ "" announce "" ] = _ ( "" disabled "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  device [ "" announce "" ] = "" %s / %s "" % ( d_total - d_failed , d_total ) ",if d_total == 0 :,if d_failed == 0:,False,51.342260563921926,98.76076411553262
820,"def update_kls ( self , sampled_kls ) : <TAB>  for i , kl in enumerate ( sampled_kls ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . kl_coeff_val [ i ] * = 0.5 <TAB><TAB>  elif kl > 1.5 * self . kl_target : <TAB><TAB><TAB>  self . kl_coeff_val [ i ] * = 2.0 <TAB>  return self . kl_coeff_val ",if kl < self . kl_target / 1.5 :,if kl < 0.5 * self.kl_target:,False,22.766723382753987,95.59285665572095
821,"def DeleteEmptyCols ( self ) : <TAB>  cols2delete = [ ] <TAB>  for c in range ( 0 , self . GetCols ( ) ) : <TAB><TAB>  f = True <TAB><TAB>  for r in range ( 0 , self . GetRows ( ) ) : <TAB><TAB><TAB>  if self . FindItemAtPosition ( ( r , c ) ) is not None : <TAB><TAB><TAB><TAB>  f = False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cols2delete . append ( c ) <TAB>  for i in range ( 0 , len ( cols2delete ) ) : <TAB><TAB>  self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB><TAB>  cols2delete = [ x - 1 for x in cols2delete ] ",if f :,if f:,False,55.58232441304368,100.00000000000004
822,"def get_session ( self ) : <TAB>  if self . _session is None : <TAB><TAB>  session = super ( ChildResourceManager , self ) . get_session ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  session = session . get_session_for_resource ( self . resource_type . resource ) <TAB><TAB>  self . _session = session <TAB>  return self . _session ",if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY :,if self.resource_type.resource:,False,24.431462248966334,90.26172471845268
823,"def _get_master_authorized_networks_config ( self , raw_cluster ) : <TAB>  if raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) : <TAB><TAB>  config = raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) <TAB><TAB>  config [ "" includes_public_cidr "" ] = False <TAB><TAB>  for block in config [ "" cidrBlocks "" ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  config [ "" includes_public_cidr "" ] = True <TAB><TAB>  return config <TAB>  else : <TAB><TAB>  return { "" enabled "" : False , "" cidrBlocks "" : [ ] , "" includes_public_cidr "" : False } ","if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :",if block['enabled']:,False,47.348457499942484,92.96477696655104
824,"def scan_folder ( folder ) : <TAB>  scanned_files = [ ] <TAB>  for root , dirs , files in os . walk ( folder ) : <TAB><TAB>  dirs [ : ] = [ d for d in dirs if d != "" __pycache__ "" ] <TAB><TAB>  relative_path = os . path . relpath ( root , folder ) <TAB><TAB>  for f in files : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  relative_name = os . path . normpath ( os . path . join ( relative_path , f ) ) . replace ( <TAB><TAB><TAB><TAB>  "" \\ "" , "" / "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  scanned_files . append ( relative_name ) <TAB>  return sorted ( scanned_files ) ","if f . endswith ( "".pyc"" ) :",if f.startswith('.pycache'):,False,58.13925748558564,96.80486821456383
825,"def read_progress ( self ) : <TAB>  while True : <TAB><TAB>  processed_file = self . queue . get ( ) <TAB><TAB>  self . threading_completed . append ( processed_file ) <TAB><TAB>  total_number = len ( self . file_list ) <TAB><TAB>  completed_number = len ( self . threading_completed ) <TAB><TAB>  # Just for the record, this slows down book searching by about 20% <TAB><TAB>  if _progress_emitter :<TAB># Skip update in reading mode <TAB><TAB><TAB>  _progress_emitter . update_progress ( completed_number * 100 / / total_number ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ",if total_number == completed_number :,if completed_number == 0:,False,64.22571479908082,95.06152980513399
826,"def next_instruction_is_function_or_class ( lines ) : <TAB>  """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB>  parser = StringParser ( "" python "" ) <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  if parser . is_quoted ( ) : <TAB><TAB><TAB>  parser . read_line ( line ) <TAB><TAB><TAB>  continue <TAB><TAB>  parser . read_line ( line ) <TAB><TAB>  if not line . strip ( ) :<TAB># empty line <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  continue <TAB><TAB>  if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB><TAB><TAB>  return True <TAB><TAB>  if line . startswith ( ( "" # "" , "" @ "" , "" "" , "" ) "" ) ) : <TAB><TAB><TAB>  continue <TAB><TAB>  return False <TAB>  return False ",if i > 0 and not lines [ i - 1 ] . strip ( ) :,if i == len(lines):,False,58.606214749449336,94.5378988736335
827,def __next__ ( self ) : <TAB>  try : <TAB><TAB>  data = next ( self . iter_loader ) <TAB>  except StopIteration : <TAB><TAB>  self . _epoch + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _dataloader . sampler . set_epoch ( self . _epoch ) <TAB><TAB>  self . iter_loader = iter ( self . _dataloader ) <TAB><TAB>  data = next ( self . iter_loader ) <TAB>  return data ,"if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :",if self._epoch > 0:,False,24.427897674888037,89.19798156328466
828,"def dgl_mp_batchify_fn ( data ) : <TAB>  if isinstance ( data [ 0 ] , tuple ) : <TAB><TAB>  data = zip ( * data ) <TAB><TAB>  return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB>  for dt in data : <TAB><TAB>  if dt is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB><TAB><TAB>  elif isinstance ( dt , nd . NDArray ) : <TAB><TAB><TAB><TAB>  pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB><TAB><TAB><TAB>  data_list = [ dt for dt in data if dt is not None ] <TAB><TAB><TAB><TAB>  return pad ( data_list ) ","if isinstance ( dt , dgl . DGLGraph ) :","if isinstance(dt, dgl.DGLGraph):",False,60.73991722781741,100.00000000000004
829,"def f ( self , info ) : <TAB>  for k in keys : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for k2 in list ( info . keys ( ) ) : <TAB><TAB><TAB><TAB>  if k ( k2 ) : <TAB><TAB><TAB><TAB><TAB>  info . pop ( k2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  info . pop ( k , None ) ",if callable ( k ) :,if info.has_key(k):,False,25.406736998183387,94.35685270904516
830,"def create ( path , binary = False ) : <TAB>  for i in range ( 10 ) : <TAB><TAB>  try : <TAB><TAB><TAB>  os . makedirs ( os . path . dirname ( path ) , exist_ok = True ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return open ( path , "" wb "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return open ( path , "" w "" , encoding = "" utf-8 "" ) <TAB><TAB><TAB>  if i > 0 : <TAB><TAB><TAB><TAB>  log ( True , f "" Created  { path }  at attempt  { i + 1 } "" ) <TAB><TAB>  except : <TAB><TAB><TAB>  time . sleep ( 0.5 ) <TAB>  else : <TAB><TAB>  raise Error ( f "" Failed to create  { path } "" ) ",if binary :,if binary:,False,45.62842433022792,100.00000000000004
831,"def validate_update ( self , update_query ) : <TAB>  structure = DotCollapsedDict ( self . doc_class . structure ) <TAB>  for op , fields in update_query . iteritems ( ) : <TAB><TAB>  for field in fields : <TAB><TAB><TAB>  if op != "" $unset "" and op != "" $rename "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise UpdateQueryError ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" ' %s '  not found in  %s ' s structure "" <TAB><TAB><TAB><TAB><TAB><TAB>  % ( field , self . doc_class . __name__ ) <TAB><TAB><TAB><TAB><TAB>  ) ",if field not in structure :,if not structure.has_section(field):,False,50.176518947520336,91.15129318497131
832,"def check_enums_ATLAS_ISAEXT ( lines ) : <TAB>  for i , isaext in enumerate ( ATLAS_ISAEXT ) : <TAB><TAB>  got = lines . pop ( 0 ) . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  expect = "" none: 1 "" <TAB><TAB>  else : <TAB><TAB><TAB>  expect = "" {0} :  {1} "" . format ( isaext , 1 << i ) <TAB><TAB>  if got != expect : <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  "" ATLAS_ISAEXT mismatch at position  "" <TAB><TAB><TAB><TAB>  + str ( i ) <TAB><TAB><TAB><TAB>  + "" : got >> "" <TAB><TAB><TAB><TAB>  + got <TAB><TAB><TAB><TAB>  + "" <<, expected >> "" <TAB><TAB><TAB><TAB>  + expect <TAB><TAB><TAB><TAB>  + "" << "" <TAB><TAB><TAB>  ) ",if i == 0 :,if not got:,False,50.31750246711258,97.92709727051358
833,"def _test_export_session_csv ( self , test_session = None ) : <TAB>  with self . app . test_request_context ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  test_session = SessionFactory ( ) <TAB><TAB>  field_data = export_sessions_csv ( [ test_session ] ) <TAB><TAB>  session_row = field_data [ 1 ] <TAB><TAB>  self . assertEqual ( session_row [ 0 ] , "" example (accepted) "" ) <TAB><TAB>  self . assertEqual ( session_row [ 9 ] , "" accepted "" ) ",if not test_session :,if test_session is None:,False,43.29594389904826,96.53889924338813
834,"def get_report_to_platform ( self , args , scan_reports ) : <TAB>  if self . bc_api_key : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  repo_id = self . get_repository ( args ) <TAB><TAB><TAB>  self . setup_bridgecrew_credentials ( <TAB><TAB><TAB><TAB>  bc_api_key = self . bc_api_key , repo_id = repo_id <TAB><TAB><TAB>  ) <TAB><TAB>  if self . is_integration_configured ( ) : <TAB><TAB><TAB>  self . _upload_run ( args , scan_reports ) ",if args . directory :,if self.is_config_enabled():,False,47.62665634362367,93.79580606443281
835,"def test_fvalue ( self ) : <TAB>  if not getattr ( self , "" skip_f "" , False ) : <TAB><TAB>  rtol = getattr ( self , "" rtol "" , 1e-10 ) <TAB><TAB>  assert_allclose ( self . res1 . fvalue , self . res2 . F , rtol = rtol ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # only available with ivreg2 <TAB><TAB><TAB>  assert_allclose ( self . res1 . f_pvalue , self . res2 . Fp , rtol = rtol ) <TAB>  else : <TAB><TAB>  raise pytest . skip ( "" TODO: document why this test is skipped "" ) ","if hasattr ( self . res2 , ""Fp"" ) :",if self.is_ivreg2():,False,49.92509310861373,93.98456617652083
836,"def fix_repeating_arguments ( self ) : <TAB>  """"""Fix elements that should accumulate/increment values."""""" <TAB>  either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB>  for case in either : <TAB><TAB>  for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB>  if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB><TAB><TAB><TAB>  if e . value is None : <TAB><TAB><TAB><TAB><TAB>  e . value = [ ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  e . value = e . value . split ( ) <TAB><TAB><TAB>  if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB><TAB><TAB><TAB>  e . value = 0 <TAB>  return self ",elif type ( e . value ) is not list :,if type(e.value) is str:,False,48.916149750362344,97.61722016857317
837,"def touch ( self ) : <TAB>  if not self . exists ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  self . parent ( ) . touch ( ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  pass <TAB><TAB>  node = self . _fs . touch ( self . pathnames , { } ) <TAB><TAB>  if not node . isdir : <TAB><TAB><TAB>  raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . watcher . emit ( "" created "" , self ) ",if self . watcher :,if self.watcher:,False,51.03110955510619,100.00000000000004
838,"def __init__ ( self , _inf = None , _tzinfos = None ) : <TAB>  if _inf : <TAB><TAB>  self . _tzinfos = _tzinfos <TAB><TAB>  self . _utcoffset , self . _dst , self . _tzname = _inf <TAB>  else : <TAB><TAB>  _tzinfos = { } <TAB><TAB>  self . _tzinfos = _tzinfos <TAB><TAB>  self . _utcoffset , self . _dst , self . _tzname = self . _transition_info [ 0 ] <TAB><TAB>  _tzinfos [ self . _transition_info [ 0 ] ] = self <TAB><TAB>  for inf in self . _transition_info [ 1 : ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  _tzinfos [ inf ] = self . __class__ ( inf , _tzinfos ) ",if not _tzinfos . has_key ( inf ) :,if inf not in _tzinfos:,False,32.08607091198574,95.1735429433782
839,"def test_sample_output ( ) : <TAB>  comment = "" SAMPLE OUTPUT "" <TAB>  skip_files = [ "" __init__.py "" ] <TAB>  errors = [ ] <TAB>  for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with _file . open ( ) as f : <TAB><TAB><TAB><TAB>  if comment not in f . read ( ) : <TAB><TAB><TAB><TAB><TAB>  errors . append ( ( comment , _file ) ) <TAB>  if errors : <TAB><TAB>  line = "" Missing sample error(s) detected! \n \n "" <TAB><TAB>  for error in errors : <TAB><TAB><TAB>  line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB><TAB>  print ( line [ : - 1 ] ) <TAB><TAB>  assert False ","if _file . suffix == "".py"" and _file . name not in skip_files :",if _file.startswith('.py'):,False,23.71296656243421,91.61848135531831
840,"def http_get ( url , target ) : <TAB>  req = requests . get ( url , stream = True ) <TAB>  content_length = req . headers . get ( "" Content-Length "" ) <TAB>  total = int ( content_length ) if content_length is not None else None <TAB>  progress = tqdm ( unit = "" B "" , total = total ) <TAB>  with open ( target , "" wb "" ) as target_file : <TAB><TAB>  for chunk in req . iter_content ( chunk_size = 1024 ) : <TAB><TAB><TAB>  <IF-STMT>:<TAB># filter out keep-alive new chunks <TAB><TAB><TAB><TAB>  progress . update ( len ( chunk ) ) <TAB><TAB><TAB><TAB>  target_file . write ( chunk ) <TAB>  progress . close ( ) ",if chunk :,if chunk.startswith(''):,False,27.956274523223605,94.63952011654436
841,"def _elements_to_datasets ( self , elements , level = 0 ) : <TAB>  for element in elements : <TAB><TAB>  extra_kwds = { "" identifier_ %d "" % level : element [ "" name "" ] } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for inner_element in self . _elements_to_datasets ( <TAB><TAB><TAB><TAB>  element [ "" elements "" ] , level = level + 1 <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  dataset = extra_kwds . copy ( ) <TAB><TAB><TAB><TAB>  dataset . update ( inner_element ) <TAB><TAB><TAB><TAB>  yield dataset <TAB><TAB>  else : <TAB><TAB><TAB>  dataset = extra_kwds <TAB><TAB><TAB>  extra_kwds . update ( element ) <TAB><TAB><TAB>  yield extra_kwds ","if ""elements"" in element :",if element['elements']:,False,27.94231074616568,97.2612358893543
842,"def update_dict ( a , b ) : <TAB>  for key , value in b . items ( ) : <TAB><TAB>  if value is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  a [ key ] = value <TAB><TAB>  elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB><TAB><TAB>  update_dict ( a [ key ] , value ) <TAB><TAB>  elif isinstance ( a [ key ] , list ) : <TAB><TAB><TAB>  a [ key ] . append ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  a [ key ] = [ a [ key ] , value ] ",if key not in a :,"if isinstance(value, int):",False,27.331298765696292,95.86167048169814
843,"def scan ( self , targets ) : <TAB>  for target in targets : <TAB><TAB>  target . print_infos ( ) <TAB><TAB>  if self . is_interesting ( target ) : <TAB><TAB><TAB>  self . target [ "" other "" ] . append ( target ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return target <TAB>  return None ",if self . match ( target ) :,if self.is_interesting(target):,False,26.76228416025859,95.63334828258171
844,"def printConnections ( switches ) : <TAB>  "" Compactly print connected nodes to each switch "" <TAB>  for sw in switches : <TAB><TAB>  output ( "" %s :  "" % sw ) <TAB><TAB>  for intf in sw . intfList ( ) : <TAB><TAB><TAB>  link = intf . link <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  intf1 , intf2 = link . intf1 , link . intf2 <TAB><TAB><TAB><TAB>  remote = intf1 if intf1 . node != sw else intf2 <TAB><TAB><TAB><TAB>  output ( "" %s ( %s )  "" % ( remote . node , sw . ports [ intf ] ) ) <TAB><TAB>  output ( "" \n "" ) ",if link :,if link:,False,57.39971352775647,100.00000000000004
845,"def __cut ( sentence ) : <TAB>  global emit_P <TAB>  prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB>  begin , nexti = 0 , 0 <TAB>  # print pos_list, sentence <TAB>  for i , char in enumerate ( sentence ) : <TAB><TAB>  pos = pos_list [ i ] <TAB><TAB>  if pos == "" B "" : <TAB><TAB><TAB>  begin = i <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield sentence [ begin : i + 1 ] <TAB><TAB><TAB>  nexti = i + 1 <TAB><TAB>  elif pos == "" S "" : <TAB><TAB><TAB>  yield char <TAB><TAB><TAB>  nexti = i + 1 <TAB>  if nexti < len ( sentence ) : <TAB><TAB>  yield sentence [ nexti : ] ","elif pos == ""E"" :","if pos == ""A':",False,52.34199405093947,97.30704046199419
846,"def check_files ( self , paths = None ) : <TAB>  """"""Run all checks on the paths."""""" <TAB>  if paths is None : <TAB><TAB>  paths = self . paths <TAB>  report = self . options . report <TAB>  runner = self . runner <TAB>  report . start ( ) <TAB>  try : <TAB><TAB>  for path in paths : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . input_dir ( path ) <TAB><TAB><TAB>  elif not self . excluded ( path ) : <TAB><TAB><TAB><TAB>  runner ( path ) <TAB>  except KeyboardInterrupt : <TAB><TAB>  print ( "" ... stopped "" ) <TAB>  report . stop ( ) <TAB>  return report ",if os . path . isdir ( path ) :,if path.startswith('.py'):,False,53.04736430612964,96.25472635613785
847,"def verts_of_loop ( edge_loop ) : <TAB>  verts = [ ] <TAB>  for e0 , e1 in iter_pairs ( edge_loop , False ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v0 = e0 . shared_vert ( e1 ) <TAB><TAB><TAB>  verts + = [ e0 . other_vert ( v0 ) , v0 ] <TAB><TAB>  verts + = [ e1 . other_vert ( verts [ - 1 ] ) ] <TAB>  if len ( verts ) > 1 and verts [ 0 ] == verts [ - 1 ] : <TAB><TAB>  return verts [ : - 1 ] <TAB>  return verts ",if not verts :,if e0.shared_vert(e1):,False,19.926523989633893,87.39267379745607
848,"def generator ( self , data ) : <TAB>  for task in data : <TAB><TAB>  # Do we scan everything or just /bin/bash instances? <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for bucket in task . bash_hash_entries ( ) : <TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB>  0 , <TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB>  int ( task . p_pid ) , <TAB><TAB><TAB><TAB><TAB>  str ( task . p_comm ) , <TAB><TAB><TAB><TAB><TAB>  int ( bucket . times_found ) , <TAB><TAB><TAB><TAB><TAB>  str ( bucket . key ) , <TAB><TAB><TAB><TAB><TAB>  str ( bucket . data . path ) , <TAB><TAB><TAB><TAB>  ] , <TAB><TAB><TAB>  ) ","if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :",if not task:,False,59.78018139636067,90.52487448241837
849,"def __get_ratio ( self ) : <TAB>  """"""Return splitter ratio of the main splitter."""""" <TAB>  c = self . c <TAB>  free_layout = c . free_layout <TAB>  if free_layout : <TAB><TAB>  w = free_layout . get_main_splitter ( ) <TAB><TAB>  if w : <TAB><TAB><TAB>  aList = w . sizes ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  n1 , n2 = aList <TAB><TAB><TAB><TAB>  # 2017/06/07: guard against division by zero. <TAB><TAB><TAB><TAB>  ratio = 0.5 if n1 + n2 == 0 else float ( n1 ) / float ( n1 + n2 ) <TAB><TAB><TAB><TAB>  return ratio <TAB>  return 0.5 ",if len ( aList ) == 2 :,if aList:,False,60.67798761023418,96.05432456913539
850,"def geterrors ( self ) : <TAB>  """"""Get all error messages."""""" <TAB>  notes = self . getnotes ( origin = "" translator "" ) . split ( "" \n "" ) <TAB>  errordict = { } <TAB>  for note in notes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  error = note . replace ( "" (pofilter)  "" , "" "" ) <TAB><TAB><TAB>  errorname , errortext = error . split ( "" :  "" , 1 ) <TAB><TAB><TAB>  errordict [ errorname ] = errortext <TAB>  return errordict ","if ""(pofilter) "" in note :",if note.startswith('(pofilter') and note.endswith('('p,False,20.050910718171917,88.53998250958283
851,"def rename_path ( self , path , new_path ) : <TAB>  logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB>  dirs = self . readdir ( path ) <TAB>  for d in dirs : <TAB><TAB>  if d in [ "" . "" , "" .. "" ] : <TAB><TAB><TAB>  continue <TAB><TAB>  d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB><TAB>  d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB><TAB>  attr = self . getattr ( d_path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . rename_path ( d_path , d_new_path ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . rename_item ( d_path , d_new_path ) <TAB>  self . rename_item ( path , new_path , dir = True ) ","if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :",if attr is not None:,False,29.987019935812896,91.78700420229451
852,"def index ( self , url_id : int ) - > FlaskResponse :<TAB># pylint: disable=no-self-use <TAB>  url = db . session . query ( models . Url ) . get ( url_id ) <TAB>  if url and url . url : <TAB><TAB>  explore_url = "" //superset/explore/? "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  explore_url + = f "" r= { url_id } "" <TAB><TAB><TAB>  return redirect ( explore_url [ 1 : ] ) <TAB><TAB>  return redirect ( url . url [ 1 : ] ) <TAB>  flash ( "" URL to nowhere... "" , "" danger "" ) <TAB>  return redirect ( "" / "" ) ",if url . url . startswith ( explore_url ) :,if url_id:,False,17.42481048293654,93.3530224850932
853,"def testShortCircuit ( self ) : <TAB>  """"""Test that creation short-circuits to reuse existing references"""""" <TAB>  sd = { } <TAB>  for s in self . ss : <TAB><TAB>  sd [ s ] = 1 <TAB>  for t in self . ts : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertTrue ( sd . has_key ( safeRef ( t . x ) ) ) <TAB><TAB><TAB>  self . assertTrue ( safeRef ( t . x ) in sd ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertTrue ( sd . has_key ( safeRef ( t ) ) ) <TAB><TAB><TAB>  self . assertTrue ( safeRef ( t ) in sd ) ","if hasattr ( t , ""x"" ) :","if isinstance(t, (int, long)):",False,56.20827465978435,94.99749776809371
854,"def wrapped ( request , * args , * * kwargs ) : <TAB>  if not request . user . is_authenticated ( ) : <TAB><TAB>  request . session [ "" _next "" ] = request . get_full_path ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  redirect_uri = reverse ( <TAB><TAB><TAB><TAB>  "" sentry-auth-organization "" , args = [ kwargs [ "" organization_slug "" ] ] <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  redirect_uri = get_login_url ( ) <TAB><TAB>  return HttpResponseRedirect ( redirect_uri ) <TAB>  return func ( request , * args , * * kwargs ) ","if ""organization_slug"" in kwargs :",if kwargs.get('organization_slug'):,False,26.357603631681908,94.88802774559548
855,"def read_info ( reader , dump = None ) : <TAB>  line_number_table_length = reader . read_u2 ( ) <TAB>  <IF-STMT>: <TAB><TAB>  reader . debug ( <TAB><TAB><TAB>  ""<TAB>  "" * dump , "" Line numbers ( %s  total): "" % line_number_table_length <TAB><TAB>  ) <TAB>  line_numbers = [ ] <TAB>  for i in range ( 0 , line_number_table_length ) : <TAB><TAB>  start_pc = reader . read_u2 ( ) <TAB><TAB>  line_number = reader . read_u2 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  reader . debug ( ""<TAB>  "" * ( dump + 1 ) , "" %s :  %s "" % ( start_pc , line_number ) ) <TAB><TAB>  line_numbers . append ( ( start_pc , line_number ) ) <TAB>  return LineNumberTable ( line_numbers ) ",if dump is not None :,if dump:,False,22.016227983538684,95.37004286475815
856,"def compute_timer_precision ( timer ) : <TAB>  precision = None <TAB>  points = 0 <TAB>  timeout = timeout_timer ( ) + 1.0 <TAB>  previous = timer ( ) <TAB>  while timeout_timer ( ) < timeout or points < 5 : <TAB><TAB>  for _ in XRANGE ( 10 ) : <TAB><TAB><TAB>  t1 = timer ( ) <TAB><TAB><TAB>  t2 = timer ( ) <TAB><TAB><TAB>  dt = t2 - t1 <TAB><TAB><TAB>  if 0 < dt : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  dt = t2 - previous <TAB><TAB><TAB>  if dt < = 0.0 : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  precision = min ( precision , dt ) <TAB><TAB>  else : <TAB><TAB><TAB>  precision = dt <TAB><TAB>  points + = 1 <TAB><TAB>  previous = timer ( ) <TAB>  return precision ",if precision is not None :,if precision is not None:,False,46.192476500916094,100.00000000000004
857,def get_hi_lineno ( self ) : <TAB>  lineno = Node . get_hi_lineno ( self ) <TAB>  if self . expr1 is None : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  lineno = self . expr1 . get_hi_lineno ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  lineno = self . expr2 . get_hi_lineno ( ) <TAB><TAB><TAB>  if self . expr3 is None : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  lineno = self . expr3 . get_hi_lineno ( ) <TAB>  return lineno ,if self . expr2 is None :,if lineno is None:,False,39.04090703656031,97.59729450809002
858,"def validate_cluster_resource_group ( cmd , namespace ) : <TAB>  if namespace . cluster_resource_group is not None : <TAB><TAB>  client = get_mgmt_service_client ( <TAB><TAB><TAB>  cmd . cli_ctx , ResourceType . MGMT_RESOURCE_RESOURCES <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise InvalidArgumentValueError ( <TAB><TAB><TAB><TAB>  "" Invalid --cluster-resource-group  ' %s ' : resource group must not exist. "" <TAB><TAB><TAB><TAB>  % namespace . cluster_resource_group <TAB><TAB><TAB>  ) ",if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,if client.check_resource_group(namespace.cluster_resource_group):,False,52.06909734672265,94.55390409785382
859,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB>  right = left = index <TAB>  done = False <TAB>  while not done : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  done = True <TAB><TAB>  elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB><TAB><TAB>  left - = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  done = False <TAB>  while not done : <TAB><TAB>  if right == len ( text ) : <TAB><TAB><TAB>  done = True <TAB><TAB>  elif not self . word_boundary_char ( text [ right ] ) : <TAB><TAB><TAB>  right + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  return left , right ",if left == 0 :,if left < len(text):,False,22.80578076314057,97.0746750897979
860,"def _check_good_input ( self , X , y = None ) : <TAB>  if isinstance ( X , dict ) : <TAB><TAB>  lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB><TAB>  if len ( set ( lengths ) ) > 1 : <TAB><TAB><TAB>  raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB><TAB>  x_len = lengths [ 0 ] <TAB>  else : <TAB><TAB>  x_len = len ( X ) <TAB>  if y is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" X and y are not of equal length. "" ) <TAB>  if self . regression and y is not None and y . ndim == 1 : <TAB><TAB>  y = y . reshape ( - 1 , 1 ) <TAB>  return X , y ",if len ( y ) != x_len :,if x_len != len(set(x_len)):,False,44.889577486578,92.87797874662577
861,"def _get_text_nodes ( nodes , html_body ) : <TAB>  text = [ ] <TAB>  open_tags = 0 <TAB>  for node in nodes : <TAB><TAB>  if isinstance ( node , HtmlTag ) : <TAB><TAB><TAB>  if node . tag_type == OPEN_TAG : <TAB><TAB><TAB><TAB>  open_tags + = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  open_tags - = 1 <TAB><TAB>  elif ( <TAB><TAB><TAB>  isinstance ( node , HtmlDataFragment ) <TAB><TAB><TAB>  and node . is_text_content <TAB><TAB><TAB>  and open_tags == 0 <TAB><TAB>  ) : <TAB><TAB><TAB>  text . append ( html_body [ node . start : node . end ] ) <TAB>  return text ",elif node . tag_type == CLOSE_TAG :,if node.tag_type == OPEN_TAG:,False,47.336121111351794,97.75256664257704
862,"def _get_spyne_type ( cls_name , k , v ) : <TAB>  try : <TAB><TAB>  v = NATIVE_MAP . get ( v , v ) <TAB>  except TypeError : <TAB><TAB>  return <TAB>  try : <TAB><TAB>  subc = issubclass ( v , ModelBase ) or issubclass ( v , SelfReference ) <TAB>  except : <TAB><TAB>  subc = False <TAB>  if subc : <TAB><TAB>  if issubclass ( v , Array ) and len ( v . _type_info ) != 1 : <TAB><TAB><TAB>  raise Exception ( "" Invalid Array definition in  %s . %s . "" % ( cls_name , k ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( "" Please specify the number of dimensions "" ) <TAB><TAB>  return v ","elif issubclass ( v , Point ) and v . Attributes . dim is None :",if len(v._type_info) == 0:,False,24.165792978818406,92.79105571333497
863,"def customize ( cls , * * kwargs ) : <TAB>  """"""return a class with some existing attributes customized"""""" <TAB>  for name , value in kwargs . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TransportError ( <TAB><TAB><TAB><TAB>  "" you cannot customize the protected attribute  %s "" % name <TAB><TAB><TAB>  ) <TAB><TAB>  if not hasattr ( cls , name ) : <TAB><TAB><TAB>  raise TransportError ( "" Transport has no attribute  %s "" % name ) <TAB>  NewSubClass = type ( "" Customized_ {} "" . format ( cls . __name__ ) , ( cls , ) , kwargs ) <TAB>  return NewSubClass ","if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :",if name == 'protected':,False,49.59736488702039,87.31078034055739
864,"def test_UNrelativize ( self ) : <TAB>  import URIlib <TAB>  relative = self . relative + self . full_relativize <TAB>  for base , rel , fullpath , common in relative : <TAB><TAB>  URI = uriparse . UnRelativizeURL ( base , rel ) <TAB><TAB>  fullURI = URIlib . URIParser ( URI ) <TAB><TAB>  # We need to canonicalize the result from unrelativize <TAB><TAB>  # compared to the original full path we expect to see. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fullpath = fullpath [ : - 1 ] <TAB><TAB>  self . failUnlessSamePath ( <TAB><TAB><TAB>  os . path . normcase ( fullURI . path ) , os . path . normcase ( fullpath ) <TAB><TAB>  ) ","if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :",if fullpath.endswith('/'):,False,62.14567533105897,91.10437346960572
865,"def get_release_info ( file_path = RELEASE_FILE ) : <TAB>  RELEASE_TYPE_REGEX = re . compile ( r "" ^[Rr]elease [Tt]ype: (major|minor|patch)$ "" ) <TAB>  with open ( file_path , "" r "" ) as f : <TAB><TAB>  line = f . readline ( ) <TAB><TAB>  match = RELEASE_TYPE_REGEX . match ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" The file RELEASE.md should start with `Release type`  "" <TAB><TAB><TAB><TAB>  "" and specify one of the following values: major, minor or patch. "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  sys . exit ( 1 ) <TAB><TAB>  type_ = match . group ( 1 ) <TAB><TAB>  changelog = "" "" . join ( [ line for line in f . readlines ( ) ] ) . strip ( ) <TAB>  return type_ , changelog ",if not match :,if not match:,False,37.241207502895826,100.00000000000004
866,"def _get_next_history_entry ( self ) : <TAB>  if self . _history : <TAB><TAB>  hist_len = len ( self . _history ) - 1 <TAB><TAB>  self . history_index = min ( hist_len , self . history_index + 1 ) <TAB><TAB>  index = self . history_index <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . history_index + = 1 <TAB><TAB>  return self . _history [ index ] <TAB>  return "" "" ",if self . history_index == hist_len :,if index < len(self._history):,False,18.630668103332066,92.64349018369693
867,"def star_op ( self ) : <TAB>  """"""Put a '*' op, with special cases for *args."""""" <TAB>  val = "" * "" <TAB>  if self . paren_level : <TAB><TAB>  i = len ( self . code_list ) - 1 <TAB><TAB>  if self . code_list [ i ] . kind == "" blank "" : <TAB><TAB><TAB>  i - = 1 <TAB><TAB>  token = self . code_list [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . op_no_blanks ( val ) <TAB><TAB>  elif token . value == "" , "" : <TAB><TAB><TAB>  self . blank ( ) <TAB><TAB><TAB>  self . add_token ( "" op-no-blanks "" , val ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . op ( val ) <TAB>  else : <TAB><TAB>  self . op ( val ) ","if token . kind == ""lt"" :","if token.value == ""', ':",False,26.987466539248572,97.12834190462219
868,"def get_safe_settings ( ) : <TAB>  "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB>  settings_dict = { } <TAB>  for k in dir ( settings ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if HIDDEN_SETTINGS . search ( k ) : <TAB><TAB><TAB><TAB>  settings_dict [ k ] = "" ******************** "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  settings_dict [ k ] = getattr ( settings , k ) <TAB>  return settings_dict ",if k . isupper ( ) :,if k.startswith('_'):,False,61.355456514446615,96.21310494592446
869,"def nextEditable ( self ) : <TAB>  """"""Moves focus of the cursor to the next editable window"""""" <TAB>  if self . currentEditable is None : <TAB><TAB>  if len ( self . _editableChildren ) : <TAB><TAB><TAB>  self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB>  else : <TAB><TAB>  for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cei = self . _editableChildren . index ( ref ) <TAB><TAB><TAB><TAB>  nei = cei + 1 <TAB><TAB><TAB><TAB>  if nei > = len ( self . _editableChildren ) : <TAB><TAB><TAB><TAB><TAB>  nei = 0 <TAB><TAB><TAB><TAB>  self . _currentEditableRef = self . _editableChildren [ nei ] <TAB>  return self . currentEditable ",if ref in self . _editableChildren :,if ref.type == 'focus':,False,50.09772337708953,97.18530167964184
870,"def _handle_dependents_type ( types , type_str , type_name , rel_name , row ) : <TAB>  if types [ type_str [ 0 ] ] is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  type_name = "" index "" <TAB><TAB><TAB>  rel_name = row [ "" indname "" ] + ""  ON  "" + rel_name <TAB><TAB>  elif type_str [ 0 ] == "" o "" : <TAB><TAB><TAB>  type_name = "" operator "" <TAB><TAB><TAB>  rel_name = row [ "" relname "" ] <TAB>  else : <TAB><TAB>  type_name = types [ type_str [ 0 ] ] <TAB>  return type_name , rel_name ","if type_str [ 0 ] == ""i"" :","if type_str[0] == ""i':",False,25.39410207463746,98.16012569839465
871,"def streamErrorHandler ( self , conn , error ) : <TAB>  name , text = "" error "" , error . getData ( ) <TAB>  for tag in error . getChildren ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if tag . getName ( ) == "" text "" : <TAB><TAB><TAB><TAB>  text = tag . getData ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  name = tag . getName ( ) <TAB>  if name in stream_exceptions . keys ( ) : <TAB><TAB>  exc = stream_exceptions [ name ] <TAB>  else : <TAB><TAB>  exc = StreamError <TAB>  raise exc ( ( name , text ) ) ",if tag . getNamespace ( ) == NS_XMPP_STREAMS :,if tag.getType() == 'text':,False,49.507014467024725,94.99169081496119
872,"def _validate_names ( self , settings : _SettingsType ) - > None : <TAB>  """"""Make sure all settings exist."""""" <TAB>  unknown = [ ] <TAB>  for name in settings : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  unknown . append ( name ) <TAB>  if unknown : <TAB><TAB>  errors = [ <TAB><TAB><TAB>  configexc . ConfigErrorDesc ( <TAB><TAB><TAB><TAB>  "" While loading options "" , "" Unknown option  {} "" . format ( e ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  for e in sorted ( unknown ) <TAB><TAB>  ] <TAB><TAB>  raise configexc . ConfigFileErrors ( "" autoconfig.yml "" , errors ) ",if name not in configdata . DATA :,if name not in unknown:,False,50.055311408456205,97.54485412702213
873,"def can_haz ( self , target , credentials ) : <TAB>  """"""Check whether key-values in target are present in credentials."""""" <TAB>  # TODO(termie): handle ANDs, probably by providing a tuple instead of a <TAB>  #<TAB><TAB><TAB>   string <TAB>  for requirement in target : <TAB><TAB>  key , match = requirement . split ( "" : "" , 1 ) <TAB><TAB>  check = credentials . get ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  check = [ check ] <TAB><TAB>  if match in check : <TAB><TAB><TAB>  return True ","if check is None or isinstance ( check , basestring ) :","if not isinstance(check, basestring):",False,64.42959880644452,96.54406378876612
874,"def _recursive_fx_apply ( input : dict , fx ) : <TAB>  for k , v in input . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = torch . tensor ( v ) <TAB><TAB>  if isinstance ( v , torch . Tensor ) : <TAB><TAB><TAB>  v = fx ( v . float ( ) ) <TAB><TAB><TAB>  input [ k ] = v <TAB><TAB>  else : <TAB><TAB><TAB>  _recursive_fx_apply ( v , fx ) ","if isinstance ( v , list ) :","if isinstance(v, torch.Tensor):",False,48.264398085479684,96.74058197355953
875,"def get ( self , url , * * kwargs ) : <TAB>  app , url = self . _prepare_call ( url , kwargs ) <TAB>  if app : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _first_ping = False <TAB><TAB><TAB>  return EmptyCapabilitiesResponse ( ) <TAB><TAB>  elif "" Hello0 "" in url and "" 1.2.1 "" in url and "" v1 "" in url : <TAB><TAB><TAB>  return ErrorApiResponse ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  response = app . get ( url , * * kwargs ) <TAB><TAB><TAB>  return TestingResponse ( response ) <TAB>  else : <TAB><TAB>  return requests . get ( url , * * kwargs ) ","if url . endswith ( ""ping"" ) and self . _first_ping :",if self._first_ping:,False,42.230521257028755,94.40866490917027
876,"def server_thread_fn ( ) : <TAB>  server_ctx = ssl . create_default_context ( ssl . Purpose . CLIENT_AUTH ) <TAB>  server_ctx . load_cert_chain ( "" trio-test-1.pem "" ) <TAB>  server = server_ctx . wrap_socket ( <TAB><TAB>  server_sock , <TAB><TAB>  server_side = True , <TAB><TAB>  suppress_ragged_eofs = False , <TAB>  ) <TAB>  while True : <TAB><TAB>  data = server . recv ( 4096 ) <TAB><TAB>  print ( "" server got: "" , data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" server waiting for client to finish everything "" ) <TAB><TAB><TAB>  client_done . wait ( ) <TAB><TAB><TAB>  print ( "" server attempting to send back close-notify "" ) <TAB><TAB><TAB>  server . unwrap ( ) <TAB><TAB><TAB>  print ( "" server ok "" ) <TAB><TAB><TAB>  break <TAB><TAB>  server . sendall ( data ) ",if not data :,if client_done.is_set():,False,32.61104772023469,96.02738228605892
877,"def find_hostnames ( data ) : <TAB>  # sends back an array of hostnames <TAB>  hostnames = [ ] <TAB>  for i in re . finditer ( hostname_regex , data ) : <TAB><TAB>  h = string . lower ( i . group ( 1 ) ) <TAB><TAB>  tld = h . split ( "" . "" ) [ - 1 : ] [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  hostnames . append ( h ) <TAB>  return hostnames ",if tld in tlds :,if tld in hostnames:,False,32.56794051121362,94.71903838236823
878,"def Validate ( self , win ) : <TAB>  textCtrl = self . GetWindow ( ) <TAB>  text = textCtrl . GetValue ( ) . strip ( ) <TAB>  sChar = Character . getInstance ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( _t ( "" You must supply a name for the Character! "" ) ) <TAB><TAB>  elif text in [ x . name for x in sChar . getCharacterList ( ) ] : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  _t ( "" Character name already in use, please choose another. "" ) <TAB><TAB><TAB>  ) <TAB><TAB>  return True <TAB>  except ValueError as e : <TAB><TAB>  pyfalog . error ( e ) <TAB><TAB>  wx . MessageBox ( "" {} "" . format ( e ) , _t ( "" Error "" ) ) <TAB><TAB>  textCtrl . SetFocus ( ) <TAB><TAB>  return False ",if len ( text ) == 0 :,if text == None:,False,31.936839542977392,96.81929721889068
879,def get_random_user_agent ( agent_list = UA_CACHE ) : <TAB>  if not len ( agent_list ) : <TAB><TAB>  ua_file = file ( UA_FILE ) <TAB><TAB>  for line in ua_file : <TAB><TAB><TAB>  line = line . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  agent_list . append ( line ) <TAB>  ua = random . choice ( UA_CACHE ) <TAB>  return ua ,if line :,if line and line not in agent_list:,False,38.11896009364288,93.4743150943089
880,"def _validate_action_like_for_prefixes ( self , key ) : <TAB>  for statement in self . _statements : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( statement [ key ] , string_types ) : <TAB><TAB><TAB><TAB>  self . _validate_action_prefix ( statement [ key ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  for action in statement [ key ] : <TAB><TAB><TAB><TAB><TAB>  self . _validate_action_prefix ( action ) ",if key in statement :,if key in statement:,False,26.792442659517913,100.00000000000004
881,"def predict ( self , X ) : <TAB>  if self . regression : <TAB><TAB>  return self . predict_proba ( X ) <TAB>  else : <TAB><TAB>  y_pred = np . argmax ( self . predict_proba ( X ) , axis = 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y_pred = self . enc_ . inverse_transform ( y_pred ) <TAB><TAB>  return y_pred ",if self . use_label_encoder :,if self.enc_:,False,33.466259690726304,94.42164852987838
882,"def _threaded_request_tracker ( self , builder ) : <TAB>  while True : <TAB><TAB>  event_type = self . _read_q . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  payload = { "" body "" : b "" "" } <TAB><TAB>  request_id = builder . build_record ( event_type , payload , "" "" ) <TAB><TAB>  self . _write_q . put_nowait ( request_id ) ",if event_type is False :,if event_type is None:,False,20.682701697985372,97.96299003437207
883,"def __call__ ( self , value ) : <TAB>  try : <TAB><TAB>  super ( EmailValidator , self ) . __call__ ( value ) <TAB>  except ValidationError as e : <TAB><TAB>  # Trivial case failed. Try for possible IDN domain-part <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parts = value . split ( "" @ "" ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  parts [ - 1 ] = parts [ - 1 ] . encode ( "" idna "" ) . decode ( "" ascii "" ) <TAB><TAB><TAB>  except UnicodeError : <TAB><TAB><TAB><TAB>  raise e <TAB><TAB><TAB>  super ( EmailValidator , self ) . __call__ ( "" @ "" . join ( parts ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ","if value and ""@"" in value :",if e.code == 'Invalid email address':,False,57.98512851551641,92.42705951737345
884,"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB>  while self : <TAB><TAB>  if self . __Token : <TAB><TAB><TAB>  x = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self < = 2 : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  RegionSizeGuid = 3 <TAB><TAB><TAB>  if not RegionSizeGuid : <TAB><TAB><TAB><TAB>  RegionLayoutLine = 5 <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  RegionLayoutLine = self . CurrentLineNumber <TAB>  return 1 ",elif not IfList :,if x == 1:,False,26.00660730689785,95.70079502187826
885,"def _arg_with_type ( self ) : <TAB>  for t in self . d [ "" Args "" ] : <TAB><TAB>  m = re . search ( "" ([A-Za-z0-9_-]+) \ s { 0,4}( \ (.+ \ )) \ s { 0,4}: "" , t ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . args [ m . group ( 1 ) ] = m . group ( 2 ) <TAB>  return self . args ",if m :,if m:,False,51.435611850104166,100.00000000000004
886,"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB>  if self . label_map is not None : <TAB><TAB>  # return subset of palette <TAB><TAB>  palette = [ ] <TAB><TAB>  for old_id , new_id in sorted ( self . label_map . items ( ) , key = lambda x : x [ 1 ] ) : <TAB><TAB><TAB>  if new_id != - 1 : <TAB><TAB><TAB><TAB>  palette . append ( self . PALETTE [ old_id ] ) <TAB><TAB>  palette = type ( self . PALETTE ) ( palette ) <TAB>  elif palette is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  palette = np . random . randint ( 0 , 255 , size = ( len ( class_names ) , 3 ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  palette = self . PALETTE <TAB>  return palette ",if self . PALETTE is None :,if palette is None:,False,51.63848092067701,96.99440532953967
887,"def Visit_star_expr ( self , node ) :<TAB># pylint: disable=invalid-name <TAB>  # star_expr ::= '*' expr <TAB>  for child in node . children : <TAB><TAB>  self . Visit ( child ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _AppendTokenSubtype ( child , format_token . Subtype . UNARY_OPERATOR ) <TAB><TAB><TAB>  _AppendTokenSubtype ( child , format_token . Subtype . VARARGS_STAR ) ","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :",if child.type == format_token.Subtype.UNARY_OPERATOR:,False,10.624253686744835,85.35781153073063
888,"def create_if_compatible ( cls , typ : Type , * , root : "" RootNode "" ) - > Optional [ "" Node "" ] : <TAB>  if cls . compatible_types : <TAB><TAB>  target_type : Type = typ <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  target_type = getattr ( typ , "" __origin__ "" , None ) or typ <TAB><TAB>  if cls . _issubclass ( target_type , cls . compatible_types ) : <TAB><TAB><TAB>  return cls ( typ , root = root ) <TAB>  return None ",if cls . use_origin :,if target_type is None:,False,20.324396702585098,95.50484487492622
889,"def grep_full_py_identifiers ( tokens ) : <TAB>  global pykeywords <TAB>  tokens = list ( tokens ) <TAB>  i = 0 <TAB>  while i < len ( tokens ) : <TAB><TAB>  tokentype , token = tokens [ i ] <TAB><TAB>  i + = 1 <TAB><TAB>  if tokentype != "" id "" : <TAB><TAB><TAB>  continue <TAB><TAB>  while ( <TAB><TAB><TAB>  i + 1 < len ( tokens ) <TAB><TAB><TAB>  and tokens [ i ] == ( "" op "" , "" . "" ) <TAB><TAB><TAB>  and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB><TAB>  ) : <TAB><TAB><TAB>  token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB><TAB><TAB>  i + = 2 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if token in pykeywords : <TAB><TAB><TAB>  continue <TAB><TAB>  if token [ 0 ] in "" .0123456789 "" : <TAB><TAB><TAB>  continue <TAB><TAB>  yield token ","if token == """" :",if token in pykeywords:,False,22.234158681852733,98.09245973504343
890,"def create_config_filepath ( cls , visibility = None ) : <TAB>  if cls . is_local ( visibility ) : <TAB><TAB>  # Local to this directory <TAB><TAB>  base_path = os . path . join ( "" . "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Add it to the current ""./.polyaxon"" <TAB><TAB><TAB>  base_path = os . path . join ( base_path , "" .polyaxon "" ) <TAB><TAB><TAB>  cls . _create_dir ( base_path ) <TAB>  elif cls . CONFIG_PATH :<TAB># Custom path <TAB><TAB>  pass <TAB>  else :<TAB># Handle both global and all cases <TAB><TAB>  base_path = polyaxon_user_path ( ) <TAB><TAB>  cls . _create_dir ( base_path ) ",if cls . IS_POLYAXON_DIR :,if os.path.exists(base_path):,False,59.28081630463669,90.6888541727487
891,"def test_len ( self ) : <TAB>  eq = self . assertEqual <TAB>  eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB>  for size in range ( 15 ) : <TAB><TAB>  if size == 0 : <TAB><TAB><TAB>  bsize = 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bsize = 4 <TAB><TAB>  elif size < = 6 : <TAB><TAB><TAB>  bsize = 8 <TAB><TAB>  elif size < = 9 : <TAB><TAB><TAB>  bsize = 12 <TAB><TAB>  elif size < = 12 : <TAB><TAB><TAB>  bsize = 16 <TAB><TAB>  else : <TAB><TAB><TAB>  bsize = 20 <TAB><TAB>  eq ( base64MIME . base64_len ( "" x "" * size ) , bsize ) ",elif size <= 3 :,if size <= 5:,False,27.963075551222545,97.73217726427006
892,"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB>  result = { } <TAB>  dirs = dir ( path , version , section ) <TAB>  if not dirs : <TAB><TAB>  return None <TAB>  for item in dirs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  records = as_dict ( path + item , version , section ) <TAB><TAB><TAB>  if records : <TAB><TAB><TAB><TAB>  result [ item [ : - 1 ] ] = records <TAB><TAB>  elif is_dict . match ( item ) : <TAB><TAB><TAB>  idx , name = is_dict . match ( item ) . groups ( ) <TAB><TAB><TAB>  records = as_dict ( path + idx + "" / "" , version , section ) <TAB><TAB><TAB>  if records : <TAB><TAB><TAB><TAB>  result [ name ] = records <TAB><TAB>  else : <TAB><TAB><TAB>  result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB>  return result ","if item . endswith ( ""/"" ) :",if is_dict.match(item):,False,49.116760849469244,95.91870883159952
893,"def api_read ( self ) : <TAB>  result = { } <TAB>  files = [ "" my.cnf "" , "" debian.cnf "" ] <TAB>  directory_list = self . exec_payload ( "" mysql_config_directory "" ) [ "" directory "" ] <TAB>  for _file in files : <TAB><TAB>  for directory in directory_list : <TAB><TAB><TAB>  mysql_conf = directory + _file <TAB><TAB><TAB>  content = self . shell . read ( mysql_conf ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ mysql_conf ] = content <TAB>  return result ",if content :,if content:,False,52.21783008960087,100.00000000000004
894,"def generate ( self , count = 100 ) : <TAB>  self . pre_generate ( ) <TAB>  counter = iter ( range ( count ) ) <TAB>  created = 0 <TAB>  while True : <TAB><TAB>  batch = list ( islice ( counter , self . batch_size ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  self . do_generate ( batch , self . batch_size ) <TAB><TAB>  from_size = created <TAB><TAB>  created + = len ( batch ) <TAB><TAB>  print ( "" Generate  %s :  %s - %s "" % ( self . resource , from_size , created ) ) <TAB>  self . after_generate ( ) ",if not batch :,if not batch:,False,43.5683442561688,97.92834762120673
895,"def _normalize_fields ( self , document , loader ) : <TAB>  # type: (Dict[Text, Text], Loader) -> None <TAB>  # Normalize fields which are prefixed or full URIn to vocabulary terms <TAB>  for d in list ( document . keys ( ) ) : <TAB><TAB>  d2 = loader . expand_url ( d , u "" "" , scoped_id = False , vocab_term = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  document [ d2 ] = document [ d ] <TAB><TAB><TAB>  del document [ d ] ",if d != d2 :,if d2 in document:,False,39.008474155494305,96.14367356140296
896,"def load_cache ( filename , get_key = mangle_key ) : <TAB>  cache = { } <TAB>  if not os . path . exists ( filename ) : <TAB><TAB>  return cache <TAB>  f = open ( filename , "" rb "" ) <TAB>  l = 0 <TAB>  for line in f . readlines ( ) : <TAB><TAB>  l + = 1 <TAB><TAB>  fields = line . split ( b "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sys . stderr . write ( "" Invalid file format in [ %s ], line  %d \n "" % ( filename , l ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  # put key:value in cache, key without ^: <TAB><TAB>  cache [ get_key ( fields [ 0 ] [ 1 : ] ) ] = fields [ 1 ] . split ( b "" \n "" ) [ 0 ] <TAB>  f . close ( ) <TAB>  return cache ","if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :",if len(fields) != 2:,False,21.84690509465577,89.1936679427736
897,"def __lshift__ ( self , other ) : <TAB>  if not self . symbolic and type ( other ) is int : <TAB><TAB>  return RegisterOffset ( <TAB><TAB><TAB>  self . _bits , self . reg , self . _to_signed ( self . offset << other ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return RegisterOffset ( self . _bits , self . reg , self . offset << other ) <TAB><TAB>  else : <TAB><TAB><TAB>  return RegisterOffset ( <TAB><TAB><TAB><TAB>  self . _bits , <TAB><TAB><TAB><TAB>  self . reg , <TAB><TAB><TAB><TAB>  ArithmeticExpression ( <TAB><TAB><TAB><TAB><TAB>  ArithmeticExpression . LShift , <TAB><TAB><TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB><TAB><TAB>  self . offset , <TAB><TAB><TAB><TAB><TAB><TAB>  other , <TAB><TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB>  ) ",if self . symbolic :,"if isinstance(other, int):",False,24.36698117769135,97.5509389090226
898,"def SaveSettings ( self , force = False ) : <TAB>  if self . config is not None : <TAB><TAB>  frame . ShellFrameMixin . SaveSettings ( self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frame . Frame . SaveSettings ( self , self . config ) <TAB><TAB><TAB>  self . shell . SaveSettings ( self . config ) ",if self . autoSaveSettings or force :,if force:,False,48.535943937165534,93.58897266104783
899,"def _parse_gene ( element ) : <TAB>  for genename_element in element : <TAB><TAB>  if "" type "" in genename_element . attrib : <TAB><TAB><TAB>  ann_key = "" gene_ %s _ %s "" % ( <TAB><TAB><TAB><TAB>  genename_element . tag . replace ( NS , "" "" ) , <TAB><TAB><TAB><TAB>  genename_element . attrib [ "" type "" ] , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  append_to_annotations ( ann_key , genename_element . text ) ","if genename_element . attrib [ ""type"" ] == ""primary"" :",if ann_key not in self.ParsedSeqRecord.annotations:,False,23.983208114552834,92.37915545797384
900,"def _write_pkg_file ( self , file ) : <TAB>  with TemporaryFile ( mode = "" w+ "" ) as tmpfd : <TAB><TAB>  _write_pkg_file_orig ( self , tmpfd ) <TAB><TAB>  tmpfd . seek ( 0 ) <TAB><TAB>  for line in tmpfd : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  file . write ( "" Metadata-Version: 2.1 \n "" ) <TAB><TAB><TAB>  elif line . startswith ( "" Description:  "" ) : <TAB><TAB><TAB><TAB>  file . write ( <TAB><TAB><TAB><TAB><TAB>  "" Description-Content-Type:  %s ; charset=UTF-8 \n "" <TAB><TAB><TAB><TAB><TAB>  % long_description_content_type <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  file . write ( line ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  file . write ( line ) ","if line . startswith ( ""Metadata-Version: "" ) :",if line.startswith('Metadata-Version':,False,23.457699142786364,97.48939252632718
901,"def get ( self ) : <TAB>  """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB>  if self . _exception is not _NONE : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . value <TAB><TAB>  getcurrent ( ) . throw ( * self . _exception )<TAB># pylint:disable=undefined-variable <TAB>  else : <TAB><TAB>  if self . greenlet is not None : <TAB><TAB><TAB>  raise ConcurrentObjectUseError ( <TAB><TAB><TAB><TAB>  "" This Waiter is already used by  %r "" % ( self . greenlet , ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . greenlet = getcurrent ( )<TAB># pylint:disable=undefined-variable <TAB><TAB>  try : <TAB><TAB><TAB>  return self . hub . switch ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . greenlet = None ",if self . _exception is None :,if self.value is not _NONE:,False,34.051795214840325,93.89241274243123
902,"def connect ( self , * args ) : <TAB>  """"""connects to the dropbox. args[0] is the username."""""" <TAB>  if len ( args ) != 1 : <TAB><TAB>  return "" expected one argument! "" <TAB>  try : <TAB><TAB>  dbci = get_dropbox_client ( args [ 0 ] , False , None , None ) <TAB>  except Exception as e : <TAB><TAB>  return e . message <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" No Dropbox configured for  ' {u} ' . "" . format ( u = args [ 0 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . client = dbci <TAB><TAB>  return True ",if dbci is None :,if not dbci:,False,48.67608852538735,97.63983469405699
903,"def escape ( text , newline = False ) : <TAB>  """"""Escape special html characters."""""" <TAB>  if isinstance ( text , str ) : <TAB><TAB>  if "" & "" in text : <TAB><TAB><TAB>  text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB>  if "" > "" in text : <TAB><TAB><TAB>  text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB>  if "" < "" in text : <TAB><TAB><TAB>  text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB>  if ' "" ' in text : <TAB><TAB><TAB>  text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB>  if "" ' "" in text : <TAB><TAB><TAB>  text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB>  if newline : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  text = text . replace ( "" \n "" , "" <br> "" ) <TAB>  return text ","if ""\n"" in text :",if newline:,False,47.903873444813996,97.24858158356922
904,def t ( ret ) : <TAB>  with IPDB ( ) as ipdb : <TAB><TAB>  with ipdb . eventqueue ( ) as evq : <TAB><TAB><TAB>  for msg in evq : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  ret . append ( msg ) <TAB><TAB><TAB><TAB><TAB>  return ,"if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :",if msg.type == 'message':,False,22.927906415726884,85.49623484938499
905,"def check_stmt ( self , stmt ) : <TAB>  if is_future ( stmt ) : <TAB><TAB>  for name , asname in stmt . names : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . found [ name ] = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise SyntaxError ( "" future feature  %s  is not defined "" % name ) <TAB><TAB>  stmt . valid_future = 1 <TAB><TAB>  return 1 <TAB>  return 0 ",if name in self . features :,if asname.name == name:,False,51.39979634507754,94.81220802317901
906,"def process_pypi_option ( option , option_str , option_value , parser ) : <TAB>  if option_str . startswith ( "" --no "" ) : <TAB><TAB>  setattr ( parser . values , option . dest , [ ] ) <TAB>  else : <TAB><TAB>  indexes = getattr ( parser . values , option . dest , [ ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  indexes . append ( _PYPI ) <TAB><TAB>  setattr ( parser . values , option . dest , indexes ) ",if _PYPI not in indexes :,if indexes is not None:,False,21.265164219260022,95.20003578913615
907,"def modify_address ( self , name , address , domain ) : <TAB>  if not self . get_entries_by_name ( name , domain ) : <TAB><TAB>  raise exception . NotFound <TAB>  infile = open ( self . filename , "" r "" ) <TAB>  outfile = tempfile . NamedTemporaryFile ( "" w "" , delete = False ) <TAB>  for line in infile : <TAB><TAB>  entry = self . parse_line ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  outfile . write ( <TAB><TAB><TAB><TAB>  "" %s<TAB> %s<TAB> %s \n "" % ( address , self . qualify ( name , domain ) , entry [ "" type "" ] ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  outfile . write ( line ) <TAB>  infile . close ( ) <TAB>  outfile . close ( ) <TAB>  shutil . move ( outfile . name , self . filename ) ","if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :",if entry['address'] == address:,False,21.37314446914164,88.84066767802094
908,"def tms_to_quadkey ( self , tms , google = False ) : <TAB>  quadKey = "" "" <TAB>  x , y , z = tms <TAB>  # this algorithm works with google tiles, rather than tms, so convert <TAB>  # to those first. <TAB>  if not google : <TAB><TAB>  y = ( 2 * * z - 1 ) - y <TAB>  for i in range ( z , 0 , - 1 ) : <TAB><TAB>  digit = 0 <TAB><TAB>  mask = 1 << ( i - 1 ) <TAB><TAB>  if ( x & mask ) != 0 : <TAB><TAB><TAB>  digit + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  digit + = 2 <TAB><TAB>  quadKey + = str ( digit ) <TAB>  return quadKey ",if ( y & mask ) != 0 :,if y & mask:,False,58.19120670489881,94.65314084740298
909,"def add_if_unique ( self , issuer , use , keys ) : <TAB>  if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB><TAB>  for typ , key in keys : <TAB><TAB><TAB>  flag = 1 <TAB><TAB><TAB>  for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB><TAB><TAB><TAB>  if _typ == typ and key is _key : <TAB><TAB><TAB><TAB><TAB>  flag = 0 <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB>  else : <TAB><TAB>  self . issuer_keys [ issuer ] [ use ] = keys ",if flag :,if flag:,False,57.19365619393073,100.00000000000004
910,"def scan_error ( self ) : <TAB>  "" A string describing why the last scan failed, or None if it didn ' t. "" <TAB>  self . acquire_lock ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . _load_buf_data_once ( ) <TAB><TAB><TAB>  except NotFoundInDatabase : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  return self . _scan_error_cache <TAB>  finally : <TAB><TAB>  self . release_lock ( ) ",if self . _scan_error_cache is None :,if self._scan_error_cache is not None:,False,44.17847728292542,95.476493751924
911,"def _query ( self ) : <TAB>  if self . _mongo_query is None : <TAB><TAB>  self . _mongo_query = self . _query_obj . to_query ( self . _document ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" _cls "" in self . _mongo_query : <TAB><TAB><TAB><TAB>  self . _mongo_query = { "" $and "" : [ self . _cls_query , self . _mongo_query ] } <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _mongo_query . update ( self . _cls_query ) <TAB>  return self . _mongo_query ",if self . _cls_query :,if self._cls_query is not None:,False,22.49849042666563,97.44414411693832
912,"def CountButtons ( self ) : <TAB>  """"""Returns the number of visible buttons in the docked pane."""""" <TAB>  n = 0 <TAB>  if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB><TAB>  if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB><TAB><TAB>  return 1 <TAB><TAB>  if self . HasCloseButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  if self . HasMaximizeButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  if self . HasMinimizeButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n + = 1 <TAB>  return n ",if self . HasPinButton ( ) :,if self.HasMinimizeButton():,False,52.14439270197402,98.66121287187084
913,"def testBind ( self ) : <TAB>  try : <TAB><TAB>  with socket . socket ( socket . PF_CAN , socket . SOCK_DGRAM , socket . CAN_J1939 ) as s : <TAB><TAB><TAB>  addr = ( <TAB><TAB><TAB><TAB>  self . interface , <TAB><TAB><TAB><TAB>  socket . J1939_NO_NAME , <TAB><TAB><TAB><TAB>  socket . J1939_NO_PGN , <TAB><TAB><TAB><TAB>  socket . J1939_NO_ADDR , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  s . bind ( addr ) <TAB><TAB><TAB>  self . assertEqual ( s . getsockname ( ) , addr ) <TAB>  except OSError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . skipTest ( "" network interface ` %s ` does not exist "" % self . interface ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ",if e . errno == errno . ENODEV :,if e.errno != errno.EADDRINUSE:,False,51.01778278017595,97.96315999802947
914,"def createFields ( self ) : <TAB>  while self . current_size < self . size : <TAB><TAB>  pos = self . stream . searchBytes ( <TAB><TAB><TAB>  "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB><TAB>  )<TAB># seek forward by at most 1MB <TAB><TAB>  if pos is not None : <TAB><TAB><TAB>  padsize = pos - self . current_size <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield PaddingBytes ( self , "" pad[] "" , padsize / / 8 ) <TAB><TAB>  chunk = Chunk ( self , "" chunk[] "" ) <TAB><TAB>  try : <TAB><TAB><TAB>  # force chunk to be processed, so that CustomFragments are complete <TAB><TAB><TAB>  chunk [ "" content/data "" ] <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB><TAB>  yield chunk ",if padsize :,if padsize > 0:,False,60.76481230875942,96.74599004275272
915,"def index_modulemd_files ( repo_path ) : <TAB>  merger = Modulemd . ModuleIndexMerger ( ) <TAB>  for fn in sorted ( os . listdir ( repo_path ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  yaml_path = os . path . join ( repo_path , fn ) <TAB><TAB>  mmd = Modulemd . ModuleIndex ( ) <TAB><TAB>  mmd . update_from_file ( yaml_path , strict = True ) <TAB><TAB>  merger . associate_index ( mmd , 0 ) <TAB>  return merger . resolve ( ) ","if not fn . endswith ( "".yaml"" ) :","if not os.path.exists(repo_path, fn):",False,32.23235662087127,92.37914008485387
916,"def set_visible ( self , visible = True ) : <TAB>  self . _visible = visible <TAB>  if self . _nswindow is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Not really sure why on_resize needs to be here, <TAB><TAB><TAB>  # but it's what pyglet wants. <TAB><TAB><TAB>  self . dispatch_event ( "" on_resize "" , self . _width , self . _height ) <TAB><TAB><TAB>  self . dispatch_event ( "" on_show "" ) <TAB><TAB><TAB>  self . dispatch_event ( "" on_expose "" ) <TAB><TAB><TAB>  self . _nswindow . makeKeyAndOrderFront_ ( None ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _nswindow . orderOut_ ( None ) ",if visible :,if visible:,False,62.62907005521134,100.00000000000004
917,"def __repr__ ( self ) : <TAB>  if self . _in_repr : <TAB><TAB>  return "" <recursion> "" <TAB>  try : <TAB><TAB>  self . _in_repr = True <TAB><TAB>  if self . is_computed ( ) : <TAB><TAB><TAB>  status = "" computed,  "" <TAB><TAB><TAB>  if self . error ( ) is None : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  status + = "" = self "" <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  status + = "" =  "" + repr ( self . value ( ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  status + = "" error =  "" + repr ( self . error ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  status = "" isn ' t computed "" <TAB><TAB>  return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB>  finally : <TAB><TAB>  self . _in_repr = False ",if self . value ( ) is self :,if self.value() is None:,False,51.483710329617004,97.60081424886069
918,"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB>  if index_type == "" val "" : <TAB><TAB>  for key , value in segment . items ( ) : <TAB><TAB><TAB>  if key == index [ 0 ] : <TAB><TAB><TAB><TAB>  return value <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if key . text == index [ 0 ] : <TAB><TAB><TAB><TAB><TAB>  return value <TAB><TAB>  raise Exception ( "" Invalid state "" ) <TAB>  elif index_type == "" index "" : <TAB><TAB>  return segment [ index ] <TAB>  elif index_type == "" textslice "" : <TAB><TAB>  return segment [ index [ 0 ] : index [ 1 ] ] <TAB>  elif index_type == "" key "" : <TAB><TAB>  return index [ 1 ] if strictdoc else index [ 0 ] <TAB>  else : <TAB><TAB>  raise Exception ( "" Invalid state "" ) ","if hasattr ( key , ""text"" ) :","if index_type == ""key':",False,15.720240007571476,96.41883441675144
919,"def _makeSafeAbsoluteURI ( base , rel = None ) : <TAB>  # bail if ACCEPTABLE_URI_SCHEMES is empty <TAB>  if not ACCEPTABLE_URI_SCHEMES : <TAB><TAB>  return _urljoin ( base , rel or u "" "" ) <TAB>  if not base : <TAB><TAB>  return rel or u "" "" <TAB>  if not rel : <TAB><TAB>  try : <TAB><TAB><TAB>  scheme = urlparse . urlparse ( base ) [ 0 ] <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  return u "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return base <TAB><TAB>  return u "" "" <TAB>  uri = _urljoin ( base , rel ) <TAB>  if uri . strip ( ) . split ( "" : "" , 1 ) [ 0 ] not in ACCEPTABLE_URI_SCHEMES : <TAB><TAB>  return u "" "" <TAB>  return uri ",if not scheme or scheme in ACCEPTABLE_URI_SCHEMES :,if scheme.scheme == scheme.scheme:,False,53.29652600988683,95.05007997022393
920,"def _write_packet ( self , packet ) : <TAB>  # Immediately writes the given packet to the network. The caller must <TAB>  # have the write lock acquired before calling this method. <TAB>  try : <TAB><TAB>  for listener in self . early_outgoing_packet_listeners : <TAB><TAB><TAB>  listener . call_packet ( packet ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  packet . write ( self . socket , self . options . compression_threshold ) <TAB><TAB>  else : <TAB><TAB><TAB>  packet . write ( self . socket ) <TAB><TAB>  for listener in self . outgoing_packet_listeners : <TAB><TAB><TAB>  listener . call_packet ( packet ) <TAB>  except IgnorePacket : <TAB><TAB>  pass ",if self . options . compression_enabled :,if self.options.compression_threshold:,False,42.74272901506587,98.69612755723132
921,"def rangelist_to_set ( rangelist ) : <TAB>  result = set ( ) <TAB>  if not rangelist : <TAB><TAB>  return result <TAB>  for x in rangelist . split ( "" , "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . add ( int ( x ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  m = re . match ( r "" ^( \ d+)-( \ d+)$ "" , x ) <TAB><TAB>  if m : <TAB><TAB><TAB>  start = int ( m . group ( 1 ) ) <TAB><TAB><TAB>  end = int ( m . group ( 2 ) ) <TAB><TAB><TAB>  result . update ( set ( range ( start , end + 1 ) ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  msg = "" Cannot understand data input:  %s %s "" % ( x , rangelist ) <TAB><TAB>  raise ValueError ( msg ) <TAB>  return result ","if re . match ( r""^(\d+)$"" , x ) :",if x.startswith('^'):,False,31.759678319750574,93.49145208165125
922,"def test_device_property_logfile_isinstance ( self ) : <TAB>  mock = MagicMock ( ) <TAB>  with patch ( builtin_string + "" .open "" , mock ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  builtin_file = "" io.TextIOWrapper "" <TAB><TAB>  else : <TAB><TAB><TAB>  builtin_file = builtin_string + "" .file "" <TAB><TAB>  with patch ( builtin_file , MagicMock ) : <TAB><TAB><TAB>  handle = open ( "" filename "" , "" r "" ) <TAB><TAB><TAB>  self . dev . logfile = handle <TAB><TAB><TAB>  self . assertEqual ( self . dev . logfile , handle ) ","if sys . version > ""3"" :",if sys.platform == 'win32':,False,51.630374290790215,96.27170493825338
923,"def _line_ranges ( statements , lines ) : <TAB>  """"""Produce a list of ranges for `format_lines`."""""" <TAB>  statements = sorted ( statements ) <TAB>  lines = sorted ( lines ) <TAB>  pairs = [ ] <TAB>  start = None <TAB>  lidx = 0 <TAB>  for stmt in statements : <TAB><TAB>  if lidx > = len ( lines ) : <TAB><TAB><TAB>  break <TAB><TAB>  if stmt == lines [ lidx ] : <TAB><TAB><TAB>  lidx + = 1 <TAB><TAB><TAB>  if not start : <TAB><TAB><TAB><TAB>  start = stmt <TAB><TAB><TAB>  end = stmt <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pairs . append ( ( start , end ) ) <TAB><TAB><TAB>  start = None <TAB>  if start : <TAB><TAB>  pairs . append ( ( start , end ) ) <TAB>  return pairs ",elif start :,if start and end:,False,24.710890989622193,97.78450571463745
924,"def reset_parameters ( self ) : <TAB>  initialize = layers . get_initializer ( self . _hparams . initializer ) <TAB>  if initialize is not None : <TAB><TAB>  # Do not re-initialize LayerNorm modules. <TAB><TAB>  for name , param in self . named_parameters ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  initialize ( param ) ","if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :",if name == 'layernorm':,False,56.0378840370972,77.5392295396059
925,"def billing_invoice_show_validator ( namespace ) : <TAB>  from azure . cli . core . azclierror import ( <TAB><TAB>  RequiredArgumentMissingError , <TAB><TAB>  MutuallyExclusiveArgumentError , <TAB>  ) <TAB>  valid_combs = ( <TAB><TAB>  "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB>  ) <TAB>  if namespace . account_name is not None : <TAB><TAB>  if namespace . by_subscription is not None : <TAB><TAB><TAB>  raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB>  if namespace . by_subscription is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RequiredArgumentMissingError ( "" --name is also required "" ) ",if namespace . name is None :,if namespace.name is None:,False,56.6697258109974,96.19748696590686
926,"def DeleteDocuments ( self , document_ids , response ) : <TAB>  """"""Deletes documents for the given document_ids."""""" <TAB>  for document_id in document_ids : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  document = self . _documents [ document_id ] <TAB><TAB><TAB>  self . _inverted_index . RemoveDocument ( document ) <TAB><TAB><TAB>  del self . _documents [ document_id ] <TAB><TAB>  delete_status = response . add_status ( ) <TAB><TAB>  delete_status . set_code ( search_service_pb . SearchServiceError . OK ) ",if document_id in self . _documents :,if self._documents.has_key(document_id):,False,52.92928102671408,93.45966479959571
927,"def generate_new_element ( items , prefix , numeric = False ) : <TAB>  """"""Creates a random string with prefix, that is not in 'items' list."""""" <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  candidate = prefix + generate_random_numeric ( 8 ) <TAB><TAB>  else : <TAB><TAB><TAB>  candidate = prefix + generate_random_alphanumeric ( 8 ) <TAB><TAB>  if not candidate in items : <TAB><TAB><TAB>  return candidate <TAB><TAB>  LOG . debug ( "" Random collision on  %s "" % candidate ) ",if numeric :,if numeric:,False,64.50281117320115,100.00000000000004
928,"def generate_text_for_vocab ( self , data_dir , tmp_dir ) : <TAB>  for i , sample in enumerate ( <TAB><TAB>  self . generate_samples ( data_dir , tmp_dir , problem . DatasetSplit . TRAIN ) <TAB>  ) : <TAB><TAB>  if self . has_inputs : <TAB><TAB><TAB>  yield sample [ "" inputs "" ] <TAB><TAB>  yield sample [ "" targets "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ",if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,if i == len(self.samples):,False,21.601793623627575,81.87280802519392
929,"def _get_ccp ( config = None , config_path = None , saltenv = "" base "" ) : <TAB>  """""" """""" <TAB>  if config_path : <TAB><TAB>  config = __salt__ [ "" cp.get_file_str "" ] ( config_path , saltenv = saltenv ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise SaltException ( "" {}  is not available "" . format ( config_path ) ) <TAB>  if isinstance ( config , six . string_types ) : <TAB><TAB>  config = config . splitlines ( ) <TAB>  ccp = ciscoconfparse . CiscoConfParse ( config ) <TAB>  return ccp ",if config is False :,if config is None:,False,33.810194721464505,98.36315750772182
930,"def rpush ( key , * vals , * * kwargs ) : <TAB>  ttl = kwargs . get ( "" ttl "" ) <TAB>  cap = kwargs . get ( "" cap "" ) <TAB>  if not ttl and not cap : <TAB><TAB>  _client . rpush ( key , * vals ) <TAB>  else : <TAB><TAB>  pipe = _client . pipeline ( ) <TAB><TAB>  pipe . rpush ( key , * vals ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pipe . ltrim ( key , 0 , cap ) <TAB><TAB>  if ttl : <TAB><TAB><TAB>  pipe . expire ( key , ttl ) <TAB><TAB>  pipe . execute ( ) ",if cap :,if cap:,False,52.864981229297236,100.00000000000004
931,"def check_apns_certificate ( ss ) : <TAB>  mode = "" start "" <TAB>  for s in ss . split ( "" \n "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB>  mode = "" key "" <TAB><TAB>  elif mode == "" key "" : <TAB><TAB><TAB>  if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB>  mode = "" end "" <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB><TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB>  "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB>  ) <TAB>  if mode != "" end "" : <TAB><TAB>  raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","if mode == ""start"" :",if s.startswith('Proc-Type'):,False,54.83253893330178,95.57293619514596
932,"def _add_communication_type ( apps , schema_editor , communication_type ) : <TAB>  Worker = apps . get_model ( "" orchestra "" , "" Worker "" ) <TAB>  CommunicationPreference = apps . get_model ( "" orchestra "" , "" CommunicationPreference "" ) <TAB>  for worker in Worker . objects . all ( ) : <TAB><TAB>  ( <TAB><TAB><TAB>  communication_preference , <TAB><TAB><TAB>  created , <TAB><TAB>  ) = CommunicationPreference . objects . get_or_create ( <TAB><TAB><TAB>  worker = worker , communication_type = communication_type <TAB><TAB>  ) <TAB><TAB>  # By default set both Slack and Email notifications to True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  communication_preference . methods . slack = True <TAB><TAB><TAB>  communication_preference . methods . email = True <TAB><TAB>  communication_preference . save ( ) ",if created :,if created:,False,59.9510310104028,100.00000000000004
933,"def get_postgresql_driver_name ( ) : <TAB>  # pylint: disable=unused-variable <TAB>  try : <TAB><TAB>  driver = os . getenv ( "" CODECHECKER_DB_DRIVER "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return driver <TAB><TAB>  try : <TAB><TAB><TAB>  # pylint: disable=W0611 <TAB><TAB><TAB>  import psycopg2 <TAB><TAB><TAB>  return "" psycopg2 "" <TAB><TAB>  except Exception : <TAB><TAB><TAB>  # pylint: disable=W0611 <TAB><TAB><TAB>  import pg8000 <TAB><TAB><TAB>  return "" pg8000 "" <TAB>  except Exception as ex : <TAB><TAB>  LOG . error ( str ( ex ) ) <TAB><TAB>  LOG . error ( "" Failed to import psycopg2 or pg8000 module. "" ) <TAB><TAB>  raise ",if driver :,if driver:,False,31.068061315274857,100.00000000000004
934,"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB>  modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB>  for modname , entry in list ( modules . items ( ) ) : <TAB><TAB>  if entry is False : <TAB><TAB><TAB>  continue <TAB><TAB>  code , tags , used , refname = entry <TAB><TAB>  for fullname in list ( used ) : <TAB><TAB><TAB>  if used [ fullname ] == docname : <TAB><TAB><TAB><TAB>  used . pop ( fullname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  modules . pop ( modname ) ",if len ( used ) == 0 :,if modname in modules:,False,48.725635012496774,95.08781507613463
935,"def do_query ( data , q ) : <TAB>  ret = [ ] <TAB>  if not q : <TAB><TAB>  return ret <TAB>  qkey = q [ 0 ] <TAB>  for key , value in iterate ( data ) : <TAB><TAB>  if len ( q ) == 1 : <TAB><TAB><TAB>  if key == qkey : <TAB><TAB><TAB><TAB>  ret . append ( value ) <TAB><TAB><TAB>  elif is_iterable ( value ) : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if key == qkey : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB>  return ret ",if not is_iterable ( value ) :,if key == qkey:,False,49.856994883420164,96.80775355391103
936,"def _get_bucket_for_key ( self , key : bytes ) - > Optional [ _DBValueTuple ] : <TAB>  dbs : Iterable [ PartitionDB ] <TAB>  try : <TAB><TAB>  partition = self . _key_index [ key ] <TAB><TAB>  dbs = [ PartitionDB ( partition , self . _dbs [ partition ] ) ] <TAB>  except KeyError : <TAB><TAB>  dbs = cast ( Iterable [ PartitionDB ] , self . _dbs . items ( ) ) <TAB>  for partition , db in dbs : <TAB><TAB>  if db . key_may_exist ( key ) [ 0 ] : <TAB><TAB><TAB>  value = db . get ( key ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _key_index [ key ] = partition <TAB><TAB><TAB><TAB>  return _DBValueTuple ( db , value ) <TAB>  return None ",if value is not None :,if value is not None:,False,26.684748418302306,100.00000000000004
937,"def _clean ( self ) : <TAB>  logger . info ( "" Cleaning up... "" ) <TAB>  if self . _process is not None : <TAB><TAB>  if self . _process . poll ( ) is None : <TAB><TAB><TAB>  for _ in range ( 3 ) : <TAB><TAB><TAB><TAB>  self . _process . terminate ( ) <TAB><TAB><TAB><TAB>  time . sleep ( 0.5 ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _process . kill ( ) <TAB><TAB><TAB><TAB>  self . _process . wait ( ) <TAB><TAB><TAB><TAB>  logger . error ( "" KILLED "" ) <TAB>  if os . path . exists ( self . _tmp_dir ) : <TAB><TAB>  shutil . rmtree ( self . _tmp_dir ) <TAB>  self . _process = None <TAB>  self . _ws = None <TAB>  logger . info ( "" Cleanup complete "" ) ",if self . _process . poll ( ) is not None :,if self._process is None:,False,50.44033307465363,97.42393573622725
938,"def _calculate_runtimes ( states ) : <TAB>  results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB>  for state , resultset in states . items ( ) : <TAB><TAB>  if isinstance ( resultset , dict ) and "" duration "" in resultset : <TAB><TAB><TAB>  # Count the pass vs failures <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  results [ "" num_passed_states "" ] + = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results [ "" num_failed_states "" ] + = 1 <TAB><TAB><TAB>  # Count durations <TAB><TAB><TAB>  results [ "" runtime "" ] + = resultset [ "" duration "" ] <TAB>  log . debug ( "" Parsed state metrics:  {} "" . format ( results ) ) <TAB>  return results ","if resultset [ ""result"" ] :",if state == 'pass':,False,53.39017508783528,96.70137626566473
939,"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB>  if next is not None and token . end_mark . line == next . start_mark . line : <TAB><TAB>  spaces = next . start_mark . pointer - token . end_mark . pointer <TAB><TAB>  if max != - 1 and spaces > max : <TAB><TAB><TAB>  return LintProblem ( <TAB><TAB><TAB><TAB>  token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return LintProblem ( <TAB><TAB><TAB><TAB>  token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB><TAB><TAB>  ) ",elif min != - 1 and spaces < min :,if min != -1 and min != -1:,False,48.246105129389385,92.25172589562553
940,"def getfileinfo ( name ) : <TAB>  finfo = FInfo ( ) <TAB>  with io . open ( name , "" rb "" ) as fp : <TAB><TAB>  # Quick check for textfile <TAB><TAB>  data = fp . read ( 512 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  finfo . Type = "" TEXT "" <TAB><TAB>  fp . seek ( 0 , 2 ) <TAB><TAB>  dsize = fp . tell ( ) <TAB>  dir , file = os . path . split ( name ) <TAB>  file = file . replace ( "" : "" , "" - "" , 1 ) <TAB>  return file , finfo , dsize , 0 ",if 0 not in data :,if data == '\n':,False,51.47265930020062,95.35556774878162
941,"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB>  """"""Return XML element converting dicts recursively."""""" <TAB>  elem = Element ( tag , * * kwargs ) <TAB>  for key , val in dictionary . items ( ) : <TAB><TAB>  if tag == "" layers "" : <TAB><TAB><TAB>  child = dict_to_XML ( "" layer "" , val , name = key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  child = dict_to_XML ( key , val ) <TAB><TAB>  else : <TAB><TAB><TAB>  if tag == "" config "" : <TAB><TAB><TAB><TAB>  child = Element ( "" variable "" , name = key ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  child = Element ( key ) <TAB><TAB><TAB>  child . text = str ( val ) <TAB><TAB>  elem . append ( child ) <TAB>  return elem ","elif isinstance ( val , MutableMapping ) :","if tag == ""value':",False,26.57899628322371,96.53599277310963
942,"def _read_bytes ( self , length ) : <TAB>  buffer = b "" "" <TAB>  while length : <TAB><TAB>  chunk = self . request . recv ( length ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . debug ( "" Connection closed "" ) <TAB><TAB><TAB>  return False <TAB><TAB>  length - = len ( chunk ) <TAB><TAB>  buffer + = chunk <TAB>  return buffer ","if chunk == b"""" :",if not chunk:,False,18.48955025230015,93.39930982056376
943,"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB>  deps = cnt [ "" _deps "" ] <TAB>  for dep in deps . copy ( ) : <TAB><TAB>  dep_cnts = services . get ( dep ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB><TAB>  if dep_cnt : <TAB><TAB><TAB>  # TODO: avoid creating loops, A->B->A <TAB><TAB><TAB>  if init_service and init_service in dep_cnt [ "" _deps "" ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB><TAB><TAB>  deps . update ( new_deps ) <TAB>  return deps ",if not dep_cnts :,if not dep_cnts:,False,56.07583750883044,100.00000000000004
944,"def fix_repeating_arguments ( self ) : <TAB>  """"""Fix elements that should accumulate/increment values."""""" <TAB>  either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB>  for case in either : <TAB><TAB>  for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if e . value is None : <TAB><TAB><TAB><TAB><TAB>  e . value = [ ] <TAB><TAB><TAB><TAB>  elif type ( e . value ) is not list : <TAB><TAB><TAB><TAB><TAB>  e . value = e . value . split ( ) <TAB><TAB><TAB>  if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB><TAB><TAB><TAB>  e . value = 0 <TAB>  return self ",if type ( e ) is Argument or type ( e ) is Option and e . argcount :,if e.value is not None:,False,55.559275237178674,92.99313403130262
945,"def do_cli ( manager , options ) : <TAB>  header = [ "" Name "" , "" Description "" ] <TAB>  table_data = [ header ] <TAB>  for filter_name , filter in get_filters ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  filter_doc = inspect . getdoc ( filter ) or "" "" <TAB><TAB>  table_data . append ( [ filter_name , filter_doc ] ) <TAB>  try : <TAB><TAB>  table = TerminalTable ( options . table_type , table_data ) <TAB>  except TerminalTableError as e : <TAB><TAB>  console ( "" ERROR:  %s "" % str ( e ) ) <TAB>  else : <TAB><TAB>  console ( table . output ) ",if options . name and not options . name in filter_name :,if filter_name == options.name:,False,46.37104671564634,94.82598108190065
946,"def _do_cmp ( f1 , f2 ) : <TAB>  bufsize = BUFSIZE <TAB>  with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB><TAB>  while True : <TAB><TAB><TAB>  b1 = fp1 . read ( bufsize ) <TAB><TAB><TAB>  b2 = fp2 . read ( bufsize ) <TAB><TAB><TAB>  if b1 != b2 : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True ",if not b1 :,if b1 != b2:,False,27.91983184303406,96.30170578045109
947,"def apply ( self , db , person ) : <TAB>  families = person . get_parent_family_handle_list ( ) <TAB>  if families == [ ] : <TAB><TAB>  return True <TAB>  for family_handle in person . get_parent_family_handle_list ( ) : <TAB><TAB>  family = db . get_family_from_handle ( family_handle ) <TAB><TAB>  if family : <TAB><TAB><TAB>  father_handle = family . get_father_handle ( ) <TAB><TAB><TAB>  mother_handle = family . get_mother_handle ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  if not mother_handle : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if not father_handle :,if not father_handle or mother_handle:,False,24.682676741212607,97.96046529006665
948,"def caesar_cipher ( s , k ) : <TAB>  result = "" "" <TAB>  for char in s : <TAB><TAB>  n = ord ( char ) <TAB><TAB>  if 64 < n < 91 : <TAB><TAB><TAB>  n = ( ( n - 65 + k ) % 26 ) + 65 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n = ( ( n - 97 + k ) % 26 ) + 97 <TAB><TAB>  result = result + chr ( n ) <TAB>  return result ",if 96 < n < 123 :,if 64 < n < n < 65:,False,28.605431638481356,94.60457113946381
949,"def title_by_index ( self , trans , index , context ) : <TAB>  d_type = self . get_datatype ( trans , context ) <TAB>  for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB><TAB>  if i == index : <TAB><TAB><TAB>  rval = composite_name <TAB><TAB><TAB>  if composite_file . description : <TAB><TAB><TAB><TAB>  rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  rval = "" %s  [optional] "" % rval <TAB><TAB><TAB>  return rval <TAB>  if index < self . get_file_count ( trans , context ) : <TAB><TAB>  return "" Extra primary file "" <TAB>  return None ",if composite_file . optional :,"if self.is_optional(trans, context):",False,37.19480421836455,95.28536779301922
950,"def __str__ ( self ) : <TAB>  t = ""<TAB>  "" <TAB>  if self . _name != "" root "" : <TAB><TAB>  r = f "" { t * ( self . _level - 1 ) } { self . _name } : \n "" <TAB>  else : <TAB><TAB>  r = "" "" <TAB>  level = self . _level <TAB>  for i , ( k , v ) in enumerate ( self . _pointer . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r + = f "" { t * ( self . _level ) } { v } \n "" <TAB><TAB><TAB>  self . _level + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  r + = f "" { t * ( self . _level ) } { k } :  { v }  ( { type ( v ) . __name__ } ) \n "" <TAB><TAB>  self . _level = level <TAB>  return r [ : - 1 ] ","if isinstance ( v , Config ) :",if i == level:,False,16.439577948631808,94.8585122639474
951,"def __get_securitygroups ( vm_ ) : <TAB>  vm_securitygroups = config . get_cloud_config_value ( <TAB><TAB>  "" securitygroups "" , vm_ , __opts__ , search_global = False <TAB>  ) <TAB>  if not vm_securitygroups : <TAB><TAB>  return [ ] <TAB>  securitygroups = list_securitygroups ( ) <TAB>  for i in range ( len ( vm_securitygroups ) ) : <TAB><TAB>  vm_securitygroups [ i ] = six . text_type ( vm_securitygroups [ i ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise SaltCloudNotFound ( <TAB><TAB><TAB><TAB>  "" The specified securitygroups  ' {0} '  could not be found. "" . format ( <TAB><TAB><TAB><TAB><TAB>  vm_securitygroups [ i ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return vm_securitygroups ",if vm_securitygroups [ i ] not in securitygroups :,if not vm_securitygroups[i] or not securitygroups:,False,48.013999154149445,97.54685786360763
952,"def assert_walk_snapshot ( <TAB>  self , field , filespecs_or_globs , paths , ignore_patterns = None , prepare = None  ) : <TAB>  with self . mk_project_tree ( ignore_patterns = ignore_patterns ) as project_tree : <TAB><TAB>  scheduler = self . mk_scheduler ( <TAB><TAB><TAB>  rules = create_fs_rules ( ) , project_tree = project_tree <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  prepare ( project_tree ) <TAB><TAB>  result = self . execute ( scheduler , Snapshot , self . specs ( filespecs_or_globs ) ) [ 0 ] <TAB><TAB>  self . assertEqual ( sorted ( getattr ( result , field ) ) , sorted ( paths ) ) ",if prepare :,if prepare is not None:,False,38.85136737469742,97.56844962711325
953,"def _parse_rowids ( self , rowids ) : <TAB>  xploded = [ ] <TAB>  rowids = [ x . strip ( ) for x in rowids . split ( "" , "" ) ] <TAB>  for rowid in rowids : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  start = int ( rowid . split ( "" - "" ) [ 0 ] . strip ( ) ) <TAB><TAB><TAB><TAB>  end = int ( rowid . split ( "" - "" ) [ - 1 ] . strip ( ) ) <TAB><TAB><TAB><TAB>  xploded + = range ( start , end + 1 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  xploded . append ( int ( rowid ) ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  continue <TAB>  return sorted ( list ( set ( xploded ) ) ) ","if ""-"" in rowid :",if len(rowid.split('-')[0].strip()):,False,20.299671102557994,91.27991218191139
954,"def ensemble ( self , pairs , other_preds ) : <TAB>  """"""Ensemble the dict with statistical model predictions."""""" <TAB>  lemmas = [ ] <TAB>  assert len ( pairs ) == len ( other_preds ) <TAB>  for p , pred in zip ( pairs , other_preds ) : <TAB><TAB>  w , pos = p <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lemma = self . composite_dict [ ( w , pos ) ] <TAB><TAB>  elif w in self . word_dict : <TAB><TAB><TAB>  lemma = self . word_dict [ w ] <TAB><TAB>  else : <TAB><TAB><TAB>  lemma = pred <TAB><TAB>  if lemma is None : <TAB><TAB><TAB>  lemma = w <TAB><TAB>  lemmas . append ( lemma ) <TAB>  return lemmas ","if ( w , pos ) in self . composite_dict :",if w in self.composite_dict:,False,43.995305741340744,97.07588949207027
955,"def selectionToChunks ( self , remove = False , add = False ) : <TAB>  box = self . selectionBox ( ) <TAB>  if box : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . selectedChunks = set ( self . level . allChunks ) <TAB><TAB><TAB>  return <TAB><TAB>  selectedChunks = self . selectedChunks <TAB><TAB>  boxedChunks = set ( box . chunkPositions ) <TAB><TAB>  if boxedChunks . issubset ( selectedChunks ) : <TAB><TAB><TAB>  remove = True <TAB><TAB>  if remove and not add : <TAB><TAB><TAB>  selectedChunks . difference_update ( boxedChunks ) <TAB><TAB>  else : <TAB><TAB><TAB>  selectedChunks . update ( boxedChunks ) <TAB>  self . selectionTool . selectNone ( ) ",if box == self . level . bounds :,if not self.level.allChunks:,False,26.214468846736448,96.2744985337547
956,"def _ensure_max_size ( cls , image , max_size , interpolation ) : <TAB>  if max_size is not None : <TAB><TAB>  size = max ( image . shape [ 0 ] , image . shape [ 1 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  resize_factor = max_size / size <TAB><TAB><TAB>  new_height = int ( image . shape [ 0 ] * resize_factor ) <TAB><TAB><TAB>  new_width = int ( image . shape [ 1 ] * resize_factor ) <TAB><TAB><TAB>  image = ia . imresize_single_image ( <TAB><TAB><TAB><TAB>  image , ( new_height , new_width ) , interpolation = interpolation <TAB><TAB><TAB>  ) <TAB>  return image ",if size > max_size :,if size > 0:,False,35.648659234403546,97.70746959803563
957,"def _1_0_cloud_ips ( self , method , url , body , headers ) : <TAB>  if method == "" GET "" : <TAB><TAB>  return self . test_response ( httplib . OK , self . fixtures . load ( "" list_cloud_ips.json "" ) ) <TAB>  elif method == "" POST "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  body = json . loads ( body ) <TAB><TAB>  node = json . loads ( self . fixtures . load ( "" create_cloud_ip.json "" ) ) <TAB><TAB>  if "" reverse_dns "" in body : <TAB><TAB><TAB>  node [ "" reverse_dns "" ] = body [ "" reverse_dns "" ] <TAB><TAB>  return self . test_response ( httplib . ACCEPTED , json . dumps ( node ) ) ",if body :,"if method == ""POST':",False,22.363391939659056,96.73688035046099
958,"def get_formatted_stats ( self ) : <TAB>  """"""Get percentage or number of rar's done"""""" <TAB>  if self . cur_setname and self . cur_setname in self . total_volumes : <TAB><TAB>  # This won't work on obfuscated posts <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" %02d / %02d "" % ( self . cur_volume , self . total_volumes [ self . cur_setname ] ) <TAB>  return self . cur_volume ",if self . total_volumes [ self . cur_setname ] >= self . cur_volume and self . cur_volume :,if self.cur_volume:,False,59.74348564017136,84.58468800419409
959,"def wdayset ( self , year , month , day ) : <TAB>  # We need to handle cross-year weeks here. <TAB>  dset = [ None ] * ( self . yearlen + 7 ) <TAB>  i = datetime . date ( year , month , day ) . toordinal ( ) - self . yearordinal <TAB>  start = i <TAB>  for j in range ( 7 ) : <TAB><TAB>  dset [ i ] = i <TAB><TAB>  i + = 1 <TAB><TAB>  # if (not (0 <= i < self.yearlen) or <TAB><TAB>  #<TAB>self.wdaymask[i] == self.rrule._wkst): <TAB><TAB>  # This will cross the year boundary, if necessary. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return dset , start , i ",if self . wdaymask [ i ] == self . rrule . _wkst :,if i >= self.yearlen:,False,36.760798735268004,93.24712918037388
960,"def do_acquire_read_lock ( self , wait = True ) : <TAB>  self . condition . acquire ( ) <TAB>  try : <TAB><TAB>  # see if a synchronous operation is waiting to start <TAB><TAB>  # or is already running, in which case we wait (or just <TAB><TAB>  # give up and return) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  while self . current_sync_operation is not None : <TAB><TAB><TAB><TAB>  self . condition . wait ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  if self . current_sync_operation is not None : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  self . asynch + = 1 <TAB>  finally : <TAB><TAB>  self . condition . release ( ) <TAB>  if not wait : <TAB><TAB>  return True ",if wait :,if self.asynch == 0:,False,65.65558375143195,96.57902360462968
961,"def _blend ( x , y ) :<TAB># pylint: disable=invalid-name <TAB>  """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB>  if isinstance ( x , ( dict , OrderedDict ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return y <TAB><TAB>  return _merge ( x , y , recursion_func = _blend ) <TAB>  if isinstance ( x , ( list , tuple ) ) : <TAB><TAB>  if not isinstance ( y , ( list , tuple ) ) : <TAB><TAB><TAB>  return y <TAB><TAB>  result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB><TAB>  if len ( x ) > len ( y ) : <TAB><TAB><TAB>  result + = x [ len ( y ) : ] <TAB><TAB>  elif len ( x ) < len ( y ) : <TAB><TAB><TAB>  result + = y [ len ( x ) : ] <TAB><TAB>  return result <TAB>  return y ","if not isinstance ( y , ( dict , OrderedDict ) ) :","if not isinstance(x, (dict, OrderedDict)):",False,11.410039281213882,97.31557230307192
962,"def update_forum_nums_topic_post ( modeladmin , request , queryset ) : <TAB>  for forum in queryset : <TAB><TAB>  forum . num_topics = forum . count_nums_topic ( ) <TAB><TAB>  forum . num_posts = forum . count_nums_post ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  forum . last_post = forum . topic_set . order_by ( "" -last_reply_on "" ) [ 0 ] . last_post <TAB><TAB>  else : <TAB><TAB><TAB>  forum . last_post = "" "" <TAB><TAB>  forum . save ( ) ",if forum . num_topics :,"if hasattr(settings, 'JOB_LAST_POST'):",False,24.814435853640195,92.97898820162793
963,"def get_docname_for_node ( self , node : Node ) - > str : <TAB>  while node : <TAB><TAB>  if isinstance ( node , nodes . document ) : <TAB><TAB><TAB>  return self . env . path2doc ( node [ "" source "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return node [ "" docname "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  node = node . parent <TAB>  return None<TAB># never reached here. only for type hinting ","elif isinstance ( node , addnodes . start_of_file ) :",if node.docname:,False,42.14435075659115,88.38212597570772
964,"def _selected_machines ( self , virtual_machines ) : <TAB>  selected_machines = [ ] <TAB>  for machine in virtual_machines : <TAB><TAB>  if self . _args . host and self . _args . host == machine . name : <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB><TAB>  if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB>  return selected_machines ",if self . locations and machine . location in self . locations :,if machine.name == machine.name:,False,49.055163020553834,92.81335637828091
965,"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB>  if len ( name ) == 1 : <TAB><TAB>  if value is True : <TAB><TAB><TAB>  return [ "" - %s "" % name ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if split_single_char_options : <TAB><TAB><TAB><TAB>  return [ "" - %s "" % name , "" %s "" % value ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return [ "" - %s %s "" % ( name , value ) ] <TAB>  else : <TAB><TAB>  if value is True : <TAB><TAB><TAB>  return [ "" -- %s "" % dashify ( name ) ] <TAB><TAB>  elif value is not False and value is not None : <TAB><TAB><TAB>  return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB>  return [ ] ","elif value not in ( False , None ) :",if value is not None:,False,29.94983121320307,96.12747069554432
966,"def indent ( elem , level = 0 ) : <TAB>  i = "" \n "" + level * ""<TAB>"" <TAB>  if len ( elem ) : <TAB><TAB>  if not elem . text or not elem . text . strip ( ) : <TAB><TAB><TAB>  elem . text = i + ""<TAB>"" <TAB><TAB>  if not elem . tail or not elem . tail . strip ( ) : <TAB><TAB><TAB>  elem . tail = i <TAB><TAB>  for elem in elem : <TAB><TAB><TAB>  indent ( elem , level + 1 ) <TAB><TAB>  if not elem . tail or not elem . tail . strip ( ) : <TAB><TAB><TAB>  elem . tail = i <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elem . tail = i ",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,if not elem.tail:,False,28.005571333249357,90.95007947976985
967,"def _run_instances_op ( self , op , instance_ids , * * kwargs ) : <TAB>  while instance_ids : <TAB><TAB>  try : <TAB><TAB><TAB>  return self . manager . retry ( op , InstanceIds = instance_ids , * * kwargs ) <TAB><TAB>  except ClientError as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  instance_ids . remove ( extract_instance_id ( e ) ) <TAB><TAB><TAB>  raise ","if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :",if e.response['Error']['Code'] == 'ResourceInUseException':,False,20.045238293706845,90.48164111301642
968,"def runTest ( self ) : <TAB>  self . poco ( text = "" wait UI "" ) . click ( ) <TAB>  bomb_count = 0 <TAB>  while True : <TAB><TAB>  blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB><TAB>  yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB><TAB>  bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB><TAB>  fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bomb_count + = 1 <TAB><TAB><TAB>  if bomb_count > 3 : <TAB><TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  fish . click ( ) <TAB><TAB>  time . sleep ( 2.5 ) ",if fish is bomb :,if fish is not None:,False,22.354805465661478,98.51033460469041
969,"def lineWidth ( self , lw = None ) : <TAB>  """"""Set/get width of mesh edges. Same as `lw()`."""""" <TAB>  if lw is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . GetProperty ( ) . EdgeVisibilityOff ( ) <TAB><TAB><TAB>  self . GetProperty ( ) . SetRepresentationToSurface ( ) <TAB><TAB><TAB>  return self <TAB><TAB>  self . GetProperty ( ) . EdgeVisibilityOn ( ) <TAB><TAB>  self . GetProperty ( ) . SetLineWidth ( lw ) <TAB>  else : <TAB><TAB>  return self . GetProperty ( ) . GetLineWidth ( ) <TAB>  return self ",if lw == 0 :,if lw > 0:,False,60.25256881823084,97.78797913289853
970,"def _current_date_updater ( doc , field_name , value ) : <TAB>  if isinstance ( doc , dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # TODO(juannyg): get_current_timestamp should also be using helpers utcnow, <TAB><TAB><TAB>  # as it currently using time.time internally <TAB><TAB><TAB>  doc [ field_name ] = helpers . get_current_timestamp ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  doc [ field_name ] = mongomock . utcnow ( ) ","if value == { ""$type"" : ""timestamp"" } :",if value:,False,54.872830048642584,90.52381891120876
971,"def fill_members ( self ) : <TAB>  if self . _get_retrieve ( ) : <TAB><TAB>  after = self . after . id if self . after else None <TAB><TAB>  data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # no data, terminate <TAB><TAB><TAB>  return <TAB><TAB>  if len ( data ) < 1000 : <TAB><TAB><TAB>  self . limit = 0<TAB># terminate loop <TAB><TAB>  self . after = Object ( id = int ( data [ - 1 ] [ "" user "" ] [ "" id "" ] ) ) <TAB><TAB>  for element in reversed ( data ) : <TAB><TAB><TAB>  await self . members . put ( self . create_member ( element ) ) ",if not data :,if not data:,False,50.88953811367798,96.09461651517941
972,"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB>  items = [ ] <TAB>  for extractor in self . extractors : <TAB><TAB>  extracted = extractor . extract ( <TAB><TAB><TAB>  page , start_index , end_index , self . template . ignored_regions <TAB><TAB>  ) <TAB><TAB>  for item in arg_to_iter ( extracted ) : <TAB><TAB><TAB>  if item : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  item [ u "" _template "" ] = self . template . id <TAB><TAB><TAB><TAB>  items . append ( item ) <TAB>  return items ","if isinstance ( item , ( ItemProcessor , dict ) ) :",if not self.template.id in item:,False,43.20428488731686,93.96207935231836
973,"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB>  fields = self . config [ fields_key ] <TAB>  node_tags = self . provider . node_tags ( node_id ) <TAB>  if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB><TAB>  node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB><TAB>  if node_type not in self . available_node_types : <TAB><TAB><TAB>  raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB><TAB>  node_specific_config = self . available_node_types [ node_type ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fields = node_specific_config [ fields_key ] <TAB>  return fields ",if fields_key in node_specific_config :,if node_specific_config and fields is None:,False,24.874386734003874,96.86846507071532
974,"def _write_all ( self , writer ) : <TAB>  """"""Writes messages and insert comments here and there."""""" <TAB>  # Note: we make no assumptions about the length of original_messages and original_comments <TAB>  for msg , comment in zip_longest ( <TAB><TAB>  self . original_messages , self . original_comments , fillvalue = None <TAB>  ) : <TAB><TAB>  # msg and comment might be None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" writing comment:  "" , comment ) <TAB><TAB><TAB>  writer . log_event ( comment )<TAB># we already know that this method exists <TAB><TAB>  if msg is not None : <TAB><TAB><TAB>  print ( "" writing message:  "" , msg ) <TAB><TAB><TAB>  writer ( msg ) ",if comment is not None :,if comment is not None:,False,67.67144615752886,97.7730323743121
975,"def run_tests ( ) : <TAB>  # type: () -> None <TAB>  x = 5 <TAB>  with switch ( x ) as case : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" zero "" ) <TAB><TAB><TAB>  print ( "" zero "" ) <TAB><TAB>  elif case ( 1 , 2 ) : <TAB><TAB><TAB>  print ( "" one or two "" ) <TAB><TAB>  elif case ( 3 , 4 ) : <TAB><TAB><TAB>  print ( "" three or four "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" default "" ) <TAB><TAB><TAB>  print ( "" another "" ) ",if case ( 0 ) :,"if case(0, 1):",False,27.03077795761105,98.02201824717983
976,"def date_to_format ( value , target_format ) : <TAB>  """"""Convert date to specified format"""""" <TAB>  if target_format == str : <TAB><TAB>  if isinstance ( value , datetime . date ) : <TAB><TAB><TAB>  ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB>  elif isinstance ( value , datetime . time ) : <TAB><TAB><TAB>  ret = value . strftime ( "" % H: % M: % S "" ) <TAB>  else : <TAB><TAB>  ret = value <TAB>  return ret ","elif isinstance ( value , datetime . datetime ) :","if isinstance(value, datetime.date):",False,29.06087469874154,97.24473083672815
977,"def database_app ( request ) : <TAB>  if request . param == "" postgres_app "" : <TAB><TAB>  if not which ( "" initdb "" ) : <TAB><TAB><TAB>  pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB>  if request . param == "" sqlite_rabbitmq_app "" : <TAB><TAB>  if not os . environ . get ( "" GALAXY_TEST_AMQP_INTERNAL_CONNECTION "" ) : <TAB><TAB><TAB>  pytest . skip ( <TAB><TAB><TAB><TAB>  "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB><TAB><TAB>  ) <TAB>  return request . getfixturevalue ( request . param ) ",if not psycopg2 :,if not which('psycopg2'):,False,37.31536095036879,97.35760303042875
978,"def poll_ms ( self , timeout = - 1 ) : <TAB>  s = bytearray ( self . evbuf ) <TAB>  <IF-STMT>: <TAB><TAB>  deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB>  while True : <TAB><TAB>  n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB><TAB>  if not os . check_error ( n ) : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB><TAB><TAB>  if timeout < 0 : <TAB><TAB><TAB><TAB>  n = 0 <TAB><TAB><TAB><TAB>  break <TAB>  res = [ ] <TAB>  if n > 0 : <TAB><TAB>  vals = struct . unpack ( epoll_event , s ) <TAB><TAB>  res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB>  return res ",if timeout >= 0 :,if timeout > 0:,False,26.74624025799811,95.49216743532016
979,"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB>  """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB>  all_plugins = [ ] <TAB>  for name in self . plugins_callback_order : <TAB><TAB>  # None is a placeholder for any plugin not having a defined order <TAB><TAB>  if name is None : <TAB><TAB><TAB>  all_plugins + = [ <TAB><TAB><TAB><TAB>  plugin <TAB><TAB><TAB><TAB>  for name , plugin in self . plugins . items ( ) <TAB><TAB><TAB><TAB>  if name not in self . plugins_callback_order and plugin . is_activated <TAB><TAB><TAB>  ] <TAB><TAB>  else : <TAB><TAB><TAB>  plugin = self . plugins [ name ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  all_plugins . append ( plugin ) <TAB>  return all_plugins ",if plugin . is_activated :,if plugin is not None:,False,59.33823332561258,97.91794873226819
980,"def get_expected_sql ( self ) : <TAB>  sql_base_path = path . join ( path . dirname ( path . realpath ( __file__ ) ) , "" sql "" ) <TAB>  # Iterate the version mapping directories. <TAB>  for version_mapping in get_version_mapping_directories ( self . server [ "" type "" ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  complete_path = path . join ( sql_base_path , version_mapping [ "" name "" ] ) <TAB><TAB>  if not path . exists ( complete_path ) : <TAB><TAB><TAB>  continue <TAB><TAB>  break <TAB>  data_sql = "" "" <TAB>  with open ( path . join ( complete_path , "" test_sql_output.sql "" ) ) as fp : <TAB><TAB>  data_sql = fp . read ( ) <TAB>  return data_sql ","if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :",if not version_mapping['name'] in sql_base_path:,False,53.76902087952799,91.87760466696376
981,"def _validate_headers ( self , headers ) : <TAB>  if headers is None : <TAB><TAB>  return headers <TAB>  res = { } <TAB>  for key , value in headers . items ( ) : <TAB><TAB>  if isinstance ( value , ( int , float ) ) : <TAB><TAB><TAB>  value = str ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ScriptError ( <TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB>  "" message "" : "" headers must be a table "" <TAB><TAB><TAB><TAB><TAB>  ""  with strings as keys and values. "" <TAB><TAB><TAB><TAB><TAB>  "" Header: ` {!r} : {!r} ` is not valid "" . format ( key , value ) <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  ) <TAB><TAB>  res [ key ] = value <TAB>  return res ","if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) :","if not isinstance(value, (Table, Table)):",False,45.31784860204805,93.79953864717608
982,"def _get_literal_value ( self , pyval ) : <TAB>  if pyval == self . vm . lookup_builtin ( "" builtins.True "" ) : <TAB><TAB>  return True <TAB>  elif pyval == self . vm . lookup_builtin ( "" builtins.False "" ) : <TAB><TAB>  return False <TAB>  elif isinstance ( pyval , str ) : <TAB><TAB>  prefix , value = parser_constants . STRING_RE . match ( pyval ) . groups ( ) [ : 2 ] <TAB><TAB>  value = value [ 1 : - 1 ]<TAB># remove quotation marks <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = compat . bytestring ( value ) <TAB><TAB>  elif "" u "" in prefix and self . vm . PY2 : <TAB><TAB><TAB>  value = compat . UnicodeType ( value ) <TAB><TAB>  return value <TAB>  else : <TAB><TAB>  return pyval ","if ""b"" in prefix and not self . vm . PY2 :","if ""s"" in prefix and self.vm.PY2:",False,25.019161085647255,95.0325646516386
983,"def decode_query_ids ( self , trans , conditional ) : <TAB>  if conditional . operator == "" and "" : <TAB><TAB>  self . decode_query_ids ( trans , conditional . left ) <TAB><TAB>  self . decode_query_ids ( trans , conditional . right ) <TAB>  else : <TAB><TAB>  left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field = self . FIELDS [ left_base ] <TAB><TAB><TAB>  if field . id_decode : <TAB><TAB><TAB><TAB>  conditional . right = trans . security . decode_id ( conditional . right ) ",if left_base in self . FIELDS :,if left_base in self.FIELDS:,False,50.95203210447872,100.00000000000004
984,"def testLastPhrases ( self ) : <TAB>  for day in ( 11 , 12 , 13 , 14 , 15 , 16 , 17 ) : <TAB><TAB>  start = datetime . datetime ( 2012 , 11 , day , 9 , 0 , 0 ) <TAB><TAB>  ( yr , mth , dy , _ , _ , _ , wd , yd , isdst ) = start . timetuple ( ) <TAB><TAB>  n = 4 - wd <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n - = 7 <TAB><TAB>  target = start + datetime . timedelta ( days = n ) <TAB><TAB>  self . assertExpectedResult ( <TAB><TAB><TAB>  self . cal . parse ( "" last friday "" , start . timetuple ( ) ) , <TAB><TAB><TAB>  ( target . timetuple ( ) , 1 ) , <TAB><TAB><TAB>  dateOnly = True , <TAB><TAB>  ) ",if n >= 0 :,if n > 7:,False,50.03214611237674,98.34305690961207
985,"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB>  nbMinBit = None <TAB>  nbMaxBit = None <TAB>  if nbChars is not None : <TAB><TAB>  if isinstance ( nbChars , int ) : <TAB><TAB><TAB>  nbMinBit = nbChars * 8 <TAB><TAB><TAB>  nbMaxBit = nbMinBit <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  nbMinBit = nbChars [ 0 ] * 8 <TAB><TAB><TAB>  if nbChars [ 1 ] is not None : <TAB><TAB><TAB><TAB>  nbMaxBit = nbChars [ 1 ] * 8 <TAB>  return ( nbMinBit , nbMaxBit ) ",if nbChars [ 0 ] is not None :,if nbChars[0] is not None:,False,52.6726269370791,100.00000000000004
986,"def getpystone ( ) : <TAB>  # Start calculation <TAB>  maxpystone = 0 <TAB>  # Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second <TAB>  for pyseed in [ 1000 , 2000 , 5000 , 10000 , 20000 , 50000 , 100000 , 200000 ] : <TAB><TAB>  duration , pystonefloat = pystones ( pyseed ) <TAB><TAB>  maxpystone = max ( maxpystone , int ( pystonefloat ) ) <TAB><TAB>  # Stop when pystone() has been running for at least 0.1 second <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return maxpystone ",if duration > 0.1 :,if maxpystone < 0:,False,44.45834779181085,96.7871319904416
987,"def _append_to_io_queue ( self , data , stream_name ) : <TAB>  # Make sure ANSI CSI codes and object links are stored as separate events <TAB>  # TODO: try to complete previously submitted incomplete code <TAB>  parts = re . split ( OUTPUT_SPLIT_REGEX , data ) <TAB>  for part in parts : <TAB><TAB>  <IF-STMT>:<TAB># split may produce empty string in the beginning or start <TAB><TAB><TAB>  # split the data so that very long lines separated <TAB><TAB><TAB>  for block in re . split ( <TAB><TAB><TAB><TAB>  "" (. { %d ,}) "" % ( self . _get_squeeze_threshold ( ) + 1 ) , part <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  if block : <TAB><TAB><TAB><TAB><TAB>  self . _queued_io_events . append ( ( block , stream_name ) ) ",if part :,"if part.startswith('.{%d,}) '):",False,45.20946465599288,92.46907182431451
988,"def qtTypeIdent ( conn , * args ) : <TAB>  # We're not using the conn object at the moment, but - we will <TAB>  # modify the <TAB>  # logic to use the server version specific keywords later. <TAB>  res = None <TAB>  value = None <TAB>  for val in args : <TAB><TAB>  # DataType doesn't have len function then convert it to string <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = str ( val ) <TAB><TAB>  if len ( val ) == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  value = val <TAB><TAB>  if Driver . needsQuoting ( val , True ) : <TAB><TAB><TAB>  value = value . replace ( ' "" ' , ' "" "" ' ) <TAB><TAB><TAB>  value = ' "" ' + value + ' "" ' <TAB><TAB>  res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB>  return res ","if not hasattr ( val , ""__len__"" ) :","if isinstance(val, basestring):",False,40.04211064266206,94.99850563084945
989,"def SetVerbose ( self , level ) : <TAB>  """"""Sets the verbose level."""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  level = int ( level ) <TAB><TAB>  if ( level > = 0 ) and ( level < = 3 ) : <TAB><TAB><TAB>  self . _verbose = level <TAB><TAB><TAB>  return <TAB>  except ValueError : <TAB><TAB>  pass <TAB>  self . Error ( "" Verbose level ( %s ) must be between 0 and 3 inclusive. "" % level ) ",if type ( level ) != types . IntType :,"if isinstance(level, int):",False,46.81364250134443,93.30623290373437
990,"def step ( self ) - > None : <TAB>  """"""Performs a single optimization step."""""" <TAB>  for group in self . param_groups : <TAB><TAB>  for p in group [ "" params "" ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  p . add_ ( p . grad , alpha = ( - group [ "" lr "" ] * self . num_data ) ) <TAB>  return None ",if p . grad is None :,if p.grad is None:,False,26.252491774874144,97.08187854150721
991,"def fill ( self , values ) : <TAB>  if lupa . lua_type ( values ) != "" table "" : <TAB><TAB>  raise ScriptError ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" argument "" : "" values "" , <TAB><TAB><TAB><TAB>  "" message "" : "" element:fill values is not a table "" , <TAB><TAB><TAB><TAB>  "" splash_method "" : "" fill "" , <TAB><TAB><TAB>  } <TAB><TAB>  ) <TAB>  # marking all tables as arrays by default <TAB>  for key , value in values . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _mark_table_as_array ( self . lua , value ) <TAB>  values = self . lua . lua2python ( values ) <TAB>  return self . element . fill ( values ) ","if lupa . lua_type ( value ) == ""table"" :",if key == 'table':,False,58.25589916231162,93.81431136147563
992,"def _gen_repr ( self , buf ) : <TAB>  print >> buf , ""<TAB> def __repr__(self): "" <TAB>  if self . argnames : <TAB><TAB>  fmt = COMMA . join ( [ "" %s "" ] * self . nargs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fmt = "" ( %s ) "" % fmt <TAB><TAB>  vals = [ "" repr(self. %s ) "" % name for name in self . argnames ] <TAB><TAB>  vals = COMMA . join ( vals ) <TAB><TAB>  if self . nargs == 1 : <TAB><TAB><TAB>  vals = vals + "" , "" <TAB><TAB>  print >> buf , '<TAB><TAB> return  "" %s ( %s ) "" %%  ( %s ) ' % ( self . name , fmt , vals ) <TAB>  else : <TAB><TAB>  print >> buf , '<TAB><TAB> return  "" %s () "" ' % self . name ","if ""("" in self . args :",if self.nargs > 0:,False,18.78360005750912,96.86355630844626
993,"def render_observation ( self ) : <TAB>  x = self . read_head_position <TAB>  label = "" Observation Grid<TAB>:  "" <TAB>  x_str = "" "" <TAB>  for j in range ( - 1 , self . rows + 1 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x_str + = "" "" * len ( label ) <TAB><TAB>  for i in range ( - 2 , self . input_width + 2 ) : <TAB><TAB><TAB>  if i == x [ 0 ] and j == x [ 1 ] : <TAB><TAB><TAB><TAB>  x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  x_str + = self . _get_str_obs ( ( i , j ) ) <TAB><TAB>  x_str + = "" \n "" <TAB>  x_str = label + x_str <TAB>  return x_str ",if j != - 1 :,if x[j] == 0:,False,27.62774808720174,94.28788664066059
994,"def get_module_comment ( self , attrname : str ) - > Optional [ List [ str ] ] : <TAB>  try : <TAB><TAB>  analyzer = ModuleAnalyzer . for_module ( self . modname ) <TAB><TAB>  analyzer . analyze ( ) <TAB><TAB>  key = ( "" "" , attrname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return list ( analyzer . attr_docs [ key ] ) <TAB>  except PycodeError : <TAB><TAB>  pass <TAB>  return None ",if key in analyzer . attr_docs :,if key in analyzer.attr_docs:,False,22.458374124694235,100.00000000000004
995,"def tms_to_quadkey ( self , tms , google = False ) : <TAB>  quadKey = "" "" <TAB>  x , y , z = tms <TAB>  # this algorithm works with google tiles, rather than tms, so convert <TAB>  # to those first. <TAB>  if not google : <TAB><TAB>  y = ( 2 * * z - 1 ) - y <TAB>  for i in range ( z , 0 , - 1 ) : <TAB><TAB>  digit = 0 <TAB><TAB>  mask = 1 << ( i - 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  digit + = 1 <TAB><TAB>  if ( y & mask ) != 0 : <TAB><TAB><TAB>  digit + = 2 <TAB><TAB>  quadKey + = str ( digit ) <TAB>  return quadKey ",if ( x & mask ) != 0 :,if x & mask != 0:,False,58.19748471291061,96.17989792476662
996,"def test_enumerate ( app ) : <TAB>  async with new_stream ( app ) as stream : <TAB><TAB>  for i in range ( 100 ) : <TAB><TAB><TAB>  await stream . channel . deliver ( message ( key = i , value = i * 4 ) ) <TAB><TAB>  async for i , value in stream . enumerate ( ) : <TAB><TAB><TAB>  current_event = stream . current_event <TAB><TAB><TAB>  assert i == current_event . key <TAB><TAB><TAB>  assert value == i * 4 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  assert await channel_empty ( stream . channel ) ",if i >= 99 :,if i == 100:,False,42.49577371461319,97.59672148034194
997,"def print_messages ( self ) : <TAB>  output_reports = self . config . get_output_report ( ) <TAB>  for report in output_reports : <TAB><TAB>  output_format , output_files = report <TAB><TAB>  self . summary [ "" formatter "" ] = output_format <TAB><TAB>  formatter = FORMATTERS [ output_format ] ( <TAB><TAB><TAB>  self . summary , self . messages , self . config . profile <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . write_to ( formatter , sys . stdout ) <TAB><TAB>  for output_file in output_files : <TAB><TAB><TAB>  with open ( output_file , "" w+ "" ) as target : <TAB><TAB><TAB><TAB>  self . write_to ( formatter , target ) ",if not output_files :,if output_format == output_format:,False,21.512507066875962,95.81384980562824
998,"def eval_metrics ( self ) : <TAB>  for task in self . task_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ <TAB><TAB><TAB><TAB>  metrics . Metrics . ACC , <TAB><TAB><TAB><TAB>  metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB><TAB><TAB><TAB>  metrics . Metrics . ROUGE_2_F , <TAB><TAB><TAB><TAB>  metrics . Metrics . ROUGE_L_F , <TAB><TAB><TAB>  ] <TAB>  return [ <TAB><TAB>  metrics . Metrics . ACC , <TAB><TAB>  metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB>  ] ","if ""summarize"" in task . name :",if task.type == 'log':,False,49.62970276251999,95.57354005854698
999,"def _getBuildRequestForBrdict ( self , brdict ) : <TAB>  # Turn a brdict into a BuildRequest into a brdict. This is useful <TAB>  # for API like 'nextBuild', which operate on BuildRequest objects. <TAB>  breq = self . breqCache . get ( brdict [ "" buildrequestid "" ] ) <TAB>  if not breq : <TAB><TAB>  breq = yield BuildRequest . fromBrdict ( self . master , brdict ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . breqCache [ brdict [ "" buildrequestid "" ] ] = breq <TAB>  defer . returnValue ( breq ) ",if breq :,if breq:,False,43.050003895347864,100.00000000000004
1000,"def _stash_splitter ( states ) : <TAB>  keep , split = [ ] , [ ] <TAB>  if state_func is not None : <TAB><TAB>  for s in states : <TAB><TAB><TAB>  ns = state_func ( s ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  split . append ( ns ) <TAB><TAB><TAB>  elif isinstance ( ns , ( list , tuple , set ) ) : <TAB><TAB><TAB><TAB>  split . extend ( ns ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  split . append ( s ) <TAB>  if stash_func is not None : <TAB><TAB>  split = stash_func ( states ) <TAB>  if to_stash is not stash : <TAB><TAB>  keep = states <TAB>  return keep , split ","if isinstance ( ns , SimState ) :","if isinstance(ns, (int, float, long)):",False,33.73925452502872,96.1584539446829
1001,"def sequence_to_text ( sequence ) : <TAB>  """"""Converts a sequence of IDs back to a string"""""" <TAB>  result = "" "" <TAB>  for symbol_id in sequence : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s = _id_to_symbol [ symbol_id ] <TAB><TAB><TAB>  # Enclose ARPAbet back in curly braces: <TAB><TAB><TAB>  if len ( s ) > 1 and s [ 0 ] == "" @ "" : <TAB><TAB><TAB><TAB>  s = "" { %s } "" % s [ 1 : ] <TAB><TAB><TAB>  result + = s <TAB>  return result . replace ( "" } { "" , "" "" ) ",if symbol_id in _id_to_symbol :,if symbol_id in _id_to_symbol:,False,60.718132372727794,100.00000000000004
1002,"def get_code ( self , fullname = None ) : <TAB>  fullname = self . _fix_name ( fullname ) <TAB>  if self . code is None : <TAB><TAB>  mod_type = self . etc [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  source = self . get_source ( fullname ) <TAB><TAB><TAB>  self . code = compile ( source , self . filename , "" exec "" ) <TAB><TAB>  elif mod_type == imp . PY_COMPILED : <TAB><TAB><TAB>  self . _reopen ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . code = read_code ( self . file ) <TAB><TAB><TAB>  finally : <TAB><TAB><TAB><TAB>  self . file . close ( ) <TAB><TAB>  elif mod_type == imp . PKG_DIRECTORY : <TAB><TAB><TAB>  self . code = self . _get_delegate ( ) . get_code ( ) <TAB>  return self . code ",if mod_type == imp . PY_SOURCE :,if mod_type == imp.PY_COMPILED:,False,30.363186548915955,99.04485426482702
1003,"def identwaf ( self , findall = False ) : <TAB>  detected = list ( ) <TAB>  try : <TAB><TAB>  self . attackres = self . performCheck ( self . centralAttack ) <TAB>  except RequestBlocked : <TAB><TAB>  return detected <TAB>  for wafvendor in self . checklist : <TAB><TAB>  self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB><TAB>  if self . wafdetections [ wafvendor ] ( self ) : <TAB><TAB><TAB>  detected . append ( wafvendor ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB>  self . knowledge [ "" wafname "" ] = detected <TAB>  return detected ",if not findall :,if findall:,False,42.52687903323237,98.43874970601577
1004,"def SessionId ( self ) : <TAB>  """"""Returns the Session ID of the process"""""" <TAB>  if self . Session . is_valid ( ) : <TAB><TAB>  process_space = self . get_process_address_space ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return obj . Object ( <TAB><TAB><TAB><TAB>  "" _MM_SESSION_SPACE "" , offset = self . Session , vm = process_space <TAB><TAB><TAB>  ) . SessionId <TAB>  return obj . NoneObject ( "" Cannot find process session "" ) ",if process_space :,if process_space:,False,57.50239098840775,100.00000000000004
1005,"def _convert_java_pattern_to_python ( pattern ) : <TAB>  """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB>  s = list ( pattern ) <TAB>  i = 0 <TAB>  while i < len ( s ) - 1 : <TAB><TAB>  c = s [ i ] <TAB><TAB>  if c == "" $ "" and s [ i + 1 ] in "" 0123456789 "" : <TAB><TAB><TAB>  s [ i ] = "" \\ "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s [ i ] = "" "" <TAB><TAB><TAB>  i + = 1 <TAB><TAB>  i + = 1 <TAB>  return pattern [ : 0 ] . join ( s ) ","elif c == ""\\"" and s [ i + 1 ] == ""$"" :","if c == ""'"":",False,35.963185821072024,91.07646178505924
1006,"def __init__ ( self , coverage ) : <TAB>  self . coverage = coverage <TAB>  self . config = self . coverage . config <TAB>  self . source_paths = set ( ) <TAB>  if self . config . source : <TAB><TAB>  for src in self . config . source : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if not self . config . relative_files : <TAB><TAB><TAB><TAB><TAB>  src = files . canonical_filename ( src ) <TAB><TAB><TAB><TAB>  self . source_paths . add ( src ) <TAB>  self . packages = { } <TAB>  self . xml_out = None ",if os . path . exists ( src ) :,if src.startswith('.py'):,False,22.369047085187756,95.6801866261983
1007,"def populate_vol_format ( self ) : <TAB>  rhel6_file_whitelist = [ "" raw "" , "" qcow2 "" , "" qed "" ] <TAB>  model = self . widget ( "" vol-format "" ) . get_model ( ) <TAB>  model . clear ( ) <TAB>  formats = self . vol_class . formats <TAB>  if hasattr ( self . vol_class , "" create_formats "" ) : <TAB><TAB>  formats = getattr ( self . vol_class , "" create_formats "" ) <TAB>  if self . vol_class == Storage . FileVolume and not self . conn . rhel6_defaults_caps ( ) : <TAB><TAB>  newfmts = [ ] <TAB><TAB>  for f in rhel6_file_whitelist : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  newfmts . append ( f ) <TAB><TAB>  formats = newfmts <TAB>  for f in formats : <TAB><TAB>  model . append ( [ f , f ] ) ",if f in formats :,if f not in formats:,False,50.835034733278775,98.90705000370515
1008,"def get_file_sources ( ) : <TAB>  global _file_sources <TAB>  if _file_sources is None : <TAB><TAB>  from galaxy . files import ConfiguredFileSources <TAB><TAB>  file_sources = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  file_sources_as_dict = None <TAB><TAB><TAB>  with open ( "" file_sources.json "" , "" r "" ) as f : <TAB><TAB><TAB><TAB>  file_sources_as_dict = json . load ( f ) <TAB><TAB><TAB>  if file_sources_as_dict is not None : <TAB><TAB><TAB><TAB>  file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB><TAB>  if file_sources is None : <TAB><TAB><TAB>  ConfiguredFileSources . from_dict ( [ ] ) <TAB><TAB>  _file_sources = file_sources <TAB>  return _file_sources ","if os . path . exists ( ""file_sources.json"" ) :","if os.path.exists(""file_sources.json""):",False,51.26053870306312,100.00000000000004
1009,"def _blend ( x , y ) :<TAB># pylint: disable=invalid-name <TAB>  """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB>  if isinstance ( x , ( dict , OrderedDict ) ) : <TAB><TAB>  if not isinstance ( y , ( dict , OrderedDict ) ) : <TAB><TAB><TAB>  return y <TAB><TAB>  return _merge ( x , y , recursion_func = _blend ) <TAB>  if isinstance ( x , ( list , tuple ) ) : <TAB><TAB>  if not isinstance ( y , ( list , tuple ) ) : <TAB><TAB><TAB>  return y <TAB><TAB>  result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result + = x [ len ( y ) : ] <TAB><TAB>  elif len ( x ) < len ( y ) : <TAB><TAB><TAB>  result + = y [ len ( x ) : ] <TAB><TAB>  return result <TAB>  return y ",if len ( x ) > len ( y ) :,if len(x) > len(y):,False,11.380610872256506,98.2763368409405
1010,"def copy_dicts ( dct ) : <TAB>  if "" _remote_data "" in dct : <TAB><TAB>  dsindex = dct [ "" _remote_data "" ] [ "" _content "" ] . dsindex <TAB><TAB>  newdct = dct . copy ( ) <TAB><TAB>  newdct [ "" _remote_data "" ] = { "" _content "" : dsindex } <TAB><TAB>  return list ( newdct . items ( ) ) <TAB>  elif "" _data "" in dct : <TAB><TAB>  newdct = dct . copy ( ) <TAB><TAB>  newdata = copy_dicts ( dct [ "" _data "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newdct [ "" _data "" ] = newdata <TAB><TAB>  return list ( newdct . items ( ) ) <TAB>  return None ",if newdata :,if newdata:,False,50.44696610245579,100.00000000000004
1011,"def _import_epic_activity ( self , project_data , taiga_epic , epic , options ) : <TAB>  offset = 0 <TAB>  while True : <TAB><TAB>  activities = self . _client . get ( <TAB><TAB><TAB>  "" /projects/ {} /epics/ {} /activity "" . format ( <TAB><TAB><TAB><TAB>  project_data [ "" id "" ] , <TAB><TAB><TAB><TAB>  epic [ "" id "" ] , <TAB><TAB><TAB>  ) , <TAB><TAB><TAB>  { "" envelope "" : "" true "" , "" limit "" : 300 , "" offset "" : offset } , <TAB><TAB>  ) <TAB><TAB>  offset + = 300 <TAB><TAB>  for activity in activities [ "" data "" ] : <TAB><TAB><TAB>  self . _import_activity ( taiga_epic , activity , options ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ","if len ( activities [ ""data"" ] ) < 300 :",if offset >= self._limit:,False,21.777232209332986,94.83867053128962
1012,"def __get__ ( self , instance , instance_type = None ) : <TAB>  if instance : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rel_obj = self . get_obj ( instance ) <TAB><TAB><TAB>  if rel_obj : <TAB><TAB><TAB><TAB>  instance . _obj_cache [ self . att_name ] = rel_obj <TAB><TAB>  return instance . _obj_cache . get ( self . att_name ) <TAB>  return self ",if self . att_name not in instance . _obj_cache :,if instance_type is None:,False,44.53474162615173,89.4623051479761
1013,"def download_main ( <TAB>  download , download_playlist , urls , playlist , output_dir , merge , info_only  ) : <TAB>  for url in urls : <TAB><TAB>  if url . startswith ( "" https:// "" ) : <TAB><TAB><TAB>  url = url [ 8 : ] <TAB><TAB>  if not url . startswith ( "" http:// "" ) : <TAB><TAB><TAB>  url = "" http:// "" + url <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  download_playlist ( <TAB><TAB><TAB><TAB>  url , output_dir = output_dir , merge = merge , info_only = info_only <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  download ( url , output_dir = output_dir , merge = merge , info_only = info_only ) ",if playlist :,if playlist:,False,50.71405307705198,100.00000000000004
1014,"def _mksubs ( self ) : <TAB>  self . _subs = { } <TAB>  commit_dir = CommitDir ( self , "" .commit "" ) <TAB>  self . _subs [ "" .commit "" ] = commit_dir <TAB>  tag_dir = TagDir ( self , "" .tag "" ) <TAB>  self . _subs [ "" .tag "" ] = tag_dir <TAB>  for ( name , sha ) in git . list_refs ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = name [ 11 : ] <TAB><TAB><TAB>  date = git . rev_get_date ( sha . encode ( "" hex "" ) ) <TAB><TAB><TAB>  n1 = BranchList ( self , name , sha ) <TAB><TAB><TAB>  n1 . ctime = n1 . mtime = date <TAB><TAB><TAB>  self . _subs [ name ] = n1 ","if name . startswith ( ""refs/heads/"" ) :",if name.startswith('git'):,False,50.63605147569571,96.53719638960352
1015,"def readAtOffset ( self , offset , size , shortok = False ) : <TAB>  ret = b "" "" <TAB>  self . fd . seek ( offset ) <TAB>  while len ( ret ) != size : <TAB><TAB>  rlen = size - len ( ret ) <TAB><TAB>  x = self . fd . read ( rlen ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not shortok : <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  return ret <TAB><TAB>  ret + = x <TAB>  return ret ","if x == b"""" :",if x == b'':,False,24.012350979754554,96.79220086167163
1016,"def remove_indent ( self ) : <TAB>  """"""Remove one tab-width of blanks from the previous token."""""" <TAB>  w = abs ( self . tab_width ) <TAB>  if self . result : <TAB><TAB>  s = self . result [ - 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . result . pop ( ) <TAB><TAB><TAB>  s = s . replace ( "" \t "" , "" "" * w ) <TAB><TAB><TAB>  if s . startswith ( "" \n "" ) : <TAB><TAB><TAB><TAB>  s2 = s [ 1 : ] <TAB><TAB><TAB><TAB>  self . result . append ( "" \n "" + s2 [ : - w ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . result . append ( s [ : - w ] ) ",if s . isspace ( ) :,if w > 0:,False,31.408641787133924,93.21959977799489
1017,"def flush ( self , * args , * * kwargs ) : <TAB>  with self . _lock : <TAB><TAB>  self . _last_updated = time . time ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  if kwargs . get ( "" in_place "" , False ) : <TAB><TAB><TAB><TAB>  self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  self . _last_updated = time . time ( ) ","if ""_create_temporary"" in traceback . format_exc ( ) :",if self._last_updated > time.time() - self._last_updated:,False,40.58572220788426,92.0530063581445
1018,"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB>  for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB><TAB>  elif act [ "" component "" ] [ "" code "" ] in MANUAL_INTERVENTION_COMP_CODES : <TAB><TAB><TAB>  manual_intervention_nodes . add ( act [ "" id "" ] ) ","if act [ ""type"" ] == ""SubProcess"" :",if act['id'] == 'pipeline':,False,26.604278677159876,92.89614331349135
1019,"def banned ( ) : <TAB>  if request . endpoint == "" views.themes "" : <TAB><TAB>  return <TAB>  if authed ( ) : <TAB><TAB>  user = get_current_user_attrs ( ) <TAB><TAB>  team = get_current_team_attrs ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ( <TAB><TAB><TAB><TAB>  render_template ( <TAB><TAB><TAB><TAB><TAB>  "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  403 , <TAB><TAB><TAB>  ) <TAB><TAB>  if team and team . banned : <TAB><TAB><TAB>  return ( <TAB><TAB><TAB><TAB>  render_template ( <TAB><TAB><TAB><TAB><TAB>  "" errors/403.html "" , <TAB><TAB><TAB><TAB><TAB>  error = "" Your team has been banned from this CTF "" , <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  403 , <TAB><TAB><TAB>  ) ",if user and user . banned :,if user and user.banned:,False,60.15329810115097,100.00000000000004
1020,"def remove ( self , values ) : <TAB>  if not isinstance ( values , ( list , tuple , set ) ) : <TAB><TAB>  values = [ values ] <TAB>  for v in values : <TAB><TAB>  v = str ( v ) <TAB><TAB>  if isinstance ( self . _definition , dict ) : <TAB><TAB><TAB>  self . _definition . pop ( v , None ) <TAB><TAB>  elif self . _definition == "" ANY "" : <TAB><TAB><TAB>  if v == "" ANY "" : <TAB><TAB><TAB><TAB>  self . _definition = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _definition . remove ( v ) <TAB>  if ( <TAB><TAB>  self . _value is not None <TAB><TAB>  and self . _value not in self . _definition <TAB><TAB>  and self . _not_any ( ) <TAB>  ) : <TAB><TAB>  raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) ) ",elif v in self . _definition :,if v in self._definition:,False,46.67163721943643,99.05209761565798
1021,"def save ( self , learner , file_name ) : <TAB>  """"""Save the model to location specified in file_name."""""" <TAB>  with open ( file_name , "" wb "" ) as f : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # don't store the large inference cache! <TAB><TAB><TAB>  learner . inference_cache_ , tmp = ( None , learner . inference_cache_ ) <TAB><TAB><TAB>  pickle . dump ( learner , f , - 1 ) <TAB><TAB><TAB>  learner . inference_cache_ = tmp <TAB><TAB>  else : <TAB><TAB><TAB>  pickle . dump ( learner , f , - 1 ) ","if hasattr ( learner , ""inference_cache_"" ) :",if learner.inference_cache_ is not None:,False,56.675715511966395,91.93142859989824
1022,"def __init__ ( self , exprs , savelist = False ) : <TAB>  super ( ParseExpression , self ) . __init__ ( savelist ) <TAB>  if isinstance ( exprs , _generatorType ) : <TAB><TAB>  exprs = list ( exprs ) <TAB>  if isinstance ( exprs , basestring ) : <TAB><TAB>  self . exprs = [ ParserElement . _literalStringClass ( exprs ) ] <TAB>  elif isinstance ( exprs , collections . Iterable ) : <TAB><TAB>  exprs = list ( exprs ) <TAB><TAB>  # if sequence of strings provided, wrap with Literal <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exprs = map ( ParserElement . _literalStringClass , exprs ) <TAB><TAB>  self . exprs = list ( exprs ) <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  self . exprs = list ( exprs ) <TAB><TAB>  except TypeError : <TAB><TAB><TAB>  self . exprs = [ exprs ] <TAB>  self . callPreparse = False ","if all ( isinstance ( expr , basestring ) for expr in exprs ) :","if isinstance(exprs, ParserElement):",False,55.69764305635705,94.97619603426108
1023,"def find ( self , back = False ) : <TAB>  flags = 0 <TAB>  <IF-STMT>: <TAB><TAB>  flags = QTextDocument . FindBackward <TAB>  if self . csBox . isChecked ( ) : <TAB><TAB>  flags = flags | QTextDocument . FindCaseSensitively <TAB>  text = self . searchEdit . text ( ) <TAB>  if not self . findMain ( text , flags ) : <TAB><TAB>  if text in self . editBoxes [ self . ind ] . toPlainText ( ) : <TAB><TAB><TAB>  cursor = self . editBoxes [ self . ind ] . textCursor ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cursor . movePosition ( QTextCursor . End ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  cursor . movePosition ( QTextCursor . Start ) <TAB><TAB><TAB>  self . editBoxes [ self . ind ] . setTextCursor ( cursor ) <TAB><TAB><TAB>  self . findMain ( text , flags ) ",if back :,if back:,False,25.030678032001347,98.04407632684465
1024,"def _load_storage ( self ) : <TAB>  self . _storage = { } <TAB>  for row in self ( "" SELECT object, resource, amount FROM storage "" ) : <TAB><TAB>  ownerid = int ( row [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _storage [ ownerid ] . append ( row [ 1 : ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _storage [ ownerid ] = [ row [ 1 : ] ] ",if ownerid in self . _storage :,if ownerid in self._storage:,False,56.06704204377437,100.00000000000004
1025,"def parse_chunked ( self , unreader ) : <TAB>  ( size , rest ) = self . parse_chunk_size ( unreader ) <TAB>  while size > 0 : <TAB><TAB>  while size > len ( rest ) : <TAB><TAB><TAB>  size - = len ( rest ) <TAB><TAB><TAB>  yield rest <TAB><TAB><TAB>  rest = unreader . read ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise NoMoreData ( ) <TAB><TAB>  yield rest [ : size ] <TAB><TAB>  # Remove \r\n after chunk <TAB><TAB>  rest = rest [ size : ] <TAB><TAB>  while len ( rest ) < 2 : <TAB><TAB><TAB>  rest + = unreader . read ( ) <TAB><TAB>  if rest [ : 2 ] != b "" \r \n "" : <TAB><TAB><TAB>  raise ChunkMissingTerminator ( rest [ : 2 ] ) <TAB><TAB>  ( size , rest ) = self . parse_chunk_size ( unreader , data = rest [ 2 : ] ) ",if not rest :,if size == 0:,False,47.89229002216712,97.90991727815049
1026,"def _augment_batch_ ( self , batch , random_state , parents , hooks ) : <TAB>  for column in batch . columns : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for i , cbaoi in enumerate ( column . value ) : <TAB><TAB><TAB><TAB>  column . value [ i ] = cbaoi . clip_out_of_image_ ( ) <TAB>  return batch ","if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :","if isinstance(column.value, (list, tuple)):",False,45.90876653695821,78.21783507659757
1027,"def to_nim ( self ) : <TAB>  if self . is_pointer == 2 : <TAB><TAB>  s = "" cstringArray "" if self . type == "" GLchar "" else "" ptr pointer "" <TAB>  else : <TAB><TAB>  s = self . type <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  default = "" ptr  "" + s <TAB><TAB><TAB>  s = self . NIM_POINTER_MAP . get ( s , default ) <TAB>  return s ",if self . is_pointer == 1 :,if self.is_pointer == 1:,False,50.99512475757433,100.00000000000004
1028,"def find ( self , path ) : <TAB>  if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB><TAB>  self . num_files = self . num_files + 1 <TAB><TAB>  if self . match_function ( path ) : <TAB><TAB><TAB>  self . files . append ( path ) <TAB>  elif os . path . isdir ( path ) : <TAB><TAB>  for content in os . listdir ( path ) : <TAB><TAB><TAB>  file = os . path . join ( path , content ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . num_files = self . num_files + 1 <TAB><TAB><TAB><TAB>  if self . match_function ( file ) : <TAB><TAB><TAB><TAB><TAB>  self . files . append ( file ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . find ( file ) ",if os . path . isfile ( file ) or os . path . islink ( file ) :,if os.path.isfile(file):,False,42.96232698446892,96.46402934831234
1029,"def remove ( self , event ) : <TAB>  try : <TAB><TAB>  self . _events_current_sweep . remove ( event ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert event . in_sweep == True <TAB><TAB><TAB>  assert event . other . in_sweep == True <TAB><TAB><TAB>  event . in_sweep = False <TAB><TAB><TAB>  event . other . in_sweep = False <TAB><TAB>  return True <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert event . in_sweep == False <TAB><TAB><TAB>  assert event . other . in_sweep == False <TAB><TAB>  return False ",if USE_DEBUG :,if self.other:,False,20.68284994869978,94.56700520566416
1030,"def update_metadata ( self ) : <TAB>  for attrname in dir ( self ) : <TAB><TAB>  if attrname . startswith ( "" __ "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  attrvalue = getattr ( self , attrname , None ) <TAB><TAB>  if attrvalue == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attrname = "" version "" <TAB><TAB>  if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB>  getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB>  elif hasattr ( self . metadata , attrname ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  pass ","if attrname == ""salt_version"" :",if attrname == '__version__':,False,50.949686854854306,96.84918591215438
1031,"def _init_auxiliary_head ( self , auxiliary_head ) : <TAB>  """"""Initialize ``auxiliary_head``"""""" <TAB>  if auxiliary_head is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . auxiliary_head = nn . ModuleList ( ) <TAB><TAB><TAB>  for head_cfg in auxiliary_head : <TAB><TAB><TAB><TAB>  self . auxiliary_head . append ( builder . build_head ( head_cfg ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . auxiliary_head = builder . build_head ( auxiliary_head ) ","if isinstance ( auxiliary_head , list ) :",if auxiliary_head is None:,False,48.22246828647447,94.96351887045684
1032,"def _str_param_list ( self , name ) : <TAB>  out = [ ] <TAB>  if self [ name ] : <TAB><TAB>  out + = self . _str_header ( name ) <TAB><TAB>  for param in self [ name ] : <TAB><TAB><TAB>  parts = [ ] <TAB><TAB><TAB>  if param . name : <TAB><TAB><TAB><TAB>  parts . append ( param . name ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  parts . append ( param . type ) <TAB><TAB><TAB>  out + = [ ""  :  "" . join ( parts ) ] <TAB><TAB><TAB>  if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB><TAB><TAB><TAB>  out + = self . _str_indent ( param . desc ) <TAB><TAB>  out + = [ "" "" ] <TAB>  return out ",if param . type :,if param.type:,False,33.953727366490796,100.00000000000004
1033,"def _set_handler ( <TAB>  self , name , handle = None , obj = None , constructor_args = ( ) , constructor_kwds = { }  ) : <TAB>  if handle is None : <TAB><TAB>  handle = obj is not None <TAB>  if handle : <TAB><TAB>  handler_class = self . handler_classes [ name ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newhandler = handler_class ( obj ) <TAB><TAB>  else : <TAB><TAB><TAB>  newhandler = handler_class ( * constructor_args , * * constructor_kwds ) <TAB>  else : <TAB><TAB>  newhandler = None <TAB>  self . _replace_handler ( name , newhandler ) ",if obj is not None :,"if isinstance(handler_class, Handler):",False,29.58346261917919,94.51767111111047
1034,"def _extract_subtitles ( src ) : <TAB>  subtitles = { } <TAB>  for caption in try_get ( src , lambda x : x [ "" captions "" ] , list ) or [ ] : <TAB><TAB>  subtitle_url = url_or_none ( caption . get ( "" uri "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lang = caption . get ( "" language "" , "" deu "" ) <TAB><TAB><TAB>  subtitles . setdefault ( lang , [ ] ) . append ( <TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB>  "" url "" : subtitle_url , <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  ) <TAB>  return subtitles ",if subtitle_url :,if subtitle_url:,False,50.898228366662515,100.00000000000004
1035,"def get_keys ( struct , ignore_first_level = False ) : <TAB>  res = [ ] <TAB>  if isinstance ( struct , dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB><TAB><TAB>  res . extend ( keys ) <TAB><TAB>  for key in struct : <TAB><TAB><TAB>  if key in IGNORED_KEYS : <TAB><TAB><TAB><TAB>  logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB>  elif isinstance ( struct , list ) : <TAB><TAB>  for item in struct : <TAB><TAB><TAB>  res . extend ( get_keys ( item ) ) <TAB>  return res ",if not ignore_first_level :,if ignore_first_level:,False,30.28526506041167,98.97597924725297
1036,"def create_dir ( path ) : <TAB>  curr_path = None <TAB>  for p in path : <TAB><TAB>  if curr_path is None : <TAB><TAB><TAB>  curr_path = os . path . abspath ( p ) <TAB><TAB>  else : <TAB><TAB><TAB>  curr_path = os . path . join ( curr_path , p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . mkdir ( curr_path ) ",if not os . path . exists ( curr_path ) :,if not os.path.exists(curr_path):,False,51.430452302552595,100.00000000000004
1037,"def dataToDumpFile ( dumpFile , data ) : <TAB>  try : <TAB><TAB>  dumpFile . write ( data ) <TAB><TAB>  dumpFile . flush ( ) <TAB>  except IOError as ex : <TAB><TAB>  if "" No space left "" in getUnicode ( ex ) : <TAB><TAB><TAB>  errMsg = "" no space left on output device "" <TAB><TAB><TAB>  logger . error ( errMsg ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  errMsg = "" permission denied when flushing dump data "" <TAB><TAB><TAB>  logger . error ( errMsg ) <TAB><TAB>  else : <TAB><TAB><TAB>  errMsg = ( <TAB><TAB><TAB><TAB>  "" error occurred when writing dump data to file ( ' %s ' ) "" % getUnicode ( ex ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  logger . error ( errMsg ) ","elif ""Permission denied"" in getUnicode ( ex ) :",if ex.errno == errno.EACCES:,False,41.28316780116994,93.80670098415536
1038,"def elements ( self , top ) : <TAB>  res = [ ] <TAB>  # try: <TAB>  #<TAB> string = ""== %s (%s)"" % (self.name,self.__class__) <TAB>  # except AttributeError: <TAB>  #<TAB> string = ""== (%s)"" % (self.__class__,) <TAB>  # print(string) <TAB>  for part in self . parts : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  res . append ( name_or_ref ( part , top ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  if isinstance ( part , Extension ) : <TAB><TAB><TAB><TAB>  res . append ( part . base ) <TAB><TAB><TAB>  res . extend ( part . elements ( top ) ) <TAB>  return res ","if isinstance ( part , Element ) :","if isinstance(part, Name):",False,60.17179005811406,98.82484493883118
1039,"def _parse_param_value ( name , datatype , default ) : <TAB>  if datatype == "" bool "" : <TAB><TAB>  if default . lower ( ) == "" true "" : <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB><TAB><TAB>  raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB>  elif datatype == "" int "" : <TAB><TAB>  if type ( default ) == int : <TAB><TAB><TAB>  return default <TAB><TAB>  else : <TAB><TAB><TAB>  return int ( default , 0 ) <TAB>  elif datatype == "" real "" : <TAB><TAB>  if type ( default ) == float : <TAB><TAB><TAB>  return default <TAB><TAB>  else : <TAB><TAB><TAB>  return float ( default ) <TAB>  else : <TAB><TAB>  return str ( default ) ","elif default . lower ( ) == ""false"" :",if default == 'false':,False,42.736744696143546,95.89687968045583
1040,"def dvmethod ( c , dx , doAST = False ) : <TAB>  for m in c . get_methods ( ) : <TAB><TAB>  mx = dx . get_method ( m ) <TAB><TAB>  ms = DvMethod ( mx ) <TAB><TAB>  ms . process ( doAST = doAST ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert ms . get_ast ( ) is not None <TAB><TAB><TAB>  assert isinstance ( ms . get_ast ( ) , dict ) <TAB><TAB><TAB>  assert "" body "" in ms . get_ast ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  assert ms . get_source ( ) is not None ",if doAST :,if doAST:,False,52.14825325961658,100.00000000000004
1041,"def _repr_pretty_ ( self , p , cycle ) : <TAB>  if cycle : <TAB><TAB>  return "" {{ ...} "" <TAB>  with p . group ( 2 , "" { "" , "" } "" ) : <TAB><TAB>  p . breakable ( "" "" ) <TAB><TAB>  for idx , key in enumerate ( self . _items ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  p . text ( "" , "" ) <TAB><TAB><TAB><TAB>  p . breakable ( ) <TAB><TAB><TAB>  value = self . _items [ key ] <TAB><TAB><TAB>  p . pretty ( key ) <TAB><TAB><TAB>  p . text ( "" :  "" ) <TAB><TAB><TAB>  if isinstance ( value , bytes ) : <TAB><TAB><TAB><TAB>  value = trimmed_repr ( value ) <TAB><TAB><TAB>  p . pretty ( value ) <TAB><TAB>  p . breakable ( "" "" ) ",if idx :,if idx == len(self._items):,False,49.820147507215694,95.91930339149536
1042,"def remove_rating ( self , songs , librarian ) : <TAB>  count = len ( songs ) <TAB>  if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB><TAB>  parent = qltk . get_menu_item_top_parent ( self ) <TAB><TAB>  dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB>  reset = [ ] <TAB>  for song in songs : <TAB><TAB>  if "" ~#rating "" in song : <TAB><TAB><TAB>  del song [ "" ~#rating "" ] <TAB><TAB><TAB>  reset . append ( song ) <TAB>  librarian . changed ( reset ) ",if dialog . run ( ) != Gtk . ResponseType . YES :,if dialog is None:,False,23.247639460283914,93.46366006789911
1043,"def get_or_create_place ( self , place_name ) : <TAB>  "" Return the requested place object tuple-packed with a new indicator. "" <TAB>  LOG . debug ( "" get_or_create_place: looking for:  %s "" , place_name ) <TAB>  for place_handle in self . db . iter_place_handles ( ) : <TAB><TAB>  place = self . db . get_place_from_handle ( place_handle ) <TAB><TAB>  place_title = place_displayer . display ( self . db , place ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ( 0 , place ) <TAB>  place = Place ( ) <TAB>  place . set_title ( place_name ) <TAB>  place . name = PlaceName ( value = place_name ) <TAB>  self . db . add_place ( place , self . trans ) <TAB>  return ( 1 , place ) ",if place_title == place_name :,if place_title == place_name:,False,58.35669339785537,100.00000000000004
1044,def _skip_trivial ( constraint_data ) : <TAB>  if skip_trivial_constraints : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if constraint_data . variables is None : <TAB><TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  if constraint_data . body . polynomial_degree ( ) == 0 : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ,"if isinstance ( constraint_data , LinearCanonicalRepn ) :",if constraint_data.body is None:,False,22.75000415838689,93.27388884733817
1045,"def get_other ( self , data , items ) : <TAB>  is_tuple = False <TAB>  if type ( data ) == tuple : <TAB><TAB>  data = list ( data ) <TAB><TAB>  is_tuple = True <TAB>  if type ( data ) == list : <TAB><TAB>  m_items = items . copy ( ) <TAB><TAB>  for idx , item in enumerate ( items ) : <TAB><TAB><TAB>  if item < 0 : <TAB><TAB><TAB><TAB>  m_items [ idx ] = len ( data ) - abs ( item ) <TAB><TAB>  for i in sorted ( set ( m_items ) , reverse = True ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del data [ i ] <TAB><TAB>  if is_tuple : <TAB><TAB><TAB>  return tuple ( data ) <TAB><TAB>  else : <TAB><TAB><TAB>  return data <TAB>  else : <TAB><TAB>  return None ",if i < len ( data ) and i > - 1 :,if data[i] == item:,False,21.819009052892827,95.70552069545718
1046,"def test_case_insensitivity ( self ) : <TAB>  with support . EnvironmentVarGuard ( ) as env : <TAB><TAB>  env . set ( "" PYTHONCASEOK "" , "" 1 "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB><TAB>  loader = self . find_module ( ) <TAB><TAB>  self . assertTrue ( hasattr ( loader , "" load_module "" ) ) ","if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :","if os.getenv('PYTHONCASEOK', '1'):",False,54.226642274877634,88.89689362308448
1047,def field_spec ( self ) : <TAB>  <IF-STMT>: <TAB><TAB>  self . lazy_init_lock_ . acquire ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . field_spec_ = FieldSpec ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . lazy_init_lock_ . release ( ) <TAB>  return self . field_spec_ ,if self . field_spec_ is None :,if not self.field_spec_:,False,34.58375258205626,87.4984606845517
1048,"def reduce ( self , f , init ) : <TAB>  for x in range ( self . _idx , rt . count ( self . _w_array ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return rt . deref ( init ) <TAB><TAB>  init = f . invoke ( [ init , rt . nth ( self . _w_array , rt . wrap ( x ) ) ] ) <TAB>  return init ",if rt . reduced_QMARK_ ( init ) :,if x == self._idx:,False,46.53650314232407,90.6693723391005
1049,"def _find ( event : E ) - > None : <TAB>  # We first check values after the selected value, then all values. <TAB>  values = list ( self . values ) <TAB>  for value in values [ self . _selected_index + 1 : ] + values : <TAB><TAB>  text = fragment_list_to_text ( to_formatted_text ( value [ 1 ] ) ) . lower ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _selected_index = self . values . index ( value ) <TAB><TAB><TAB>  return ",if text . startswith ( event . data . lower ( ) ) :,if text in self.values:,False,26.456963405589995,91.50299637490413
1050,"def check_permissions ( ) : <TAB>  if platform_os ( ) != "" Windows "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( localization . lang_check_permissions [ "" permissions_granted "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( localization . lang_check_permissions [ "" permissions_denied "" ] ) <TAB><TAB><TAB>  exit ( ) <TAB>  else : <TAB><TAB>  print ( localization . lang_check_permissions [ "" windows_warning "" ] ) <TAB><TAB>  exit ( ) ",if getuid ( ) == 0 :,if platform_os.system() == 'Linux':,False,23.7912314273533,93.87345797654456
1051,"def _ProcessName ( self , name , dependencies ) : <TAB>  """"""Retrieve a module name from a node name."""""" <TAB>  module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB>  if dot : <TAB><TAB>  if module_name : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  dependencies [ module_name ] . add ( base_name ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  dependencies [ module_name ] = { base_name } <TAB><TAB>  else : <TAB><TAB><TAB>  # If we have a relative import that did not get qualified (usually due <TAB><TAB><TAB>  # to an empty package_name), don't insert module_name='' into the <TAB><TAB><TAB>  # dependencies; we get a better error message if we filter it out here <TAB><TAB><TAB>  # and fail later on. <TAB><TAB><TAB>  logging . warning ( "" Empty package name:  %s "" , name ) ",if module_name in dependencies :,if module_name in dependencies:,False,70.89858199734772,100.00000000000004
1052,"def _load_db ( self ) : <TAB>  try : <TAB><TAB>  with open ( self . db ) as db : <TAB><TAB><TAB>  content = db . read ( 8 ) <TAB><TAB><TAB>  db . seek ( 0 ) <TAB><TAB><TAB>  if content == ( "" Salted__ "" ) : <TAB><TAB><TAB><TAB>  data = StringIO ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . encryptor . decrypt ( db , data ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  raise EncryptionError ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  return json . loads ( data . getvalue ( ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return json . load ( db ) <TAB>  except : <TAB><TAB>  return { "" creds "" : [ ] } ",if self . encryptor :,if content == 'CWS':,False,23.91182587904523,98.13653288694141
1053,"def _parse ( self , stream , context ) : <TAB>  obj = [ ] <TAB>  try : <TAB><TAB>  context_for_subcon = context <TAB><TAB>  if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB><TAB><TAB>  context_for_subcon = context . __copy__ ( ) <TAB><TAB>  while True : <TAB><TAB><TAB>  subobj = self . subcon . _parse ( stream , context_for_subcon ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  obj . append ( subobj ) <TAB>  except ConstructError as ex : <TAB><TAB>  raise ArrayError ( "" missing terminator "" , ex ) <TAB>  return obj ","if self . predicate ( subobj , context ) :",if subobj is None:,False,21.596351648452575,95.12304157832546
1054,"def is_active_for_user ( self , user ) : <TAB>  is_active = super ( AbstractUserFlag , self ) . is_active_for_user ( user ) <TAB>  if is_active : <TAB><TAB>  return is_active <TAB>  user_ids = self . _get_user_ids ( ) <TAB>  if hasattr ( user , "" pk "" ) and user . pk in user_ids : <TAB><TAB>  return True <TAB>  if hasattr ( user , "" groups "" ) : <TAB><TAB>  group_ids = self . _get_group_ids ( ) <TAB><TAB>  if group_ids : <TAB><TAB><TAB>  user_groups = set ( user . groups . all ( ) . values_list ( "" pk "" , flat = True ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return None ",if group_ids . intersection ( user_groups ) :,if user_groups.count(user_groups) == 1:,False,36.58942079024062,95.28594075952081
1055,"def lookup_member ( self , member_name ) : <TAB>  document_choices = self . choices or [ ] <TAB>  for document_choice in document_choices : <TAB><TAB>  doc_and_subclasses = [ document_choice ] + document_choice . __subclasses__ ( ) <TAB><TAB>  for doc_type in doc_and_subclasses : <TAB><TAB><TAB>  field = doc_type . _fields . get ( member_name ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return field ",if field :,if field:,False,51.25858271442456,100.00000000000004
1056,"def apply ( self , db , person ) : <TAB>  families = person . get_parent_family_handle_list ( ) <TAB>  if families == [ ] : <TAB><TAB>  return True <TAB>  for family_handle in person . get_parent_family_handle_list ( ) : <TAB><TAB>  family = db . get_family_from_handle ( family_handle ) <TAB><TAB>  if family : <TAB><TAB><TAB>  father_handle = family . get_father_handle ( ) <TAB><TAB><TAB>  mother_handle = family . get_mother_handle ( ) <TAB><TAB><TAB>  if not father_handle : <TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if not mother_handle :,if mother_handle:,False,33.542667828481385,98.77530731861061
1057,"def init_weights ( self ) : <TAB>  for m in self . modules ( ) : <TAB><TAB>  if isinstance ( m , nn . Linear ) : <TAB><TAB><TAB>  normal_init ( m , std = 0.01 ) <TAB><TAB>  if isinstance ( m , nn . Conv3d ) : <TAB><TAB><TAB>  xavier_init ( m , distribution = "" uniform "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  constant_init ( m , 1 ) ","if isinstance ( m , nn . BatchNorm3d ) :","if isinstance(m, nn.Constant):",False,26.22125969560798,97.96299003437207
1058,"def _update_learning_params ( self ) : <TAB>  model = self . model <TAB>  hparams = self . hparams <TAB>  fd = self . runner . feed_dict <TAB>  step_num = self . step_num <TAB>  if hparams . model_type == "" resnet_tf "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn <TAB><TAB>  elif step_num < 30000 : <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn / 10 <TAB><TAB>  elif step_num < 35000 : <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn / 100 <TAB><TAB>  else : <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn / 1000 <TAB><TAB>  fd [ model . lrn_rate ] = lrn_rate ",if step_num < hparams . lrn_step :,if step_num < 1000:,False,26.183600400906258,96.9469366829967
1059,"def token_producer ( source ) : <TAB>  token = source . read_uint8 ( ) <TAB>  while token is not None : <TAB><TAB>  if is_push_data_token ( token ) : <TAB><TAB><TAB>  yield DataToken ( read_data ( token , source ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield Token ( token ) <TAB><TAB>  token = source . read_uint8 ( ) ",elif is_small_integer ( token ) :,if token.flags & 8:,False,51.20306010738774,92.68955104015303
1060,"def user_info ( oicsrv , userdb , sub , client_id = "" "" , user_info_claims = None ) : <TAB>  identity = userdb [ sub ] <TAB>  if user_info_claims : <TAB><TAB>  result = { } <TAB><TAB>  for key , restr in user_info_claims [ "" claims "" ] . items ( ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  result [ key ] = identity [ key ] <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise Exception ( "" Missing property  ' %s ' "" % key ) <TAB>  else : <TAB><TAB>  result = identity <TAB>  return OpenIDSchema ( * * result ) ","if restr == { ""essential"" : True } :",if key not in identity:,False,46.289943562943016,92.9921354652094
1061,"def _helpSlot ( self , * args ) : <TAB>  help_text = "" Filters are applied to packets in both direction. \n \n "" <TAB>  filter_nb = 0 <TAB>  for filter in self . _filters : <TAB><TAB>  help_text + = "" {} :  {} "" . format ( filter [ "" name "" ] , filter [ "" description "" ] ) <TAB><TAB>  filter_nb + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  help_text + = "" \n \n "" <TAB>  QtWidgets . QMessageBox . information ( self , "" Help for filters "" , help_text ) ",if len ( self . _filters ) != filter_nb :,if filter_nb > 0:,False,21.951695386942156,92.3044481532693
1062,"def find_user_theme ( self , name : str ) - > Theme : <TAB>  """"""Find a theme named as *name* from latex_theme_path."""""" <TAB>  for theme_path in self . theme_paths : <TAB><TAB>  config_path = path . join ( theme_path , name , "" theme.conf "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return UserTheme ( name , config_path ) <TAB><TAB><TAB>  except ThemeError as exc : <TAB><TAB><TAB><TAB>  logger . warning ( exc ) <TAB>  return None ",if path . isfile ( config_path ) :,if os.path.exists(config_path):,False,29.12396504910851,96.53159621239394
1063,"def decompress ( self , value ) : <TAB>  if value : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if value . country_code and value . national_number : <TAB><TAB><TAB><TAB>  return [ <TAB><TAB><TAB><TAB><TAB>  "" + %d "" % value . country_code , <TAB><TAB><TAB><TAB><TAB>  national_significant_number ( value ) , <TAB><TAB><TAB><TAB>  ] <TAB><TAB>  else : <TAB><TAB><TAB>  return value . split ( "" . "" ) <TAB>  return [ None , "" "" ] ",if type ( value ) == PhoneNumber :,if value:,False,23.47674667262649,94.91031643143974
1064,"def update_prevdoc_status ( self , flag ) : <TAB>  for quotation in list ( set ( [ d . prevdoc_docname for d in self . get ( "" items "" ) ] ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  doc = frappe . get_doc ( "" Quotation "" , quotation ) <TAB><TAB><TAB>  if doc . docstatus == 2 : <TAB><TAB><TAB><TAB>  frappe . throw ( _ ( "" Quotation  {0}  is cancelled "" ) . format ( quotation ) ) <TAB><TAB><TAB>  doc . set_status ( update = True ) <TAB><TAB><TAB>  doc . update_opportunity ( ) ",if quotation :,if flag:,False,27.501104405604792,98.41504940787179
1065,"def map ( item ) : <TAB>  if item . deleted : <TAB><TAB>  return <TAB>  exploration = exp_fetchers . get_exploration_from_model ( item ) <TAB>  for state_name , state in exploration . states . items ( ) : <TAB><TAB>  hints_length = len ( state . interaction . hints ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exp_and_state_key = "" %s %s "" % ( item . id , state_name . encode ( "" utf-8 "" ) ) <TAB><TAB><TAB>  yield ( python_utils . UNICODE ( hints_length ) , exp_and_state_key ) ",if hints_length > 0 :,if hints_length > 0:,False,51.05350671070183,100.00000000000004
1066,"def _selected_machines ( self , virtual_machines ) : <TAB>  selected_machines = [ ] <TAB>  for machine in virtual_machines : <TAB><TAB>  if self . _args . host and self . _args . host == machine . name : <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB><TAB>  if self . locations and machine . location in self . locations : <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB>  return selected_machines ","if self . tags and self . _tags_match ( machine . tags , self . tags ) :",if self.locations and machine.location in self.locations:,False,52.48405511318286,89.45494839681207
1067,"def _ripple_trim_compositors_move ( self , delta ) : <TAB>  comp_ids = self . multi_data . moved_compositors_destroy_ids <TAB>  tracks_compositors = _get_tracks_compositors_list ( ) <TAB>  track_moved = self . multi_data . track_affected <TAB>  for i in range ( 1 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB><TAB>  if not track_moved [ i - 1 ] : <TAB><TAB><TAB>  continue <TAB><TAB>  track_comps = tracks_compositors [ i - 1 ] <TAB><TAB>  for comp in track_comps : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  comp . move ( delta ) ",if comp . destroy_id in comp_ids :,if comp.id == self.id:,False,21.239445662975413,95.57085637478816
1068,"def stream_docker_log ( log_stream ) : <TAB>  async for line in log_stream : <TAB><TAB>  if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB><TAB><TAB>  logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB><TAB>  elif "" error "" in line : <TAB><TAB><TAB>  logger . error ( line [ "" error "" ] . strip ( ) ) <TAB><TAB><TAB>  raise DockerBuildError ","elif ""status"" in line :","if ""status"" in line:",False,53.483414177126456,98.37380598312615
1069,"def create_keyfile ( self , keyfile , size = 64 , force = False ) : <TAB>  if force or not os . path . exists ( keyfile ) : <TAB><TAB>  keypath = os . path . dirname ( keyfile ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( keypath ) <TAB><TAB>  subprocess . run ( <TAB><TAB><TAB>  [ "" dd "" , "" if=/dev/random "" , f "" of= { keyfile } "" , f "" bs= { size } "" , "" count=1 "" ] , <TAB><TAB><TAB>  check = True , <TAB><TAB><TAB>  stdout = subprocess . DEVNULL , <TAB><TAB><TAB>  stderr = subprocess . DEVNULL , <TAB><TAB>  ) ",if not os . path . exists ( keypath ) :,if not os.path.exists(keypath):,False,49.05303374329383,100.00000000000004
1070,"def calc ( self , arg ) : <TAB>  op = arg [ "" op "" ] <TAB>  if op == "" C "" : <TAB><TAB>  self . clear ( ) <TAB><TAB>  return str ( self . current ) <TAB>  num = decimal . Decimal ( arg [ "" num "" ] ) <TAB>  if self . op : <TAB><TAB>  if self . op == "" + "" : <TAB><TAB><TAB>  self . current + = num <TAB><TAB>  elif self . op == "" - "" : <TAB><TAB><TAB>  self . current - = num <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . current * = num <TAB><TAB>  elif self . op == "" / "" : <TAB><TAB><TAB>  self . current / = num <TAB><TAB>  self . op = op <TAB>  else : <TAB><TAB>  self . op = op <TAB><TAB>  self . current = num <TAB>  res = str ( self . current ) <TAB>  if op == "" = "" : <TAB><TAB>  self . clear ( ) <TAB>  return res ","elif self . op == ""*"" :","if self.op == ""+"":",False,30.793000847207775,98.18499072600078
1071,"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB>  if isinstance ( expr , Real ) : <TAB><TAB>  if - delta < expr . get_float_value ( ) < delta : <TAB><TAB><TAB>  return Integer ( 0 ) <TAB>  elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB><TAB>  real , imag = expr . real , expr . imag <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  real = Integer ( 0 ) <TAB><TAB>  if - delta < imag . get_float_value ( ) < delta : <TAB><TAB><TAB>  imag = Integer ( 0 ) <TAB><TAB>  return Complex ( real , imag ) <TAB>  elif isinstance ( expr , Expression ) : <TAB><TAB>  return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB>  return expr ",if - delta < real . get_float_value ( ) < delta :,if real is None:,False,26.326251183071246,90.44105172574875
1072,"def get_file_sources ( ) : <TAB>  global _file_sources <TAB>  if _file_sources is None : <TAB><TAB>  from galaxy . files import ConfiguredFileSources <TAB><TAB>  file_sources = None <TAB><TAB>  if os . path . exists ( "" file_sources.json "" ) : <TAB><TAB><TAB>  file_sources_as_dict = None <TAB><TAB><TAB>  with open ( "" file_sources.json "" , "" r "" ) as f : <TAB><TAB><TAB><TAB>  file_sources_as_dict = json . load ( f ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB><TAB>  if file_sources is None : <TAB><TAB><TAB>  ConfiguredFileSources . from_dict ( [ ] ) <TAB><TAB>  _file_sources = file_sources <TAB>  return _file_sources ",if file_sources_as_dict is not None :,if file_sources_as_dict is not None:,False,51.831369750510014,100.00000000000004
1073,"def _get_sort_map ( tags ) : <TAB>  """"""See TAG_TO_SORT"""""" <TAB>  tts = { } <TAB>  for name , tag in tags . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if tag . user : <TAB><TAB><TAB><TAB>  tts [ name ] = "" %s sort "" % name <TAB><TAB><TAB>  if tag . internal : <TAB><TAB><TAB><TAB>  tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB>  return tts ",if tag . has_sort :,if name not in sort_map:,False,49.660599733283306,90.44351467053897
1074,"def __init__ ( self , * * kwargs ) : <TAB>  if self . name is None : <TAB><TAB>  raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB>  self . option_values = { } <TAB>  for key , val in kwargs . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . option_values [ key ] = val <TAB>  # set up defaults <TAB>  for name , ( description , default ) in self . options . items ( ) : <TAB><TAB>  if not name in self . option_values : <TAB><TAB><TAB>  self . option_values [ name ] = default ",if not key in self . options :,if key not in self.option_values:,False,31.468377665530745,96.53500585414776
1075,"def modify_bottle_params ( self , output_stride = None ) : <TAB>  if output_stride is not None and output_stride % 2 != 0 : <TAB><TAB>  raise Exception ( "" output stride must to be even number "" ) <TAB>  if output_stride is None : <TAB><TAB>  return <TAB>  else : <TAB><TAB>  stride = 2 <TAB><TAB>  for i , _cfg in enumerate ( self . cfg ) : <TAB><TAB><TAB>  stride = stride * _cfg [ - 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  s = 1 <TAB><TAB><TAB><TAB>  self . cfg [ i ] [ - 1 ] = s ",if stride > output_stride :,if output_stride == 0:,False,37.373180720348344,92.66597889722227
1076,"def do_query ( data , q ) : <TAB>  ret = [ ] <TAB>  if not q : <TAB><TAB>  return ret <TAB>  qkey = q [ 0 ] <TAB>  for key , value in iterate ( data ) : <TAB><TAB>  if len ( q ) == 1 : <TAB><TAB><TAB>  if key == qkey : <TAB><TAB><TAB><TAB>  ret . append ( value ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  if not is_iterable ( value ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if key == qkey : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB>  return ret ",elif is_iterable ( value ) :,"if isinstance(value, tuple):",False,49.89524765999822,97.46139759816691
1077,"def make_shares ( self , plaintext ) : <TAB>  share_arrays = [ ] <TAB>  for i , p in enumerate ( plaintext ) : <TAB><TAB>  share_array = self . make_byte_shares ( p ) <TAB><TAB>  for sa in share_array : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  share_arrays . append ( array . array ( "" H "" ) ) <TAB><TAB><TAB>  current_share_array = sa <TAB><TAB><TAB>  current_share_array . append ( sa ) <TAB>  return share_arrays ",if i == 0 :,if sa.type == 'SHARE':,False,47.82905978864884,95.46614536094086
1078,"def populate ( self , item ) : <TAB>  # log.message('populate: %s', item) <TAB>  path = self . getItemPath ( item ) <TAB>  # log.message('populate: path=%s', path) <TAB>  value = self . getValue ( path ) <TAB>  for name in sorted ( value . __dict__ . keys ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  child = getattr ( value , name , None ) <TAB><TAB>  if hasattr ( child , "" __dict__ "" ) : <TAB><TAB><TAB>  item . addChild ( name , True ) <TAB><TAB>  else : <TAB><TAB><TAB>  item . addChild ( name , False ) ","if name [ : 2 ] == ""__"" and name [ - 2 : ] == ""__"" :",if name == 'value':,False,25.869450358141314,88.26479369040845
1079,"def __repr__ ( self ) : <TAB>  try : <TAB><TAB>  if self . _semlock . _is_mine ( ) : <TAB><TAB><TAB>  name = current_process ( ) . name <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  name + = "" | "" + threading . current_thread ( ) . name <TAB><TAB>  elif self . _semlock . _get_value ( ) == 1 : <TAB><TAB><TAB>  name = "" None "" <TAB><TAB>  elif self . _semlock . _count ( ) > 0 : <TAB><TAB><TAB>  name = "" SomeOtherThread "" <TAB><TAB>  else : <TAB><TAB><TAB>  name = "" SomeOtherProcess "" <TAB>  except Exception : <TAB><TAB>  name = "" unknown "" <TAB>  return "" <Lock(owner= %s )> "" % name ","if threading . current_thread ( ) . name != ""MainThread"" :",if threading is not None:,False,25.98122625046505,93.5844406807637
1080,"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB>  "" Add data to be displayed in the buffer. "" <TAB>  self . values . extend ( lines ) <TAB>  if scroll_end : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB><TAB>  elif scroll_if_editing : <TAB><TAB><TAB>  self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) ",if not self . editing :,if scroll_if_editing:,False,45.24992263343497,96.2104970118713
1081,"def warehouses ( self ) - > tuple : <TAB>  from . . repositories import WarehouseBaseRepo <TAB>  repos = dict ( ) <TAB>  for dep in chain ( self . dependencies , [ self ] ) : <TAB><TAB>  if dep . repo is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for repo in dep . repo . repos : <TAB><TAB><TAB>  if repo . from_config : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  repos [ repo . name ] = repo <TAB>  return tuple ( repos . values ( ) ) ","if not isinstance ( dep . repo , WarehouseBaseRepo ) :",if dep.repo.name == 'WarehouseBaseRepo':,False,48.12203625822226,94.51258360152138
1082,"def _apply_flag_attrs ( src_flag , dest_flag ) : <TAB>  # Use a baseline flag def to get default values for empty data. <TAB>  baseline_flag = FlagDef ( "" "" , { } , None ) <TAB>  for name in dir ( src_flag ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  dest_val = getattr ( dest_flag , name , None ) <TAB><TAB>  baseline_val = getattr ( baseline_flag , name , None ) <TAB><TAB>  if dest_val == baseline_val : <TAB><TAB><TAB>  setattr ( dest_flag , name , getattr ( src_flag , name ) ) ","if name [ : 1 ] == ""_"" :",if name.startswith('_'):,False,36.23295848105025,94.05127589414703
1083,"def out ( parent , attr , indent = 0 ) : <TAB>  val = getattr ( parent , attr ) <TAB>  prefix = "" %s %s : "" % ( "" "" * indent , attr . replace ( "" _ "" , "" - "" ) ) <TAB>  if val is None : <TAB><TAB>  cli . out ( prefix ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = [ flag_util . encode_flag_val ( c . value ) for c in val ] <TAB><TAB>  cli . out ( "" %s %s "" % ( prefix , flag_util . encode_flag_val ( val ) ) ) ","if attr == ""choices"" :","if isinstance(val, (list, tuple)):",False,48.920709050903014,92.87116124154649
1084,"def add_cand_to_check ( cands ) : <TAB>  for cand in cands : <TAB><TAB>  x = cand . creator <TAB><TAB>  if x is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # `len(fan_out)` is in order to avoid comparing `x` <TAB><TAB><TAB>  heapq . heappush ( cand_funcs , ( - x . rank , len ( fan_out ) , x ) ) <TAB><TAB>  fan_out [ x ] + = 1 ",if x not in fan_out :,if x.rank < 0:,False,56.327321713245674,93.47347679401403
1085,"def task_tree_lines ( task = None ) : <TAB>  if task is None : <TAB><TAB>  task = current_root_task ( ) <TAB>  rendered_children = [ ] <TAB>  nurseries = list ( task . child_nurseries ) <TAB>  while nurseries : <TAB><TAB>  nursery = nurseries . pop ( ) <TAB><TAB>  nursery_children = _rendered_nursery_children ( nursery ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  nested = _render_subtree ( "" (nested nursery) "" , rendered_children ) <TAB><TAB><TAB>  nursery_children . append ( nested ) <TAB><TAB>  rendered_children = nursery_children <TAB>  return _render_subtree ( task . name , rendered_children ) ",if rendered_children :,if nursery_children:,False,39.63767034797287,98.59341533613703
1086,"def lock_workspace ( build_dir ) : <TAB>  _BUILDING_LOCK_FILE = "" .blade.building.lock "" <TAB>  lock_file_fd , ret_code = lock_file ( os . path . join ( build_dir , _BUILDING_LOCK_FILE ) ) <TAB>  if lock_file_fd == - 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  console . fatal ( "" There is already an active building in current workspace. "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  console . fatal ( "" Lock exception, please try it later. "" ) <TAB>  return lock_file_fd ",if ret_code == errno . EAGAIN :,if lock_file_fd == -1:,False,59.51891157224246,93.98442043289896
1087,"def test_list ( self ) : <TAB>  self . _create_locations ( ) <TAB>  response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB>  self . assertEqual ( response . status_code , 200 ) <TAB>  self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB>  for feature in response . data [ "" features "" ] : <TAB><TAB>  self . assertIn ( "" bbox "" , feature ) <TAB><TAB>  fid = feature [ "" id "" ] <TAB><TAB>  if fid == 1 : <TAB><TAB><TAB>  self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB>  BoxedLocation . objects . all ( ) . delete ( ) ",elif fid == 2 :,if fid == 2:,False,26.078658925175542,99.0069109851336
1088,"def result ( ) : <TAB>  # ""global"" does not work here... <TAB>  R , V = rays , virtual_rays <TAB>  if V is not None : <TAB><TAB>  if normalize : <TAB><TAB><TAB>  V = normalize_rays ( V , lattice ) <TAB><TAB>  if check : <TAB><TAB><TAB>  R = PointCollection ( V , lattice ) <TAB><TAB><TAB>  V = PointCollection ( V , lattice ) <TAB><TAB><TAB>  d = lattice . dimension ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB><TAB>  "" virtual rays must be linearly  "" <TAB><TAB><TAB><TAB><TAB>  "" independent and with other rays span the ambient space. "" <TAB><TAB><TAB><TAB>  ) <TAB>  return RationalPolyhedralFan ( cones , R , lattice , is_complete , V ) ",if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,if d < 4:,False,33.565724646827086,89.06541044190084
1089,"def search_host ( self , search_string ) : <TAB>  results = [ ] <TAB>  for host_entry in self . config_data : <TAB><TAB>  if host_entry . get ( "" type "" ) != "" entry "" : <TAB><TAB><TAB>  continue <TAB><TAB>  if host_entry . get ( "" host "" ) == "" * "" : <TAB><TAB><TAB>  continue <TAB><TAB>  searchable_information = host_entry . get ( "" host "" ) <TAB><TAB>  for key , value in six . iteritems ( host_entry . get ( "" options "" ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = "" "" . join ( value ) <TAB><TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB><TAB>  value = str ( value ) <TAB><TAB><TAB>  searchable_information + = "" "" + value <TAB><TAB>  if search_string in searchable_information : <TAB><TAB><TAB>  results . append ( host_entry ) <TAB>  return results ","if isinstance ( value , list ) :",if key == 'host':,False,41.05004094032695,97.24639500144968
1090,"def test_async_iterator ( app ) : <TAB>  async with new_stream ( app ) as stream : <TAB><TAB>  for i in range ( 100 ) : <TAB><TAB><TAB>  await stream . channel . deliver ( message ( key = i , value = i ) ) <TAB><TAB>  received = 0 <TAB><TAB>  async for value in stream : <TAB><TAB><TAB>  assert value == received <TAB><TAB><TAB>  received + = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  assert await channel_empty ( stream . channel ) ",if received >= 100 :,if received == 100:,False,39.08080176948783,98.38431679164988
1091,"def has_google_credentials ( ) : <TAB>  global _HAS_GOOGLE_CREDENTIALS <TAB>  if _HAS_GOOGLE_CREDENTIALS is None : <TAB><TAB>  provider = Provider ( "" google "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _HAS_GOOGLE_CREDENTIALS = False <TAB><TAB>  else : <TAB><TAB><TAB>  _HAS_GOOGLE_CREDENTIALS = True <TAB>  return _HAS_GOOGLE_CREDENTIALS ",if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,if provider.is_google():,False,21.821656958443853,82.66330620310562
1092,"def __cmp__ ( self , other ) : <TAB>  if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB><TAB>  a = self . _d . getTime ( ) <TAB><TAB>  b = other . _d . getTime ( ) <TAB><TAB>  if a < b : <TAB><TAB><TAB>  return - 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return 0 <TAB>  else : <TAB><TAB>  raise TypeError ( "" expected date or datetime object "" ) <TAB>  return 1 ",elif a == b :,if a == b:,False,27.106718220918363,95.4759063384644
1093,"def validate_weight ( self , weight ) : <TAB>  try : <TAB><TAB>  add_acl_to_obj ( self . context [ "" user_acl "" ] , self . category ) <TAB>  except AttributeError : <TAB><TAB>  return weight<TAB># don't validate weight further if category failed <TAB>  if weight > self . category . acl . get ( "" can_pin_threads "" , 0 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB>  _ ( <TAB><TAB><TAB><TAB><TAB>  "" You don ' t have permission to pin threads globally  "" <TAB><TAB><TAB><TAB><TAB>  "" in this category. "" <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB>  _ ( "" You don ' t have permission to pin threads in this category. "" ) <TAB><TAB><TAB>  ) <TAB>  return weight ",if weight == 2 :,if weight < 0:,False,58.15111597417572,93.57412707822746
1094,"def effective ( line ) : <TAB>  for b in line : <TAB><TAB>  if not b . cond : <TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  val = 5 <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if b . ignore : <TAB><TAB><TAB><TAB><TAB><TAB>  b . ignore - = 1 <TAB><TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB><TAB>  return ( b , True ) <TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB>  return ( b , False ) <TAB>  return ",if val :,if val < 5:,False,21.167995073606225,98.275438549687
1095,"def wheelEvent ( self , event ) : <TAB>  """"""Handle a wheel event."""""" <TAB>  if QtCore . Qt . ControlModifier & event . modifiers ( ) : <TAB><TAB>  d = { "" c "" : self . leo_c } <TAB><TAB>  if isQt5 : <TAB><TAB><TAB>  point = event . angleDelta ( ) <TAB><TAB><TAB>  delta = point . y ( ) or point . x ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  delta = event . delta ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  zoom_out ( d ) <TAB><TAB>  else : <TAB><TAB><TAB>  zoom_in ( d ) <TAB><TAB>  event . accept ( ) <TAB><TAB>  return <TAB>  QtWidgets . QTextBrowser . wheelEvent ( self , event ) ",if delta < 0 :,if delta < 0:,False,50.9336951496871,100.00000000000004
1096,"def test_evname_in_mp_events_testcases ( ) : <TAB>  ok = True <TAB>  for evname in ins . mp_events : <TAB><TAB>  if evname == "" version "" : <TAB><TAB><TAB>  continue <TAB><TAB>  for i , args in enumerate ( ins . mp_events [ evname ] [ "" test_cases "" ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  msg = "" Error, for evname  %s  the testase # %d  does not match evname "" <TAB><TAB><TAB><TAB>  print ( msg % ( evname , i ) ) <TAB><TAB><TAB><TAB>  ok = False <TAB>  if ok : <TAB><TAB>  print ( "" test_evname_in_mp_events_testcases: passed "" ) ",if evname != args [ 0 ] :,if args.test_name != evname:,False,54.44409475355978,95.90946117785536
1097,"def check_database ( ) : <TAB>  if len ( EmailAddress . objects . all ( ) ) > 0 : <TAB><TAB>  print ( <TAB><TAB><TAB>  "" Are you sure you want to wipe the existing development database and reseed it? (Y/N) "" <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  destroy_database ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  else : <TAB><TAB>  return True ","if raw_input ( ) . lower ( ) == ""y"" :",if not len(EmailAddress.objects.all()) > 0:,False,37.898294633122674,89.70052305186047
1098,"def _get_requested_databases ( self ) : <TAB>  """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB>  requested_databases = [ ] <TAB>  if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB><TAB>  for requested_namespace in self . _requested_namespaces : <TAB><TAB><TAB>  if requested_namespace [ 0 ] is "" * "" : <TAB><TAB><TAB><TAB>  return [ ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  requested_databases . append ( requested_namespace [ 0 ] ) <TAB>  return requested_databases ",elif requested_namespace [ 0 ] not in IGNORE_DBS :,if requested_namespace[0] in self._requested_databases:,False,57.834547677296676,94.05867228601602
1099,"def decorated ( self , * args , * * kwargs ) : <TAB>  start_time = time . perf_counter ( ) <TAB>  stderr = "" "" <TAB>  saved_exception = None <TAB>  try : <TAB><TAB>  yield from fn ( self , * args , * * kwargs ) <TAB>  except GitSavvyError as e : <TAB><TAB>  stderr = e . stderr <TAB><TAB>  saved_exception = e <TAB>  finally : <TAB><TAB>  end_time = time . perf_counter ( ) <TAB><TAB>  util . debug . log_git ( args , None , "" <SNIP> "" , stderr , end_time - start_time ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise saved_exception from None ",if saved_exception :,if saved_exception is not None:,False,32.39779422007179,97.48696792430982
1100,"def is_suppressed_warning ( <TAB>  type : str , subtype : str , suppress_warnings : List [ str ]  ) - > bool : <TAB>  """"""Check the warning is suppressed or not."""""" <TAB>  if type is None : <TAB><TAB>  return False <TAB>  for warning_type in suppress_warnings : <TAB><TAB>  if "" . "" in warning_type : <TAB><TAB><TAB>  target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  target , subtarget = warning_type , None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  subtype is None <TAB><TAB><TAB><TAB>  or subtarget is None <TAB><TAB><TAB><TAB>  or subtarget == subtype <TAB><TAB><TAB><TAB>  or subtarget == "" * "" <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if target == type :,if target == type:,False,54.49483711170806,100.00000000000004
1101,"def talk ( self , words ) : <TAB>  if self . writeSentence ( words ) == 0 : <TAB><TAB>  return <TAB>  r = [ ] <TAB>  while 1 : <TAB><TAB>  i = self . readSentence ( ) <TAB><TAB>  if len ( i ) == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  reply = i [ 0 ] <TAB><TAB>  attrs = { } <TAB><TAB>  for w in i [ 1 : ] : <TAB><TAB><TAB>  j = w . find ( "" = "" , 1 ) <TAB><TAB><TAB>  if j == - 1 : <TAB><TAB><TAB><TAB>  attrs [ w ] = "" "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB><TAB>  r . append ( ( reply , attrs ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return r ","if reply == ""!done"" :",if r:,False,22.455684232985785,95.61024807626896
1102,"def encrypt ( self , plaintext ) : <TAB>  encrypted = [ ] <TAB>  for p in _string_to_bytes ( plaintext ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _remaining_block = self . _aes . encrypt ( self . _last_precipherblock ) <TAB><TAB><TAB>  self . _last_precipherblock = [ ] <TAB><TAB>  precipherbyte = self . _remaining_block . pop ( 0 ) <TAB><TAB>  self . _last_precipherblock . append ( precipherbyte ) <TAB><TAB>  cipherbyte = p ^ precipherbyte <TAB><TAB>  encrypted . append ( cipherbyte ) <TAB>  return _bytes_to_string ( encrypted ) ",if len ( self . _remaining_block ) == 0 :,if p & self._last_precipherblock:,False,48.24642733909692,93.03788701693227
1103,"def find_symbol ( self , r , globally = False ) : <TAB>  query = self . view . substr ( self . view . word ( r ) ) <TAB>  fname = self . view . file_name ( ) . replace ( "" \\ "" , "" / "" ) <TAB>  locations = self . view . window ( ) . lookup_symbol_in_index ( query ) <TAB>  if not locations : <TAB><TAB>  return <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  location = [ hit [ 2 ] for hit in locations if fname . endswith ( hit [ 1 ] ) ] [ 0 ] <TAB><TAB><TAB>  return location [ 0 ] - 1 , location [ 1 ] - 1 <TAB><TAB>  else : <TAB><TAB><TAB>  # TODO: There might be many symbols with the same name. <TAB><TAB><TAB>  return locations [ 0 ] <TAB>  except IndexError : <TAB><TAB>  return ",if not globally :,if globally:,False,59.02702515112146,98.8845977535863
1104,"def __getslice__ ( self , i , j ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # handle the case where the right bound is unspecified <TAB><TAB><TAB>  j = len ( self ) <TAB><TAB>  if i < 0 or j < 0 : <TAB><TAB><TAB>  raise dns . exception . FormError <TAB><TAB>  # If it's not an empty slice, access left and right bounds <TAB><TAB>  # to make sure they're valid <TAB><TAB>  if i != j : <TAB><TAB><TAB>  super ( WireData , self ) . __getitem__ ( i ) <TAB><TAB><TAB>  super ( WireData , self ) . __getitem__ ( j - 1 ) <TAB><TAB>  return WireData ( super ( WireData , self ) . __getslice__ ( i , j ) ) <TAB>  except IndexError : <TAB><TAB>  raise dns . exception . FormError ",if j == sys . maxint :,if j is None:,False,59.01612162468349,97.21271834624025
1105,"def main ( ) : <TAB>  r = redis . StrictRedis ( ) <TAB>  curr_memory = prev_memory = r . info ( ) [ "" used_memory "" ] <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" Delta Memory :  %d , Total Memory :  %d "" <TAB><TAB><TAB><TAB>  % ( ( curr_memory - prev_memory ) , curr_memory ) <TAB><TAB><TAB>  ) <TAB><TAB>  time . sleep ( 1 ) <TAB><TAB>  prev_memory = curr_memory <TAB><TAB>  curr_memory = r . info ( ) [ "" used_memory "" ] ",if prev_memory != curr_memory :,if curr_memory > prev_memory:,False,43.29489101296605,97.05818782239044
1106,"def _visit ( self , func ) : <TAB>  fname = func [ 0 ] <TAB>  if fname in self . _flags : <TAB><TAB>  if self . _flags [ fname ] == 1 : <TAB><TAB><TAB>  logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB><TAB><TAB>  import sys <TAB><TAB><TAB>  sys . exit ( - 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  return <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _flags [ fname ] = 1 <TAB><TAB>  for output in func [ 3 ] : <TAB><TAB><TAB>  for f in self . _orig : <TAB><TAB><TAB><TAB>  for input in f [ 2 ] : <TAB><TAB><TAB><TAB><TAB>  if output == input : <TAB><TAB><TAB><TAB><TAB><TAB>  self . _visit ( f ) <TAB>  self . _flags [ fname ] = 2 <TAB>  self . _sorted . insert ( 0 , func ) ",if fname not in self . _flags :,if fname not in self._flags:,False,54.64002859132824,98.72705924320974
1107,"def urls ( self , version = None ) : <TAB>  """"""Returns all URLS that are mapped to this interface"""""" <TAB>  urls = [ ] <TAB>  for _base_url , routes in self . api . http . routes . items ( ) : <TAB><TAB>  for url , methods in routes . items ( ) : <TAB><TAB><TAB>  for _method , versions in methods . items ( ) : <TAB><TAB><TAB><TAB>  for interface_version , interface in versions . items ( ) : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  if not url in urls : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  urls . append ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB><TAB>  ( "" /v {0} "" . format ( version ) if version else "" "" ) + url <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB>  return urls ",if interface_version == version and interface == self :,if interface_version == _base_url:,False,56.954949321806524,97.20535103118952
1108,"def _handle_data ( self , text ) : <TAB>  if self . _translate : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _data . append ( text ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _translate = False <TAB><TAB><TAB>  self . _data = [ ] <TAB><TAB><TAB>  self . _comments = [ ] ","if not text . startswith ( ""gtk-"" ) :",if text:,False,39.36734766801292,90.36103134401469
1109,"def set_dir_modes ( self , dirname , mode ) : <TAB>  if not self . is_chmod_supported ( ) : <TAB><TAB>  return <TAB>  for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB><TAB>  if not self . dry_run : <TAB><TAB><TAB>  os . chmod ( dirpath , mode ) ",if os . path . islink ( dirpath ) :,if not os.path.isdir(dirpath):,False,24.881937931210725,96.25354647617574
1110,"def language ( self ) : <TAB>  if self . lang_data : <TAB><TAB>  lang_data = [ s if s != "" None "" else None for s in self . lang_data ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return Language ( lang_data [ 0 ] , country = lang_data [ 1 ] , script = lang_data [ 2 ] ) ",if lang_data [ 0 ] :,if lang_data:,False,29.489607736826496,95.26639866552483
1111,"def _addItemToLayout ( self , sample , label ) : <TAB>  col = self . layout . columnCount ( ) <TAB>  row = self . layout . rowCount ( ) <TAB>  if row : <TAB><TAB>  row - = 1 <TAB>  nCol = self . columnCount * 2 <TAB>  # FIRST ROW FULL <TAB>  if col == nCol : <TAB><TAB>  for col in range ( 0 , nCol , 2 ) : <TAB><TAB><TAB>  # FIND RIGHT COLUMN <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if col + 2 == nCol : <TAB><TAB><TAB>  # MAKE NEW ROW <TAB><TAB><TAB>  col = 0 <TAB><TAB><TAB>  row + = 1 <TAB>  self . layout . addItem ( sample , row , col ) <TAB>  self . layout . addItem ( label , row , col + 1 ) ","if not self . layout . itemAt ( row , col ) :",if col == nCol:,False,47.43423923617145,94.53506978891669
1112,"def align_comments ( tlist ) : <TAB>  tidx , token = tlist . token_next_by ( i = sql . Comment ) <TAB>  while token : <TAB><TAB>  pidx , prev_ = tlist . token_prev ( tidx ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tlist . group_tokens ( sql . TokenList , pidx , tidx , extend = True ) <TAB><TAB><TAB>  tidx = pidx <TAB><TAB>  tidx , token = tlist . token_next_by ( i = sql . Comment , idx = tidx ) ","if isinstance ( prev_ , sql . TokenList ) :",if prev_:,False,26.37481068458313,92.76068351026534
1113,"def hook_GetVariable ( ql , address , params ) : <TAB>  if params [ "" VariableName "" ] in ql . env : <TAB><TAB>  var = ql . env [ params [ "" VariableName "" ] ] <TAB><TAB>  read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB><TAB>  if params [ "" Attributes "" ] != 0 : <TAB><TAB><TAB>  write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB><TAB>  write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return EFI_BUFFER_TOO_SMALL <TAB><TAB>  if params [ "" Data "" ] != 0 : <TAB><TAB><TAB>  ql . mem . write ( params [ "" Data "" ] , var ) <TAB><TAB>  return EFI_SUCCESS <TAB>  return EFI_NOT_FOUND ",if read_len < len ( var ) :,if read_len == 0:,False,48.854877066026006,97.11559741851308
1114,"def _PromptMySQL ( self , config ) : <TAB>  """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB>  while True : <TAB><TAB>  self . _PromptMySQLOnce ( config ) <TAB><TAB>  if self . _CheckMySQLConnection ( ) : <TAB><TAB><TAB>  print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB><TAB><TAB>  retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ConfigInitError ( ) ",if not retry :,if retry:,False,44.49742894278099,98.63485593898541
1115,"def split_long_line_with_indent ( line , max_per_line , indent ) : <TAB>  """"""Split the `line` so that it doesn't go over `max_per_line` and adds `indent` to new lines."""""" <TAB>  words = line . split ( "" "" ) <TAB>  lines = [ ] <TAB>  current_line = words [ 0 ] <TAB>  for word in words [ 1 : ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lines . append ( current_line ) <TAB><TAB><TAB>  current_line = "" "" * indent + word <TAB><TAB>  else : <TAB><TAB><TAB>  current_line = f "" { current_line } { word } "" <TAB>  lines . append ( current_line ) <TAB>  return "" \n "" . join ( lines ) ","if len ( f""{current_line} {word}"" ) > max_per_line :",if word in max_per_line:,False,39.357060953507315,92.4215327589617
1116,"def gen_cli ( docs_dir ) : <TAB>  with open ( os . path . join ( docs_dir , "" CLI_template.md "" ) , "" r "" ) as cli_temp_file : <TAB><TAB>  temp_lines = cli_temp_file . readlines ( ) <TAB>  lines = [ ] <TAB>  for line in temp_lines : <TAB><TAB>  matched = re . match ( r "" { onnx-tf.*} "" , line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  command = matched . string . strip ( ) [ 1 : - 1 ] <TAB><TAB><TAB>  output = subprocess . check_output ( command . split ( "" "" ) ) . decode ( "" UTF-8 "" ) <TAB><TAB><TAB>  lines . append ( output ) <TAB><TAB>  else : <TAB><TAB><TAB>  lines . append ( line ) <TAB>  with open ( os . path . join ( docs_dir , "" CLI.md "" ) , "" w "" ) as cli_file : <TAB><TAB>  cli_file . writelines ( lines ) ",if matched :,if matched:,False,22.782390833627037,98.6108515911854
1117,"def read ( self , size = None ) : <TAB>  if size == 0 : <TAB><TAB>  return "" "" <TAB>  data = list ( ) <TAB>  while size is None or size > 0 : <TAB><TAB>  line = self . readline ( size or - 1 ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size - = len ( line ) <TAB><TAB>  data . append ( line ) <TAB>  return "" "" . join ( data ) ",if size is not None :,if len(line) > 0:,False,30.509325045158775,91.91162607297093
1118,"def _get_format_and_pattern ( file_path ) : <TAB>  file_path = Path ( file_path ) <TAB>  with file_path . open ( ) as f : <TAB><TAB>  first_line = f . readline ( ) . strip ( ) <TAB><TAB>  match = re . match ( r "" format *: *(.+) "" , first_line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" gztar "" , first_line , 1 <TAB><TAB>  return match . group ( 1 ) , f . readline ( ) . strip ( ) , 2 ",if match is None :,if match is None:,False,27.931790398990014,100.00000000000004
1119,"def remove_old_snapshot ( install_dir ) : <TAB>  logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB>  for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  if os . path . isfile ( file ) : <TAB><TAB><TAB><TAB>  os . unlink ( file ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  shutil . rmtree ( file ) <TAB><TAB>  except Exception as error : <TAB><TAB><TAB>  logging . error ( "" Error:  {} "" . format ( error ) ) <TAB><TAB><TAB>  sys . exit ( 1 ) ",elif os . path . isdir ( file ) :,if os.path.isdir(file):,False,31.540933894746747,98.69612755723132
1120,"def _test_forever ( self , tests ) : <TAB>  while True : <TAB><TAB>  for test_name in tests : <TAB><TAB><TAB>  yield test_name <TAB><TAB><TAB>  if self . bad : <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return ",if self . ns . fail_env_changed and self . environment_changed :,if self.bad:,False,23.219106944434277,86.03132207338702
1121,"def _swig_extract_dependency_files ( self , src ) : <TAB>  dep = [ ] <TAB>  for line in open ( src ) : <TAB><TAB>  if line . startswith ( "" #include "" ) or line . startswith ( "" %i nclude "" ) : <TAB><TAB><TAB>  line = line . split ( "" "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  dep . append ( line ) <TAB>  return [ i for i in dep if os . path . exists ( i ) ] ","if not ( ""<"" in line or line in dep ) :",if line:,False,33.30965420807562,89.7696492718151
1122,"def update_service_key ( kid , name = None , metadata = None ) : <TAB>  try : <TAB><TAB>  with db_transaction ( ) : <TAB><TAB><TAB>  key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  key . name = name <TAB><TAB><TAB>  if metadata is not None : <TAB><TAB><TAB><TAB>  key . metadata . update ( metadata ) <TAB><TAB><TAB>  key . save ( ) <TAB>  except ServiceKey . DoesNotExist : <TAB><TAB>  raise ServiceKeyDoesNotExist ",if name is not None :,if name is not None:,False,52.91091426756921,100.00000000000004
1123,"def range ( self , dimension , data_range = True , dimension_range = True ) : <TAB>  if self . nodes and dimension in self . nodes . dimensions ( ) : <TAB><TAB>  node_range = self . nodes . range ( dimension , data_range , dimension_range ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path_range = self . _edgepaths . range ( dimension , data_range , dimension_range ) <TAB><TAB><TAB>  return max_range ( [ node_range , path_range ] ) <TAB><TAB>  return node_range <TAB>  return super ( Graph , self ) . range ( dimension , data_range , dimension_range ) ",if self . _edgepaths :,if self._edgepaths:,False,51.55954479555298,100.00000000000004
1124,"def handler ( chan , host , port ) : <TAB>  sock = socket ( ) <TAB>  try : <TAB><TAB>  sock . connect ( ( host , port ) ) <TAB>  except Exception as e : <TAB><TAB>  if verbose == True : <TAB><TAB><TAB>  print ( e ) <TAB><TAB>  return <TAB>  while True : <TAB><TAB>  r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB><TAB>  if sock in r : <TAB><TAB><TAB>  data = sock . recv ( 1024 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  chan . send ( data ) <TAB><TAB>  if chan in r : <TAB><TAB><TAB>  data = chan . recv ( 1024 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  sock . send ( data ) <TAB>  chan . close ( ) <TAB>  sock . close ( ) ",if len ( data ) == 0 :,if not data:,False,22.33567917643585,93.50344543238762
1125,"def output_layer ( self , features , * * kwargs ) : <TAB>  """"""Project features to the vocabulary size."""""" <TAB>  if self . adaptive_softmax is None : <TAB><TAB>  # project back to size of vocabulary <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return F . linear ( features , self . embed_tokens . weight ) <TAB><TAB>  else : <TAB><TAB><TAB>  return F . linear ( features , self . embed_out ) <TAB>  else : <TAB><TAB>  return features ",if self . share_input_output_embed :,if self.embed_tokens:,False,50.75843599550195,94.15061190876094
1126,"def generate ( self , dest , vars ) : <TAB>  util . ensure_dir ( dest ) <TAB>  for relpath , src , template in self . _file_templates : <TAB><TAB>  file_dest = os . path . join ( dest , relpath ) <TAB><TAB>  util . ensure_dir ( os . path . dirname ( file_dest ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shutil . copyfile ( src , file_dest ) <TAB><TAB>  else : <TAB><TAB><TAB>  _render_template ( template , vars , file_dest ) ",if template is None :,if os.path.exists(src):,False,21.786509918595414,93.41558421388604
1127,"def _py_matching_callback ( self , context , result , sender , device ) : <TAB>  d = HIDDevice . get_device ( c_void_p ( device ) ) <TAB>  if d not in self . devices : <TAB><TAB>  self . devices . add ( d ) <TAB><TAB>  for x in self . matching_observers : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  x . device_discovered ( d ) ","if hasattr ( x , ""device_discovered"" ) :",if x.device_discovered is not None:,False,49.19445068796504,91.73008908715917
1128,"def urlquote ( * args , * * kwargs ) : <TAB>  new_kwargs = dict ( kwargs ) <TAB>  if not PY3 : <TAB><TAB>  new_kwargs = dict ( kwargs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del new_kwargs [ "" encoding "" ] <TAB><TAB>  if "" errors "" in kwargs : <TAB><TAB><TAB>  del new_kwargs [ "" errors "" ] <TAB>  return quote ( * args , * * new_kwargs ) ","if ""encoding"" in new_kwargs :","if ""encoding"" in kwargs:",False,20.646525448893343,97.08882898877195
1129,"def Set ( self , attr , value ) : <TAB>  hook = getattr ( self , "" _set_ %s "" % attr , None ) <TAB>  if hook : <TAB><TAB>  # If there is a set hook we must use the context manager. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Can only update attribute  %s  using the context manager. "" % attr <TAB><TAB><TAB>  ) <TAB><TAB>  if attr not in self . _pending_hooks : <TAB><TAB><TAB>  self . _pending_hooks . append ( attr ) <TAB><TAB>  self . _pending_parameters [ attr ] = value <TAB>  else : <TAB><TAB>  super ( Configuration , self ) . Set ( attr , value ) ",if self . _lock > 0 :,"if not hasattr(self, '_contextmanager'):",False,64.05327664710549,94.97743816772447
1130,"def on_profiles_loaded ( self , profiles ) : <TAB>  cb = self . builder . get_object ( "" cbProfile "" ) <TAB>  model = cb . get_model ( ) <TAB>  model . clear ( ) <TAB>  for f in profiles : <TAB><TAB>  name = f . get_basename ( ) <TAB><TAB>  if name . endswith ( "" .mod "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = name [ 0 : - 11 ] <TAB><TAB>  model . append ( ( name , f , None ) ) <TAB>  cb . set_active ( 0 ) ","if name . endswith ( "".sccprofile"" ) :",if name.endswith('.py'):,False,50.999635213468885,95.14579915678168
1131,"def get_eval_task ( self , worker_id ) : <TAB>  """"""Return next evaluation (task_id, Task) tuple"""""" <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return - 1 , None <TAB><TAB>  self . _task_id + = 1 <TAB><TAB>  task = self . _eval_todo . pop ( ) <TAB><TAB>  self . _doing [ self . _task_id ] = ( worker_id , task , time . time ( ) ) <TAB><TAB>  return self . _task_id , task ",if not self . _eval_todo :,if self._task_id >= len(self._eval_todo):,False,31.31329380374921,89.0551394889771
1132,"def queries ( self ) : <TAB>  if DEV : <TAB><TAB>  cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not cmd . stdout . strip ( ) : <TAB><TAB><TAB><TAB>  log_cmd = ShellCommand ( <TAB><TAB><TAB><TAB><TAB>  "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB><TAB><TAB><TAB><TAB>  print ( cmd . stdout ) <TAB><TAB><TAB><TAB>  pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB>  return ( ) ","if not cmd . check ( f""docker check for {self.path.k8s}"" ) :","if cmd.check(f""Running docker logs for {self.path.k8s",False,16.389520129928403,95.46940737557925
1133,"def disjoined ( data ) : <TAB>  # create marginalized distributions and multiple them together <TAB>  data_disjoined = None <TAB>  dim = len ( data . shape ) <TAB>  for d in range ( dim ) : <TAB><TAB>  axes = list ( range ( dim ) ) <TAB><TAB>  axes . remove ( d ) <TAB><TAB>  data1d = multisum ( data , axes ) <TAB><TAB>  shape = [ 1 for k in range ( dim ) ] <TAB><TAB>  shape [ d ] = len ( data1d ) <TAB><TAB>  data1d = data1d . reshape ( tuple ( shape ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data_disjoined = data1d <TAB><TAB>  else : <TAB><TAB><TAB>  data_disjoined = data_disjoined * data1d <TAB>  return data_disjoined ",if d == 0 :,if data_disjoined is None:,False,32.18149253999654,96.68698036066837
1134,"def safe_repr ( val ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # We special case dicts to have a sorted repr. This makes testing <TAB><TAB><TAB>  # significantly easier <TAB><TAB><TAB>  val = _obj_with_safe_repr ( val ) <TAB><TAB>  ret = repr ( val ) <TAB><TAB>  if six . PY2 : <TAB><TAB><TAB>  ret = ret . decode ( "" utf-8 "" ) <TAB>  except UnicodeEncodeError : <TAB><TAB>  ret = red ( "" a  %r  that cannot be represented "" % type ( val ) ) <TAB>  else : <TAB><TAB>  ret = green ( ret ) <TAB>  return ret ","if isinstance ( val , dict ) :","if isinstance(val, dict):",False,62.759145609091824,100.00000000000004
1135,"def wrapper ( * args , * * kwargs ) : <TAB>  resp = view_func ( * args , * * kwargs ) <TAB>  if isinstance ( resp , dict ) : <TAB><TAB>  ctx_params = request . environ . get ( "" webrec.template_params "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  resp . update ( ctx_params ) <TAB><TAB>  template = self . jinja_env . jinja_env . get_or_select_template ( template_name ) <TAB><TAB>  return template . render ( * * resp ) <TAB>  else : <TAB><TAB>  return resp ",if ctx_params :,if ctx_params:,False,42.55558098901273,100.00000000000004
1136,"def post ( self , request , * args , * * kwargs ) : <TAB>  contact_id = kwargs . get ( "" pk "" ) <TAB>  self . object = get_object_or_404 ( Contact , id = contact_id ) <TAB>  if ( <TAB><TAB>  self . request . user . role != "" ADMIN "" <TAB><TAB>  and not self . request . user . is_superuser <TAB><TAB>  and self . request . user != self . object . created_by <TAB>  ) or self . object . company != self . request . company : <TAB><TAB>  raise PermissionDenied <TAB>  else : <TAB><TAB>  if self . object . address_id : <TAB><TAB><TAB>  self . object . address . delete ( ) <TAB><TAB>  self . object . delete ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return JsonResponse ( { "" error "" : False } ) <TAB><TAB>  return redirect ( "" contacts:list "" ) ",if self . request . is_ajax ( ) :,if not self.object:,False,47.12583519354624,95.94724874958874
1137,"def escape ( text , newline = False ) : <TAB>  """"""Escape special html characters."""""" <TAB>  if isinstance ( text , str ) : <TAB><TAB>  if "" & "" in text : <TAB><TAB><TAB>  text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB>  if "" > "" in text : <TAB><TAB><TAB>  text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB>  if ' "" ' in text : <TAB><TAB><TAB>  text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB>  if "" ' "" in text : <TAB><TAB><TAB>  text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB>  if newline : <TAB><TAB><TAB>  if "" \n "" in text : <TAB><TAB><TAB><TAB>  text = text . replace ( "" \n "" , "" <br> "" ) <TAB>  return text ","if ""<"" in text :","if ""<"" in text:",False,50.171043615281484,100.00000000000004
1138,"def everythingIsUnicode ( d ) : <TAB>  """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  if isinstance ( v , dict ) and k != "" headers "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  for i in v : <TAB><TAB><TAB><TAB>  if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB><TAB>  elif isinstance ( i , _bytes ) : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif isinstance ( v , _bytes ) : <TAB><TAB><TAB>  return False <TAB>  return True ",if not everythingIsUnicode ( v ) :,"if not isinstance(v, unicode):",False,32.685597308335566,97.50855959338632
1139,"def fill ( self ) : <TAB>  try : <TAB><TAB>  while ( <TAB><TAB><TAB>  not self . stopping . wait ( self . sample_wait ) <TAB><TAB><TAB>  and len ( self . queue ) < self . queue . maxlen <TAB><TAB>  ) : <TAB><TAB><TAB>  self . queue . append ( self . parent . _read ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . parent . _fire_events ( ) <TAB><TAB>  self . full . set ( ) <TAB><TAB>  while not self . stopping . wait ( self . sample_wait ) : <TAB><TAB><TAB>  self . queue . append ( self . parent . _read ( ) ) <TAB><TAB><TAB>  if isinstance ( self . parent , EventsMixin ) : <TAB><TAB><TAB><TAB>  self . parent . _fire_events ( ) <TAB>  except ReferenceError : <TAB><TAB>  # Parent is dead; time to die! <TAB><TAB>  pass ","if self . partial and isinstance ( self . parent , EventsMixin ) :","if isinstance(self.parent, EventsMixin):",False,54.75687094471662,97.92291264466706
1140,"def _SetListviewTextItems ( self , items ) : <TAB>  self . listview . DeleteAllItems ( ) <TAB>  index = - 1 <TAB>  for item in items : <TAB><TAB>  index = self . listview . InsertItem ( index + 1 , item [ 0 ] ) <TAB><TAB>  data = item [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = "" "" <TAB><TAB>  self . listview . SetItemText ( index , 1 , data ) ",if data is None :,if data == '':,False,45.8896884218966,92.71523330185501
1141,"def process_request ( self , request ) : <TAB>  for old , new in self . names_name : <TAB><TAB>  request . uri = request . uri . replace ( old , new ) <TAB><TAB>  if is_text_payload ( request ) and request . body : <TAB><TAB><TAB>  body = six . ensure_str ( request . body ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  request . body = body . replace ( old , new ) <TAB>  return request ",if old in body :,if body:,False,33.62472630820885,97.22723267947742
1142,"def serialize ( cls , value , * args , * * kwargs ) : <TAB>  if value is None : <TAB><TAB>  return "" "" <TAB>  value_as_string = six . text_type ( value ) <TAB>  if SHOULD_NOT_USE_LOCALE : <TAB><TAB>  return value_as_string <TAB>  else : <TAB><TAB>  grouping = kwargs . get ( "" grouping "" , None ) <TAB><TAB>  has_decimal_places = value_as_string . find ( "" . "" ) != - 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  string_format = "" %d "" <TAB><TAB>  else : <TAB><TAB><TAB>  decimal_places = len ( value_as_string . split ( "" . "" ) [ 1 ] ) <TAB><TAB><TAB>  string_format = "" % . {} f "" . format ( decimal_places ) <TAB><TAB>  return locale . format ( string_format , value , grouping = grouping ) ",if not has_decimal_places :,if has_decimal_places:,False,45.88158149035104,97.90336739735513
1143,"def review_link ( request , path_obj ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if check_permission ( "" translate "" , request ) : <TAB><TAB><TAB><TAB>  text = _ ( "" Review Suggestions "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  text = _ ( "" View Suggestions "" ) <TAB><TAB><TAB>  return { <TAB><TAB><TAB><TAB>  "" href "" : dispatch . translate ( <TAB><TAB><TAB><TAB><TAB>  request , path_obj . pootle_path , matchnames = [ "" hassuggestion "" ] <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  "" text "" : text , <TAB><TAB><TAB>  } <TAB>  except IOError : <TAB><TAB>  pass ",if path_obj . has_suggestions ( ) :,if path_obj.show_link(request):,False,48.71772583847432,97.33163700864877
1144,"def _migrate_key ( self , key ) : <TAB>  """"""migrate key from old .dat file"""""" <TAB>  key_path = os . path . join ( self . home_path , "" keys.dat "" ) <TAB>  if os . path . exists ( key_path ) : <TAB><TAB>  try : <TAB><TAB><TAB>  key_data = json . loads ( open ( key_path , "" rb "" ) . read ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . add_key ( key , key_data . get ( key ) ) <TAB><TAB>  except : <TAB><TAB><TAB>  self . error ( f "" Corrupt key file. Manual migration of  ' { key } '  required. "" ) ",if key_data . get ( key ) :,if key_data.get(key) is not None:,False,27.69937642933215,97.6931116171903
1145,"def gather_callback_args ( self , obj , callbacks ) : <TAB>  session = sa . orm . object_session ( obj ) <TAB>  for callback in callbacks : <TAB><TAB>  backref = callback . backref <TAB><TAB>  root_objs = getdotattr ( obj , backref ) if backref else obj <TAB><TAB>  if root_objs : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  root_objs = [ root_objs ] <TAB><TAB><TAB>  with session . no_autoflush : <TAB><TAB><TAB><TAB>  for root_obj in root_objs : <TAB><TAB><TAB><TAB><TAB>  if root_obj : <TAB><TAB><TAB><TAB><TAB><TAB>  args = self . get_callback_args ( root_obj , callback ) <TAB><TAB><TAB><TAB><TAB><TAB>  if args : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  yield args ","if not isinstance ( root_objs , Iterable ) :","if isinstance(root_objs, (list, tuple)):",False,22.44492854914089,96.87318608866009
1146,"def GetDefFile ( self , gyp_to_build_path ) : <TAB>  """"""Returns the .def file from sources, if any.  Otherwise returns None."""""" <TAB>  spec = self . spec <TAB>  if spec [ "" type "" ] in ( "" shared_library "" , "" loadable_module "" , "" executable "" ) : <TAB><TAB>  def_files = [ s for s in spec . get ( "" sources "" , [ ] ) if s . endswith ( "" .def "" ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return gyp_to_build_path ( def_files [ 0 ] ) <TAB><TAB>  elif len ( def_files ) > 1 : <TAB><TAB><TAB>  raise Exception ( "" Multiple .def files "" ) <TAB>  return None ",if len ( def_files ) == 1 :,if def_files:,False,31.028171659280517,95.28663818983617
1147,"def _validate_gallery ( images ) : <TAB>  for image in images : <TAB><TAB>  image_path = image . get ( "" image_path "" , "" "" ) <TAB><TAB>  if image_path : <TAB><TAB><TAB>  if not isfile ( image_path ) : <TAB><TAB><TAB><TAB>  raise TypeError ( f "" { image_path !r}  is not a valid image path. "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise TypeError ( "" ' image_path '  is required. "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( "" Caption must be 180 characters or less. "" ) ","if not len ( image . get ( ""caption"" , """" ) ) <= 180 :",if len(image.get_caption()) < 180:,False,26.792109059001767,90.25602694384891
1148,"def VType ( self ) : <TAB>  if "" DW_AT_type "" in self . attributes : <TAB><TAB>  target = self . types [ self . type_id ] <TAB><TAB>  target_type = target . VType ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  target_type = [ target_type , None ] <TAB><TAB>  return [ "" Pointer "" , dict ( target = target_type [ 0 ] , target_args = target_type [ 1 ] ) ] <TAB>  return [ "" Pointer "" , dict ( target = "" Void "" ) ] ","if not isinstance ( target_type , list ) :",if target_type is None:,False,30.469077061793797,93.69286211075112
1149,"def addInPlace ( self , value1 , value2 ) : <TAB>  for group in value2 : <TAB><TAB>  for key in value2 [ group ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value1 [ group ] [ key ] = value2 [ group ] [ key ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  value1 [ group ] [ key ] + = value2 [ group ] [ key ] <TAB>  return value1 ",if key not in value1 [ group ] :,if key in value1:,False,39.48224120331956,94.30847825084821
1150,"def _mongo_query_and ( self , queries ) : <TAB>  if len ( queries ) == 1 : <TAB><TAB>  return queries [ 0 ] <TAB>  query = { } <TAB>  for q in queries : <TAB><TAB>  for k , v in q . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  query [ k ] = { } <TAB><TAB><TAB>  if isinstance ( v , list ) : <TAB><TAB><TAB><TAB>  # TODO check exists of k in query, may be it should be update <TAB><TAB><TAB><TAB>  query [ k ] = v <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  query [ k ] . update ( v ) <TAB>  return query ",if k not in query :,if k not in query:,False,62.77614617937473,100.00000000000004
1151,"def _handled_eventtype ( self , eventtype , handler ) : <TAB>  if eventtype not in known_events : <TAB><TAB>  log . error ( ' The event  "" %s ""  is not known ' , eventtype ) <TAB><TAB>  return False <TAB>  if known_events [ eventtype ] . __module__ . startswith ( "" deluge.event "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  log . error ( <TAB><TAB><TAB>  "" You cannot register custom notification providers  "" <TAB><TAB><TAB>  "" for built-in event types. "" <TAB><TAB>  ) <TAB><TAB>  return False <TAB>  return True ",if handler . __self__ is self :,if handler is None:,False,29.647026763141326,91.54460195132896
1152,"def get_ax_arg ( uri ) : <TAB>  if not ax_ns : <TAB><TAB>  return u "" "" <TAB>  prefix = "" openid. "" + ax_ns + "" .type. "" <TAB>  ax_name = None <TAB>  for name , values in self . request . arguments . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  part = name [ len ( prefix ) : ] <TAB><TAB><TAB>  ax_name = "" openid. "" + ax_ns + "" .value. "" + part <TAB><TAB><TAB>  break <TAB>  if not ax_name : <TAB><TAB>  return u "" "" <TAB>  return self . get_argument ( ax_name , u "" "" ) ",if values [ - 1 ] == uri and name . startswith ( prefix ) :,if name.startswith(prefix):,False,31.999457261130974,94.92597137131646
1153,"def handle_starttag ( self , tag , attrs ) : <TAB>  if tag == "" base "" : <TAB><TAB>  self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB>  if self . scan_tag ( tag ) : <TAB><TAB>  for attr , value in attrs : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if self . strip : <TAB><TAB><TAB><TAB><TAB>  value = strip_html5_whitespace ( value ) <TAB><TAB><TAB><TAB>  url = self . process_attr ( value ) <TAB><TAB><TAB><TAB>  link = Link ( url = url ) <TAB><TAB><TAB><TAB>  self . links . append ( link ) <TAB><TAB><TAB><TAB>  self . current_link = link ",if self . scan_attr ( attr ) :,if attr.startswith('a') and attr.startswith('a') and (not,False,46.71999899868994,92.57894467749861
1154,"def test_long_steadystate_queue_popright ( self ) : <TAB>  for size in ( 0 , 1 , 2 , 100 , 1000 ) : <TAB><TAB>  d = deque ( reversed ( range ( size ) ) ) <TAB><TAB>  append , pop = d . appendleft , d . pop <TAB><TAB>  for i in range ( size , BIG ) : <TAB><TAB><TAB>  append ( i ) <TAB><TAB><TAB>  x = pop ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( x , i - size ) <TAB><TAB>  self . assertEqual ( list ( reversed ( list ( d ) ) ) , list ( range ( BIG - size , BIG ) ) ) ",if x != i - size :,if x != i:,False,22.622446417709934,98.05808565345808
1155,"def _update_read ( self ) : <TAB>  """"""Update state when there is read event"""""" <TAB>  try : <TAB><TAB>  msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . on_message ( msg ) <TAB><TAB><TAB>  return True <TAB><TAB>  # normal close, remote is closed <TAB><TAB>  self . close ( ) <TAB>  except socket . error as err : <TAB><TAB>  if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) : <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  self . on_error ( err ) <TAB>  return False ",if msg :,if msg.data.read_count == 0:,False,55.37645296235466,94.53991277449855
1156,"def prepend ( self , value ) : <TAB>  """"""prepend value to nodes"""""" <TAB>  root , root_text = self . _get_root ( value ) <TAB>  for i , tag in enumerate ( self ) : <TAB><TAB>  if not tag . text : <TAB><TAB><TAB>  tag . text = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  root [ - 1 ] . tail = tag . text <TAB><TAB><TAB>  tag . text = root_text <TAB><TAB>  else : <TAB><TAB><TAB>  tag . text = root_text + tag . text <TAB><TAB>  if i > 0 : <TAB><TAB><TAB>  root = deepcopy ( list ( root ) ) <TAB><TAB>  tag [ : 0 ] = root <TAB><TAB>  root = tag [ : len ( root ) ] <TAB>  return self ",if len ( root ) > 0 :,if root:,False,26.781170324956754,95.49936090012113
1157,"def cmp ( self , other ) : <TAB>  v_is_ptr = not isinstance ( self , CTypesGenericPrimitive ) <TAB>  w_is_ptr = isinstance ( other , CTypesData ) and not isinstance ( <TAB><TAB>  other , CTypesGenericPrimitive <TAB>  ) <TAB>  if v_is_ptr and w_is_ptr : <TAB><TAB>  return cmpfunc ( self . _convert_to_address ( None ) , other . _convert_to_address ( None ) ) <TAB>  elif v_is_ptr or w_is_ptr : <TAB><TAB>  return NotImplemented <TAB>  else : <TAB><TAB>  if isinstance ( self , CTypesGenericPrimitive ) : <TAB><TAB><TAB>  self = self . _value <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  other = other . _value <TAB><TAB>  return cmpfunc ( self , other ) ","if isinstance ( other , CTypesGenericPrimitive ) :","if isinstance(other, CTypesGenericPrimitive):",False,50.96722705139093,100.00000000000004
1158,"def get_external_addresses ( self , label = None ) - > List [ str ] : <TAB>  result = [ ] <TAB>  for c in self . _conf [ "" pools "" ] . values ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if label == c [ "" label "" ] : <TAB><TAB><TAB><TAB>  result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB>  return result ",if label is not None :,if c['external_address']:,False,47.87841743182524,94.83570802887468
1159,"def coerce_text ( v ) : <TAB>  if not isinstance ( v , basestring_ ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attr = "" __unicode__ "" <TAB><TAB>  else : <TAB><TAB><TAB>  attr = "" __str__ "" <TAB><TAB>  if hasattr ( v , attr ) : <TAB><TAB><TAB>  return unicode ( v ) <TAB><TAB>  else : <TAB><TAB><TAB>  return bytes ( v ) <TAB>  return v ",if sys . version_info [ 0 ] < 3 :,"if isinstance(v, unicode):",False,38.063336855135496,91.55373718492298
1160,"def check_localhost ( self ) : <TAB>  """"""Warn if any socket_host is 'localhost'. See #711."""""" <TAB>  for k , v in cherrypy . config . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  "" The use of  ' localhost '  as a socket host can  "" <TAB><TAB><TAB><TAB>  "" cause problems on newer systems, since  "" <TAB><TAB><TAB><TAB>  "" ' localhost '  can map to either an IPv4 or an  "" <TAB><TAB><TAB><TAB>  "" IPv6 address. You should use  ' 127.0.0.1 ' "" <TAB><TAB><TAB><TAB>  "" or  ' [::1] '  instead. "" <TAB><TAB><TAB>  ) ","if k == ""server.socket_host"" and v == ""localhost"" :",if k == 'socket_host':,False,64.61989627712873,88.9352524371347
1161,"def add_songs ( self , filenames , library ) : <TAB>  changed = [ ] <TAB>  for i in range ( len ( self ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  song = library [ self . _list [ i ] ] <TAB><TAB><TAB>  self . _list [ i ] = song <TAB><TAB><TAB>  changed . append ( song ) <TAB>  if changed : <TAB><TAB>  self . _emit_changed ( changed , msg = "" add "" ) <TAB>  return bool ( changed ) ","if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :",if self._list[i] in filenames:,False,43.05619216695905,92.03386193922192
1162,"def _expand_deps_java_generation ( self ) : <TAB>  """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB>  queue = collections . deque ( self . deps ) <TAB>  keys = set ( ) <TAB>  while queue : <TAB><TAB>  k = queue . popleft ( ) <TAB><TAB>  if k not in keys : <TAB><TAB><TAB>  keys . add ( k ) <TAB><TAB><TAB>  dep = self . target_database [ k ] <TAB><TAB><TAB>  <IF-STMT>:<TAB># Has this attribute <TAB><TAB><TAB><TAB>  dep . attr [ "" generate_java "" ] = True <TAB><TAB><TAB><TAB>  queue . extend ( dep . deps ) ","if ""generate_java"" in dep . attr :",if dep.attr and (not dep.attr['generate_java']):,False,59.019439589018184,90.61112989983269
1163,"def get ( self ) : <TAB>  name = request . args . get ( "" filename "" ) <TAB>  if name is not None : <TAB><TAB>  opts = dict ( ) <TAB><TAB>  opts [ "" type "" ] = "" episode "" <TAB><TAB>  result = guessit ( name , options = opts ) <TAB><TAB>  res = dict ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  res [ "" episode "" ] = result [ "" episode "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  res [ "" episode "" ] = 0 <TAB><TAB>  if "" season "" in result : <TAB><TAB><TAB>  res [ "" season "" ] = result [ "" season "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  res [ "" season "" ] = 0 <TAB><TAB>  if "" subtitle_language "" in result : <TAB><TAB><TAB>  res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB><TAB>  return jsonify ( data = res ) <TAB>  else : <TAB><TAB>  return "" "" , 400 ","if ""episode"" in result :","if ""episode"" in result:",False,23.485751084986862,100.00000000000004
1164,def _get_error_file ( self ) - > Optional [ str ] : <TAB>  error_file = None <TAB>  min_timestamp = sys . maxsize <TAB>  for replicas in self . role_replicas . values ( ) : <TAB><TAB>  for replica in replicas : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  mtime = os . path . getmtime ( replica . error_file ) <TAB><TAB><TAB>  if mtime < min_timestamp : <TAB><TAB><TAB><TAB>  min_timestamp = mtime <TAB><TAB><TAB><TAB>  error_file = replica . error_file <TAB>  return error_file ,if not os . path . exists ( replica . error_file ) :,"if not isinstance(replica, UserRoleReplicas):",False,26.167577027221274,93.4868501769378
1165,"def findChapterNameForPosition ( self , p ) : <TAB>  """"""Return the name of a chapter containing p or None if p does not exist."""""" <TAB>  cc , c = self , self . c <TAB>  if not p or not c . positionExists ( p ) : <TAB><TAB>  return None <TAB>  for name in cc . chaptersDict : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  theChapter = cc . chaptersDict . get ( name ) <TAB><TAB><TAB>  if theChapter . positionIsInChapter ( p ) : <TAB><TAB><TAB><TAB>  return name <TAB>  return "" main "" ","if name != ""main"" :",if name in cc.chaptersDict:,False,60.12239074014175,95.58837758607865
1166,"def remove_files ( folder , file_extensions ) : <TAB>  for f in os . listdir ( folder ) : <TAB><TAB>  f_path = os . path . join ( folder , f ) <TAB><TAB>  if os . path . isfile ( f_path ) : <TAB><TAB><TAB>  extension = os . path . splitext ( f_path ) [ 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . remove ( f_path ) ",if extension in file_extensions :,if extension in file_extensions:,False,51.48618081886636,100.00000000000004
1167,"def execute_uncomment ( self , event ) : <TAB>  cursor = self . _editor . GetCurrentPos ( ) <TAB>  line , pos = self . _editor . GetCurLine ( ) <TAB>  spaces = "" "" * self . _tab_size <TAB>  comment = "" Comment "" + spaces <TAB>  cpos = cursor - len ( comment ) <TAB>  lenline = len ( line ) <TAB>  if lenline > 0 : <TAB><TAB>  idx = 0 <TAB><TAB>  while idx < lenline and line [ idx ] == "" "" : <TAB><TAB><TAB>  idx + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _editor . DeleteRange ( cursor - pos + idx , len ( comment ) ) <TAB><TAB><TAB>  self . _editor . SetCurrentPos ( cpos ) <TAB><TAB><TAB>  self . _editor . SetSelection ( cpos , cpos ) <TAB><TAB><TAB>  self . store_position ( ) ",if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,if idx < lenline:,False,25.67375909690645,89.30672854130994
1168,"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell ( <TAB>  critical_suite_with_citations , empty_data_context  ) : <TAB>  obs = SuiteEditNotebookRenderer . from_data_context ( empty_data_context ) . render ( <TAB><TAB>  critical_suite_with_citations , { "" path "" : "" ./foo/data "" } <TAB>  ) <TAB>  assert isinstance ( obs , dict ) <TAB>  found_expected = False <TAB>  for cell in obs [ "" cells "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  source_code = cell [ "" source "" ] <TAB><TAB><TAB>  if ' batch_kwargs =  { "" path "" :  "" ../.././foo/data "" } ' in source_code : <TAB><TAB><TAB><TAB>  found_expected = True <TAB><TAB><TAB><TAB>  break <TAB>  assert found_expected ","if cell [ ""cell_type"" ] == ""code"" :",if cell['type'] == 'code':,False,50.74579587360783,94.52134980887908
1169,"def _get_file ( self ) : <TAB>  if self . _file is None : <TAB><TAB>  self . _file = SpooledTemporaryFile ( <TAB><TAB><TAB>  max_size = self . _storage . max_memory_size , <TAB><TAB><TAB>  suffix = "" .S3Boto3StorageFile "" , <TAB><TAB><TAB>  dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB><TAB>  ) <TAB><TAB>  if "" r "" in self . _mode : <TAB><TAB><TAB>  self . _is_dirty = False <TAB><TAB><TAB>  self . obj . download_fileobj ( self . _file ) <TAB><TAB><TAB>  self . _file . seek ( 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB>  return self . _file ","if self . _storage . gzip and self . obj . content_encoding == ""gzip"" :",if self._mode == 'gz':,False,27.372860221861078,93.05303305390207
1170,"def _parse_filters ( f_strs ) : <TAB>  filters = [ ] <TAB>  if not f_strs : <TAB><TAB>  return filters <TAB>  for f_str in f_strs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fname , fopts = f_str . split ( "" : "" , 1 ) <TAB><TAB><TAB>  filters . append ( ( fname , _parse_options ( [ fopts ] ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  filters . append ( ( f_str , { } ) ) <TAB>  return filters ","if "":"" in f_str :",if f_str.startswith(':') and f_str.endswith(':,False,19.993212306936854,88.77287100090301
1171,"def update_completion ( self ) : <TAB>  """"""Update completion model with exist tags"""""" <TAB>  orig_text = self . widget . text ( ) <TAB>  text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB>  tags = [ ] <TAB>  for tag in self . tags_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if orig_text [ - 1 ] not in ( "" , "" , "" "" ) : <TAB><TAB><TAB><TAB>  tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB><TAB><TAB>  tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  tags . append ( tag ) <TAB>  if tags != self . completer_model . stringList ( ) : <TAB><TAB>  self . completer_model . setStringList ( tags ) ","if "","" in orig_text :",if tag.startswith('-'):,False,25.585761294663467,94.1250300814364
1172,"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB>  names = set ( ) <TAB>  for path in lib_path . iterdir ( ) : <TAB><TAB>  name = path . name <TAB><TAB>  if name == "" __pycache__ "" : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB><TAB>  elif path . is_dir ( ) and "" . "" not in name : <TAB><TAB><TAB>  names . add ( name ) <TAB>  if packages : <TAB><TAB>  packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB><TAB>  if len ( names & packages ) == len ( packages ) : <TAB><TAB><TAB>  return packages <TAB>  return names ","if name . endswith ( "".py"" ) :",if path.is_dir() and name.startswith('.'):,False,50.07268335739368,93.64702844468654
1173,"def get_cloud_credential ( self ) : <TAB>  """"""Return the credential which is directly tied to the inventory source type."""""" <TAB>  credential = None <TAB>  for cred in self . credentials . all ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if cred . kind == self . source . replace ( "" ec2 "" , "" aws "" ) : <TAB><TAB><TAB><TAB>  credential = cred <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  # these need to be returned in the API credential field <TAB><TAB><TAB>  if cred . credential_type . kind != "" vault "" : <TAB><TAB><TAB><TAB>  credential = cred <TAB><TAB><TAB><TAB>  break <TAB>  return credential ",if self . source in CLOUD_PROVIDERS :,if cred.type.name == 'aws2':,False,62.861358363099676,95.5568903845655
1174,"def newickize ( clade ) : <TAB>  """"""Convert a node tree to a Newick tree string, recursively."""""" <TAB>  label = clade . name or "" "" <TAB>  if label : <TAB><TAB>  unquoted_label = re . match ( token_dict [ "" unquoted node label "" ] , label ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  label = "" ' %s ' "" % label . replace ( "" \\ "" , "" \\ \\ "" ) . replace ( "" ' "" , "" \\ ' "" ) <TAB>  if clade . is_terminal ( ) :<TAB># terminal <TAB><TAB>  return label + make_info_string ( clade , terminal = True ) <TAB>  else : <TAB><TAB>  subtrees = ( newickize ( sub ) for sub in clade ) <TAB><TAB>  return "" ( %s ) %s "" % ( "" , "" . join ( subtrees ) , label + make_info_string ( clade ) ) ",if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) :,if unquoted_label:,False,50.14800817288829,89.71725841626417
1175,"def __iter__ ( self ) : <TAB>  for name , value in self . _vars . store . data . items ( ) : <TAB><TAB>  source = self . _sources [ name ] <TAB><TAB>  prefix = self . _get_prefix ( value ) <TAB><TAB>  name = u "" {0} {{ {1} }} "" . format ( prefix , name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield ArgumentInfo ( name , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield VariableInfo ( name , value , source ) ",if source == self . ARGUMENT_SOURCE :,if source is None:,False,21.505275209187875,94.20575348833114
1176,"def filepath_enumerate ( paths ) : <TAB>  """"""Enumerate the file paths of all subfiles of the list of paths"""""" <TAB>  out = [ ] <TAB>  for path in paths : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out . append ( path ) <TAB><TAB>  else : <TAB><TAB><TAB>  for root , dirs , files in os . walk ( path ) : <TAB><TAB><TAB><TAB>  for name in files : <TAB><TAB><TAB><TAB><TAB>  out . append ( os . path . normpath ( os . path . join ( root , name ) ) ) <TAB>  return out ",if os . path . isfile ( path ) :,if os.path.isdir(path):,False,63.09842116967839,98.46375189435108
1177,"def del_ ( self , key ) : <TAB>  hash_ = self . hash ( key ) <TAB>  node_ = self . _table [ hash_ ] <TAB>  pre_node = None <TAB>  while node_ is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if pre_node is None : <TAB><TAB><TAB><TAB>  self . _table [ hash_ ] = node_ . next <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  pre_node . next = node_ . next <TAB><TAB><TAB>  self . _len - = 1 <TAB><TAB>  pre_node = node_ <TAB><TAB>  node_ = node_ . next ",if node_ . key == key :,if node_.next is not None:,False,33.41228564790198,96.9637097467493
1178,"def _recurse ( self , base_path , rel_source , rel_zip ) : <TAB>  submodules_path = Path ( base_path ) / "" submodules "" <TAB>  if not submodules_path . is_dir ( ) : <TAB><TAB>  return <TAB>  for submodule in submodules_path . iterdir ( ) : <TAB><TAB>  source_path = submodule / rel_source <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  output_path = submodule / rel_zip <TAB><TAB>  self . _build_lambdas ( source_path , output_path ) <TAB><TAB>  self . _recurse ( submodule , rel_source , rel_zip ) ",if not source_path . is_dir ( ) :,if not source_path.is_absolute():,False,31.22562597551192,98.52711397709152
1179,"def find_test_functions ( collections ) : <TAB>  if not isinstance ( collections , list ) : <TAB><TAB>  collections = [ collections ] <TAB>  functions = [ ] <TAB>  for collection in collections : <TAB><TAB>  if not isinstance ( collection , dict ) : <TAB><TAB><TAB>  collection = vars ( collection ) <TAB><TAB>  keys = collection . keys ( ) <TAB><TAB>  keys . sort ( ) <TAB><TAB>  for key in keys : <TAB><TAB><TAB>  value = collection [ key ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  functions . append ( value ) <TAB>  return functions ","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",if value is not None:,False,19.79715667367775,89.50667686423822
1180,"def __init__ ( <TAB>  self , <TAB>  classifier , <TAB>  layer_name = None , <TAB>  transpose = None , <TAB>  distance = None , <TAB>  copy_weights = True ,  ) : <TAB>  super ( ) . __init__ ( ) <TAB>  self . copy_weights = copy_weights <TAB>  ### set layer weights ### <TAB>  if layer_name is not None : <TAB><TAB>  self . set_weights ( getattr ( classifier , layer_name ) ) <TAB>  else : <TAB><TAB>  for x in self . possible_layer_names : <TAB><TAB><TAB>  layer = getattr ( classifier , x , None ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . set_weights ( layer ) <TAB><TAB><TAB><TAB>  break <TAB>  ### set distance measure ### <TAB>  self . distance = classifier . distance if distance is None else distance <TAB>  self . transpose = transpose ",if layer is not None :,if layer is not None:,False,57.67293524546611,100.00000000000004
1181,def multi_dev_generator ( self ) : <TAB>  for data in self . _data_loader ( ) : <TAB><TAB>  if len ( self . _tail_data ) < self . _base_number : <TAB><TAB><TAB>  self . _tail_data + = data <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield self . _tail_data <TAB><TAB><TAB>  self . _tail_data = [ ] ,if len ( self . _tail_data ) == self . _base_number :,if len(self._tail_data) > self._base_number:,False,22.27456734944892,97.18241258696202
1182,"def Resolve ( self , updater = None ) : <TAB>  if len ( self . Conflicts ) : <TAB><TAB>  for setting , edge in self . Conflicts : <TAB><TAB><TAB>  answer = self . AskUser ( self . Setting , setting ) <TAB><TAB><TAB>  if answer == Gtk . ResponseType . YES : <TAB><TAB><TAB><TAB>  value = setting . Value . split ( "" | "" ) <TAB><TAB><TAB><TAB>  value . remove ( edge ) <TAB><TAB><TAB><TAB>  setting . Value = "" | "" . join ( value ) <TAB><TAB><TAB><TAB>  if updater : <TAB><TAB><TAB><TAB><TAB>  updater . UpdateSetting ( setting ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB>  return True ",if answer == Gtk . ResponseType . NO :,if not len(self.Conflicts):,False,24.526694109077305,95.68345794842864
1183,"def _post_process_ttl ( zone ) : <TAB>  for name in zone : <TAB><TAB>  for record_type in zone [ name ] : <TAB><TAB><TAB>  records = zone [ name ] [ record_type ] <TAB><TAB><TAB>  if isinstance ( records , list ) : <TAB><TAB><TAB><TAB>  ttl = min ( [ x [ "" ttl "" ] for x in records ] ) <TAB><TAB><TAB><TAB>  for record in records : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" Using lowest TTL  {}  for the record set. Ignoring value  {} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB><TAB>  ttl , record [ "" ttl "" ] <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB><TAB>  record [ "" ttl "" ] = ttl ","if record [ ""ttl"" ] != ttl :",if ttl < 0:,False,56.706616211126374,96.57608116376848
1184,"def __init__ ( self , cmds , env , cleanup = [ ] ) : <TAB>  self . handle = None <TAB>  self . cmds = cmds <TAB>  self . env = env <TAB>  if cleanup : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cleanup = [ cleanup ] <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  cleanup = [ c for c in cleanup if callable ( c ) ] <TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB>  cleanup = [ ] <TAB>  self . cleanup = cleanup ",if callable ( cleanup ) :,"if isinstance(cleanup, basestring):",False,34.37581253372494,96.28505712097868
1185,"def _parse_data_of_birth ( cls , data_of_birth_string ) : <TAB>  if data_of_birth_string : <TAB><TAB>  format = "" % m/ %d / % Y "" <TAB><TAB>  try : <TAB><TAB><TAB>  parsed_date = datetime . datetime . strptime ( data_of_birth_string , format ) <TAB><TAB><TAB>  return parsed_date <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  # Facebook sometimes provides a partial date format <TAB><TAB><TAB>  # ie 04/07 (ignore those) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ","if data_of_birth_string . count ( ""/"" ) != 1 :","if not isinstance(data_of_birth_string, str):",False,58.810307570633604,93.1953118889709
1186,"def process_lib ( vars_ , coreval ) : <TAB>  for d in vars_ : <TAB><TAB>  var = d . upper ( ) <TAB><TAB>  if var == "" QTCORE "" : <TAB><TAB><TAB>  continue <TAB><TAB>  value = env [ "" LIBPATH_ "" + var ] <TAB><TAB>  if value : <TAB><TAB><TAB>  core = env [ coreval ] <TAB><TAB><TAB>  accu = [ ] <TAB><TAB><TAB>  for lib in value : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  accu . append ( lib ) <TAB><TAB><TAB>  env [ "" LIBPATH_ "" + var ] = accu ",if lib in core :,if lib == core:,False,51.06425157548111,98.2046638126254
1187,"def throttle_status ( server = None ) : <TAB>  result = AmonStruct ( ) <TAB>  result . allow = False <TAB>  last_check = server . get ( "" last_check "" ) <TAB>  server_check_period = server . get ( "" check_every "" , 60 ) <TAB>  if last_check : <TAB><TAB>  period_since_last_check = unix_utc_now ( ) - last_check <TAB><TAB>  # Add 15 seconds buffer, for statsd <TAB><TAB>  period_since_last_check = period_since_last_check + 15 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . allow = True <TAB>  else : <TAB><TAB>  result . allow = True<TAB># Never checked <TAB>  return result ",if period_since_last_check >= server_check_period :,if server_check_period < max_period:,False,55.92276524083515,93.99801404965973
1188,"def fetch_scatter_outputs ( self , task ) : <TAB>  scatteroutputs = [ ] <TAB>  for var in task [ "" body "" ] : <TAB><TAB>  # TODO variable support <TAB><TAB>  if var . startswith ( "" call "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for output in self . tasks_dictionary [ task [ "" body "" ] [ var ] [ "" task "" ] ] [ <TAB><TAB><TAB><TAB><TAB>  "" outputs "" <TAB><TAB><TAB><TAB>  ] : <TAB><TAB><TAB><TAB><TAB>  scatteroutputs . append ( <TAB><TAB><TAB><TAB><TAB><TAB>  { "" task "" : task [ "" body "" ] [ var ] [ "" alias "" ] , "" output "" : output [ 0 ] } <TAB><TAB><TAB><TAB><TAB>  ) <TAB>  return scatteroutputs ","if ""outputs"" in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :",if var in self.tasks_dictionary:,False,51.16278906765083,91.01825370803547
1189,"def _add_constant_node ( self , source_node ) : <TAB>  parent_ids = range ( len ( source_node . in_edges ) ) <TAB>  for idx in parent_ids : <TAB><TAB>  parent_node = self . tf_graph . get_node ( source_node . in_edges [ idx ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _rename_Const ( parent_node ) ","if parent_node . type == ""Const"" :",if parent_node:,False,20.445166836205473,92.3194184259913
1190,"def enableCtrls ( self ) : <TAB>  # Check if each ctrl has a requirement or an incompatibility, <TAB>  # look it up, and enable/disable if so <TAB>  for data in self . storySettingsData : <TAB><TAB>  name = data [ "" name "" ] <TAB><TAB>  if name in self . ctrls : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  set = self . getSetting ( data [ "" requires "" ] ) <TAB><TAB><TAB><TAB>  for i in self . ctrls [ name ] : <TAB><TAB><TAB><TAB><TAB>  i . Enable ( set not in [ "" off "" , "" false "" , "" 0 "" ] ) ","if ""requires"" in data :",if name not in self.ctrls:,False,38.560138833199474,95.73787491900966
1191,"def update_realtime ( self , stdout = "" "" , stderr = "" "" , delete = False ) : <TAB>  wooey_cache = wooey_settings . WOOEY_REALTIME_CACHE <TAB>  if delete == False and wooey_cache is None : <TAB><TAB>  self . stdout = stdout <TAB><TAB>  self . stderr = stderr <TAB><TAB>  self . save ( ) <TAB>  elif wooey_cache is not None : <TAB><TAB>  cache = django_cache [ wooey_cache ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cache . delete ( self . get_realtime_key ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  cache . set ( <TAB><TAB><TAB><TAB>  self . get_realtime_key ( ) , <TAB><TAB><TAB><TAB>  json . dumps ( { "" stdout "" : stdout , "" stderr "" : stderr } ) , <TAB><TAB><TAB>  ) ",if delete :,if delete == True and cache.exists(self.get_realtime_key()):,False,56.66100795634059,92.05347494245561
1192,"def _check_for_batch_clashes ( xs ) : <TAB>  """"""Check that batch names do not overlap with sample names."""""" <TAB>  names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB>  dups = set ( [ ] ) <TAB>  for x in xs : <TAB><TAB>  batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB><TAB>  if batches : <TAB><TAB><TAB>  if not isinstance ( batches , ( list , tuple ) ) : <TAB><TAB><TAB><TAB>  batches = [ batches ] <TAB><TAB><TAB>  for batch in batches : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  dups . add ( batch ) <TAB>  if len ( dups ) > 0 : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" Batch names must be unique from sample descriptions. \n "" <TAB><TAB><TAB>  "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB><TAB>  ) ",if batch in names :,if len(batch) == len(names):,False,58.751498727113315,96.0165438935226
1193,"def toggle ( self , event = None ) : <TAB>  if self . absolute : <TAB><TAB>  if self . save == self . split : <TAB><TAB><TAB>  self . save = 100 <TAB><TAB>  if self . split > 20 : <TAB><TAB><TAB>  self . save = self . split <TAB><TAB><TAB>  self . split = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  self . split = self . save <TAB>  else : <TAB><TAB>  if self . save == self . split : <TAB><TAB><TAB>  self . save = 0.3 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . split = self . save <TAB><TAB>  elif self . split < 0.5 : <TAB><TAB><TAB>  self . split = self . min <TAB><TAB>  else : <TAB><TAB><TAB>  self . split = self . max <TAB>  self . placeChilds ( ) ",if self . split <= self . min or self . split >= self . max :,if self.split > 0.5:,False,26.044386014048303,94.12265561472461
1194,"def can_read ( self ) : <TAB>  if hasattr ( self . file , "" __iter__ "" ) : <TAB><TAB>  iterator = iter ( self . file ) <TAB><TAB>  head = next ( iterator , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . repaired = [ ] <TAB><TAB><TAB>  return True <TAB><TAB>  if isinstance ( head , str ) : <TAB><TAB><TAB>  self . repaired = itertools . chain ( [ head ] , iterator ) <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  # We may have mangled a generator at this point, so just abort <TAB><TAB><TAB>  raise IOSourceError ( <TAB><TAB><TAB><TAB>  "" Could not open source:  %r  (mode:  %r ) "" <TAB><TAB><TAB><TAB>  % ( self . file , self . options [ "" mode "" ] ) <TAB><TAB><TAB>  ) <TAB>  return False ",if head is None :,if head is None:,False,61.882835736815366,100.00000000000004
1195,"def _print_message_content ( self , peer , data ) : <TAB>  inheaders = 1 <TAB>  lines = data . splitlines ( ) <TAB>  for line in lines : <TAB><TAB>  # headers first <TAB><TAB>  if inheaders and not line : <TAB><TAB><TAB>  peerheader = "" X-Peer:  "" + peer [ 0 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # decoded_data=false; make header match other binary output <TAB><TAB><TAB><TAB>  peerheader = repr ( peerheader . encode ( "" utf-8 "" ) ) <TAB><TAB><TAB>  print ( peerheader ) <TAB><TAB><TAB>  inheaders = 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Avoid spurious 'str on bytes instance' warning. <TAB><TAB><TAB>  line = repr ( line ) <TAB><TAB>  print ( line ) ","if not isinstance ( data , str ) :",if inheaders:,False,59.33109082516719,92.06515079232013
1196,"def connect ( self ) : <TAB>  # Makes connection with MySQL server <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  connection = pymysql . connect ( read_default_file = "" /etc/mysql/conf.d/my.cnf "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  connection = pymysql . connect ( read_default_file = "" ~/.my.cnf "" ) <TAB><TAB>  return connection <TAB>  except ValueError as e : <TAB><TAB>  Log . debug ( self , str ( e ) ) <TAB><TAB>  raise MySQLConnectionError <TAB>  except pymysql . err . InternalError as e : <TAB><TAB>  Log . debug ( self , str ( e ) ) <TAB><TAB>  raise MySQLConnectionError ","if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :",if os.name == 'nt':,False,29.697122526918072,89.49669464084266
1197,"def _copy_package_apps ( <TAB>  local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" ""  ) - > None : <TAB>  for src_unresolved in app_paths : <TAB><TAB>  src = src_unresolved . resolve ( ) <TAB><TAB>  app = src . name <TAB><TAB>  dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB><TAB>  if not dest . parent . is_dir ( ) : <TAB><TAB><TAB>  mkdir ( dest . parent ) <TAB><TAB>  if dest . exists ( ) : <TAB><TAB><TAB>  logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB><TAB><TAB>  dest . unlink ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shutil . copy ( src , dest ) ",if src . exists ( ) :,if os.path.exists(dest):,False,22.86125748473245,96.92658767930764
1198,"def update ( self , x , who = None , metadata = None ) : <TAB>  self . _retain_refs ( metadata ) <TAB>  y = self . _get_key ( x ) <TAB>  if self . keep == "" last "" : <TAB><TAB>  # remove key if already present so that emitted value <TAB><TAB>  # will reflect elements' actual relative ordering <TAB><TAB>  self . _buffer . pop ( y , None ) <TAB><TAB>  self . _metadata_buffer . pop ( y , None ) <TAB><TAB>  self . _buffer [ y ] = x <TAB><TAB>  self . _metadata_buffer [ y ] = metadata <TAB>  else :<TAB># self.keep == ""first"" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _buffer [ y ] = x <TAB><TAB><TAB>  self . _metadata_buffer [ y ] = metadata <TAB>  return self . last ",if y not in self . _buffer :,if who == 'first':,False,58.96466007101624,95.53515914047988
1199,"def resolve_credential_keys ( m_keys , keys ) : <TAB>  res = [ ] <TAB>  for k in m_keys : <TAB><TAB>  if k [ "" c7n:match-type "" ] == "" credential "" : <TAB><TAB><TAB>  c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB><TAB><TAB>  for ak in keys : <TAB><TAB><TAB><TAB>  if c_date == ak [ "" CreateDate "" ] : <TAB><TAB><TAB><TAB><TAB>  ak = dict ( ak ) <TAB><TAB><TAB><TAB><TAB>  ak [ "" c7n:match-type "" ] = "" access "" <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  res . append ( ak ) <TAB><TAB>  elif k not in res : <TAB><TAB><TAB>  res . append ( k ) <TAB>  return res ",if ak not in res :,if k in res:,False,34.260050986670656,98.54309026474702
1200,"def _apply_flag_attrs ( src_flag , dest_flag ) : <TAB>  # Use a baseline flag def to get default values for empty data. <TAB>  baseline_flag = FlagDef ( "" "" , { } , None ) <TAB>  for name in dir ( src_flag ) : <TAB><TAB>  if name [ : 1 ] == "" _ "" : <TAB><TAB><TAB>  continue <TAB><TAB>  dest_val = getattr ( dest_flag , name , None ) <TAB><TAB>  baseline_val = getattr ( baseline_flag , name , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( dest_flag , name , getattr ( src_flag , name ) ) ",if dest_val == baseline_val :,if baseline_val is not None:,False,35.708509227128175,95.34778604376685
1201,"def _ws_keep_reading ( self ) : <TAB>  import websockets . exceptions <TAB>  while not self . _reader_stopped : <TAB><TAB>  try : <TAB><TAB><TAB>  data = await self . _ws . recv ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data = data . encode ( "" UTF-8 "" ) <TAB><TAB><TAB>  if len ( data ) == 0 : <TAB><TAB><TAB><TAB>  self . _error = "" EOF "" <TAB><TAB><TAB><TAB>  break <TAB><TAB>  except websockets . exceptions . ConnectionClosedError : <TAB><TAB><TAB>  # TODO: try to reconnect in case of Ctrl+D <TAB><TAB><TAB>  self . _error = "" EOF "" <TAB><TAB><TAB>  break <TAB><TAB>  self . num_bytes_received + = len ( data ) <TAB><TAB>  self . _make_output_available ( data , block = False ) ","if isinstance ( data , str ) :","if isinstance(data, unicode):",False,57.82476661663407,98.98678591079545
1202,"def to_dict ( self ) - > Dict [ str , Any ] : <TAB>  result = { } <TAB>  for field_name in self . API_FIELDS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ "" stream_id "" ] = self . id <TAB><TAB><TAB>  continue <TAB><TAB>  elif field_name == "" date_created "" : <TAB><TAB><TAB>  result [ "" date_created "" ] = datetime_to_timestamp ( self . date_created ) <TAB><TAB><TAB>  continue <TAB><TAB>  result [ field_name ] = getattr ( self , field_name ) <TAB>  result [ "" is_announcement_only "" ] = ( <TAB><TAB>  self . stream_post_policy == Stream . STREAM_POST_POLICY_ADMINS <TAB>  ) <TAB>  return result ","if field_name == ""id"" :","if field_name == ""stream_id':",False,17.905147812414935,97.85784742388435
1203,"def all_masks ( <TAB>  cls , <TAB>  images , <TAB>  run , <TAB>  run_key , <TAB>  step ,  ) : <TAB>  all_mask_groups = [ ] <TAB>  for image in images : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mask_group = { } <TAB><TAB><TAB>  for k in image . _masks : <TAB><TAB><TAB><TAB>  mask = image . _masks [ k ] <TAB><TAB><TAB><TAB>  mask_group [ k ] = mask . to_json ( run ) <TAB><TAB><TAB>  all_mask_groups . append ( mask_group ) <TAB><TAB>  else : <TAB><TAB><TAB>  all_mask_groups . append ( None ) <TAB>  if all_mask_groups and not all ( x is None for x in all_mask_groups ) : <TAB><TAB>  return all_mask_groups <TAB>  else : <TAB><TAB>  return False ",if image . _masks :,if run_key == image.run_key:,False,54.859829339523934,95.76592575202454
1204,"def disconnect_all ( listener ) : <TAB>  """"""Disconnect from all signals"""""" <TAB>  for emitter in listener . _signal_data . emitters : <TAB><TAB>  for signal in emitter . _signal_data . listeners : <TAB><TAB><TAB>  emitter . _signal_data . listeners [ signal ] = [ <TAB><TAB><TAB><TAB>  i <TAB><TAB><TAB><TAB>  for i in emitter . _signal_data . listeners [ signal ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ] ","if getattr ( i , ""__self__"" , None ) != listener",if i._signal_data.listeners[signal] == [i._signal_data.,False,30.947552630982727,86.62144355188495
1205,"def wait ( self , timeout = None ) : <TAB>  if self . returncode is None : <TAB><TAB>  if timeout is None : <TAB><TAB><TAB>  msecs = _subprocess . INFINITE <TAB><TAB>  else : <TAB><TAB><TAB>  msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB><TAB>  res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB><TAB>  if res == _subprocess . WAIT_OBJECT_0 : <TAB><TAB><TAB>  code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  code = - signal . SIGTERM <TAB><TAB><TAB>  self . returncode = code <TAB>  return self . returncode ",if code == TERMINATE :,if code is _subprocess.WAIT_OBJECT_0:,False,27.3373201592087,92.96871353524844
1206,"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB>  gtk . gdk . threads_enter ( ) <TAB>  try : <TAB><TAB>  self . is_pulsing = False <TAB><TAB>  self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB><TAB>  self . pbar . set_text ( progress ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frac = 1.0 <TAB><TAB>  if frac < 0 : <TAB><TAB><TAB>  frac = 0 <TAB><TAB>  self . pbar . set_fraction ( frac ) <TAB>  finally : <TAB><TAB>  gtk . gdk . threads_leave ( ) ",if frac > 1 :,if frac > 1.0:,False,24.663999195599303,98.52711397709152
1207,"def get_aa_from_codonre ( re_aa ) : <TAB>  aas = [ ] <TAB>  m = 0 <TAB>  for i in re_aa : <TAB><TAB>  if i == "" [ "" : <TAB><TAB><TAB>  m = - 1 <TAB><TAB><TAB>  aas . append ( "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  m = 0 <TAB><TAB><TAB>  continue <TAB><TAB>  elif m == - 1 : <TAB><TAB><TAB>  aas [ - 1 ] = aas [ - 1 ] + i <TAB><TAB>  elif m == 0 : <TAB><TAB><TAB>  aas . append ( i ) <TAB>  return aas ","elif i == ""]"" :",if m == 1:,False,27.71925721690168,88.90108624877452
1208,"def link ( token , base_url ) : <TAB>  """"""Validation for ``link``."""""" <TAB>  if get_keyword ( token ) == "" none "" : <TAB><TAB>  return "" none "" <TAB>  parsed_url = get_url ( token , base_url ) <TAB>  if parsed_url : <TAB><TAB>  return parsed_url <TAB>  function = parse_function ( token ) <TAB>  if function : <TAB><TAB>  name , args = function <TAB><TAB>  prototype = ( name , [ a . type for a in args ] ) <TAB><TAB>  args = [ getattr ( a , "" value "" , a ) for a in args ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ( "" attr() "" , args [ 0 ] ) ","if prototype == ( ""attr"" , [ ""ident"" ] ) :",if prototype is not None:,False,22.31806812464993,92.7867950779739
1209,"def on_bt_search_clicked ( self , widget ) : <TAB>  if self . current_provider is None : <TAB><TAB>  return <TAB>  query = self . en_query . get_text ( ) <TAB>  @self . obtain_podcasts_with <TAB>  def load_data ( ) : <TAB><TAB>  if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB><TAB><TAB>  return self . current_provider . on_search ( query ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . current_provider . on_url ( query ) <TAB><TAB>  elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB><TAB><TAB>  return self . current_provider . on_file ( query ) ",elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,if self.current_provider.kind == directory.Provider.PROVIDER_URL:,False,50.86647023711925,98.78485915987739
1210,"def test_handle_single ( self ) : <TAB>  self . skipTest ( <TAB><TAB>  "" Pops up windows and needs user input.. so disabled. "" <TAB><TAB>  "" Still worth keeping whilst we don ' t have unit tests  "" <TAB><TAB>  "" for all plugins. "" <TAB>  ) <TAB>  # Ignored... <TAB>  for id_ , plugin in self . plugins . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . h . plugin_enable ( plugin , None ) <TAB><TAB><TAB>  self . h . handle ( id_ , self . lib , self . parent , SONGS ) <TAB><TAB><TAB>  self . h . plugin_disable ( plugin ) ",if self . h . plugin_handle ( plugin ) :,if plugin.is_enabled():,False,60.91204044564827,93.2811999192949
1211,"def __repr__ ( self ) : <TAB>  attrs = [ ] <TAB>  for k in self . _keydata : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB><TAB>  elif hasattr ( self , k ) : <TAB><TAB><TAB>  attrs . append ( k ) <TAB>  if self . has_private ( ) : <TAB><TAB>  attrs . append ( "" private "" ) <TAB>  # PY3K: This is meant to be text, do not change to bytes (data) <TAB>  return "" < %s  @0x %x %s > "" % ( self . __class__ . __name__ , id ( self ) , "" , "" . join ( attrs ) ) ","if k == ""p"" :",if k == 'size':,False,61.80392306693393,97.6838685016374
1212,"def apply ( self , node , code , required ) : <TAB>  yield "" try: "" <TAB>  yield from self . iterIndented ( code ) <TAB>  yield ""<TAB> pass "" <TAB>  yield "" except  {} : "" . format ( self . exceptionString ) <TAB>  outputVariables = node . getOutputSocketVariables ( ) <TAB>  for i , s in enumerate ( node . outputs ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if hasattr ( s , "" getDefaultValueCode "" ) : <TAB><TAB><TAB><TAB>  yield f ""<TAB>  { outputVariables [ s . identifier ] }  =  { s . getDefaultValueCode ( ) } "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield f ""<TAB>  { outputVariables [ s . identifier ] }  = self.outputs[ { i } ].getDefaultValue() "" <TAB>  yield ""<TAB> pass "" ",if s . identifier in required :,if s.identifier not in outputVariables:,False,45.81204403534751,97.9746928229485
1213,"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB>  module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB>  if fromlist and module . __name__ in modules : <TAB><TAB>  if "" * "" in fromlist : <TAB><TAB><TAB>  fromlist = list ( fromlist ) <TAB><TAB><TAB>  fromlist . remove ( "" * "" ) <TAB><TAB><TAB>  fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB><TAB>  for x in fromlist : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB><TAB><TAB><TAB>  if from_name in modules : <TAB><TAB><TAB><TAB><TAB>  importlib . import_module ( from_name ) <TAB>  return module ","if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :",if x.__name__ == name:,False,50.77258657797439,93.8449984547307
1214,"def _consume_msg ( self ) : <TAB>  ws = self . _ws <TAB>  try : <TAB><TAB>  while True : <TAB><TAB><TAB>  r = await ws . recv ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  r = r . decode ( "" utf-8 "" ) <TAB><TAB><TAB>  msg = json . loads ( r ) <TAB><TAB><TAB>  stream = msg . get ( "" stream "" ) <TAB><TAB><TAB>  if stream is not None : <TAB><TAB><TAB><TAB>  await self . _dispatch ( stream , msg ) <TAB>  except websockets . WebSocketException as wse : <TAB><TAB>  logging . warn ( wse ) <TAB><TAB>  await self . close ( ) <TAB><TAB>  asyncio . ensure_future ( self . _ensure_ws ( ) ) ","if isinstance ( r , bytes ) :","if isinstance(r, unicode):",False,51.86786953903925,98.83034336405589
1215,"def add_source ( self , source , name = None ) : <TAB>  """"""Adds a new data source to an existing provider."""""" <TAB>  if self . randomize : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Cannot add a non-shuffleable source to an  "" <TAB><TAB><TAB><TAB>  "" already shuffled provider. "" <TAB><TAB><TAB>  ) <TAB>  super ( ) . add_source ( source , name = name ) <TAB>  if self . randomize is True : <TAB><TAB>  self . _shuffle_len = self . entries ",if not source . can_shuffle ( ) :,if self._shuffle_len == 0:,False,57.79586359529443,94.05966940399223
1216,"def __str__ ( self ) : <TAB>  buf = [ "" "" ] <TAB>  if self . fileName : <TAB><TAB>  buf . append ( self . fileName + "" : "" ) <TAB>  if self . line != - 1 : <TAB><TAB>  if not self . fileName : <TAB><TAB><TAB>  buf . append ( "" line  "" ) <TAB><TAB>  buf . append ( str ( self . line ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  buf . append ( "" : "" + str ( self . column ) ) <TAB><TAB>  buf . append ( "" : "" ) <TAB>  buf . append ( "" "" ) <TAB>  return str ( "" "" ) . join ( buf ) ",if self . column != - 1 :,if self.column != -1:,False,50.900318039501315,98.02201824717983
1217,"def has_bad_headers ( self ) : <TAB>  headers = [ self . sender , self . reply_to ] + self . recipients <TAB>  for header in headers : <TAB><TAB>  if _has_newline ( header ) : <TAB><TAB><TAB>  return True <TAB>  if self . subject : <TAB><TAB>  if _has_newline ( self . subject ) : <TAB><TAB><TAB>  for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB><TAB><TAB><TAB>  if not line : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  if linenum > 0 and line [ 0 ] not in "" \t "" : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  if _has_newline ( line ) : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if len ( line . strip ( ) ) == 0 :,if _has_newline(self.subject):,False,51.73244182942591,95.8205855862029
1218,"def scanHexEscape ( self , prefix ) : <TAB>  code = 0 <TAB>  leng = 4 if ( prefix == "" u "" ) else 2 <TAB>  for i in xrange ( leng ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ch = self . source [ self . index ] <TAB><TAB><TAB>  self . index + = 1 <TAB><TAB><TAB>  code = code * 16 + HEX_CONV [ ch ] <TAB><TAB>  else : <TAB><TAB><TAB>  return "" "" <TAB>  return unichr ( code ) ",if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,if self.source[self.index] in HEX_CONV:,False,38.86451559627718,91.45556983490447
1219,"def _get_table_info ( self , table_name ) : <TAB>  table_addr = self . addr_space . profile . get_symbol ( table_name ) <TAB>  table_size = self . _get_table_info_distorm ( ) <TAB>  <IF-STMT>: <TAB><TAB>  table_size = self . _get_table_info_other ( table_addr , table_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  debug . error ( "" Unable to get system call table size "" ) <TAB>  return [ table_addr , table_size ] ",if table_size == 0 :,if table_size is None:,False,23.378008611884805,91.01689700715971
1220,"def format_file_path ( filepath ) : <TAB>  """"""Formats a path as absolute and with the correct platform separator."""""" <TAB>  try : <TAB><TAB>  is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN . match ( filepath ) <TAB><TAB>  filepath = os . path . realpath ( os . path . abspath ( filepath ) ) <TAB><TAB>  filepath = re . sub ( BACKSLASH_REPLACE_PATTERN , "" / "" , filepath ) <TAB><TAB>  is_windows_drive = WINDOWS_DRIVE_PATTERN . match ( filepath ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filepath = filepath . capitalize ( ) <TAB><TAB>  if is_windows_network_mount : <TAB><TAB><TAB>  # Add back a / to the front, since the previous modifications <TAB><TAB><TAB>  # will have replaced any double slashes with single <TAB><TAB><TAB>  filepath = "" / "" + filepath <TAB>  except : <TAB><TAB>  pass <TAB>  return filepath ",if is_windows_drive :,if is_windows_drive:,False,66.73186299109113,100.00000000000004
1221,"def _match ( self , cre , s ) : <TAB>  # Run compiled regular expression match method on 's'. <TAB>  # Save result, return success. <TAB>  self . mo = cre . match ( s ) <TAB>  if __debug__ : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _mesg ( "" \t matched r ' %r '  =>  %r "" % ( cre . pattern , self . mo . groups ( ) ) ) <TAB>  return self . mo is not None ",if self . mo is not None and self . debug >= 5 :,if self.mo:,False,33.57753961214088,86.6333479388198
1222,"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB>  self . sanitize_allowlist = [ ] <TAB>  try : <TAB><TAB>  with open ( self . sanitize_allowlist_file ) as f : <TAB><TAB><TAB>  for line in f . readlines ( ) : <TAB><TAB><TAB><TAB>  if not line . startswith ( "" # "" ) : <TAB><TAB><TAB><TAB><TAB>  self . sanitize_allowlist . append ( line . strip ( ) ) <TAB>  except OSError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . warning ( <TAB><TAB><TAB><TAB>  "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB><TAB><TAB><TAB>  self . sanitize_allowlist_file , <TAB><TAB><TAB>  ) ",if explicit :,if explicit:,False,62.815706578752426,98.34867301206474
1223,"def conj ( self ) : <TAB>  dtype = self . dtype <TAB>  if issubclass ( self . dtype . type , np . complexfloating ) : <TAB><TAB>  if not self . flags . forc : <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  order = "" F "" <TAB><TAB>  else : <TAB><TAB><TAB>  order = "" C "" <TAB><TAB>  result = self . _new_like_me ( order = order ) <TAB><TAB>  func = elementwise . get_conj_kernel ( dtype ) <TAB><TAB>  func . prepared_async_call ( <TAB><TAB><TAB>  self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB><TAB>  ) <TAB><TAB>  return result <TAB>  else : <TAB><TAB>  return self ",if self . flags . f_contiguous :,if self.flags.forc:,False,54.98845074506703,98.25779613915081
1224,"def scan_spec_conf ( self , conf ) : <TAB>  if "" metadata "" in conf : <TAB><TAB>  if "" annotations "" in conf [ "" metadata "" ] and conf [ "" metadata "" ] . get ( "" annotations "" ) : <TAB><TAB><TAB>  for annotation in conf [ "" metadata "" ] [ "" annotations "" ] : <TAB><TAB><TAB><TAB>  for key in annotation : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" docker/default "" in annotation [ key ] <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  or "" runtime/default "" in annotation [ key ] <TAB><TAB><TAB><TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  return CheckResult . PASSED <TAB>  return CheckResult . FAILED ","if ""seccomp.security.alpha.kubernetes.io/defaultProfileName"" in key :",if key in conf:,False,24.619502464569482,93.77326862005619
1225,"def test_error_through_destructor ( self ) : <TAB>  # Test that the exception state is not modified by a destructor, <TAB>  # even if close() fails. <TAB>  rawio = self . CloseFailureIO ( ) <TAB>  with support . catch_unraisable_exception ( ) as cm : <TAB><TAB>  with self . assertRaises ( AttributeError ) : <TAB><TAB><TAB>  self . tp ( rawio ) . xyzzy <TAB><TAB>  if not IOBASE_EMITS_UNRAISABLE : <TAB><TAB><TAB>  self . assertIsNone ( cm . unraisable ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( cm . unraisable . exc_type , OSError ) ",elif cm . unraisable is not None :,if sys.platform == 'win32':,False,37.35259386700477,94.9120174921946
1226,"def _dumpf ( frame ) : <TAB>  if frame is None : <TAB><TAB>  return "" <None> "" <TAB>  else : <TAB><TAB>  addn = "" (with trace!) "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  addn = ""  **No Trace Set ** "" <TAB><TAB>  return "" Frame at  %d , file  %s , line:  %d %s "" % ( <TAB><TAB><TAB>  id ( frame ) , <TAB><TAB><TAB>  frame . f_code . co_filename , <TAB><TAB><TAB>  frame . f_lineno , <TAB><TAB><TAB>  addn , <TAB><TAB>  ) ",if frame . f_trace is None :,if not frame.f_code.co_filename:,False,55.91831418747651,94.85446523328109
1227,"def containsBadbytes ( self , value , bytecount = 4 ) : <TAB>  for b in self . badbytes : <TAB><TAB>  tmp = value <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  b = ord ( b ) <TAB><TAB>  for i in range ( bytecount ) : <TAB><TAB><TAB>  if ( tmp & 0xFF ) == b : <TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  tmp >> = 8 <TAB>  return False ",if type ( b ) == str :,if tmp & 0x00:,False,23.100080829508762,93.20200090052703
1228,"def _set_peer_statuses ( self ) : <TAB>  """"""Set peer statuses."""""" <TAB>  cutoff = time . time ( ) - STALE_SECS <TAB>  for peer in self . peers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  peer . status = PEER_BAD <TAB><TAB>  elif peer . last_good > cutoff : <TAB><TAB><TAB>  peer . status = PEER_GOOD <TAB><TAB>  elif peer . last_good : <TAB><TAB><TAB>  peer . status = PEER_STALE <TAB><TAB>  else : <TAB><TAB><TAB>  peer . status = PEER_NEVER ",if peer . bad :,if peer.status == PEER_GOOD:,False,48.460548333281004,95.37694615203544
1229,"def afterTest ( self , test ) : <TAB>  try : <TAB><TAB>  # If the browser window is still open, close it now. <TAB><TAB>  self . driver . quit ( ) <TAB>  except AttributeError : <TAB><TAB>  pass <TAB>  except Exception : <TAB><TAB>  pass <TAB>  if self . options . headless : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . display . stop ( ) <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  pass ",if self . headless_active :,if self.display:,False,64.08353719360993,97.38808495663733
1230,"def _written_variables_in_proxy ( self , contract ) : <TAB>  variables = [ ] <TAB>  if contract . is_upgradeable : <TAB><TAB>  variables_name_written_in_proxy = self . _variable_written_in_proxy ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  variables_in_contract = [ <TAB><TAB><TAB><TAB>  contract . get_state_variable_from_name ( v ) <TAB><TAB><TAB><TAB>  for v in variables_name_written_in_proxy <TAB><TAB><TAB>  ] <TAB><TAB><TAB>  variables_in_contract = [ v for v in variables_in_contract if v ] <TAB><TAB><TAB>  variables + = variables_in_contract <TAB>  return list ( set ( variables ) ) ",if variables_name_written_in_proxy :,if variables_name_written_in_proxy:,False,47.44080828642365,100.00000000000004
1231,"def _available_symbols ( self , scoperef , expr ) : <TAB>  cplns = [ ] <TAB>  found_names = set ( ) <TAB>  while scoperef : <TAB><TAB>  elem = self . _elem_from_scoperef ( scoperef ) <TAB><TAB>  for child in elem : <TAB><TAB><TAB>  name = child . get ( "" name "" , "" "" ) <TAB><TAB><TAB>  if name . startswith ( expr ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  found_names . add ( name ) <TAB><TAB><TAB><TAB><TAB>  ilk = child . get ( "" ilk "" ) or child . tag <TAB><TAB><TAB><TAB><TAB>  cplns . append ( ( ilk , name ) ) <TAB><TAB>  scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB><TAB>  if not scoperef : <TAB><TAB><TAB>  break <TAB>  return sorted ( cplns , key = operator . itemgetter ( 1 ) ) ",if name not in found_names :,if name not in found_names:,False,51.54505658193328,100.00000000000004
1232,"def get_resource_public_actions ( resource_class ) : <TAB>  resource_class_members = inspect . getmembers ( resource_class ) <TAB>  resource_methods = { } <TAB>  for name , member in resource_class_members : <TAB><TAB>  if not name . startswith ( "" _ "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if not name . startswith ( "" wait_until "" ) : <TAB><TAB><TAB><TAB><TAB>  if is_resource_action ( member ) : <TAB><TAB><TAB><TAB><TAB><TAB>  resource_methods [ name ] = member <TAB>  return resource_methods ",if not name [ 0 ] . isupper ( ) :,if name.startswith('wait_for'):,False,26.10809712707225,94.9130914695178
1233,def UpdateControlState ( self ) : <TAB>  active = self . demoModules . GetActiveID ( ) <TAB>  # Update the radio/restore buttons <TAB>  for moduleID in self . radioButtons : <TAB><TAB>  btn = self . radioButtons [ moduleID ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  btn . SetValue ( True ) <TAB><TAB>  else : <TAB><TAB><TAB>  btn . SetValue ( False ) <TAB><TAB>  if self . demoModules . Exists ( moduleID ) : <TAB><TAB><TAB>  btn . Enable ( True ) <TAB><TAB><TAB>  if moduleID == modModified : <TAB><TAB><TAB><TAB>  self . btnRestore . Enable ( True ) <TAB><TAB>  else : <TAB><TAB><TAB>  btn . Enable ( False ) <TAB><TAB><TAB>  if moduleID == modModified : <TAB><TAB><TAB><TAB>  self . btnRestore . Enable ( False ) ,if moduleID == active :,if active == btn.GetValue(0):,False,52.314116948210824,95.85035436355675
1234,"def test_controlcharacters ( self ) : <TAB>  for i in range ( 128 ) : <TAB><TAB>  c = chr ( i ) <TAB><TAB>  testString = "" string containing  %s "" % c <TAB><TAB>  if i > = 32 or c in "" \r \n \t "" : <TAB><TAB><TAB>  # \r, \n and \t are the only legal control chars in XML <TAB><TAB><TAB>  data = plistlib . dumps ( testString , fmt = plistlib . FMT_XML ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( plistlib . loads ( data ) , testString ) <TAB><TAB>  else : <TAB><TAB><TAB>  with self . assertRaises ( ValueError ) : <TAB><TAB><TAB><TAB>  plistlib . dumps ( testString , fmt = plistlib . FMT_XML ) <TAB><TAB>  plistlib . dumps ( testString , fmt = plistlib . FMT_BINARY ) ","if c != ""\r"" :",if data:,False,57.227256243732526,96.33986171332515
1235,"def remove_usernames ( self , username : SLT [ str ] ) - > None : <TAB>  with self . __lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  f "" Can ' t set  { self . username_name }  in conjunction with (already set)  "" <TAB><TAB><TAB><TAB>  f "" { self . chat_id_name } s. "" <TAB><TAB><TAB>  ) <TAB><TAB>  parsed_username = self . _parse_username ( username ) <TAB><TAB>  self . _usernames - = parsed_username ",if self . _chat_ids :,if self._usernames is None:,False,26.796599377926526,94.18995401842217
1236,"def get_size ( self , shape_info ) : <TAB>  # The size is the data, that have constant size. <TAB>  state = np . random . RandomState ( ) . get_state ( ) <TAB>  size = 0 <TAB>  for elem in state : <TAB><TAB>  if isinstance ( elem , str ) : <TAB><TAB><TAB>  size + = len ( elem ) <TAB><TAB>  elif isinstance ( elem , np . ndarray ) : <TAB><TAB><TAB>  size + = elem . size * elem . itemsize <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size + = np . dtype ( "" int "" ) . itemsize <TAB><TAB>  elif isinstance ( elem , float ) : <TAB><TAB><TAB>  size + = np . dtype ( "" float "" ) . itemsize <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError ( ) <TAB>  return size ","elif isinstance ( elem , int ) :","if isinstance(elem, int):",False,32.13232862086674,98.86228284909593
1237,"def before_step ( self , step , feed_dict ) : <TAB>  if step == 0 : <TAB><TAB>  for _type , mem in self . memories . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . gan . session . run ( tf . assign ( mem [ "" var "" ] , mem [ "" source "" ] ) ) ","if ""var"" in mem and ""source"" in mem :",if _type == 'step':,False,22.60926156657663,87.70427844078218
1238,"def write ( self , * bits ) : <TAB>  for bit in bits : <TAB><TAB>  if not self . bytestream : <TAB><TAB><TAB>  self . bytestream . append ( 0 ) <TAB><TAB>  byte = self . bytestream [ self . bytenum ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . bytenum == len ( self . bytestream ) - 1 : <TAB><TAB><TAB><TAB>  byte = 0 <TAB><TAB><TAB><TAB>  self . bytestream + = bytes ( [ byte ] ) <TAB><TAB><TAB>  self . bytenum + = 1 <TAB><TAB><TAB>  self . bitnum = 0 <TAB><TAB>  mask = 2 * * self . bitnum <TAB><TAB>  if bit : <TAB><TAB><TAB>  byte | = mask <TAB><TAB>  else : <TAB><TAB><TAB>  byte & = ~ mask <TAB><TAB>  self . bytestream [ self . bytenum ] = byte <TAB><TAB>  self . bitnum + = 1 ",if self . bitnum == 8 :,if byte & 0x1f:,False,18.9740306247335,97.01481440911019
1239,"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB>  """"""Placeholder docstring"""""" <TAB>  for ( <TAB><TAB>  parameter_range_key , <TAB><TAB>  parameter_range_value , <TAB>  ) in parameter_range . __dict__ . items ( ) : <TAB><TAB>  if parameter_range_key == "" scaling_type "" : <TAB><TAB><TAB>  continue <TAB><TAB>  # Categorical ranges <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for categorical_value in parameter_range_value : <TAB><TAB><TAB><TAB>  value_hp . validate ( categorical_value ) <TAB><TAB>  # Continuous, Integer ranges <TAB><TAB>  else : <TAB><TAB><TAB>  value_hp . validate ( parameter_range_value ) ","if isinstance ( parameter_range_value , list ) :",if parameter_range_key == 'categorical_range':,False,51.251430638201946,95.81231323208755
1240,"def _trackA ( self , tracks ) : <TAB>  try : <TAB><TAB>  track , start , end = self . featureA <TAB><TAB>  assert track in tracks <TAB><TAB>  return track <TAB>  except TypeError : <TAB><TAB>  for track in tracks : <TAB><TAB><TAB>  for feature_set in track . get_sets ( ) : <TAB><TAB><TAB><TAB>  if hasattr ( feature_set , "" features "" ) : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  return track <TAB><TAB>  return None ",if self . featureA in feature_set . features . values ( ) :,if feature_set.features[start] == feature_set.features[end]:,False,48.7634144205517,90.79269421313475
1241,"def walk ( directory , path_so_far ) : <TAB>  for name in sorted ( os . listdir ( directory ) ) : <TAB><TAB>  if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB><TAB><TAB>  continue <TAB><TAB>  path = path_so_far + "" / "" + name if path_so_far else name <TAB><TAB>  if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB><TAB><TAB>  continue <TAB><TAB>  full_name = os . path . join ( directory , name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for file_path in walk ( full_name , path ) : <TAB><TAB><TAB><TAB>  yield file_path <TAB><TAB>  elif os . path . isfile ( full_name ) : <TAB><TAB><TAB>  yield path ",if os . path . isdir ( full_name ) :,if os.path.isdir(full_name):,False,57.01011058043688,100.00000000000004
1242,"def _poll_ipc_requests ( self ) - > None : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  while not self . _ipc_requests . empty ( ) : <TAB><TAB><TAB>  args = self . _ipc_requests . get ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  for filename in args : <TAB><TAB><TAB><TAB><TAB>  if os . path . isfile ( filename ) : <TAB><TAB><TAB><TAB><TAB><TAB>  self . get_editor_notebook ( ) . show_file ( filename ) <TAB><TAB><TAB>  except Exception as e : <TAB><TAB><TAB><TAB>  logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB><TAB>  self . become_active_window ( ) <TAB>  finally : <TAB><TAB>  self . after ( 50 , self . _poll_ipc_requests ) ",if self . _ipc_requests . empty ( ) :,if self._ipc_requests.empty():,False,50.339783471014876,100.00000000000004
1243,"def test_read1 ( self ) : <TAB>  self . test_write ( ) <TAB>  blocks = [ ] <TAB>  nread = 0 <TAB>  with gzip . GzipFile ( self . filename , "" r "" ) as f : <TAB><TAB>  while True : <TAB><TAB><TAB>  d = f . read1 ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  blocks . append ( d ) <TAB><TAB><TAB>  nread + = len ( d ) <TAB><TAB><TAB>  # Check that position was updated correctly (see issue10791). <TAB><TAB><TAB>  self . assertEqual ( f . tell ( ) , nread ) <TAB>  self . assertEqual ( b "" "" . join ( blocks ) , data1 * 50 ) ",if not d :,if not d:,False,57.19693239424395,100.00000000000004
1244,"def _target_generator ( self ) : <TAB>  if self . _internal_target_generator is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  from . . . . model_zoo . rcnn . rpn . rpn_target import RPNTargetGenerator <TAB><TAB>  self . _internal_target_generator = RPNTargetGenerator ( <TAB><TAB><TAB>  num_sample = self . _num_sample , <TAB><TAB><TAB>  pos_iou_thresh = self . _pos_iou_thresh , <TAB><TAB><TAB>  neg_iou_thresh = self . _neg_iou_thresh , <TAB><TAB><TAB>  pos_ratio = self . _pos_ratio , <TAB><TAB><TAB>  stds = self . _box_norm , <TAB><TAB><TAB>  * * self . _kwargs <TAB><TAB>  ) <TAB><TAB>  return self . _internal_target_generator <TAB>  else : <TAB><TAB>  return self . _internal_target_generator ",if self . _net_none :,if self._internal_target_generator is None:,False,45.37349712506108,96.76667923358636
1245,"def time_left ( self ) : <TAB>  """"""Return how many seconds are left until the timeout expires"""""" <TAB>  if self . is_non_blocking : <TAB><TAB>  return 0 <TAB>  elif self . is_infinite : <TAB><TAB>  return None <TAB>  else : <TAB><TAB>  delta = self . target_time - self . TIME ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # clock jumped, recalculate <TAB><TAB><TAB>  self . target_time = self . TIME ( ) + self . duration <TAB><TAB><TAB>  return self . duration <TAB><TAB>  else : <TAB><TAB><TAB>  return max ( 0 , delta ) ",if delta > self . duration :,if delta < 0:,False,54.79455132031688,96.86291175776402
1246,"def _decorator ( cls ) : <TAB>  for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB><TAB>  if name not in cls . __dict__ : <TAB><TAB><TAB>  continue <TAB><TAB>  if name != "" __init__ "" : <TAB><TAB><TAB>  if not private and name . startswith ( "" _ "" ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  setattr ( cls , name , decorator ( meth ) ) <TAB>  return cls ",if name in butnot :,if not callable(meth):,False,23.347108858692316,95.67216592937487
1247,"def load_vocab ( vocab_file : str ) - > List : <TAB>  """"""Loads a vocabulary file into a dictionary."""""" <TAB>  vocab = collections . OrderedDict ( ) <TAB>  with io . open ( vocab_file , "" r "" , encoding = "" UTF-8 "" ) as file : <TAB><TAB>  for num , line in enumerate ( file ) : <TAB><TAB><TAB>  items = convert_to_unicode ( line . strip ( ) ) . split ( "" \t "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  token = items [ 0 ] <TAB><TAB><TAB>  index = items [ 1 ] if len ( items ) == 2 else num <TAB><TAB><TAB>  token = token . strip ( ) <TAB><TAB><TAB>  vocab [ token ] = int ( index ) <TAB><TAB>  return vocab ",if len ( items ) > 2 :,if num == 2:,False,35.846316689589344,97.10273979638033
1248,"def slice_fill ( self , slice_ ) : <TAB>  "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB>  if isinstance ( self . indexes , int ) : <TAB><TAB>  new_slice_ = [ 0 ] <TAB><TAB>  offset = 0 <TAB>  else : <TAB><TAB>  new_slice_ = [ slice_ [ 0 ] ] <TAB><TAB>  offset = 1 <TAB>  for i in range ( 1 , len ( self . nums ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_slice_ . append ( 0 ) <TAB><TAB>  elif offset < len ( slice_ ) : <TAB><TAB><TAB>  new_slice_ . append ( slice_ [ offset ] ) <TAB><TAB><TAB>  offset + = 1 <TAB>  new_slice_ + = slice_ [ offset : ] <TAB>  return new_slice_ ",if self . squeeze_dims [ i ] :,if slice_[i] == 0:,False,32.08179023098754,96.53504148762481
1249,"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB>  remote_version = urllib . urlopen ( url ) . read ( ) <TAB>  if remote_version . isdigit ( ) : <TAB><TAB>  local_version = get_local_timestamp ( folder ) <TAB><TAB>  if remote_version > local_version : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  update_setter . set_value ( True ) <TAB><TAB><TAB>  version_setter . set_value ( remote_version ) <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  else : <TAB><TAB>  return False ",if auto :,if auto:,False,51.004986416081245,100.00000000000004
1250,"def iter_content ( self , chunk_size_bytes ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  data = self . _fp . read ( chunk_size_bytes ) <TAB><TAB>  except IOError as e : <TAB><TAB><TAB>  raise Fetcher . PermanentError ( <TAB><TAB><TAB><TAB>  "" Problem reading chunk from  {} :  {} "" . format ( self . _fp . name , e ) <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  yield data ",if not data :,if not data:,False,52.50131889608171,100.00000000000004
1251,"def gvariant_args ( args : List [ Any ] ) - > str : <TAB>  """"""Convert args into gvariant."""""" <TAB>  gvariant = "" "" <TAB>  for arg in args : <TAB><TAB>  if isinstance ( arg , bool ) : <TAB><TAB><TAB>  gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB><TAB>  elif isinstance ( arg , ( int , float ) ) : <TAB><TAB><TAB>  gvariant + = f "" { arg } "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gvariant + = f ' "" { arg } "" ' <TAB><TAB>  else : <TAB><TAB><TAB>  gvariant + = f "" { arg !s} "" <TAB>  return gvariant . lstrip ( ) ","elif isinstance ( arg , str ) :","if isinstance(arg, str):",False,42.474801814587295,96.8690798650169
1252,"def _element_keywords ( cls , backend , elements = None ) : <TAB>  "" Returns a dictionary of element names to allowed keywords "" <TAB>  if backend not in Store . loaded_backends ( ) : <TAB><TAB>  return { } <TAB>  mapping = { } <TAB>  backend_options = Store . options ( backend ) <TAB>  elements = elements if elements is not None else backend_options . keys ( ) <TAB>  for element in elements : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  element = element if isinstance ( element , tuple ) else ( element , ) <TAB><TAB>  element_keywords = [ ] <TAB><TAB>  options = backend_options [ "" . "" . join ( element ) ] <TAB><TAB>  for group in Options . _option_groups : <TAB><TAB><TAB>  element_keywords . extend ( options [ group ] . allowed_keywords ) <TAB><TAB>  mapping [ element [ 0 ] ] = element_keywords <TAB>  return mapping ","if ""."" in element :","if not isinstance(element, basestring):",False,47.03841015454283,96.55034878042655
1253,"def setup_parameter_node ( self , param_node ) : <TAB>  if param_node . bl_idname == "" SvNumberNode "" : <TAB><TAB>  if self . use_prop or self . get_prop_name ( ) : <TAB><TAB><TAB>  value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB><TAB><TAB>  print ( "" V "" , value ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  param_node . selected_mode = "" int "" <TAB><TAB><TAB><TAB>  param_node . int_ = value <TAB><TAB><TAB>  elif isinstance ( value , float ) : <TAB><TAB><TAB><TAB>  param_node . selected_mode = "" float "" <TAB><TAB><TAB><TAB>  param_node . float_ = value ","if isinstance ( value , int ) :","if isinstance(value, int):",False,50.82633410562335,100.00000000000004
1254,"def _get_oshape ( indices_shape , depth , axis ) : <TAB>  oshape = [ ] <TAB>  true_axis = len ( indices_shape ) if axis == - 1 else axis <TAB>  ndim = len ( indices_shape ) + 1 <TAB>  indices_index = 0 <TAB>  for i in range ( 0 , ndim ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  oshape . append ( depth ) <TAB><TAB>  else : <TAB><TAB><TAB>  oshape . append ( indices_shape [ indices_index ] ) <TAB><TAB><TAB>  indices_index + = 1 <TAB>  return oshape ",if i == true_axis :,if indices_index + 1 == ndim:,False,20.298712009987188,92.2900705454319
1255,"def check ( self , value ) : <TAB>  value = String . check ( self , value ) <TAB>  if isinstance ( value , str ) : <TAB><TAB>  value = value . upper ( ) <TAB><TAB>  for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB><TAB><TAB>  # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = value [ len ( prefix ) : ] <TAB><TAB><TAB>  value = value . lstrip ( "" _ "" ) <TAB><TAB>  if hasattr ( self . group , value ) : <TAB><TAB><TAB>  return getattr ( self . group , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" No such constant:  %s _ %s "" % ( self . prefix , value ) ) <TAB>  else : <TAB><TAB>  return value ",if value . startswith ( prefix ) :,if prefix.startswith(prefix):,False,56.89710067378719,98.9949330384878
1256,"def shuffle_unison_inplace ( list_of_lists , random_state = None ) : <TAB>  if list_of_lists : <TAB><TAB>  assert all ( len ( l ) == len ( list_of_lists [ 0 ] ) for l in list_of_lists ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  random_state . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  p = np . random . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB><TAB>  return [ l [ p ] for l in list_of_lists ] <TAB>  return None ",if random_state is not None :,if random_state:,False,49.35437125484785,97.30657055799949
1257,"def _load_module ( self ) : <TAB>  spec = self . default_module_spec <TAB>  module_identifier = self . module_identifier <TAB>  if module_identifier : <TAB><TAB>  impls = self . get_module_implementation_map ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ModuleNotFound ( <TAB><TAB><TAB><TAB>  "" Invalid module identifier  %r  in  %s "" <TAB><TAB><TAB><TAB>  % ( module_identifier , force_ascii ( repr ( self ) ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  spec = impls [ module_identifier ] <TAB>  cls = load ( <TAB><TAB>  spec , context_explanation = "" Loading module for  %s "" % force_ascii ( repr ( self ) ) <TAB>  ) <TAB>  options = getattr ( self , self . module_options_field , None ) or { } <TAB>  return cls ( self , options ) ",if module_identifier not in impls :,if module_identifier not in impls:,False,53.98977466361963,100.00000000000004
1258,"def get_data ( self , state = None , request = None ) : <TAB>  if self . load_in_memory : <TAB><TAB>  data , shapes = self . _in_memory_get_data ( state , request ) <TAB>  else : <TAB><TAB>  data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB>  for i in range ( len ( data ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( request , numbers . Integral ) : <TAB><TAB><TAB><TAB>  data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  for j in range ( len ( data [ i ] ) ) : <TAB><TAB><TAB><TAB><TAB>  data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB>  return tuple ( data ) ",if shapes [ i ] is not None :,"if state.get('in_memory', False):",False,49.684985845753616,95.38752896363414
1259,"def resolve_credential_keys ( m_keys , keys ) : <TAB>  res = [ ] <TAB>  for k in m_keys : <TAB><TAB>  if k [ "" c7n:match-type "" ] == "" credential "" : <TAB><TAB><TAB>  c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB><TAB><TAB>  for ak in keys : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  ak = dict ( ak ) <TAB><TAB><TAB><TAB><TAB>  ak [ "" c7n:match-type "" ] = "" access "" <TAB><TAB><TAB><TAB><TAB>  if ak not in res : <TAB><TAB><TAB><TAB><TAB><TAB>  res . append ( ak ) <TAB><TAB>  elif k not in res : <TAB><TAB><TAB>  res . append ( k ) <TAB>  return res ","if c_date == ak [ ""CreateDate"" ] :",if c_date <= k['c7n:,False,25.807712782913217,96.25104886760832
1260,"def _is_legacy_mode ( self , node ) : <TAB>  """"""Checks if the ``ast.Call`` node's keywords signal using legacy mode."""""" <TAB>  script_mode = False <TAB>  py_version = "" py2 "" <TAB>  for kw in node . keywords : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  script_mode = ( <TAB><TAB><TAB><TAB>  bool ( kw . value . value ) if isinstance ( kw . value , ast . NameConstant ) else True <TAB><TAB><TAB>  ) <TAB><TAB>  if kw . arg == "" py_version "" : <TAB><TAB><TAB>  py_version = kw . value . s if isinstance ( kw . value , ast . Str ) else "" py3 "" <TAB>  return not ( py_version . startswith ( "" py3 "" ) or script_mode ) ","if kw . arg == ""script_mode"" :","if isinstance(kw.value, ast.NameConstant):",False,55.09250720260255,94.93179392273782
1261,"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB>  statuses_by_refs = { u : [ ] for u in upstream } <TAB>  events = self . events or [ ]<TAB># type: List[V1EventTrigger] <TAB>  for e in events : <TAB><TAB>  entity_ref = contexts_refs . get_entity_ref ( e . ref ) <TAB><TAB>  if not entity_ref : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for kind in e . kinds : <TAB><TAB><TAB>  status = V1EventKind . events_statuses_mapping . get ( kind ) <TAB><TAB><TAB>  if status : <TAB><TAB><TAB><TAB>  statuses_by_refs [ entity_ref ] . append ( status ) <TAB>  return statuses_by_refs ",if entity_ref not in statuses_by_refs :,if e.kinds is None:,False,23.042159558538945,94.22634286026225
1262,"def items ( self ) : <TAB>  dict = { } <TAB>  for userdir in self . XDG_DIRS . keys ( ) : <TAB><TAB>  prefix = self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = ( <TAB><TAB><TAB><TAB>  os . getenv ( "" HOME "" ) <TAB><TAB><TAB><TAB>  + "" / "" <TAB><TAB><TAB><TAB>  + "" / "" . join ( self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 1 : ] ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  path = self . get ( userdir ) . strip ( ' "" ' ) <TAB><TAB>  dict [ userdir ] = path <TAB>  return dict . items ( ) ",if prefix :,if prefix == 'xdk':,False,25.295115034164116,98.00062233445554
1263,"def clean_objects ( string , common_attributes ) : <TAB>  """"""Return object and attribute lists"""""" <TAB>  string = clean_string ( string ) <TAB>  words = string . split ( ) <TAB>  if len ( words ) > 1 : <TAB><TAB>  prefix_words_are_adj = True <TAB><TAB>  for att in words [ : - 1 ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  prefix_words_are_adj = False <TAB><TAB>  if prefix_words_are_adj : <TAB><TAB><TAB>  return words [ - 1 : ] , words [ : - 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  return [ string ] , [ ] <TAB>  else : <TAB><TAB>  return [ string ] , [ ] ",if att not in common_attributes :,if not common_attributes.has_attribute(att):,False,23.008011190647757,89.95663348849102
1264,"def extract_custom ( extractor , * args , * * kw ) : <TAB>  for match in extractor ( * args , * * kw ) : <TAB><TAB>  msg = match [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  unused = ( <TAB><TAB><TAB><TAB>  "" <unused singular (hash= %s )> "" % md5 ( msg [ 1 ] . encode ( "" utf8 "" ) ) . hexdigest ( ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  msg = ( unused , msg [ 1 ] , msg [ 2 ] ) <TAB><TAB><TAB>  match = ( match [ 0 ] , match [ 1 ] , msg , match [ 3 ] ) <TAB><TAB>  yield match ","if isinstance ( msg , tuple ) and msg [ 0 ] == """" :",if msg[0] == 'unavailable':,False,22.692562301928593,93.63203009357382
1265,"def test_convex_decomposition ( self ) : <TAB>  mesh = g . get_mesh ( "" quadknot.obj "" ) <TAB>  engines = [ ( "" vhacd "" , g . trimesh . interfaces . vhacd . exists ) ] <TAB>  for engine , exists in engines : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . log . warning ( "" skipping convex decomposition engine  %s "" , engine ) <TAB><TAB><TAB>  continue <TAB><TAB>  g . log . info ( "" Testing convex decomposition with engine  %s "" , engine ) <TAB><TAB>  meshes = mesh . convex_decomposition ( engine = engine ) <TAB><TAB>  self . assertTrue ( len ( meshes ) > 1 ) <TAB><TAB>  for m in meshes : <TAB><TAB><TAB>  self . assertTrue ( m . is_watertight ) <TAB><TAB>  g . log . info ( "" convex decomposition succeeded with  %s "" , engine ) ",if not exists :,if exists:,False,26.981009124622364,98.83793210362091
1266,"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB>  if verbose : <TAB><TAB>  ostream . write ( ""  ,  "" ) <TAB>  else : <TAB><TAB>  hasConst = not ( <TAB><TAB><TAB>  self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB><TAB>  ) <TAB><TAB>  if hasConst : <TAB><TAB><TAB>  idx - = 1 <TAB><TAB>  _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB><TAB>  _lt = _l . __class__ <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ostream . write ( ""  -  "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  ostream . write ( ""  +  "" ) ",if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,if _lt is not _lt:,False,21.414790963208635,91.50073125786403
1267,"def get_other ( self , data , items ) : <TAB>  is_tuple = False <TAB>  if type ( data ) == tuple : <TAB><TAB>  data = list ( data ) <TAB><TAB>  is_tuple = True <TAB>  if type ( data ) == list : <TAB><TAB>  m_items = items . copy ( ) <TAB><TAB>  for idx , item in enumerate ( items ) : <TAB><TAB><TAB>  if item < 0 : <TAB><TAB><TAB><TAB>  m_items [ idx ] = len ( data ) - abs ( item ) <TAB><TAB>  for i in sorted ( set ( m_items ) , reverse = True ) : <TAB><TAB><TAB>  if i < len ( data ) and i > - 1 : <TAB><TAB><TAB><TAB>  del data [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return tuple ( data ) <TAB><TAB>  else : <TAB><TAB><TAB>  return data <TAB>  else : <TAB><TAB>  return None ",if is_tuple :,if is_tuple:,False,51.50798489742733,98.63788395907144
1268,"def process_error ( self , data ) : <TAB>  if data . get ( "" error "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AuthCanceled ( self , data . get ( "" error_description "" , "" "" ) ) <TAB><TAB>  raise AuthFailed ( self , data . get ( "" error_description "" ) or data [ "" error "" ] ) <TAB>  elif "" denied "" in data : <TAB><TAB>  raise AuthCanceled ( self , data [ "" denied "" ] ) ","if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :","if ""cancelled"" in data:",False,23.188903875442595,85.9391245616363
1269,"def tamper ( payload , * * kwargs ) : <TAB>  junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB>  retval = "" "" <TAB>  for i , char in enumerate ( payload , start = 1 ) : <TAB><TAB>  amount = random . randint ( 10 , 15 ) <TAB><TAB>  if char == "" > "" : <TAB><TAB><TAB>  retval + = "" > "" <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  elif char == "" < "" : <TAB><TAB><TAB>  retval + = "" < "" <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  else : <TAB><TAB><TAB>  retval + = char <TAB>  return retval ","elif char == "" "" :","if char == ""<"":",False,22.91310220999349,98.33045198920432
1270,"def retry_http_digest_auth ( self , req , auth ) : <TAB>  token , challenge = auth . split ( "" "" , 1 ) <TAB>  chal = parse_keqv_list ( parse_http_list ( challenge ) ) <TAB>  auth = self . get_authorization ( req , chal ) <TAB>  if auth : <TAB><TAB>  auth_val = "" Digest  %s "" % auth <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  req . add_unredirected_header ( self . auth_header , auth_val ) <TAB><TAB>  resp = self . parent . open ( req ) <TAB><TAB>  return resp ","if req . headers . get ( self . auth_header , None ) == auth_val :",if not token:,False,24.56562916277386,87.85597756292749
1271,"def close ( self ) : <TAB>  self . selector . close ( ) <TAB>  if self . sock : <TAB><TAB>  sockname = None <TAB><TAB>  try : <TAB><TAB><TAB>  sockname = self . sock . getsockname ( ) <TAB><TAB>  except ( socket . error , OSError ) : <TAB><TAB><TAB>  pass <TAB><TAB>  self . sock . close ( ) <TAB><TAB>  if type ( sockname ) is str : <TAB><TAB><TAB>  # it was a Unix domain socket, remove it from the filesystem <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . remove ( sockname ) <TAB>  self . sock = None ",if os . path . exists ( sockname ) :,if sockname is not None:,False,63.00385144275735,94.74375073704323
1272,"def to_nurbs ( self , curves ) : <TAB>  result = [ ] <TAB>  for i , c in enumerate ( curves ) : <TAB><TAB>  nurbs = SvNurbsCurve . to_nurbs ( c ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( f "" Curve # { i }  -  { c }  - can not be converted to NURBS! "" ) <TAB><TAB>  result . append ( nurbs ) <TAB>  return result ",if nurbs is None :,if nurbs == 0:,False,23.867273646084048,95.75690457118198
1273,"def handle_1_roomid_raffle ( self , i ) : <TAB>  if i [ 1 ] in [ "" handle_1_room_TV "" , "" handle_1_room_captain "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await self . notify ( "" post_watching_history "" , i [ 0 ] ) <TAB><TAB><TAB>  await self . notify ( i [ 1 ] , i [ 0 ] , i [ 2 ] ) <TAB>  else : <TAB><TAB>  print ( "" hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh "" , i ) ","if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :","if i[1] == ""handle_1_room_TV':",False,9.72006155914019,85.70432335558458
1274,"def init_ps_var_partition ( self ) : <TAB>  ps_vars = { } <TAB>  for v in self . _non_embed_vars . values ( ) : <TAB><TAB>  if v . name not in self . _var_to_ps : <TAB><TAB><TAB>  self . _var_to_ps [ v . name ] = string_to_id ( v . name , self . _ps_num ) <TAB><TAB>  ps_id = self . _var_to_ps [ v . name ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ps_vars [ ps_id ] = [ v ] <TAB><TAB>  else : <TAB><TAB><TAB>  ps_vars [ ps_id ] . append ( v ) <TAB>  self . _ps_vars = ps_vars ",if ps_id not in ps_vars :,if ps_id not in ps_vars:,False,52.37020358460788,100.00000000000004
1275,"def get_files ( d ) : <TAB>  f = [ ] <TAB>  for root , dirs , files in os . walk ( d ) : <TAB><TAB>  for name in files : <TAB><TAB><TAB>  if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  f . append ( os . path . join ( root , name ) ) <TAB>  return f ","if ""do_build"" not in name and ""do_populate_sdk"" not in name :","if os.path.exists(root, name):",False,51.223307163110434,88.3021160662624
1276,"def setSelectedLabelState ( self , p ) :<TAB># selected, disabled <TAB>  c = self . c <TAB>  # g.trace(p,c.edit_widget(p)) <TAB>  if p and c . edit_widget ( p ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . trace ( self . trace_n , c . edit_widget ( p ) , p ) <TAB><TAB><TAB>  # g.trace(g.callers(6)) <TAB><TAB><TAB>  self . trace_n + = 1 <TAB><TAB>  self . setDisabledHeadlineColors ( p ) ",if 0 :,if p and c.edit_widget(p):,False,9.36133787756874,89.55226280135318
1277,"def filter_tasks ( self , task_types = None , task_states = None , task_text = None ) : <TAB>  tasks = self . api . tasks ( self . id ) . get ( "" tasks "" , { } ) <TAB>  if tasks and tasks . get ( "" task "" ) : <TAB><TAB>  return [ <TAB><TAB><TAB>  Task ( self , task ) <TAB><TAB><TAB>  for task in tasks . get ( "" task "" , [ ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  and ( not task_states or task [ "" state "" ] . lower ( ) in task_states ) <TAB><TAB><TAB>  and ( not task_text or task_text . lower ( ) in str ( task ) . lower ( ) ) <TAB><TAB>  ] <TAB>  else : <TAB><TAB>  return [ ] ","if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )",if task['type'] == 'Task':,False,42.42746043169291,90.3739078246642
1278,"def GenerateVector ( self , hits , vector , level ) : <TAB>  """"""Generate possible hit vectors which match the rules."""""" <TAB>  for item in hits . get ( level , [ ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if item < vector [ - 1 ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if item > self . max_separation + vector [ - 1 ] : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  new_vector = vector + [ item ] <TAB><TAB>  if level + 1 == len ( hits ) : <TAB><TAB><TAB>  yield new_vector <TAB><TAB>  elif level + 1 < len ( hits ) : <TAB><TAB><TAB>  for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB><TAB><TAB><TAB>  yield result ",if vector :,if vector:,False,59.56404836527906,96.8575944092633
1279,def _transmit_from_storage ( self ) - > None : <TAB>  for blob in self . storage . gets ( ) : <TAB><TAB>  # give a few more seconds for blob lease operation <TAB><TAB>  # to reduce the chance of race (for perf consideration) <TAB><TAB>  if blob . lease ( self . _timeout + 5 ) : <TAB><TAB><TAB>  envelopes = [ TelemetryItem ( * * x ) for x in blob . get ( ) ] <TAB><TAB><TAB>  result = self . _transmit ( list ( envelopes ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  blob . lease ( 1 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  blob . delete ( ) ,if result == ExportResult . FAILED_RETRYABLE :,if result == TelemetryItem.SUCCESS:,False,59.316459281607855,96.74824713049406
1280,"def load_dictionary ( file ) : <TAB>  oui = { } <TAB>  with open ( file , "" r "" ) as f : <TAB><TAB>  for line in f : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data = line . split ( "" (hex) "" ) <TAB><TAB><TAB><TAB>  key = data [ 0 ] . replace ( "" - "" , "" : "" ) . lower ( ) . strip ( ) <TAB><TAB><TAB><TAB>  company = data [ 1 ] . strip ( ) <TAB><TAB><TAB><TAB>  oui [ key ] = company <TAB>  return oui ","if ""(hex)"" in line :",if line.startswith('#'):,False,48.58947606761967,94.6613785115697
1281,"def _yield_minibatches_idx ( self , rgen , n_batches , data_ary , shuffle = True ) : <TAB>  indices = np . arange ( data_ary . shape [ 0 ] ) <TAB>  if shuffle : <TAB><TAB>  indices = rgen . permutation ( indices ) <TAB>  if n_batches > 1 : <TAB><TAB>  remainder = data_ary . shape [ 0 ] % n_batches <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  minis = np . array_split ( indices [ : - remainder ] , n_batches ) <TAB><TAB><TAB>  minis [ - 1 ] = np . concatenate ( ( minis [ - 1 ] , indices [ - remainder : ] ) , axis = 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  minis = np . array_split ( indices , n_batches ) <TAB>  else : <TAB><TAB>  minis = ( indices , ) <TAB>  for idx_batch in minis : <TAB><TAB>  yield idx_batch ",if remainder :,if remainder > 0:,False,40.2575635858878,92.6620484766793
1282,"def canonical_custom_headers ( self , headers ) : <TAB>  hoi = [ ] <TAB>  custom_headers = { } <TAB>  for key in headers : <TAB><TAB>  lk = key . lower ( ) <TAB><TAB>  if headers [ key ] is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  custom_headers [ lk ] = "" , "" . join ( v . strip ( ) for v in headers . get_all ( key ) ) <TAB>  sorted_header_keys = sorted ( custom_headers . keys ( ) ) <TAB>  for key in sorted_header_keys : <TAB><TAB>  hoi . append ( "" %s : %s "" % ( key , custom_headers [ key ] ) ) <TAB>  return "" \n "" . join ( hoi ) ","if lk . startswith ( ""x-amz-"" ) :",if lk not in custom_headers:,False,23.252532293347873,95.67161822242149
1283,"def validate ( self , data ) : <TAB>  if not data . get ( "" reason "" ) : <TAB><TAB>  # If reason is not provided, message is required and can not be <TAB><TAB>  # null or blank. <TAB><TAB>  message = data . get ( "" message "" ) <TAB><TAB>  if not message : <TAB><TAB><TAB>  if "" message "" not in data : <TAB><TAB><TAB><TAB>  msg = serializers . Field . default_error_messages [ "" required "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  msg = serializers . Field . default_error_messages [ "" null "" ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  msg = serializers . CharField . default_error_messages [ "" blank "" ] <TAB><TAB><TAB>  raise serializers . ValidationError ( { "" message "" : [ msg ] } ) <TAB>  return data ",elif message is None :,if not msg:,False,60.657513157422194,97.63261684505059
1284,def tearDown ( self ) : <TAB>  try : <TAB><TAB>  os . chdir ( self . cwd ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . remove ( self . pythonexe ) <TAB><TAB>  test_support . rmtree ( self . parent_dir ) <TAB>  finally : <TAB><TAB>  BaseTestCase . tearDown ( self ) ,if self . pythonexe != sys . executable :,if os.path.exists(self.pythonexe):,False,23.85150888952279,89.49152530414366
1285,"def update ( self , value , label ) : <TAB>  if self . _disabled : <TAB><TAB>  return <TAB>  try : <TAB><TAB>  self . _progress . value = value <TAB><TAB>  self . _label . value = label <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _displayed = True <TAB><TAB><TAB>  display_widget ( self . _widget ) <TAB>  except Exception as e : <TAB><TAB>  self . _disabled = True <TAB><TAB>  logger . exception ( e ) <TAB><TAB>  wandb . termwarn ( "" Unable to render progress bar, see the user log for details "" ) ",if not self . _displayed :,if self._displayed:,False,54.23123514951915,98.43874970601577
1286,"def GetBinaryOperationBinder ( self , op ) : <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _binaryOperationBinders [ op ] <TAB><TAB>  b = runtime . SymplBinaryOperationBinder ( op ) <TAB><TAB>  self . _binaryOperationBinders [ op ] = b <TAB>  return b ",if self . _binaryOperationBinders . ContainsKey ( op ) :,if op in self._binaryOperationBinders:,False,45.73474487770221,90.61991348684401
1287,"def apply ( self , l , b , evaluation ) : <TAB>  "" FromDigits[l_, b_] "" <TAB>  if l . get_head_name ( ) == "" System`List "" : <TAB><TAB>  value = Integer ( 0 ) <TAB><TAB>  for leaf in l . leaves : <TAB><TAB><TAB>  value = Expression ( "" Plus "" , Expression ( "" Times "" , value , b ) , leaf ) <TAB><TAB>  return value <TAB>  elif isinstance ( l , String ) : <TAB><TAB>  value = FromDigits . _parse_string ( l . get_string_value ( ) , b ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  evaluation . message ( "" FromDigits "" , "" nlst "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  return value <TAB>  else : <TAB><TAB>  evaluation . message ( "" FromDigits "" , "" nlst "" ) ",if value is None :,if value is None:,False,50.73361036415395,100.00000000000004
1288,"def hsconn_sender ( self ) : <TAB>  while not self . stop_event . is_set ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  # Block, but timeout, so that we can exit the loop gracefully <TAB><TAB><TAB>  request = self . send_queue . get ( True , 6.0 ) <TAB><TAB><TAB>  if self . socket is not None : <TAB><TAB><TAB><TAB>  # Socket got closed and set to None in another thread... <TAB><TAB><TAB><TAB>  self . socket . sendall ( request ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . send_queue . task_done ( ) <TAB><TAB>  except queue . Empty : <TAB><TAB><TAB>  pass <TAB><TAB>  except OSError : <TAB><TAB><TAB>  self . stop_event . set ( ) ",if self . send_queue is not None :,if request:,False,66.02723412177077,95.8487744941336
1289,"def check_expected ( result , expected , contains = False ) : <TAB>  if sys . version_info [ 0 ] > = 3 : <TAB><TAB>  if isinstance ( result , str ) : <TAB><TAB><TAB>  result = result . encode ( "" ascii "" ) <TAB><TAB>  if isinstance ( expected , str ) : <TAB><TAB><TAB>  expected = expected . encode ( "" ascii "" ) <TAB>  resultlines = result . splitlines ( ) <TAB>  expectedlines = expected . splitlines ( ) <TAB>  if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB>  return False <TAB>  for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB>  if contains : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ",if eline not in rline :,if rline.endswith(eline):,False,23.64114347575526,97.04574395174971
1290,"def init_weights ( self ) : <TAB>  """"""Initialize model weights."""""" <TAB>  for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  normal_init ( m , std = 0.001 ) <TAB><TAB>  elif isinstance ( m , nn . BatchNorm2d ) : <TAB><TAB><TAB>  constant_init ( m , 1 ) <TAB>  for m in self . multi_final_layers . modules ( ) : <TAB><TAB>  if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB>  normal_init ( m , std = 0.001 , bias = 0 ) ","if isinstance ( m , nn . ConvTranspose2d ) :","if isinstance(m, nn.BatchNorm2d):",False,26.071396781570556,98.49156258720447
1291,"def filter_rel_attrs ( field_name , * * rel_attrs ) : <TAB>  clean_dict = { } <TAB>  for k , v in rel_attrs . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  splitted_key = k . split ( "" __ "" ) <TAB><TAB><TAB>  key = "" __ "" . join ( splitted_key [ 1 : ] ) <TAB><TAB><TAB>  clean_dict [ key ] = v <TAB><TAB>  else : <TAB><TAB><TAB>  clean_dict [ k ] = v <TAB>  return clean_dict ","if k . startswith ( field_name + ""__"" ) :",if k.startswith('__') and k.endswith('__'):,False,46.42986623214757,91.21785583387965
1292,"def cancel ( self ) : <TAB>  with self . _condition : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _squash ( <TAB><TAB><TAB><TAB>  state_root = self . _previous_state_hash , <TAB><TAB><TAB><TAB>  context_ids = [ self . _previous_context_id ] , <TAB><TAB><TAB><TAB>  persist = False , <TAB><TAB><TAB><TAB>  clean_up = True , <TAB><TAB><TAB>  ) <TAB><TAB>  self . _cancelled = True <TAB><TAB>  self . _condition . notify_all ( ) ",if not self . _cancelled and not self . _final and self . _previous_context_id :,if self._squash:,False,44.7435490474394,88.52045146052349
1293,"def _get_level ( levels , level_ref ) : <TAB>  if level_ref in levels : <TAB><TAB>  return levels . index ( level_ref ) <TAB>  if isinstance ( level_ref , six . integer_types ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  level_ref + = len ( levels ) <TAB><TAB>  if not ( 0 < = level_ref < len ( levels ) ) : <TAB><TAB><TAB>  raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB><TAB>  return level_ref <TAB>  raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) ) ",if level_ref < 0 :,"if isinstance(level_ref, int):",False,27.651045019377445,95.3172372118228
1294,"def parse_node ( self , node , alias_map = None , conv = None ) : <TAB>  sql , params , unknown = self . _parse ( node , alias_map , conv ) <TAB>  if unknown and conv and params : <TAB><TAB>  params = [ conv . db_value ( i ) for i in params ] <TAB>  if isinstance ( node , Node ) : <TAB><TAB>  if node . _negated : <TAB><TAB><TAB>  sql = "" NOT  %s "" % sql <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sql = "" "" . join ( ( sql , "" AS "" , node . _alias ) ) <TAB><TAB>  if node . _ordering : <TAB><TAB><TAB>  sql = "" "" . join ( ( sql , node . _ordering ) ) <TAB>  return sql , params ",if node . _alias :,if node._alias:,False,53.89709695254907,100.00000000000004
1295,"def parse_object_id ( _ , values ) : <TAB>  if values : <TAB><TAB>  for key in values : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  val = values [ key ] <TAB><TAB><TAB><TAB>  if len ( val ) > 10 : <TAB><TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB><TAB>  values [ key ] = utils . ObjectIdSilent ( val ) <TAB><TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB><TAB>  values [ key ] = None ","if key . endswith ( ""_id"" ) :",if key in values:,False,46.5529006466811,94.45648274803996
1296,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  self . set_app_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 16 : <TAB><TAB><TAB>  self . set_max_rows ( d . getVarInt32 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 8:,False,51.36809638600636,98.41504940787179
1297,"def has_invalid_cce ( yaml_file , product_yaml = None ) : <TAB>  rule = yaml . open_and_macro_expand ( yaml_file , product_yaml ) <TAB>  if "" identifiers "" in rule and rule [ "" identifiers "" ] is not None : <TAB><TAB>  for i_type , i_value in rule [ "" identifiers "" ] . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if not checks . is_cce_value_valid ( "" CCE- "" + str ( i_value ) ) : <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if i_type [ 0 : 3 ] == ""cce"" :",if i_type == 'cce':,False,49.203485202895166,93.51821583723334
1298,"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB>  if fromdesc or todesc : <TAB><TAB>  yield ( <TAB><TAB><TAB>  simple_colorize ( fromdesc , "" description "" ) , <TAB><TAB><TAB>  simple_colorize ( todesc , "" description "" ) , <TAB><TAB>  ) <TAB>  for i , line in enumerate ( diffs ) : <TAB><TAB>  if line is None : <TAB><TAB><TAB>  # mdiff yields None on separator lines; skip the bogus ones <TAB><TAB><TAB>  # generated for the first line <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB><TAB>  simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB><TAB>  simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield line ",if i > 0 :,if i == len(diffs):,False,60.70892257739055,97.07303108408803
1299,"def _getPatternTemplate ( pattern , key = None ) : <TAB>  if key is None : <TAB><TAB>  key = pattern <TAB><TAB>  if "" % "" not in pattern : <TAB><TAB><TAB>  key = pattern . upper ( ) <TAB>  template = DD_patternCache . get ( key ) <TAB>  if not template : <TAB><TAB>  if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB><TAB><TAB>  template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  template = DatePatternRegex ( pattern ) <TAB>  DD_patternCache . set ( key , template ) <TAB>  return template ","elif key in ( ""TAI64N"" , ""{^LN-BEG}TAI64N"" , ""^TAI64N"" ) :","if key in (""TAI64N"", ""{^LN-BEG}",False,27.181070297652603,94.2240663557746
1300,"def ref_max_pooling_2d ( x , kernel , stride , ignore_border , pad ) : <TAB>  y = [ ] <TAB>  for xx in x . reshape ( ( - 1 , ) + x . shape [ - 3 : ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  xx = xx [ np . newaxis ] <TAB><TAB>  y + = [ <TAB><TAB><TAB>  refs . pooling_2d ( xx , "" max "" , kernel , stride , pad , ignore_border ) [ np . newaxis ] <TAB><TAB>  ] <TAB>  y = np . vstack ( y ) <TAB>  if x . ndim == 2 : <TAB><TAB>  y = np . squeeze ( y , 1 ) <TAB>  return y . reshape ( x . shape [ : - 3 ] + y . shape [ 1 : ] ) ",if xx . ndim == 2 :,"if isinstance(xx, np.ndarray):",False,43.46964614175258,90.31865668424878
1301,"def show_topics ( ) : <TAB>  """"""prints all available miscellaneous help topics."""""" <TAB>  print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB>  for pp in PAGEPATHS : <TAB><TAB>  if not os . path . isdir ( pp ) : <TAB><TAB><TAB>  continue <TAB><TAB>  content = os . listdir ( pp ) <TAB><TAB>  for pn in content : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  name = pn [ : pn . index ( "" . "" ) ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  name = pn <TAB><TAB><TAB>  print ( name ) ","if ""."" in pn :",if pn.startswith('.'):,False,51.75970986688752,95.21426830491062
1302,"def justify_toggle_auto ( self , event = None ) : <TAB>  c = self <TAB>  if c . editCommands . autojustify == 0 : <TAB><TAB>  c . editCommands . autojustify = abs ( c . config . getInt ( "" autojustify "" ) or 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . es ( "" Autojustify on, @int autojustify ==  %s "" % c . editCommands . autojustify ) <TAB><TAB>  else : <TAB><TAB><TAB>  g . es ( "" Set @int autojustify in @settings "" ) <TAB>  else : <TAB><TAB>  c . editCommands . autojustify = 0 <TAB><TAB>  g . es ( "" Autojustify off "" ) ",if c . editCommands . autojustify :,if c.editCommands.autojustify:,False,54.888704628211784,100.00000000000004
1303,"def render_token_list ( self , tokens ) : <TAB>  result = [ ] <TAB>  vars = [ ] <TAB>  for token in tokens : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB><TAB>  elif token . token_type == TOKEN_VAR : <TAB><TAB><TAB>  result . append ( "" %% ( %s )s "" % token . contents ) <TAB><TAB><TAB>  vars . append ( token . contents ) <TAB>  return "" "" . join ( result ) , vars ",if token . token_type == TOKEN_TEXT :,if token.token_type == TOKEN_COMMENT:,False,51.10032683438388,98.37380598312615
1304,"def get_target_dimensions ( self ) : <TAB>  width , height = self . engine . size <TAB>  for operation in self . operations : <TAB><TAB>  if operation [ "" type "" ] == "" crop "" : <TAB><TAB><TAB>  width = operation [ "" right "" ] - operation [ "" left "" ] <TAB><TAB><TAB>  height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  width = operation [ "" width "" ] <TAB><TAB><TAB>  height = operation [ "" height "" ] <TAB>  return ( width , height ) ","if operation [ ""type"" ] == ""resize"" :",if width == 0:,False,28.987725568761213,92.56301049819513
1305,"def get_eval_matcher ( self ) : <TAB>  if isinstance ( self . data [ "" match "" ] , str ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values = [ "" explicitDeny "" , "" implicitDeny "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  values = [ "" allowed "" ] <TAB><TAB>  vf = ValueFilter ( <TAB><TAB><TAB>  { "" type "" : "" value "" , "" key "" : "" EvalDecision "" , "" value "" : values , "" op "" : "" in "" } <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  vf = ValueFilter ( self . data [ "" match "" ] ) <TAB>  vf . annotate = False <TAB>  return vf ","if self . data [ ""match"" ] == ""denied"" :",if self.data['match'] == 'deny':,False,49.76707855202809,95.1272852975261
1306,"def test_training ( self ) : <TAB>  if not self . model_tester . is_training : <TAB><TAB>  return <TAB>  config , inputs_dict = self . model_tester . prepare_config_and_inputs_for_common ( ) <TAB>  config . return_dict = True <TAB>  for model_class in self . all_model_classes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  model = model_class ( config ) <TAB><TAB>  model . to ( torch_device ) <TAB><TAB>  model . train ( ) <TAB><TAB>  inputs = self . _prepare_for_class ( inputs_dict , model_class , return_labels = True ) <TAB><TAB>  loss = model ( * * inputs ) . loss <TAB><TAB>  loss . backward ( ) ",if model_class in MODEL_MAPPING . values ( ) :,if model_class is None:,False,46.08212502004925,95.41878484131328
1307,"def prehook ( self , emu , op , eip ) : <TAB>  if op in self . badops : <TAB><TAB>  emu . stopEmu ( ) <TAB><TAB>  raise v_exc . BadOpBytes ( op . va ) <TAB>  if op . mnem in STOS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB><TAB>  elif self . arch == "" amd64 "" : <TAB><TAB><TAB>  reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB><TAB>  if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB><TAB><TAB>  self . vw . makePointer ( reg , follow = True ) ","if self . arch == ""i386"" :","if self.arch == ""i386':",False,21.427578217761983,98.14057443749836
1308,"def test_len ( self ) : <TAB>  eq = self . assertEqual <TAB>  eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB>  for size in range ( 15 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bsize = 0 <TAB><TAB>  elif size < = 3 : <TAB><TAB><TAB>  bsize = 4 <TAB><TAB>  elif size < = 6 : <TAB><TAB><TAB>  bsize = 8 <TAB><TAB>  elif size < = 9 : <TAB><TAB><TAB>  bsize = 12 <TAB><TAB>  elif size < = 12 : <TAB><TAB><TAB>  bsize = 16 <TAB><TAB>  else : <TAB><TAB><TAB>  bsize = 20 <TAB><TAB>  eq ( base64mime . base64_len ( "" x "" * size ) , bsize ) ",if size == 0 :,if size <= 1:,False,33.977499065546525,98.0755776972933
1309,"def __new__ ( cls , dependencies ) : <TAB>  deps = check . list_param ( dependencies , "" dependencies "" , of_type = DependencyDefinition ) <TAB>  seen = { } <TAB>  for dep in deps : <TAB><TAB>  key = dep . solid + "" : "" + dep . output <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise DagsterInvalidDefinitionError ( <TAB><TAB><TAB><TAB>  ' Duplicate dependencies on solid  "" {dep.solid} ""  output  "" {dep.output} "" ' <TAB><TAB><TAB><TAB>  "" used in the same MultiDependencyDefinition. "" . format ( dep = dep ) <TAB><TAB><TAB>  ) <TAB><TAB>  seen [ key ] = True <TAB>  return super ( MultiDependencyDefinition , cls ) . __new__ ( cls , deps ) ",if key in seen :,if key in seen:,False,52.073988548130814,98.18605297716823
1310,"def get_explanation ( self , spec ) : <TAB>  """"""Expand an explanation."""""" <TAB>  if spec : <TAB><TAB>  try : <TAB><TAB><TAB>  a = self . dns_txt ( spec ) <TAB><TAB><TAB>  if len ( a ) == 1 : <TAB><TAB><TAB><TAB>  return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB><TAB>  except PermError : <TAB><TAB><TAB>  # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise<TAB># but report in harsh mode for record checking tools <TAB><TAB><TAB>  pass <TAB>  el<IF-STMT>: <TAB><TAB>  raise PermError ( "" Empty domain-spec on exp= "" ) <TAB>  # RFC4408 6.2/4 empty domain spec is ignored <TAB>  # (unless you give precedence to the grammar). <TAB>  return None ",if self . strict > 1 :,"if not isinstance(spec, basestring):",False,65.32198921886078,92.73420525552316
1311,"def build ( self ) : <TAB>  if self . args . get ( "" sle_id "" ) : <TAB><TAB>  self . process_sle_against_current_voucher ( ) <TAB>  else : <TAB><TAB>  entries_to_fix = self . get_future_entries_to_fix ( ) <TAB><TAB>  i = 0 <TAB><TAB>  while i < len ( entries_to_fix ) : <TAB><TAB><TAB>  sle = entries_to_fix [ i ] <TAB><TAB><TAB>  i + = 1 <TAB><TAB><TAB>  self . process_sle ( sle ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . get_dependent_entries_to_fix ( entries_to_fix , sle ) <TAB>  if self . exceptions : <TAB><TAB>  self . raise_exceptions ( ) <TAB>  self . update_bin ( ) ",if sle . dependant_sle_voucher_detail_no :,if sle.id:,False,41.49405575485206,95.42372519449492
1312,"def ValidateStopLatitude ( self , problems ) : <TAB>  if self . stop_lat is not None : <TAB><TAB>  value = self . stop_lat <TAB><TAB>  try : <TAB><TAB><TAB>  if not isinstance ( value , ( float , int ) ) : <TAB><TAB><TAB><TAB>  self . stop_lat = util . FloatStringToFloat ( value , problems ) <TAB><TAB>  except ( ValueError , TypeError ) : <TAB><TAB><TAB>  problems . InvalidValue ( "" stop_lat "" , value ) <TAB><TAB><TAB>  del self . stop_lat <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  problems . InvalidValue ( "" stop_lat "" , value ) ",if self . stop_lat > 90 or self . stop_lat < - 90 :,if self.stop_lat is None:,False,47.9842859892723,94.06095062584718
1313,"def set ( self , obj , * * kwargs ) : <TAB>  """"""Check for missing event functions and substitute these with"""""" <TAB>  """"""the ignore method"""""" <TAB>  ignore = getattr ( self , "" ignore "" ) <TAB>  for k , v in kwargs . iteritems ( ) : <TAB><TAB>  setattr ( self , k , getattr ( obj , v ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for k1 in self . combinations [ k ] : <TAB><TAB><TAB><TAB>  if not hasattr ( self , k1 ) : <TAB><TAB><TAB><TAB><TAB>  setattr ( self , k1 , ignore ) ",if k in self . combinations :,if ignore is not None:,False,54.018428510893614,95.99607440994059
1314,"def split ( self , duration , include_remainder = True ) : <TAB>  # Convert seconds to timedelta, if appropriate. <TAB>  duration = _seconds_or_timedelta ( duration ) <TAB>  if duration < = timedelta ( seconds = 0 ) : <TAB><TAB>  raise ValueError ( "" cannot call split with a non-positive timedelta "" ) <TAB>  start = self . start <TAB>  while start < self . end : <TAB><TAB>  if start + duration < = self . end : <TAB><TAB><TAB>  yield MayaInterval ( start , start + duration ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield MayaInterval ( start , self . end ) <TAB><TAB>  start + = duration ",elif include_remainder :,if include_remainder:,False,58.357408794119294,98.45425234727975
1315,"def get_first_field ( layout , clz ) : <TAB>  for layout_object in layout . fields : <TAB><TAB>  if issubclass ( layout_object . __class__ , clz ) : <TAB><TAB><TAB>  return layout_object <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gf = get_first_field ( layout_object , clz ) <TAB><TAB><TAB>  if gf : <TAB><TAB><TAB><TAB>  return gf ","elif hasattr ( layout_object , ""get_field_names"" ) :",if layout_object.is_class_class_class(clz):,False,39.353894837197494,89.62631667759895
1316,"def _getPatternTemplate ( pattern , key = None ) : <TAB>  if key is None : <TAB><TAB>  key = pattern <TAB><TAB>  if "" % "" not in pattern : <TAB><TAB><TAB>  key = pattern . upper ( ) <TAB>  template = DD_patternCache . get ( key ) <TAB>  if not template : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB><TAB>  elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB><TAB><TAB>  template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  template = DatePatternRegex ( pattern ) <TAB>  DD_patternCache . set ( key , template ) <TAB>  return template ","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :","if key in (""EPOCH"", ""{^LN-BEG}EPOCH",False,23.200573843751897,95.78195289582519
1317,"def findOwningViewController ( self , object ) : <TAB>  while object : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  description = fb . evaluateExpressionValue ( object ) . GetObjectDescription ( ) <TAB><TAB><TAB>  print ( "" Found the owning view controller. \n {} "" . format ( description ) ) <TAB><TAB><TAB>  cmd = ' echo  {}  | tr -d  "" \n ""  | pbcopy ' . format ( object ) <TAB><TAB><TAB>  os . system ( cmd ) <TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  object = self . nextResponder ( object ) <TAB>  print ( "" Could not find an owning view controller "" ) ",if self . isViewController ( object ) :,if self.isViewController(object):,False,58.91264930697149,95.90046201976197
1318,"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB>  for element in file_list : <TAB><TAB>  if idx == num : <TAB><TAB><TAB>  return element <TAB><TAB>  if element [ 3 ] and element [ 4 ] : <TAB><TAB><TAB>  i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return i <TAB><TAB><TAB>  idx = i <TAB><TAB>  else : <TAB><TAB><TAB>  idx + = 1 <TAB>  return idx ","if not isinstance ( i , int ) :",if i is not None:,False,24.58662816309246,95.45480521671502
1319,"def promtool ( * * kwargs ) : <TAB>  key = "" prometheus:promtool "" <TAB>  try : <TAB><TAB>  path = pathlib . Path ( util . setting ( key ) ) <TAB>  except TypeError : <TAB><TAB>  yield checks . Warning ( <TAB><TAB><TAB>  "" Missing setting for  %s  in  %s "" % ( key , settings . PROMGEN_CONFIG_FILE ) , <TAB><TAB><TAB>  id = "" promgen.W001 "" , <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield checks . Warning ( "" Unable to execute file  %s "" % path , id = "" promgen.W003 "" ) ","if not os . access ( path , os . X_OK ) :",if not path.exists():,False,29.474631032310295,93.12486089245266
1320,"def parse_config ( schema , config ) : <TAB>  schemaparser = ConfigParser ( ) <TAB>  schemaparser . readfp ( StringIO ( schema ) ) <TAB>  cfgparser = ConfigParser ( ) <TAB>  cfgparser . readfp ( StringIO ( config ) ) <TAB>  result = { } <TAB>  for section in cfgparser . sections ( ) : <TAB><TAB>  result_section = { } <TAB><TAB>  schema = { } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  schema = dict ( schemaparser . items ( section ) ) <TAB><TAB>  for key , value in cfgparser . items ( section ) : <TAB><TAB><TAB>  converter = converters [ schema . get ( key , "" string "" ) ] <TAB><TAB><TAB>  result_section [ key ] = converter ( value ) <TAB><TAB>  result [ section ] = result_section <TAB>  return result ",if section in schemaparser . sections ( ) :,if section in schemaparser:,False,37.43492215857549,97.31436601180472
1321,"def validate_arguments ( args ) : <TAB>  if args . num_pss < 1 : <TAB><TAB>  print ( "" Value error: must have ore than one parameter servers. "" ) <TAB><TAB>  exit ( 1 ) <TAB>  if not GPU_IDS : <TAB><TAB>  num_cpus = multiprocessing . cpu_count ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" Value error: there are  %s  available CPUs but you are requiring  %s . "" <TAB><TAB><TAB><TAB>  % ( num_cpus , args . cpu_trainers ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  exit ( 1 ) <TAB>  if not os . path . isfile ( args . file ) : <TAB><TAB>  print ( "" Value error: model trainning file does not exist "" ) <TAB><TAB>  exit ( 1 ) ",if args . cpu_trainers > num_cpus :,if num_cpus != args.cpu_trainers:,False,37.991644179848315,97.13680590024833
1322,"def infer_dataset_impl ( path ) : <TAB>  if IndexedRawTextDataset . exists ( path ) : <TAB><TAB>  return "" raw "" <TAB>  elif IndexedDataset . exists ( path ) : <TAB><TAB>  with open ( index_file_path ( path ) , "" rb "" ) as f : <TAB><TAB><TAB>  magic = f . read ( 8 ) <TAB><TAB><TAB>  if magic == IndexedDataset . _HDR_MAGIC : <TAB><TAB><TAB><TAB>  return "" cached "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return "" mmap "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return None <TAB>  elif FastaDataset . exists ( path ) : <TAB><TAB>  return "" fasta "" <TAB>  else : <TAB><TAB>  return None ",elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,if MAGIC == IndexedDataset._HDR_MAGIC:,False,23.704412691812447,93.92789396496717
1323,"def _add_resource_group ( obj ) : <TAB>  if isinstance ( obj , list ) : <TAB><TAB>  for array_item in obj : <TAB><TAB><TAB>  _add_resource_group ( array_item ) <TAB>  elif isinstance ( obj , dict ) : <TAB><TAB>  try : <TAB><TAB><TAB>  if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB><TAB>  except ( KeyError , IndexError , TypeError ) : <TAB><TAB><TAB>  pass <TAB><TAB>  for item_key in obj : <TAB><TAB><TAB>  if item_key != "" sourceVault "" : <TAB><TAB><TAB><TAB>  _add_resource_group ( obj [ item_key ] ) ","if obj [ ""id"" ] :","if x.lower() in ['resource-group', 'resource-group']:",False,26.084325539695914,95.50436345684189
1324,"def reformatBody ( self , event = None ) : <TAB>  """"""Reformat all paragraphs in the body."""""" <TAB>  c , p = self , self . p <TAB>  undoType = "" reformat-body "" <TAB>  w = c . frame . body . wrapper <TAB>  c . undoer . beforeChangeGroup ( p , undoType ) <TAB>  w . setInsertPoint ( 0 ) <TAB>  while 1 : <TAB><TAB>  progress = w . getInsertPoint ( ) <TAB><TAB>  c . reformatParagraph ( event , undoType = undoType ) <TAB><TAB>  ins = w . getInsertPoint ( ) <TAB><TAB>  s = w . getAllText ( ) <TAB><TAB>  w . setInsertPoint ( ins ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  c . undoer . afterChangeGroup ( p , undoType ) ",if ins <= progress or ins >= len ( s ) :,if s == '':,False,24.41834044541732,93.37910930988856
1325,"def make_sources ( project : RootDependency ) - > str : <TAB>  content = [ ] <TAB>  if project . readme : <TAB><TAB>  content . append ( project . readme . path . name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  content . append ( project . readme . to_rst ( ) . path . name ) <TAB>  path = project . package . path <TAB>  for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB><TAB>  if ( path / fname ) . exists ( ) : <TAB><TAB><TAB>  content . append ( fname ) <TAB>  for package in chain ( project . package . packages , project . package . data ) : <TAB><TAB>  for fpath in package : <TAB><TAB><TAB>  fpath = fpath . relative_to ( project . package . path ) <TAB><TAB><TAB>  content . append ( "" / "" . join ( fpath . parts ) ) <TAB>  return "" \n "" . join ( content ) ","if project . readme . markup != ""rst"" :",if project.readme:,False,42.178505355942654,96.48249850153914
1326,"def __init__ ( self , response ) : <TAB>  error = "" {} {} "" . format ( response . status_code , response . reason ) <TAB>  extra = [ ] <TAB>  try : <TAB><TAB>  response_json = response . json ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  error = "" "" . join ( error [ "" message "" ] for error in response_json [ "" error_list "" ] ) <TAB><TAB><TAB>  extra = [ <TAB><TAB><TAB><TAB>  error [ "" extra "" ] <TAB><TAB><TAB><TAB>  for error in response_json [ "" error_list "" ] <TAB><TAB><TAB><TAB>  if "" extra "" in error <TAB><TAB><TAB>  ] <TAB>  except JSONDecodeError : <TAB><TAB>  pass <TAB>  super ( ) . __init__ ( response = response , error = error , extra = extra ) ","if ""error_list"" in response_json :",if response_json['error_list']:,False,23.88971818992956,96.27453714004497
1327,"def handle_event ( self , fileno = None , events = None ) : <TAB>  if self . _state == RUN : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _it = self . _process_result ( 0 )<TAB># non-blocking <TAB><TAB>  try : <TAB><TAB><TAB>  next ( self . _it ) <TAB><TAB>  except ( StopIteration , CoroStop ) : <TAB><TAB><TAB>  self . _it = None ",if self . _it is None :,if self._state == FINISH:,False,37.2819392335905,91.73188845244293
1328,"def find_query ( self , needle , haystack ) : <TAB>  try : <TAB><TAB>  import pinyin <TAB><TAB>  haystack_py = pinyin . get_initial ( haystack , "" "" ) <TAB><TAB>  needle_len = len ( needle ) <TAB><TAB>  start = 0 <TAB><TAB>  result = [ ] <TAB><TAB>  while True : <TAB><TAB><TAB>  found = haystack_py . find ( needle , start ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  result . append ( ( found , needle_len ) ) <TAB><TAB><TAB>  start = found + needle_len <TAB><TAB>  return result <TAB>  except : <TAB><TAB>  return None ",if found < 0 :,if found is None:,False,22.57451555741899,98.17660210107306
1329,"def decorated_function ( * args , * * kwargs ) : <TAB>  rv = f ( * args , * * kwargs ) <TAB>  if "" Last-Modified "" not in rv . headers : <TAB><TAB>  try : <TAB><TAB><TAB>  result = date <TAB><TAB><TAB>  if callable ( result ) : <TAB><TAB><TAB><TAB>  result = result ( rv ) <TAB><TAB><TAB>  if not isinstance ( result , basestring ) : <TAB><TAB><TAB><TAB>  from werkzeug . http import http_date <TAB><TAB><TAB><TAB>  result = http_date ( result ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  rv . headers [ "" Last-Modified "" ] = result <TAB><TAB>  except Exception : <TAB><TAB><TAB>  logging . getLogger ( __name__ ) . exception ( <TAB><TAB><TAB><TAB>  "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB><TAB><TAB><TAB><TAB>  rv <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return rv ",if result :,if result is not None:,False,27.63467313091452,98.44866662347114
1330,"def check_require ( require_modules , require_lines ) : <TAB>  for require_module in require_modules : <TAB><TAB>  st = try_import ( require_module ) <TAB><TAB>  if st == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" installed  {} :  {} \n "" . format ( <TAB><TAB><TAB><TAB><TAB>  require_module , require_lines [ require_module ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  elif st == 2 : <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" failed installed  {} :  {} \n "" . format ( <TAB><TAB><TAB><TAB><TAB>  require_module , require_lines [ require_module ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) ",elif st == 1 :,if st == 1:,False,47.49045049000884,99.03377926228485
1331,"def bundle_directory ( self , dirpath ) : <TAB>  """"""Bundle all modules/packages in the given directory."""""" <TAB>  dirpath = os . path . abspath ( dirpath ) <TAB>  for nm in os . listdir ( dirpath ) : <TAB><TAB>  nm = _u ( nm ) <TAB><TAB>  if nm . startswith ( "" . "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  itempath = os . path . join ( dirpath , nm ) <TAB><TAB>  if os . path . isdir ( itempath ) : <TAB><TAB><TAB>  if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB><TAB><TAB><TAB>  self . bundle_package ( itempath ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . bundle_module ( itempath ) ","elif nm . endswith ( "".py"" ) :","if os.path.exists(os.path.join(dirpath, '__init__.",False,28.31900879087636,89.98915138622708
1332,"def _find_root ( ) : <TAB>  test_dirs = [ "" Src "" , "" Build "" , "" Package "" , "" Tests "" , "" Util "" ] <TAB>  root = os . getcwd ( ) <TAB>  test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB>  while not test : <TAB><TAB>  last_root = root <TAB><TAB>  root = os . path . dirname ( root ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( "" Root not found "" ) <TAB><TAB>  test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB>  return root ",if root == last_root :,if not root:,False,32.14110353630409,96.46547826382431
1333,"def findMarkForUnitTestNodes ( self ) : <TAB>  """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB>  c = self . c <TAB>  p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB>  while p : <TAB><TAB>  if p . v in seen : <TAB><TAB><TAB>  p . moveToNodeAfterTree ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  seen . append ( p . v ) <TAB><TAB><TAB>  if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB><TAB><TAB><TAB>  p . moveToNodeAfterTree ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result . append ( p . copy ( ) ) <TAB><TAB><TAB><TAB>  p . moveToNodeAfterTree ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  p . moveToThreadNext ( ) <TAB>  return result ","elif p . h . startswith ( ""@mark-for-unit-tests"" ) :",if p.v in result:,False,55.54073489835958,94.88955515104381
1334,"def startTagFrameset ( self , token ) : <TAB>  self . parser . parseError ( "" unexpected-start-tag "" , { "" name "" : "" frameset "" } ) <TAB>  if len ( self . tree . openElements ) == 1 or self . tree . openElements [ 1 ] . name != "" body "" : <TAB><TAB>  assert self . parser . innerHTML <TAB>  elif not self . parser . framesetOK : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . tree . openElements [ 1 ] . parent . removeChild ( self . tree . openElements [ 1 ] ) <TAB><TAB>  while self . tree . openElements [ - 1 ] . name != "" html "" : <TAB><TAB><TAB>  self . tree . openElements . pop ( ) <TAB><TAB>  self . tree . insertElement ( token ) <TAB><TAB>  self . parser . phase = self . parser . phases [ "" inFrameset "" ] ",if self . tree . openElements [ 1 ] . parent :,if self.tree.openElements[1].parent:,False,51.80170984698491,98.43015134438294
1335,"def try_split ( self , split_text : List [ str ] ) : <TAB>  ret = [ ] <TAB>  for i in split_text : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  val = int ( i , 2 ) <TAB><TAB>  if val > 255 or val < 0 : <TAB><TAB><TAB>  return None <TAB><TAB>  ret . append ( val ) <TAB>  if len ( ret ) != 0 : <TAB><TAB>  ret = bytes ( ret ) <TAB><TAB>  logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB><TAB>  return ret ",if len ( i ) == 0 :,if i == '0':,False,47.31757202830099,95.58275115517525
1336,"def generator ( self , data ) : <TAB>  for sock in data : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  offset = sock . obj_offset <TAB><TAB>  else : <TAB><TAB><TAB>  offset = sock . obj_vm . vtop ( sock . obj_offset ) <TAB><TAB>  yield ( <TAB><TAB><TAB>  0 , <TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB>  Address ( offset ) , <TAB><TAB><TAB><TAB>  int ( sock . Pid ) , <TAB><TAB><TAB><TAB>  int ( sock . LocalPort ) , <TAB><TAB><TAB><TAB>  int ( sock . Protocol ) , <TAB><TAB><TAB><TAB>  str ( protos . protos . get ( sock . Protocol . v ( ) , "" - "" ) ) , <TAB><TAB><TAB><TAB>  str ( sock . LocalIpAddress ) , <TAB><TAB><TAB><TAB>  str ( sock . CreateTime ) , <TAB><TAB><TAB>  ] , <TAB><TAB>  ) ",if not self . _config . PHYSICAL_OFFSET :,"if isinstance(sock.obj_offset, (int, int)):",False,33.691918932053774,94.60882312165002
1337,"def __init__ ( self , num_bits = 4 , always_apply = False , p = 0.5 ) : <TAB>  super ( Posterize , self ) . __init__ ( always_apply , p ) <TAB>  if isinstance ( num_bits , ( list , tuple ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . num_bits = [ to_tuple ( i , 0 ) for i in num_bits ] <TAB><TAB>  else : <TAB><TAB><TAB>  self . num_bits = to_tuple ( num_bits , 0 ) <TAB>  else : <TAB><TAB>  self . num_bits = to_tuple ( num_bits , num_bits ) ",if len ( num_bits ) == 3 :,"if isinstance(num_bits, (list, tuple)):",False,49.0368265005382,93.88789023961228
1338,"def tearDown ( self ) : <TAB>  """"""Just in case yn00 creates some junk files, do a clean-up."""""" <TAB>  del_files = [ self . out_file , "" 2YN.dN "" , "" 2YN.dS "" , "" 2YN.t "" , "" rst "" , "" rst1 "" , "" rub "" ] <TAB>  for filename in del_files : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . remove ( filename ) <TAB>  if os . path . exists ( self . working_dir ) : <TAB><TAB>  for filename in os . listdir ( self . working_dir ) : <TAB><TAB><TAB>  filepath = os . path . join ( self . working_dir , filename ) <TAB><TAB><TAB>  os . remove ( filepath ) <TAB><TAB>  os . rmdir ( self . working_dir ) ",if os . path . exists ( filename ) :,if os.path.exists(filename):,False,60.092030322155864,100.00000000000004
1339,"def reverse_search_history ( self , searchfor , startpos = None ) : <TAB>  if startpos is None : <TAB><TAB>  startpos = self . history_cursor <TAB>  if _ignore_leading_spaces : <TAB><TAB>  res = [ <TAB><TAB><TAB>  ( idx , line . lstrip ( ) ) <TAB><TAB><TAB>  for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  ] <TAB>  else : <TAB><TAB>  res = [ <TAB><TAB><TAB>  ( idx , line ) <TAB><TAB><TAB>  for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB>  if line . startswith ( searchfor ) <TAB><TAB>  ] <TAB>  if res : <TAB><TAB>  self . history_cursor - = res [ 0 ] [ 0 ] <TAB><TAB>  return res [ 0 ] [ 1 ] . get_line_text ( ) <TAB>  return "" "" ",if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),if line.startswith(searchfor):,False,39.861212173661606,93.89794259250203
1340,"def ComboBoxDroppedHeightTest ( windows ) : <TAB>  "" Check if each combobox height is the same as the reference "" <TAB>  bugs = [ ] <TAB>  for win in windows : <TAB><TAB>  if not win . ref : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) : <TAB><TAB><TAB>  bugs . append ( <TAB><TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB><TAB>  win , <TAB><TAB><TAB><TAB><TAB>  ] , <TAB><TAB><TAB><TAB><TAB>  { } , <TAB><TAB><TAB><TAB><TAB>  testname , <TAB><TAB><TAB><TAB><TAB>  0 , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return bugs ","if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :",if win.ref.Name() == testname:,False,58.64195789251669,93.13017328503983
1341,"def get_changed ( self ) : <TAB>  if self . _is_expression ( ) : <TAB><TAB>  result = self . _get_node_text ( self . ast ) <TAB><TAB>  if result == self . source : <TAB><TAB><TAB>  return None <TAB><TAB>  return result <TAB>  else : <TAB><TAB>  collector = codeanalyze . ChangeCollector ( self . source ) <TAB><TAB>  last_end = - 1 <TAB><TAB>  for match in self . matches : <TAB><TAB><TAB>  start , end = match . get_region ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if not self . _is_expression ( ) : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  last_end = end <TAB><TAB><TAB>  replacement = self . _get_matched_text ( match ) <TAB><TAB><TAB>  collector . add_change ( start , end , replacement ) <TAB><TAB>  return collector . get_changed ( ) ",if start < last_end :,if start == last_end:,False,50.8774876457476,97.36608071388366
1342,"def unpickle_from_file ( file_path , gzip = False ) : <TAB>  """"""Unpickle obj from file_path with gzipping."""""" <TAB>  with tf . io . gfile . GFile ( file_path , "" rb "" ) as f : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  obj = pickle . load ( f ) <TAB><TAB>  else : <TAB><TAB><TAB>  with gzip_lib . GzipFile ( fileobj = f , compresslevel = 2 ) as gzipf : <TAB><TAB><TAB><TAB>  obj = pickle . load ( gzipf ) <TAB>  return obj ",if not gzip :,if gzip:,False,40.60550988096312,98.24098822896327
1343,"def get_user_context ( request , escape = False ) : <TAB>  if isinstance ( request , HttpRequest ) : <TAB><TAB>  user = getattr ( request , "" user "" , None ) <TAB><TAB>  result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB><TAB>  if user and user . is_authenticated ( ) : <TAB><TAB><TAB>  result . update ( <TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB>  "" email "" : user . email , <TAB><TAB><TAB><TAB><TAB>  "" id "" : user . id , <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ "" name "" ] = user . name <TAB>  else : <TAB><TAB>  result = { } <TAB>  return mark_safe ( json . dumps ( result ) ) ",if user . name :,if escape:,False,30.71047254186874,98.16545844274299
1344,"def get_item_address ( self , item ) : <TAB>  """"""Get an item's address as a collection of names"""""" <TAB>  result = [ ] <TAB>  while True : <TAB><TAB>  name = self . tree_ctrl . GetItemPyData ( item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  result . insert ( 0 , name ) <TAB><TAB><TAB>  item = self . tree_ctrl . GetItemParent ( item ) <TAB>  return result ",if name is None :,if name is None:,False,60.53665488836101,100.00000000000004
1345,"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB>  # find the closest unseen from this row/col <TAB>  min_dist = maxint <TAB>  closest_unseen = None <TAB>  for row in range ( self . height ) : <TAB><TAB>  for col in range ( self . width ) : <TAB><TAB><TAB>  if filter is None or ( row , col ) not in filter : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  dist = self . distance ( row1 , col1 , row , col ) <TAB><TAB><TAB><TAB><TAB>  if dist < min_dist : <TAB><TAB><TAB><TAB><TAB><TAB>  min_dist = dist <TAB><TAB><TAB><TAB><TAB><TAB>  closest_unseen = ( row , col ) <TAB>  return closest_unseen ",if self . map [ row ] [ col ] == UNSEEN :,if closest_unseen is None:,False,57.52545456003659,94.08800132302501
1346,"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB>  if self . _log_graph : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  input_array = model . example_input_array <TAB><TAB>  if input_array is not None : <TAB><TAB><TAB>  input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB><TAB><TAB>  self . experiment . add_graph ( model , input_array ) <TAB><TAB>  else : <TAB><TAB><TAB>  rank_zero_warn ( <TAB><TAB><TAB><TAB>  "" Could not log computational graph since the "" <TAB><TAB><TAB><TAB>  ""  `model.example_input_array` attribute is not set "" <TAB><TAB><TAB><TAB>  ""  or `input_array` was not given "" , <TAB><TAB><TAB><TAB>  UserWarning , <TAB><TAB><TAB>  ) ",if input_array is None :,if input_array is None:,False,60.53134036936621,100.00000000000004
1347,"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB>  scene_exceptions = [ ] <TAB>  for scene_exception in self . scene_exceptions : <TAB><TAB>  if not len ( scene_exception ) == 2 : <TAB><TAB><TAB>  continue <TAB><TAB>  scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  scene_exceptions . append ( scene_name ) <TAB>  return scene_exceptions ",if season == scene_season :,if scene_season == season:,False,31.872652436415017,94.4479070240867
1348,def _clean_temp_files ( ) : <TAB>  for pattern in _temp_files : <TAB><TAB>  for path in glob . glob ( pattern ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . remove ( path ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  shutil . rmtree ( path ) ,if os . path . islink ( path ) or os . path . isfile ( path ) :,if os.path.exists(path):,False,24.512999467203457,89.35865350840481
1349,"def wait_for_completion ( self , job_id , offset , max_results , start_time , timeout ) : <TAB>  """"""Wait for job completion and return the first page."""""" <TAB>  while True : <TAB><TAB>  result = self . get_query_results ( <TAB><TAB><TAB>  job_id = job_id , page_token = None , start_index = offset , max_results = max_results <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return result <TAB><TAB>  if ( time . time ( ) - start_time ) > timeout : <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Timeout: the query doesn ' t finish within  %d  seconds. "" % timeout <TAB><TAB><TAB>  ) <TAB><TAB>  time . sleep ( 1 ) ","if result [ ""jobComplete"" ] :",if result:,False,27.52560187925659,95.81237189653912
1350,"def get_data ( self , element , ranges , style ) : <TAB>  <IF-STMT>: <TAB><TAB>  groups = element . groupby ( element . kdims ) . items ( ) <TAB>  else : <TAB><TAB>  groups = [ ( element . label , element ) ] <TAB>  plots = [ ] <TAB>  axis = "" x "" if self . invert_axes else "" y "" <TAB>  for key , group in groups : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  label = "" , "" . join ( [ d . pprint_value ( v ) for d , v in zip ( element . kdims , key ) ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  label = key <TAB><TAB>  data = { axis : group . dimension_values ( group . vdims [ 0 ] ) , "" name "" : label } <TAB><TAB>  plots . append ( data ) <TAB>  return plots ",if element . kdims :,"if isinstance(group, dict):",False,28.472526763020966,94.52190385684649
1351,"def get_files ( self , dirname ) : <TAB>  if not self . _data . has_key ( dirname ) : <TAB><TAB>  self . _create ( dirname ) <TAB>  else : <TAB><TAB>  new_time = self . _changed ( dirname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _update ( dirname , new_time ) <TAB><TAB><TAB>  dcLog . debug ( "" ==>  "" + "" \t \n "" . join ( self . _data [ dirname ] [ "" flist "" ] ) ) <TAB>  return self . _data [ dirname ] [ "" flist "" ] ",if new_time :,if new_time is not None:,False,22.717074211869,97.04071023597234
1352,"def __init__ ( self , dir ) : <TAB>  self . module_names = set ( ) <TAB>  for name in os . listdir ( dir ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . module_names . add ( name [ : - 3 ] ) <TAB><TAB>  elif "" . "" not in name : <TAB><TAB><TAB>  self . module_names . add ( name ) ","if name . endswith ( "".py"" ) :",if name.endswith('.py') or name.endswith('.py') or,False,18.960143003009165,84.1887413687349
1353,"def logic ( ) : <TAB>  for i in range ( 100 ) : <TAB><TAB>  yield clock . posedge , reset . negedge <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  count . next = 0 <TAB><TAB>  else : <TAB><TAB><TAB>  if enable : <TAB><TAB><TAB><TAB>  count . next = ( count + 1 ) % n <TAB>  raise StopSimulation ",if reset == ACTIVE_LOW :,if n == 0:,False,43.930209415459856,93.51015328405607
1354,"def sortkeypicker ( keynames ) : <TAB>  negate = set ( ) <TAB>  for i , k in enumerate ( keynames ) : <TAB><TAB>  if k [ : 1 ] == "" - "" : <TAB><TAB><TAB>  keynames [ i ] = k [ 1 : ] <TAB><TAB><TAB>  negate . add ( k [ 1 : ] ) <TAB>  def getit ( adict ) : <TAB><TAB>  composite = [ adict [ k ] for k in keynames ] <TAB><TAB>  for i , ( k , v ) in enumerate ( zip ( keynames , composite ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  composite [ i ] = - v <TAB><TAB>  return composite <TAB>  return getit ",if k in negate :,if k not in negate:,False,51.59644733375117,96.65989211875184
1355,"def show_image ( self , wnd_name , img ) : <TAB>  if wnd_name in self . named_windows : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . named_windows [ wnd_name ] = 1 <TAB><TAB><TAB>  self . on_create_window ( wnd_name ) <TAB><TAB><TAB>  if wnd_name in self . capture_mouse_windows : <TAB><TAB><TAB><TAB>  self . capture_mouse ( wnd_name ) <TAB><TAB>  self . on_show_image ( wnd_name , img ) <TAB>  else : <TAB><TAB>  print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" ) ",if self . named_windows [ wnd_name ] == 0 :,if wnd_name not in self.named_windows:,False,42.73316549984555,94.87765660187769
1356,"def check_action_permitted ( self ) : <TAB>  if ( <TAB><TAB>  self . _action == "" sts:GetCallerIdentity "" <TAB>  ) :<TAB># always allowed, even if there's an explicit Deny for it <TAB><TAB>  return True <TAB>  policies = self . _access_key . collect_policies ( ) <TAB>  permitted = False <TAB>  for policy in policies : <TAB><TAB>  iam_policy = IAMPolicy ( policy ) <TAB><TAB>  permission_result = iam_policy . is_action_permitted ( self . _action ) <TAB><TAB>  if permission_result == PermissionResult . DENIED : <TAB><TAB><TAB>  self . _raise_access_denied ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  permitted = True <TAB>  if not permitted : <TAB><TAB>  self . _raise_access_denied ( ) ",elif permission_result == PermissionResult . PERMITTED :,if permission_result == PermissionResult.DENIED:,False,50.680904890047486,95.54964587257372
1357,"def _limit_value ( key , value , config ) : <TAB>  if config [ key ] . get ( "" upper_limit "" ) : <TAB><TAB>  limit = config [ key ] [ "" upper_limit "" ] <TAB><TAB>  # auto handle datetime <TAB><TAB>  if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB><TAB><TAB>  if config [ key ] [ "" inverse "" ] is True : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  value = datetime . now ( ) - limit <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  if ( datetime . now ( ) + limit ) < value : <TAB><TAB><TAB><TAB><TAB>  value = datetime . now ( ) + limit <TAB><TAB>  elif value > limit : <TAB><TAB><TAB>  value = limit <TAB>  return value ",if ( datetime . now ( ) - limit ) > value :,"if isinstance(value, datetime):",False,50.66066524483925,95.15794954325403
1358,"def replace_dataset_ids ( path , key , value ) : <TAB>  """"""Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job."""""" <TAB>  current_case = input_values <TAB>  if key == "" id "" : <TAB><TAB>  for i , p in enumerate ( path ) : <TAB><TAB><TAB>  if isinstance ( current_case , ( list , dict ) ) : <TAB><TAB><TAB><TAB>  current_case = current_case [ p ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return key , translate_values . get ( current_case [ "" id "" ] , value ) <TAB>  return key , value ","if src == current_case . get ( ""src"" ) :",if i == len(path):,False,53.484014525884646,93.22029778558009
1359,"def load_ext ( name , funcs ) : <TAB>  ExtModule = namedtuple ( "" ExtModule "" , funcs ) <TAB>  ext_list = [ ] <TAB>  lib_root = os . path . dirname ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) <TAB>  for fun in funcs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op ) <TAB><TAB>  else : <TAB><TAB><TAB>  ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op_ ) <TAB>  return ExtModule ( * ext_list ) ","if fun in [ ""nms"" , ""softnms"" ] :",if fun.startswith('_'):,False,46.75833137868735,93.55097186762254
1360,"def execute_action ( self ) : <TAB>  selected_actions = self . model_action . get_selected_results_with_index ( ) <TAB>  if selected_actions and self . args_for_action : <TAB><TAB>  for name , _ , act_idx in selected_actions : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  action = self . actions [ act_idx ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  action . act ( [ arg for arg , _ , _ in self . args_for_action ] , self ) <TAB><TAB><TAB>  except Exception as e : <TAB><TAB><TAB><TAB>  debug . log ( "" execute_action "" , e ) ",if action :,if action:,False,51.19360772105943,100.00000000000004
1361,"def __getattr__ ( self , attr ) : <TAB>  proxy = self . __proxy <TAB>  if proxy and hasattr ( proxy , attr ) : <TAB><TAB>  return getattr ( proxy , attr ) <TAB>  attrmap = self . __attrmap <TAB>  if attr in attrmap : <TAB><TAB>  source = attrmap [ attr ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = source ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  value = _import_object ( source ) <TAB><TAB>  setattr ( self , attr , value ) <TAB><TAB>  self . __log . debug ( "" loaded lazy attr  %r :  %r "" , attr , value ) <TAB><TAB>  return value <TAB>  raise AttributeError ( "" ' module '  object has no attribute  ' %s ' "" % ( attr , ) ) ",if callable ( source ) :,if callable(source):,False,53.39273920728471,96.07545507664518
1362,"def forward ( self , x ) : <TAB>  # BxT -> BxCxT <TAB>  x = x . unsqueeze ( 1 ) <TAB>  for conv in self . conv_layers : <TAB><TAB>  residual = x <TAB><TAB>  x = conv ( x ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tsz = x . size ( 2 ) <TAB><TAB><TAB>  r_tsz = residual . size ( 2 ) <TAB><TAB><TAB>  residual = residual [ . . . , : : r_tsz / / tsz ] [ . . . , : tsz ] <TAB><TAB><TAB>  x = ( x + residual ) * self . residual_scale <TAB>  if self . log_compression : <TAB><TAB>  x = x . abs ( ) <TAB><TAB>  x = x + 1 <TAB><TAB>  x = x . log ( ) <TAB>  return x ",if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,if self.residual_scale:,False,26.29208833561116,91.58118843186637
1363,"def __Prefix_Step2a ( self , token ) : <TAB>  for prefix in self . __prefix_step2a : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  token = token [ len ( prefix ) : ] <TAB><TAB><TAB>  self . prefix_step2a_success = True <TAB><TAB><TAB>  break <TAB>  return token ",if token . startswith ( prefix ) and len ( token ) > 5 :,if token.startswith(prefix):,False,44.50894875034329,91.11571463132499
1364,"def is_valid ( sample ) : <TAB>  if sample is None : <TAB><TAB>  return False <TAB>  if isinstance ( sample , tuple ) : <TAB><TAB>  for s in sample : <TAB><TAB><TAB>  if s is None : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB>  return True ","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :","if isinstance(sample, np.ndarray):",False,22.415948363887132,87.99841214065314
1365,"def get_all_comments ( self , gallery_id , post_no , comment_cnt ) : <TAB>  comment_page_cnt = ( comment_cnt - 1 ) / / self . options . comments_per_page + 1 <TAB>  comments = [ ] <TAB>  headers = { "" X-Requested-With "" : "" XMLHttpRequest "" } <TAB>  data = { "" ci_t "" : self . _session . cookies [ "" ci_c "" ] , "" id "" : gallery_id , "" no "" : post_no } <TAB>  for i in range ( comment_page_cnt ) : <TAB><TAB>  data [ "" comment_page "" ] = i + 1 <TAB><TAB>  response = self . request_comment ( headers , data ) <TAB><TAB>  batch = self . parse_comments ( response . text ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  comments = batch + comments <TAB>  return comments ",if not batch :,if not batch:,False,14.201186222147044,100.00000000000004
1366,def run_on_module ( self ) : <TAB>  try : <TAB><TAB>  self . module_base . disable ( self . opts . module_spec ) <TAB>  except dnf . exceptions . MarkingErrors as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if e . no_match_group_specs or e . error_group_specs : <TAB><TAB><TAB><TAB>  raise e <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  e . module_depsolv_errors <TAB><TAB><TAB><TAB>  and e . module_depsolv_errors [ 1 ] <TAB><TAB><TAB><TAB>  != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  raise e <TAB><TAB>  logger . error ( str ( e ) ) ,if self . base . conf . strict :,if e.module_spec is not None:,False,24.38531788133174,95.89233883852434
1367,"def find_field_notnull_differ ( self , meta , table_description , table_name ) : <TAB>  if not self . can_detect_notnull_differ : <TAB><TAB>  return <TAB>  for field in all_local_fields ( meta ) : <TAB><TAB>  attname = field . db_column or field . attname <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  null = self . get_field_db_nullable ( field , table_name ) <TAB><TAB>  if field . null != null : <TAB><TAB><TAB>  action = field . null and "" DROP "" or "" SET "" <TAB><TAB><TAB>  self . add_difference ( "" notnull-differ "" , table_name , attname , action ) ","if ( table_name , attname ) in self . new_db_fields :",if not field.is_null:,False,43.02327172722923,91.69400874338339
1368,"def _change_moving_module ( self , changes , dest ) : <TAB>  if not self . source . is_folder ( ) : <TAB><TAB>  pymodule = self . pycore . resource_to_pyobject ( self . source ) <TAB><TAB>  source = self . import_tools . relatives_to_absolutes ( pymodule ) <TAB><TAB>  pymodule = self . tools . new_pymodule ( pymodule , source ) <TAB><TAB>  source = self . _change_occurrences_in_module ( dest , pymodule ) <TAB><TAB>  source = self . tools . new_source ( pymodule , source ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  changes . add_change ( ChangeContents ( self . source , source ) ) ",if source != self . source . read ( ) :,if source is not None:,False,21.233384415372132,94.0503471635237
1369,"def get ( quality_name ) : <TAB>  """"""Returns a quality object based on canonical quality name."""""" <TAB>  found_components = { } <TAB>  for part in quality_name . lower ( ) . split ( ) : <TAB><TAB>  component = _registry . get ( part ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" ` %s ` is not a valid quality string "" % part ) <TAB><TAB>  if component . type in found_components : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" ` %s ` cannot be defined twice in a quality "" % component . type <TAB><TAB><TAB>  ) <TAB><TAB>  found_components [ component . type ] = component <TAB>  if not found_components : <TAB><TAB>  raise ValueError ( "" No quality specified "" ) <TAB>  result = Quality ( ) <TAB>  for type , component in found_components . items ( ) : <TAB><TAB>  setattr ( result , type , component ) <TAB>  return result ",if not component :,if not component:,False,60.19120931124704,100.00000000000004
1370,def _unselected ( self ) : <TAB>  selected = self . _selected <TAB>  k = 0 <TAB>  z = selected [ k ] <TAB>  k + = 1 <TAB>  for i in range ( self . _n ) : <TAB><TAB>  if i == z : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  z = selected [ k ] <TAB><TAB><TAB><TAB>  k + = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  z = - 1 <TAB><TAB>  else : <TAB><TAB><TAB>  yield i ,if k < len ( selected ) :,if selected[k] == 0:,False,18.68686244833788,92.8028249790049
1371,"def render_headers ( self ) - > bytes : <TAB>  if not hasattr ( self , "" _headers "" ) : <TAB><TAB>  parts = [ <TAB><TAB><TAB>  b "" Content-Disposition: form-data;  "" , <TAB><TAB><TAB>  format_form_param ( "" name "" , self . name ) , <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename = format_form_param ( "" filename "" , self . filename ) <TAB><TAB><TAB>  parts . extend ( [ b "" ;  "" , filename ] ) <TAB><TAB>  if self . content_type is not None : <TAB><TAB><TAB>  content_type = self . content_type . encode ( ) <TAB><TAB><TAB>  parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB><TAB>  parts . append ( b "" \r \n \r \n "" ) <TAB><TAB>  self . _headers = b "" "" . join ( parts ) <TAB>  return self . _headers ",if self . filename :,if self.filename is not None:,False,17.947878044096004,96.89744116885062
1372,"def app_middleware ( next , root , info , * * kwargs ) : <TAB>  app_auth_header = "" HTTP_AUTHORIZATION "" <TAB>  prefix = "" bearer "" <TAB>  request = info . context <TAB>  if request . path == API_PATH : <TAB><TAB>  if not hasattr ( request , "" app "" ) : <TAB><TAB><TAB>  request . app = None <TAB><TAB><TAB>  auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  auth_prefix , auth_token = auth <TAB><TAB><TAB><TAB>  if auth_prefix . lower ( ) == prefix : <TAB><TAB><TAB><TAB><TAB>  request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB>  return next ( root , info , * * kwargs ) ",if len ( auth ) == 2 :,if auth:,False,24.61943058635161,96.35099321002734
1373,"def _shortest_hypernym_paths ( self , simulate_root ) : <TAB>  if self . offset == "" 00000000 "" : <TAB><TAB>  return { self : 0 } <TAB>  queue = deque ( [ ( self , 0 ) ] ) <TAB>  path = { } <TAB>  while queue : <TAB><TAB>  s , depth = queue . popleft ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  path [ s ] = depth <TAB><TAB>  depth + = 1 <TAB><TAB>  queue . extend ( ( hyp , depth ) for hyp in s . _hypernyms ( ) ) <TAB>  if simulate_root : <TAB><TAB>  root = Synset ( self . _wordnet_corpus_reader , None , self . pos ( ) , "" 00000000 "" , "" "" ) <TAB><TAB>  path [ root ] = max ( path . values ( ) ) + 1 <TAB>  return path ",if s in path :,if depth == 0:,False,38.45965579726089,97.47874165150922
1374,"def _populate_class_variables ( ) : <TAB>  lookup = { } <TAB>  reverse_lookup = { } <TAB>  characters_for_re = [ ] <TAB>  for codepoint , name in list ( codepoint2name . items ( ) ) : <TAB><TAB>  character = chr ( codepoint ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # There's no point in turning the quotation mark into <TAB><TAB><TAB>  # &quot;, unless it happens within an attribute value, which <TAB><TAB><TAB>  # is handled elsewhere. <TAB><TAB><TAB>  characters_for_re . append ( character ) <TAB><TAB><TAB>  lookup [ character ] = name <TAB><TAB>  # But we do want to turn &quot; into the quotation mark. <TAB><TAB>  reverse_lookup [ name ] = character <TAB>  re_definition = "" [ %s ] "" % "" "" . join ( characters_for_re ) <TAB>  return lookup , reverse_lookup , re . compile ( re_definition ) ",if codepoint != 34 :,if character not in characters_for_re:,False,60.979720054961085,96.11117301101112
1375,"def prepare_data_status ( self , view : sublime . View , data : Dict [ str , Any ] ) - > Any : <TAB>  """"""Prepare the returned data for status"""""" <TAB>  if ( <TAB><TAB>  data [ "" success "" ] <TAB><TAB>  and "" No docstring "" not in data [ "" doc "" ] <TAB><TAB>  and data [ "" doc "" ] != "" list \n "" <TAB>  ) : <TAB><TAB>  self . signature = data [ "" doc "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  try : <TAB><TAB><TAB>  self . signature = self . signature . splitlines ( ) [ 2 ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  return <TAB><TAB>  return self . _show_status ( view ) ",if self . _signature_excluded ( self . signature ) :,if not self.signature:,False,25.50193987326101,94.80605381938665
1376,"def _setup_once_tables ( cls ) : <TAB>  if cls . run_define_tables == "" once "" : <TAB><TAB>  cls . define_tables ( cls . metadata ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . metadata . create_all ( cls . bind ) <TAB><TAB>  cls . tables . update ( cls . metadata . tables ) ","if cls . run_create_tables == ""once"" :",if cls.metadata.tables is None:,False,23.17578475416873,88.84102948667538
1377,"def _send_recursive ( self , files ) : <TAB>  for base in files : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # filename mixed into the bunch <TAB><TAB><TAB>  self . _send_files ( [ base ] ) <TAB><TAB><TAB>  continue <TAB><TAB>  last_dir = asbytes ( base ) <TAB><TAB>  for root , dirs , fls in os . walk ( base ) : <TAB><TAB><TAB>  self . _chdir ( last_dir , asbytes ( root ) ) <TAB><TAB><TAB>  self . _send_files ( [ os . path . join ( root , f ) for f in fls ] ) <TAB><TAB><TAB>  last_dir = asbytes ( root ) <TAB><TAB>  # back out of the directory <TAB><TAB>  for i in range ( len ( os . path . split ( last_dir ) ) ) : <TAB><TAB><TAB>  self . _send_popd ( ) ",if not os . path . isdir ( base ) :,if base == base:,False,29.76344107145563,95.74244342036616
1378,"def __init__ ( self , * args , * * kwargs ) : <TAB>  super ( ) . __init__ ( * args , * * kwargs ) <TAB>  # Automatically register models if required. <TAB>  if not is_registered ( self . model ) : <TAB><TAB>  inline_fields = ( ) <TAB><TAB>  for inline in self . inlines : <TAB><TAB><TAB>  inline_model , follow_field = self . _reversion_introspect_inline_admin ( inline ) <TAB><TAB><TAB>  if inline_model : <TAB><TAB><TAB><TAB>  self . _reversion_autoregister ( inline_model , ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  inline_fields + = ( follow_field , ) <TAB><TAB>  self . _reversion_autoregister ( self . model , inline_fields ) ",if follow_field :,if follow_field:,False,41.00120767430785,100.00000000000004
1379,"def dispatch_hook ( key , hooks , hook_data , * * kwargs ) : <TAB>  """"""Dispatches a hook dictionary on a given piece of data."""""" <TAB>  hooks = hooks or dict ( ) <TAB>  hooks = hooks . get ( key ) <TAB>  if hooks : <TAB><TAB>  if hasattr ( hooks , "" __call__ "" ) : <TAB><TAB><TAB>  hooks = [ hooks ] <TAB><TAB>  for hook in hooks : <TAB><TAB><TAB>  _hook_data = hook ( hook_data , * * kwargs ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  hook_data = _hook_data <TAB>  return hook_data ",if _hook_data is not None :,if _hook_data is not None:,False,55.03799266688942,100.00000000000004
1380,"def __call__ ( self , image , crop = True ) : <TAB>  if isinstance ( image , PTensor ) : <TAB><TAB>  return self . crop_to_output ( <TAB><TAB><TAB>  numpy_to_paddle ( self ( paddle_to_numpy ( image ) , crop = False ) ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  warp = cv . warpAffine ( <TAB><TAB><TAB>  image , <TAB><TAB><TAB>  self . transform_matrix , <TAB><TAB><TAB>  image . shape [ 1 : : - 1 ] , <TAB><TAB><TAB>  borderMode = cv . BORDER_REPLICATE , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . crop_to_output ( warp ) <TAB><TAB>  else : <TAB><TAB><TAB>  return warp ",if crop :,if crop:,False,50.65022842603777,98.35642800945634
1381,"def _analyze ( self ) : <TAB>  lines = open ( self . log_path , "" r "" ) . readlines ( ) <TAB>  prev_line = None <TAB>  for line in lines : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . errors . append ( line [ len ( "" ERROR: "" ) : ] . strip ( ) ) <TAB><TAB>  elif line . startswith ( "" FAIL: "" ) and prev_line and prev_line . startswith ( "" = "" ) : <TAB><TAB><TAB>  self . failures . append ( line [ len ( "" FAIL: "" ) : ] . strip ( ) ) <TAB><TAB>  prev_line = line ","if line . startswith ( ""ERROR:"" ) and prev_line and prev_line . startswith ( ""="" ) :",if line.startswith('ERROR: '):,False,51.303807140406455,88.38962899116336
1382,"def end ( self , name ) : <TAB>  self . soup . endData ( ) <TAB>  completed_tag = self . soup . tagStack [ - 1 ] <TAB>  namespace , name = self . _getNsTag ( name ) <TAB>  nsprefix = None <TAB>  if namespace is not None : <TAB><TAB>  for inverted_nsmap in reversed ( self . nsmaps ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  nsprefix = inverted_nsmap [ namespace ] <TAB><TAB><TAB><TAB>  break <TAB>  self . soup . handle_endtag ( name , nsprefix ) <TAB>  if len ( self . nsmaps ) > 1 : <TAB><TAB>  # This tag, or one of its parents, introduced a namespace <TAB><TAB>  # mapping, so pop it off the stack. <TAB><TAB>  self . nsmaps . pop ( ) ",if inverted_nsmap is not None and namespace in inverted_nsmap :,if completed_tag == inverted_nsmap[namespace]:,False,57.91380166490925,93.3182740688983
1383,"def _bind_parameters ( operation , parameters ) : <TAB>  # inspired by MySQL Python Connector (conversion.py) <TAB>  string_parameters = { } <TAB>  for ( name , value ) in parameters . iteritems ( ) : <TAB><TAB>  if value is None : <TAB><TAB><TAB>  string_parameters [ name ] = "" NULL "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  string_parameters [ name ] = "" ' "" + _escape ( value ) + "" ' "" <TAB><TAB>  else : <TAB><TAB><TAB>  string_parameters [ name ] = str ( value ) <TAB>  return operation % string_parameters ","elif isinstance ( value , basestring ) :",if value is not None:,False,31.261605816002145,94.7871925539351
1384,"def plugin_on_song_ended ( self , song , skipped ) : <TAB>  if song is not None : <TAB><TAB>  rating = song ( "" ~#rating "" ) <TAB><TAB>  invrating = 1.0 - rating <TAB><TAB>  delta = min ( rating , invrating ) / 2.0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rating - = delta <TAB><TAB>  else : <TAB><TAB><TAB>  rating + = delta <TAB><TAB>  song [ "" ~#rating "" ] = rating ",if skipped :,if skipped:,False,40.915169592571004,100.00000000000004
1385,"def on_activated_async ( self , view ) : <TAB>  if settings [ "" modified_lines_only "" ] : <TAB><TAB>  self . freeze_last_version ( view ) <TAB>  if settings [ "" enabled "" ] : <TAB><TAB>  match_trailing_spaces ( view ) <TAB><TAB>  # continuously watch view for changes to the visible region <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # track <TAB><TAB><TAB>  active_views [ view . id ( ) ] = view . visible_region ( ) <TAB><TAB><TAB>  self . update_on_region_change ( view ) ",if not view . id ( ) in active_views :,if view.visible_region():,False,60.98153277590366,93.85282810568604
1386,"def _notin_text ( term , text , verbose = False ) : <TAB>  index = text . find ( term ) <TAB>  head = text [ : index ] <TAB>  tail = text [ index + len ( term ) : ] <TAB>  correct_text = head + tail <TAB>  diff = _diff_text ( correct_text , text , verbose ) <TAB>  newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB>  for line in diff : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if line . startswith ( u ( "" -  "" ) ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if line . startswith ( u ( "" +  "" ) ) : <TAB><TAB><TAB>  newdiff . append ( u ( ""<TAB>"" ) + line [ 2 : ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  newdiff . append ( line ) <TAB>  return newdiff ","if line . startswith ( u ( ""Skipping"" ) ) :","if line.startswith(u(u(u(u""- "")):",False,24.366761193051353,94.9799874277372
1387,"def delete_all ( path ) : <TAB>  ppath = os . getcwd ( ) <TAB>  os . chdir ( path ) <TAB>  for fn in glob . glob ( "" * "" ) : <TAB><TAB>  fn_full = os . path . join ( path , fn ) <TAB><TAB>  if os . path . isdir ( fn ) : <TAB><TAB><TAB>  delete_all ( fn_full ) <TAB><TAB>  elif fn . endswith ( "" .png "" ) : <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB><TAB>  elif DELETE_ALL_OLD : <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB>  os . chdir ( ppath ) <TAB>  os . rmdir ( path ) ","elif fn . endswith ( "".md"" ) :",if os.path.isdir(fn_full):,False,50.911373001309535,94.99672759094736
1388,"def reward ( self ) : <TAB>  """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB>  raw_rewards , processed_rewards = 0 , 0 <TAB>  for ts in self . time_steps : <TAB><TAB>  # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB><TAB>  if ts . raw_reward is not None : <TAB><TAB><TAB>  raw_rewards + = ts . raw_reward <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  processed_rewards + = ts . processed_reward <TAB>  return raw_rewards , processed_rewards ",if ts . processed_reward is not None :,if ts.processed_reward is not None:,False,66.70423282280976,100.00000000000004
1389,"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB>  with TimeEncoding ( self . locale ) as encoding : <TAB><TAB>  s = month_name [ themonth ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s = s . decode ( encoding ) <TAB><TAB>  if withyear : <TAB><TAB><TAB>  s = "" %s %s "" % ( s , theyear ) <TAB><TAB>  return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s ",if encoding is not None :,"if isinstance(s, unicode):",False,28.085958475683437,94.613115843255
1390,"def check_digest_auth ( user , passwd ) : <TAB>  """"""Check user authentication using HTTP Digest auth"""""" <TAB>  if request . headers . get ( "" Authorization "" ) : <TAB><TAB>  credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  response_hash = response ( <TAB><TAB><TAB>  credentails , <TAB><TAB><TAB>  passwd , <TAB><TAB><TAB>  dict ( <TAB><TAB><TAB><TAB>  uri = request . script_root + request . path , <TAB><TAB><TAB><TAB>  body = request . data , <TAB><TAB><TAB><TAB>  method = request . method , <TAB><TAB><TAB>  ) , <TAB><TAB>  ) <TAB><TAB>  if credentails . get ( "" response "" ) == response_hash : <TAB><TAB><TAB>  return True <TAB>  return False ",if not credentails :,if not credentails:,False,56.05132710861015,100.00000000000004
1391,"def wrapped ( self , request ) : <TAB>  try : <TAB><TAB>  return self . _finished <TAB>  except AttributeError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not request . session . shouldfail and not request . session . shouldstop : <TAB><TAB><TAB><TAB>  log . debug ( <TAB><TAB><TAB><TAB><TAB>  "" %s  is still going to be used, not terminating it.  "" <TAB><TAB><TAB><TAB><TAB>  "" Still in use on: \n %s "" , <TAB><TAB><TAB><TAB><TAB>  self , <TAB><TAB><TAB><TAB><TAB>  pprint . pformat ( list ( self . node_ids ) ) , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  return <TAB><TAB>  log . debug ( "" Finish called on  %s "" , self ) <TAB><TAB>  try : <TAB><TAB><TAB>  return func ( request ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . _finished = True ",if self . node_ids :,if self._finished:,False,61.098478681308436,98.45499667359185
1392,"def run_tests ( ) : <TAB>  # type: () -> None <TAB>  x = 5 <TAB>  with switch ( x ) as case : <TAB><TAB>  if case ( 0 ) : <TAB><TAB><TAB>  print ( "" zero "" ) <TAB><TAB><TAB>  print ( "" zero "" ) <TAB><TAB>  elif case ( 1 , 2 ) : <TAB><TAB><TAB>  print ( "" one or two "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" three or four "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" default "" ) <TAB><TAB><TAB>  print ( "" another "" ) ","elif case ( 3 , 4 ) :","if case(2, 3):",False,27.03735245422219,96.41698317588322
1393,"def task_done ( self ) : <TAB>  with self . _cond : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" task_done() called too many times "" ) <TAB><TAB>  if self . _unfinished_tasks . _semlock . _is_zero ( ) : <TAB><TAB><TAB>  self . _cond . notify_all ( ) ",if not self . _unfinished_tasks . acquire ( False ) :,if self._unfinished_tasks._semlock._is_zero():,False,21.41232927821991,89.84417272709678
1394,"def _set_uid ( self , val ) : <TAB>  if val is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB><TAB><TAB>  val = None <TAB><TAB>  elif isinstance ( val , text_or_bytes ) : <TAB><TAB><TAB>  val = pwd . getpwnam ( val ) [ 2 ] <TAB>  self . _uid = val ",if pwd is None :,if not pwd:,False,48.108577342185896,96.40012101775575
1395,"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB>  with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB><TAB>  version = load_version_data ( hive_name , company , tag , tag_key ) <TAB><TAB>  if version is not None :<TAB># if failed to get version bail <TAB><TAB><TAB>  major , minor , _ = version <TAB><TAB><TAB>  arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB><TAB><TAB>  if arch is not None : <TAB><TAB><TAB><TAB>  exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  exe , args = exe_data <TAB><TAB><TAB><TAB><TAB>  return company , major , minor , arch , exe , args ",if exe_data is not None :,if exe_data is not None:,False,53.244541416360924,98.21479206893271
1396,"def run ( algs ) : <TAB>  for alg in algs : <TAB><TAB>  vcs = alg . get ( "" variantcaller "" ) <TAB><TAB>  if vcs : <TAB><TAB><TAB>  if isinstance ( vcs , dict ) : <TAB><TAB><TAB><TAB>  vcs = reduce ( operator . add , vcs . values ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  vcs = [ vcs ] <TAB><TAB><TAB>  return any ( vc . startswith ( prefix ) for vc in vcs if vc ) ","if not isinstance ( vcs , ( list , tuple ) ) :","if not isinstance(vcs, basestring):",False,38.12867018135353,95.48295290281621
1397,"def wrapper ( self , * args , * * kwargs ) : <TAB>  if not self . request . path . endswith ( "" / "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  uri = self . request . path + "" / "" <TAB><TAB><TAB>  if self . request . query : <TAB><TAB><TAB><TAB>  uri + = "" ? "" + self . request . query <TAB><TAB><TAB>  self . redirect ( uri , permanent = True ) <TAB><TAB><TAB>  return <TAB><TAB>  raise HTTPError ( 404 ) <TAB>  return method ( self , * args , * * kwargs ) ","if self . request . method in ( ""GET"" , ""HEAD"" ) :",if self.request.path:,False,29.071023701504746,92.40655180828497
1398,"def check_response ( self , response ) : <TAB>  """"""Specialized version of check_response()."""""" <TAB>  for line in response : <TAB><TAB>  # Skip blank lines: <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if line . startswith ( b "" OK "" ) : <TAB><TAB><TAB>  return <TAB><TAB>  elif line . startswith ( b "" Benutzer/Passwort Fehler "" ) : <TAB><TAB><TAB>  raise BadLogin ( line ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise FailedPost ( "" Server returned  ' %s ' "" % six . ensure_text ( line ) ) ",if not line . strip ( ) :,"if line.startswith(b""ERROR""):",False,51.10438367047241,92.9680429630529
1399,"def Walk ( self , hMenu = None ) : <TAB>  if not hMenu : <TAB><TAB>  hMenu = self . handle <TAB>  n = user32 . GetMenuItemCount ( hMenu ) <TAB>  mi = MENUITEMINFO ( ) <TAB>  for i in range ( n ) : <TAB><TAB>  mi . fMask = 2<TAB>#  MIIM_ID <TAB><TAB>  user32 . GetMenuItemInfoA ( hMenu , i , 1 , byref ( mi ) ) <TAB><TAB>  handle = user32 . GetSubMenu ( hMenu , i ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield handle , self . ListItems ( handle ) <TAB><TAB><TAB>  for i in self . Walk ( handle ) : <TAB><TAB><TAB><TAB>  yield i ",if handle :,if handle is not None:,False,21.058630631893184,94.82487135229508
1400,"def setSelection ( self , labels ) : <TAB>  input = self . __validateInput ( labels ) <TAB>  if len ( input ) == 0 and not self . __allowEmptySelection : <TAB><TAB>  return <TAB>  if self . __allowMultipleSelection : <TAB><TAB>  self . __selectedLabels [ : ] = input <TAB><TAB>  self . __selectionChanged ( ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  "" Parameter must be single item or a list with one element. "" <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . __selectedLabels [ : ] = input <TAB><TAB><TAB>  self . __selectionChanged ( ) <TAB>  # Remove all selected labels that are not in the menu, emit signals if necessary and update the button. <TAB>  self . __validateState ( ) ",if len ( input ) > 1 :,"if not isinstance(input, (list, tuple)):",False,64.66173895464301,95.06498133530259
1401,"def _parse ( self , engine ) : <TAB>  """"""Parse the layer."""""" <TAB>  if isinstance ( self . args , dict ) : <TAB><TAB>  if "" axis "" in self . args : <TAB><TAB><TAB>  self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB>  if not isinstance ( self . axis , int ) : <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB>  if "" momentum "" in self . args : <TAB><TAB><TAB>  self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if not isinstance ( self . momentum , ( int , float ) ) :","if not isinstance(self.momentum, (int, float)):",False,51.99913461112663,100.00000000000004
1402,"def get_order ( self , aBuf ) : <TAB>  if not aBuf : <TAB><TAB>  return - 1 , 1 <TAB>  # find out current char's byte length <TAB>  first_char = wrap_ord ( aBuf [ 0 ] ) <TAB>  if ( 0x81 < = first_char < = 0x9F ) or ( 0xE0 < = first_char < = 0xFC ) : <TAB><TAB>  charLen = 2 <TAB>  else : <TAB><TAB>  charLen = 1 <TAB>  # return its order if it is hiragana <TAB>  if len ( aBuf ) > 1 : <TAB><TAB>  second_char = wrap_ord ( aBuf [ 1 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return second_char - 0x9F , charLen <TAB>  return - 1 , charLen ",if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,if second_char > 0x9F:,False,56.77750424561382,87.26186643045524
1403,"def saveSpecial ( self , * * kwargs ) : <TAB>  for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST : <TAB><TAB>  item = config . get_config ( "" misc "" , kw ) <TAB><TAB>  value = kwargs . get ( kw ) <TAB><TAB>  msg = item . set ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return badParameterResponse ( msg ) <TAB>  config . save_config ( ) <TAB>  raise Raiser ( self . __root ) ",if msg :,if msg is not None:,False,28.218339305168243,96.48601406493847
1404,"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB>  # Sanity check: Don't honor keys that we don't recognize. <TAB>  for key in list ( kwargs . keys ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs . pop ( key ) <TAB>  # Truncate certain values over 1k <TAB>  for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB><TAB>  if isinstance ( kwargs . get ( "" event_data "" , { } ) . get ( key ) , str ) : <TAB><TAB><TAB>  if len ( kwargs [ "" event_data "" ] [ key ] ) > 1024 : <TAB><TAB><TAB><TAB>  kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB><TAB><TAB><TAB><TAB>  1024 <TAB><TAB><TAB><TAB>  ) ",if key not in valid_keys :,if key in valid_keys:,False,34.28888611840081,98.92304015041188
1405,"def toggleFactorReload ( self , value = None ) : <TAB>  self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB><TAB>  value <TAB><TAB>  if value is not None <TAB><TAB>  else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB>  ) <TAB>  fitIDs = set ( ) <TAB>  for fit in set ( self . _loadedFits ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if fit . calculated : <TAB><TAB><TAB>  fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB><TAB><TAB>  fit . clearFactorReloadDependentData ( ) <TAB><TAB><TAB>  fitIDs . add ( fit . ID ) <TAB>  return fitIDs ",if fit is None :,if not fit.isEnabled():,False,32.48855169399633,95.81175020183858
1406,"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB>  # find the closest unseen from this row/col <TAB>  min_dist = maxint <TAB>  closest_unseen = None <TAB>  for row in range ( self . height ) : <TAB><TAB>  for col in range ( self . width ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if self . map [ row ] [ col ] == UNSEEN : <TAB><TAB><TAB><TAB><TAB>  dist = self . distance ( row1 , col1 , row , col ) <TAB><TAB><TAB><TAB><TAB>  if dist < min_dist : <TAB><TAB><TAB><TAB><TAB><TAB>  min_dist = dist <TAB><TAB><TAB><TAB><TAB><TAB>  closest_unseen = ( row , col ) <TAB>  return closest_unseen ","if filter is None or ( row , col ) not in filter :",if filter is None:,False,55.60399897000774,95.37003258235356
1407,"def getAlphaClone ( lookfor , eager = None ) : <TAB>  if isinstance ( lookfor , int ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  item = get_gamedata_session ( ) . query ( AlphaClone ) . get ( lookfor ) <TAB><TAB>  else : <TAB><TAB><TAB>  item = ( <TAB><TAB><TAB><TAB>  get_gamedata_session ( ) <TAB><TAB><TAB><TAB>  . query ( AlphaClone ) <TAB><TAB><TAB><TAB>  . options ( * processEager ( eager ) ) <TAB><TAB><TAB><TAB>  . filter ( AlphaClone . ID == lookfor ) <TAB><TAB><TAB><TAB>  . first ( ) <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise TypeError ( "" Need integer as argument "" ) <TAB>  return item ",if eager is None :,if eager is None:,False,51.18331852367937,100.00000000000004
1408,"def _rle_encode ( string ) : <TAB>  new = b "" "" <TAB>  count = 0 <TAB>  for cur in string : <TAB><TAB>  if not cur : <TAB><TAB><TAB>  count + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  new + = b "" \0 "" + bytes ( [ count ] ) <TAB><TAB><TAB><TAB>  count = 0 <TAB><TAB><TAB>  new + = bytes ( [ cur ] ) <TAB>  return new ",if count :,if count > 0:,False,21.500518722960873,97.48099096887756
1409,def result_iterator ( ) : <TAB>  try : <TAB><TAB>  for future in fs : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield future . result ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield future . result ( end_time - time . time ( ) ) <TAB>  finally : <TAB><TAB>  for future in fs : <TAB><TAB><TAB>  future . cancel ( ) ,if timeout is None :,if future.cancelled():,False,24.48641403204917,94.72341858096623
1410,"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB>  if index_type == "" val "" : <TAB><TAB>  for key , value in segment . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return value <TAB><TAB><TAB>  if hasattr ( key , "" text "" ) : <TAB><TAB><TAB><TAB>  if key . text == index [ 0 ] : <TAB><TAB><TAB><TAB><TAB>  return value <TAB><TAB>  raise Exception ( "" Invalid state "" ) <TAB>  elif index_type == "" index "" : <TAB><TAB>  return segment [ index ] <TAB>  elif index_type == "" textslice "" : <TAB><TAB>  return segment [ index [ 0 ] : index [ 1 ] ] <TAB>  elif index_type == "" key "" : <TAB><TAB>  return index [ 1 ] if strictdoc else index [ 0 ] <TAB>  else : <TAB><TAB>  raise Exception ( "" Invalid state "" ) ",if key == index [ 0 ] :,if key.type == index[0] and value is not None:,False,25.38781226701477,96.22608188828723
1411,"def _reset_sequences ( self , db_name ) : <TAB>  conn = connections [ db_name ] <TAB>  if conn . features . supports_sequence_reset : <TAB><TAB>  sql_list = conn . ops . sequence_reset_by_name_sql ( <TAB><TAB><TAB>  no_style ( ) , conn . introspection . sequence_list ( ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  cursor = conn . cursor ( ) <TAB><TAB><TAB><TAB>  for sql in sql_list : <TAB><TAB><TAB><TAB><TAB>  cursor . execute ( sql ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  transaction . rollback_unless_managed ( using = db_name ) <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  transaction . commit_unless_managed ( using = db_name ) ",if sql_list :,if sql_list:,False,51.08539527914693,100.00000000000004
1412,"def translate_to_statements ( self , statements , conditional_write_vars ) : <TAB>  lines = [ ] <TAB>  for stmt in statements : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . temporary_vars . add ( ( stmt . var , stmt . dtype ) ) <TAB><TAB>  line = self . translate_statement ( stmt ) <TAB><TAB>  if stmt . var in conditional_write_vars : <TAB><TAB><TAB>  subs = { } <TAB><TAB><TAB>  condvar = conditional_write_vars [ stmt . var ] <TAB><TAB><TAB>  lines . append ( "" if  %s : "" % condvar ) <TAB><TAB><TAB>  lines . append ( indent ( line ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  lines . append ( line ) <TAB>  return lines ","if stmt . op == "":="" and not stmt . var in self . variables :","if isinstance(stmt, ast.Name):",False,44.95221814816577,91.2655311405282
1413,"def _bytecode_filenames ( self , py_filenames ) : <TAB>  bytecode_files = [ ] <TAB>  for py_file in py_filenames : <TAB><TAB>  # Since build_py handles package data installation, the <TAB><TAB>  # list of outputs can contain more than just .py files. <TAB><TAB>  # Make sure we only report bytecode for the .py files. <TAB><TAB>  ext = os . path . splitext ( os . path . normcase ( py_file ) ) [ 1 ] <TAB><TAB>  if ext != PYTHON_SOURCE_EXTENSION : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bytecode_files . append ( py_file + "" c "" ) <TAB><TAB>  if self . optimize > 0 : <TAB><TAB><TAB>  bytecode_files . append ( py_file + "" o "" ) <TAB>  return bytecode_files ",if self . compile :,if self.optimize > 0:,False,66.44647541944731,97.95519354525233
1414,"def logic ( ) : <TAB>  for i in range ( 100 ) : <TAB><TAB>  yield clock . posedge , reset . negedge <TAB><TAB>  if reset == ACTIVE_LOW : <TAB><TAB><TAB>  count . next = 0 <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  count . next = ( count + 1 ) % n <TAB>  raise StopSimulation ",if enable :,if reset == ACTIVE_HIGH:,False,49.29924377149698,93.13315033206047
1415,"def _is_subnet_of ( a , b ) : <TAB>  try : <TAB><TAB>  # Always false if one is v4 and the other is v6. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( "" %s  and  %s  are not of the same version "" % ( a , b ) ) <TAB><TAB>  return ( <TAB><TAB><TAB>  b . network_address < = a . network_address <TAB><TAB><TAB>  and b . broadcast_address > = a . broadcast_address <TAB><TAB>  ) <TAB>  except AttributeError : <TAB><TAB>  raise TypeError ( <TAB><TAB><TAB>  "" Unable to test subnet containment  "" "" between  %s  and  %s "" % ( a , b ) <TAB><TAB>  ) ",if a . _version != b . _version :,if a.version != b.version:,False,64.84040761847916,97.43155299743215
1416,"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB>  """""".gitignore style file filtering."""""" <TAB>  for item in exclude : <TAB><TAB>  # Items ending in '/' apply only to directories. <TAB><TAB>  if item . endswith ( "" / "" ) and not is_dir : <TAB><TAB><TAB>  continue <TAB><TAB>  # Items starting with '/' apply to the whole path. <TAB><TAB>  # In any other cases just the basename is used. <TAB><TAB>  match = path if item . startswith ( "" / "" ) else basename <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  return False ","if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",if match.startswith('/'):,False,67.25427456571778,91.99385551161016
1417,"def __recv_null ( self ) : <TAB>  """"""Receive a null byte."""""" <TAB>  while 1 : <TAB><TAB>  c = self . sock . recv ( 1 ) <TAB><TAB>  if c == "" "" : <TAB><TAB><TAB>  self . close ( ) <TAB><TAB><TAB>  raise EOFError ( "" Socket Closed "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ","if c == ""\0"" :",if c == '\n':,False,48.989800997976275,95.35944714760085
1418,"def onMessage ( self , payload , isBinary ) : <TAB>  if isBinary : <TAB><TAB>  self . result = "" Expected text message with payload, but got binary. "" <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . result = ( <TAB><TAB><TAB><TAB>  "" Expected text message with payload of length  %d , but got  %d . "" <TAB><TAB><TAB><TAB>  % ( self . DATALEN , len ( payload ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  ## FIXME : check actual content <TAB><TAB><TAB>  ## <TAB><TAB><TAB>  self . behavior = Case . OK <TAB><TAB><TAB>  self . result = "" Received text message of length  %d . "" % len ( payload ) <TAB>  self . p . createWirelog = True <TAB>  self . p . sendClose ( self . p . CLOSE_STATUS_CODE_NORMAL ) ",if len ( payload ) != self . DATALEN :,if self.DATALEN != len(payload):,False,59.074356356204696,97.62559898776331
1419,"def rename_path ( self , path , new_path ) : <TAB>  logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB>  dirs = self . readdir ( path ) <TAB>  for d in dirs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB><TAB>  d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB><TAB>  attr = self . getattr ( d_path ) <TAB><TAB>  if stat . S_ISDIR ( attr [ "" st_mode "" ] ) : <TAB><TAB><TAB>  self . rename_path ( d_path , d_new_path ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . rename_item ( d_path , d_new_path ) <TAB>  self . rename_item ( path , new_path , dir = True ) ","if d in [ ""."" , "".."" ] :",if not d.startswith('/'):,False,21.868961380119668,93.07134178188744
1420,"def dir_box_click ( self , double ) : <TAB>  if double : <TAB><TAB>  name = self . list_box . get_selected_name ( ) <TAB><TAB>  path = os . path . join ( self . directory , name ) <TAB><TAB>  suffix = os . path . splitext ( name ) [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . directory = path <TAB><TAB>  else : <TAB><TAB><TAB>  self . double_click_file ( name ) <TAB>  self . update ( ) ",if suffix not in self . suffixes and os . path . isdir ( path ) :,if suffix == 'dir':,False,21.31285998968332,89.35796688643644
1421,"def __getattr__ ( self , key ) : <TAB>  try : <TAB><TAB>  value = self . __parent . contents [ key ] <TAB>  except KeyError : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  if value is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return value . mod_ns <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  assert isinstance ( value , _MultipleClassMarker ) <TAB><TAB><TAB><TAB>  return value . attempt_get ( self . __parent . path , key ) <TAB>  raise AttributeError ( <TAB><TAB>  "" Module  %r  has no mapped classes  "" <TAB><TAB>  "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB>  ) ","if isinstance ( value , _ModuleMarker ) :","if isinstance(value, Module):",False,56.74916134039514,98.33517475254375
1422,"def poll_thread ( ) : <TAB>  time . sleep ( 0.5 ) <TAB>  if process . wait ( ) and process_state : <TAB><TAB>  time . sleep ( 0.25 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stdout , stderr = process . _communicate ( None ) <TAB><TAB><TAB>  logger . error ( <TAB><TAB><TAB><TAB>  "" Web server process exited unexpectedly "" , <TAB><TAB><TAB><TAB>  "" app "" , <TAB><TAB><TAB><TAB>  stdout = stdout , <TAB><TAB><TAB><TAB>  stderr = stderr , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  time . sleep ( 1 ) <TAB><TAB><TAB>  restart_server ( 1 ) ",if not check_global_interrupt ( ) :,if process.wait() and (not process_state):,False,47.71442680990093,94.27929534882372
1423,"def apply_dateparser_timezone ( utc_datetime , offset_or_timezone_abb ) : <TAB>  for name , info in _tz_offsets : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tz = StaticTzInfo ( name , info [ "" offset "" ] ) <TAB><TAB><TAB>  return utc_datetime . astimezone ( tz ) ","if info [ ""regex"" ] . search ( "" %s"" % offset_or_timezone_abb ) :",if offset_or_timezone_abb and info['offset'] == offset_or_timezone,False,38.54268692865313,82.13664377947616
1424,"def _load_wordlist ( filename ) : <TAB>  if filename is None : <TAB><TAB>  return { } <TAB>  path = None <TAB>  for dir in ( CONFIG_DIR , ASSETS_DIR ) : <TAB><TAB>  path = os . path . realpath ( os . path . join ( dir , filename ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  words = { } <TAB>  with open ( path , encoding = "" utf-8 "" ) as f : <TAB><TAB>  pairs = [ word . strip ( ) . rsplit ( "" "" , 1 ) for word in f ] <TAB><TAB>  pairs . sort ( reverse = True , key = lambda x : int ( x [ 1 ] ) ) <TAB><TAB>  words = { p [ 0 ] : int ( p [ 1 ] ) for p in pairs } <TAB>  return words ",if os . path . exists ( path ) :,if path is None:,False,24.8000321210461,95.50244465259176
1425,"def terminate_processes_matching_names ( match_strings , kill = False ) : <TAB>  """"""Terminates processes matching particular names (case sensitive)."""""" <TAB>  if isinstance ( match_strings , str ) : <TAB><TAB>  match_strings = [ match_strings ] <TAB>  for process in psutil . process_iter ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  process_info = process . as_dict ( attrs = [ "" name "" , "" pid "" ] ) <TAB><TAB><TAB>  process_name = process_info [ "" name "" ] <TAB><TAB>  except ( psutil . AccessDenied , psutil . NoSuchProcess , OSError ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  terminate_process ( process_info [ "" pid "" ] , kill ) ",if any ( x == process_name for x in match_strings ) :,if process_name == process_name:,False,26.79127225668749,93.98370556088373
1426,"def has_scheme ( self , inp ) : <TAB>  if "" :// "" in inp : <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  authority = inp . replace ( "" / "" , "" # "" ) . replace ( "" ? "" , "" # "" ) . split ( "" # "" ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _ , host_or_port = authority . split ( "" : "" , 1 ) <TAB><TAB><TAB>  # Assert it's not a port number <TAB><TAB><TAB>  if re . match ( r "" ^ \ d+$ "" , host_or_port ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  return True ","if "":"" in authority :",if authority:,False,23.01828751850649,97.21931900403013
1427,"def close ( self ) : <TAB>  with BrowserContext . _BROWSER_LOCK : <TAB><TAB>  BrowserContext . _BROWSER_REFCNT - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . info ( "" Destroying browser main loop "" ) <TAB><TAB><TAB>  BrowserContext . _BROWSER_LOOP . destroy ( ) <TAB><TAB><TAB>  BrowserContext . _BROWSER_LOOP = None ",if BrowserContext . _BROWSER_REFCNT == 0 :,if _BROWSER_LOOP is not None:,False,19.35052880139395,91.26103215154082
1428,"def _mock_get_merge_ticks ( self , order_book_id_list , trading_date , last_dt = None ) : <TAB>  for tick in self . _ticks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if ( <TAB><TAB><TAB>  self . env . data_proxy . get_future_trading_date ( tick . datetime ) . date ( ) <TAB><TAB><TAB>  != trading_date . date ( ) <TAB><TAB>  ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if last_dt and tick . datetime < = last_dt : <TAB><TAB><TAB>  continue <TAB><TAB>  yield tick ",if tick . order_book_id not in order_book_id_list :,if tick.datetime == trading_date.date():,False,46.178360368159346,91.93890332495441
1429,"def messageSourceStamps ( self , source_stamps ) : <TAB>  text = "" "" <TAB>  for ss in source_stamps : <TAB><TAB>  source = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB><TAB>  if ss [ "" revision "" ] : <TAB><TAB><TAB>  source + = str ( ss [ "" revision "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  source + = "" HEAD "" <TAB><TAB>  if ss [ "" patch "" ] is not None : <TAB><TAB><TAB>  source + = ""  (plus patch) "" <TAB><TAB>  discriminator = "" "" <TAB><TAB>  if ss [ "" codebase "" ] : <TAB><TAB><TAB>  discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB><TAB>  text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB>  return text ","if ss [ ""branch"" ] :",if ss['branch']:,False,20.855160123900315,97.1648522805543
1430,"def test_open_read_bytes ( self , sftp ) : <TAB>  """"""Test reading bytes from a file"""""" <TAB>  f = None <TAB>  try : <TAB><TAB>  self . _create_file ( "" file "" , "" xxx "" ) <TAB><TAB>  f = yield from sftp . open ( "" file "" , "" rb "" ) <TAB><TAB>  self . assertEqual ( ( yield from f . read ( ) ) , b "" xxx "" ) <TAB>  finally : <TAB><TAB>  <IF-STMT>:<TAB># pragma: no branch <TAB><TAB><TAB>  yield from f . close ( ) <TAB><TAB>  remove ( "" file "" ) ",if f :,if f is None:,False,30.33437359666956,95.41432967747319
1431,"def handler ( chan , host , port ) : <TAB>  sock = socket ( ) <TAB>  try : <TAB><TAB>  sock . connect ( ( host , port ) ) <TAB>  except Exception as e : <TAB><TAB>  if verbose == True : <TAB><TAB><TAB>  print ( e ) <TAB><TAB>  return <TAB>  while True : <TAB><TAB>  r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB><TAB>  if sock in r : <TAB><TAB><TAB>  data = sock . recv ( 1024 ) <TAB><TAB><TAB>  if len ( data ) == 0 : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  chan . send ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = chan . recv ( 1024 ) <TAB><TAB><TAB>  if len ( data ) == 0 : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  sock . send ( data ) <TAB>  chan . close ( ) <TAB>  sock . close ( ) ",if chan in r :,if w:,False,46.56857978187272,98.3653856556467
1432,"def detect ( get_page ) : <TAB>  retval = False <TAB>  for vector in WAF_ATTACK_VECTORS : <TAB><TAB>  page , headers , code = get_page ( get = vector ) <TAB><TAB>  retval = re . search ( r "" url \ ( ' /ks-waf-error \ .png ' \ ) "" , page , re . I ) is not None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return retval ",if retval :,if retval:,False,18.688629962132815,96.66465443060467
1433,"def __init__ ( self , raw ) : <TAB>  ticker_ticks = { } <TAB>  for tick in raw [ "" results "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ticker_ticks [ tick [ "" T "" ] ] . append ( tick ) <TAB><TAB>  else : <TAB><TAB><TAB>  ticker_ticks [ tick [ "" T "" ] ] = [ tick ] <TAB>  super ( ) . __init__ ( <TAB><TAB>  { ticker : Aggsv2 ( { "" results "" : ticks } ) for ticker , ticks in ticker_ticks . items ( ) } <TAB>  ) ","if ticker_ticks . get ( tick [ ""T"" ] ) :",if tick['T'] in ticker_ticks:,False,49.19817779140764,92.4174597414729
1434,"def _makefiles ( self , f ) : <TAB>  if isinstance ( f , dict ) : <TAB><TAB>  for k , v in list ( f . items ( ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . makedir ( dirname = k , content = v ) <TAB><TAB><TAB>  elif isinstance ( v , str ) : <TAB><TAB><TAB><TAB>  self . make_file ( filename = k , content = v ) <TAB><TAB><TAB>  else :<TAB># pragma: nocover <TAB><TAB><TAB><TAB>  raise ValueError ( "" Unexpected: "" , k , v ) <TAB>  elif isinstance ( f , str ) : <TAB><TAB>  self . _make_empty_file ( f ) <TAB>  elif isinstance ( f , list ) : <TAB><TAB>  self . make_list ( f ) <TAB>  else :<TAB># pragma: nocover <TAB><TAB>  raise ValueError ( "" Unknown type: "" , f ) ","if isinstance ( v , list ) :","if isinstance(v, (int, long)):",False,23.565008354825455,93.79631867266923
1435,"def migrate_command_storage ( apps , schema_editor ) : <TAB>  model = apps . get_model ( "" terminal "" , "" CommandStorage "" ) <TAB>  init_storage_data ( model ) <TAB>  setting = get_setting ( apps , schema_editor , "" TERMINAL_COMMAND_STORAGE "" ) <TAB>  if not setting : <TAB><TAB>  return <TAB>  values = get_storage_data ( setting ) <TAB>  for name , meta in values . items ( ) : <TAB><TAB>  tp = meta . pop ( "" TYPE "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  model . objects . create ( name = name , type = tp , meta = meta ) ","if not tp or name in [ ""default"" , ""null"" ] :","if not isinstance(tp, basestring):",False,20.85380260255362,92.10188691060473
1436,"def build_vertices ( self , ulines ) : <TAB>  vertex_idx = 0 <TAB>  vertices = collections . OrderedDict ( ) <TAB>  for line in ulines : <TAB><TAB>  for vt in line : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  new_vertex = ( vt . u , vt . v , 0.0 ) <TAB><TAB><TAB>  if new_vertex in vertices : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  vt . index = vertex_idx <TAB><TAB><TAB>  vertex_idx + = 1 <TAB><TAB><TAB>  vertices [ new_vertex ] = 1 <TAB>  return vertex_idx , list ( vertices . keys ( ) ) ",if vt . replacement is not None :,if vt.index == vertex_idx:,False,42.273270982967716,96.13867314831056
1437,"def get_quarantine_count ( self ) : <TAB>  """"""get obj/container/account quarantine counts"""""" <TAB>  qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB>  qdir = "" quarantined "" <TAB>  for device in os . listdir ( self . devices ) : <TAB><TAB>  for qtype in qcounts : <TAB><TAB><TAB>  qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB><TAB><TAB>  if os . path . exists ( qtgt ) : <TAB><TAB><TAB><TAB>  linkcount = os . lstat ( qtgt ) . st_nlink <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  qcounts [ qtype ] + = linkcount - 2 <TAB>  return qcounts ",if linkcount > 2 :,if linkcount > 2:,False,47.77407482037293,100.00000000000004
1438,"def _format_arg ( self , name , trait_spec , value ) : <TAB>  if name == "" mask_file "" : <TAB><TAB>  return "" "" <TAB>  if name == "" op_string "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isdefined ( self . inputs . mask_file ) : <TAB><TAB><TAB><TAB>  return self . inputs . op_string % self . inputs . mask_file <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise ValueError ( "" -k  %s  option in op_string requires mask_file "" ) <TAB>  return super ( ImageStats , self ) . _format_arg ( name , trait_spec , value ) ","if ""-k %s"" in self . inputs . op_string :",if name == 'op_file':,False,28.350995163685845,92.27036607338295
1439,"def _update_theme_style ( self , * args ) : <TAB>  self . line_color_normal = self . theme_cls . divider_color <TAB>  if not any ( [ self . error , self . _text_len_error ] ) : <TAB><TAB>  if not self . focus : <TAB><TAB><TAB>  self . _current_hint_text_color = self . theme_cls . disabled_hint_text_color <TAB><TAB><TAB>  self . _current_right_lbl_color = self . theme_cls . disabled_hint_text_color <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _current_error_color = self . theme_cls . disabled_hint_text_color ","if self . helper_text_mode == ""persistent"" :","if not any([[self.error, self._text_len_error, self.",False,28.83198098902388,90.2302444012413
1440,"def createFields ( self ) : <TAB>  for item in self . format : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield item [ 0 ] ( self , * item [ 1 : - 1 ] , * * item [ - 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield item [ 0 ] ( self , * item [ 1 : ] ) ","if isinstance ( item [ - 1 ] , dict ) :",if len(item) > 1:,False,20.52916390208174,84.6297960734387
1441,"def execute ( self , statement , arguments = None ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . cursor . execute ( statement , arguments ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . cursor . execute ( statement ) <TAB><TAB>  except sqlite3 . OperationalError as ex : <TAB><TAB><TAB>  if "" locked "" not in getSafeExString ( ex ) : <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB><TAB>  return self . cursor . fetchall ( ) ",if arguments :,if arguments:,False,51.08596793791658,100.00000000000004
1442,"def set_income_account_for_fixed_assets ( self ) : <TAB>  disposal_account = depreciation_cost_center = None <TAB>  for d in self . get ( "" items "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not disposal_account : <TAB><TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB><TAB>  disposal_account , <TAB><TAB><TAB><TAB><TAB>  depreciation_cost_center , <TAB><TAB><TAB><TAB>  ) = get_disposal_account_and_cost_center ( self . company ) <TAB><TAB><TAB>  d . income_account = disposal_account <TAB><TAB><TAB>  if not d . cost_center : <TAB><TAB><TAB><TAB>  d . cost_center = depreciation_cost_center ",if d . is_fixed_asset :,if d.income_account is None:,False,50.22963404040021,97.1943740232306
1443,"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB>  nbMinBit = None <TAB>  nbMaxBit = None <TAB>  if nbChars is not None : <TAB><TAB>  if isinstance ( nbChars , int ) : <TAB><TAB><TAB>  nbMinBit = nbChars * 8 <TAB><TAB><TAB>  nbMaxBit = nbMinBit <TAB><TAB>  else : <TAB><TAB><TAB>  if nbChars [ 0 ] is not None : <TAB><TAB><TAB><TAB>  nbMinBit = nbChars [ 0 ] * 8 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  nbMaxBit = nbChars [ 1 ] * 8 <TAB>  return ( nbMinBit , nbMaxBit ) ",if nbChars [ 1 ] is not None :,if nbChars[1] is not None:,False,52.6726269370791,100.00000000000004
1444,"def _get_service_full_name ( self , name , help_command_table ) : <TAB>  if help_command_table and name not in self . _NON_SERVICE_COMMANDS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _HIGH_LEVEL_SERVICE_FULL_NAMES [ name ] <TAB><TAB>  service = help_command_table . get ( name ) <TAB><TAB>  if service : <TAB><TAB><TAB>  return service . service_model . metadata [ "" serviceFullName "" ] ",if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,if name in self._HIGH_LEVEL_SERVICE_FULL_NAMES:,False,58.6051749454381,100.00000000000004
1445,"def print_addresses ( self ) : <TAB>  p = 3 <TAB>  tmp_str = "" [ "" <TAB>  if self . get_len ( ) > = 7 :<TAB># at least one complete IP address <TAB><TAB>  while 1 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tmp_str + = "" # "" <TAB><TAB><TAB>  tmp_str + = self . get_ip_address ( p ) <TAB><TAB><TAB>  p + = 4 <TAB><TAB><TAB>  if p > = self . get_len ( ) : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  tmp_str + = "" ,  "" <TAB>  tmp_str + = "" ]  "" <TAB>  if self . get_ptr ( ) % 4 :<TAB># ptr field should be a multiple of 4 <TAB><TAB>  tmp_str + = "" nonsense ptr field:  %d "" % self . get_ptr ( ) <TAB>  return tmp_str ",if p + 1 == self . get_ptr ( ) :,if p < 7:,False,52.249897409231494,94.16977169823257
1446,"def run ( self ) : <TAB>  for _ in range ( self . n ) : <TAB><TAB>  error = True <TAB><TAB>  try : <TAB><TAB><TAB>  self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB><TAB><TAB>  error = False <TAB><TAB>  except : <TAB><TAB><TAB>  if not self . expect_exception : <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert error ",if self . expect_exception :,if self.expect_exception:,False,51.344806927517276,100.00000000000004
1447,"def create_composite_mounter_by_args ( args ) : <TAB>  """"""Creates a CompositeMounter by the images in given args."""""" <TAB>  logging . info ( "" Mount images... "" ) <TAB>  mounter = composite_mounter . CompositeMounter ( ) <TAB>  for partition in composite_mounter . SUPPORTED_PARTITIONS : <TAB><TAB>  image_source = vars ( args ) [ partition ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logging . info ( ""<TAB>%s = %s "" , partition , image_source ) <TAB><TAB><TAB>  mounter . add_by_mount_target ( partition , image_source ) <TAB>  if mounter . is_empty ( ) : <TAB><TAB>  raise RuntimeError ( "" Must give at least one image source. "" ) <TAB>  return mounter ",if image_source :,if image_source:,False,60.92965742119627,97.65707625998525
1448,"def _get_containing_class ( self , pyname ) : <TAB>  if isinstance ( pyname , pynames . DefinedName ) : <TAB><TAB>  scope = pyname . get_object ( ) . get_scope ( ) <TAB><TAB>  parent = scope . parent <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return parent . pyobject ","if parent is not None and parent . get_kind ( ) == ""Class"" :",if parent is not None:,False,21.187179087192913,83.90376841843329
1449,"def test_chunkcoding ( self ) : <TAB>  tstring_lines = [ ] <TAB>  for b in self . tstring : <TAB><TAB>  lines = b . split ( b "" \n "" ) <TAB><TAB>  last = lines . pop ( ) <TAB><TAB>  assert last == b "" "" <TAB><TAB>  lines = [ line + b "" \n "" for line in lines ] <TAB><TAB>  tstring_lines . append ( lines ) <TAB>  for native , utf8 in zip ( * tstring_lines ) : <TAB><TAB>  u = self . decode ( native ) [ 0 ] <TAB><TAB>  self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( native , self . encode ( u ) [ 0 ] ) ",if self . roundtriptest :,if u == u:,False,17.674204483878597,97.1815590545188
1450,"def set_default_variants ( apps , schema_editor ) : <TAB>  Product = apps . get_model ( "" product "" , "" Product "" ) <TAB>  for product in Product . objects . iterator ( ) : <TAB><TAB>  first_variant = product . variants . first ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  product . default_variant = first_variant <TAB><TAB><TAB>  product . save ( update_fields = [ "" default_variant "" , "" updated_at "" ] ) ",if first_variant :,if first_variant is not None:,False,28.92324892735673,96.40170192701808
1451,"def json ( self ) : <TAB>  try : <TAB><TAB>  if self . is_json ( ) : <TAB><TAB><TAB>  raw_data = self . raw_data ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raw_data = raw_data . decode ( "" utf-8 "" ) <TAB><TAB><TAB>  return json . loads ( raw_data ) <TAB>  except ValueError : <TAB><TAB>  pass ","if not isinstance ( raw_data , text_type ) :","if isinstance(raw_data, unicode):",False,48.02280841071003,94.2970454658956
1452,"def clear_react ( self , message : discord . Message , emoji : MutableMapping = None ) - > None : <TAB>  try : <TAB><TAB>  await message . clear_reactions ( ) <TAB>  except discord . Forbidden : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  with contextlib . suppress ( discord . HTTPException ) : <TAB><TAB><TAB>  async for key in AsyncIter ( emoji . values ( ) , delay = 0.2 ) : <TAB><TAB><TAB><TAB>  await message . remove_reaction ( key , self . bot . user ) <TAB>  except discord . HTTPException : <TAB><TAB>  return ",if not emoji :,if emoji is None:,False,49.50030480071847,97.21929240801559
1453,"def check ( self , value ) : <TAB>  value = String . check ( self , value ) <TAB>  if isinstance ( value , str ) : <TAB><TAB>  value = value . upper ( ) <TAB><TAB>  for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB><TAB><TAB>  # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB><TAB><TAB>  if value . startswith ( prefix ) : <TAB><TAB><TAB><TAB>  value = value [ len ( prefix ) : ] <TAB><TAB><TAB>  value = value . lstrip ( "" _ "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return getattr ( self . group , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" No such constant:  %s _ %s "" % ( self . prefix , value ) ) <TAB>  else : <TAB><TAB>  return value ","if hasattr ( self . group , value ) :","if hasattr(self.group, value):",False,56.97542449973747,100.00000000000004
1454,"def value ( self ) : <TAB>  quote = False <TAB>  if self . defects : <TAB><TAB>  quote = True <TAB>  else : <TAB><TAB>  for x in self : <TAB><TAB><TAB>  if x . token_type == "" quoted-string "" : <TAB><TAB><TAB><TAB>  quote = True <TAB>  if quote : <TAB><TAB>  pre = post = "" "" <TAB><TAB>  if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB><TAB><TAB>  pre = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  post = "" "" <TAB><TAB>  return pre + quote_string ( self . display_name ) + post <TAB>  else : <TAB><TAB>  return super ( DisplayName , self ) . value ","if self [ - 1 ] . token_type == ""cfws"" or self [ - 1 ] [ - 1 ] . token_type == ""cfws"" :","if self[0].token_type == ""cfws':",False,25.943704092533835,90.19540538825552
1455,"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB>  for drive in self . drives : <TAB><TAB>  if root_path : <TAB><TAB><TAB>  config_root_path = drive . get ( "" root_path "" ) <TAB><TAB><TAB>  if config_root_path and root_path == config_root_path : <TAB><TAB><TAB><TAB>  return drive <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB><TAB><TAB>  if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB><TAB><TAB><TAB>  return drive ",elif volume_guid_path :,if volume_guid_path:,False,49.49203698451991,98.73569411297849
1456,"def parse_edges ( self , pcb ) : <TAB>  edges = [ ] <TAB>  drawings = list ( pcb . GetDrawings ( ) ) <TAB>  bbox = None <TAB>  for m in pcb . GetModules ( ) : <TAB><TAB>  for g in m . GraphicalItems ( ) : <TAB><TAB><TAB>  drawings . append ( g ) <TAB>  for d in drawings : <TAB><TAB>  if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB><TAB><TAB>  parsed_drawing = self . parse_drawing ( d ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  edges . append ( parsed_drawing ) <TAB><TAB><TAB><TAB>  if bbox is None : <TAB><TAB><TAB><TAB><TAB>  bbox = d . GetBoundingBox ( ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  bbox . Merge ( d . GetBoundingBox ( ) ) <TAB>  if bbox : <TAB><TAB>  bbox . Normalize ( ) <TAB>  return edges , bbox ",if parsed_drawing :,if parsed_drawing is not None:,False,31.87750470150277,98.29591943895359
1457,"def to_key ( literal_or_identifier ) : <TAB>  """"""returns string representation of this object"""""" <TAB>  if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB>  return literal_or_identifier [ "" name "" ] <TAB>  elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB>  k = literal_or_identifier [ "" value "" ] <TAB><TAB>  if isinstance ( k , float ) : <TAB><TAB><TAB>  return unicode ( float_repr ( k ) ) <TAB><TAB>  elif "" regex "" in literal_or_identifier : <TAB><TAB><TAB>  return compose_regex ( k ) <TAB><TAB>  elif isinstance ( k , bool ) : <TAB><TAB><TAB>  return "" true "" if k else "" false "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" null "" <TAB><TAB>  else : <TAB><TAB><TAB>  return unicode ( k ) ",elif k is None :,if not literal_or_identifier:,False,50.63820388385145,96.57626230436388
1458,"def find_multiple_stats ( stats , name , _found = None , _on_found = None ) : <TAB>  if _found is None : <TAB><TAB>  _found = [ ] <TAB>  for child_stats in stats : <TAB><TAB>  if child_stats . name == name : <TAB><TAB><TAB>  _found . append ( child_stats ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  _on_found ( _found ) <TAB><TAB>  find_multiple_stats ( child_stats , name , _found ) <TAB>  return _found ",if callable ( _on_found ) :,if _on_found is not None:,False,49.33298111788705,96.01669286939061
1459,"def _run_generated_code ( <TAB>  self , <TAB>  code , <TAB>  globs , <TAB>  locs , <TAB>  fails_under_py3k = True ,  ) : <TAB>  import warnings <TAB>  from zope . interface . _compat import PYTHON3 <TAB>  with warnings . catch_warnings ( record = True ) as log : <TAB><TAB>  warnings . resetwarnings ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exec ( code , globs , locs ) <TAB><TAB><TAB>  self . assertEqual ( len ( log ) , 0 )<TAB># no longer warn <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  exec ( code , globs , locs ) <TAB><TAB><TAB>  except TypeError : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  if fails_under_py3k : <TAB><TAB><TAB><TAB><TAB>  self . fail ( "" Didn ' t raise TypeError "" ) ",if not PYTHON3 :,if PYTHON3:,False,44.64616264087049,96.10489927295555
1460,"def _get_node ( self , node_id ) : <TAB>  self . non_terminated_nodes ( { } )<TAB># Side effect: updates cache <TAB>  with self . lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . cached_nodes [ node_id ] <TAB><TAB>  instance = ( <TAB><TAB><TAB>  self . compute . instances ( ) <TAB><TAB><TAB>  . get ( <TAB><TAB><TAB><TAB>  project = self . provider_config [ "" project_id "" ] , <TAB><TAB><TAB><TAB>  zone = self . provider_config [ "" availability_zone "" ] , <TAB><TAB><TAB><TAB>  instance = node_id , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  . execute ( ) <TAB><TAB>  ) <TAB><TAB>  return instance ",if node_id in self . cached_nodes :,if node_id in self.cached_nodes:,False,41.278563337586995,98.00946692295871
1461,"def skip_to_close_match ( self ) : <TAB>  nestedCount = 1 <TAB>  while 1 : <TAB><TAB>  tok = self . tokenizer . get_next_token ( ) <TAB><TAB>  ttype = tok [ "" style "" ] <TAB><TAB>  if ttype == SCE_PL_UNUSED : <TAB><TAB><TAB>  return <TAB><TAB>  elif self . classifier . is_index_op ( tok ) : <TAB><TAB><TAB>  tval = tok [ "" text "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if self . opHash [ tval ] [ 1 ] == 1 : <TAB><TAB><TAB><TAB><TAB>  nestedCount + = 1 <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  nestedCount - = 1 <TAB><TAB><TAB><TAB><TAB>  if nestedCount < = 0 : <TAB><TAB><TAB><TAB><TAB><TAB>  break ",if self . opHash . has_key ( tval ) :,if tval in self.opHash:,False,21.665558915610784,96.19645841075705
1462,"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB>  # Prefer creating a new helper when at least one kwarg is specified. <TAB>  prefer_new = len ( kwargs ) > 0 <TAB>  kwargs . update ( infer_mode = infer_mode ) <TAB>  is_training = not infer_mode if infer_mode is not None else self . training <TAB>  helper = self . _train_helper if is_training else self . _infer_helper <TAB>  if prefer_new or helper is None : <TAB><TAB>  helper = self . create_helper ( * * kwargs ) <TAB><TAB>  if is_training and self . _train_helper is None : <TAB><TAB><TAB>  self . _train_helper = helper <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _infer_helper = helper <TAB>  return helper ",elif not is_training and self . _infer_helper is None :,if infer_mode is not None:,False,25.356838337934622,94.16212712697033
1463,"def get_ldset ( self , ldsets ) : <TAB>  ldset = None <TAB>  if self . _properties [ "" ldset_name "" ] == "" "" : <TAB><TAB>  nldset = len ( ldsets ) <TAB><TAB>  if nldset == 0 : <TAB><TAB><TAB>  msg = _ ( "" Logical Disk Set could not be found. "" ) <TAB><TAB><TAB>  raise exception . NotFound ( msg ) <TAB><TAB>  else : <TAB><TAB><TAB>  ldset = None <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg = ( <TAB><TAB><TAB><TAB>  _ ( "" Logical Disk Set ` %s ` could not be found. "" ) <TAB><TAB><TAB><TAB>  % self . _properties [ "" ldset_name "" ] <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  raise exception . NotFound ( msg ) <TAB><TAB>  ldset = ldsets [ self . _properties [ "" ldset_name "" ] ] <TAB>  return ldset ","if self . _properties [ ""ldset_name"" ] not in ldsets :",if not ldsets:,False,41.62816118204423,94.51030912429884
1464,"def calc_fractal_serial ( q , maxiter ) : <TAB>  # calculate z using pure python on a numpy array <TAB>  # note that, unlike the other two implementations, <TAB>  # the number of iterations per point is NOT constant <TAB>  z = np . zeros ( q . shape , complex ) <TAB>  output = np . resize ( <TAB><TAB>  np . array ( <TAB><TAB><TAB>  0 , <TAB><TAB>  ) , <TAB><TAB>  q . shape , <TAB>  ) <TAB>  for i in range ( len ( q ) ) : <TAB><TAB>  for iter in range ( maxiter ) : <TAB><TAB><TAB>  z [ i ] = z [ i ] * z [ i ] + q [ i ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  output [ i ] = iter <TAB><TAB><TAB><TAB>  break <TAB>  return output ",if abs ( z [ i ] ) > 2.0 :,"if np.isclose(z, 0):",False,38.9048392637653,95.83399313325147
1465,"def _verifySubs ( self ) : <TAB>  for inst in self . subs : <TAB><TAB>  if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB><TAB><TAB>  raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not inst . modctxt : <TAB><TAB><TAB><TAB>  raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) ) ","if isinstance ( inst , ( _Block , _Instantiator ) ) :","if isinstance(inst, _Block):",False,22.20567625675231,94.05903189024482
1466,"def walks_generator ( ) : <TAB>  if filelist is not None : <TAB><TAB>  bucket = [ ] <TAB><TAB>  for filename in filelist : <TAB><TAB><TAB>  with io . open ( filename ) as inf : <TAB><TAB><TAB><TAB>  for line in inf : <TAB><TAB><TAB><TAB><TAB>  walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( "" "" ) ] <TAB><TAB><TAB><TAB><TAB>  bucket . append ( walk ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  yield bucket <TAB><TAB><TAB><TAB><TAB><TAB>  bucket = [ ] <TAB><TAB>  if len ( bucket ) : <TAB><TAB><TAB>  yield bucket <TAB>  else : <TAB><TAB>  for _ in range ( epoch ) : <TAB><TAB><TAB>  for nodes in graph . node_batch_iter ( batch_size ) : <TAB><TAB><TAB><TAB>  walks = graph . random_walk ( nodes , walk_len ) <TAB><TAB><TAB><TAB>  yield walks ",if len ( bucket ) == batch_size :,if len(bucket) > 0:,False,50.402372242875714,97.89101051584002
1467,def _traverse ( op ) : <TAB>  if op in visited : <TAB><TAB>  return <TAB>  visited . add ( op ) <TAB>  if tag . is_injective ( op . tag ) : <TAB><TAB>  if op not in s . outputs : <TAB><TAB><TAB>  s [ op ] . compute_inline ( ) <TAB><TAB>  for tensor in op . input_tensors : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  _traverse ( tensor . op ) <TAB>  callback ( op ) ,"if isinstance ( tensor . op , tvm . te . ComputeOp ) :",if tensor.op.type == op.OP_TYPE_INVOKED:,False,25.99961274018928,90.55112026744474
1468,"def unwatch_run ( self , run_id , handler ) : <TAB>  with self . _dict_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _handlers_dict [ run_id ] = [ <TAB><TAB><TAB><TAB>  ( start_cursor , callback ) <TAB><TAB><TAB><TAB>  for ( start_cursor , callback ) in self . _handlers_dict [ run_id ] <TAB><TAB><TAB><TAB>  if callback != handler <TAB><TAB><TAB>  ] <TAB><TAB>  if not self . _handlers_dict [ run_id ] : <TAB><TAB><TAB>  del self . _handlers_dict [ run_id ] <TAB><TAB><TAB>  run_id_dict = self . _run_id_dict <TAB><TAB><TAB>  del run_id_dict [ run_id ] <TAB><TAB><TAB>  self . _run_id_dict = run_id_dict ",if run_id in self . _run_id_dict :,if run_id not in self._handlers_dict:,False,50.54515125573638,97.5981410976512
1469,"def _PromptMySQL ( self , config ) : <TAB>  """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB>  while True : <TAB><TAB>  self . _PromptMySQLOnce ( config ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB><TAB><TAB>  retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB><TAB><TAB>  if not retry : <TAB><TAB><TAB><TAB>  raise ConfigInitError ( ) ",if self . _CheckMySQLConnection ( ) :,if self.TryTry(config):,False,66.89431044470928,97.67559353967069
1470,"def get_courses_without_topic ( topic ) : <TAB>  data = [ ] <TAB>  for entry in frappe . db . get_all ( "" Course "" ) : <TAB><TAB>  course = frappe . get_doc ( "" Course "" , entry . name ) <TAB><TAB>  topics = [ t . topic for t in course . topics ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data . append ( course . name ) <TAB>  return data ",if not topics or topic not in topics :,if topic in topics:,False,21.90636205932226,94.50479317599181
1471,"def _error_handler ( action , * * keywords ) : <TAB>  if keywords : <TAB><TAB>  file_type = keywords . get ( "" file_type "" , None ) <TAB><TAB>  if file_type : <TAB><TAB><TAB>  raise exceptions . FileTypeNotSupported ( <TAB><TAB><TAB><TAB>  constants . FILE_TYPE_NOT_SUPPORTED_FMT % ( file_type , action ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  keywords . pop ( "" on_demand "" ) <TAB><TAB><TAB>  msg = "" Please check if there were typos in  "" <TAB><TAB><TAB>  msg + = "" function parameters:  %s . Otherwise  "" <TAB><TAB><TAB>  msg + = "" unrecognized parameters were given. "" <TAB><TAB><TAB>  raise exceptions . UnknownParameters ( msg % keywords ) <TAB>  else : <TAB><TAB>  raise exceptions . UnknownParameters ( "" No parameters found! "" ) ","if ""on_demand"" in keywords :","if ""on_demand"" in keywords:",False,34.702009982205944,100.00000000000004
1472,"def select ( self , regions , register ) : <TAB>  self . view . sel ( ) . clear ( ) <TAB>  to_store = [ ] <TAB>  for r in regions : <TAB><TAB>  self . view . sel ( ) . add ( r ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB>  <IF-STMT>: <TAB><TAB>  text = "" "" . join ( to_store ) <TAB><TAB>  if not text . endswith ( "" \n "" ) : <TAB><TAB><TAB>  text = text + "" \n "" <TAB><TAB>  state = State ( self . view ) <TAB><TAB>  state . registers [ register ] = [ text ] ",if register :,if to_store:,False,33.91394998899202,95.260959396527
1473,"def has_actor ( self , message : HasActorMessage ) - > ResultMessage : <TAB>  actor_ref = message . actor_ref <TAB>  # lookup allocated <TAB>  for address , item in self . _allocated_actors . items ( ) : <TAB><TAB>  ref = create_actor_ref ( address , actor_ref . uid ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ResultMessage ( message . message_id , True , protocol = message . protocol ) <TAB>  return ResultMessage ( message . message_id , False , protocol = message . protocol ) ",if ref in item :,if ref is not None:,False,45.73035222016586,96.54006048023358
1474,"def toggleMetaButton ( self , event ) : <TAB>  """"""Process clicks on toggle buttons"""""" <TAB>  clickedBtn = event . EventObject <TAB>  if wx . GetMouseState ( ) . GetModifiers ( ) == wx . MOD_CONTROL : <TAB><TAB>  activeBtns = [ btn for btn in self . metaButtons if btn . GetValue ( ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  clickedBtn . setUserSelection ( clickedBtn . GetValue ( ) ) <TAB><TAB><TAB>  self . itemView . filterItemStore ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  # Do 'nothing' if we're trying to turn last active button off <TAB><TAB><TAB>  # Keep button in the same state <TAB><TAB><TAB>  clickedBtn . setUserSelection ( True ) <TAB>  else : <TAB><TAB>  for btn in self . metaButtons : <TAB><TAB><TAB>  btn . setUserSelection ( btn == clickedBtn ) <TAB><TAB>  self . itemView . filterItemStore ( ) ",if activeBtns :,if activeBtns:,False,62.83944933853698,100.00000000000004
1475,"def __init__ ( self , hub = None ) :<TAB># pylint: disable=unused-argument <TAB>  if resolver . _resolver is None : <TAB><TAB>  _resolver = resolver . _resolver = _DualResolver ( ) <TAB><TAB>  if config . resolver_nameservers : <TAB><TAB><TAB>  _resolver . network_resolver . nameservers [ : ] = config . resolver_nameservers <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _resolver . network_resolver . lifetime = config . resolver_timeout <TAB>  # Different hubs in different threads could be sharing the same <TAB>  # resolver. <TAB>  assert isinstance ( resolver . _resolver , _DualResolver ) <TAB>  self . _resolver = resolver . _resolver ",if config . resolver_timeout :,if config.resolver_timeout:,False,47.00897751538455,97.36943262081637
1476,"def sub_paragraph ( self , li ) : <TAB>  """"""Search for checkbox in sub-paragraph."""""" <TAB>  found = False <TAB>  if len ( li ) : <TAB><TAB>  first = list ( li ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  m = RE_CHECKBOX . match ( first . text ) <TAB><TAB><TAB>  if m is not None : <TAB><TAB><TAB><TAB>  first . text = self . markdown . htmlStash . store ( <TAB><TAB><TAB><TAB><TAB>  get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB><TAB><TAB><TAB>  ) + m . group ( "" line "" ) <TAB><TAB><TAB><TAB>  found = True <TAB>  return found ","if first . tag == ""p"" and first . text is not None :",if first.text:,False,24.4329675545306,93.33958175696547
1477,"def _check_mswin_locale ( locale ) : <TAB>  msloc = None <TAB>  try : <TAB><TAB>  msloc = _LOCALE_NAMES [ locale [ : 5 ] ] [ : 2 ] <TAB><TAB>  locale = locale [ : 5 ] <TAB>  except KeyError : <TAB><TAB>  try : <TAB><TAB><TAB>  msloc = _LOCALE_NAMES [ locale [ : 2 ] ] [ : 2 ] <TAB><TAB><TAB>  locale = locale [ : 2 ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  # US English is the outlier, all other English locales want <TAB><TAB><TAB>  # real English: <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return ( "" en_GB "" , "" 1252 "" ) <TAB><TAB><TAB>  return ( None , None ) <TAB>  return ( locale , msloc ) ","if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :",if locale == 'en_GB':,False,57.86922112729116,89.49778029663031
1478,"def setLabel ( self , s , protect = False ) : <TAB>  """"""Set the label of the minibuffer."""""" <TAB>  c , k , w = self . c , self , self . w <TAB>  if w : <TAB><TAB>  # Support for the curses gui. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . app . gui . set_minibuffer_label ( c , s ) <TAB><TAB>  w . setAllText ( s ) <TAB><TAB>  n = len ( s ) <TAB><TAB>  w . setSelectionRange ( n , n , insert = n ) <TAB><TAB>  if protect : <TAB><TAB><TAB>  k . mb_prefix = s ","if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :",if c:,False,56.30812882134653,89.9651459374248
1479,"def getProc ( su , innerTarget ) : <TAB>  if len ( su ) == 1 :<TAB># have a one element wedge <TAB><TAB>  proc = ( "" first "" , "" last "" ) <TAB>  else : <TAB><TAB>  if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) : <TAB><TAB><TAB>  proc = ( "" first "" , "" last "" )<TAB># same element can be first and last <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  proc = ( "" first "" , ) <TAB><TAB>  elif su . isLast ( innerTarget ) : <TAB><TAB><TAB>  proc = ( "" last "" , ) <TAB><TAB>  else : <TAB><TAB><TAB>  proc = ( ) <TAB>  return proc ",elif su . isFirst ( innerTarget ) :,if su.isFirst(innerTarget):,False,51.8068474607457,93.90337579736179
1480,"def await_test_end ( self ) : <TAB>  iterations = 0 <TAB>  while True : <TAB><TAB>  if iterations > 100 : <TAB><TAB><TAB>  self . log . debug ( "" Await: iteration limit reached "" ) <TAB><TAB><TAB>  return <TAB><TAB>  status = self . master . get_status ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  iterations + = 1 <TAB><TAB>  time . sleep ( 1.0 ) ","if status . get ( ""status"" ) == ""ENDED"" :",if status == Status.OK:,False,33.93540782732616,90.60103682277663
1481,"def _handle_autocomplete_request_for_text ( text ) : <TAB>  if not hasattr ( text , "" autocompleter "" ) : <TAB><TAB>  if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  text . autocompleter = Completer ( text ) <TAB><TAB><TAB>  elif isinstance ( text , ShellText ) : <TAB><TAB><TAB><TAB>  text . autocompleter = ShellCompleter ( text ) <TAB><TAB><TAB>  text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB><TAB>  else : <TAB><TAB><TAB>  return <TAB>  text . autocompleter . handle_autocomplete_request ( ) ","if isinstance ( text , CodeViewText ) :","if isinstance(text, CodeViewText):",False,50.53756890065117,100.00000000000004
1482,"def validate_party_details ( self ) : <TAB>  if self . party : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB><TAB>  if self . party_account and self . party_type in ( "" Customer "" , "" Supplier "" ) : <TAB><TAB><TAB>  self . validate_account_type ( <TAB><TAB><TAB><TAB>  self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB><TAB><TAB>  ) ","if not frappe . db . exists ( self . party_type , self . party ) :","if self.party_type not in (""User"", ""User""):",False,46.39403389503951,92.3329817389954
1483,"def format ( self , formatstr ) : <TAB>  pieces = [ ] <TAB>  for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB><TAB>  elif piece : <TAB><TAB><TAB>  pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB>  return "" "" . join ( pieces ) ",if i % 2 :,"if hasattr(self, piece):",False,45.92285700255364,94.10492214153918
1484,"def _convert_java_pattern_to_python ( pattern ) : <TAB>  """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB>  s = list ( pattern ) <TAB>  i = 0 <TAB>  while i < len ( s ) - 1 : <TAB><TAB>  c = s [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s [ i ] = "" \\ "" <TAB><TAB>  elif c == "" \\ "" and s [ i + 1 ] == "" $ "" : <TAB><TAB><TAB>  s [ i ] = "" "" <TAB><TAB><TAB>  i + = 1 <TAB><TAB>  i + = 1 <TAB>  return pattern [ : 0 ] . join ( s ) ","if c == ""$"" and s [ i + 1 ] in ""0123456789"" :","if c == ""'"":",False,37.55257381734944,93.3223513257897
1485,"def download ( self , url , filename , * * kwargs ) : <TAB>  try : <TAB><TAB>  r = self . get ( url , timeout = 10 , stream = True , * * kwargs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  with open ( filename , "" wb "" ) as f : <TAB><TAB><TAB>  for chunk in r . iter_content ( chunk_size = 1024 ) : <TAB><TAB><TAB><TAB>  if chunk : <TAB><TAB><TAB><TAB><TAB>  f . write ( chunk ) <TAB><TAB>  helpers . chmod_as_parent ( filename ) <TAB>  except Exception as e : <TAB><TAB>  sickrage . app . log . debug ( <TAB><TAB><TAB>  "" Failed to download file from  {}  - ERROR:  {} "" . format ( url , e ) <TAB><TAB>  ) <TAB><TAB>  if os . path . exists ( filename ) : <TAB><TAB><TAB>  os . remove ( filename ) <TAB><TAB>  return False <TAB>  return True ",if r . status_code >= 400 :,if r.status_code != 200:,False,53.408490444117575,98.41327988269505
1486,"def run ( self , paths = [ ] ) : <TAB>  items = [ ] <TAB>  for item in SideBarSelection ( paths ) . getSelectedFilesWithExtension ( "" js "" ) : <TAB><TAB>  items . append ( <TAB><TAB><TAB>  ' <script type= "" text/javascript ""  src= "" ' <TAB><TAB><TAB>  + item . pathAbsoluteFromProjectEncoded ( ) <TAB><TAB><TAB>  + ' "" ></script> ' <TAB><TAB>  ) <TAB>  if len ( items ) > 0 : <TAB><TAB>  sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sublime . status_message ( "" Items copied "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  sublime . status_message ( "" Item copied "" ) ",if len ( items ) > 1 :,if len(items) == 0:,False,50.872288795739266,97.7839997677923
1487,"def work ( self ) : <TAB>  while True : <TAB><TAB>  timeout = self . timeout <TAB><TAB>  if idle . is_set ( ) : <TAB><TAB><TAB>  timeout = self . idle_timeout <TAB><TAB>  log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB><TAB>  fetch . wait ( timeout ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( "" Stop fetch worker "" ) <TAB><TAB><TAB>  break <TAB><TAB>  self . fetch ( ) ",if shutting_down . is_set ( ) :,if timeout == 0:,False,22.113254264279337,92.64971932126507
1488,"def check_apns_certificate ( ss ) : <TAB>  mode = "" start "" <TAB>  for s in ss . split ( "" \n "" ) : <TAB><TAB>  if mode == "" start "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  mode = "" key "" <TAB><TAB>  elif mode == "" key "" : <TAB><TAB><TAB>  if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB>  mode = "" end "" <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB><TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB>  "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB>  ) <TAB>  if mode != "" end "" : <TAB><TAB>  raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s :",if s.startswith('RSA-Type'):,False,41.85755472695865,92.63598302155094
1489,"def compare_lists ( self , l1 , l2 , key ) : <TAB>  l2_lookup = { o . get ( key ) : o for o in l2 } <TAB>  for obj1 in l1 : <TAB><TAB>  obj2 = l2_lookup . get ( obj1 . get ( key ) ) <TAB><TAB>  for k in obj1 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( obj1 . get ( k ) , obj2 . get ( k ) ) ","if k not in ""id"" and obj1 . get ( k ) :",if k not in l2_lookup:,False,52.848600401482756,90.88461855036866
1490,"def before_get_object ( self , view_kwargs ) : <TAB>  if view_kwargs . get ( "" id "" ) is not None : <TAB><TAB>  try : <TAB><TAB><TAB>  user_favourite_event = find_user_favourite_event_by_id ( <TAB><TAB><TAB><TAB>  event_id = view_kwargs [ "" id "" ] <TAB><TAB><TAB>  ) <TAB><TAB>  except NoResultFound : <TAB><TAB><TAB>  raise ObjectNotFound ( <TAB><TAB><TAB><TAB>  { "" source "" : "" /data/relationships/event "" } , "" Object: not found "" <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  view_kwargs [ "" id "" ] = user_favourite_event . id <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  view_kwargs [ "" id "" ] = None ",if user_favourite_event is not None :,if user_favourite_event:,False,48.21198403923434,98.20771908466585
1491,"def close ( self ) : <TAB>  super ( ) . close ( ) <TAB>  if not sys . is_finalizing ( ) : <TAB><TAB>  for sig in list ( self . _signal_handlers ) : <TAB><TAB><TAB>  self . remove_signal_handler ( sig ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  f "" Closing the loop  { self !r} "" <TAB><TAB><TAB><TAB>  f "" on interpreter shutdown  "" <TAB><TAB><TAB><TAB>  f "" stage, skipping signal handlers removal "" , <TAB><TAB><TAB><TAB>  ResourceWarning , <TAB><TAB><TAB><TAB>  source = self , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . _signal_handlers . clear ( ) ",if self . _signal_handlers :,if self != self:,False,46.74343456292037,97.03669291639385
1492,"def install_script ( self , script , install_options = None ) : <TAB>  try : <TAB><TAB>  fname = utils . do_script ( <TAB><TAB><TAB>  script , <TAB><TAB><TAB>  python_exe = osp . join ( self . target , "" python.exe "" ) , <TAB><TAB><TAB>  architecture = self . architecture , <TAB><TAB><TAB>  verbose = self . verbose , <TAB><TAB><TAB>  install_options = install_options , <TAB><TAB>  ) <TAB>  except RuntimeError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Failed! "" ) <TAB><TAB><TAB>  raise ",if not self . verbose :,if self.verbose:,False,45.54011961957332,98.53053008329684
1493,"def GetRouterForUser ( self , username ) : <TAB>  """"""Returns a router corresponding to a given username."""""" <TAB>  for index , router in enumerate ( self . routers ) : <TAB><TAB>  router_id = str ( index ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logging . debug ( <TAB><TAB><TAB><TAB>  "" Matched router  %s  to user  %s "" , router . __class__ . __name__ , username <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return router <TAB>  logging . debug ( <TAB><TAB>  "" No router ACL rule match for user  %s . Using default  "" "" router  %s "" , <TAB><TAB>  username , <TAB><TAB>  self . default_router . __class__ . __name__ , <TAB>  ) <TAB>  return self . default_router ","if self . auth_manager . CheckPermissions ( username , router_id ) :",if router_id == username:,False,33.135268454166,93.85103845044901
1494,"def charset ( self ) : <TAB>  """"""The charset from the content type."""""" <TAB>  header = self . environ . get ( "" CONTENT_TYPE "" ) <TAB>  if header : <TAB><TAB>  ct , options = parse_options_header ( header ) <TAB><TAB>  charset = options . get ( "" charset "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if is_known_charset ( charset ) : <TAB><TAB><TAB><TAB>  return charset <TAB><TAB><TAB>  return self . unknown_charset ( charset ) <TAB>  return self . default_charset ",if charset :,if charset:,False,55.22787983652025,100.00000000000004
1495,def isFinished ( self ) : <TAB>  # returns true if episode timesteps has reached episode length and resets the task <TAB>  if self . count > self . epiLen : <TAB><TAB>  self . res ( ) <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  if self . count == 1 : <TAB><TAB><TAB>  self . pertGlasPos ( 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . env . reset ( ) <TAB><TAB><TAB>  self . pertGlasPos ( 1 ) <TAB><TAB>  self . count + = 1 <TAB><TAB>  return False ,if self . count == self . epiLen / 2 + 1 :,if self.count == 0:,False,38.793761875869585,94.5595489850582
1496,"def mtimes_of_files ( dirnames : List [ str ] , suffix : str ) - > Iterator [ float ] : <TAB>  for dirname in dirnames : <TAB><TAB>  for root , dirs , files in os . walk ( dirname ) : <TAB><TAB><TAB>  for sfile in files : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB><TAB>  yield path . getmtime ( path . join ( root , sfile ) ) <TAB><TAB><TAB><TAB><TAB>  except OSError : <TAB><TAB><TAB><TAB><TAB><TAB>  pass ",if sfile . endswith ( suffix ) :,if suffix == sfile:,False,49.40943467280904,95.908325857548
1497,"def get_all_hashes ( self ) : <TAB>  event_hashes = [ ] <TAB>  sample_hashes = [ ] <TAB>  for a in self . event . attributes : <TAB><TAB>  h = None <TAB><TAB>  if a . type in ( "" md5 "" , "" sha1 "" , "" sha256 "" ) : <TAB><TAB><TAB>  h = a . value <TAB><TAB><TAB>  event_hashes . append ( h ) <TAB><TAB>  elif a . type in ( "" filename|md5 "" , "" filename|sha1 "" , "" filename|sha256 "" ) : <TAB><TAB><TAB>  h = a . value . split ( "" | "" ) [ 1 ] <TAB><TAB><TAB>  event_hashes . append ( h ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  h = a . value . split ( "" | "" ) [ 1 ] <TAB><TAB><TAB>  sample_hashes . append ( h ) <TAB>  return event_hashes , sample_hashes ","elif a . type == ""malware-sample"" :","if a.type in (""filename|md5"", ""sha1"", ""sha256",False,28.428921975236847,93.02869843345059
1498,"def _validate ( self , event ) : <TAB>  if self . type is None : <TAB><TAB>  return <TAB>  new = self . value <TAB>  if not isinstance ( new , self . type ) and new is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . value = event . old <TAB><TAB>  types = repr ( self . type ) if isinstance ( self . type , tuple ) else self . type . __name__ <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" LiteralInput expected  %s  type but value  %s "" <TAB><TAB><TAB>  "" is of type  %s . "" % ( types , new , type ( new ) . __name__ ) <TAB><TAB>  ) ",if event :,if event.old is not None:,False,56.25202235011748,96.47112295555014
1499,"def update_dict ( a , b ) : <TAB>  for key , value in b . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if key not in a : <TAB><TAB><TAB>  a [ key ] = value <TAB><TAB>  elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB><TAB><TAB>  update_dict ( a [ key ] , value ) <TAB><TAB>  elif isinstance ( a [ key ] , list ) : <TAB><TAB><TAB>  a [ key ] . append ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  a [ key ] = [ a [ key ] , value ] ",if value is None :,if key in a:,False,50.11120635477104,97.48696792430982
1500,"def on_pre_save ( self , view ) : <TAB>  extOrClause = "" | "" . join ( s . get ( "" format_on_save_extensions "" ) ) <TAB>  extRegex = "" \\ .( "" + extOrClause + "" )$ "" <TAB>  if s . get ( "" format_on_save "" ) and re . search ( extRegex , view . file_name ( ) ) : <TAB><TAB>  # only auto-format on save if there are no ""lint errors"" <TAB><TAB>  # here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3 <TAB><TAB>  lints_regions = [ "" lint-keyword-underline "" , "" lint-keyword-outline "" ] <TAB><TAB>  for linter in lints_regions : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB>  view . run_command ( "" js_format "" ) ",if len ( view . get_regions ( linter ) ) :,"if not re.search(extRegex, view.file_name()):",False,64.47087864050201,94.19249198277663
1501,"def readMemory ( self , va , size ) : <TAB>  for mva , mmaxva , mmap , mbytes in self . _map_defs : <TAB><TAB>  if mva < = va < mmaxva : <TAB><TAB><TAB>  mva , msize , mperms , mfname = mmap <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise envi . SegmentationViolation ( va ) <TAB><TAB><TAB>  offset = va - mva <TAB><TAB><TAB>  return mbytes [ offset : offset + size ] <TAB>  raise envi . SegmentationViolation ( va ) ",if not mperms & MM_READ :,if msize == mmaxva:,False,28.936701953040718,94.53976445855642
1502,"def assertFilepathsEqual ( self , p1 , p2 ) : <TAB>  if sys . platform == "" win32 "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p1 = [ normcase ( normpath ( x ) ) for x in p1 ] <TAB><TAB><TAB>  p2 = [ normcase ( normpath ( x ) ) for x in p2 ] <TAB><TAB>  else : <TAB><TAB><TAB>  assert isinstance ( p1 , ( str , unicode ) ) <TAB><TAB><TAB>  p1 = normcase ( normpath ( p1 ) ) <TAB><TAB><TAB>  p2 = normcase ( normpath ( p2 ) ) <TAB>  self . assertEqual ( p1 , p2 ) ","if isinstance ( p1 , ( list , tuple ) ) :",if sys.platform == 'win32':,False,49.7481786123179,92.90808255784917
1503,"def add_directory_csv_files ( dir_path , paths = None ) : <TAB>  if not paths : <TAB><TAB>  paths = [ ] <TAB>  for p in listdir ( dir_path ) : <TAB><TAB>  path = join ( dir_path , p ) <TAB><TAB>  if isdir ( path ) : <TAB><TAB><TAB>  # call recursively for each dir <TAB><TAB><TAB>  paths = add_directory_csv_files ( path , paths ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # add every file to the list <TAB><TAB><TAB>  paths . append ( path ) <TAB>  return paths ","elif isfile ( path ) and path . endswith ( "".csv"" ) :",if os.path.isdir(path):,False,57.85026364822245,92.16939602536796
1504,"def _verifySubs ( self ) : <TAB>  for inst in self . subs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB><TAB>  if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB><TAB><TAB>  if not inst . modctxt : <TAB><TAB><TAB><TAB>  raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) ) ","if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :","if not isinstance(inst, _ArgType):",False,21.32382428084875,92.05277922706752
1505,"def __annotations_bytes ( self ) : <TAB>  if self . annotations : <TAB><TAB>  a = [ ] <TAB><TAB>  for k , v in self . annotations . items ( ) : <TAB><TAB><TAB>  if len ( k ) != 4 : <TAB><TAB><TAB><TAB>  raise errors . ProtocolError ( "" annotation key must be of length 4 "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  k = k . encode ( "" ASCII "" ) <TAB><TAB><TAB>  a . append ( struct . pack ( "" !4sH "" , k , len ( v ) ) ) <TAB><TAB><TAB>  a . append ( v ) <TAB><TAB>  return b "" "" . join ( a ) <TAB>  return b "" "" ","if sys . version_info >= ( 3 , 0 ) :","if isinstance(k, unicode):",False,40.09443295540952,94.04308854414955
1506,"def session ( self , profile : str = "" default "" , region : str = None ) - > boto3 . Session : <TAB>  region = self . _get_region ( region , profile ) <TAB>  try : <TAB><TAB>  session = self . _cache_lookup ( <TAB><TAB><TAB>  self . _session_cache , <TAB><TAB><TAB>  [ profile , region ] , <TAB><TAB><TAB>  self . _boto3 . Session , <TAB><TAB><TAB>  [ ] , <TAB><TAB><TAB>  { "" region_name "" : region , "" profile_name "" : profile } , <TAB><TAB>  ) <TAB>  except ProfileNotFound : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB><TAB>  session = self . _boto3 . Session ( region_name = region ) <TAB><TAB>  self . _cache_set ( self . _session_cache , [ profile , region ] , session ) <TAB>  return session ","if profile != ""default"" :",if region is None:,False,47.88724581040226,96.82526304106426
1507,"def spans_score ( gold_spans , system_spans ) : <TAB>  correct , gi , si = 0 , 0 , 0 <TAB>  while gi < len ( gold_spans ) and si < len ( system_spans ) : <TAB><TAB>  if system_spans [ si ] . start < gold_spans [ gi ] . start : <TAB><TAB><TAB>  si + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gi + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  correct + = gold_spans [ gi ] . end == system_spans [ si ] . end <TAB><TAB><TAB>  si + = 1 <TAB><TAB><TAB>  gi + = 1 <TAB>  return Score ( len ( gold_spans ) , len ( system_spans ) , correct ) ",elif gold_spans [ gi ] . start < system_spans [ si ] . start :,if sys.platform == 'win32':,False,47.19077724252701,90.75245514494918
1508,"def to_api ( tag , raw_value ) : <TAB>  try : <TAB><TAB>  api_tag , converter = _QL_TO_SC [ tag ] if tag else ( "" q "" , None ) <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise self . error ( <TAB><TAB><TAB><TAB>  "" Unsupported  ' %s '  tag. Try:  %s "" % ( tag , "" ,  "" . join ( SUPPORTED ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  return None , None <TAB>  else : <TAB><TAB>  value = str ( converter ( raw_value ) if converter else raw_value ) <TAB><TAB>  return api_tag , value ",if tag not in SUPPORTED :,"if not isinstance(raw_value, tuple):",False,31.612675995461416,92.40356684447895
1509,"def unpack ( self , buf ) : <TAB>  dpkt . Packet . unpack ( self , buf ) <TAB>  buf = buf [ self . __hdr_len__ : ] <TAB>  # single-byte IE <TAB>  if self . type & 0x80 : <TAB><TAB>  self . len = 0 <TAB><TAB>  self . data = b "" "" <TAB>  # multi-byte IE <TAB>  else : <TAB><TAB>  # special PER-encoded UUIE <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . len = struct . unpack ( "" >H "" , buf [ : 2 ] ) [ 0 ] <TAB><TAB><TAB>  buf = buf [ 2 : ] <TAB><TAB>  # normal TLV-like IE <TAB><TAB>  else : <TAB><TAB><TAB>  self . len = struct . unpack ( "" B "" , buf [ : 1 ] ) [ 0 ] <TAB><TAB><TAB>  buf = buf [ 1 : ] <TAB><TAB>  self . data = buf [ : self . len ] ",if self . type == USER_TO_USER :,if self.type & 0x80:,False,50.70551237839979,96.51203278137451
1510,"def on_bt_search_clicked ( self , widget ) : <TAB>  if self . current_provider is None : <TAB><TAB>  return <TAB>  query = self . en_query . get_text ( ) <TAB>  @self . obtain_podcasts_with <TAB>  def load_data ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . current_provider . on_search ( query ) <TAB><TAB>  elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB><TAB><TAB>  return self . current_provider . on_url ( query ) <TAB><TAB>  elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB><TAB><TAB>  return self . current_provider . on_file ( query ) ",if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH:,False,50.86647023711925,100.00000000000004
1511,"def _text ( bitlist ) : <TAB>  out = "" "" <TAB>  for typ , text in bitlist : <TAB><TAB>  if not typ : <TAB><TAB><TAB>  out + = text <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out + = "" \\ fI %s \\ fR "" % text <TAB><TAB>  elif typ in [ "" strong "" , "" code "" ] : <TAB><TAB><TAB>  out + = "" \\ fB %s \\ fR "" % text <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB>  out = out . strip ( ) <TAB>  out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB>  return out ","elif typ == ""em"" :","if typ in ['text', 'code']:",False,20.117601129304667,95.5354435149338
1512,"def process ( self , buckets ) : <TAB>  with self . executor_factory ( max_workers = 3 ) as w : <TAB><TAB>  futures = { } <TAB><TAB>  results = [ ] <TAB><TAB>  for b in buckets : <TAB><TAB><TAB>  futures [ w . submit ( self . process_bucket , b ) ] = b <TAB><TAB>  for f in as_completed ( futures ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  b = futures [ f ] <TAB><TAB><TAB><TAB>  self . log . error ( <TAB><TAB><TAB><TAB><TAB>  "" error modifying bucket: %s \n %s "" , b [ "" Name "" ] , f . exception ( ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  results + = filter ( None , [ f . result ( ) ] ) <TAB><TAB>  return results ",if f . exception ( ) :,if f.success() and futures[f] is not None:,False,35.0165897073656,95.16741309445808
1513,"def check_settings ( self ) : <TAB>  if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB>  "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB><TAB><TAB><TAB>  "" False. "" % self . alias <TAB><TAB><TAB>  ) <TAB><TAB>  elif self . features . supports_timezones : <TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB>  "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB><TAB><TAB><TAB>  "" handles time zones conversions natively. "" % self . alias <TAB><TAB><TAB>  ) ",if not settings . USE_TZ :,if self.features.supports_use_tz:,False,57.88258269814761,91.57087224432638
1514,"def process_webhook_prop ( namespace ) : <TAB>  if not isinstance ( namespace . webhook_properties , list ) : <TAB><TAB>  return <TAB>  result = { } <TAB>  for each in namespace . webhook_properties : <TAB><TAB>  if each : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  key , value = each . split ( "" = "" , 1 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  key , value = each , "" "" <TAB><TAB><TAB>  result [ key ] = value <TAB>  namespace . webhook_properties = result ","if ""="" in each :",if each.startswith('='):,False,27.789005146954892,94.3769180016919
1515,"def _expand_query_values ( original_query_list ) : <TAB>  query_list = [ ] <TAB>  for key , value in original_query_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  query_list . append ( ( key , value ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  key_fmt = key + "" [ %s ] "" <TAB><TAB><TAB>  value_list = _to_kv_list ( value ) <TAB><TAB><TAB>  query_list . extend ( ( key_fmt % k , v ) for k , v in value_list ) <TAB>  return query_list ","if isinstance ( value , basestring ) :","if isinstance(value, (int, float)):",False,49.517233685537825,96.08887705265735
1516,"def tags ( ) : <TAB>  """"""Return a dictionary of all tags in the form {hash: [tag_names, ...]}."""""" <TAB>  tags = { } <TAB>  for ( n , c ) in list_refs ( ) : <TAB><TAB>  if n . startswith ( "" refs/tags/ "" ) : <TAB><TAB><TAB>  name = n [ 10 : ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tags [ c ] = [ ] <TAB><TAB><TAB>  tags [ c ] . append ( name )<TAB># more than one tag can point at 'c' <TAB>  return tags ",if not c in tags :,if c not in tags:,False,47.81767152348133,95.35428309046218
1517,"def test_colorspiral ( self ) : <TAB>  """"""Set of 625 colours, with jitter, using get_colors()."""""" <TAB>  boxedge = 20 <TAB>  boxes_per_row = 25 <TAB>  rows = 0 <TAB>  for i , c in enumerate ( get_colors ( 625 ) ) : <TAB><TAB>  self . c . setFillColor ( c ) <TAB><TAB>  x1 = boxedge * ( i % boxes_per_row ) <TAB><TAB>  y1 = rows * boxedge <TAB><TAB>  self . c . rect ( x1 , y1 , boxedge , boxedge , fill = 1 , stroke = 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rows + = 1 <TAB>  self . finish ( ) ",if not ( i + 1 ) % boxes_per_row :,if x1 != 0 and y1 != 0:,False,27.005458610913134,92.63684857944496
1518,"def oldest_pending_update_in_days ( ) : <TAB>  """"""Return the datestamp of the oldest pending update"""""" <TAB>  pendingupdatespath = os . path . join ( <TAB><TAB>  prefs . pref ( "" ManagedInstallDir "" ) , "" UpdateNotificationTracking.plist "" <TAB>  ) <TAB>  try : <TAB><TAB>  pending_updates = FoundationPlist . readPlist ( pendingupdatespath ) <TAB>  except FoundationPlist . NSPropertyListSerializationException : <TAB><TAB>  return 0 <TAB>  oldest_date = now = NSDate . date ( ) <TAB>  for category in pending_updates : <TAB><TAB>  for name in pending_updates [ category ] : <TAB><TAB><TAB>  this_date = pending_updates [ category ] [ name ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  oldest_date = this_date <TAB>  return now . timeIntervalSinceDate_ ( oldest_date ) / ( 24 * 60 * 60 ) ",if this_date < oldest_date :,if this_date > oldest_date:,False,57.298770489250074,98.86228284909593
1519,"def _try_read_gpg ( path ) : <TAB>  path = os . path . expanduser ( path ) <TAB>  cmd = _gpg_cmd ( ) + [ path ] <TAB>  log . debug ( "" gpg cmd:  %s "" , cmd ) <TAB>  try : <TAB><TAB>  p = subprocess . Popen ( <TAB><TAB><TAB>  cmd , env = os . environ , stdout = subprocess . PIPE , stderr = subprocess . PIPE <TAB><TAB>  ) <TAB>  except OSError as e : <TAB><TAB>  log . error ( "" cannot decode  %s  with command  ' %s '  ( %s ) "" , path , "" "" . join ( cmd ) , e ) <TAB>  else : <TAB><TAB>  out , err = p . communicate ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . error ( err . decode ( errors = "" replace "" ) . strip ( ) ) <TAB><TAB><TAB>  return None <TAB><TAB>  return out . decode ( errors = "" replace "" ) ",if p . returncode != 0 :,if err:,False,24.606136363281195,95.86407912746755
1520,"def sort_nested_dictionary_lists ( d ) : <TAB>  for k , v in d . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for i in range ( 0 , len ( v ) ) : <TAB><TAB><TAB><TAB>  if isinstance ( v [ i ] , dict ) : <TAB><TAB><TAB><TAB><TAB>  v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB><TAB><TAB><TAB>  d [ k ] = sorted ( v ) <TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB>  d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB>  return d ","if isinstance ( v , list ) :",if k == 'sort':,False,49.95120020369526,95.88733529272753
1521,"def _the_callback ( widget , event_id ) : <TAB>  point = widget . GetCenter ( ) <TAB>  index = widget . WIDGET_INDEX <TAB>  if hasattr ( callback , "" __call__ "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args = [ point , index ] <TAB><TAB>  else : <TAB><TAB><TAB>  args = [ point ] <TAB><TAB>  if pass_widget : <TAB><TAB><TAB>  args . append ( widget ) <TAB><TAB>  try_callback ( callback , * args ) <TAB>  return ",if num > 1 :,if index is not None:,False,46.53615102276972,96.15753974716091
1522,"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB>  new_parameters = [ ] <TAB>  for hp in sub_cs . get_hyperparameters ( ) : <TAB><TAB>  new_parameter = copy . deepcopy ( hp ) <TAB><TAB>  # Allow for an empty top-level parameter <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_parameter . name = prefix <TAB><TAB>  elif not prefix == "" "" : <TAB><TAB><TAB>  new_parameter . name = "" {} {} {} "" . format ( prefix , SPLITTER , new_parameter . name ) <TAB><TAB>  new_parameters . append ( new_parameter ) <TAB>  for hp in new_parameters : <TAB><TAB>  _add_hp ( master_cs , hp ) ","if new_parameter . name == """" :",if prefix == '':,False,55.87713499477731,95.28020461762057
1523,"def tearDown ( self ) : <TAB>  """"""Shutdown the server."""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . server . stop ( ) <TAB><TAB>  if self . sl_hdlr : <TAB><TAB><TAB>  self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB>  self . sl_hdlr . close ( ) <TAB>  finally : <TAB><TAB>  BaseTest . tearDown ( self ) ",if self . server :,if self.server:,False,26.497816028235594,100.00000000000004
1524,"def app_uninstall_all ( self , excludes = [ ] , verbose = False ) : <TAB>  """"""Uninstall all apps"""""" <TAB>  our_apps = [ "" com.github.uiautomator "" , "" com.github.uiautomator.test "" ] <TAB>  output , _ = self . shell ( [ "" pm "" , "" list "" , "" packages "" , "" -3 "" ] ) <TAB>  pkgs = re . findall ( r "" package:([^ \ s]+) "" , output ) <TAB>  pkgs = set ( pkgs ) . difference ( our_apps + excludes ) <TAB>  pkgs = list ( pkgs ) <TAB>  for pkg_name in pkgs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" uninstalling "" , pkg_name , "" "" , end = "" "" , flush = True ) <TAB><TAB>  ok = self . app_uninstall ( pkg_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" OK "" if ok else "" FAIL "" ) <TAB>  return pkgs ",if verbose :,if verbose:,False,21.449355656141876,98.12555355897456
1525,"def httpapi ( self , arg , opts ) : <TAB>  sc = HttpAPIStatsCollector ( ) <TAB>  headers = [ "" #Item "" , "" Value "" ] <TAB>  table = [ ] <TAB>  for k , v in sc . get ( ) . getStats ( ) . items ( ) : <TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB>  v = json . dumps ( v ) <TAB><TAB>  row = [ ] <TAB><TAB>  row . append ( "" # %s "" % k ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  row . append ( formatDateTime ( v ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  row . append ( v ) <TAB><TAB>  table . append ( row ) <TAB>  self . protocol . sendData ( <TAB><TAB>  tabulate ( table , headers , tablefmt = "" plain "" , numalign = "" left "" ) . encode ( "" ascii "" ) <TAB>  ) ","if k [ - 3 : ] == ""_at"" :","if isinstance(v, datetime):",False,47.240272710378505,94.67981758741391
1526,"def Get_Gene ( self , id ) : <TAB>  """"""Retreive the gene name (GN)."""""" <TAB>  entry = self . Get ( id ) <TAB>  if not entry : <TAB><TAB>  return None <TAB>  GN = "" "" <TAB>  for line in string . split ( entry , "" \n "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  GN = string . strip ( line [ 5 : ] ) <TAB><TAB><TAB>  if GN [ - 1 ] == "" . "" : <TAB><TAB><TAB><TAB>  GN = GN [ 0 : - 1 ] <TAB><TAB><TAB>  return GN <TAB><TAB>  if line [ 0 : 2 ] == "" // "" : <TAB><TAB><TAB>  break <TAB>  return GN ","if line [ 0 : 5 ] == ""GN   "" :",if len(line) > 5:,False,49.147612527347995,91.57093991025435
1527,"def replace_dir_vars ( path , d ) : <TAB>  """"""Replace common directory paths with appropriate variable references (e.g. /etc becomes ${sysconfdir})"""""" <TAB>  dirvars = { } <TAB>  # Sort by length so we get the variables we're interested in first <TAB>  for var in sorted ( list ( d . keys ( ) ) , key = len ) : <TAB><TAB>  if var . endswith ( "" dir "" ) and var . lower ( ) == var : <TAB><TAB><TAB>  value = d . getVar ( var ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  dirvars [ value ] = var <TAB>  for dirpath in sorted ( list ( dirvars . keys ( ) ) , reverse = True ) : <TAB><TAB>  path = path . replace ( dirpath , "" $ { %s } "" % dirvars [ dirpath ] ) <TAB>  return path ","if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :",if value not in dirvars:,False,63.03499130394715,92.10571669885029
1528,"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB>  """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB>  for root , _ , filenames in safe_walk ( target_workdir ) : <TAB><TAB>  for filename in filenames : <TAB><TAB><TAB>  source = os . path . join ( root , filename ) <TAB><TAB><TAB>  with open ( source , "" r "" ) as f : <TAB><TAB><TAB><TAB>  lines = f . readlines ( ) <TAB><TAB><TAB>  if len ( lines ) < 1 : <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  with open ( source , "" w "" ) as f : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  f . write ( lines [ 0 ] ) <TAB><TAB><TAB><TAB>  for line in lines [ 1 : ] : <TAB><TAB><TAB><TAB><TAB>  f . write ( line ) ",if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,if lines[0] == 'timestamp':,False,32.898333697600606,93.46140610456439
1529,"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB>  """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB>  all_plugins = [ ] <TAB>  for name in self . plugins_callback_order : <TAB><TAB>  # None is a placeholder for any plugin not having a defined order <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  all_plugins + = [ <TAB><TAB><TAB><TAB>  plugin <TAB><TAB><TAB><TAB>  for name , plugin in self . plugins . items ( ) <TAB><TAB><TAB><TAB>  if name not in self . plugins_callback_order and plugin . is_activated <TAB><TAB><TAB>  ] <TAB><TAB>  else : <TAB><TAB><TAB>  plugin = self . plugins [ name ] <TAB><TAB><TAB>  if plugin . is_activated : <TAB><TAB><TAB><TAB>  all_plugins . append ( plugin ) <TAB>  return all_plugins ",if name is None :,if name not in self.plugins:,False,58.96413263429686,97.45297193063888
1530,"def test_query_level ( self ) : <TAB>  "" Tests querying at a level other than max "" <TAB>  # level 2 <TAB>  l2 = set ( ) <TAB>  for p in self . tile_paths : <TAB><TAB>  l2 . add ( p [ 0 : 2 ] ) <TAB>  for path in iterate_base4 ( 2 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertTrue ( self . tree . query_path ( path ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertFalse ( self . tree . query_path ( path ) ) <TAB>  # level 1: <TAB>  self . assertTrue ( self . tree . query_path ( ( 0 , ) ) ) <TAB>  self . assertTrue ( self . tree . query_path ( ( 1 , ) ) ) <TAB>  self . assertTrue ( self . tree . query_path ( ( 2 , ) ) ) <TAB>  self . assertFalse ( self . tree . query_path ( ( 3 , ) ) ) ",if path in l2 :,if path == 'max':,False,57.6734555915567,98.09379109130822
1531,"def program_exists ( name ) : <TAB>  paths = ( os . getenv ( "" PATH "" ) or os . defpath ) . split ( os . pathsep ) <TAB>  for p in paths : <TAB><TAB>  fn = "" %s / %s "" % ( p , name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return not os . path . isdir ( fn ) and os . access ( fn , os . X_OK ) ",if os . path . exists ( fn ) :,if os.path.exists(fn):,False,51.02174345162751,100.00000000000004
1532,"def decoration_helper ( self , patched , args , keywargs ) : <TAB>  extra_args = [ ] <TAB>  with contextlib . ExitStack ( ) as exit_stack : <TAB><TAB>  for patching in patched . patchings : <TAB><TAB><TAB>  arg = exit_stack . enter_context ( patching ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  keywargs . update ( arg ) <TAB><TAB><TAB>  elif patching . new is DEFAULT : <TAB><TAB><TAB><TAB>  extra_args . append ( arg ) <TAB><TAB>  args + = tuple ( extra_args ) <TAB><TAB>  yield ( args , keywargs ) ",if patching . attribute_name is not None :,if patching.old is DEFAULT:,False,46.3765774993297,95.71278831179274
1533,"def update_neighbor ( neigh_ip_address , changes ) : <TAB>  rets = [ ] <TAB>  for k , v in changes . items ( ) : <TAB><TAB>  if k == neighbors . MULTI_EXIT_DISC : <TAB><TAB><TAB>  rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB><TAB>  if k == neighbors . CONNECT_MODE : <TAB><TAB><TAB>  rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB>  return all ( rets ) ",if k == neighbors . ENABLED :,if k == neighbors.CONTROL_ENABLED:,False,51.27096539468352,97.99940387680654
1534,"def calcUniqueStates ( self ) : <TAB>  # Here we show which colors can be relied on to map to an <TAB>  # internal state.  The current position will be at the first <TAB>  # character in the buffer styled that color, so this might not <TAB>  # work in all cases. <TAB>  self . uniqueStates = { } <TAB>  for k in self . holdUniqueStates . keys ( ) : <TAB><TAB>  v = self . holdUniqueStates [ k ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . uniqueStates [ k ] = v . keys ( ) [ 0 ] <TAB><TAB><TAB>  log . debug ( "" Map style [ %s ] to state [ %s ] "" , k , v . keys ( ) [ 0 ] ) <TAB><TAB>  log . debug ( "" Style [ %s ] maps to states [ %s ] "" , k , "" ,  "" . join ( v . keys ( ) ) ) <TAB>  self . holdUniqueStates = None ",if len ( v . keys ( ) ) == 1 :,if v:,False,41.75984749141994,94.56680262476215
1535,"def init_logger ( ) : <TAB>  configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB><TAB>  logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB>  ] <TAB>  used_handlers = { <TAB><TAB>  handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB>  } <TAB>  for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del log_config [ "" handlers "" ] [ handler_id ] <TAB><TAB>  elif "" filename "" in handler . keys ( ) : <TAB><TAB><TAB>  filename = handler [ "" filename "" ] <TAB><TAB><TAB>  logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB><TAB><TAB>  handler [ "" filename "" ] = str ( logfile_path ) <TAB>  logging . config . dictConfig ( log_config ) ",if handler_id not in used_handlers :,if handler_id in log_config['handlers']:,False,56.33388881072292,96.92324604034675
1536,"def _selected_machines ( self , virtual_machines ) : <TAB>  selected_machines = [ ] <TAB>  for machine in virtual_machines : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB><TAB>  if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB><TAB>  if self . locations and machine . location in self . locations : <TAB><TAB><TAB>  selected_machines . append ( machine ) <TAB>  return selected_machines ",if self . _args . host and self . _args . host == machine . name :,if machine.name == self.machine_name:,False,48.029769987835195,90.21880967063386
1537,"def init ( self ) : <TAB>  r = self . get_redis ( ) <TAB>  if r : <TAB><TAB>  key = "" pocsuite_target "" <TAB><TAB>  info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB><TAB>  logger . info ( info_msg ) <TAB><TAB>  targets = r . get ( key ) <TAB><TAB>  count = 0 <TAB><TAB>  if targets : <TAB><TAB><TAB>  for target in targets : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  count + = 1 <TAB><TAB>  info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB><TAB>  logger . info ( info_msg ) ",if self . add_target ( target ) :,if target.name == key:,False,33.34197350665707,95.57019288517353
1538,"def tearDown ( self ) : <TAB>  suffix = str ( os . getgid ( ) ) <TAB>  cli = monitoring_v3 . MetricServiceClient ( ) <TAB>  for md in cli . list_metric_descriptors ( "" projects/ {} "" . format ( PROJECT ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  cli . delete_metric_descriptor ( md . name ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  pass ","if ""OpenCensus"" in md . name and suffix in md . name :",if md.name.endswith(suffix):,False,48.231502216973034,90.8398932177917
1539,"def InitializeColours ( self ) : <TAB>  """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB>  curr = self . _colourData . GetColour ( ) <TAB>  self . _colourSelection = - 1 <TAB>  for i in range ( 16 ) : <TAB><TAB>  c = self . _colourData . GetCustomColour ( i ) <TAB><TAB>  if c . IsOk ( ) : <TAB><TAB><TAB>  self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _customColours [ i ] = wx . WHITE <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _colourSelection = i ",if c == curr :,if curr == i:,False,31.616119594627783,95.30135196897962
1540,"def __getitem__ ( self , index ) : <TAB>  if self . _check ( ) : <TAB><TAB>  if isinstance ( index , int ) : <TAB><TAB><TAB>  if index < 0 or index > = len ( self . features ) : <TAB><TAB><TAB><TAB>  raise IndexError ( index ) <TAB><TAB><TAB>  if self . features [ index ] is None : <TAB><TAB><TAB><TAB>  feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB><TAB><TAB><TAB><TAB>  self . features [ index ] = FEATURE [ feature ] <TAB><TAB><TAB>  return self . features [ index ] <TAB><TAB>  elif isinstance ( index , slice ) : <TAB><TAB><TAB>  indices = index . indices ( len ( self . features ) ) <TAB><TAB><TAB>  return [ self . __getitem__ ( i ) for i in range ( * indices ) ] ",if feature :,"if isinstance(feature, str):",False,29.76302839138492,97.49232298540703
1541,"def _get_data_from_buffer ( obj ) : <TAB>  try : <TAB><TAB>  view = memoryview ( obj ) <TAB>  except TypeError : <TAB><TAB>  # try to use legacy buffer protocol if 2.7, otherwise re-raise <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  view = memoryview ( buffer ( obj ) ) <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  "" using old buffer interface to unpack  %s ;  "" <TAB><TAB><TAB><TAB>  "" this leads to unpacking errors if slicing is used and  "" <TAB><TAB><TAB><TAB>  "" will be removed in a future version "" % type ( obj ) , <TAB><TAB><TAB><TAB>  RuntimeWarning , <TAB><TAB><TAB><TAB>  stacklevel = 3 , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise <TAB>  if view . itemsize != 1 : <TAB><TAB>  raise ValueError ( "" cannot unpack from multi-byte object "" ) <TAB>  return view ",if PY2 :,if sys.platform == 'win32':,False,66.8775342424945,97.14000324946026
1542,"def import_modules ( modules , safe = True ) : <TAB>  """"""Safely import a list of *modules*"""""" <TAB>  all = [ ] <TAB>  for mname in modules : <TAB><TAB>  if mname . endswith ( "" .* "" ) : <TAB><TAB><TAB>  to_load = expand_star ( mname ) <TAB><TAB>  else : <TAB><TAB><TAB>  to_load = [ mname ] <TAB><TAB>  for module in to_load : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  all . append ( import_module ( module ) ) <TAB><TAB><TAB>  except ImportError : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise <TAB>  return all ",if not safe :,if safe:,False,53.081191801293016,98.73821696079902
1543,"def pack ( types , * args ) : <TAB>  if len ( types ) != len ( args ) : <TAB><TAB>  raise Exception ( "" number of arguments does not match format string "" ) <TAB>  port = StringIO ( ) <TAB>  for ( type , value ) in zip ( types , args ) : <TAB><TAB>  if type == "" V "" : <TAB><TAB><TAB>  write_vuint ( port , value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  write_vint ( port , value ) <TAB><TAB>  elif type == "" s "" : <TAB><TAB><TAB>  write_bvec ( port , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB>  return port . getvalue ( ) ","elif type == ""v"" :","if type == ""V':",False,52.188112362384764,95.79933408169136
1544,"def create_local_app_folder ( local_app_path ) : <TAB>  if exists ( local_app_path ) : <TAB><TAB>  raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB>  for folder in subfolders ( local_app_path ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . mkdir ( folder ) <TAB><TAB><TAB>  init_path = join ( folder , "" __init__.py "" ) <TAB><TAB><TAB>  if not exists ( init_path ) : <TAB><TAB><TAB><TAB>  create_file ( init_path ) ",if not exists ( folder ) :,if not folder.startswith('.'):,False,49.869106733833725,93.18671360937431
1545,"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB>  fields = self . config [ fields_key ] <TAB>  node_tags = self . provider . node_tags ( node_id ) <TAB>  if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB><TAB>  node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB><TAB>  node_specific_config = self . available_node_types [ node_type ] <TAB><TAB>  if fields_key in node_specific_config : <TAB><TAB><TAB>  fields = node_specific_config [ fields_key ] <TAB>  return fields ",if node_type not in self . available_node_types :,if node_type not in self.available_node_types:,False,26.257834424298498,100.00000000000004
1546,"def _maybe_fix_sequence_in_union ( <TAB>  aliases : List [ Alias ] , typecst : cst . SubscriptElement  ) - > cst . SubscriptElement : <TAB>  slc = typecst . slice <TAB>  if isinstance ( slc , cst . Index ) : <TAB><TAB>  val = slc . value <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return cst . ensure_type ( <TAB><TAB><TAB><TAB>  typecst . deep_replace ( val , _get_clean_type_from_subscript ( aliases , val ) ) , <TAB><TAB><TAB><TAB>  cst . SubscriptElement , <TAB><TAB><TAB>  ) <TAB>  return typecst ","if isinstance ( val , cst . Subscript ) :",if val is not None:,False,28.93963333772609,94.35907784202398
1547,"def cancel_download ( self , downloads ) : <TAB>  # Make sure we're always dealing with a list <TAB>  if isinstance ( downloads , Download ) : <TAB><TAB>  downloads = [ downloads ] <TAB>  for download in downloads : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . cancel_current_download ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . __paused = True <TAB><TAB><TAB>  new_queue = queue . Queue ( ) <TAB><TAB><TAB>  while not self . __queue . empty ( ) : <TAB><TAB><TAB><TAB>  queued_download = self . __queue . get ( ) <TAB><TAB><TAB><TAB>  if download == queued_download : <TAB><TAB><TAB><TAB><TAB>  download . cancel ( ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  new_queue . put ( queued_download ) <TAB><TAB><TAB>  self . __queue = new_queue <TAB><TAB><TAB>  self . __paused = False ",if download == self . __current_download :,if download.download_mode == Download.MODE_RUNNING:,False,32.69939311064552,96.2746926785243
1548,"def migrate_account_metadata ( account_id ) : <TAB>  from inbox . models . session import session_scope <TAB>  from inbox . models import Account <TAB>  with session_scope ( versioned = False ) as db_session : <TAB><TAB>  account = db_session . query ( Account ) . get ( account_id ) <TAB><TAB>  if account . discriminator == "" easaccount "" : <TAB><TAB><TAB>  create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB><TAB>  else : <TAB><TAB><TAB>  create_categories_for_folders ( account , db_session ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  set_labels_for_imapuids ( account , db_session ) <TAB><TAB>  db_session . commit ( ) ","if account . discriminator == ""gmailaccount"" :","if account.discriminator == ""labels':",False,43.15065916702772,98.1980200506683
1549,"def __init__ ( self , fmt = None , * args ) : <TAB>  if not isinstance ( fmt , BaseException ) : <TAB><TAB>  Error . __init__ ( self , fmt , * args ) <TAB>  else : <TAB><TAB>  e = fmt <TAB><TAB>  cls = e . __class__ <TAB><TAB>  fmt = "" %s . %s :  %s "" % ( cls . __module__ , cls . __name__ , e ) <TAB><TAB>  tb = sys . exc_info ( ) [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fmt + = "" \n "" <TAB><TAB><TAB>  fmt + = "" "" . join ( traceback . format_tb ( tb ) ) <TAB><TAB>  Error . __init__ ( self , fmt ) ",if tb :,if tb:,False,20.260514540049808,100.00000000000004
1550,"def setLabel ( self , label ) : <TAB>  if label is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . label . scene ( ) . removeItem ( self . label ) <TAB><TAB><TAB>  self . label = None <TAB>  else : <TAB><TAB>  if self . label is None : <TAB><TAB><TAB>  self . label = TextItem ( ) <TAB><TAB><TAB>  self . label . setParentItem ( self ) <TAB><TAB>  self . label . setText ( label ) <TAB><TAB>  self . _updateLabel ( ) ",if self . label is not None :,if self.label is not None:,False,52.675048779645195,100.00000000000004
1551,"def serve_until_stopped ( self ) - > None : <TAB>  while True : <TAB><TAB>  rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . handle_request ( ) <TAB><TAB>  if self . event is not None and self . event . is_set ( ) : <TAB><TAB><TAB>  break ",if rd :,if rd:,False,54.139955232108136,100.00000000000004
1552,"def generateCompressedFile ( inputfile , outputfile , formatstring ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  in_file = open ( inputfile , "" rb "" ) <TAB><TAB><TAB>  in_data = in_file . read ( ) <TAB><TAB><TAB>  out_file = open ( inputfile + "" .xz "" , "" wb "" ) <TAB><TAB><TAB>  out_file . write ( xz . compress ( in_data ) ) <TAB><TAB><TAB>  in_file . close ( ) <TAB><TAB><TAB>  out_file . close ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  tarout = tarfile . open ( outputfile , formatstring ) <TAB><TAB><TAB>  tarout . add ( inputfile , arcname = os . path . basename ( inputfile ) ) <TAB><TAB><TAB>  tarout . close ( ) <TAB>  except Exception as e : <TAB><TAB>  print ( e ) <TAB><TAB>  return False <TAB>  return True ","if formatstring == ""w:xz"" :",if formatstring == 'xz':,False,50.897310698476296,97.39897406831442
1553,"def _datastore_get_handler ( signal , sender , keys , * * kwargs ) : <TAB>  txn = current_transaction ( ) <TAB>  if txn : <TAB><TAB>  for key in keys : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise PreventedReadError ( <TAB><TAB><TAB><TAB><TAB>  "" Attempted to read key ( %s : %s ) inside a transaction  "" <TAB><TAB><TAB><TAB><TAB>  "" where it was marked protected "" % ( key . kind ( ) , key . id_or_name ( ) ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  txn . _fetched_keys . update ( set ( keys ) ) ",if key in txn . _protected_keys :,if key.kind() != 'read':,False,49.85567860845492,95.47075283966343
1554,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_access_token ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 16 : <TAB><TAB><TAB>  self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 8:,False,51.36809638600636,98.41504940787179
1555,"def write_vuint ( port , x ) : <TAB>  if x < 0 : <TAB><TAB>  raise Exception ( "" vuints must not be negative "" ) <TAB>  elif x == 0 : <TAB><TAB>  port . write ( "" \0 "" ) <TAB>  else : <TAB><TAB>  while x : <TAB><TAB><TAB>  seven_bits = x & 0x7F <TAB><TAB><TAB>  x >> = 7 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  port . write ( chr ( 0x80 | seven_bits ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  port . write ( chr ( seven_bits ) ) ",if x :,if x & 0x7F:,False,24.326955370024095,97.98790164424962
1556,"def _expand_srcs ( self ) : <TAB>  """"""Expand src to [(src, full_path)]"""""" <TAB>  result = [ ] <TAB>  for src in self . srcs : <TAB><TAB>  full_path = self . _source_file_path ( src ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Assume generated <TAB><TAB><TAB>  full_path = self . _target_file_path ( src ) <TAB><TAB>  result . append ( ( src , full_path ) ) <TAB>  return result ",if not os . path . exists ( full_path ) :,if full_path == self._target_file_path:,False,46.04469945671733,91.42845572767922
1557,"def pytest_collection_modifyitems ( items ) : <TAB>  for item in items : <TAB><TAB>  if item . nodeid . startswith ( "" tests/ops "" ) : <TAB><TAB><TAB>  if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if ""init"" not in item . keywords :","if ""init"" not in item.keywords:",False,28.420407113655756,100.00000000000004
1558,"def set_shape ( self , shape ) : <TAB>  """"""Sets a shape."""""" <TAB>  if self . _shape is not None : <TAB><TAB>  logger . warning ( ' Modifying the shape of Placeholder  "" %s "" . ' , self . name ) <TAB>  if not isinstance ( shape , ( list , tuple ) ) : <TAB><TAB>  shape = ( shape , ) <TAB>  shape = tuple ( x if x != "" None "" else None for x in shape ) <TAB>  for x in shape : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ParsingError ( <TAB><TAB><TAB><TAB>  ' All entries in  "" shape ""  must be integers, or in special  ' <TAB><TAB><TAB><TAB>  "" cases None. Shape is:  {} "" . format ( shape ) <TAB><TAB><TAB>  ) <TAB>  self . _shape = shape ","if not isinstance ( x , ( int , type ( None ) ) ) :","if not isinstance(x, (int, long)):",False,44.725483520891416,95.28411329988342
1559,"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB>  for line in raw_string . splitlines ( ) : <TAB><TAB>  for field_name in field_names : <TAB><TAB><TAB>  field_name = field_name . lower ( ) <TAB><TAB><TAB>  if "" : "" in line : <TAB><TAB><TAB><TAB>  left , right = line . split ( "" : "" , 1 ) <TAB><TAB><TAB><TAB>  left = left . strip ( ) . lower ( ) <TAB><TAB><TAB><TAB>  right = right . strip ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if cant_be_number : <TAB><TAB><TAB><TAB><TAB><TAB>  if not right . isdigit ( ) : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  return right <TAB><TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB><TAB>  return right <TAB>  return None ",if left == field_name and len ( right ) > 0 :,if left == field_name:,False,22.094602911274947,97.0954659381119
1560,"def validate_attributes ( self ) : <TAB>  for attribute in self . get_all_attributes ( ) : <TAB><TAB>  value = getattr ( self , attribute . code , None ) <TAB><TAB>  if value is None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB><TAB>  _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  attribute . validate_value ( value ) <TAB><TAB><TAB>  except ValidationError as e : <TAB><TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB><TAB>  _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB><TAB><TAB><TAB>  ) ",if attribute . required :,"if not hasattr(attribute, 'validate_value'):",False,26.8517270435689,96.14980366023892
1561,"def append ( self , s ) : <TAB>  buf = self . buf <TAB>  if buf is None : <TAB><TAB>  strbuf = self . strbuf <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . strbuf = strbuf + s <TAB><TAB><TAB>  return <TAB><TAB>  buf = self . _create_buffer ( ) <TAB>  buf . append ( s ) <TAB>  # use buf.__len__ rather than len(buf) FBO of not getting <TAB>  # OverflowError on Python 2 <TAB>  sz = buf . __len__ ( ) <TAB>  if not self . overflowed : <TAB><TAB>  if sz > = self . overflow : <TAB><TAB><TAB>  self . _set_large_buffer ( ) ",if len ( strbuf ) + len ( s ) < STRBUF_LIMIT :,if len(strbuf) > 0:,False,55.08650839873961,94.47406822666656
1562,"def billing_invoice_show_validator ( namespace ) : <TAB>  from azure . cli . core . azclierror import ( <TAB><TAB>  RequiredArgumentMissingError , <TAB><TAB>  MutuallyExclusiveArgumentError , <TAB>  ) <TAB>  valid_combs = ( <TAB><TAB>  "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB>  ) <TAB>  if namespace . account_name is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB><TAB>  if namespace . name is None : <TAB><TAB><TAB>  raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB>  <IF-STMT>: <TAB><TAB>  if namespace . name is None : <TAB><TAB><TAB>  raise RequiredArgumentMissingError ( "" --name is also required "" ) ",if namespace . by_subscription is not None :,if valid_combs:,False,55.14746886725117,89.87395288007109
1563,"def Handle ( self , args , context = None ) : <TAB>  for client_id in args . client_ids : <TAB><TAB>  cid = str ( client_id ) <TAB><TAB>  data_store . REL_DB . RemoveClientLabels ( cid , context . username , args . labels ) <TAB><TAB>  labels_to_remove = set ( args . labels ) <TAB><TAB>  existing_labels = data_store . REL_DB . ReadClientLabels ( cid ) <TAB><TAB>  for label in existing_labels : <TAB><TAB><TAB>  labels_to_remove . discard ( label . name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  idx = client_index . ClientIndex ( ) <TAB><TAB><TAB>  idx . RemoveClientLabels ( cid , labels_to_remove ) ",if labels_to_remove :,if len(labels_to_remove) > 0:,False,27.205452501937327,95.89414846700805
1564,"def delete_snapshot ( self , snapshot ) : <TAB>  snap_name = self . _get_snap_name ( snapshot [ "" id "" ] ) <TAB>  LOG . debug ( "" Deleting snapshot ( %s ) "" , snapshot [ "" id "" ] ) <TAB>  self . client_login ( ) <TAB>  try : <TAB><TAB>  self . client . delete_snapshot ( snap_name , self . backend_type ) <TAB>  except exception . DotHillRequestError as ex : <TAB><TAB>  # if the volume wasn't found, ignore the error <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  LOG . exception ( "" Deleting snapshot  %s  failed "" , snapshot [ "" id "" ] ) <TAB><TAB>  raise exception . Invalid ( ex ) <TAB>  finally : <TAB><TAB>  self . client_logout ( ) ","if ""The volume was not found on this system."" in ex . args :",if ex.code == 'ResourceNotFoundException':,False,56.45180133708049,92.37589950936932
1565,"def jobs ( self ) : <TAB>  # How many jobs have we done? <TAB>  total_processed = 0 <TAB>  for jobEntity in self . jobItems . query_entities ( ) : <TAB><TAB>  # Process the items in the page <TAB><TAB>  yield AzureJob . fromEntity ( jobEntity ) <TAB><TAB>  total_processed + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Produce some feedback for the user, because this can take <TAB><TAB><TAB>  # a long time on, for example, Azure <TAB><TAB><TAB>  logger . debug ( "" Processed  %d  total jobs "" % total_processed ) <TAB>  logger . debug ( "" Processed  %d  total jobs "" % total_processed ) ",if total_processed % 1000 == 0 :,if total_processed > 100:,False,40.32656619049489,96.33180785411403
1566,def run ( self ) : <TAB>  while not self . completed : <TAB><TAB>  if self . block : <TAB><TAB><TAB>  time . sleep ( self . period ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _completed . wait ( self . period ) <TAB><TAB>  self . counter + = 1 <TAB><TAB>  try : <TAB><TAB><TAB>  self . callback ( self . counter ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  if self . timeout is not None : <TAB><TAB><TAB>  dt = time . time ( ) - self . _start_time <TAB><TAB><TAB>  if dt > self . timeout : <TAB><TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . stop ( ) ,if self . counter == self . count :,if self.completed:,False,23.96421357746913,96.71897776475593
1567,"def get_instance ( cls , pool_size = None ) : <TAB>  if cls . _instance is not None : <TAB><TAB>  return cls . _instance <TAB>  # Lazy init <TAB>  with cls . _SINGLETON_LOCK : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . _instance = cls ( <TAB><TAB><TAB><TAB>  ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size <TAB><TAB><TAB>  ) <TAB>  return cls . _instance ",if cls . _instance is None :,if cls._instance is None:,False,57.82293352541026,100.00000000000004
1568,"def set_state ( self , state ) : <TAB>  if self . _inhibit_play : <TAB><TAB>  # PLAYING, PAUSED change the state for after buffering is finished, <TAB><TAB>  # everything else aborts buffering <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # abort <TAB><TAB><TAB>  self . __set_inhibit_play ( False ) <TAB><TAB><TAB>  self . bin . set_state ( state ) <TAB><TAB><TAB>  return <TAB><TAB>  self . _wanted_state = state <TAB>  else : <TAB><TAB>  self . bin . set_state ( state ) ","if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :",if state == self._wanted_state:,False,62.67176112923385,90.35636678989935
1569,"def seen_add ( options ) : <TAB>  seen_name = options . add_value <TAB>  if is_imdb_url ( seen_name ) : <TAB><TAB>  console ( "" IMDB url detected, try to parse ID "" ) <TAB><TAB>  imdb_id = extract_id ( seen_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  seen_name = imdb_id <TAB><TAB>  else : <TAB><TAB><TAB>  console ( "" Could not parse IMDB ID "" ) <TAB>  db . add ( seen_name , "" cli_add "" , { "" cli_add "" : seen_name } ) <TAB>  console ( "" Added  %s  as seen. This will affect all tasks. "" % seen_name ) ",if imdb_id :,if imdb_id:,False,61.713894495996136,100.00000000000004
1570,"def test_204_invalid_content_length ( self ) : <TAB>  # 204 status with non-zero content length is malformed <TAB>  with ExpectLog ( gen_log , "" .*Response with code 204 should not have body "" ) : <TAB><TAB>  response = self . fetch ( "" /?error=1 "" ) <TAB><TAB>  if not self . http1 : <TAB><TAB><TAB>  self . skipTest ( "" requires HTTP/1.x "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . skipTest ( "" curl client accepts invalid headers "" ) <TAB><TAB>  self . assertEqual ( response . code , 599 ) ",if self . http_client . configured_class != SimpleAsyncHTTPClient :,if not response:,False,38.26949983162747,91.39272765175215
1571,"def set_related_perm ( _mapper : Mapper , _connection : Connection , target : Slice ) - > None : <TAB>  src_class = target . cls_model <TAB>  id_ = target . datasource_id <TAB>  if id_ : <TAB><TAB>  ds = db . session . query ( src_class ) . filter_by ( id = int ( id_ ) ) . first ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  target . perm = ds . perm <TAB><TAB><TAB>  target . schema_perm = ds . schema_perm ",if ds :,if ds:,False,49.24904884910704,100.00000000000004
1572,"def on_modified_async ( self , view ) : <TAB>  if self . is_command_line ( view ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  view . run_command ( "" text_pastry_selection_preview "" ) ","if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :",if self.is_command_line(view):,False,16.631309852766172,63.50831487703252
1573,"def _improve_answer_span ( <TAB>  doc_tokens , input_start , input_end , tokenizer , orig_answer_text  ) : <TAB>  """"""Returns tokenized answer spans that better match the annotated answer."""""" <TAB>  tok_answer_text = "" "" . join ( tokenizer . tokenize ( orig_answer_text ) ) <TAB>  for new_start in range ( input_start , input_end + 1 ) : <TAB><TAB>  for new_end in range ( input_end , new_start - 1 , - 1 ) : <TAB><TAB><TAB>  text_span = "" "" . join ( doc_tokens [ new_start : ( new_end + 1 ) ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return new_start , new_end <TAB>  return input_start , input_end ",if text_span == tok_answer_text :,if text_span in tok_answer_text:,False,58.36321654012062,97.1242252929786
1574,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 18 : <TAB><TAB><TAB>  self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 26 : <TAB><TAB><TAB>  self . set_method ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 34 : <TAB><TAB><TAB>  self . set_queue ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 16:,False,51.21886122345749,98.97431450598246
1575,"def _add_resource_group ( obj ) : <TAB>  if isinstance ( obj , list ) : <TAB><TAB>  for array_item in obj : <TAB><TAB><TAB>  _add_resource_group ( array_item ) <TAB>  elif isinstance ( obj , dict ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if obj [ "" id "" ] : <TAB><TAB><TAB><TAB><TAB>  obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB><TAB>  except ( KeyError , IndexError , TypeError ) : <TAB><TAB><TAB>  pass <TAB><TAB>  for item_key in obj : <TAB><TAB><TAB>  if item_key != "" sourceVault "" : <TAB><TAB><TAB><TAB>  _add_resource_group ( obj [ item_key ] ) ","if ""resourcegroup"" not in [ x . lower ( ) for x in obj . keys ( ) ] :","if isinstance(obj, list):",False,47.49946626627805,91.41363839787321
1576,"def build ( opt ) : <TAB>  dpath = os . path . join ( opt [ "" datapath "" ] , DECODE ) <TAB>  version = DECODE_VERSION <TAB>  if not build_data . built ( dpath , version_string = version ) : <TAB><TAB>  print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # An older version exists, so remove these outdated files. <TAB><TAB><TAB>  build_data . remove_dir ( dpath ) <TAB><TAB>  build_data . make_dir ( dpath ) <TAB><TAB>  # Download the data. <TAB><TAB>  for downloadable_file in RESOURCES : <TAB><TAB><TAB>  downloadable_file . download_file ( dpath ) <TAB><TAB>  # Mark the data as built. <TAB><TAB>  build_data . mark_done ( dpath , version_string = version ) ",if build_data . built ( dpath ) :,if version < MIN_VERSION:,False,57.87768246492495,95.85557965020419
1577,"def toterminal ( self , tw ) : <TAB>  # the entries might have different styles <TAB>  last_style = None <TAB>  for i , entry in enumerate ( self . reprentries ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tw . line ( "" "" ) <TAB><TAB>  entry . toterminal ( tw ) <TAB><TAB>  if i < len ( self . reprentries ) - 1 : <TAB><TAB><TAB>  next_entry = self . reprentries [ i + 1 ] <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  entry . style == "" long "" <TAB><TAB><TAB><TAB>  or entry . style == "" short "" <TAB><TAB><TAB><TAB>  and next_entry . style == "" long "" <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  tw . sep ( self . entrysep ) <TAB>  if self . extraline : <TAB><TAB>  tw . line ( self . extraline ) ","if entry . style == ""long"" :",if not entry.style:,False,29.6276813423887,96.79501438639308
1578,"def reposition_division ( f1 ) : <TAB>  lines = f1 . splitlines ( ) <TAB>  if lines [ 2 ] == division : <TAB><TAB>  lines . pop ( 2 ) <TAB>  found = 0 <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  found + = 1 <TAB><TAB><TAB>  if found == 2 : <TAB><TAB><TAB><TAB>  if division in "" \n "" . join ( lines ) : <TAB><TAB><TAB><TAB><TAB>  break<TAB># already in the right place <TAB><TAB><TAB><TAB>  lines . insert ( i + 1 , "" "" ) <TAB><TAB><TAB><TAB>  lines . insert ( i + 2 , division ) <TAB><TAB><TAB><TAB>  break <TAB>  return "" \n "" . join ( lines ) ","if line . startswith ( '""""""' ) :",if line.startswith('division'):,False,48.76324362429869,96.41204921815056
1579,def run_on_module ( self ) : <TAB>  try : <TAB><TAB>  self . module_base . disable ( self . opts . module_spec ) <TAB>  except dnf . exceptions . MarkingErrors as e : <TAB><TAB>  if self . base . conf . strict : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise e <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  e . module_depsolv_errors <TAB><TAB><TAB><TAB>  and e . module_depsolv_errors [ 1 ] <TAB><TAB><TAB><TAB>  != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  raise e <TAB><TAB>  logger . error ( str ( e ) ) ,if e . no_match_group_specs or e . error_group_specs :,if e.module_depsolv_errors[0] != libdnf.module,False,21.757549894236895,92.52825181386318
1580,"def test_len ( self ) : <TAB>  eq = self . assertEqual <TAB>  eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB>  for size in range ( 15 ) : <TAB><TAB>  if size == 0 : <TAB><TAB><TAB>  bsize = 0 <TAB><TAB>  elif size < = 3 : <TAB><TAB><TAB>  bsize = 4 <TAB><TAB>  elif size < = 6 : <TAB><TAB><TAB>  bsize = 8 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bsize = 12 <TAB><TAB>  elif size < = 12 : <TAB><TAB><TAB>  bsize = 16 <TAB><TAB>  else : <TAB><TAB><TAB>  bsize = 20 <TAB><TAB>  eq ( base64mime . base64_len ( "" x "" * size ) , bsize ) ",elif size <= 9 :,if size <= 6:,False,27.963075551222545,97.73217726427006
1581,"def is_valid ( self ) : <TAB>  """"""Determines whether file is valid for this reader"""""" <TAB>  blocklist = self . open ( ) <TAB>  valid = True <TAB>  for line in blocklist : <TAB><TAB>  line = decode_bytes ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  ( start , end ) = self . parse ( line ) <TAB><TAB><TAB><TAB>  if not re . match ( r "" ^( \ d { 1,3} \ .) {4} $ "" , start + "" . "" ) or not re . match ( <TAB><TAB><TAB><TAB><TAB>  r "" ^( \ d { 1,3} \ .) {4} $ "" , end + "" . "" <TAB><TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB><TAB>  valid = False <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  valid = False <TAB><TAB><TAB>  break <TAB>  blocklist . close ( ) <TAB>  return valid ",if not self . is_ignored ( line ) :,if line:,False,38.795398658817135,96.3301675769409
1582,"def next ( self ) : <TAB>  while self . index < len ( self . data ) : <TAB><TAB>  uid = self . _read_next_word ( ) <TAB><TAB>  dont_care = self . _read_next_word ( ) <TAB><TAB>  entry = self . _read_next_string ( ) <TAB><TAB>  total_size = int ( 4 + 4 + len ( entry ) ) <TAB><TAB>  count = int ( total_size / self . SIZE ) <TAB><TAB>  if count == 0 : <TAB><TAB><TAB>  mod = self . SIZE - total_size <TAB><TAB>  else : <TAB><TAB><TAB>  mod = self . SIZE - int ( total_size - ( count * self . SIZE ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  remainder = self . _read_next_block ( mod ) <TAB><TAB>  yield ( uid , entry ) ",if mod > 0 :,if mod > 0:,False,51.40706939922639,100.00000000000004
1583,"def _str_param_list ( self , name ) : <TAB>  out = [ ] <TAB>  if self [ name ] : <TAB><TAB>  out + = self . _str_header ( name ) <TAB><TAB>  for param in self [ name ] : <TAB><TAB><TAB>  parts = [ ] <TAB><TAB><TAB>  if param . name : <TAB><TAB><TAB><TAB>  parts . append ( param . name ) <TAB><TAB><TAB>  if param . type : <TAB><TAB><TAB><TAB>  parts . append ( param . type ) <TAB><TAB><TAB>  out + = [ ""  :  "" . join ( parts ) ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  out + = self . _str_indent ( param . desc ) <TAB><TAB>  out + = [ "" "" ] <TAB>  return out ","if param . desc and """" . join ( param . desc ) . strip ( ) :",if param.desc:,False,32.92138717171142,93.24606718826624
1584,"def assert_backend ( self , expected_translated , language = "" cs "" ) : <TAB>  """"""Check that backend has correct data."""""" <TAB>  translation = self . get_translation ( language ) <TAB>  translation . commit_pending ( "" test "" , None ) <TAB>  store = translation . component . file_format_cls ( translation . get_filename ( ) , None ) <TAB>  messages = set ( ) <TAB>  translated = 0 <TAB>  for unit in store . content_units : <TAB><TAB>  id_hash = unit . id_hash <TAB><TAB>  self . assertFalse ( id_hash in messages , "" Duplicate string in in backend file! "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  translated + = 1 <TAB>  self . assertEqual ( <TAB><TAB>  translated , <TAB><TAB>  expected_translated , <TAB><TAB>  "" Did not found expected number of translations ( {}  !=  {} ). "" . format ( <TAB><TAB><TAB>  translated , expected_translated <TAB><TAB>  ) , <TAB>  ) ",if unit . is_translated ( ) :,if translation.is_translated:,False,56.29039475460183,97.67269992747956
1585,"def status ( self , name , error = "" No matching script logs found "" ) : <TAB>  with self . script_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . script_running [ 1 : ] <TAB><TAB>  elif self . script_last and self . script_last [ 1 ] == name : <TAB><TAB><TAB>  return self . script_last [ 1 : ] <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( error ) ",if self . script_running and self . script_running [ 1 ] == name :,if self.script_running and self.script_running[0] == name:,False,52.183678345667474,98.15812081525185
1586,"def dict_no_value_from_proto_list ( obj_list ) : <TAB>  d = dict ( ) <TAB>  for item in obj_list : <TAB><TAB>  possible_dict = json . loads ( item . value_json ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # (tss) TODO: This is protecting against legacy 'wandb_version' field. <TAB><TAB><TAB>  # Should investigate why the config payload even has 'wandb_version'. <TAB><TAB><TAB>  logger . warning ( "" key  ' {} '  has no  ' value '  attribute "" . format ( item . key ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  d [ item . key ] = possible_dict [ "" value "" ] <TAB>  return d ","if not isinstance ( possible_dict , dict ) or ""value"" not in possible_dict :",if not possible_dict:,False,51.72831883983038,90.76475981652045
1587,"def visit ( self , node ) : <TAB>  """"""dispatcher on node's class/bases name."""""" <TAB>  cls = node . __class__ <TAB>  try : <TAB><TAB>  visitmethod = self . cache [ cls ] <TAB>  except KeyError : <TAB><TAB>  for subclass in cls . __mro__ : <TAB><TAB><TAB>  visitmethod = getattr ( self , subclass . __name__ , None ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  visitmethod = self . __object <TAB><TAB>  self . cache [ cls ] = visitmethod <TAB>  visitmethod ( node ) ",if visitmethod is not None :,if visitmethod is None:,False,51.99501271639877,98.57248877503186
1588,"def _get_adapter ( <TAB>  mcls , <TAB>  reversed_mro : Tuple [ type , . . . ] , <TAB>  collection : Dict [ Any , Dict [ type , Adapter ] ] , <TAB>  kwargs : Dict [ str , Any ] ,  ) - > Optional [ Adapter ] : <TAB>  registry_key = mcls . get_registry_key ( kwargs ) <TAB>  adapters = collection . get ( registry_key ) <TAB>  if adapters is None : <TAB><TAB>  return None <TAB>  result = None <TAB>  seen : Set [ Adapter ] = set ( ) <TAB>  for base in reversed_mro : <TAB><TAB>  for adaptee , adapter in adapters . items ( ) : <TAB><TAB><TAB>  found = mcls . _match_adapter ( base , adaptee , adapter ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result = found <TAB><TAB><TAB><TAB>  seen . add ( found ) <TAB>  return result ",if found and found not in seen :,if found is not None:,False,35.5621797120173,97.31998672236902
1589,"def test_pt_BR_rg ( self ) : <TAB>  for _ in range ( 100 ) : <TAB><TAB>  to_test = self . fake . rg ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert re . search ( r "" ^ \ d {8} X "" , to_test ) <TAB><TAB>  else : <TAB><TAB><TAB>  assert re . search ( r "" ^ \ d {9} $ "" , to_test ) ","if ""X"" in to_test :",if sys.platform == 'win32':,False,16.88081604212346,92.8788199324923
1590,"def get_user_extra_data_by_client_id ( self , client_id , username ) : <TAB>  extra_data = { } <TAB>  current_client = self . clients . get ( client_id , None ) <TAB>  if current_client : <TAB><TAB>  for readable_field in current_client . get_readable_fields ( ) : <TAB><TAB><TAB>  attribute = list ( <TAB><TAB><TAB><TAB>  filter ( <TAB><TAB><TAB><TAB><TAB>  lambda f : f [ "" Name "" ] == readable_field , <TAB><TAB><TAB><TAB><TAB>  self . users . get ( username ) . attributes , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  extra_data . update ( { attribute [ 0 ] [ "" Name "" ] : attribute [ 0 ] [ "" Value "" ] } ) <TAB>  return extra_data ",if len ( attribute ) > 0 :,if attribute:,False,49.070556077497315,97.10506355095241
1591,"def augment ( self , resources ) : <TAB>  super ( ) . augment ( resources ) <TAB>  for r in resources : <TAB><TAB>  md = r . get ( "" SAMLMetadataDocument "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  root = sso_metadata ( md ) <TAB><TAB>  r [ "" IDPSSODescriptor "" ] = root [ "" IDPSSODescriptor "" ] <TAB>  return resources ",if not md :,if md is None:,False,24.59667021962229,95.7426374601143
1592,"def __init__ ( self , mode = 0 , decode = None ) : <TAB>  self . regex = self . REGEX [ mode ] <TAB>  self . decode = decode <TAB>  if decode : <TAB><TAB>  self . header = _ ( <TAB><TAB><TAB>  "" ### This log has been decoded with automatic search pattern \n "" <TAB><TAB><TAB>  "" ### If some paths are not decoded you can manually decode them with: \n "" <TAB><TAB>  ) <TAB><TAB>  self . header + = "" ###  ' backintime --quiet  "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . header + = ' --profile  "" %s "" ' % decode . config . profileName ( ) <TAB><TAB>  self . header + = "" --decode <path> ' \n \n "" <TAB>  else : <TAB><TAB>  self . header = "" "" ",if int ( decode . config . currentProfile ( ) ) > 1 :,if decode:,False,33.68386997373103,91.68350661607666
1593,"def _get_dynamic_attr ( self , attname , obj , default = None ) : <TAB>  try : <TAB><TAB>  attr = getattr ( self , attname ) <TAB>  except AttributeError : <TAB><TAB>  return default <TAB>  if callable ( attr ) : <TAB><TAB>  # Check co_argcount rather than try/excepting the function and <TAB><TAB>  # catching the TypeError, because something inside the function <TAB><TAB>  # may raise the TypeError. This technique is more accurate. <TAB><TAB>  try : <TAB><TAB><TAB>  code = six . get_function_code ( attr ) <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  code = six . get_function_code ( attr . __call__ ) <TAB><TAB>  <IF-STMT>:<TAB># one argument is 'self' <TAB><TAB><TAB>  return attr ( obj ) <TAB><TAB>  else : <TAB><TAB><TAB>  return attr ( ) <TAB>  return attr ",if code . co_argcount == 2 :,if code == 0:,False,64.06633415713104,96.42837510354624
1594,"def grep_full_py_identifiers ( tokens ) : <TAB>  global pykeywords <TAB>  tokens = list ( tokens ) <TAB>  i = 0 <TAB>  while i < len ( tokens ) : <TAB><TAB>  tokentype , token = tokens [ i ] <TAB><TAB>  i + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  while ( <TAB><TAB><TAB>  i + 1 < len ( tokens ) <TAB><TAB><TAB>  and tokens [ i ] == ( "" op "" , "" . "" ) <TAB><TAB><TAB>  and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB><TAB>  ) : <TAB><TAB><TAB>  token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB><TAB><TAB>  i + = 2 <TAB><TAB>  if token == "" "" : <TAB><TAB><TAB>  continue <TAB><TAB>  if token in pykeywords : <TAB><TAB><TAB>  continue <TAB><TAB>  if token [ 0 ] in "" .0123456789 "" : <TAB><TAB><TAB>  continue <TAB><TAB>  yield token ","if tokentype != ""id"" :",if token in pykeywords:,False,23.060452584242082,97.39801879745775
1595,"def _add_disk_config ( self , context , images ) : <TAB>  for image in images : <TAB><TAB>  metadata = image [ "" metadata "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raw_value = metadata [ INTERNAL_DISK_CONFIG ] <TAB><TAB><TAB>  value = utils . bool_from_str ( raw_value ) <TAB><TAB><TAB>  image [ API_DISK_CONFIG ] = disk_config_to_api ( value ) ",if INTERNAL_DISK_CONFIG in metadata :,if metadata.has_key('INTERNAL_DISK_CONFIG'):,False,21.447473672797212,90.74156789682712
1596,"def test_edgeql_expr_valid_setop_07 ( self ) : <TAB>  expected_error_msg = "" cannot be applied to operands "" <TAB>  # IF ELSE with every scalar as the condition <TAB>  for val in get_test_values ( ) : <TAB><TAB>  query = f """""" SELECT 1 IF  { val }  ELSE 2; """""" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await self . assert_query_result ( query , [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  # every other combination must produce an error <TAB><TAB><TAB>  with self . assertRaisesRegex ( <TAB><TAB><TAB><TAB>  edgedb . QueryError , expected_error_msg , msg = query <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  async with self . con . transaction ( ) : <TAB><TAB><TAB><TAB><TAB>  await self . con . execute ( query ) ","if val == ""<bool>True"" :",if val == 1:,False,60.97058140436313,96.89552947517946
1597,"def get_all_url_infos ( ) - > Dict [ str , UrlInfo ] : <TAB>  """"""Returns dict associating URL to UrlInfo."""""" <TAB>  url_infos = { } <TAB>  for path in _checksum_paths ( ) . values ( ) : <TAB><TAB>  dataset_url_infos = load_url_infos ( path ) <TAB><TAB>  for url , url_info in dataset_url_infos . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise AssertionError ( <TAB><TAB><TAB><TAB><TAB>  "" URL  {}  is registered with 2+ distinct size/checksum tuples.  "" <TAB><TAB><TAB><TAB><TAB>  "" {}  vs  {} "" . format ( url , url_info , url_infos [ url ] ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  url_infos . update ( dataset_url_infos ) <TAB>  return url_infos ","if url_infos . get ( url , url_info ) != url_info :",if url not in url_infos:,False,49.63772909262912,93.58700729867576
1598,"def global_fixes ( ) : <TAB>  """"""Yield multiple (code, function) tuples."""""" <TAB>  for function in list ( globals ( ) . values ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  arguments = _get_parameters ( function ) <TAB><TAB><TAB>  if arguments [ : 1 ] != [ "" source "" ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  code = extract_code_from_function ( function ) <TAB><TAB><TAB>  if code : <TAB><TAB><TAB><TAB>  yield ( code , function ) ",if inspect . isfunction ( function ) :,if function.name == 'code':,False,50.37184886724147,95.59574392917206
1599,"def createSocket ( self ) : <TAB>  skt = Port . createSocket ( self ) <TAB>  if self . listenMultiple : <TAB><TAB>  skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEPORT , 1 ) <TAB>  return skt ","if hasattr ( socket , ""SO_REUSEPORT"" ) :",if self.listenPort:,False,46.6802533731549,88.0424237806756
1600,"def _asStringList ( self , sep = "" "" ) : <TAB>  out = [ ] <TAB>  for item in self . _toklist : <TAB><TAB>  if out and sep : <TAB><TAB><TAB>  out . append ( sep ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out + = item . _asStringList ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  out . append ( str ( item ) ) <TAB>  return out ","if isinstance ( item , ParseResults ) :","if hasattr(item, '_asStringList'):",False,48.23577906829304,94.10451604405156
1601,"def parse_c_comments ( lexer , tok , ntok ) : <TAB>  if tok != "" / "" or ntok != "" * "" : <TAB><TAB>  return False <TAB>  quotes = lexer . quotes <TAB>  lexer . quotes = "" "" <TAB>  while True : <TAB><TAB>  tok = lexer . get_token ( ) <TAB><TAB>  ntok = lexer . get_token ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lexer . quotes = quotes <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  lexer . push_token ( ntok ) <TAB>  return True ","if tok == ""*"" and ntok == ""/"" :",if tok == tok:,False,22.623217266107346,92.98955651648978
1602,"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB>  sibling = self <TAB>  while sibling : <TAB><TAB>  c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB><TAB>  if c1 : <TAB><TAB><TAB>  v . append ( sibling ) <TAB><TAB>  else : <TAB><TAB><TAB>  c2 = not partialMatch and sibling . equalsTree ( target ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  v . append ( sibling ) <TAB><TAB>  ### regardless of match or not, check any children for matches <TAB><TAB>  if sibling . getFirstChild ( ) : <TAB><TAB><TAB>  sibling . getFirstChild ( ) . doWorkForFindAll ( v , target , partialMatch ) <TAB><TAB>  sibling = sibling . getNextSibling ( ) ",if c2 :,if c1 or c2:,False,60.436305571139606,98.16705222087585
1603,"def __view_beside ( self , onsideof , * * kwargs ) : <TAB>  bounds = self . info [ "" bounds "" ] <TAB>  min_dist , found = - 1 , None <TAB>  for ui in UiObject ( self . session , Selector ( * * kwargs ) ) : <TAB><TAB>  dist = onsideof ( bounds , ui . info [ "" bounds "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  min_dist , found = dist , ui <TAB>  return found ",if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,if dist < min_dist:,False,17.80612836531874,85.92800115674105
1604,"def __eq__ ( self , other ) : <TAB>  if isinstance ( other , numeric_range ) : <TAB><TAB>  empty_self = not bool ( self ) <TAB><TAB>  empty_other = not bool ( other ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return empty_self and empty_other<TAB># True if both empty <TAB><TAB>  else : <TAB><TAB><TAB>  return ( <TAB><TAB><TAB><TAB>  self . _start == other . _start <TAB><TAB><TAB><TAB>  and self . _step == other . _step <TAB><TAB><TAB><TAB>  and self . _get_by_index ( - 1 ) == other . _get_by_index ( - 1 ) <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return False ",if empty_self or empty_other :,if self._start == other._start and self._step == other._step:,False,18.477859274540446,85.81602882733755
1605,"def _buffered_generator ( self , size ) : <TAB>  buf = [ ] <TAB>  c_size = 0 <TAB>  push = buf . append <TAB>  while 1 : <TAB><TAB>  try : <TAB><TAB><TAB>  while c_size < size : <TAB><TAB><TAB><TAB>  c = next ( self . _gen ) <TAB><TAB><TAB><TAB>  push ( c ) <TAB><TAB><TAB><TAB>  if c : <TAB><TAB><TAB><TAB><TAB>  c_size + = 1 <TAB><TAB>  except StopIteration : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB>  yield concat ( buf ) <TAB><TAB>  del buf [ : ] <TAB><TAB>  c_size = 0 ",if not c_size :,if c_size == size:,False,26.288900139733112,97.46032653923551
1606,"def connect ( self ) : <TAB>  with self . _conn_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Error, database not properly initialized  "" "" before opening connection "" <TAB><TAB><TAB>  ) <TAB><TAB>  with self . exception_wrapper ( ) : <TAB><TAB><TAB>  self . __local . conn = self . _connect ( self . database , * * self . connect_kwargs ) <TAB><TAB><TAB>  self . __local . closed = False <TAB><TAB><TAB>  self . initialize_connection ( self . __local . conn ) ",if self . deferred :,if not self.__local:,False,50.54689695760961,95.93087506884073
1607,"def _merge_substs ( self , subst , new_substs ) : <TAB>  subst = subst . copy ( ) <TAB>  for new_subst in new_substs : <TAB><TAB>  for name , var in new_subst . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  subst [ name ] = var <TAB><TAB><TAB>  elif subst [ name ] is not var : <TAB><TAB><TAB><TAB>  subst [ name ] . PasteVariable ( var ) <TAB>  return subst ",if name not in subst :,if name not in self.substs:,False,44.92812312673211,96.61808264736948
1608,"def remove ( self , tag ) : <TAB>  """"""Removes a tag recursively from all containers."""""" <TAB>  new_contents = [ ] <TAB>  self . content_size = 0 <TAB>  for element in self . contents : <TAB><TAB>  if element . name != tag : <TAB><TAB><TAB>  new_contents . append ( element ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  element . remove ( tag ) <TAB><TAB><TAB>  self . content_size + = element . size ( ) <TAB>  self . contents = new_contents ","if isinstance ( element , Container ) :",if element.name == tag:,False,51.206977593840264,95.13748226719638
1609,"def _create_object ( self , obj_body ) : <TAB>  props = obj_body [ SYMBOL_PROPERTIES ] <TAB>  for prop_name , prop_value in props . items ( ) : <TAB><TAB>  if isinstance ( prop_value , dict ) and prop_value : <TAB><TAB><TAB>  # get the first key as the convert function <TAB><TAB><TAB>  func_name = list ( prop_value . keys ( ) ) [ 0 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  func = getattr ( self , func_name ) <TAB><TAB><TAB><TAB>  props [ prop_name ] = func ( prop_value [ func_name ] ) <TAB>  if SYMBOL_TYPE in obj_body and obj_body [ SYMBOL_TYPE ] in self . fake_func_mapping : <TAB><TAB>  return self . fake_func_mapping [ obj_body [ SYMBOL_TYPE ] ] ( * * props ) <TAB>  else : <TAB><TAB>  return props ","if func_name . startswith ( ""_"" ) :",if func_name in self.fake_func_mapping:,False,58.69023033563856,96.41527505849903
1610,"def visit_try_stmt ( self , o : "" mypy.nodes.TryStmt "" ) - > str : <TAB>  a = [ o . body ]<TAB># type: List[Any] <TAB>  for i in range ( len ( o . vars ) ) : <TAB><TAB>  a . append ( o . types [ i ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  a . append ( o . vars [ i ] ) <TAB><TAB>  a . append ( o . handlers [ i ] ) <TAB>  if o . else_body : <TAB><TAB>  a . append ( ( "" Else "" , o . else_body . body ) ) <TAB>  if o . finally_body : <TAB><TAB>  a . append ( ( "" Finally "" , o . finally_body . body ) ) <TAB>  return self . dump ( a , o ) ",if o . vars [ i ] :,if o.vars[i] is not None:,False,29.861064087096658,95.67130352948436
1611,"def everythingIsUnicode ( d ) : <TAB>  """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  if isinstance ( v , dict ) and k != "" headers "" : <TAB><TAB><TAB>  if not everythingIsUnicode ( v ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  for i in v : <TAB><TAB><TAB><TAB>  if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif isinstance ( v , _bytes ) : <TAB><TAB><TAB>  return False <TAB>  return True ","elif isinstance ( i , _bytes ) :","if isinstance(v, unicode):",False,33.8129753899165,96.72377344839968
1612,"def msg_ser ( inst , sformat , lev = 0 ) : <TAB>  if sformat in [ "" urlencoded "" , "" json "" ] : <TAB><TAB>  if isinstance ( inst , Message ) : <TAB><TAB><TAB>  res = inst . serialize ( sformat , lev ) <TAB><TAB>  else : <TAB><TAB><TAB>  res = inst <TAB>  elif sformat == "" dict "" : <TAB><TAB>  if isinstance ( inst , Message ) : <TAB><TAB><TAB>  res = inst . serialize ( sformat , lev ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  res = inst <TAB><TAB>  elif isinstance ( inst , str ) :<TAB># Iff ID Token <TAB><TAB><TAB>  res = inst <TAB><TAB>  else : <TAB><TAB><TAB>  raise MessageException ( "" Wrong type:  %s "" % type ( inst ) ) <TAB>  else : <TAB><TAB>  raise PyoidcError ( "" Unknown sformat "" , inst ) <TAB>  return res ","elif isinstance ( inst , dict ) :","if isinstance(inst, Token):",False,48.67865748640236,96.08202146084251
1613,"def start_container_if_stopped ( self , container , attach_logs = False , quiet = False ) : <TAB>  if not container . is_running : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( "" Starting  %s "" % container . name ) <TAB><TAB>  if attach_logs : <TAB><TAB><TAB>  container . attach_log_stream ( ) <TAB><TAB>  return self . start_container ( container ) ",if not quiet :,if quiet:,False,46.28565285139762,97.72970686458564
1614,"def layer_op ( self , input_image , mask = None ) : <TAB>  if not isinstance ( input_image , dict ) : <TAB><TAB>  self . _set_full_border ( input_image ) <TAB><TAB>  input_image = np . pad ( input_image , self . full_border , mode = self . mode ) <TAB><TAB>  return input_image , mask <TAB>  for name , image in input_image . items ( ) : <TAB><TAB>  self . _set_full_border ( image ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tf . logging . warning ( <TAB><TAB><TAB><TAB>  "" could not pad, dict name  %s  not in  %s "" , name , self . image_name <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  continue <TAB><TAB>  input_image [ name ] = np . pad ( image , self . full_border , mode = self . mode ) <TAB>  return input_image , mask ",if name not in self . image_name :,if name not in self.image_name:,False,57.584250452282916,100.00000000000004
1615,"def __Suffix_Noun_Step2b ( self , token ) : <TAB>  for suffix in self . __suffix_noun_step2b : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  token = token [ : - 2 ] <TAB><TAB><TAB>  self . suffix_noun_step2b_success = True <TAB><TAB><TAB>  break <TAB>  return token ",if token . endswith ( suffix ) and len ( token ) >= 5 :,if suffix.endswith(token):,False,43.77092804533776,84.92534959278247
1616,"def replace_header_items ( ps , replacments ) : <TAB>  match = read_while ( ps , header_item_or_end_re . match , lambda match : match is None ) <TAB>  while not ps . current_line . startswith ( "" */ "" ) : <TAB><TAB>  match = header_item_re . match ( ps . current_line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  key = match . groupdict ( ) [ "" key "" ] <TAB><TAB><TAB>  if key in replacments : <TAB><TAB><TAB><TAB>  ps . current_line = match . expand ( <TAB><TAB><TAB><TAB><TAB>  "" \ g<key> \ g<space> %s \n "" % replacments [ key ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  ps . read_line ( ) ",if match is not None :,if match:,False,40.18227395716751,97.87811371702125
1617,"def __projectBookmark ( widget , location ) : <TAB>  script = None <TAB>  while widget is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  script = widget . scriptNode ( ) <TAB><TAB><TAB>  if isinstance ( script , Gaffer . ScriptNode ) : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  widget = widget . parent ( ) <TAB>  if script is not None : <TAB><TAB>  p = script . context ( ) . substitute ( location ) <TAB><TAB>  if not os . path . exists ( p ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  os . makedirs ( p ) <TAB><TAB><TAB>  except OSError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  return p <TAB>  else : <TAB><TAB>  return os . getcwd ( ) ","if hasattr ( widget , ""scriptNode"" ) :","if hasattr(widget, 'scriptNode'):",False,49.44841366512934,97.98469818368231
1618,"def events_to_str ( event_field , all_events ) : <TAB>  result = [ ] <TAB>  for ( flag , string ) in all_events : <TAB><TAB>  c_flag = flag <TAB><TAB>  if event_field & c_flag : <TAB><TAB><TAB>  result . append ( string ) <TAB><TAB><TAB>  event_field = event_field & ( ~ c_flag ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  if event_field : <TAB><TAB>  result . append ( hex ( event_field ) ) <TAB>  return "" | "" . join ( result ) ",if not event_field :,if event_field == 0:,False,22.817111580259994,96.24132726880812
1619,"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB>  """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB>  for b in buckets : <TAB><TAB>  if b . get ( "" Logging "" ) : <TAB><TAB><TAB>  if self_log : <TAB><TAB><TAB><TAB>  if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield ( b [ "" Name "" ] , "" "" ) ","if not self_log and b [ ""Name"" ] . startswith ( ""cf-templates-"" ) :",if self_log:,False,54.61653422460736,91.10417710703143
1620,"def extract_file ( tgz , tarinfo , dst_path , buffer_size = 10 << 20 , log_function = None ) : <TAB>  """"""Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'."""""" <TAB>  src = tgz . extractfile ( tarinfo ) <TAB>  if src is None : <TAB><TAB>  return <TAB>  dst = tf . compat . v1 . gfile . GFile ( dst_path , "" wb "" ) <TAB>  while 1 : <TAB><TAB>  buf = src . read ( buffer_size ) <TAB><TAB>  if not buf : <TAB><TAB><TAB>  break <TAB><TAB>  dst . write ( buf ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log_function ( len ( buf ) ) <TAB>  dst . close ( ) <TAB>  src . close ( ) ",if log_function is not None :,if log_function is not None:,False,57.45095189483991,100.00000000000004
1621,"def make_index_fields ( rec ) : <TAB>  fields = { } <TAB>  for k , v in rec . iteritems ( ) : <TAB><TAB>  if k in ( "" lccn "" , "" oclc "" , "" isbn "" ) : <TAB><TAB><TAB>  fields [ k ] = v <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB>  return fields ","if k == ""full_title"" :",if v:,False,30.593819939031686,92.26793021620249
1622,"def disconnect_application ( self ) : <TAB>  if not self . is_app_running ( self . APP_BACKDROP ) : <TAB><TAB>  self . socket . send ( commands . CloseCommand ( destination_id = False ) ) <TAB><TAB>  start_time = time . time ( ) <TAB><TAB>  while not self . is_app_running ( None ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . socket . send_and_wait ( commands . StatusCommand ( ) ) <TAB><TAB><TAB>  except cast_socket . ConnectionTerminatedException : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  current_time = time . time ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise TimeoutException ( ) <TAB><TAB><TAB>  time . sleep ( self . WAIT_INTERVAL ) <TAB>  else : <TAB><TAB>  logger . debug ( "" Closing not necessary. Backdrop is running ... "" ) ",if current_time - start_time > self . timeout :,if current_time - start_time > self.WAIT_INTERVAL:,False,50.637798271830334,98.24267944374645
1623,"def matches ( self , cursor_offset , line , * * kwargs ) : <TAB>  cs = lineparts . current_string ( cursor_offset , line ) <TAB>  if cs is None : <TAB><TAB>  return None <TAB>  matches = set ( ) <TAB>  username = cs . word . split ( os . path . sep , 1 ) [ 0 ] <TAB>  user_dir = os . path . expanduser ( username ) <TAB>  for filename in self . safe_glob ( os . path . expanduser ( cs . word ) ) : <TAB><TAB>  if os . path . isdir ( filename ) : <TAB><TAB><TAB>  filename + = os . path . sep <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename = username + filename [ len ( user_dir ) : ] <TAB><TAB>  matches . add ( filename ) <TAB>  return matches ","if cs . word . startswith ( ""~"" ) :",if filename.startswith(user_dir):,False,28.080133955719273,95.65265231002037
1624,"def eventFilter ( self , obj , event ) : <TAB>  if event . type ( ) == QEvent . MouseButtonPress : <TAB><TAB>  button = event . button ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _app . browser . back ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  elif button == Qt . ForwardButton : <TAB><TAB><TAB>  self . _app . browser . forward ( ) <TAB><TAB><TAB>  return True <TAB>  return False ",if button == Qt . BackButton :,if button == Qt.BackButton:,False,51.26618663763223,100.00000000000004
1625,"def reset_parameters ( self ) : <TAB>  for m in self . modules ( ) : <TAB><TAB>  if isinstance ( m , nn . Embedding ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  nn . init . constant_ ( m . weight , 0.1 ) <TAB><TAB><TAB>  nn . init . constant_ ( m . bias , 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  for p in m . parameters ( ) : <TAB><TAB><TAB><TAB>  nn . init . normal_ ( p , 0 , 0.1 ) ","elif isinstance ( m , nn . LayerNorm ) :","if isinstance(m, nn.Constant):",False,26.340856494294524,96.76302463119038
1626,"def get_scalding_core ( self ) : <TAB>  lib_dir = os . path . join ( self . scalding_home , "" lib "" ) <TAB>  for j in os . listdir ( lib_dir ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p = os . path . join ( lib_dir , j ) <TAB><TAB><TAB>  logger . debug ( "" Found scalding-core:  %s "" , p ) <TAB><TAB><TAB>  return p <TAB>  raise luigi . contrib . hadoop . HadoopJobError ( "" Could not find scalding-core. "" ) ","if j . startswith ( ""scalding-core-"" ) :",if os.path.isdir(j):,False,48.17061152410042,94.41732594530288
1627,"def save ( self ) : <TAB>  """"""Saves a new set of golden output frames to disk."""""" <TAB>  for pixels , ( relative_to_assets , filename ) in zip ( <TAB><TAB>  self . iter_render ( ) , self . _iter_paths ( ) <TAB>  ) : <TAB><TAB>  full_directory_path = os . path . join ( self . _ASSETS_DIR , relative_to_assets ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( full_directory_path ) <TAB><TAB>  path = os . path . join ( full_directory_path , filename ) <TAB><TAB>  _save_pixels ( pixels , path ) ",if not os . path . exists ( full_directory_path ) :,if not os.path.exists(full_directory_path):,False,59.950031282677585,100.00000000000004
1628,"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB>  new_names = [ ] <TAB>  map = { } <TAB>  for op in operators : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  iter = op . inputs <TAB><TAB>  else : <TAB><TAB><TAB>  iter = op . outputs <TAB><TAB>  for i in iter : <TAB><TAB><TAB>  for name in names : <TAB><TAB><TAB><TAB>  if i . raw_name == name and name not in map : <TAB><TAB><TAB><TAB><TAB>  map [ i . raw_name ] = i . full_name <TAB><TAB>  if len ( map ) == len ( names ) : <TAB><TAB><TAB>  break <TAB>  for name in names : <TAB><TAB>  new_names . append ( map [ name ] ) <TAB>  return new_names ","if mod == ""input"" :",if mod == 'input':,False,48.188167932232595,98.06278444184801
1629,"def Tokenize ( s ) : <TAB>  # type: (str) -> Iterator[Token] <TAB>  for item in TOKEN_RE . findall ( s ) : <TAB><TAB>  # The type checker can't know the true type of item! <TAB><TAB>  item = cast ( TupleStr4 , item ) <TAB><TAB>  if item [ 0 ] : <TAB><TAB><TAB>  typ = "" number "" <TAB><TAB><TAB>  val = item [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  typ = "" name "" <TAB><TAB><TAB>  val = item [ 1 ] <TAB><TAB>  elif item [ 2 ] : <TAB><TAB><TAB>  typ = item [ 2 ] <TAB><TAB><TAB>  val = item [ 2 ] <TAB><TAB>  elif item [ 3 ] : <TAB><TAB><TAB>  typ = item [ 3 ] <TAB><TAB><TAB>  val = item [ 3 ] <TAB><TAB>  yield Token ( typ , val ) ",elif item [ 1 ] :,if val == 'name':,False,33.46704755640636,97.34909066950655
1630,"def init_errorhandler ( ) : <TAB>  # http error handling <TAB>  for ex in default_exceptions : <TAB><TAB>  if ex < 500 : <TAB><TAB><TAB>  app . register_error_handler ( ex , error_http ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  app . register_error_handler ( ex , internal_error ) <TAB>  if services . ldap : <TAB><TAB>  # Only way of catching the LDAPException upon logging in with LDAP server down <TAB><TAB>  @app . errorhandler ( services . ldap . LDAPException ) <TAB><TAB>  def handle_exception ( e ) : <TAB><TAB><TAB>  log . debug ( "" LDAP server not accessible while trying to login to opds feed "" ) <TAB><TAB><TAB>  return error_http ( FailedDependency ( ) ) ",elif ex == 500 :,if ex < 500:,False,42.46465358750465,97.30976155705424
1631,"def decode ( self , ids ) : <TAB>  ids = pad_decr ( ids ) <TAB>  tokens = [ ] <TAB>  for int_id in ids : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tokens . append ( self . _vocab_list [ int_id ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  tokens . append ( self . _oov_token ) <TAB>  return self . _decode_token_separator . join ( tokens ) ",if int_id < len ( self . _vocab_list ) :,if int_id in self._vocab_list:,False,48.350782183637556,94.38851287592884
1632,"def remove_contest ( contest_id ) : <TAB>  with SessionGen ( ) as session : <TAB><TAB>  contest = session . query ( Contest ) . filter ( Contest . id == contest_id ) . first ( ) <TAB><TAB>  if not contest : <TAB><TAB><TAB>  print ( "" No contest with id  %s  found. "" % contest_id ) <TAB><TAB><TAB>  return False <TAB><TAB>  contest_name = contest . name <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Not removing contest ` %s ' . "" % contest_name ) <TAB><TAB><TAB>  return False <TAB><TAB>  session . delete ( contest ) <TAB><TAB>  session . commit ( ) <TAB><TAB>  print ( "" Contest ` %s '  removed. "" % contest_name ) <TAB>  return True ",if not ask ( contest ) :,if not contest_name in session.list:,False,25.39104083918302,92.76301082484045
1633,def get_hi_lineno ( self ) : <TAB>  lineno = Node . get_hi_lineno ( self ) <TAB>  if self . expr1 is None : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  lineno = self . expr1 . get_hi_lineno ( ) <TAB><TAB>  if self . expr2 is None : <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  lineno = self . expr2 . get_hi_lineno ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  lineno = self . expr3 . get_hi_lineno ( ) <TAB>  return lineno ,if self . expr3 is None :,if lineno is None:,False,32.58103807669136,97.59729450809002
1634,"def _send_internal ( self , bytes_ ) : <TAB>  # buffering <TAB>  if self . pendings : <TAB><TAB>  self . pendings + = bytes_ <TAB><TAB>  bytes_ = self . pendings <TAB>  try : <TAB><TAB>  # reconnect if possible <TAB><TAB>  self . _reconnect ( ) <TAB><TAB>  # send message <TAB><TAB>  self . socket . sendall ( bytes_ ) <TAB><TAB>  # send finished <TAB><TAB>  self . pendings = None <TAB>  except Exception :<TAB># pylint: disable=broad-except <TAB><TAB>  # close socket <TAB><TAB>  self . _close ( ) <TAB><TAB>  # clear buffer if it exceeds max bufer size <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # TODO: add callback handler here <TAB><TAB><TAB>  self . pendings = None <TAB><TAB>  else : <TAB><TAB><TAB>  self . pendings = bytes_ ",if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,if bytes_ == 0:,False,32.727644014417365,92.28797279695449
1635,"def _unpack ( self , fmt , byt ) : <TAB>  d = unpack ( self . _header [ "" byteorder "" ] + fmt , byt ) [ 0 ] <TAB>  if fmt [ - 1 ] in self . MISSING_VALUES : <TAB><TAB>  nmin , nmax = self . MISSING_VALUES [ fmt [ - 1 ] ] <TAB><TAB>  if d < nmin or d > nmax : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return StataMissingValue ( nmax , d ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return None <TAB>  return d ",if self . _missing_values :,if nmin < 0 or nmax < 0 or nmin > nmax:,False,55.56870056329966,87.57521784923226
1636,"def tuple_iter ( self ) : <TAB>  for x in range ( <TAB><TAB>  self . center . x - self . max_radius , self . center . x + self . max_radius + 1 <TAB>  ) : <TAB><TAB>  for y in range ( <TAB><TAB><TAB>  self . center . y - self . max_radius , self . center . y + self . max_radius + 1 <TAB><TAB>  ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield ( x , y ) ","if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :",if x <= y <= self.center.x and y <= self.center.y:,False,21.436276415598314,87.44013441458243
1637,"def _parse_gene ( element ) : <TAB>  for genename_element in element : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ann_key = "" gene_ %s _ %s "" % ( <TAB><TAB><TAB><TAB>  genename_element . tag . replace ( NS , "" "" ) , <TAB><TAB><TAB><TAB>  genename_element . attrib [ "" type "" ] , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  if genename_element . attrib [ "" type "" ] == "" primary "" : <TAB><TAB><TAB><TAB>  self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  append_to_annotations ( ann_key , genename_element . text ) ","if ""type"" in genename_element . attrib :",if genename_element.tag == NS:,False,47.64922498307242,96.18986820358803
1638,"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB>  # only user defined curve can have slice dependency relationships <TAB>  if self . isSystemCurveIndex ( iFirstCurve ) : <TAB><TAB>  return <TAB>  nCurves = self . getNCurves ( ) <TAB>  for i in range ( iFirstCurve , nCurves ) : <TAB><TAB>  c = self . getSystemCurve ( i ) <TAB><TAB>  if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) : <TAB><TAB><TAB>  c . invalidate ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # if first curve isn't a slice, <TAB><TAB><TAB>  break <TAB><TAB><TAB>  # there are no dependent slices ",elif i == iFirstCurve :,if c.getSymbol().getSymbolType() == SymbolType.PieSliceSymbolType,False,38.92649350539607,91.01113794906674
1639,"def gen_app_versions ( self ) : <TAB>  for app_config in apps . get_app_configs ( ) : <TAB><TAB>  name = app_config . verbose_name <TAB><TAB>  app = app_config . module <TAB><TAB>  version = self . get_app_version ( app ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield app . __name__ , name , version ",if version :,if version:,False,51.31003982113329,100.00000000000004
1640,"def verify_relative_valid_path ( root , path ) : <TAB>  if len ( path ) < 1 : <TAB><TAB>  raise PackagerError ( "" Empty chown path "" ) <TAB>  checkpath = root <TAB>  parts = path . split ( os . sep ) <TAB>  for part in parts : <TAB><TAB>  if part in ( "" . "" , "" .. "" ) : <TAB><TAB><TAB>  raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB><TAB>  checkpath = os . path . join ( checkpath , part ) <TAB><TAB>  relpath = checkpath [ len ( root ) + 1 : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB><TAB>  if os . path . islink ( checkpath ) : <TAB><TAB><TAB>  raise PackagerError ( f "" chown path  { relpath }  is a soft link "" ) ",if not os . path . exists ( checkpath ) :,if not os.path.exists(checkpath):,False,37.244221118934604,100.00000000000004
1641,"def create_or_update_tag_at_scope ( cmd , resource_id = None , tags = None , tag_name = None ) : <TAB>  rcf = _resource_client_factory ( cmd . cli_ctx ) <TAB>  if resource_id is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise IncorrectUsageError ( "" Tags could not be empty. "" ) <TAB><TAB>  Tags = cmd . get_models ( "" Tags "" ) <TAB><TAB>  tag_obj = Tags ( tags = tags ) <TAB><TAB>  return rcf . tags . create_or_update_at_scope ( scope = resource_id , properties = tag_obj ) <TAB>  return rcf . tags . create_or_update ( tag_name = tag_name ) ",if not tags :,if tags is None:,False,36.14174520278459,97.63681549074664
1642,"def generate_auto_complete ( self , base , iterable_var ) : <TAB>  sugg = [ ] <TAB>  for entry in iterable_var : <TAB><TAB>  compare_entry = entry <TAB><TAB>  compare_base = base <TAB><TAB>  if self . settings . get ( IGNORE_CASE_SETTING ) : <TAB><TAB><TAB>  compare_entry = compare_entry . lower ( ) <TAB><TAB><TAB>  compare_base = compare_base . lower ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if entry not in sugg : <TAB><TAB><TAB><TAB>  sugg . append ( entry ) <TAB>  return sugg ","if self . compare_entries ( compare_entry , compare_base ) :",if compare_base == compare_entry:,False,21.66780424721404,92.73300838729065
1643,"def createFields ( self ) : <TAB>  yield String ( self , "" dict_start "" , 2 ) <TAB>  while not self . eof : <TAB><TAB>  addr = self . absolute_address + self . current_size <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for field in parsePDFType ( self ) : <TAB><TAB><TAB><TAB>  yield field <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  yield String ( self , "" dict_end "" , 2 ) ","if self . stream . readBytes ( addr , 2 ) != "">>"" :",if addr == self.absolute_address:,False,20.3968196998284,88.04378635875808
1644,"def Visit_and_test ( self , node ) :<TAB># pylint: disable=invalid-name <TAB>  # and_test ::= not_test ('and' not_test)* <TAB>  for child in node . children : <TAB><TAB>  self . Visit ( child ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _AppendTokenSubtype ( child , format_token . Subtype . BINARY_OPERATOR ) ","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :","if isinstance(child, format_token.Subtype.BINARY_OPERATOR):",False,13.950249068428588,85.72056052225993
1645,"def getfiledata ( directories ) : <TAB>  columns = None <TAB>  data = [ ] <TAB>  counter = 1 <TAB>  for directory in directories : <TAB><TAB>  for f in os . listdir ( directory ) : <TAB><TAB><TAB>  if not os . path . isfile ( os . path . join ( directory , f ) ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  counter + = 1 <TAB><TAB><TAB>  st = os . stat ( os . path . join ( directory , f ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  columns = [ "" rowid "" , "" name "" , "" directory "" ] + [ <TAB><TAB><TAB><TAB><TAB>  x for x in dir ( st ) if x . startswith ( "" st_ "" ) <TAB><TAB><TAB><TAB>  ] <TAB><TAB><TAB>  data . append ( [ counter , f , directory ] + [ getattr ( st , x ) for x in columns [ 3 : ] ] ) <TAB>  return columns , data ",if columns is None :,if st.startswith('st_'):,False,35.17275231365161,96.44581797831898
1646,"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB>  for attr in attributes : <TAB><TAB>  value = getattr ( obj , attr , None ) <TAB><TAB>  if value is None : <TAB><TAB><TAB>  continue <TAB><TAB>  name = name_fmt % attr <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = formatter ( attr , value ) <TAB><TAB>  info_add ( name , value ) ",if formatter is not None :,if formatter is not None:,False,52.80623417442995,100.00000000000004
1647,"def main ( args ) : <TAB>  ap = argparse . ArgumentParser ( ) <TAB>  ap . add_argument ( "" job_ids "" , nargs = "" + "" , type = int , help = "" ID of a running job "" ) <TAB>  ns = ap . parse_args ( args ) <TAB>  _stash = globals ( ) [ "" _stash "" ] <TAB>  """""":type : StaSh"""""" <TAB>  for job_id in ns . job_ids : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" killing job  {}  ... "" . format ( job_id ) ) <TAB><TAB><TAB>  worker = _stash . runtime . worker_registry . get_worker ( job_id ) <TAB><TAB><TAB>  worker . kill ( ) <TAB><TAB><TAB>  time . sleep ( 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" error: no such job with id:  {} "" . format ( job_id ) ) <TAB><TAB><TAB>  break ",if job_id in _stash . runtime . worker_registry :,if _stash.runtime.worker_registry.has_job(job_id):,False,27.874598674343265,96.0010415007059
1648,"def _check_choice ( self ) : <TAB>  if self . type == "" choice "" : <TAB><TAB>  if self . choices is None : <TAB><TAB><TAB>  raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise OptionError ( <TAB><TAB><TAB><TAB>  "" choices must be a list of strings ( ' %s '  supplied) "" <TAB><TAB><TAB><TAB>  % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB><TAB><TAB><TAB>  self , <TAB><TAB><TAB>  ) <TAB>  elif self . choices is not None : <TAB><TAB>  raise OptionError ( "" must not supply choices for type  %r "" % self . type , self ) ","elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :",if type(self.choices) is not list:,False,34.64471714174403,90.87017543335074
1649,"def add_file ( pipe , srcpath , tgtpath ) : <TAB>  with open ( srcpath , "" rb "" ) as handle : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  write ( pipe , enc ( "" M 100755 inline  %s \n "" % tgtpath ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  write ( pipe , enc ( "" M 100644 inline  %s \n "" % tgtpath ) ) <TAB><TAB>  data = handle . read ( ) <TAB><TAB>  write ( pipe , enc ( "" data  %d \n "" % len ( data ) ) ) <TAB><TAB>  write ( pipe , enc ( data ) ) <TAB><TAB>  write ( pipe , enc ( "" \n "" ) ) ","if os . access ( srcpath , os . X_OK ) :",if os.path.exists(tgtpath):,False,47.722819184261766,94.47245102118416
1650,"def cdf ( self , x ) : <TAB>  if x == numpy . inf : <TAB><TAB>  return 1.0 <TAB>  else :<TAB># Inefficient sum. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" Invalid value. "" ) <TAB><TAB>  c = 0.0 <TAB><TAB>  for i in xrange ( x + 1 ) : <TAB><TAB><TAB>  c + = self . probability ( i ) <TAB><TAB>  return c ",if x != int ( x ) :,if x < 0 or x > self.num_values:,False,23.23597663383758,87.40413464102305
1651,"def convert_to_strings ( self , out , seq_len ) : <TAB>  results = [ ] <TAB>  for b , batch in enumerate ( out ) : <TAB><TAB>  utterances = [ ] <TAB><TAB>  for p , utt in enumerate ( batch ) : <TAB><TAB><TAB>  size = seq_len [ b ] [ p ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  transcript = "" "" . join ( <TAB><TAB><TAB><TAB><TAB>  map ( lambda x : self . int_to_char [ x . item ( ) ] , utt [ 0 : size ] ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  transcript = "" "" <TAB><TAB><TAB>  utterances . append ( transcript ) <TAB><TAB>  results . append ( utterances ) <TAB>  return results ",if size > 0 :,if size > 0:,False,50.94904202593078,100.00000000000004
1652,"def get_date_range ( self ) : <TAB>  if not hasattr ( self , "" start "" ) or not hasattr ( self , "" end "" ) : <TAB><TAB>  args = ( self . today . year , self . today . month ) <TAB><TAB>  form = self . get_form ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args = ( int ( form . cleaned_data [ "" year "" ] ) , int ( form . cleaned_data [ "" month "" ] ) ) <TAB><TAB>  self . start = self . get_start ( * args ) <TAB><TAB>  self . end = self . get_end ( * args ) <TAB>  return self . start , self . end ",if form . is_valid ( ) :,if form.is_valid():,False,50.81193280888697,100.00000000000004
1653,"def save_stats ( self ) : <TAB>  LOGGER . info ( "" Saving task-level statistics. "" ) <TAB>  has_headers = os . path . isfile ( paths . TABLE_COUNT_PATH ) <TAB>  with open ( paths . TABLE_COUNT_PATH , "" a "" ) as csvfile : <TAB><TAB>  headers = [ "" start_time "" , "" database_name "" , "" number_tables "" ] <TAB><TAB>  writer = csv . DictWriter ( <TAB><TAB><TAB>  csvfile , delimiter = "" , "" , lineterminator = "" \n "" , fieldnames = headers <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  writer . writeheader ( ) <TAB><TAB>  writer . writerow ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" start_time "" : self . start_time , <TAB><TAB><TAB><TAB>  "" database_name "" : self . database_name , <TAB><TAB><TAB><TAB>  "" number_tables "" : self . count , <TAB><TAB><TAB>  } <TAB><TAB>  ) ",if not has_headers :,if has_headers:,False,50.06895675733665,99.06764068615378
1654,"def _CheckCanaryCommand ( self ) : <TAB>  <IF-STMT>:<TAB># fast path <TAB><TAB>  return <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  logging . info ( "" Testing OpenStack CLI command is installed and working "" ) <TAB><TAB>  cmd = os_utils . OpenStackCLICommand ( self , "" image "" , "" list "" ) <TAB><TAB>  stdout , stderr , _ = cmd . Issue ( ) <TAB><TAB>  if stderr : <TAB><TAB><TAB>  raise errors . Config . InvalidValue ( <TAB><TAB><TAB><TAB>  "" OpenStack CLI test command failed. Please make sure the OpenStack  "" <TAB><TAB><TAB><TAB>  "" CLI client is installed and properly configured "" <TAB><TAB><TAB>  ) <TAB><TAB>  OpenStackVirtualMachine . command_works = True ",if OpenStackVirtualMachine . command_works :,if os_utils.OpenStackCLICommand is None:,False,26.86050979331789,92.43785590431229
1655,"def test_windows_hidden ( self ) : <TAB>  if not sys . platform == "" win32 "" : <TAB><TAB>  self . skipTest ( "" sys.platform is not windows "" ) <TAB><TAB>  return <TAB>  # FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation. <TAB>  hidden_mask = 2 <TAB>  with tempfile . NamedTemporaryFile ( ) as f : <TAB><TAB>  # Hide the file using <TAB><TAB>  success = ctypes . windll . kernel32 . SetFileAttributesW ( f . name , hidden_mask ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . skipTest ( "" unable to set file attributes "" ) <TAB><TAB>  self . assertTrue ( hidden . is_hidden ( f . name ) ) ",if not success :,if not success:,False,58.31353685788119,100.00000000000004
1656,"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB>  if tr < 1 : <TAB><TAB>  tr = 1 <TAB>  x = time . time ( ) + t <TAB>  y = [ ] <TAB>  r = "" "" <TAB>  if stderr : <TAB><TAB>  pr = p . recv_err <TAB>  else : <TAB><TAB>  pr = p . recv <TAB>  while time . time ( ) < x or r : <TAB><TAB>  r = pr ( ) <TAB><TAB>  if r is None : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y . append ( r ) <TAB><TAB>  else : <TAB><TAB><TAB>  time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB>  return b "" "" . join ( y ) ",elif r :,if r.code == e:,False,27.6153398426137,96.33583471800091
1657,"def _is_xml ( accepts ) : <TAB>  if accepts . startswith ( b "" application/ "" ) : <TAB><TAB>  has_xml = accepts . find ( b "" xml "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  semicolon = accepts . find ( b "" ; "" ) <TAB><TAB><TAB>  if semicolon < 0 or has_xml < semicolon : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if has_xml > 0 :,if has_xml > -1:,False,23.125670620079323,97.78225290627776
1658,"def times ( self , value : int ) : <TAB>  if value is None : <TAB><TAB>  self . _times = None <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  candidate = int ( value ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  # pylint: disable:raise-missing-from <TAB><TAB><TAB>  raise BarException ( f "" cannot set repeat times to:  { value !r} "" ) <TAB><TAB>  if candidate < 0 : <TAB><TAB><TAB>  raise BarException ( <TAB><TAB><TAB><TAB>  f "" cannot set repeat times to a value less than zero:  { value } "" <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise BarException ( "" cannot set repeat times on a start Repeat "" ) <TAB><TAB>  self . _times = candidate ","if self . direction == ""start"" :",if candidate > self._times:,False,62.82359717262578,96.02517529319304
1659,"def __call__ ( self , * args , * * kwargs ) : <TAB>  if not NET_INITTED : <TAB><TAB>  return self . raw ( * args , * * kwargs ) <TAB>  for stack in traceback . walk_stack ( None ) : <TAB><TAB>  if "" self "" in stack [ 0 ] . f_locals : <TAB><TAB><TAB>  layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  log . pytorch_layer_name = layer_names [ layer ] <TAB><TAB><TAB><TAB>  print ( layer_names [ layer ] ) <TAB><TAB><TAB><TAB>  break <TAB>  out = self . obj ( self . raw , * args , * * kwargs ) <TAB>  # if isinstance(out,Variable): <TAB>  #<TAB> out=[out] <TAB>  return out ",if layer in layer_names :,if layer in layer_names:,False,45.38780851297069,100.00000000000004
1660,"def do_begin ( self , byte ) : <TAB>  if byte . isspace ( ) : <TAB><TAB>  return <TAB>  if byte != "" < "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _leadingBodyData = byte <TAB><TAB><TAB>  return "" bodydata "" <TAB><TAB>  self . _parseError ( "" First char of document [ {!r} ] wasn ' t < "" . format ( byte ) ) <TAB>  return "" tagstart "" ",if self . beExtremelyLenient :,if byte != '<':,False,49.16898821170009,89.83281980142705
1661,"def pretty ( self , n , comment = True ) : <TAB>  if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB><TAB>  r = repr ( n ) <TAB><TAB>  <IF-STMT>:<TAB># then it can be inside a comment! <TAB><TAB><TAB>  r = r . replace ( "" */ "" , r "" \ x2a/ "" ) <TAB><TAB>  return r <TAB>  if not isinstance ( n , six . integer_types ) : <TAB><TAB>  return n <TAB>  if isinstance ( n , constants . Constant ) : <TAB><TAB>  if comment : <TAB><TAB><TAB>  return "" %s  /*  %s  */ "" % ( n , self . pretty ( int ( n ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  return "" %s  ( %s ) "" % ( n , self . pretty ( int ( n ) ) ) <TAB>  elif abs ( n ) < 10 : <TAB><TAB>  return str ( n ) <TAB>  else : <TAB><TAB>  return hex ( n ) ",if not comment :,if r.startswith('**'):,False,49.41788723770234,94.6286028516974
1662,"def test_training_script_with_max_history_set ( tmpdir ) : <TAB>  train_dialogue_model ( <TAB><TAB>  DEFAULT_DOMAIN_PATH , <TAB><TAB>  DEFAULT_STORIES_FILE , <TAB><TAB>  tmpdir . strpath , <TAB><TAB>  interpreter = RegexInterpreter ( ) , <TAB><TAB>  policy_config = "" data/test_config/max_hist_config.yml "" , <TAB><TAB>  kwargs = { } , <TAB>  ) <TAB>  agent = Agent . load ( tmpdir . strpath ) <TAB>  for policy in agent . policy_ensemble . policies : <TAB><TAB>  if hasattr ( policy . featurizer , "" max_history "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  assert policy . featurizer . max_history == 2 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  assert policy . featurizer . max_history == 5 ",if type ( policy ) == FormPolicy :,if sys.platform == 'win32':,False,26.730596918140147,96.68933738042357
1663,"def cli_uninstall_distro ( ) : <TAB>  distro_list = install_distro_list ( ) <TAB>  if distro_list is not None : <TAB><TAB>  for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB>  log ( str ( index ) + ""   --->>   "" + _distro_dir ) <TAB><TAB>  user_input = read_input_uninstall ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB><TAB>  if index == user_input : <TAB><TAB><TAB><TAB><TAB>  config . uninstall_distro_dir_name = _distro_dir <TAB><TAB><TAB><TAB><TAB>  unin_distro ( ) <TAB>  else : <TAB><TAB>  log ( "" No distro installed on  "" + config . usb_disk ) ",if user_input is not False :,if user_input is not None:,False,39.587529919929,98.91180759779758
1664,"def set_random_avatar ( user ) : <TAB>  galleries = get_available_galleries ( include_default = True ) <TAB>  if not galleries : <TAB><TAB>  raise RuntimeError ( "" no avatar galleries are set "" ) <TAB>  avatars_list = [ ] <TAB>  for gallery in galleries : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  avatars_list = gallery [ "" images "" ] <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  avatars_list + = gallery [ "" images "" ] <TAB>  random_avatar = random . choice ( avatars_list ) <TAB>  store . store_new_avatar ( user , Image . open ( random_avatar . image ) ) ","if gallery [ ""name"" ] == DEFAULT_GALLERY :","if not isinstance(gallery, User):",False,26.016603367586193,93.2359611168051
1665,"def make_query ( self , key , filters ) : <TAB>  meta = self . get_meta ( key ) <TAB>  q = { meta . facet_key : self . normalize_key ( meta . path ) } <TAB>  if filters : <TAB><TAB>  if filters . get ( "" has_fulltext "" ) == "" true "" : <TAB><TAB><TAB>  q [ "" has_fulltext "" ] = "" true "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  q [ "" publish_year "" ] = filters [ "" publish_year "" ] <TAB>  return q ","if filters . get ( ""publish_year"" ) :",if filters.get('publish_year'):,False,38.02755777204256,95.69550292887835
1666,"def test_named_parameters_and_constraints ( self ) : <TAB>  likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB>  model = ExactGPModel ( None , None , likelihood ) <TAB>  for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB><TAB>  if name == "" likelihood.noise_covar.raw_noise "" : <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIsNone ( constraint ) <TAB><TAB>  elif name == "" covar_module.raw_outputscale "" : <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB><TAB>  elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) ","elif name == ""mean_module.constant"" :","if name == ""param_name_covar_raw_noise':",False,46.20861988540982,94.332817525431
1667,"def _test_pooling ( input_shape , * * kwargs ) : <TAB>  _test_pooling_iteration ( input_shape , * * kwargs ) <TAB>  if is_gpu_available ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  input_shape = [ input_shape [ ii ] for ii in ( 0 , 3 , 1 , 2 ) ] <TAB><TAB><TAB>  kwargs [ "" data_format "" ] = "" NCHW "" <TAB><TAB><TAB>  _test_pooling_iteration ( input_shape , * * kwargs ) ",if len ( input_shape ) == 4 :,if is_gpu_available():,False,37.962457397001714,92.9372580257256
1668,"def init ( self ) : <TAB>  r = self . get_redis ( ) <TAB>  if r : <TAB><TAB>  key = "" pocsuite_target "" <TAB><TAB>  info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB><TAB>  logger . info ( info_msg ) <TAB><TAB>  targets = r . get ( key ) <TAB><TAB>  count = 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for target in targets : <TAB><TAB><TAB><TAB>  if self . add_target ( target ) : <TAB><TAB><TAB><TAB><TAB>  count + = 1 <TAB><TAB>  info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB><TAB>  logger . info ( info_msg ) ",if targets :,if targets:,False,50.09805807901988,100.00000000000004
1669,"def reload_json_api_settings ( * args , * * kwargs ) : <TAB>  django_setting = kwargs [ "" setting "" ] <TAB>  setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB>  value = kwargs [ "" value "" ] <TAB>  if setting in DEFAULTS . keys ( ) : <TAB><TAB>  if value is not None : <TAB><TAB><TAB>  setattr ( json_api_settings , setting , value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  delattr ( json_api_settings , setting ) ","elif hasattr ( json_api_settings , setting ) :",if setting in json_api_settings.settings:,False,21.054123554088235,93.87459012022629
1670,"def update_metadata ( self ) : <TAB>  for attrname in dir ( self ) : <TAB><TAB>  if attrname . startswith ( "" __ "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  attrvalue = getattr ( self , attrname , None ) <TAB><TAB>  if attrvalue == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  if attrname == "" salt_version "" : <TAB><TAB><TAB>  attrname = "" version "" <TAB><TAB>  if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB>  getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  pass ","elif hasattr ( self . metadata , attrname ) :",if attrname != 'version':,False,39.45314781707386,95.79974896955474
1671,"def test_02_looking_at_listdir_path_ ( name ) : <TAB>  for dline in listdir . json ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert dline [ "" type "" ] in ( "" DIRECTORY "" , "" FILE "" ) , listdir . text <TAB><TAB><TAB>  assert dline [ "" uid "" ] == 0 , listdir . text <TAB><TAB><TAB>  assert dline [ "" gid "" ] == 0 , listdir . text <TAB><TAB><TAB>  assert dline [ "" name "" ] == name , listdir . text <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  raise AssertionError ( f "" / { path } / { name }  not found "" ) ","if dline [ ""path"" ] == f""{path}/{name}"" :",if dline['type'] == 'DIRECTORY':,False,19.981675318591822,91.46723803108316
1672,"def DeletePlugin ( ) : <TAB>  oid = request . form . get ( "" oid "" , "" "" ) <TAB>  if oid : <TAB><TAB>  result = Mongo . coll [ "" Plugin "" ] . find_one_and_delete ( <TAB><TAB><TAB>  { "" _id "" : ObjectId ( oid ) } , remove = True <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ "" filename "" ] = result [ "" filename "" ] + "" .py "" <TAB><TAB>  if os . path . exists ( file_path + result [ "" filename "" ] ) : <TAB><TAB><TAB>  os . remove ( file_path + result [ "" filename "" ] ) <TAB><TAB><TAB>  return "" success "" <TAB>  return "" fail "" ","if not result [ ""filename"" ] . find ( ""."" ) > - 1 :",if result:,False,21.724796479443196,91.29865607148601
1673,"def iterparent ( self , node ) : <TAB>  """"""Iterator wrapper to get allowed parent and child all at once."""""" <TAB>  # We do not allow the marker inside a header as that <TAB>  # would causes an enless loop of placing a new TOC <TAB>  # inside previously generated TOC. <TAB>  for child in node : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield node , child <TAB><TAB><TAB>  yield from self . iterparent ( child ) ","if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :","if isinstance(child, (str, unicode)):",False,70.88258079323816,79.05700552321002
1674,"def _get_matched_layout ( command ) : <TAB>  # don't use command.split_script here because a layout mismatch will likely <TAB>  # result in a non-splitable script as per shlex <TAB>  cmd = command . script . split ( "" "" ) <TAB>  for source_layout in source_layouts : <TAB><TAB>  is_all_match = True <TAB><TAB>  for cmd_part in cmd : <TAB><TAB><TAB>  if not all ( [ ch in source_layout or ch in "" -_ "" for ch in cmd_part ] ) : <TAB><TAB><TAB><TAB>  is_all_match = False <TAB><TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return source_layout ",if is_all_match :,if is_all_match:,False,41.66255121375918,100.00000000000004
1675,"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB>  for n in tileable_graph : <TAB><TAB>  if n . op in failed_ops : <TAB><TAB><TAB>  continue <TAB><TAB>  tiled_n = get_tiled ( n ) <TAB><TAB>  if has_unknown_shape ( tiled_n ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # some of the chunks has been fused <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  new_nsplits = self . get_tileable_nsplits ( n , chunk_result = chunk_result ) <TAB><TAB><TAB>  for node in ( n , tiled_n ) : <TAB><TAB><TAB><TAB>  node . _update_shape ( tuple ( sum ( nsplit ) for nsplit in new_nsplits ) ) <TAB><TAB><TAB>  tiled_n . _nsplits = new_nsplits ",if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,if tiled_n._shape is None:,False,28.018565439764696,93.11290178499407
1676,"def _get_items ( self , name , target = 1 ) : <TAB>  all_items = self . get_items ( name ) <TAB>  items = [ o for o in all_items if not o . disabled ] <TAB>  if len ( items ) < target : <TAB><TAB>  if len ( all_items ) < target : <TAB><TAB><TAB>  raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB>  on = [ ] <TAB>  off = [ ] <TAB>  for o in items : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  on . append ( o ) <TAB><TAB>  else : <TAB><TAB><TAB>  off . append ( o ) <TAB>  return on , off ",if o . selected :,if o.disabled:,False,57.534882090682615,98.79073721675567
1677,def parse_flow_sequence_entry_mapping_value ( self ) : <TAB>  if self . check_token ( ValueToken ) : <TAB><TAB>  token = self . get_token ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . states . append ( self . parse_flow_sequence_entry_mapping_end ) <TAB><TAB><TAB>  return self . parse_flow_node ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . state = self . parse_flow_sequence_entry_mapping_end <TAB><TAB><TAB>  return self . process_empty_scalar ( token . end_mark ) <TAB>  else : <TAB><TAB>  self . state = self . parse_flow_sequence_entry_mapping_end <TAB><TAB>  token = self . peek_token ( ) <TAB><TAB>  return self . process_empty_scalar ( token . start_mark ) ,"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :",if token.type == ValueToken.NODE:,False,27.19557773087483,94.80898992231894
1678,"def serialize_config ( self , session , key , tid , language ) : <TAB>  cache_key = gen_cache_key ( key , tid , language ) <TAB>  cache_obj = None <TAB>  if cache_key not in self . cache : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cache_obj = db_admin_serialize_node ( session , tid , language ) <TAB><TAB>  elif key == "" notification "" : <TAB><TAB><TAB>  cache_obj = db_get_notification ( session , tid , language ) <TAB><TAB>  self . cache [ cache_key ] = cache_obj <TAB>  return self . cache [ cache_key ] ","if key == ""node"" :","if key == ""node':",False,20.104397245516033,97.868806568568
1679,"def get_lldp_neighbors ( self ) : <TAB>  commands = [ "" show lldp neighbors "" ] <TAB>  output = self . device . run_commands ( commands ) [ 0 ] [ "" lldpNeighbors "" ] <TAB>  lldp = { } <TAB>  for n in output : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lldp [ n [ "" port "" ] ] = [ ] <TAB><TAB>  lldp [ n [ "" port "" ] ] . append ( <TAB><TAB><TAB>  { "" hostname "" : n [ "" neighborDevice "" ] , "" port "" : n [ "" neighborPort "" ] } <TAB><TAB>  ) <TAB>  return lldp ","if n [ ""port"" ] not in lldp . keys ( ) :",if n['port'] not in lldp:,False,33.721540168588334,93.7927575483378
1680,"def handle ( self ) : <TAB>  from poetry . utils . env import EnvManager <TAB>  manager = EnvManager ( self . poetry ) <TAB>  current_env = manager . get ( ) <TAB>  for venv in manager . list ( ) : <TAB><TAB>  name = venv . path . name <TAB><TAB>  if self . option ( "" full-path "" ) : <TAB><TAB><TAB>  name = str ( venv . path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  self . line ( name ) ",if venv == current_env :,if name in current_env:,False,30.082121526457318,97.27738334833546
1681,"def resolve_env_secrets ( config , environ ) : <TAB>  """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB>  if isinstance ( config , dict ) : <TAB><TAB>  if list ( config . keys ( ) ) == [ "" $env "" ] : <TAB><TAB><TAB>  return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  return { <TAB><TAB><TAB><TAB>  key : resolve_env_secrets ( value , environ ) <TAB><TAB><TAB><TAB>  for key , value in config . items ( ) <TAB><TAB><TAB>  } <TAB>  elif isinstance ( config , list ) : <TAB><TAB>  return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB>  else : <TAB><TAB>  return config ","elif list ( config . keys ( ) ) == [ ""$file"" ] :","if isinstance(config, str):",False,33.2451948637494,93.54849195158913
1682,"def _is_valid_16bit_as_path ( cls , buf ) : <TAB>  two_byte_as_size = struct . calcsize ( "" !H "" ) <TAB>  while buf : <TAB><TAB>  ( type_ , num_as ) = struct . unpack_from ( <TAB><TAB><TAB>  cls . _SEG_HDR_PACK_STR , six . binary_type ( buf ) <TAB><TAB>  ) <TAB><TAB>  if type_ is not cls . _AS_SET and type_ is not cls . _AS_SEQUENCE : <TAB><TAB><TAB>  return False <TAB><TAB>  buf = buf [ struct . calcsize ( cls . _SEG_HDR_PACK_STR ) : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  buf = buf [ num_as * two_byte_as_size : ] <TAB>  return True ",if len ( buf ) < num_as * two_byte_as_size :,if num_as * two_byte_as_size == 0:,False,29.006482472557238,96.47531829531029
1683,"def reparentChildren ( self , newParent ) : <TAB>  if newParent . childNodes : <TAB><TAB>  newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newParent . _element . text = "" "" <TAB><TAB>  if self . _element . text is not None : <TAB><TAB><TAB>  newParent . _element . text + = self . _element . text <TAB>  self . _element . text = "" "" <TAB>  base . Node . reparentChildren ( self , newParent ) ",if not newParent . _element . text :,if newParent._element.text is None:,False,26.24148371654325,94.06954609493242
1684,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB>  operation = None <TAB>  for definition in document_ast . definitions : <TAB><TAB>  if isinstance ( definition , ast . OperationDefinition ) : <TAB><TAB><TAB>  if not operation_name : <TAB><TAB><TAB><TAB>  # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB>  # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB>  # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB>  if operation : <TAB><TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB><TAB>  operation = definition <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return definition <TAB>  return operation ",elif definition . name and definition . name . value == operation_name :,if not operation:,False,75.81384526745951,93.44972538380044
1685,"def reprSmart ( vw , item ) : <TAB>  ptype = type ( item ) <TAB>  if ptype is int : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return str ( item ) <TAB><TAB>  elif vw . isValidPointer ( item ) : <TAB><TAB><TAB>  return vw . reprPointer ( item ) <TAB><TAB>  else : <TAB><TAB><TAB>  return hex ( item ) <TAB>  elif ptype in ( list , tuple ) : <TAB><TAB>  return reprComplex ( vw , item )<TAB># recurse <TAB>  elif ptype is dict : <TAB><TAB>  return "" { %s } "" % "" , "" . join ( <TAB><TAB><TAB>  [ "" %s : %s "" % ( reprSmart ( vw , k ) , reprSmart ( vw , v ) ) for k , v in item . items ( ) ] <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return repr ( item ) ",if - 1024 < item < 1024 :,if ptype is float:,False,20.16288584273512,96.1069376300118
1686,"def cleanDataCmd ( cmd ) : <TAB>  newcmd = "" AbracadabrA ** <?php  "" <TAB>  if cmd [ : 6 ] != "" php:// "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cmds = cmd . split ( "" & "" ) <TAB><TAB><TAB>  for c in cmds : <TAB><TAB><TAB><TAB>  if len ( c ) > 0 : <TAB><TAB><TAB><TAB><TAB>  newcmd + = "" system( ' %s ' ); "" % c <TAB><TAB>  else : <TAB><TAB><TAB>  b64cmd = base64 . b64encode ( cmd ) <TAB><TAB><TAB>  newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB>  else : <TAB><TAB>  newcmd + = cmd [ 6 : ] <TAB>  newcmd + = "" ?> ** "" <TAB>  return newcmd ",if reverseConn not in cmd :,if cmd.startswith('&'):,False,27.92598242879074,92.73808559589571
1687,"def render_tasks ( self ) - > List : <TAB>  results = [ ] <TAB>  for task in self . tasks . values ( ) : <TAB><TAB>  job_entry = self . jobs . get ( task . job_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not self . should_render_job ( job_entry ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  files = self . get_file_counts ( [ task ] ) <TAB><TAB>  entry = ( <TAB><TAB><TAB>  task . job_id , <TAB><TAB><TAB>  task . task_id , <TAB><TAB><TAB>  task . state , <TAB><TAB><TAB>  task . type . name , <TAB><TAB><TAB>  task . target , <TAB><TAB><TAB>  files , <TAB><TAB><TAB>  task . pool , <TAB><TAB><TAB>  task . end_time , <TAB><TAB>  ) <TAB><TAB>  results . append ( entry ) <TAB>  return results ",if job_entry :,if job_entry:,False,50.17413986683299,100.00000000000004
1688,"def __call__ ( self , environ , start_response ) : <TAB>  for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB><TAB>  if key not in environ : <TAB><TAB><TAB>  continue <TAB><TAB>  request_uri = unquote ( environ [ key ] ) <TAB><TAB>  script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB><TAB><TAB>  break <TAB>  return self . app ( environ , start_response ) ",if request_uri . startswith ( script_name ) :,if script_name and (not self.app_path_info(environ.get(',False,28.754381499194633,90.63823095368815
1689,"def _add_role_information ( self , function_dict , role_id ) : <TAB>  # Make it easier to build rules based on policies attached to execution roles <TAB>  function_dict [ "" role_arn "" ] = role_id <TAB>  role_name = role_id . split ( "" / "" ) [ - 1 ] <TAB>  function_dict [ <TAB><TAB>  "" execution_role "" <TAB>  ] = await self . facade . awslambda . get_role_with_managed_policies ( role_name ) <TAB>  if function_dict . get ( "" execution_role "" ) : <TAB><TAB>  statements = [ ] <TAB><TAB>  for policy in function_dict [ "" execution_role "" ] . get ( "" policies "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  statements + = policy [ "" Document "" ] [ "" Statement "" ] <TAB><TAB>  function_dict [ "" execution_role "" ] [ "" policy_statements "" ] = statements ","if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :",if policy['Document']['Type'] == 'Document':,False,35.56672235647618,92.29871312362943
1690,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 8 : <TAB><TAB><TAB>  self . set_ts ( d . getVarInt64 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 0:,False,51.452429171598,100.00000000000004
1691,"def format_counts ( results , json_output = False , human_readable = False ) : <TAB>  if json_output : <TAB><TAB>  for result in results : <TAB><TAB><TAB>  yield json . dumps ( result ) <TAB>  else : <TAB><TAB>  for result in results : <TAB><TAB><TAB>  space_consumed = result . get ( "" spaceConsumed "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  space_consumed = _sizeof_fmt ( int ( result . get ( "" spaceConsumed "" ) ) ) <TAB><TAB><TAB>  yield "" %12s %12s %18s %s "" % ( <TAB><TAB><TAB><TAB>  result . get ( "" directoryCount "" ) , <TAB><TAB><TAB><TAB>  result . get ( "" fileCount "" ) , <TAB><TAB><TAB><TAB>  space_consumed , <TAB><TAB><TAB><TAB>  result . get ( "" path "" ) , <TAB><TAB><TAB>  ) ",if human_readable :,if space_consumed is None:,False,44.428554977879585,97.50050516118901
1692,"def parse_edges ( self , pcb ) : <TAB>  edges = [ ] <TAB>  drawings = list ( pcb . GetDrawings ( ) ) <TAB>  bbox = None <TAB>  for m in pcb . GetModules ( ) : <TAB><TAB>  for g in m . GraphicalItems ( ) : <TAB><TAB><TAB>  drawings . append ( g ) <TAB>  for d in drawings : <TAB><TAB>  if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB><TAB><TAB>  parsed_drawing = self . parse_drawing ( d ) <TAB><TAB><TAB>  if parsed_drawing : <TAB><TAB><TAB><TAB>  edges . append ( parsed_drawing ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  bbox = d . GetBoundingBox ( ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  bbox . Merge ( d . GetBoundingBox ( ) ) <TAB>  if bbox : <TAB><TAB>  bbox . Normalize ( ) <TAB>  return edges , bbox ",if bbox is None :,if bbox is None:,False,50.963311909055356,100.00000000000004
1693,"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB>  if isinstance ( k , slice ) : <TAB><TAB>  if k . step is not None : <TAB><TAB><TAB>  raise ValueError ( "" Slices with strides are not supported "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Must specify start index "" ) <TAB><TAB>  elif k . stop is not None : <TAB><TAB><TAB>  raise ValueError ( "" Slices with stop index are not supported "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  addr = k . start <TAB>  elif self . _type is not None and self . _type . _can_refine_int : <TAB><TAB>  return self . _type . _refine ( self , k ) <TAB>  else : <TAB><TAB>  addr = k <TAB>  return self . _deeper ( addr = addr ) ",elif k . start is None :,if k.start is None:,False,56.93151659240441,98.8674372687216
1694,"def _parse ( self , stream , context ) : <TAB>  obj = [ ] <TAB>  try : <TAB><TAB>  if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  subobj = self . subcon . _parse ( stream , context . __copy__ ( ) ) <TAB><TAB><TAB><TAB>  obj . append ( subobj ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  subobj = self . subcon . _parse ( stream , context ) <TAB><TAB><TAB><TAB>  obj . append ( subobj ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB>  except ConstructError as ex : <TAB><TAB>  raise ArrayError ( "" missing terminator "" , ex ) <TAB>  return obj ","if self . predicate ( subobj , context ) :",if subobj is None:,False,34.571178377012004,92.71264818856166
1695,"def before_run ( self , run_context ) : <TAB>  if "" featurizer "" in self . model_portion and ( <TAB><TAB>  self . need_to_refresh or self . refresh_base_model <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . refresh_base_model = True <TAB><TAB>  self . init_fn ( <TAB><TAB><TAB>  None , run_context . session , self . model_portion , self . refresh_base_model <TAB><TAB>  ) <TAB><TAB>  self . need_to_refresh = False <TAB><TAB>  self . refresh_base_model = False ","if self . model_portion == ""whole_featurizer"" :",if self.refresh_base_model:,False,47.15912171838673,93.5846156366608
1696,"def run ( self ) : <TAB>  while True : <TAB><TAB>  task = self . requestQueue . get ( ) <TAB><TAB>  if task is None : <TAB><TAB><TAB>  # The ""None"" value is used as a sentinel by <TAB><TAB><TAB>  # ThreadPool.cleanup().  This indicates that there <TAB><TAB><TAB>  # are no more tasks, so we should quit. <TAB><TAB><TAB>  break <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise SCons . Errors . BuildError ( task . targets [ 0 ] , errstr = interrupt_msg ) <TAB><TAB><TAB>  task . execute ( ) <TAB><TAB>  except : <TAB><TAB><TAB>  task . exception_set ( ) <TAB><TAB><TAB>  ok = False <TAB><TAB>  else : <TAB><TAB><TAB>  ok = True <TAB><TAB>  self . resultsQueue . put ( ( task , ok ) ) ",if self . interrupted ( ) :,if task.targets:,False,64.12373963990802,97.51203239352351
1697,"def get_overdue_evergreen_documents ( * , db_session ) - > List [ Optional [ Document ] ] : <TAB>  """"""Returns all documents that have need had a recent evergreen notification."""""" <TAB>  documents = ( <TAB><TAB>  db_session . query ( Document ) . filter ( Document . evergreen == True ) <TAB>  ) . all ( )<TAB># noqa <TAB>  overdue_documents = [ ] <TAB>  now = datetime . utcnow ( ) <TAB>  for d in documents : <TAB><TAB>  next_reminder = d . evergreen_last_reminder_at + timedelta ( <TAB><TAB><TAB>  days = d . evergreen_reminder_interval <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  overdue_documents . append ( d ) <TAB>  return overdue_documents ",if now > next_reminder :,if next_reminder <= now:,False,38.55717238322406,94.95372190817743
1698,"def create_local_app_folder ( local_app_path ) : <TAB>  if exists ( local_app_path ) : <TAB><TAB>  raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB>  for folder in subfolders ( local_app_path ) : <TAB><TAB>  if not exists ( folder ) : <TAB><TAB><TAB>  os . mkdir ( folder ) <TAB><TAB><TAB>  init_path = join ( folder , "" __init__.py "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  create_file ( init_path ) ",if not exists ( init_path ) :,if not exists(init_path):,False,52.27295288767988,97.87810430466244
1699,"def generate ( ) : <TAB>  for leaf in u . leaves : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = leaf . get_int_value ( ) <TAB><TAB><TAB>  if val in ( 0 , 1 ) : <TAB><TAB><TAB><TAB>  yield val <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise _NoBoolVector <TAB><TAB>  elif isinstance ( leaf , Symbol ) : <TAB><TAB><TAB>  if leaf == SymbolTrue : <TAB><TAB><TAB><TAB>  yield 1 <TAB><TAB><TAB>  elif leaf == SymbolFalse : <TAB><TAB><TAB><TAB>  yield 0 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise _NoBoolVector <TAB><TAB>  else : <TAB><TAB><TAB>  raise _NoBoolVector ","if isinstance ( leaf , Integer ) :","if isinstance(leaf, int):",False,51.14140332162063,98.87760724645923
1700,"def replace ( self , old , new ) : <TAB>  v_m = self . var_map <TAB>  size = v_m [ self . size ] <TAB>  if not ( size . is_const ( ) or size . is_ident ( ) ) : <TAB><TAB>  size . replace ( old , new ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v_m [ new . value ( ) ] = new <TAB><TAB><TAB>  self . size = new . value ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  v_m [ old ] = new ",if new . is_ident ( ) :,if new.value() != old:,False,48.32985515452158,95.64182163295612
1701,"def method_for_doctype ( doctype ) : <TAB>  method = "" xhtml "" <TAB>  if doctype : <TAB><TAB>  if doctype . startswith ( "" html "" ) : <TAB><TAB><TAB>  method = "" html "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  method = "" xhtml "" <TAB><TAB>  elif doctype . startswith ( "" svg "" ) : <TAB><TAB><TAB>  method = "" xml "" <TAB><TAB>  else : <TAB><TAB><TAB>  method = "" xhtml "" <TAB>  return method ","elif doctype . startswith ( ""xhtml"" ) :",if doctype.startswith('html'):,False,30.23045232705222,94.95973100148939
1702,"def delete ( self , trans , * * kwd ) : <TAB>  idnum = kwd [ self . tagged_item_id ] <TAB>  item = self . _get_item_from_id ( trans , idnum , check_writable = True ) <TAB>  if item is not None : <TAB><TAB>  ex_obj = self . get_item_extended_metadata_obj ( trans , item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . unset_item_extended_metadata_obj ( trans , item ) <TAB><TAB><TAB>  self . delete_extended_metadata ( trans , ex_obj ) ",if ex_obj is not None :,if ex_obj is not None:,False,50.62598495583019,100.00000000000004
1703,"def check_testv ( self , testv ) : <TAB>  test_good = True <TAB>  f = open ( self . home , "" rb+ "" ) <TAB>  for ( offset , length , operator , specimen ) in testv : <TAB><TAB>  data = self . _read_share_data ( f , offset , length ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  test_good = False <TAB><TAB><TAB>  break <TAB>  f . close ( ) <TAB>  return test_good ","if not testv_compare ( data , operator , specimen ) :",if data == 0:,False,32.92378795393244,90.44257759835064
1704,"def get_history_user ( self , instance ) : <TAB>  """"""Get the modifying user from instance or middleware."""""" <TAB>  try : <TAB><TAB>  return instance . _history_user <TAB>  except AttributeError : <TAB><TAB>  request = None <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  request = self . thread . request <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  pass <TAB>  return self . get_user ( instance = instance , request = request ) ",if self . thread . request . user . is_authenticated :,"if hasattr(self.thread, 'request'):",False,52.27523187497086,92.51726136232426
1705,"def _check ( self , name , size = None , * extra ) : <TAB>  func = getattr ( imageop , name ) <TAB>  for height in VALUES : <TAB><TAB>  for width in VALUES : <TAB><TAB><TAB>  strlen = abs ( width * height ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  strlen * = size <TAB><TAB><TAB>  if strlen < MAX_LEN : <TAB><TAB><TAB><TAB>  data = "" A "" * strlen <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  data = AAAAA <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  arguments = ( data , size , width , height ) + extra <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  arguments = ( data , width , height ) + extra <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  func ( * arguments ) <TAB><TAB><TAB>  except ( ValueError , imageop . error ) : <TAB><TAB><TAB><TAB>  pass ",if size :,if size is not None:,False,25.588434345612114,96.83012585947415
1706,"def __setattr__ ( self , name , value ) : <TAB>  if name == "" path "" : <TAB><TAB>  if value and value != "" "" : <TAB><TAB><TAB>  if value [ 0 ] != "" / "" : <TAB><TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB><TAB>  ' The page path should always start with a slash ( "" / "" ). ' <TAB><TAB><TAB><TAB>  ) <TAB>  elif name == "" load_time "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Page load time must be specified in integer milliseconds. "" <TAB><TAB><TAB>  ) <TAB>  object . __setattr__ ( self , name , value ) ","if value and not isinstance ( value , int ) :",if value and value < 0:,False,36.059490081156184,94.87826650479029
1707,"def __repr__ ( self ) : <TAB>  if self . _in_repr : <TAB><TAB>  return "" <recursion> "" <TAB>  try : <TAB><TAB>  self . _in_repr = True <TAB><TAB>  if self . is_computed ( ) : <TAB><TAB><TAB>  status = "" computed,  "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if self . value ( ) is self : <TAB><TAB><TAB><TAB><TAB>  status + = "" = self "" <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  status + = "" =  "" + repr ( self . value ( ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  status + = "" error =  "" + repr ( self . error ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  status = "" isn ' t computed "" <TAB><TAB>  return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB>  finally : <TAB><TAB>  self . _in_repr = False ",if self . error ( ) is None :,if self.is_value():,False,51.33859594724708,96.56968126814506
1708,"def _exclude_node ( self , name ) : <TAB>  if "" exclude_nodes "" in self . node_filters : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . loggit . info ( ' Excluding node  "" {0} ""  due to node_filters ' . format ( name ) ) <TAB><TAB><TAB>  return True <TAB>  return False ","if name in self . node_filters [ ""exclude_nodes"" ] :",if name in self.exclude_nodes:,False,22.677400902298796,84.9684997850254
1709,"def enumerate_projects ( ) : <TAB>  """"""List projects in _DEFAULT_APP_DIR."""""" <TAB>  src_path = os . path . join ( _DEFAULT_APP_DIR , "" src "" ) <TAB>  projects = { } <TAB>  for project in os . listdir ( src_path ) : <TAB><TAB>  projects [ project ] = [ ] <TAB><TAB>  project_path = os . path . join ( src_path , project ) <TAB><TAB>  for file in os . listdir ( project_path ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  projects [ project ] . append ( file [ : - 8 ] ) <TAB>  return projects ","if file . endswith ( "".gwt.xml"" ) :",if file.endswith('.py') and file.endswith('.py') and,False,22.07515534550809,89.96909034714828
1710,"def zip_readline_read_test ( self , f , compression ) : <TAB>  self . make_test_archive ( f , compression ) <TAB>  # Read the ZIP archive <TAB>  with zipfile . ZipFile ( f , "" r "" ) as zipfp , zipfp . open ( TESTFN ) as zipopen : <TAB><TAB>  data = b "" "" <TAB><TAB>  while True : <TAB><TAB><TAB>  read = zipopen . readline ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  data + = read <TAB><TAB><TAB>  read = zipopen . read ( 100 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  data + = read <TAB>  self . assertEqual ( data , self . data ) ",if not read :,if not read:,False,51.37885166255586,97.82680988754501
1711,"def f ( view , s ) : <TAB>  if mode == modes . NORMAL : <TAB><TAB>  return sublime . Region ( 0 ) <TAB>  elif mode == modes . VISUAL : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return sublime . Region ( s . a + 1 , 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  return sublime . Region ( s . a , 0 ) <TAB>  elif mode == modes . INTERNAL_NORMAL : <TAB><TAB>  return sublime . Region ( view . full_line ( s . b ) . b , 0 ) <TAB>  elif mode == modes . VISUAL_LINE : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return sublime . Region ( 0 , s . b ) <TAB><TAB>  else : <TAB><TAB><TAB>  return sublime . Region ( 0 , s . a ) <TAB>  return s ",if s . a < s . b :,if mode == modes.NORMAL:,False,23.12456642016283,92.24097125534519
1712,def response ( self ) : <TAB>  try : <TAB><TAB>  response = requests . get ( str ( self ) ) <TAB><TAB>  rjson = response . json ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( response . text ) <TAB><TAB>  return rjson <TAB>  except Exception as e : <TAB><TAB>  raise ResponseFanartError ( str ( e ) ) ,"if not isinstance ( rjson , dict ) :",if rjson['status_code'] != 200:,False,21.165441056300853,89.97013409160829
1713,"def __get_type ( self , cexpr ) : <TAB>  """"""Returns one of the following types: 'R' - read value, 'W' - write value, 'A' - function argument"""""" <TAB>  child = cexpr <TAB>  for p in reversed ( self . parents ) : <TAB><TAB>  assert p , "" Failed to get type at  "" + helper . to_hex ( self . __function_address ) <TAB><TAB>  if p . cexpr . op == idaapi . cot_call : <TAB><TAB><TAB>  return "" Arg "" <TAB><TAB>  if not p . is_expr ( ) : <TAB><TAB><TAB>  return "" R "" <TAB><TAB>  if p . cexpr . op == idaapi . cot_asg : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return "" W "" <TAB><TAB><TAB>  return "" R "" <TAB><TAB>  child = p . cexpr ",if p . cexpr . x == child :,if p.is_op:,False,58.84210320082235,96.7566139839759
1714,"def _extract_lemma ( self , parse : Parse ) - > str : <TAB>  special_feats = [ x for x in self . SPECIAL_FEATURES if x in parse . tag ] <TAB>  if len ( special_feats ) == 0 : <TAB><TAB>  return parse . normal_form <TAB>  # here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly <TAB>  for other in parse . lexeme : <TAB><TAB>  tag = other . tag <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if ( <TAB><TAB><TAB>  tag . case == "" nomn "" <TAB><TAB><TAB>  and tag . gender == parse . tag . gender <TAB><TAB><TAB>  and tag . number == "" sing "" <TAB><TAB>  ) : <TAB><TAB><TAB>  return other . word <TAB>  return parse . normal_form ",if any ( x not in tag for x in special_feats ) :,if tag.case == 'lemma':,False,56.93194903039376,93.61989137942426
1715,"def evaluateWord ( self , argument ) : <TAB>  wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB>  if wildcard_count > 0 : <TAB><TAB>  if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB><TAB><TAB>  return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB><TAB><TAB>  matched = False <TAB><TAB><TAB>  for w in self . words : <TAB><TAB><TAB><TAB>  matched = bool ( re . search ( _regex , w ) ) <TAB><TAB><TAB><TAB>  if matched : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  return matched <TAB>  return self . GetWord ( argument [ 0 ] ) ","if wildcard_count == 1 and argument [ 0 ] . endswith ( ""*"" ) :",if wildcard_count == 0:,False,48.78466270776669,94.23916814549047
1716,def getAllEntries ( self ) : <TAB>  entries = [ ] <TAB>  for bucket in self . buckets : <TAB><TAB>  last = None <TAB><TAB>  for entry in bucket . entries : <TAB><TAB><TAB>  if last is not None : <TAB><TAB><TAB><TAB>  last . size = entry . virtualOffset - last . virtualOffset <TAB><TAB><TAB>  last = entry <TAB><TAB><TAB>  entries . append ( entry ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  entries [ - 1 ] . size = bucket . endOffset - entries [ - 1 ] . virtualOffset <TAB>  return entries ,if len ( entries ) != 0 :,if entries[-1].size > 0:,False,32.77245821127155,91.71262470941387
1717,def clean ( self ) : <TAB>  if self . _ctx : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  libcrypto . EVP_CIPHER_CTX_cleanup ( self . _ctx ) <TAB><TAB>  else : <TAB><TAB><TAB>  libcrypto . EVP_CIPHER_CTX_reset ( self . _ctx ) <TAB><TAB>  libcrypto . EVP_CIPHER_CTX_free ( self . _ctx ) ,"if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :",if self._ctx.type == libcrypto.EVP_CIPHER_CTX,False,17.685475484045845,88.82048820062077
1718,"def _addTab ( self , name , label , idx = None ) : <TAB>  label = getLanguageString ( label ) <TAB>  tab = Tab ( self , name , label ) <TAB>  tab . idx = self . _makeTab ( tab , idx ) <TAB>  if idx != None : <TAB><TAB>  # Update index list when inserting tabs at arbitrary positions <TAB><TAB>  newIdxList = { } <TAB><TAB>  for tIdx , t in list ( self . _tabs_by_idx . items ( ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  t . idx + = 1 <TAB><TAB><TAB>  newIdxList [ t . idx ] = t <TAB><TAB>  self . _tabs_by_idx = newIdxList <TAB>  self . _tabs_by_idx [ tab . idx ] = tab <TAB>  self . _tabs_by_name [ tab . name ] = tab <TAB>  return tab ",if int ( tIdx ) >= idx :,if tIdx == idx:,False,56.753726787821805,97.19797513821803
1719,"def set ( self , _key , _new_login = True ) : <TAB>  with self . lock : <TAB><TAB>  user = self . users . get ( current_user . id , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB><TAB>  else : <TAB><TAB><TAB>  if _new_login : <TAB><TAB><TAB><TAB>  user [ "" session_count "" ] + = 1 <TAB><TAB><TAB>  user [ "" key "" ] = _key ",if user is None :,if user is None:,False,47.82237360518275,100.00000000000004
1720,"def stop ( self ) : <TAB>  # Try to shut the connection down, but if we get any sort of <TAB>  # errors, go ahead and ignore them.. as we're shutting down anyway <TAB>  try : <TAB><TAB>  self . rpcserver . stop ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . backend_rpcserver . stop ( ) <TAB><TAB>  if self . cluster_rpcserver : <TAB><TAB><TAB>  self . cluster_rpcserver . stop ( ) <TAB>  except Exception : <TAB><TAB>  pass <TAB>  if self . coordination : <TAB><TAB>  try : <TAB><TAB><TAB>  coordination . COORDINATOR . stop ( ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  pass <TAB>  super ( Service , self ) . stop ( graceful = True ) ",if self . backend_rpcserver :,if self.backend_rpcserver:,False,45.41329588701359,100.00000000000004
1721,"def __genmenuOnlyAllocated ( menu ) : <TAB>  for submenu in menu . Submenus : <TAB><TAB>  __genmenuOnlyAllocated ( submenu ) <TAB>  if menu . OnlyUnallocated == True : <TAB><TAB>  tmp [ "" cache "" ] . addMenuEntries ( menu . AppDirs ) <TAB><TAB>  menuentries = [ ] <TAB><TAB>  for rule in menu . Rules : <TAB><TAB><TAB>  menuentries = rule . do ( <TAB><TAB><TAB><TAB>  tmp [ "" cache "" ] . getMenuEntries ( menu . AppDirs ) , rule . Type , 2 <TAB><TAB><TAB>  ) <TAB><TAB>  for menuentry in menuentries : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  menuentry . Parents . append ( menu ) <TAB><TAB><TAB><TAB>  #   menuentry.Add = False <TAB><TAB><TAB><TAB>  #   menuentry.Allocated = True <TAB><TAB><TAB><TAB>  menu . MenuEntries . append ( menuentry ) ",if menuentry . Add == True :,if menuentry.Add:,False,49.27175870236038,98.13337205976185
1722,"def __init__ ( self , * * options ) : <TAB>  self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB>  self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB>  self . _functions = set ( ) <TAB>  if self . func_name_highlighting : <TAB><TAB>  from pygments . lexers . _lua_builtins import MODULES <TAB><TAB>  for mod , func in iteritems ( MODULES ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _functions . update ( func ) <TAB>  RegexLexer . __init__ ( self , * * options ) ",if mod not in self . disabled_modules :,if mod in self._functions:,False,19.29978361016112,96.24348983986467
1723,"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB>  if tr < 1 : <TAB><TAB>  tr = 1 <TAB>  x = time . time ( ) + t <TAB>  y = [ ] <TAB>  r = "" "" <TAB>  if stderr : <TAB><TAB>  pr = p . recv_err <TAB>  else : <TAB><TAB>  pr = p . recv <TAB>  while time . time ( ) < x or r : <TAB><TAB>  r = pr ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  elif r : <TAB><TAB><TAB>  y . append ( r ) <TAB><TAB>  else : <TAB><TAB><TAB>  time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB>  return "" "" . join ( y ) ",if r is None :,if r == e:,False,27.97980029110807,97.95519354525233
1724,"def get_menu_items ( node ) : <TAB>  aList = [ ] <TAB>  for child in node . children : <TAB><TAB>  for tag in ( "" @menu "" , "" @item "" ) : <TAB><TAB><TAB>  if child . h . startswith ( tag ) : <TAB><TAB><TAB><TAB>  name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  aList . append ( ( "" %s %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  b = g . splitLines ( "" "" . join ( child . b ) ) <TAB><TAB><TAB><TAB><TAB>  aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB><TAB><TAB><TAB>  break <TAB>  return aList ","if tag == ""@menu"" :","if name not in ('@menu', '@item'):",False,38.23340390392341,94.9863733260773
1725,"def import_suffix_generator ( a_block , datatype = False ) : <TAB>  if datatype is False : <TAB><TAB>  for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield name , suffix <TAB>  else : <TAB><TAB>  for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB><TAB><TAB>  if ( suffix . import_enabled ( ) is True ) and ( <TAB><TAB><TAB><TAB>  suffix . get_datatype ( ) is datatype <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  yield name , suffix ",if suffix . import_enabled ( ) is True :,if suffix.import_enabled() is True:,False,51.143864903556526,100.00000000000004
1726,"def verify_relative_valid_path ( root , path ) : <TAB>  if len ( path ) < 1 : <TAB><TAB>  raise PackagerError ( "" Empty chown path "" ) <TAB>  checkpath = root <TAB>  parts = path . split ( os . sep ) <TAB>  for part in parts : <TAB><TAB>  if part in ( "" . "" , "" .. "" ) : <TAB><TAB><TAB>  raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB><TAB>  checkpath = os . path . join ( checkpath , part ) <TAB><TAB>  relpath = checkpath [ len ( root ) + 1 : ] <TAB><TAB>  if not os . path . exists ( checkpath ) : <TAB><TAB><TAB>  raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise PackagerError ( f "" chown path  { relpath }  is a soft link "" ) ",if os . path . islink ( checkpath ) :,if relpath != root:,False,36.71337099683678,95.83494266173875
1727,"def load_syntax ( syntax ) : <TAB>  context = _create_scheme ( ) or { } <TAB>  partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB>  scanners = { } <TAB>  for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB><TAB>  scanners [ part_name ] = Scanner ( part_scanner ) <TAB>  formats = [ ] <TAB>  for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if fstyle . startswith ( "" % ( "" ) and fstyle . endswith ( "" )s "" ) : <TAB><TAB><TAB><TAB>  key = fstyle [ 2 : - 2 ] <TAB><TAB><TAB><TAB>  fstyle = context [ key ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  fstyle = fstyle % context <TAB><TAB>  formats . append ( ( fname , fstyle ) ) <TAB>  return partition_scanner , scanners , formats ","if isinstance ( fstyle , basestring ) :",if fstyle.startswith('%s'):,False,27.94110332947548,95.76905881082308
1728,"def should_keep_alive ( commit_msg ) : <TAB>  result = False <TAB>  ci = get_current_ci ( ) or "" "" <TAB>  for line in commit_msg . splitlines ( ) : <TAB><TAB>  parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB><TAB>  ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ci_names = val . replace ( "" , "" , "" "" ) . lower ( ) . split ( ) if val else [ ] <TAB><TAB><TAB>  if len ( ci_names ) == 0 or ci . lower ( ) in ci_names : <TAB><TAB><TAB><TAB>  result = True <TAB>  return result ","if key == ""CI_KEEP_ALIVE"" :",if key == ci:,False,25.127111177809592,95.83809057281137
1729,"def get_note_title_file ( note ) : <TAB>  mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB>  if mo : <TAB><TAB>  fn = mo . groups ( ) [ 0 ] <TAB><TAB>  fn = fn . replace ( "" "" , "" _ "" ) <TAB><TAB>  fn = fn . replace ( "" / "" , "" _ "" ) <TAB><TAB>  if not fn : <TAB><TAB><TAB>  return "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fn = unicode ( fn , "" utf-8 "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  fn = unicode ( fn ) <TAB><TAB>  if note_markdown ( note ) : <TAB><TAB><TAB>  fn + = "" .mkdn "" <TAB><TAB>  else : <TAB><TAB><TAB>  fn + = "" .txt "" <TAB><TAB>  return fn <TAB>  else : <TAB><TAB>  return "" "" ","if isinstance ( fn , str ) :","if isinstance(fn, unicode):",False,50.336932312300796,98.99895766450993
1730,"def post ( self , orgname , teamname ) : <TAB>  if _syncing_setup_allowed ( orgname ) : <TAB><TAB>  try : <TAB><TAB><TAB>  team = model . team . get_organization_team ( orgname , teamname ) <TAB><TAB>  except model . InvalidTeamException : <TAB><TAB><TAB>  raise NotFound ( ) <TAB><TAB>  config = request . get_json ( ) <TAB><TAB>  # Ensure that the specified config points to a valid group. <TAB><TAB>  status , err = authentication . check_group_lookup_args ( config ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise InvalidRequest ( "" Could not sync to group:  %s "" % err ) <TAB><TAB>  # Set the team's syncing config. <TAB><TAB>  model . team . set_team_syncing ( team , authentication . federated_service , config ) <TAB><TAB>  return team_view ( orgname , team ) <TAB>  raise Unauthorized ( ) ",if not status :,if status != model.SUCCESS:,False,60.27568288325982,96.90315344077845
1731,"def _marshalData ( self ) : <TAB>  if self . _cache == None : <TAB><TAB>  d = self . _data <TAB><TAB>  s = "" "" <TAB><TAB>  s = time . strftime ( "" % H: % M: % S "" , ( 0 , 0 , 0 ) + d + ( 0 , 0 , - 1 ) ) <TAB><TAB>  f = d [ 2 ] - int ( d [ 2 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s + = ( "" %g "" % f ) [ 1 : ] <TAB><TAB>  s + = "" Z "" <TAB><TAB>  self . _cache = s <TAB>  return self . _cache ",if f != 0 :,if f > 0:,False,41.74173271044101,96.4207434613648
1732,"def _get_level ( levels , level_ref ) : <TAB>  if level_ref in levels : <TAB><TAB>  return levels . index ( level_ref ) <TAB>  if isinstance ( level_ref , six . integer_types ) : <TAB><TAB>  if level_ref < 0 : <TAB><TAB><TAB>  level_ref + = len ( levels ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB><TAB>  return level_ref <TAB>  raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) ) ",if not ( 0 <= level_ref < len ( levels ) ) :,if level_ref > 0:,False,27.91801387035328,91.7232572649801
1733,"def iterfieldselect ( source , field , where , complement , missing ) : <TAB>  it = iter ( source ) <TAB>  hdr = next ( it ) <TAB>  yield tuple ( hdr ) <TAB>  indices = asindices ( hdr , field ) <TAB>  getv = operator . itemgetter ( * indices ) <TAB>  for row in it : <TAB><TAB>  try : <TAB><TAB><TAB>  v = getv ( row ) <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  v = missing <TAB><TAB>  <IF-STMT>:<TAB># XOR <TAB><TAB><TAB>  yield tuple ( row ) ",if bool ( where ( v ) ) != complement :,if v == where:,False,37.19035766346569,92.17174071642803
1734,"def _test_wait_read_invalid_switch ( self , sleep ) : <TAB>  sock1 , sock2 = socket . socketpair ( ) <TAB>  try : <TAB><TAB>  p = gevent . spawn ( <TAB><TAB><TAB>  util . wrap_errors ( <TAB><TAB><TAB><TAB>  AssertionError , socket . wait_read <TAB><TAB><TAB>  ) ,<TAB># pylint:disable=no-member <TAB><TAB><TAB>  sock1 . fileno ( ) , <TAB><TAB>  ) <TAB><TAB>  gevent . get_hub ( ) . loop . run_callback ( switch_None , p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gevent . sleep ( sleep ) <TAB><TAB>  result = p . get ( ) <TAB><TAB>  assert isinstance ( result , AssertionError ) , result <TAB><TAB>  assert "" Invalid switch "" in str ( result ) , repr ( str ( result ) ) <TAB>  finally : <TAB><TAB>  sock1 . close ( ) <TAB><TAB>  sock2 . close ( ) ",if sleep is not None :,if sleep:,False,20.64579334572866,97.5869104108202
1735,"def train ( config , args ) : <TAB>  gan = setup_gan ( config , inputs , args ) <TAB>  test_batches = [ ] <TAB>  for i in range ( args . steps ) : <TAB><TAB>  gan . step ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  correct_prediction = 0 <TAB><TAB><TAB>  total = 0 <TAB><TAB><TAB>  for ( x , y ) in gan . inputs . testdata ( ) : <TAB><TAB><TAB><TAB>  prediction = gan . generator ( x ) <TAB><TAB><TAB><TAB>  correct_prediction + = ( <TAB><TAB><TAB><TAB><TAB>  torch . argmax ( prediction , 1 ) == torch . argmax ( y , 1 ) <TAB><TAB><TAB><TAB>  ) . sum ( ) <TAB><TAB><TAB><TAB>  total + = y . shape [ 0 ] <TAB><TAB><TAB>  accuracy = ( float ( correct_prediction ) / total ) * 100 <TAB><TAB><TAB>  print ( "" accuracy:  "" , accuracy ) <TAB>  return sum_metrics ",if i % args . sample_every == 0 and i > 0 :,if gan.inputs.testdata():,False,34.743126560798224,94.60030182847954
1736,"def process_response ( self , request , response , spider ) : <TAB>  if not response . body : <TAB><TAB>  return response <TAB>  for fmt , func in six . iteritems ( self . _formats ) : <TAB><TAB>  new_response = func ( response ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( <TAB><TAB><TAB><TAB>  "" Decompressed response with format:  %(responsefmt)s "" , <TAB><TAB><TAB><TAB>  { "" responsefmt "" : fmt } , <TAB><TAB><TAB><TAB>  extra = { "" spider "" : spider } , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return new_response <TAB>  return response ",if new_response :,if new_response is not None:,False,37.123355648651824,97.54188262591686
1737,"def detect_ssl_option ( self ) : <TAB>  for option in self . ssl_options ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for other_option in self . ssl_options ( ) : <TAB><TAB><TAB><TAB>  if option != other_option : <TAB><TAB><TAB><TAB><TAB>  if scan_argv ( self . argv , other_option ) is not None : <TAB><TAB><TAB><TAB><TAB><TAB>  raise ConfigurationError ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return option ","if scan_argv ( self . argv , option ) is not None :",if option.is_ssl_option(option):,False,28.803130796101073,93.8315097110255
1738,"def load ( cls , storefile , template_store ) : <TAB>  # Did we get file or filename? <TAB>  if not hasattr ( storefile , "" read "" ) : <TAB><TAB>  storefile = open ( storefile , "" rb "" ) <TAB>  # Adjust store to have translations <TAB>  store = cls . convertfile ( storefile , template_store ) <TAB>  for unit in store . units : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # HTML does this properly on loading, others need it <TAB><TAB>  if cls . needs_target_sync : <TAB><TAB><TAB>  unit . target = unit . source <TAB><TAB><TAB>  unit . rich_target = unit . rich_source <TAB>  return store ",if unit . isheader ( ) :,if unit.source == 'html':,False,36.680284721940914,96.98038122635303
1739,"def _pre_get_table ( self , _ctx , table_name ) : <TAB>  vsctl_table = self . _get_table ( table_name ) <TAB>  schema_helper = self . schema_helper <TAB>  schema_helper . register_table ( vsctl_table . table_name ) <TAB>  for row_id in vsctl_table . row_ids : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  schema_helper . register_table ( row_id . table ) <TAB><TAB>  if row_id . name_column : <TAB><TAB><TAB>  schema_helper . register_columns ( row_id . table , [ row_id . name_column ] ) <TAB><TAB>  if row_id . uuid_column : <TAB><TAB><TAB>  schema_helper . register_columns ( row_id . table , [ row_id . uuid_column ] ) <TAB>  return vsctl_table ",if row_id . table :,if row_id.table:,False,51.02517200921345,100.00000000000004
1740,"def __init__ ( self , pin = None , pull_up = False ) : <TAB>  super ( InputDevice , self ) . __init__ ( pin ) <TAB>  try : <TAB><TAB>  self . pin . function = "" input "" <TAB><TAB>  pull = "" up "" if pull_up else "" down "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . pin . pull = pull <TAB>  except : <TAB><TAB>  self . close ( ) <TAB><TAB>  raise <TAB>  self . _active_state = False if pull_up else True <TAB>  self . _inactive_state = True if pull_up else False ",if self . pin . pull != pull :,if pull:,False,47.65452872932817,94.77427657208653
1741,"def _increment_operations_count ( self , operation , executed ) : <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _executed_operations + = 1 <TAB><TAB><TAB>  self . _executed [ operation . job_type ] + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  self . _skipped [ operation . job_type ] + = 1 ",if executed :,if executed:,False,20.861780871468248,100.00000000000004
1742,"def emit ( self , type , info = None ) : <TAB>  # Overload emit() to send events to the proxy object at the other end <TAB>  ev = super ( ) . emit ( type , info ) <TAB>  if self . _has_proxy is True and self . _session . status > 0 : <TAB><TAB>  # implicit: and self._disposed is False: <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) <TAB><TAB>  elif type in self . __event_types_at_proxy : <TAB><TAB><TAB>  self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) ",if type in self . __proxy_properties__ :,if type in self.__event_types_at_proxy:,False,63.1104586491817,96.45613654603899
1743,"def validate_pull_secret ( namespace ) : <TAB>  if namespace . pull_secret is None : <TAB><TAB>  # TODO: add aka.ms link here <TAB><TAB>  warning = ( <TAB><TAB><TAB>  "" No --pull-secret provided: cluster will not include samples or operators from  "" <TAB><TAB><TAB>  + "" Red Hat or from certified partners. "" <TAB><TAB>  ) <TAB><TAB>  logger . warning ( warning ) <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise Exception ( ) <TAB><TAB>  except : <TAB><TAB><TAB>  raise InvalidArgumentValueError ( "" Invalid --pull-secret. "" ) ","if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :",if namespace.pull_secret is None:,False,65.01493521628122,92.44296687897184
1744,"def pack ( types , * args ) : <TAB>  if len ( types ) != len ( args ) : <TAB><TAB>  raise Exception ( "" number of arguments does not match format string "" ) <TAB>  port = StringIO ( ) <TAB>  for ( type , value ) in zip ( types , args ) : <TAB><TAB>  if type == "" V "" : <TAB><TAB><TAB>  write_vuint ( port , value ) <TAB><TAB>  elif type == "" v "" : <TAB><TAB><TAB>  write_vint ( port , value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  write_bvec ( port , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB>  return port . getvalue ( ) ","elif type == ""s"" :","if type == ""b':",False,54.83517118591416,95.79933408169136
1745,"def data ( self ) : <TAB>  if self . _data is not None : <TAB><TAB>  return self . _data <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with open ( self . path , "" rb "" ) as jsonfile : <TAB><TAB><TAB><TAB>  data = jsonfile . read ( ) . decode ( "" utf8 "" ) <TAB><TAB><TAB><TAB>  data = json . loads ( data ) <TAB><TAB><TAB><TAB>  self . _data = data <TAB><TAB><TAB><TAB>  return self . _data <TAB><TAB>  else : <TAB><TAB><TAB>  return dict ( ) ",if os . path . exists ( self . path ) :,if os.path.exists(self.path):,False,50.96531042154449,100.00000000000004
1746,"def interact ( self ) : <TAB>  self . output . write ( "" \n "" ) <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  request = self . getline ( "" help>  "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  except ( KeyboardInterrupt , EOFError ) : <TAB><TAB><TAB>  break <TAB><TAB>  request = strip ( request ) <TAB><TAB>  # Make sure significant trailing quotation marks of literals don't <TAB><TAB>  # get deleted while cleaning input <TAB><TAB>  if ( <TAB><TAB><TAB>  len ( request ) > 2 <TAB><TAB><TAB>  and request [ 0 ] == request [ - 1 ] in ( "" ' "" , ' "" ' ) <TAB><TAB><TAB>  and request [ 0 ] not in request [ 1 : - 1 ] <TAB><TAB>  ) : <TAB><TAB><TAB>  request = request [ 1 : - 1 ] <TAB><TAB>  if lower ( request ) in ( "" q "" , "" quit "" ) : <TAB><TAB><TAB>  break <TAB><TAB>  self . help ( request ) ",if not request :,if not request:,False,58.160740319929374,96.348738566741
1747,"def api_attachment_metadata ( self ) : <TAB>  resp = [ ] <TAB>  for part in self . parts : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  k = { <TAB><TAB><TAB>  "" content_type "" : part . block . content_type , <TAB><TAB><TAB>  "" size "" : part . block . size , <TAB><TAB><TAB>  "" filename "" : part . block . filename , <TAB><TAB><TAB>  "" id "" : part . block . public_id , <TAB><TAB>  } <TAB><TAB>  content_id = part . content_id <TAB><TAB>  if content_id : <TAB><TAB><TAB>  if content_id [ 0 ] == "" < "" and content_id [ - 1 ] == "" > "" : <TAB><TAB><TAB><TAB>  content_id = content_id [ 1 : - 1 ] <TAB><TAB><TAB>  k [ "" content_id "" ] = content_id <TAB><TAB>  resp . append ( k ) <TAB>  return resp ",if not part . is_attachment :,if part.block.content_type == 'content-type':,False,24.191585720057457,93.62658753607244
1748,"def _notin_text ( term , text , verbose = False ) : <TAB>  index = text . find ( term ) <TAB>  head = text [ : index ] <TAB>  tail = text [ index + len ( term ) : ] <TAB>  correct_text = head + tail <TAB>  diff = _diff_text ( correct_text , text , verbose ) <TAB>  newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB>  for line in diff : <TAB><TAB>  if line . startswith ( u ( "" Skipping "" ) ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if line . startswith ( u ( "" +  "" ) ) : <TAB><TAB><TAB>  newdiff . append ( u ( ""<TAB>"" ) + line [ 2 : ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  newdiff . append ( line ) <TAB>  return newdiff ","if line . startswith ( u ( ""- "" ) ) :",if line.startswith(u(u(u(u(u(u(u,False,23.01132323705371,93.31182894674006
1749,"def get_api ( user , url ) : <TAB>  global API_CACHE <TAB>  if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB><TAB>  API_CACHE_LOCK . acquire ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  API_CACHE = { } <TAB><TAB><TAB>  if API_CACHE . get ( url ) is None : <TAB><TAB><TAB><TAB>  API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB><TAB>  finally : <TAB><TAB><TAB>  API_CACHE_LOCK . release ( ) <TAB>  api = API_CACHE [ url ] <TAB>  api . set_user ( user ) <TAB>  return api ",if API_CACHE is None :,if API_CACHE is None:,False,54.78448303200325,100.00000000000004
1750,"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB>  res = "" "" <TAB>  if self . has_index_name_ : <TAB><TAB>  res + = prefix + ( "" index_name:  %s \n "" % self . DebugFormatString ( self . index_name_ ) ) <TAB>  cnt = 0 <TAB>  for e in self . prefix_value_ : <TAB><TAB>  elm = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elm = "" ( %d ) "" % cnt <TAB><TAB>  res + = prefix + ( "" prefix_value %s :  %s \n "" % ( elm , self . DebugFormatString ( e ) ) ) <TAB><TAB>  cnt + = 1 <TAB>  if self . has_value_prefix_ : <TAB><TAB>  res + = prefix + ( <TAB><TAB><TAB>  "" value_prefix:  %s \n "" % self . DebugFormatBool ( self . value_prefix_ ) <TAB><TAB>  ) <TAB>  return res ",if printElemNumber :,if printElemNumber:,False,20.437392586974802,100.00000000000004
1751,"def add_group ( x , nl , in_group , mw ) : <TAB>  if len ( x ) == 0 : <TAB><TAB>  return x <TAB>  if len ( x ) > 1 and not in_group : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ "" [[ "" ] + x + [ "" ]] "" ] <TAB><TAB>  mw . warn ( <TAB><TAB><TAB>  "" Equation will multiplex and may produce inaccurate results (see manual) "" <TAB><TAB>  ) <TAB>  return [ "" [ "" ] + x + [ "" ] "" ] ","if supports_group ( x , nl ) :",if nl:,False,34.38793543192861,93.69544193579699
1752,"def unfulfilled_items ( self ) : <TAB>  unfulfilled_items = 0 <TAB>  for order_item in self . items . all ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  aggr = order_item . deliver_item . aggregate ( delivered = Sum ( "" quantity "" ) ) <TAB><TAB><TAB>  unfulfilled_items + = order_item . quantity - ( aggr [ "" delivered "" ] or 0 ) <TAB>  return unfulfilled_items ",if not order_item . canceled :,if order_item.quantity:,False,23.202070633423038,95.48087182242973
1753,"def _get_pattern ( self , pattern_id ) : <TAB>  """"""Get pattern item by id."""""" <TAB>  for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = self . tagged_blocks . get_data ( key ) <TAB><TAB><TAB>  for pattern in data : <TAB><TAB><TAB><TAB>  if pattern . pattern_id == pattern_id : <TAB><TAB><TAB><TAB><TAB>  return pattern <TAB>  return None ",if key in self . tagged_blocks :,if self.tagged_blocks.has_data(key):,False,49.89739990234241,93.44820096743855
1754,"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB>  more_results = True <TAB>  num_results = 0 <TAB>  next_token = None <TAB>  while more_results : <TAB><TAB>  rs = domain . connection . query_with_attributes ( <TAB><TAB><TAB>  domain , query , attr_names , next_token = next_token <TAB><TAB>  ) <TAB><TAB>  for item in rs : <TAB><TAB><TAB>  if max_items : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise StopIteration <TAB><TAB><TAB>  yield item <TAB><TAB><TAB>  num_results + = 1 <TAB><TAB>  next_token = rs . next_token <TAB><TAB>  more_results = next_token != None ",if num_results == max_items :,if next_token is None:,False,32.8492889397197,95.89239003393618
1755,"def find_deprecated_settings ( source ) :<TAB># pragma: no cover <TAB>  from celery . utils import deprecated <TAB>  for name , opt in flatten ( NAMESPACES ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  deprecated . warn ( <TAB><TAB><TAB><TAB>  description = "" The  {0!r}  setting "" . format ( name ) , <TAB><TAB><TAB><TAB>  deprecation = opt . deprecate_by , <TAB><TAB><TAB><TAB>  removal = opt . remove_by , <TAB><TAB><TAB><TAB>  alternative = "" Use the  {0.alt}  instead "" . format ( opt ) , <TAB><TAB><TAB>  ) <TAB>  return source ","if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) :",if name.startswith('_'):,False,9.358675129068997,87.90672580513302
1756,"def tearDown ( self ) : <TAB>  """"""Shutdown the server."""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . server . stop ( 2.0 ) <TAB><TAB>  if self . sl_hdlr : <TAB><TAB><TAB>  self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB>  self . sl_hdlr . close ( ) <TAB>  finally : <TAB><TAB>  BaseTest . tearDown ( self ) ",if self . server :,if self.server:,False,26.49624343647647,100.00000000000004
1757,"def broadcast_events ( self , events ) : <TAB>  LOGGER . debug ( "" Broadcasting events:  %s "" , events ) <TAB>  with self . _subscribers_cv : <TAB><TAB>  # Copy the subscribers <TAB><TAB>  subscribers = { conn : sub . copy ( ) for conn , sub in self . _subscribers . items ( ) } <TAB>  if subscribers : <TAB><TAB>  for connection_id , subscriber in subscribers . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  subscriber_events = [ <TAB><TAB><TAB><TAB><TAB>  event for event in events if subscriber . is_subscribed ( event ) <TAB><TAB><TAB><TAB>  ] <TAB><TAB><TAB><TAB>  event_list = EventList ( events = subscriber_events ) <TAB><TAB><TAB><TAB>  self . _send ( connection_id , event_list . SerializeToString ( ) ) ",if subscriber . is_listening ( ) :,if connection_id == self._connection_id:,False,55.35977166392141,94.89724686899805
1758,"def _get_info ( self , path ) : <TAB>  info = OrderedDict ( ) <TAB>  if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB><TAB>  stdout = None <TAB><TAB>  try : <TAB><TAB><TAB>  stdout , stderr = Popen ( <TAB><TAB><TAB><TAB>  [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB><TAB><TAB><TAB>  stdout = PIPE , <TAB><TAB><TAB><TAB>  stderr = PIPE , <TAB><TAB><TAB>  ) . communicate ( ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  if stdout : <TAB><TAB><TAB><TAB>  for line in stdout . splitlines ( ) : <TAB><TAB><TAB><TAB><TAB>  line = u ( line ) . split ( "" :  "" , 1 ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  info [ line [ 0 ] ] = line [ 1 ] <TAB>  return info ",if len ( line ) == 2 :,if len(line) == 2:,False,50.88867616192787,100.00000000000004
1759,"def test_call_extern_c_fn ( self ) : <TAB>  global memcmp <TAB>  memcmp = cffi_support . ExternCFunction ( <TAB><TAB>  "" memcmp "" , <TAB><TAB>  ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB>  ) <TAB>  @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB>  def fn ( context , a , b ) : <TAB><TAB>  if a . is_null != b . is_null : <TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  if len ( a ) != b . len : <TAB><TAB><TAB>  return False <TAB><TAB>  if a . ptr == b . ptr : <TAB><TAB><TAB>  return True <TAB><TAB>  return memcmp ( a . ptr , b . ptr , a . len ) == 0 ",if a is None :,if a.is_null != b.is_null:,False,54.45267964776668,95.02562258408342
1760,"def _flatten ( * args ) : <TAB>  ahs = set ( ) <TAB>  if len ( args ) > 0 : <TAB><TAB>  for item in args : <TAB><TAB><TAB>  if type ( item ) is ActionHandle : <TAB><TAB><TAB><TAB>  ahs . add ( item ) <TAB><TAB><TAB>  elif type ( item ) in ( list , tuple , dict , set ) : <TAB><TAB><TAB><TAB>  for ah in item : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>:<TAB># pragma:nocover <TAB><TAB><TAB><TAB><TAB><TAB>  raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB><TAB><TAB><TAB><TAB>  ahs . add ( ah ) <TAB><TAB><TAB>  else :<TAB># pragma:nocover <TAB><TAB><TAB><TAB>  raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB>  return ahs ",if type ( ah ) is not ActionHandle :,if type(ah) is ActionHandle:,False,50.12257262787172,95.87837021186522
1761,"def startElement ( self , name , attrs , connection ) : <TAB>  if name == "" Parameter "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self [ self . _current_param . name ] = self . _current_param <TAB><TAB>  self . _current_param = Parameter ( self ) <TAB><TAB>  return self . _current_param ",if self . _current_param :,if self._current_param:,False,51.276700536543906,100.00000000000004
1762,"def _find_class_in_descendants ( self , search_key ) : <TAB>  for cls in self . primitive_classes : <TAB><TAB>  cls_key = ( cls . __name__ , cls . __module__ ) <TAB><TAB>  self . class_cache [ cls_key ] = cls <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return cls ",if cls_key == search_key :,if search_key in self.class_cache:,False,19.717309260527262,91.22522142741789
1763,"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB>  sibling = self <TAB>  while sibling : <TAB><TAB>  c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB><TAB>  if c1 : <TAB><TAB><TAB>  v . append ( sibling ) <TAB><TAB>  else : <TAB><TAB><TAB>  c2 = not partialMatch and sibling . equalsTree ( target ) <TAB><TAB><TAB>  if c2 : <TAB><TAB><TAB><TAB>  v . append ( sibling ) <TAB><TAB>  ### regardless of match or not, check any children for matches <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sibling . getFirstChild ( ) . doWorkForFindAll ( v , target , partialMatch ) <TAB><TAB>  sibling = sibling . getNextSibling ( ) ",if sibling . getFirstChild ( ) :,if sibling.getFirstChild() is not None:,False,62.13915190400498,97.65707625998525
1764,"def forward ( self , inputs : paddle . Tensor ) : <TAB>  outputs = [ ] <TAB>  blocks = self . block ( inputs ) <TAB>  route = None <TAB>  for i , block in enumerate ( blocks ) : <TAB><TAB>  if i > 0 : <TAB><TAB><TAB>  block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB><TAB>  route , tip = self . yolo_blocks [ i ] ( block ) <TAB><TAB>  block_out = self . block_outputs [ i ] ( tip ) <TAB><TAB>  outputs . append ( block_out ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  route = self . route_blocks_2 [ i ] ( route ) <TAB><TAB><TAB>  route = self . upsample ( route ) <TAB>  return outputs ",if i < 2 :,if route is not None:,False,30.348137691652795,97.21015417051196
1765,"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB>  """""".gitignore style file filtering."""""" <TAB>  for item in exclude : <TAB><TAB>  # Items ending in '/' apply only to directories. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # Items starting with '/' apply to the whole path. <TAB><TAB>  # In any other cases just the basename is used. <TAB><TAB>  match = path if item . startswith ( "" / "" ) else basename <TAB><TAB>  if fnmatch . fnmatch ( match , item . strip ( "" / "" ) ) : <TAB><TAB><TAB>  return True <TAB>  return False ","if item . endswith ( ""/"" ) and not is_dir :",if is_dir and (not item.startswith('/')):,False,66.44702817593164,92.89913400915023
1766,"def reposition_division ( f1 ) : <TAB>  lines = f1 . splitlines ( ) <TAB>  if lines [ 2 ] == division : <TAB><TAB>  lines . pop ( 2 ) <TAB>  found = 0 <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  if line . startswith ( ' "" "" "" ' ) : <TAB><TAB><TAB>  found + = 1 <TAB><TAB><TAB>  if found == 2 : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break<TAB># already in the right place <TAB><TAB><TAB><TAB>  lines . insert ( i + 1 , "" "" ) <TAB><TAB><TAB><TAB>  lines . insert ( i + 2 , division ) <TAB><TAB><TAB><TAB>  break <TAB>  return "" \n "" . join ( lines ) ","if division in ""\n"" . join ( lines ) :",if found == 3:,False,47.359608766349396,93.7214354783094
1767,"def buildImage ( opt ) : <TAB>  dpath = os . path . join ( opt [ "" datapath "" ] , "" COCO-IMG-2015 "" ) <TAB>  version = "" 1 "" <TAB>  if not build_data . built ( dpath , version_string = version ) : <TAB><TAB>  print ( "" [building image data:  "" + dpath + "" ] "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # An older version exists, so remove these outdated files. <TAB><TAB><TAB>  build_data . remove_dir ( dpath ) <TAB><TAB>  build_data . make_dir ( dpath ) <TAB><TAB>  # Download the data. <TAB><TAB>  for downloadable_file in RESOURCES [ : 1 ] : <TAB><TAB><TAB>  downloadable_file . download_file ( dpath ) <TAB><TAB>  # Mark the data as built. <TAB><TAB>  build_data . mark_done ( dpath , version_string = version ) ",if build_data . built ( dpath ) :,if version > 2:,False,58.489146314403484,95.86561790115063
1768,"def colorformat ( text ) : <TAB>  if text [ 0 : 1 ] == "" # "" : <TAB><TAB>  col = text [ 1 : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return col <TAB><TAB>  elif len ( col ) == 3 : <TAB><TAB><TAB>  return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB>  elif text == "" "" : <TAB><TAB>  return "" "" <TAB>  assert False , "" wrong color format  %r "" % text ",if len ( col ) == 6 :,if len(col) == 2:,False,52.41023224172696,98.18487054407757
1769,"def tree_print ( tree ) : <TAB>  for key in tree : <TAB><TAB>  print ( key , end = "" "" )<TAB># end=' ' prevents a newline character <TAB><TAB>  tree_element = tree [ key ]<TAB># multiple lookups is expensive, even amortized O(1)! <TAB><TAB>  for subElem in tree_element : <TAB><TAB><TAB>  print ( ""  ->  "" , subElem , end = "" "" ) <TAB><TAB><TAB>  <IF-STMT>:<TAB># OP wants indenting after digits <TAB><TAB><TAB><TAB>  print ( "" \n "" )<TAB># newline and a space to match indenting <TAB><TAB>  print ( )<TAB># forces a newline ",if type ( subElem ) != str :,if len(tree_element) > 1:,False,28.339426911421008,82.95018019069776
1770,"def is_dse_cluster ( path ) : <TAB>  try : <TAB><TAB>  with open ( os . path . join ( path , "" CURRENT "" ) , "" r "" ) as f : <TAB><TAB><TAB>  name = f . readline ( ) . strip ( ) <TAB><TAB><TAB>  cluster_path = os . path . join ( path , name ) <TAB><TAB><TAB>  filename = os . path . join ( cluster_path , "" cluster.conf "" ) <TAB><TAB><TAB>  with open ( filename , "" r "" ) as f : <TAB><TAB><TAB><TAB>  data = yaml . load ( f ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  except IOError : <TAB><TAB>  return False ","if ""dse_dir"" in data :",if data['cluster_name'] == name:,False,22.010121301145443,95.02739465185164
1771,"def delete_old_target_output_files ( classpath_prefix ) : <TAB>  """"""Delete existing output files or symlinks for target."""""" <TAB>  directory , basename = os . path . split ( classpath_prefix ) <TAB>  pattern = re . compile ( <TAB><TAB>  r "" ^ {basename} (([0-9]+)( \ .jar)?|classpath \ .txt)$ "" . format ( <TAB><TAB><TAB>  basename = re . escape ( basename ) <TAB><TAB>  ) <TAB>  ) <TAB>  files = [ filename for filename in os . listdir ( directory ) if pattern . match ( filename ) ] <TAB>  for rel_path in files : <TAB><TAB>  path = os . path . join ( directory , rel_path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  safe_delete ( path ) ",if os . path . islink ( path ) or os . path . isfile ( path ) :,if os.path.exists(path):,False,28.421220831393633,94.67662161319936
1772,"def test_files ( self ) : <TAB>  # get names of files to test <TAB>  dist_dir = os . path . join ( os . path . dirname ( __file__ ) , os . pardir , os . pardir ) <TAB>  names = [ ] <TAB>  for d in self . test_directories : <TAB><TAB>  test_dir = os . path . join ( dist_dir , d ) <TAB><TAB>  for n in os . listdir ( test_dir ) : <TAB><TAB><TAB>  if n . endswith ( "" .py "" ) and not n . startswith ( "" bad "" ) : <TAB><TAB><TAB><TAB>  names . append ( os . path . join ( test_dir , n ) ) <TAB>  for filename in names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Testing  %s "" % filename ) <TAB><TAB>  source = read_pyfile ( filename ) <TAB><TAB>  self . check_roundtrip ( source ) ",if test_support . verbose :,if self.verbose:,False,30.135301115139313,98.09557986747902
1773,"def __str__ ( self ) : <TAB>  if self . HasError ( ) : <TAB><TAB>  return self . ErrorAsStr ( ) <TAB>  else : <TAB><TAB>  # Format is: {action} ""{target}"" ({filename}:{lineno}) <TAB><TAB>  string = self . _action <TAB><TAB>  if self . _target is not None : <TAB><TAB><TAB>  string + = ' "" {target} "" ' . format ( target = self . _target ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = self . _filename <TAB><TAB><TAB>  if self . _lineno is not None : <TAB><TAB><TAB><TAB>  path + = "" : {lineno} "" . format ( lineno = self . _lineno ) <TAB><TAB><TAB>  string + = ""  ( {path} ) "" . format ( path = path ) <TAB><TAB>  return string ",if self . _filename is not None :,if self._filename is not None:,False,54.58175309675517,100.00000000000004
1774,"def extra_action_out ( self , input_dict , state_batches , model , action_dist ) : <TAB>  with self . _no_grad_context ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stats_dict = extra_action_out_fn ( <TAB><TAB><TAB><TAB>  self , input_dict , state_batches , model , action_dist <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  stats_dict = parent_cls . extra_action_out ( <TAB><TAB><TAB><TAB>  self , input_dict , state_batches , model , action_dist <TAB><TAB><TAB>  ) <TAB><TAB>  return self . _convert_to_non_torch_type ( stats_dict ) ",if extra_action_out_fn :,if self._is_extra_action_out_fn:,False,47.857209190961264,96.86288140553816
1775,"def _retract_bindings ( fstruct , inv_bindings , fs_class , visited ) : <TAB>  # Visit each node only once: <TAB>  if id ( fstruct ) in visited : <TAB><TAB>  return <TAB>  visited . add ( id ( fstruct ) ) <TAB>  if _is_mapping ( fstruct ) : <TAB><TAB>  items = fstruct . items ( ) <TAB>  elif _is_sequence ( fstruct ) : <TAB><TAB>  items = enumerate ( fstruct ) <TAB>  else : <TAB><TAB>  raise ValueError ( "" Expected mapping or sequence "" ) <TAB>  for ( fname , fval ) in items : <TAB><TAB>  if isinstance ( fval , fs_class ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  fstruct [ fname ] = inv_bindings [ id ( fval ) ] <TAB><TAB><TAB>  _retract_bindings ( fval , inv_bindings , fs_class , visited ) ",if id ( fval ) in inv_bindings :,if fstruct.mapping == fstruct.sequence:,False,28.050947139594,95.80181992940811
1776,"def warehouses ( self ) - > tuple : <TAB>  from . . repositories import WarehouseBaseRepo <TAB>  repos = dict ( ) <TAB>  for dep in chain ( self . dependencies , [ self ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if not isinstance ( dep . repo , WarehouseBaseRepo ) : <TAB><TAB><TAB>  continue <TAB><TAB>  for repo in dep . repo . repos : <TAB><TAB><TAB>  if repo . from_config : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  repos [ repo . name ] = repo <TAB>  return tuple ( repos . values ( ) ) ",if dep . repo is None :,"if not isinstance(dep.repo, WarehouseBaseRepo):",False,46.465299494766285,94.63990214781202
1777,"def detype ( self ) : <TAB>  if self . _detyped is not None : <TAB><TAB>  return self . _detyped <TAB>  ctx = { } <TAB>  for key , val in self . _d . items ( ) : <TAB><TAB>  if not isinstance ( key , str ) : <TAB><TAB><TAB>  key = str ( key ) <TAB><TAB>  detyper = self . get_detyper ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # cannot be detyped <TAB><TAB><TAB>  continue <TAB><TAB>  deval = detyper ( val ) <TAB><TAB>  if deval is None : <TAB><TAB><TAB>  # cannot be detyped <TAB><TAB><TAB>  continue <TAB><TAB>  ctx [ key ] = deval <TAB>  self . _detyped = ctx <TAB>  return ctx ",if detyper is None :,if not detyper:,False,49.191574164547035,97.90717534996858
1778,"def populate_obj ( self , obj , name ) : <TAB>  field = getattr ( obj , name , None ) <TAB>  if field is not None : <TAB><TAB>  # If field should be deleted, clean it up <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field . delete ( ) <TAB><TAB><TAB>  return <TAB><TAB>  if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) : <TAB><TAB><TAB>  if not field . grid_id : <TAB><TAB><TAB><TAB>  func = field . put <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  func = field . replace <TAB><TAB><TAB>  func ( <TAB><TAB><TAB><TAB>  self . data . stream , <TAB><TAB><TAB><TAB>  filename = self . data . filename , <TAB><TAB><TAB><TAB>  content_type = self . data . content_type , <TAB><TAB><TAB>  ) ",if self . _should_delete :,"if hasattr(field, 'delete'):",False,58.51982378772762,97.10690471785854
1779,"def _load ( container ) : <TAB>  if isinstance ( container , str ) : <TAB><TAB>  # If container is a filename. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with open ( container , "" rb "" ) as f : <TAB><TAB><TAB><TAB>  return pickle . load ( f ) <TAB><TAB>  # If container is a pickle string. <TAB><TAB>  else : <TAB><TAB><TAB>  return pickle . loads ( container ) <TAB>  # If container is an open file <TAB>  elif isinstance ( container , IOBase ) : <TAB><TAB>  return pickle . load ( container ) <TAB>  # What else could it be? <TAB>  else : <TAB><TAB>  l . error ( "" Cannot unpickle container of type  %s "" , type ( container ) ) <TAB><TAB>  return None ",if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,"if isinstance(container, str):",False,60.06221658741098,90.3087971480375
1780,"def append_row ( self , row ) : <TAB>  self . allocate_future_payments ( row ) <TAB>  self . set_invoice_details ( row ) <TAB>  self . set_party_details ( row ) <TAB>  self . set_ageing ( row ) <TAB>  if self . filters . get ( "" group_by_party "" ) : <TAB><TAB>  self . update_sub_total_row ( row , row . party ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . append_subtotal_row ( self . previous_party ) <TAB><TAB>  self . previous_party = row . party <TAB>  self . data . append ( row ) ",if self . previous_party and ( self . previous_party != row . party ) :,if self.previous_party is not None:,False,41.185012680741764,91.5712989874395
1781,"def gg1 ( ) : <TAB>  while 1 : <TAB><TAB>  tt = 3 <TAB><TAB>  while tt > 0 : <TAB><TAB><TAB>  trace . append ( tt ) <TAB><TAB><TAB>  val = yield <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tt = 10<TAB># <= uncomment this line <TAB><TAB><TAB><TAB>  trace . append ( "" breaking early... "" ) <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  tt - = 1 <TAB><TAB>  trace . append ( "" try! "" ) ",if val is not None :,if val == '\n':,False,43.35515086375072,93.2101206214907
1782,"def migrate_common_facts ( facts ) : <TAB>  """"""Migrate facts from various roles into common"""""" <TAB>  params = { "" node "" : ( "" portal_net "" ) , "" master "" : ( "" portal_net "" ) } <TAB>  if "" common "" not in facts : <TAB><TAB>  facts [ "" common "" ] = { } <TAB>  # pylint: disable=consider-iterating-dictionary <TAB>  for role in params . keys ( ) : <TAB><TAB>  if role in facts : <TAB><TAB><TAB>  for param in params [ role ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  facts [ "" common "" ] [ param ] = facts [ role ] . pop ( param ) <TAB>  return facts ",if param in facts [ role ] :,if param in facts:,False,55.813020977531025,97.60733003686417
1783,"def get_measurements ( self , pipeline , object_name , category ) : <TAB>  if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB><TAB>  results = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if object_name == "" Image "" : <TAB><TAB><TAB><TAB>  results + = [ "" Correlation "" , "" Slope "" ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results + = [ "" Correlation "" ] <TAB><TAB>  if self . do_overlap : <TAB><TAB><TAB>  results + = [ "" Overlap "" , "" K "" ] <TAB><TAB>  if self . do_manders : <TAB><TAB><TAB>  results + = [ "" Manders "" ] <TAB><TAB>  if self . do_rwc : <TAB><TAB><TAB>  results + = [ "" RWC "" ] <TAB><TAB>  if self . do_costes : <TAB><TAB><TAB>  results + = [ "" Costes "" ] <TAB><TAB>  return results <TAB>  return [ ] ",if self . do_corr_and_slope :,if self.do_correlation:,False,43.05829699509132,97.63551785258915
1784,"def access_modes ( self ) : <TAB>  """"""access_modes property"""""" <TAB>  if self . _access_modes is None : <TAB><TAB>  self . _access_modes = self . get_access_modes ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _access_modes = list ( self . _access_modes ) <TAB>  return self . _access_modes ","if not isinstance ( self . _access_modes , list ) :",if self._access_modes is not None:,False,26.709937393573046,91.95253490755219
1785,"def unwrap_envelope ( self , data , many ) : <TAB>  if many : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) : <TAB><TAB><TAB><TAB>  self . context [ "" total "" ] = len ( data ) <TAB><TAB><TAB><TAB>  return data <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . context [ "" total "" ] = data [ "" total "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  self . context [ "" total "" ] = 0 <TAB><TAB><TAB>  data = { "" items "" : [ ] } <TAB><TAB>  return data [ "" items "" ] <TAB>  return data ","if data [ ""items"" ] :",if self.context.get('total'):,False,49.2715859160538,95.1846649535066
1786,"def to_string ( self , fmt = "" {:.4f} "" ) : <TAB>  result_str = "" "" <TAB>  for key in self . measures : <TAB><TAB>  result = self . m_dict [ key ] [ 0 ] ( ) <TAB><TAB>  result_str + = ( <TAB><TAB><TAB>  "" , "" . join ( fmt . format ( x ) for x in result ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else fmt . format ( result ) <TAB><TAB>  ) <TAB><TAB>  result_str + = "" , "" <TAB>  return result_str [ : - 1 ]<TAB># trim the last comma ","if isinstance ( result , tuple )",if result == '':,False,24.41727831382757,91.86174281884362
1787,"def on_torrent_created ( self , result ) : <TAB>  if not result : <TAB><TAB>  return <TAB>  self . dialog_widget . btn_create . setEnabled ( True ) <TAB>  self . dialog_widget . edit_channel_create_torrent_progress_label . setText ( <TAB><TAB>  "" Created torrent "" <TAB>  ) <TAB>  if "" torrent "" in result : <TAB><TAB>  self . create_torrent_notification . emit ( { "" msg "" : "" Torrent successfully created "" } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add_torrent_to_channel ( result [ "" torrent "" ] ) <TAB><TAB>  self . close_dialog ( ) ",if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,if result['torrent']:,False,23.746612581096596,89.54910157276476
1788,"def save ( self ) : <TAB>  for var_name in self . default_config : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if var_name in self . file_config : <TAB><TAB><TAB><TAB>  del self . file_config [ var_name ] <TAB><TAB>  else : <TAB><TAB><TAB>  self . file_config [ var_name ] = getattr ( self , var_name ) <TAB>  with open ( self . config_path , "" w "" ) as f : <TAB><TAB>  f . write ( json . dumps ( self . file_config , indent = 2 ) ) ","if getattr ( self , var_name , None ) == self . default_config [ var_name ] :",if var_name == self.config_name:,False,48.42461487198584,88.97758820133205
1789,"def get_class_parameters ( kwarg ) : <TAB>  ret = { "" attrs "" : [ ] } <TAB>  for key in ( "" rsc "" , "" fsc "" , "" usc "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret [ "" attrs "" ] . append ( <TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB>  "" TCA_HFSC_ %s "" % key . upper ( ) , <TAB><TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB><TAB>  "" m1 "" : get_rate ( kwarg [ key ] . get ( "" m1 "" , 0 ) ) , <TAB><TAB><TAB><TAB><TAB><TAB>  "" d "" : get_time ( kwarg [ key ] . get ( "" d "" , 0 ) ) , <TAB><TAB><TAB><TAB><TAB><TAB>  "" m2 "" : get_rate ( kwarg [ key ] . get ( "" m2 "" , 0 ) ) , <TAB><TAB><TAB><TAB><TAB>  } , <TAB><TAB><TAB><TAB>  ] <TAB><TAB><TAB>  ) <TAB>  return ret ",if key in kwarg :,if key.upper() in kwarg:,False,50.18521582953651,98.17366132813338
1790,"def forward ( self , x ) : <TAB>  f_x = x <TAB>  if self . exp : <TAB><TAB>  f_x = self . exp_swish ( self . exp_bn ( self . exp ( f_x ) ) ) <TAB>  f_x = self . dwise_swish ( self . dwise_bn ( self . dwise ( f_x ) ) ) <TAB>  f_x = self . se ( f_x ) <TAB>  f_x = self . lin_proj_bn ( self . lin_proj ( f_x ) ) <TAB>  if self . has_skip : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  f_x = drop_connect ( f_x , effnet_cfg . EN . DC_RATIO ) <TAB><TAB>  f_x = x + f_x <TAB>  return f_x ",if self . training and effnet_cfg . EN . DC_RATIO > 0.0 :,if self.is_connected:,False,24.89047333977258,93.14610174949847
1791,"def cli_uninstall_distro ( ) : <TAB>  distro_list = install_distro_list ( ) <TAB>  if distro_list is not None : <TAB><TAB>  for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB>  log ( str ( index ) + ""   --->>   "" + _distro_dir ) <TAB><TAB>  user_input = read_input_uninstall ( ) <TAB><TAB>  if user_input is not False : <TAB><TAB><TAB>  for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  config . uninstall_distro_dir_name = _distro_dir <TAB><TAB><TAB><TAB><TAB>  unin_distro ( ) <TAB>  else : <TAB><TAB>  log ( "" No distro installed on  "" + config . usb_disk ) ",if index == user_input :,if _distro_dir == config.usb_disk:,False,52.79713140714374,95.106981168436
1792,"def IMPORTFROM ( self , node ) : <TAB>  if node . module == "" __future__ "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB>  else : <TAB><TAB>  self . futuresAllowed = False <TAB>  for alias in node . names : <TAB><TAB>  if alias . name == "" * "" : <TAB><TAB><TAB>  self . scope . importStarred = True <TAB><TAB><TAB>  self . report ( messages . ImportStarUsed , node , node . module ) <TAB><TAB><TAB>  continue <TAB><TAB>  name = alias . asname or alias . name <TAB><TAB>  importation = Importation ( name , node ) <TAB><TAB>  if node . module == "" __future__ "" : <TAB><TAB><TAB>  importation . used = ( self . scope , node ) <TAB><TAB>  self . addBinding ( node , importation ) ",if not self . futuresAllowed :,if node.futuresAllowed:,False,28.94889978906144,98.54309026474702
1793,"def _split_and_load ( batch , ctx_list ) : <TAB>  """"""Split data to 1 batch each device."""""" <TAB>  new_batch = [ ] <TAB>  for _ , data in enumerate ( batch ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_data = [ x . as_in_context ( ctx ) for x , ctx in zip ( data , ctx_list ) ] <TAB><TAB>  else : <TAB><TAB><TAB>  new_data = [ data . as_in_context ( ctx_list [ 0 ] ) ] <TAB><TAB>  new_batch . append ( new_data ) <TAB>  return new_batch ","if isinstance ( data , ( list , tuple ) ) :",if len(data) == 1:,False,52.440128897771665,93.7862325709678
1794,"def wait_success ( self , timeout = 60 * 10 ) : <TAB>  for i in range ( timeout / / 10 ) : <TAB><TAB>  time . sleep ( 10 ) <TAB><TAB>  status = self . query_job ( ) <TAB><TAB>  print ( "" job  {}  status is  {} "" . format ( self . job_id , status ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  if status and status in [ <TAB><TAB><TAB>  StatusSet . CANCELED , <TAB><TAB><TAB>  StatusSet . TIMEOUT , <TAB><TAB><TAB>  StatusSet . FAILED , <TAB><TAB>  ] : <TAB><TAB><TAB>  return False <TAB>  return False ",if status and status == StatusSet . SUCCESS :,if status == StatusSet.SUCCESS:,False,35.47434120926468,98.50875233876613
1795,"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB>  for src_root , _ , files in os . walk ( src_dir ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rel_root = os . path . relpath ( src_root , src_dir ) <TAB><TAB>  else : <TAB><TAB><TAB>  rel_root = "" "" <TAB><TAB>  if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  dst_root = os . path . join ( dst_dir , rel_root ) <TAB><TAB>  if not os . path . exists ( dst_root ) : <TAB><TAB><TAB>  os . makedirs ( dst_root ) <TAB><TAB>  for f in files : <TAB><TAB><TAB>  shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) ) ",if src_root != src_dir :,if os.path.isdir(src_root):,False,48.21186845222984,96.01554338453481
1796,"def _make_padded_shapes ( self , dataset , decoders ) : <TAB>  padded_shapes = dataset . output_shapes <TAB>  for i , hparams_i in enumerate ( self . _hparams . datasets ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if not hparams_i [ "" pad_to_max_seq_length "" ] : <TAB><TAB><TAB>  continue <TAB><TAB>  text_and_id_shapes = MonoTextData . _make_padded_text_and_id_shapes ( <TAB><TAB><TAB>  dataset , hparams_i , decoders [ i ] , self . text_name ( i ) , self . text_id_name ( i ) <TAB><TAB>  ) <TAB><TAB>  padded_shapes . update ( text_and_id_shapes ) <TAB>  return padded_shapes ","if not _is_text_data ( hparams_i [ ""data_type"" ] ) :",if not hparams_i['pad_to_max_seq_length']:,False,37.37102548539381,92.7918773113282
1797,"def format_errors ( messages ) : <TAB>  errors = { } <TAB>  for k , v in messages . items ( ) : <TAB><TAB>  key = camelize ( k , uppercase_first_letter = False ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  errors [ key ] = format_errors ( v ) <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  errors [ key ] = v [ 0 ] <TAB>  return errors ","if isinstance ( v , dict ) :","if isinstance(v, str):",False,50.99910421342526,97.87646095521553
1798,"def generic_visit ( self , node , parents = None ) : <TAB>  parents = ( parents or [ ] ) + [ node ] <TAB>  for field , value in iter_fields ( node ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for item in value : <TAB><TAB><TAB><TAB>  if isinstance ( item , AST ) : <TAB><TAB><TAB><TAB><TAB>  self . visit ( item , parents ) <TAB><TAB>  elif isinstance ( value , AST ) : <TAB><TAB><TAB>  self . visit ( value , parents ) ","if isinstance ( value , list ) :","if isinstance(value, list):",False,50.99370395923435,100.00000000000004
1799,"def get_override_css ( self ) : <TAB>  """"""handls allow_css_overrides setting."""""" <TAB>  if self . settings . get ( "" allow_css_overrides "" ) : <TAB><TAB>  filename = self . view . file_name ( ) <TAB><TAB>  filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB><TAB>  if filename and filetypes : <TAB><TAB><TAB>  for filetype in filetypes : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB><TAB><TAB><TAB><TAB>  if os . path . isfile ( css_filename ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB>  return "" "" ",if filename . endswith ( filetype ) :,if filetype.startswith('.css'):,False,44.60444948064056,96.68573318111757
1800,"def clean ( self ) : <TAB>  super ( ) . clean ( ) <TAB>  # If the Cluster is assigned to a Site, all Devices must be assigned to that Site. <TAB>  if self . cluster . site is not None : <TAB><TAB>  for device in self . cleaned_data . get ( "" devices "" , [ ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB><TAB>  "" devices "" : "" {}  belongs to a different site ( {} ) than the cluster ( {} ) "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  device , device . site , self . cluster . site <TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB><TAB>  ) ",if device . site != self . cluster . site :,if device.site != self.cluster.site:,False,66.96280076125582,100.00000000000004
1801,"def _setProcessPriority ( process , nice_val , disable_gc ) : <TAB>  org_nice_val = Computer . _process_original_nice_value <TAB>  try : <TAB><TAB>  process . nice ( nice_val ) <TAB><TAB>  Computer . in_high_priority_mode = nice_val != org_nice_val <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gc . disable ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  gc . enable ( ) <TAB><TAB>  return True <TAB>  except psutil . AccessDenied : <TAB><TAB>  print2err ( <TAB><TAB><TAB>  "" WARNING: Could not set process  {}  priority  "" <TAB><TAB><TAB>  "" to  {} "" . format ( process . pid , nice_val ) <TAB><TAB>  ) <TAB><TAB>  return False ",if disable_gc :,if disable_gc:,False,59.055674354248424,100.00000000000004
1802,"def _setResultsName ( self , name , listAllMatches = False ) : <TAB>  if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  "" {} : setting results name  {!r}  on  {}  expression  "" <TAB><TAB><TAB><TAB>  "" may only return a single token for an And alternative,  "" <TAB><TAB><TAB><TAB>  "" in future will return the full list of tokens "" . format ( <TAB><TAB><TAB><TAB><TAB>  "" warn_multiple_tokens_in_named_alternation "" , <TAB><TAB><TAB><TAB><TAB>  name , <TAB><TAB><TAB><TAB><TAB>  type ( self ) . __name__ , <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  stacklevel = 3 , <TAB><TAB><TAB>  ) <TAB>  return super ( ) . _setResultsName ( name , listAllMatches ) ","if any ( isinstance ( e , And ) for e in self . exprs ) :",if not name:,False,56.785314598831626,93.9231167970929
1803,"def make_sources ( project : RootDependency ) - > str : <TAB>  content = [ ] <TAB>  if project . readme : <TAB><TAB>  content . append ( project . readme . path . name ) <TAB><TAB>  if project . readme . markup != "" rst "" : <TAB><TAB><TAB>  content . append ( project . readme . to_rst ( ) . path . name ) <TAB>  path = project . package . path <TAB>  for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  content . append ( fname ) <TAB>  for package in chain ( project . package . packages , project . package . data ) : <TAB><TAB>  for fpath in package : <TAB><TAB><TAB>  fpath = fpath . relative_to ( project . package . path ) <TAB><TAB><TAB>  content . append ( "" / "" . join ( fpath . parts ) ) <TAB>  return "" \n "" . join ( content ) ",if ( path / fname ) . exists ( ) :,if fname.startswith('.py') and fname.endswith('.py') and,False,38.838121902389446,92.82637873066308
1804,"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB>  controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB>  index = 0 <TAB>  for i , c in enumerate ( subsegments ) : <TAB><TAB>  segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB><TAB>  for j , s in enumerate ( c ) : <TAB><TAB><TAB>  if j < segmentCount : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  controlPointIndices [ index ] = 1 <TAB><TAB><TAB>  index + = s [ 1 ] <TAB>  return controlPointIndices ","if glyph . contours [ i ] . segments [ j ] . type == ""line"" :",if s[0] == 1:,False,22.773205062555093,89.12572214632557
1805,"def MergeFrom ( self , other ) : <TAB>  if self . message_class is not None : <TAB><TAB>  if other . Parse ( self . message_class ) : <TAB><TAB><TAB>  self . message . MergeFrom ( other . message ) <TAB>  elif other . message_class is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . message = other . message_class ( ) <TAB><TAB><TAB>  self . message_class = other . message_class <TAB><TAB>  self . message . MergeFrom ( other . message ) <TAB>  else : <TAB><TAB>  self . message + = other . message ",if not self . Parse ( other . message_class ) :,"if isinstance(other.message_class, Message):",False,46.89470919958506,95.70251247243695
1806,"def remove_old_snapshot ( install_dir ) : <TAB>  logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB>  for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . unlink ( file ) <TAB><TAB><TAB>  elif os . path . isdir ( file ) : <TAB><TAB><TAB><TAB>  shutil . rmtree ( file ) <TAB><TAB>  except Exception as error : <TAB><TAB><TAB>  logging . error ( "" Error:  {} "" . format ( error ) ) <TAB><TAB><TAB>  sys . exit ( 1 ) ",if os . path . isfile ( file ) :,if os.path.isfile(file):,False,31.540933894746747,100.00000000000004
1807,"def writexml ( <TAB>  self , <TAB>  stream , <TAB>  indent = "" "" , <TAB>  addindent = "" "" , <TAB>  newl = "" "" , <TAB>  strip = 0 , <TAB>  nsprefixes = { } , <TAB>  namespace = "" "" ,  ) : <TAB>  w = _streamWriteWrapper ( stream ) <TAB>  if self . raw : <TAB><TAB>  val = self . nodeValue <TAB><TAB>  if not isinstance ( val , str ) : <TAB><TAB><TAB>  val = str ( self . nodeValue ) <TAB>  else : <TAB><TAB>  v = self . nodeValue <TAB><TAB>  if not isinstance ( v , str ) : <TAB><TAB><TAB>  v = str ( v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = "" "" . join ( v . split ( ) ) <TAB><TAB>  val = escape ( v ) <TAB>  w ( val ) ",if strip :,if v.startswith(''):,False,31.204647899067083,96.62520701406525
1808,"def validate_attributes ( self ) : <TAB>  for attribute in self . get_all_attributes ( ) : <TAB><TAB>  value = getattr ( self , attribute . code , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if attribute . required : <TAB><TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB><TAB>  _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  attribute . validate_value ( value ) <TAB><TAB><TAB>  except ValidationError as e : <TAB><TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB><TAB>  _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB><TAB><TAB><TAB>  ) ",if value is None :,if value is None:,False,51.81067614044903,100.00000000000004
1809,"def PyJsHoisted_BinaryExpression_ ( node , parent , this , arguments , var = var ) : <TAB>  var = Scope ( <TAB><TAB>  { u "" node "" : node , u "" this "" : this , u "" arguments "" : arguments , u "" parent "" : parent } , var <TAB>  ) <TAB>  var . registers ( [ u "" node "" , u "" parent "" ] ) <TAB>  if PyJsStrictEq ( var . get ( u "" node "" ) . get ( u "" operator "" ) , Js ( u "" in "" ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return var . get ( u "" true "" ) <TAB><TAB>  if var . get ( u "" t "" ) . callprop ( u "" isFor "" , var . get ( u "" parent "" ) ) : <TAB><TAB><TAB>  return var . get ( u "" true "" ) <TAB>  return Js ( False ) ","if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :","if var.get(u""isFor""):",False,24.440499854804322,90.75241897626206
1810,"def distinct ( expr , * on ) : <TAB>  fields = frozenset ( expr . fields ) <TAB>  _on = [ ] <TAB>  append = _on . append <TAB>  for n in on : <TAB><TAB>  if isinstance ( n , Field ) : <TAB><TAB><TAB>  if n . _child . isidentical ( expr ) : <TAB><TAB><TAB><TAB>  n = n . _name <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB><TAB>  elif n not in fields : <TAB><TAB><TAB>  raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB>  append ( n ) <TAB>  return Distinct ( expr , tuple ( _on ) ) ","if not isinstance ( n , _strtypes ) :",if n not in fields:,False,31.93462348547612,96.53650183295079
1811,"def encode ( self , msg ) : <TAB>  """"""Encodes the message to the stream encoding."""""" <TAB>  stream = self . stream <TAB>  rv = msg + "" \n "" <TAB>  if ( PY2 and is_unicode ( rv ) ) or not ( <TAB><TAB>  PY2 or is_unicode ( rv ) or _is_text_stream ( stream ) <TAB>  ) : <TAB><TAB>  enc = self . encoding <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  enc = getattr ( stream , "" encoding "" , None ) or "" utf-8 "" <TAB><TAB>  rv = rv . encode ( enc , "" replace "" ) <TAB>  return rv ",if enc is None :,if enc is None:,False,55.82407441265057,100.00000000000004
1812,"def color_convert ( self , to_color_space , preserve_alpha = True ) : <TAB>  if to_color_space == self . color_space and preserve_alpha : <TAB><TAB>  return self <TAB>  else : <TAB><TAB>  pixels = pixels_as_float ( self . pixels ) <TAB><TAB>  converted = convert_color ( <TAB><TAB><TAB>  pixels , self . color_space , to_color_space , preserve_alpha <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  return Image ( converted , to_color_space ) ",if converted is None :,if converted is None:,False,51.06457352386442,100.00000000000004
1813,"def seek ( self , pos ) : <TAB>  if self . closed : <TAB><TAB>  raise IOError ( "" Cannot seek on a closed file "" ) <TAB>  for n , idx in enumerate ( self . _indexes [ : : - 1 ] ) : <TAB><TAB>  if idx . offset < = pos : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _idxiter = iter ( self . _indexes [ - ( n + 1 ) : ] ) <TAB><TAB><TAB><TAB>  self . _nextidx ( ) <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  raise Exception ( "" Cannot seek to pos "" ) <TAB>  self . _curfile . seek ( pos - self . _curidx . offset ) ",if idx != self . _curidx :,if n + 1 in self._indexes:,False,24.98771018944676,93.87087254355106
1814,"def load_from_json ( self , node_data : dict , import_version : float ) : <TAB>  if import_version < = 0.08 : <TAB><TAB>  self . image_pointer = unpack_pointer_property_name ( <TAB><TAB><TAB>  bpy . data . images , node_data , "" image_name "" <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  proposed_name = node_data . get ( "" image_name "" ) <TAB><TAB><TAB>  self . info ( f "" image data not found in current  { proposed_name } "" ) ",if not self . image_pointer :,if node_data.get('image_name'):,False,29.60394629258004,92.81645173734739
1815,"def __init__ ( self , execution_context , aggregate_operators ) : <TAB>  super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB>  self . _local_aggregators = [ ] <TAB>  self . _results = None <TAB>  self . _result_index = 0 <TAB>  for operator in aggregate_operators : <TAB><TAB>  if operator == "" Average "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB><TAB>  elif operator == "" Max "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB><TAB>  elif operator == "" Min "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB><TAB>  elif operator == "" Sum "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _SumAggregator ( ) ) ","elif operator == ""Count"" :","if operator == ""Count"":",False,26.117769787880146,99.05209761565798
1816,"def attrgetter ( item ) : <TAB>  items = [ None ] * len ( attribute ) <TAB>  for i , attribute_part in enumerate ( attribute ) : <TAB><TAB>  item_i = item <TAB><TAB>  for part in attribute_part : <TAB><TAB><TAB>  item_i = environment . getitem ( item_i , part ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  item_i = postprocess ( item_i ) <TAB><TAB>  items [ i ] = item_i <TAB>  return items ",if postprocess is not None :,if item_i is not None:,False,38.65530685909394,96.56646489059675
1817,"def work ( self ) : <TAB>  while True : <TAB><TAB>  timeout = self . timeout <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  timeout = self . idle_timeout <TAB><TAB>  log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB><TAB>  fetch . wait ( timeout ) <TAB><TAB>  if shutting_down . is_set ( ) : <TAB><TAB><TAB>  log . info ( "" Stop fetch worker "" ) <TAB><TAB><TAB>  break <TAB><TAB>  self . fetch ( ) ",if idle . is_set ( ) :,if timeout < self.idle_timeout:,False,22.51648007073095,94.57371924257022
1818,"def testCoreInterfaceIntInputData ( ) : <TAB>  result_testing = False <TAB>  for _ in range ( 10 ) : <TAB><TAB>  hsyncnet_instance = hsyncnet ( <TAB><TAB><TAB>  [ [ 1 ] , [ 2 ] , [ 3 ] , [ 20 ] , [ 21 ] , [ 22 ] ] , 2 , initial_type . EQUIPARTITION , ccore = True <TAB><TAB>  ) <TAB><TAB>  analyser = hsyncnet_instance . process ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result_testing = True <TAB><TAB><TAB>  break <TAB>  assert result_testing ",if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,if analyser.is_analyser():,False,22.70061747768204,90.90549512316639
1819,"def _gen ( ) : <TAB>  buf = [ ] <TAB>  iterable = dataset ( ) <TAB>  try : <TAB><TAB>  while len ( buf ) < buffer_size : <TAB><TAB><TAB>  buf . append ( next ( iterable ) ) <TAB><TAB>  while 1 : <TAB><TAB><TAB>  i = random . randint ( 0 , buffer_size - 1 ) <TAB><TAB><TAB>  n = next ( iterable ) <TAB><TAB><TAB>  yield buf [ i ] <TAB><TAB><TAB>  buf [ i ] = n <TAB>  except StopIteration : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  random . shuffle ( buf ) <TAB><TAB><TAB>  for i in buf : <TAB><TAB><TAB><TAB>  yield i ",if len ( buf ) :,if len(buf) > buffer_size:,False,49.91929702546675,97.23817483175623
1820,"def debug_tree ( tree ) : <TAB>  l = [ ] <TAB>  for elt in tree : <TAB><TAB>  if isinstance ( elt , ( int , long ) ) : <TAB><TAB><TAB>  l . append ( _names . get ( elt , elt ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  l . append ( elt ) <TAB><TAB>  else : <TAB><TAB><TAB>  l . append ( debug_tree ( elt ) ) <TAB>  return l ","elif isinstance ( elt , str ) :","if isinstance(elt, (int, long)):",False,49.312145712172864,92.96298012164046
1821,"def reverse_code ( apps : StateApps , schema_editor : DatabaseSchemaEditor ) - > None : <TAB>  PreregistrationUser = apps . get_model ( "" zerver "" , "" PreregistrationUser "" ) <TAB>  for user in PreregistrationUser . objects . all ( ) : <TAB><TAB>  <IF-STMT>:<TAB># PreregistrationUser.INVITE_AS['REALM_ADMIN'] <TAB><TAB><TAB>  user . invited_as_admin = True <TAB><TAB>  else :<TAB># PreregistrationUser.INVITE_AS['MEMBER'] <TAB><TAB><TAB>  user . invited_as_admin = False <TAB><TAB>  user . save ( update_fields = [ "" invited_as_admin "" ] ) ",if user . invited_as == 2 :,if user.is_staff:,False,46.515921020794096,92.02987953503437
1822,"def _fastqc_data_section ( self , section_name ) : <TAB>  out = [ ] <TAB>  in_section = False <TAB>  data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB>  if os . path . exists ( data_file ) : <TAB><TAB>  with open ( data_file ) as in_handle : <TAB><TAB><TAB>  for line in in_handle : <TAB><TAB><TAB><TAB>  if line . startswith ( "" >> %s "" % section_name ) : <TAB><TAB><TAB><TAB><TAB>  in_section = True <TAB><TAB><TAB><TAB>  elif in_section : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB><TAB>  out . append ( line . rstrip ( "" \r \n "" ) ) <TAB>  return out ","if line . startswith ( "">>END"" ) :",if not in_section:,False,20.795848689131915,95.41040393087529
1823,"def determine_block_hints ( self , text ) : <TAB>  hints = "" "" <TAB>  if text : <TAB><TAB>  if text [ 0 ] in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB>  hints + = str ( self . best_indent ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  hints + = "" - "" <TAB><TAB>  elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB>  hints + = "" + "" <TAB>  return hints ","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :",if len(text) == 0:,False,44.568303312746636,87.2754839816544
1824,"def database_app ( request ) : <TAB>  if request . param == "" postgres_app "" : <TAB><TAB>  if not which ( "" initdb "" ) : <TAB><TAB><TAB>  pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB><TAB>  if not psycopg2 : <TAB><TAB><TAB>  pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB>  if request . param == "" sqlite_rabbitmq_app "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pytest . skip ( <TAB><TAB><TAB><TAB>  "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB><TAB><TAB>  ) <TAB>  return request . getfixturevalue ( request . param ) ","if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :",if not which('rabbitmq_test'):,False,37.61626489967138,91.10619884517493
1825,"def do_rollout ( agent , env , num_steps , render = False ) : <TAB>  total_rew = 0 <TAB>  ob = env . reset ( ) <TAB>  for t in range ( num_steps ) : <TAB><TAB>  a = agent . act ( ob ) <TAB><TAB>  ( ob , reward , done , _info ) = env . step ( a ) <TAB><TAB>  total_rew + = reward <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  env . render ( ) <TAB><TAB>  if done : <TAB><TAB><TAB>  break <TAB>  return total_rew , t + 1 ",if render and t % 3 == 0 :,if render:,False,21.7976245964607,94.50400933534824
1826,"def _handle_subrepos ( self , ctx , dirty_trees ) : <TAB>  substate = util . parse_hgsubstate ( ctx [ "" .hgsubstate "" ] . data ( ) . splitlines ( ) ) <TAB>  sub = util . OrderedDict ( ) <TAB>  if "" .hgsub "" in ctx : <TAB><TAB>  sub = util . parse_hgsub ( ctx [ "" .hgsub "" ] . data ( ) . splitlines ( ) ) <TAB>  for path , sha in substate . iteritems ( ) : <TAB><TAB>  # Ignore non-Git repositories keeping state in .hgsubstate. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  d = os . path . dirname ( path ) <TAB><TAB>  dirty_trees . add ( d ) <TAB><TAB>  tree = self . _dirs . setdefault ( d , dulobjs . Tree ( ) ) <TAB><TAB>  tree . add ( os . path . basename ( path ) , dulobjs . S_IFGITLINK , sha ) ","if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :",if os.path.exists(path):,False,55.26192044718754,92.5591505382754
1827,"def get_property_file_image_choices ( self , pipeline ) : <TAB>  columns = pipeline . get_measurement_columns ( ) <TAB>  image_names = [ ] <TAB>  for column in columns : <TAB><TAB>  object_name , feature , coltype = column [ : 3 ] <TAB><TAB>  choice = feature [ ( len ( C_FILE_NAME ) + 1 ) : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  image_names . append ( choice ) <TAB>  return image_names ","if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :",if choice in C_FILE_NAME:,False,19.648184917633753,86.16819088519573
1828,"def check_all_decorator_order ( ) : <TAB>  """"""Check that in all test files, the slow decorator is always last."""""" <TAB>  errors = [ ] <TAB>  for fname in os . listdir ( PATH_TO_TESTS ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename = os . path . join ( PATH_TO_TESTS , fname ) <TAB><TAB><TAB>  new_errors = check_decorator_order ( filename ) <TAB><TAB><TAB>  errors + = [ f "" -  { filename } , line  { i } "" for i in new_errors ] <TAB>  if len ( errors ) > 0 : <TAB><TAB>  msg = "" \n "" . join ( errors ) <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  f "" The parameterized decorator (and its variants) should always be first, but this is not the case in the following files: \n { msg } "" <TAB><TAB>  ) ","if fname . endswith ( "".py"" ) :",if os.path.isfile(fname):,False,62.53698563710407,96.39584332481004
1829,"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB>  tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB>  watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB>  if watchdir_id : <TAB><TAB>  if col and col . get_title ( ) == _ ( "" Active "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  client . autoadd . disable_watchdir ( watchdir_id ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  client . autoadd . enable_watchdir ( watchdir_id ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id ) ","if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :",if self.is_active(watchdir_id):,False,49.60024296449389,95.08971603565766
1830,"def get_conv_output_size ( input_size , kernel_size , stride , padding , dilation ) : <TAB>  ndim = len ( input_size ) <TAB>  output_size = [ ] <TAB>  for i in range ( ndim ) : <TAB><TAB>  size = ( <TAB><TAB><TAB>  input_size [ i ] + 2 * padding [ i ] - dilation [ i ] * ( kernel_size [ i ] - 1 ) - 1 <TAB><TAB>  ) / / stride [ i ] + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  output_size . append ( 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  output_size . append ( size ) <TAB>  return output_size ",if kernel_size [ i ] == - 1 :,if size == 0:,False,21.878830804445567,94.79243407286631
1831,"def from_location ( cls , location , basename , metadata = None , * * kw ) : <TAB>  project_name , version , py_version , platform = [ None ] * 4 <TAB>  basename , ext = os . path . splitext ( basename ) <TAB>  if ext . lower ( ) in ( "" .egg "" , "" .egg-info "" ) : <TAB><TAB>  match = EGG_NAME ( basename ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  project_name , version , py_version , platform = match . group ( <TAB><TAB><TAB><TAB>  "" name "" , "" ver "" , "" pyver "" , "" plat "" <TAB><TAB><TAB>  ) <TAB>  return cls ( <TAB><TAB>  location , <TAB><TAB>  metadata , <TAB><TAB>  project_name = project_name , <TAB><TAB>  version = version , <TAB><TAB>  py_version = py_version , <TAB><TAB>  platform = platform , <TAB><TAB>  * * kw <TAB>  ) ",if match :,if match:,False,49.42870207162232,100.00000000000004
1832,"def __new__ ( metacls , typename , bases , namespace ) : <TAB>  annotations = namespace . get ( "" __annotations__ "" , { } ) <TAB>  for t in annotations . values ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for ut in t . __args__ : <TAB><TAB><TAB><TAB>  _assert_tensorizer_type ( ut ) <TAB><TAB>  else : <TAB><TAB><TAB>  _assert_tensorizer_type ( t ) <TAB>  return super ( ) . __new__ ( metacls , typename , bases , namespace ) ","if getattr ( t , ""__origin__"" , """" ) is Union :","if hasattr(t, '__args__'):",False,48.019181042054356,90.42276346792274
1833,"def decode_content ( self ) : <TAB>  """"""Return the best possible representation of the response body."""""" <TAB>  ct = self . headers . get ( "" content-type "" ) <TAB>  if ct : <TAB><TAB>  ct , options = parse_options_header ( ct ) <TAB><TAB>  charset = options . get ( "" charset "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . json ( charset ) <TAB><TAB>  elif ct . startswith ( "" text/ "" ) : <TAB><TAB><TAB>  return self . text ( charset ) <TAB><TAB>  elif ct == FORM_URL_ENCODED : <TAB><TAB><TAB>  return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB>  return self . content ",if ct in JSON_CONTENT_TYPES :,if ct.startswith('application/json'):,False,29.656114164047096,95.73429033599881
1834,"def get_full_path ( path ) : <TAB>  if "" :// "" not in path : <TAB><TAB>  path = os . path . join ( self . AUTO_COLL_TEMPL , path , "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = os . path . join ( abs_path , path ) <TAB>  return path ",if abs_path :,if os.path.isdir(abs_path):,False,29.2179700030307,89.35373775610007
1835,"def __getitem__ ( self , name_or_path ) : <TAB>  if isinstance ( name_or_path , integer_types ) : <TAB><TAB>  return list . __getitem__ ( self , name_or_path ) <TAB>  elif isinstance ( name_or_path , tuple ) : <TAB><TAB>  try : <TAB><TAB><TAB>  val = self <TAB><TAB><TAB>  for fid in name_or_path : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise KeyError<TAB># path contains base value <TAB><TAB><TAB><TAB>  val = val [ fid ] <TAB><TAB><TAB>  return val <TAB><TAB>  except ( KeyError , IndexError ) : <TAB><TAB><TAB>  raise KeyError ( name_or_path ) <TAB>  else : <TAB><TAB>  raise TypeError ( self . _INDEX_ERROR % name_or_path ) ","if not isinstance ( val , FeatStruct ) :",if val.has_key(fid):,False,21.502854549762517,94.81016720485464
1836,"def scan ( scope ) : <TAB>  for s in scope . children : <TAB><TAB>  if s . start_pos < = position < = s . end_pos : <TAB><TAB><TAB>  if isinstance ( s , ( tree . Scope , tree . Flow ) ) : <TAB><TAB><TAB><TAB>  return scan ( s ) or s <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return scan ( s ) <TAB>  return None ","elif s . type in ( ""suite"" , ""decorated"" ) :","if isinstance(s, tree.Function):",False,18.41894425814365,89.33966664253721
1837,"def _get_key ( self ) : <TAB>  if not self . key : <TAB><TAB>  self . _channel . send ( u "" pake "" , self . msg1 ) <TAB><TAB>  pake_msg = self . _channel . get ( u "" pake "" ) <TAB><TAB>  self . key = self . sp . finish ( pake_msg ) <TAB><TAB>  self . verifier = self . derive_key ( u "" wormhole:verifier "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  confkey = self . derive_key ( u "" wormhole:confirmation "" ) <TAB><TAB>  nonce = os . urandom ( CONFMSG_NONCE_LENGTH ) <TAB><TAB>  confmsg = make_confmsg ( confkey , nonce ) <TAB><TAB>  self . _channel . send ( u "" _confirm "" , confmsg ) ",if not self . _send_confirm :,if not pake_msg:,False,20.896338810064368,96.44800572517717
1838,"def executeScript ( self , script ) : <TAB>  if len ( script ) > 0 : <TAB><TAB>  commands = [ ] <TAB><TAB>  for l in script : <TAB><TAB><TAB>  extracted = self . extract_command ( l ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  commands . append ( extracted ) <TAB><TAB>  for command in commands : <TAB><TAB><TAB>  cmd , argv = command <TAB><TAB><TAB>  self . dispatch_command ( cmd , argv ) ",if extracted :,if extracted is not None:,False,31.944543221303068,96.64331377240634
1839,"def create_path ( n , fullname , meta ) : <TAB>  if meta : <TAB><TAB>  meta . create_path ( fullname ) <TAB>  else : <TAB><TAB>  # These fallbacks are important -- meta could be null if, for <TAB><TAB>  # example, save created a ""fake"" item, i.e. a new strip/graft <TAB><TAB>  # path element, etc.  You can find cases like that by <TAB><TAB>  # searching for ""Metadata()"". <TAB><TAB>  unlink ( fullname ) <TAB><TAB>  if stat . S_ISDIR ( n . mode ) : <TAB><TAB><TAB>  mkdirp ( fullname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . symlink ( n . readlink ( ) , fullname ) ",elif stat . S_ISLNK ( n . mode ) :,if n.islink():,False,71.01867622506289,94.5744306602005
1840,def get_cycle ( self ) : <TAB>  if self . has_cycle ( ) : <TAB><TAB>  cross_node = self . path [ - 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . path [ self . path . index ( cross_node ) : ] <TAB><TAB>  else : <TAB><TAB><TAB>  return self . path <TAB>  return [ ] ,if self . path . count ( cross_node ) > 1 :,if cross_node:,False,21.463732558690253,86.47206665813407
1841,"def _select_block ( str_in , start_tag , end_tag ) : <TAB>  """"""Select first block delimited by start_tag and end_tag"""""" <TAB>  start_pos = str_in . find ( start_tag ) <TAB>  if start_pos < 0 : <TAB><TAB>  raise ValueError ( "" start_tag not found "" ) <TAB>  depth = 0 <TAB>  for pos in range ( start_pos , len ( str_in ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  depth + = 1 <TAB><TAB>  elif str_in [ pos ] == end_tag : <TAB><TAB><TAB>  depth - = 1 <TAB><TAB>  if depth == 0 : <TAB><TAB><TAB>  break <TAB>  sel = str_in [ start_pos + 1 : pos ] <TAB>  return sel ",if str_in [ pos ] == start_tag :,if str_in[pos] == start_tag:,False,46.52758248063344,100.00000000000004
1842,"def device ( self ) : <TAB>  """"""Device on which the data array of this variable reside."""""" <TAB>  # lazy initialization for performance <TAB>  if self . _device is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _device = backend . CpuDevice ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _device = backend . get_device_from_array ( self . _data [ 0 ] ) <TAB>  return self . _device ",if self . _data [ 0 ] is None :,if len(self._data) == 0:,False,61.72741730375488,93.14984132596764
1843,"def function_out ( * args , * * kwargs ) : <TAB>  try : <TAB><TAB>  return function_in ( * args , * * kwargs ) <TAB>  except dbus . exceptions . DBusException as e : <TAB><TAB>  if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB><TAB><TAB>  raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB><TAB>  if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) : <TAB><TAB><TAB>  raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB><TAB>  raise ",if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT :,if e.get_dbus_name() in (DBUS_NO_REPLY,False,17.633153222395688,95.45262746693743
1844,"def run ( self ) : <TAB>  """"""Continual loop evaluating when_statements"""""" <TAB>  while len ( self . library ) > 0 : <TAB><TAB>  for name , expression in self . library . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del self . library [ name ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  expression . evaluate ( ) <TAB><TAB>  sleep ( 0.01 ) <TAB>  return ",if expression . remove_me == True :,if name in self.library:,False,23.964583056776387,92.94865899240737
1845,"def tamper ( payload , * * kwargs ) : <TAB>  junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB>  retval = "" "" <TAB>  for i , char in enumerate ( payload , start = 1 ) : <TAB><TAB>  amount = random . randint ( 10 , 15 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  retval + = "" > "" <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  elif char == "" < "" : <TAB><TAB><TAB>  retval + = "" < "" <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  elif char == "" "" : <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  else : <TAB><TAB><TAB>  retval + = char <TAB>  return retval ","if char == "">"" :","if char == "">"":",False,22.91526653648737,100.00000000000004
1846,"def _source_target_path ( source , source_path , source_location ) : <TAB>  target_path_attr = source . target_path or source . resdef . target_path <TAB>  if source . preserve_path : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . warning ( <TAB><TAB><TAB><TAB>  "" target-path  ' %s '  specified with preserve-path - ignoring "" , <TAB><TAB><TAB><TAB>  target_path_attr , <TAB><TAB><TAB>  ) <TAB><TAB>  return os . path . relpath ( os . path . dirname ( source_path ) , source_location ) <TAB>  else : <TAB><TAB>  return target_path_attr or source . resdef . target_path or "" "" ",if target_path_attr :,if target_path_attr is not None and target_path_attr is not None:,False,53.1232364497314,91.33412814083363
1847,"def _load_user_from_header ( self , header ) : <TAB>  if self . _header_callback : <TAB><TAB>  user = self . _header_callback ( header ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  app = current_app . _get_current_object ( ) <TAB><TAB><TAB>  user_loaded_from_header . send ( app , user = user ) <TAB><TAB><TAB>  return user <TAB>  return None ",if user is not None :,if user:,False,35.06242252483514,96.15610259289309
1848,"def setup ( cls ) : <TAB>  "" Check dependencies and warn about firewalling "" <TAB>  pathCheck ( "" brctl "" , moduleName = "" bridge-utils "" ) <TAB>  # Disable Linux bridge firewalling so that traffic can flow! <TAB>  for table in "" arp "" , "" ip "" , "" ip6 "" : <TAB><TAB>  cmd = "" sysctl net.bridge.bridge-nf-call- %s tables "" % table <TAB><TAB>  out = quietRun ( cmd ) . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warn ( "" Warning: Linux bridge may not work with "" , out , "" \n "" ) ","if out . endswith ( ""1"" ) :",if out:,False,62.83868727910239,92.26602117581984
1849,"def _browse_your_music ( web_client , variant ) : <TAB>  if not web_client . logged_in : <TAB><TAB>  return [ ] <TAB>  if variant in ( "" tracks "" , "" albums "" ) : <TAB><TAB>  items = flatten ( <TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB>  page . get ( "" items "" , [ ] ) <TAB><TAB><TAB><TAB>  for page in web_client . get_all ( <TAB><TAB><TAB><TAB><TAB>  f "" me/ { variant } "" , <TAB><TAB><TAB><TAB><TAB>  params = { "" market "" : "" from_token "" , "" limit "" : 50 } , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  if page <TAB><TAB><TAB>  ] <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return list ( translator . web_to_track_refs ( items ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  return list ( translator . web_to_album_refs ( items ) ) <TAB>  else : <TAB><TAB>  return [ ] ","if variant == ""tracks"" :","if variant == ""tracks':",False,22.302728142992294,98.85709761959302
1850,"def reset_styling ( self ) : <TAB>  for edge in self . fsm_graph . edges_iter ( ) : <TAB><TAB>  style_attr = self . fsm_graph . style_attributes . get ( "" edge "" , { } ) . get ( "" default "" ) <TAB><TAB>  edge . attr . update ( style_attr ) <TAB>  for node in self . fsm_graph . nodes_iter ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  style_attr = self . fsm_graph . style_attributes . get ( "" node "" , { } ) . get ( "" inactive "" ) <TAB><TAB><TAB>  node . attr . update ( style_attr ) <TAB>  for sub_graph in self . fsm_graph . subgraphs_iter ( ) : <TAB><TAB>  style_attr = self . fsm_graph . style_attributes . get ( "" graph "" , { } ) . get ( "" default "" ) <TAB><TAB>  sub_graph . graph_attr . update ( style_attr ) ","if ""point"" not in node . attr [ ""shape"" ] :",if node.state == 'inactive':,False,48.99462037247254,94.4603308689244
1851,"def set_message_type_visibility ( self , message_type : MessageType ) : <TAB>  try : <TAB><TAB>  rows = { <TAB><TAB><TAB>  i <TAB><TAB><TAB>  for i , msg in enumerate ( self . proto_analyzer . messages ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  } <TAB><TAB>  if message_type . show : <TAB><TAB><TAB>  self . ui . tblViewProtocol . show_rows ( rows ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . ui . tblViewProtocol . hide_rows ( rows ) <TAB>  except Exception as e : <TAB><TAB>  logger . exception ( e ) ",if msg . message_type == message_type,if msg.type == message_type:,False,22.28471886731766,97.12085602970417
1852,"def POP ( cpu , * regs ) : <TAB>  for reg in regs : <TAB><TAB>  val = cpu . stack_pop ( cpu . address_bit_size / / 8 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cpu . _set_mode_by_val ( val ) <TAB><TAB><TAB>  val = val & ~ 0x1 <TAB><TAB>  reg . write ( val ) ","if reg . reg in ( ""PC"" , ""R15"" ) :",if val & 0x1:,False,23.937912724775707,86.58373081897592
1853,"def processMovie ( self , atom ) : <TAB>  for field in atom : <TAB><TAB>  if "" track "" in field : <TAB><TAB><TAB>  self . processTrack ( field [ "" track "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . processMovieHeader ( field [ "" movie_hdr "" ] ) ","if ""movie_hdr"" in field :","if ""movie_hdr"" in field:",False,26.875323785919804,100.00000000000004
1854,"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB>  remote_version = urllib . urlopen ( url ) . read ( ) <TAB>  if remote_version . isdigit ( ) : <TAB><TAB>  local_version = get_local_timestamp ( folder ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if auto : <TAB><TAB><TAB><TAB>  update_setter . set_value ( True ) <TAB><TAB><TAB>  version_setter . set_value ( remote_version ) <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  else : <TAB><TAB>  return False ",if remote_version > local_version :,if local_version == remote_version:,False,25.55244878723889,97.08783007085559
1855,"def init ( self , view , items = None ) : <TAB>  selections = [ ] <TAB>  if view . sel ( ) : <TAB><TAB>  for region in view . sel ( ) : <TAB><TAB><TAB>  selections . append ( view . substr ( region ) ) <TAB>  values = [ ] <TAB>  for idx , index in enumerate ( map ( int , items ) ) : <TAB><TAB>  if idx > = len ( selections ) : <TAB><TAB><TAB>  break <TAB><TAB>  i = index - 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values . append ( selections [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  values . append ( None ) <TAB>  # fill up <TAB>  for idx , value in enumerate ( selections ) : <TAB><TAB>  if len ( values ) + 1 < idx : <TAB><TAB><TAB>  values . append ( value ) <TAB>  self . stack = values ",if i >= 0 and i < len ( selections ) :,if i >= 0:,False,27.45929212535001,96.45314508391803
1856,"def find_int_identifiers ( directory ) : <TAB>  results = find_rules ( directory , has_int_identifier ) <TAB>  print ( "" Number of rules with integer identifiers:  %d "" % len ( results ) ) <TAB>  for result in results : <TAB><TAB>  rule_path = result [ 0 ] <TAB><TAB>  product_yaml_path = result [ 1 ] <TAB><TAB>  product_yaml = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  product_yaml = yaml . open_raw ( product_yaml_path ) <TAB><TAB>  fix_file ( rule_path , product_yaml , fix_int_identifier ) ",if product_yaml_path is not None :,if product_yaml_path:,False,34.31303289256546,97.206233154257
1857,"def condition ( self ) : <TAB>  if self . __condition is None : <TAB><TAB>  if len ( self . flat_conditions ) == 1 : <TAB><TAB><TAB>  # Avoid an extra indirection in the common case of only one condition. <TAB><TAB><TAB>  self . __condition = self . flat_conditions [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Possible, if unlikely, due to filter predicate rewriting <TAB><TAB><TAB>  self . __condition = lambda _ : True <TAB><TAB>  else : <TAB><TAB><TAB>  self . __condition = lambda x : all ( cond ( x ) for cond in self . flat_conditions ) <TAB>  return self . __condition ",elif len ( self . flat_conditions ) == 0 :,if self.__condition is None:,False,65.35577894244416,93.38306807341417
1858,"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB>  scene_exceptions = [ ] <TAB>  for scene_exception in self . scene_exceptions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB><TAB>  if season == scene_season : <TAB><TAB><TAB>  scene_exceptions . append ( scene_name ) <TAB>  return scene_exceptions ",if not len ( scene_exception ) == 2 :,if scene_exception.startswith('|') or scene_exception.startswith('|,False,25.5386804426328,84.26444749002563
1859,"def init ( self , view , items = None ) : <TAB>  selections = [ ] <TAB>  if view . sel ( ) : <TAB><TAB>  for region in view . sel ( ) : <TAB><TAB><TAB>  selections . append ( view . substr ( region ) ) <TAB>  values = [ ] <TAB>  for idx , index in enumerate ( map ( int , items ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  i = index - 1 <TAB><TAB>  if i > = 0 and i < len ( selections ) : <TAB><TAB><TAB>  values . append ( selections [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  values . append ( None ) <TAB>  # fill up <TAB>  for idx , value in enumerate ( selections ) : <TAB><TAB>  if len ( values ) + 1 < idx : <TAB><TAB><TAB>  values . append ( value ) <TAB>  self . stack = values ",if idx >= len ( selections ) :,if idx == 0:,False,49.230836797566255,96.99311061989411
1860,"def to_tool_path ( self , path_or_uri_like , * * kwds ) : <TAB>  if "" :// "" not in path_or_uri_like : <TAB><TAB>  path = path_or_uri_like <TAB>  else : <TAB><TAB>  uri_like = path_or_uri_like <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( "" Invalid URI passed to get_tool_source "" ) <TAB><TAB>  scheme , rest = uri_like . split ( "" : "" , 2 ) <TAB><TAB>  if scheme not in self . resolver_classes : <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Unknown tool scheme [ {} ] for URI [ {} ] "" . format ( scheme , uri_like ) <TAB><TAB><TAB>  ) <TAB><TAB>  path = self . resolver_classes [ scheme ] ( ) . get_tool_source_path ( uri_like ) <TAB>  return path ","if "":"" not in path_or_uri_like :","if not isinstance(uri_like, basestring):",False,20.870573833919526,95.33626511263739
1861,def mainWindow ( ) : <TAB>  global MW <TAB>  if not MW : <TAB><TAB>  for i in qApp . topLevelWidgets ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  MW = i <TAB><TAB><TAB><TAB>  return MW <TAB><TAB>  return None <TAB>  else : <TAB><TAB>  return MW ,"if i . objectName ( ) == ""MainWindow"" :",if i.isWindow():,False,39.69074929040703,91.2907348365951
1862,"def async_get_service ( hass , config , discovery_info = None ) : <TAB>  # pylint: disable=unused-argument <TAB>  """"""Get the demo notification service."""""" <TAB>  for account , account_dict in hass . data [ DATA_ALEXAMEDIA ] [ "" accounts "" ] . items ( ) : <TAB><TAB>  for key , _ in account_dict [ "" devices "" ] [ "" media_player "" ] . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  _LOGGER . debug ( <TAB><TAB><TAB><TAB><TAB>  "" %s : Media player  %s  not loaded yet; delaying load "" , <TAB><TAB><TAB><TAB><TAB>  hide_email ( account ) , <TAB><TAB><TAB><TAB><TAB>  hide_serial ( key ) , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  return False <TAB>  return AlexaNotificationService ( hass ) ","if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :",if key not in hass.data:,False,59.80499330491177,93.45723713839502
1863,"def _migrate_bool ( self , name : str , true_value : str , false_value : str ) - > None : <TAB>  if name not in self . _settings : <TAB><TAB>  return <TAB>  values = self . _settings [ name ] <TAB>  if not isinstance ( values , dict ) : <TAB><TAB>  return <TAB>  for scope , val in values . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_value = true_value if val else false_value <TAB><TAB><TAB>  self . _settings [ name ] [ scope ] = new_value <TAB><TAB><TAB>  self . changed . emit ( ) ","if isinstance ( val , bool ) :",if scope == 'boolean':,False,51.47115079501394,95.46447958624135
1864,"def send ( self , data , flags = 0 ) : <TAB>  self . _checkClosed ( ) <TAB>  if self . _sslobj : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" non-zero flags not allowed in calls to send() on  %s "" % self . __class__ <TAB><TAB><TAB>  ) <TAB><TAB>  return self . _sslobj . write ( data ) <TAB>  else : <TAB><TAB>  return socket . send ( self , data , flags ) ",if flags != 0 :,if flags == 0:,False,60.67613443898621,98.14444805292847
1865,"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB>  deps = cnt [ "" _deps "" ] <TAB>  for dep in deps . copy ( ) : <TAB><TAB>  dep_cnts = services . get ( dep ) <TAB><TAB>  if not dep_cnts : <TAB><TAB><TAB>  continue <TAB><TAB>  dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # TODO: avoid creating loops, A->B->A <TAB><TAB><TAB>  if init_service and init_service in dep_cnt [ "" _deps "" ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB><TAB><TAB>  deps . update ( new_deps ) <TAB>  return deps ",if dep_cnt :,if dep_cnt and dep_cnt['type'] == 'module':,False,54.67639522618975,95.27378604615839
1866,"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB>  result = { } <TAB>  dirs = dir ( path , version , section ) <TAB>  if not dirs : <TAB><TAB>  return None <TAB>  for item in dirs : <TAB><TAB>  if item . endswith ( "" / "" ) : <TAB><TAB><TAB>  records = as_dict ( path + item , version , section ) <TAB><TAB><TAB>  if records : <TAB><TAB><TAB><TAB>  result [ item [ : - 1 ] ] = records <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  idx , name = is_dict . match ( item ) . groups ( ) <TAB><TAB><TAB>  records = as_dict ( path + idx + "" / "" , version , section ) <TAB><TAB><TAB>  if records : <TAB><TAB><TAB><TAB>  result [ name ] = records <TAB><TAB>  else : <TAB><TAB><TAB>  result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB>  return result ",elif is_dict . match ( item ) :,if is_dict.match(item):,False,33.47111679530833,97.82329640837675
1867,"def PrintColGroup ( col_names , schema ) : <TAB>  """"""Print HTML colgroup element, used for JavaScript sorting."""""" <TAB>  print ( ""   <colgroup> "" ) <TAB>  for i , col in enumerate ( col_names ) : <TAB><TAB>  if col . endswith ( "" _HREF "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  # CSS class is used for sorting <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  css_class = "" number "" <TAB><TAB>  else : <TAB><TAB><TAB>  css_class = "" case-insensitive "" <TAB><TAB>  # NOTE: id is a comment only; not used <TAB><TAB>  print ( '<TAB> <col id= "" {} ""  type= "" {} ""  /> ' . format ( col , css_class ) ) <TAB>  print ( ""   </colgroup> "" ) ",if schema . IsNumeric ( col ) :,if i == len(col_names):,False,62.930384216870905,95.98667330680372
1868,"def check_region ( self , region ) : <TAB>  for other in self . regions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if ( other . start < region . start < other . end ) or ( <TAB><TAB><TAB>  other . start < region . end < other . end <TAB><TAB>  ) : <TAB><TAB><TAB>  raise Exception ( "" %r  overlaps with  %r "" % ( region , other ) ) ",if other is region :,if region == other:,False,50.987295218582574,95.71615417597162
1869,"def _write_value ( self , rng , value , scalar ) : <TAB>  if rng . api and value : <TAB><TAB>  # it is assumed by this stage that value is a list of lists <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = value [ 0 ] [ 0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  rng = rng . resize ( len ( value ) , len ( value [ 0 ] ) ) <TAB><TAB>  rng . raw_value = value ",if scalar :,if len(value) == 1:,False,65.09407609164121,93.21376124132718
1870,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . mutable_cost ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 24 : <TAB><TAB><TAB>  self . add_version ( d . getVarInt64 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 8:,False,49.590851874253616,98.86228284909593
1871,"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB>  # This part of function creates faces in SV format <TAB>  # It ignores  boundless super face <TAB>  sv_faces = [ ] <TAB>  for i , face in enumerate ( dcel_mesh . faces ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  "" Face ( {} ) has inner components! Sverchok cant show polygons with holes. "" . format ( <TAB><TAB><TAB><TAB>  i <TAB><TAB><TAB>  ) <TAB><TAB>  if not face . outer or del_flag in face . flags : <TAB><TAB><TAB>  continue <TAB><TAB>  if only_select and not face . select : <TAB><TAB><TAB>  continue <TAB><TAB>  sv_faces . append ( [ point_index [ hedge . origin ] for hedge in face . outer . loop_hedges ] ) <TAB>  return sv_faces ",if face . inners and face . outer :,if face.inner:,False,63.987956630558784,97.26777400031013
1872,"def _get_x_for_y ( self , xValue , x , y ) : <TAB>  # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB>  x_value = str ( xValue ) <TAB>  for anime in self . xmlMap . findall ( "" anime "" ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return int ( anime . get ( y , 0 ) ) <TAB><TAB>  except ValueError as e : <TAB><TAB><TAB>  continue <TAB>  return 0 ","if anime . get ( x , False ) == x_value :","if anime.get(x, 0) == x_value:",False,38.51098105480476,98.43489635453342
1873,"def dir_copy ( src_dir , dest_dir , merge_if_exists = True ) : <TAB>  try : <TAB><TAB>  if not os . path . exists ( dest_dir ) : <TAB><TAB><TAB>  shutil . copytree ( src_dir , dest_dir ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  merge_dir ( src_dir , dest_dir ) <TAB>  except OSError as e : <TAB><TAB>  # If source is not a directory, copy with shutil.copy <TAB><TAB>  if e . errno == errno . ENOTDIR : <TAB><TAB><TAB>  shutil . copy ( src_dir , dest_dir ) <TAB><TAB>  else : <TAB><TAB><TAB>  logging . error ( "" Could not copy  %s  to  %s "" , src_dir , dest_dir ) ",elif merge_if_exists :,if merge_if_exists:,False,61.10005923056641,98.76687702431273
1874,"def mapping ( self ) : <TAB>  m = { } <TAB>  if getGdriveCredentialsFile ( ) is not None : <TAB><TAB>  m [ "" gdrive "" ] = "" "" <TAB>  unknown = 0 <TAB>  for f in self . scan : <TAB><TAB>  bits = f . split ( "" # "" , 2 ) <TAB><TAB>  if len ( bits ) == 1 : <TAB><TAB><TAB>  label = os . path . basename ( f ) <TAB><TAB>  else : <TAB><TAB><TAB>  label = bits [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  label = "" L "" + str ( unknown ) <TAB><TAB><TAB>  unknown + = 1 <TAB><TAB>  m [ label ] = bits [ 0 ] <TAB>  return m ","if not label or len ( label ) == 0 or label == """" :",if label == 'unknown':,False,21.456478255892353,92.03554745083183
1875,"def get_tag_values ( self , event ) : <TAB>  http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB>  if not http : <TAB><TAB>  return [ ] <TAB>  if not http . headers : <TAB><TAB>  return [ ] <TAB>  headers = http . headers <TAB>  # XXX: transitional support for workers <TAB>  if isinstance ( headers , dict ) : <TAB><TAB>  headers = headers . items ( ) <TAB>  output = [ ] <TAB>  for key , value in headers : <TAB><TAB>  if key != "" User-Agent "" : <TAB><TAB><TAB>  continue <TAB><TAB>  ua = Parse ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  result = self . get_tag_from_ua ( ua ) <TAB><TAB>  if result : <TAB><TAB><TAB>  output . append ( result ) <TAB>  return output ",if not ua :,if not ua:,False,53.41635521893233,100.00000000000004
1876,"def __iter__ ( self ) : <TAB>  it = DiskHashMerger . __iter__ ( self ) <TAB>  direct_upstreams = self . direct_upstreams <TAB>  for k , groups in it : <TAB><TAB>  t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB><TAB>  for i , g in enumerate ( groups ) : <TAB><TAB><TAB>  if g : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  t [ i ] = g <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  g . sort ( key = itemgetter ( 0 ) ) <TAB><TAB><TAB><TAB><TAB>  g1 = [ ] <TAB><TAB><TAB><TAB><TAB>  for _ , vs in g : <TAB><TAB><TAB><TAB><TAB><TAB>  g1 . extend ( vs ) <TAB><TAB><TAB><TAB><TAB>  t [ i ] = g1 <TAB><TAB>  yield k , tuple ( t ) ",if i in direct_upstreams :,if k == 'g':,False,27.355713076890925,97.6479190898389
1877,"def process_question ( qtxt ) : <TAB>  question = "" "" <TAB>  skip = False <TAB>  for letter in qtxt : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  skip = True <TAB><TAB>  if letter == "" > "" : <TAB><TAB><TAB>  skip = False <TAB><TAB>  if skip : <TAB><TAB><TAB>  continue <TAB><TAB>  if letter . isalnum ( ) or letter == "" "" : <TAB><TAB><TAB>  if letter == "" "" : <TAB><TAB><TAB><TAB>  letter = "" _ "" <TAB><TAB><TAB>  question + = letter . lower ( ) <TAB>  return question ","if letter == ""<"" :","if letter == ""<"":",False,52.84595615557054,100.00000000000004
1878,"def _module_repr_from_spec ( spec ) : <TAB>  """"""Return the repr to use for the module."""""" <TAB>  # We mostly replicate _module_repr() using the spec attributes. <TAB>  name = "" ? "" if spec . name is None else spec . name <TAB>  if spec . origin is None : <TAB><TAB>  if spec . loader is None : <TAB><TAB><TAB>  return "" <module  {!r} > "" . format ( name ) <TAB><TAB>  else : <TAB><TAB><TAB>  return "" <module  {!r}  ( {!r} )> "" . format ( name , spec . loader ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" <module  {!r}  from  {!r} > "" . format ( name , spec . origin ) <TAB><TAB>  else : <TAB><TAB><TAB>  return "" <module  {!r}  ( {} )> "" . format ( spec . name , spec . origin ) ",if spec . has_location :,if spec.origin is None:,False,59.952883527040846,98.17866291941851
1879,"def test_row ( self , row ) : <TAB>  for idx , test in self . patterns . items ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  value = row [ idx ] <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  value = "" "" <TAB><TAB>  result = test ( value ) <TAB><TAB>  if self . any_match : <TAB><TAB><TAB>  if result : <TAB><TAB><TAB><TAB>  return not self . inverse<TAB># True <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return self . inverse<TAB># False <TAB>  if self . any_match : <TAB><TAB>  return self . inverse<TAB># False <TAB>  else : <TAB><TAB>  return not self . inverse<TAB># True ",if not result :,if result:,False,21.23703589970258,91.02047432516
1880,"def frequent_thread_switches ( ) : <TAB>  """"""Make concurrency bugs more likely to manifest."""""" <TAB>  interval = None <TAB>  if not sys . platform . startswith ( "" java "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  interval = sys . getswitchinterval ( ) <TAB><TAB><TAB>  sys . setswitchinterval ( 1e-6 ) <TAB><TAB>  else : <TAB><TAB><TAB>  interval = sys . getcheckinterval ( ) <TAB><TAB><TAB>  sys . setcheckinterval ( 1 ) <TAB>  try : <TAB><TAB>  yield <TAB>  finally : <TAB><TAB>  if not sys . platform . startswith ( "" java "" ) : <TAB><TAB><TAB>  if hasattr ( sys , "" setswitchinterval "" ) : <TAB><TAB><TAB><TAB>  sys . setswitchinterval ( interval ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  sys . setcheckinterval ( interval ) ","if hasattr ( sys , ""getswitchinterval"" ) :",if sys.platform == 'win32':,False,27.870480339515563,96.05199157773829
1881,"def record_expected_exportable_production ( self , ticks ) : <TAB>  """"""Record the amount of production that should be transferred to other islands."""""" <TAB>  for ( quota_holder , resource_id ) , amount in self . _low_priority_requests . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _settlement_manager_id [ quota_holder ] = WorldObject . get_object_by_id ( <TAB><TAB><TAB><TAB>  int ( quota_holder [ 1 : ] . split ( "" , "" ) [ 0 ] ) <TAB><TAB><TAB>  ) . settlement_manager . worldid <TAB><TAB>  self . trade_storage [ self . _settlement_manager_id [ quota_holder ] ] [ resource_id ] + = ( <TAB><TAB><TAB>  ticks * amount <TAB><TAB>  ) ",if quota_holder not in self . _settlement_manager_id :,if amount > 0:,False,35.38967731718222,93.28752489614746
1882,"def _method_events_callback ( self , values ) : <TAB>  try : <TAB><TAB>  previous_echoed = ( <TAB><TAB><TAB>  values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" echo foo2 \n "" <TAB><TAB>  elif previous_echoed . endswith ( "" foo2 "" ) : <TAB><TAB><TAB>  return "" echo foo3 \n "" <TAB><TAB>  elif previous_echoed . endswith ( "" foo3 "" ) : <TAB><TAB><TAB>  return "" exit \n "" <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB>  except IndexError : <TAB><TAB>  return "" echo foo1 \n "" ","if previous_echoed . endswith ( ""foo1"" ) :",if previous_echoed.endswith('foo1'):,False,50.443713446515105,95.89579550292191
1883,"def describe_cluster_snapshots ( self , cluster_identifier = None , snapshot_identifier = None ) : <TAB>  if cluster_identifier : <TAB><TAB>  cluster_snapshots = [ ] <TAB><TAB>  for snapshot in self . snapshots . values ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cluster_snapshots . append ( snapshot ) <TAB><TAB>  if cluster_snapshots : <TAB><TAB><TAB>  return cluster_snapshots <TAB>  if snapshot_identifier : <TAB><TAB>  if snapshot_identifier in self . snapshots : <TAB><TAB><TAB>  return [ self . snapshots [ snapshot_identifier ] ] <TAB><TAB>  raise ClusterSnapshotNotFoundError ( snapshot_identifier ) <TAB>  return self . snapshots . values ( ) ",if snapshot . cluster . cluster_identifier == cluster_identifier :,if snapshot.spec.name == cluster_identifier:,False,51.03091038285217,96.73123848522455
1884,def get_snippet_edit_handler ( model ) : <TAB>  if model not in SNIPPET_EDIT_HANDLERS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # use the edit handler specified on the page class <TAB><TAB><TAB>  edit_handler = model . edit_handler <TAB><TAB>  else : <TAB><TAB><TAB>  panels = extract_panel_definitions_from_model_class ( model ) <TAB><TAB><TAB>  edit_handler = ObjectList ( panels ) <TAB><TAB>  SNIPPET_EDIT_HANDLERS [ model ] = edit_handler . bind_to ( model = model ) <TAB>  return SNIPPET_EDIT_HANDLERS [ model ] ,"if hasattr ( model , ""edit_handler"" ) :","if hasattr(model, 'edit_handler'):",False,62.15994059903856,96.2619794082679
1885,"def start ( ) : <TAB>  if os . environ . get ( "" RUN_MAIN "" ) != "" true "" : <TAB><TAB>  try : <TAB><TAB><TAB>  exit_code = restart_with_reloader ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . kill ( os . getpid ( ) , - exit_code ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  sys . exit ( exit_code ) <TAB><TAB>  except KeyboardInterrupt : <TAB><TAB><TAB>  pass ",if exit_code < 0 :,if exit_code < 0:,False,51.403878413402396,97.60182872635554
1886,"def discover ( self , * objlist ) : <TAB>  ret = [ ] <TAB>  for l in self . splitlines ( ) : <TAB><TAB>  if len ( l ) < 5 : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  int ( l [ 2 ] ) <TAB><TAB><TAB>  int ( l [ 3 ] ) <TAB><TAB>  except : <TAB><TAB><TAB>  continue <TAB><TAB>  #<TAB><TAB>   ret.append(improve(l[0])) <TAB><TAB>  ret . append ( l [ 0 ] ) <TAB>  ret . sort ( ) <TAB>  for item in objlist : <TAB><TAB>  ret . append ( item ) <TAB>  return ret ","if l [ 0 ] == ""Filename"" :",if len(l) < 4:,False,49.03682994267516,95.07729106395426
1887,"def ipfs_publish ( self , lib ) : <TAB>  with tempfile . NamedTemporaryFile ( ) as tmp : <TAB><TAB>  self . ipfs_added_albums ( lib , tmp . name ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cmd = "" ipfs add --nocopy -q  "" . split ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  cmd = "" ipfs add -q  "" . split ( ) <TAB><TAB><TAB>  cmd . append ( tmp . name ) <TAB><TAB><TAB>  output = util . command_output ( cmd ) <TAB><TAB>  except ( OSError , subprocess . CalledProcessError ) as err : <TAB><TAB><TAB>  msg = "" Failed to publish library. Error:  {0} "" . format ( err ) <TAB><TAB><TAB>  self . _log . error ( msg ) <TAB><TAB><TAB>  return False <TAB><TAB>  self . _log . info ( "" hash of library:  {0} "" , output ) ","if self . config [ ""nocopy"" ] :",if sys.platform == 'win32':,False,52.3537644741063,96.44637089448851
1888,"def spends ( self ) : <TAB>  # Return spends indexed by hashX <TAB>  spends = defaultdict ( list ) <TAB>  utxos = self . mempool_utxos ( ) <TAB>  for tx_hash , tx in self . txs . items ( ) : <TAB><TAB>  for n , input in enumerate ( tx . inputs ) : <TAB><TAB><TAB>  if input . is_generation ( ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  prevout = ( input . prev_hash , input . prev_idx ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  hashX , value = utxos . pop ( prevout ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  hashX , value = self . db_utxos [ prevout ] <TAB><TAB><TAB>  spends [ hashX ] . append ( prevout ) <TAB>  return spends ",if prevout in utxos :,if prevout in utxos:,False,29.38065799052001,100.00000000000004
1889,"def terminate ( self ) : <TAB>  if self . returncode is None : <TAB><TAB>  try : <TAB><TAB><TAB>  os . kill ( self . pid , TERM_SIGNAL ) <TAB><TAB>  except OSError as exc : <TAB><TAB><TAB>  if getattr ( exc , "" errno "" , None ) != errno . ESRCH : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise ",if self . wait ( timeout = 0.1 ) is None :,if exc.errno == errno.EINVAL:,False,22.007351995365124,90.84886979176565
1890,"def _getVolumeScalar ( self ) : <TAB>  if self . _volumeScalar is not None : <TAB><TAB>  return self . _volumeScalar <TAB>  # use default <TAB>  elif self . _value in dynamicStrToScalar : <TAB><TAB>  return dynamicStrToScalar [ self . _value ] <TAB>  else : <TAB><TAB>  thisDynamic = self . _value <TAB><TAB>  # ignore leading s like in sf <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  thisDynamic = thisDynamic [ 1 : ] <TAB><TAB>  # ignore closing z like in fz <TAB><TAB>  if thisDynamic [ - 1 ] == "" z "" : <TAB><TAB><TAB>  thisDynamic = thisDynamic [ : - 1 ] <TAB><TAB>  if thisDynamic in dynamicStrToScalar : <TAB><TAB><TAB>  return dynamicStrToScalar [ thisDynamic ] <TAB><TAB>  else : <TAB><TAB><TAB>  return dynamicStrToScalar [ None ] ","if ""s"" in thisDynamic :","if thisDynamic[-1] == ""s':",False,57.58693325194648,93.74698638370836
1891,"def init_values ( self ) : <TAB>  config = self . _raw_config <TAB>  for valname , value in self . overrides . iteritems ( ) : <TAB><TAB>  if "" . "" in valname : <TAB><TAB><TAB>  realvalname , key = valname . split ( "" . "" , 1 ) <TAB><TAB><TAB>  config . setdefault ( realvalname , { } ) [ key ] = value <TAB><TAB>  else : <TAB><TAB><TAB>  config [ valname ] = value <TAB>  for name in config : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __dict__ [ name ] = config [ name ] <TAB>  del self . _raw_config ",if name in self . values :,if name not in self.__dict__:,False,51.000282246646634,94.85446523328109
1892,"def modified ( self ) : <TAB>  paths = set ( ) <TAB>  dictionary_list = [ ] <TAB>  for op_list in self . _operations : <TAB><TAB>  if not isinstance ( op_list , list ) : <TAB><TAB><TAB>  op_list = ( op_list , ) <TAB><TAB>  for item in chain ( * op_list ) : <TAB><TAB><TAB>  if item is None : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  dictionary = item . dictionary <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  paths . add ( dictionary . path ) <TAB><TAB><TAB>  dictionary_list . append ( dictionary ) <TAB>  return dictionary_list ",if dictionary . path in paths :,"if not isinstance(dictionary, dict):",False,22.09805124039749,95.87812077512638
1893,"def __getitem__ ( self , key , _get_mode = False ) : <TAB>  if not _get_mode : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _list [ key ] <TAB><TAB>  elif isinstance ( key , slice ) : <TAB><TAB><TAB>  return self . __class__ ( self . _list [ key ] ) <TAB>  ikey = key . lower ( ) <TAB>  for k , v in self . _list : <TAB><TAB>  if k . lower ( ) == ikey : <TAB><TAB><TAB>  return v <TAB>  # micro optimization: if we are in get mode we will catch that <TAB>  # exception one stack level down so we can raise a standard <TAB>  # key error instead of our special one. <TAB>  if _get_mode : <TAB><TAB>  raise KeyError ( ) <TAB>  raise BadRequestKeyError ( key ) ","if isinstance ( key , ( int , long ) ) :","if isinstance(key, int):",False,63.21097700889675,97.19404314880101
1894,"def _get_items ( self , name , target = 1 ) : <TAB>  all_items = self . get_items ( name ) <TAB>  items = [ o for o in all_items if not o . disabled ] <TAB>  if len ( items ) < target : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB>  on = [ ] <TAB>  off = [ ] <TAB>  for o in items : <TAB><TAB>  if o . selected : <TAB><TAB><TAB>  on . append ( o ) <TAB><TAB>  else : <TAB><TAB><TAB>  off . append ( o ) <TAB>  return on , off ",if len ( all_items ) < target :,if len(items) == 0:,False,52.76305038875826,96.73964482578013
1895,"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB>  """"""Return standard location of genome directories."""""" <TAB>  if galaxy_dir : <TAB><TAB>  refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB><TAB>  seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB>  else : <TAB><TAB>  gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB><TAB>  if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) : <TAB><TAB><TAB>  return gdirs [ 0 ] ",if seq_file and os . path . exists ( seq_file ) :,if seq_file:,False,26.1096878702819,94.31517927788074
1896,"def _PrintFuncs ( self , names ) : <TAB>  # type: (List[str]) -> int <TAB>  status = 0 <TAB>  for name in names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( name ) <TAB><TAB><TAB>  # TODO: Could print LST for -f, or render LST.  Bash does this.  'trap' <TAB><TAB><TAB>  # could use that too. <TAB><TAB>  else : <TAB><TAB><TAB>  status = 1 <TAB>  return status ",if name in self . funcs :,"if name in ('-f', '-f', '-f', '-f', '-f',",False,41.84426606866112,90.83076487052722
1897,"def package_files ( self ) : <TAB>  seen_package_directories = ( ) <TAB>  directories = self . distribution . package_dir or { } <TAB>  empty_directory_exists = "" "" in directories <TAB>  packages = self . distribution . packages or [ ] <TAB>  for package in packages : <TAB><TAB>  if package in directories : <TAB><TAB><TAB>  package_directory = directories [ package ] <TAB><TAB>  elif empty_directory_exists : <TAB><TAB><TAB>  package_directory = os . path . join ( directories [ "" "" ] , package ) <TAB><TAB>  else : <TAB><TAB><TAB>  package_directory = package <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  seen_package_directories + = ( package_directory + "" . "" , ) <TAB><TAB><TAB>  yield package_directory ",if not package_directory . startswith ( seen_package_directories ) :,if package_directory not in seen_package_directories:,False,20.332494013857648,95.70302099239248
1898,"def apply_conf_file ( fn , conf_filename ) : <TAB>  for env in LSF_CONF_ENV : <TAB><TAB>  conf_file = get_conf_file ( conf_filename , env ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with open ( conf_file ) as conf_handle : <TAB><TAB><TAB><TAB>  value = fn ( conf_handle ) <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  return value <TAB>  return None ",if conf_file :,if conf_file:,False,51.1517928362655,100.00000000000004
1899,"def on_text ( self , text ) : <TAB>  if text != self . chosen_text : <TAB><TAB>  self . fail_test ( ' Expected  "" {} "" , received  "" {} "" ' . format ( self . chosen_text , text ) ) <TAB>  else : <TAB><TAB>  self . checks_passed + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . pass_test ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _select_next_text ( ) ",if self . checks_passed >= self . number_of_checks :,if self.checks_passed == 0:,False,19.744125643914582,90.93163484697376
1900,"def test_field_attr_existence ( self ) : <TAB>  for name , item in ast . __dict__ . items ( ) : <TAB><TAB>  if self . _is_ast_node ( name , item ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # Index(value) just returns value now. <TAB><TAB><TAB><TAB>  # The argument is required. <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  x = item ( ) <TAB><TAB><TAB>  if isinstance ( x , ast . AST ) : <TAB><TAB><TAB><TAB>  self . assertEqual ( type ( x . _fields ) , tuple ) ","if name == ""Index"" :","if not isinstance(item, (ast.Index, ast.Index)):",False,36.64971124386371,91.41623174282664
1901,"def apply ( self , response ) : <TAB>  updated_headers = self . update_headers ( response ) <TAB>  if updated_headers : <TAB><TAB>  response . headers . update ( updated_headers ) <TAB><TAB>  warning_header_value = self . warning ( response ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  response . headers . update ( { "" Warning "" : warning_header_value } ) <TAB>  return response ",if warning_header_value is not None :,if warning_header_value:,False,20.64347911143832,95.94842215381966
1902,"def validate ( self ) : <TAB>  self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB>  for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB><TAB>  self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB><TAB>  if self . use_parallel_executor and not self . use_double_buffer : <TAB><TAB><TAB>  self . validate_unordered_batch ( batch_in , batch_out ) <TAB><TAB>  else : <TAB><TAB><TAB>  for in_data , out_data in zip ( batch_in , batch_out ) : <TAB><TAB><TAB><TAB>  self . assertEqual ( in_data . shape , out_data . shape ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . assertTrue ( ( in_data == out_data ) . all ( ) ) ",if not self . use_parallel_executor :,if self.use_parallel_executor and (not self.use_double_buffer):,False,24.63706213624289,94.84311230565838
1903,def finalize ( self ) : <TAB>  if self . _started : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _queue . put ( None ) <TAB><TAB><TAB>  self . _queue . join ( ) <TAB><TAB><TAB>  self . _consumer . join ( ) <TAB><TAB>  self . _started = False <TAB>  self . _finalized = True ,if not self . _finalized :,if self._finalized:,False,38.49355972839675,97.47765987505922
1904,"def _get_ilo_version ( self ) : <TAB>  try : <TAB><TAB>  self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB>  except ResponseError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if e . code == 405 : <TAB><TAB><TAB><TAB>  return 3 <TAB><TAB><TAB>  if e . code == 501 : <TAB><TAB><TAB><TAB>  return 1 <TAB><TAB>  raise <TAB>  return 2 ","if hasattr ( e , ""code"" ) :",if e.code == 400:,False,23.48455524339628,94.00638300542505
1905,"def _check_data ( self , source , expected_bytes , expected_duration ) : <TAB>  received_bytes = 0 <TAB>  received_seconds = 0.0 <TAB>  bytes_to_read = 1024 <TAB>  while True : <TAB><TAB>  data = source . get_audio_data ( bytes_to_read ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  received_bytes + = data . length <TAB><TAB>  received_seconds + = data . duration <TAB><TAB>  self . assertEqual ( data . length , len ( data . data ) ) <TAB>  self . assertAlmostEqual ( expected_duration , received_seconds , places = 1 ) <TAB>  self . assertAlmostEqual ( expected_bytes , received_bytes , delta = 5 ) ",if data is None :,if not data:,False,18.79448541182158,97.626652961462
1906,"def __randomize_interval_task ( self ) : <TAB>  for job in self . aps_scheduler . get_jobs ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . aps_scheduler . modify_job ( <TAB><TAB><TAB><TAB>  job . id , <TAB><TAB><TAB><TAB>  next_run_time = datetime . now ( ) <TAB><TAB><TAB><TAB>  + timedelta ( <TAB><TAB><TAB><TAB><TAB>  seconds = randrange ( <TAB><TAB><TAB><TAB><TAB><TAB>  job . trigger . interval . total_seconds ( ) * 0.75 , <TAB><TAB><TAB><TAB><TAB><TAB>  job . trigger . interval . total_seconds ( ) , <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB>  ) ","if isinstance ( job . trigger , IntervalTrigger ) :",if job.id == self.job_id:,False,49.539613177412576,95.52287673702449
1907,"def find_approximant ( x ) : <TAB>  c = 1e-4 <TAB>  it = sympy . ntheory . continued_fraction_convergents ( <TAB><TAB>  sympy . ntheory . continued_fraction_iterator ( x ) <TAB>  ) <TAB>  for i in it : <TAB><TAB>  p , q = i . as_numer_denom ( ) <TAB><TAB>  tol = c / q * * 2 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return i <TAB><TAB>  if tol < machine_epsilon : <TAB><TAB><TAB>  break <TAB>  return x ",if abs ( i - x ) <= tol :,if tol < machine_epsilon:,False,22.997757932937965,93.14639259628883
1908,"def fix_newlines ( lines ) : <TAB>  """"""Convert newlines to unix."""""" <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  if line . endswith ( "" \r \n "" ) : <TAB><TAB><TAB>  lines [ i ] = line [ : - 2 ] + "" \n "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lines [ i ] = line [ : - 1 ] + "" \n "" ","elif line . endswith ( ""\r"" ) :",if line.endswith('\n'):,False,51.242447325465946,88.25910368876326
1909,"def payment_control_render ( self , request : HttpRequest , payment : OrderPayment ) : <TAB>  template = get_template ( "" pretixplugins/paypal/control.html "" ) <TAB>  sale_id = None <TAB>  for trans in payment . info_data . get ( "" transactions "" , [ ] ) : <TAB><TAB>  for res in trans . get ( "" related_resources "" , [ ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sale_id = res [ "" sale "" ] [ "" id "" ] <TAB>  ctx = { <TAB><TAB>  "" request "" : request , <TAB><TAB>  "" event "" : self . event , <TAB><TAB>  "" settings "" : self . settings , <TAB><TAB>  "" payment_info "" : payment . info_data , <TAB><TAB>  "" order "" : payment . order , <TAB><TAB>  "" sale_id "" : sale_id , <TAB>  } <TAB>  return template . render ( ctx ) ","if ""sale"" in res and ""id"" in res [ ""sale"" ] :",if res['sale']['id'] is not None:,False,48.61135529503818,93.39067725297085
1910,"def for_name ( self , name ) : <TAB>  try : <TAB><TAB>  name_resources = self . _resources [ name ] <TAB>  except KeyError : <TAB><TAB>  raise LookupError ( name ) <TAB>  else : <TAB><TAB>  for res in name_resources : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  inst = res . inst ( ) <TAB><TAB><TAB>  except Exception as e : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  log . exception ( "" error initializing  %s "" , res ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  log . error ( "" error initializing  %s :  %s "" , res , e ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield inst ",if log . getEffectiveLevel ( ) <= logging . DEBUG :,if e.args[0] == 'init':,False,49.44530119131522,95.28353961852247
1911,"def describe ( self , done = False ) : <TAB>  description = ShellCommand . describe ( self , done ) <TAB>  if done : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  description = [ "" compile "" ] <TAB><TAB>  description . append ( "" %d  projects "" % self . getStatistic ( "" projects "" , 0 ) ) <TAB><TAB>  description . append ( "" %d  files "" % self . getStatistic ( "" files "" , 0 ) ) <TAB><TAB>  warnings = self . getStatistic ( "" warnings "" , 0 ) <TAB><TAB>  if warnings > 0 : <TAB><TAB><TAB>  description . append ( "" %d  warnings "" % warnings ) <TAB><TAB>  errors = self . getStatistic ( "" errors "" , 0 ) <TAB><TAB>  if errors > 0 : <TAB><TAB><TAB>  description . append ( "" %d  errors "" % errors ) <TAB>  return description ",if not description :,if description is None:,False,43.00290116025559,98.00324117469137
1912,"def parse_list ( tl ) : <TAB>  ls = [ ] <TAB>  nm = [ ] <TAB>  while True : <TAB><TAB>  term , nmt , tl = parse_term ( tl ) <TAB><TAB>  ls . append ( term ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  nm . append ( nmt ) <TAB><TAB>  if tl [ 0 ] != "" , "" : <TAB><TAB><TAB>  break <TAB><TAB>  tl = tl [ 1 : ] <TAB>  return ls , nm , tl ",if nmt is not None :,if nmt:,False,27.73639005101322,96.59272713974649
1913,"def infer_dataset_impl ( path ) : <TAB>  if IndexedRawTextDataset . exists ( path ) : <TAB><TAB>  return "" raw "" <TAB>  elif IndexedDataset . exists ( path ) : <TAB><TAB>  with open ( index_file_path ( path ) , "" rb "" ) as f : <TAB><TAB><TAB>  magic = f . read ( 8 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return "" cached "" <TAB><TAB><TAB>  elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] : <TAB><TAB><TAB><TAB>  return "" mmap "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return None <TAB>  elif FastaDataset . exists ( path ) : <TAB><TAB>  return "" fasta "" <TAB>  else : <TAB><TAB>  return None ",if magic == IndexedDataset . _HDR_MAGIC :,if magic == MMapIndexedDataset.Index._HDR_MAGIC:,False,24.385065539607336,97.96444371972918
1914,"def _get ( self ) : <TAB>  fut = item = None <TAB>  with self . _mutex : <TAB><TAB>  # Critical section never blocks. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fut = Future ( ) <TAB><TAB><TAB>  fut . add_done_callback ( <TAB><TAB><TAB><TAB>  lambda f : self . _get_complete ( ) if not f . cancelled ( ) else None <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . _getters . append ( fut ) <TAB><TAB>  else : <TAB><TAB><TAB>  item = self . _get_item ( ) <TAB><TAB><TAB>  self . _get_complete ( ) <TAB>  return item , fut ",if not self . _queue or self . _getters :,if self._get_item() is None:,False,52.40746265757936,94.9697084134811
1915,"def validate ( self ) : <TAB>  dates = [ ] <TAB>  for d in self . get ( "" leave_block_list_dates "" ) : <TAB><TAB>  # date is not repeated <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . msgprint ( <TAB><TAB><TAB><TAB>  _ ( "" Date is repeated "" ) + "" : "" + d . block_date , raise_exception = 1 <TAB><TAB><TAB>  ) <TAB><TAB>  dates . append ( d . block_date ) ",if d . block_date in dates :,if d.date == 0:,False,52.30512397567634,95.30747278407871
1916,"def on_choose_watch_dir_clicked ( self ) : <TAB>  if self . window ( ) . watchfolder_enabled_checkbox . isChecked ( ) : <TAB><TAB>  previous_watch_dir = self . window ( ) . watchfolder_location_input . text ( ) or "" "" <TAB><TAB>  watch_dir = QFileDialog . getExistingDirectory ( <TAB><TAB><TAB>  self . window ( ) , <TAB><TAB><TAB>  "" Please select the watch folder "" , <TAB><TAB><TAB>  previous_watch_dir , <TAB><TAB><TAB>  QFileDialog . ShowDirsOnly , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  self . window ( ) . watchfolder_location_input . setText ( watch_dir ) ",if not watch_dir :,if watch_dir is None:,False,24.477503250863172,97.3610841055131
1917,"def log_generator ( self , limit = 6000 , * * kwargs ) : <TAB>  # Generator for show_log_panel <TAB>  skip = 0 <TAB>  while True : <TAB><TAB>  logs = self . log ( limit = limit , skip = skip , * * kwargs ) <TAB><TAB>  if not logs : <TAB><TAB><TAB>  break <TAB><TAB>  for entry in logs : <TAB><TAB><TAB>  yield entry <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  skip = skip + limit ",if len ( logs ) < limit :,if skip >= limit:,False,38.03262610015295,95.30142583880928
1918,"def _setUpClass ( cls ) : <TAB>  global solver <TAB>  import pyomo . environ <TAB>  from pyomo . solvers . tests . io . writer_test_cases import testCases <TAB>  for test_case in testCases : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  solver [ ( test_case . name , test_case . io ) ] = True ","if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :",if test_case.name == 'test' and test_case.io is not None,False,43.662502968248674,80.65408108203644
1919,"def _get_file_data ( self , normpath , normrev ) : <TAB>  data = self . client . cat ( normpath , normrev ) <TAB>  if has_expanded_svn_keywords ( data ) : <TAB><TAB>  # Find out if this file has any keyword expansion set. <TAB><TAB>  # If it does, collapse these keywords. This is because SVN <TAB><TAB>  # will return the file expanded to us, which would break patching. <TAB><TAB>  keywords = self . client . propget ( "" svn:keywords "" , normpath , normrev , recurse = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = collapse_svn_keywords ( data , force_bytes ( keywords [ normpath ] ) ) <TAB>  return data ",if normpath in keywords :,if keywords:,False,68.25144221299496,97.97960999188328
1920,"def add_controller_list ( path ) : <TAB>  if not os . path . exists ( os . path . join ( path , "" __init__.py "" ) ) : <TAB><TAB>  bb . fatal ( "" Controllers directory  %s  exists but is missing __init__.py "" % path ) <TAB>  files = sorted ( <TAB><TAB>  [ f for f in os . listdir ( path ) if f . endswith ( "" .py "" ) and not f . startswith ( "" _ "" ) ] <TAB>  ) <TAB>  for f in files : <TAB><TAB>  module = "" oeqa.controllers. "" + f [ : - 3 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  controllerslist . append ( module ) <TAB><TAB>  else : <TAB><TAB><TAB>  bb . warn ( <TAB><TAB><TAB><TAB>  "" Duplicate controller module found for  %s , only one added. Layers should create unique controller module names "" <TAB><TAB><TAB><TAB>  % module <TAB><TAB><TAB>  ) ",if module not in controllerslist :,if module in controllerslist:,False,62.097843696532486,98.0038225164117
1921,"def on_session2 ( event ) : <TAB>  new_xmpp . get_roster ( ) <TAB>  new_xmpp . send_presence ( ) <TAB>  logging . info ( roster [ 0 ] ) <TAB>  data = roster [ 0 ] [ "" roster "" ] [ "" items "" ] <TAB>  logging . info ( data ) <TAB>  for jid , item in data . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_xmpp . send_presence ( ptype = "" subscribe "" , pto = jid ) <TAB><TAB>  new_xmpp . update_roster ( jid , name = item [ "" name "" ] , groups = item [ "" groups "" ] ) <TAB>  new_xmpp . disconnect ( ) ","if item [ ""subscription"" ] != ""none"" :",if jid != new_xmpp.get_jid():,False,49.36950579830443,92.72087515395025
1922,"def _parse_class_simplified ( symbol ) : <TAB>  results = { } <TAB>  name = symbol . name + "" ( "" <TAB>  name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB>  name + = "" ) "" <TAB>  for sym in symbol . body : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = _parse_function_simplified ( sym , symbol . name ) <TAB><TAB><TAB>  results . update ( result ) <TAB><TAB>  elif isinstance ( sym , ast . ClassDef ) : <TAB><TAB><TAB>  result = _parse_class_simplified ( sym ) <TAB><TAB><TAB>  results . update ( result ) <TAB>  lineno = symbol . lineno <TAB>  for decorator in symbol . decorator_list : <TAB><TAB>  lineno + = 1 <TAB>  results [ lineno ] = ( name , "" c "" ) <TAB>  return results ","if isinstance ( sym , ast . FunctionDef ) :","if isinstance(sym, ast.FunctionDef):",False,21.098117277390394,100.00000000000004
1923,"def check_args ( args ) : <TAB>  """"""Checks that the args are coherent."""""" <TAB>  check_args_has_attributes ( args ) <TAB>  if args . v : <TAB><TAB>  non_version_attrs = [ v for k , v in args . __dict__ . items ( ) if k != "" v "" ] <TAB><TAB>  print ( "" non_version_attrs "" , non_version_attrs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fail ( "" Cannot show the version number with another command. "" ) <TAB><TAB>  return <TAB>  if args . i is None : <TAB><TAB>  fail ( "" Cannot draw ER diagram of no database. "" ) <TAB>  if args . o is None : <TAB><TAB>  fail ( "" Cannot draw ER diagram with no output file. "" ) ",if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,if not args.v:,False,30.300874219282203,89.38414143618566
1924,"def handle ( self , * args , * * options ) : <TAB>  if not settings . ST_BASE_DIR . endswith ( "" spirit "" ) : <TAB><TAB>  raise CommandError ( <TAB><TAB><TAB>  "" settings.ST_BASE_DIR is not the spirit root folder, are you overriding it? "" <TAB><TAB>  ) <TAB>  for root , dirs , files in os . walk ( settings . ST_BASE_DIR ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  with utils . pushd ( root ) : <TAB><TAB><TAB>  call_command ( <TAB><TAB><TAB><TAB>  "" makemessages "" , stdout = self . stdout , stderr = self . stderr , * * options <TAB><TAB><TAB>  ) <TAB>  self . stdout . write ( "" ok "" ) ","if ""locale"" not in dirs :",if root == settings.ST_BASE_DIR:,False,57.13187812233831,94.50605835717514
1925,"def scan ( scope ) : <TAB>  for s in scope . children : <TAB><TAB>  if s . start_pos < = position < = s . end_pos : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return scan ( s ) or s <TAB><TAB><TAB>  elif s . type in ( "" suite "" , "" decorated "" ) : <TAB><TAB><TAB><TAB>  return scan ( s ) <TAB>  return None ","if isinstance ( s , ( tree . Scope , tree . Flow ) ) :","if s.type in (""suite"", ""decorated""):",False,20.19045772648841,89.37328342499535
1926,def run_sync ( self ) : <TAB>  count = 0 <TAB>  while count < self . args . num_messages : <TAB><TAB>  batch = self . receiver . fetch_next ( max_batch_size = self . args . num_messages - count ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for msg in batch : <TAB><TAB><TAB><TAB>  msg . complete ( ) <TAB><TAB>  count + = len ( batch ) ,if self . args . peeklock :,if batch:,False,19.635100229006223,94.34280697245599
1927,"def __getitem__ ( self , item ) : <TAB>  if self . _datas is not None : <TAB><TAB>  ret = [ ] <TAB><TAB>  for data in self . _datas : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret . append ( data [ self . _offset ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret . append ( data . iloc [ self . _offset ] ) <TAB><TAB>  self . _offset + = 1 <TAB><TAB>  return ret <TAB>  else : <TAB><TAB>  return self . _get_data ( item ) ","if isinstance ( data , np . ndarray ) :",if self._offset < len(data.iloc):,False,46.38052569556771,93.8588166388964
1928,"def removedir ( self , path ) : <TAB>  # type: (Text) -> None <TAB>  _path = self . validatepath ( path ) <TAB>  if _path == "" / "" : <TAB><TAB>  raise errors . RemoveRootError ( ) <TAB>  with ftp_errors ( self , path ) : <TAB><TAB>  try : <TAB><TAB><TAB>  self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB><TAB>  except error_perm as error : <TAB><TAB><TAB>  code , _ = _parse_ftp_error ( error ) <TAB><TAB><TAB>  if code == "" 550 "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise errors . DirectoryExpected ( path ) <TAB><TAB><TAB><TAB>  if not self . isempty ( path ) : <TAB><TAB><TAB><TAB><TAB>  raise errors . DirectoryNotEmpty ( path ) <TAB><TAB><TAB>  raise<TAB># pragma: no cover ",if self . isfile ( path ) :,"if code == ""404':",False,27.339960140749575,95.72019473760653
1929,"def replaces_in_file ( file , replacement_list ) : <TAB>  rs = [ ( re . compile ( regexp ) , repl ) for ( regexp , repl ) in replacement_list ] <TAB>  file_tmp = file + "" . "" + str ( os . getpid ( ) ) + "" .tmp "" <TAB>  with open ( file , "" r "" ) as f : <TAB><TAB>  with open ( file_tmp , "" w "" ) as f_tmp : <TAB><TAB><TAB>  for line in f : <TAB><TAB><TAB><TAB>  for r , replace in rs : <TAB><TAB><TAB><TAB><TAB>  match = r . search ( line ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  line = replace + "" \n "" <TAB><TAB><TAB><TAB>  f_tmp . write ( line ) <TAB>  shutil . move ( file_tmp , file ) ",if match :,if match:,False,51.921256202432176,100.00000000000004
1930,"def _get_path_check_mem ( self , i , size ) : <TAB>  if size > 0 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p = self . _get_path ( i , - 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  p = self . _get_path ( i , size ) <TAB><TAB><TAB>  if p . startswith ( "" /dev/shm "" ) : <TAB><TAB><TAB><TAB>  env . meminfo . add ( size ) <TAB>  else : <TAB><TAB>  p = self . _get_path ( i , size ) <TAB>  return p ",if env . meminfo . rss + size > env . meminfo . mem_limit_soft :,if size == 0:,False,45.042243990454764,87.70150276906446
1931,"def find_widget_by_id ( self , id , parent = None ) : <TAB>  """"""Recursively searches for widget with specified ID"""""" <TAB>  if parent == None : <TAB><TAB>  if id in self : <TAB><TAB><TAB>  return self [ id ]<TAB># Do things fast if possible <TAB><TAB>  parent = self [ "" editor "" ] <TAB>  for c in parent . get_children ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if c . get_id ( ) == id : <TAB><TAB><TAB><TAB>  return c <TAB><TAB>  if isinstance ( c , Gtk . Container ) : <TAB><TAB><TAB>  r = self . find_widget_by_id ( id , c ) <TAB><TAB><TAB>  if not r is None : <TAB><TAB><TAB><TAB>  return r <TAB>  return None ","if hasattr ( c , ""get_id"" ) :",if c.get_type() == gtk.gdk.TYPE_ACTION:,False,39.81516569944494,91.34294472696011
1932,"def _deserialize ( cls , io ) : <TAB>  flags = VideoFlags ( ) <TAB>  flags . byte = U8 . read ( io ) <TAB>  if flags . bit . type == VIDEO_FRAME_TYPE_COMMAND_FRAME : <TAB><TAB>  data = VideoCommandFrame . deserialize ( io ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = AVCVideoData . deserialize ( io ) <TAB><TAB>  else : <TAB><TAB><TAB>  data = io . read ( ) <TAB>  return cls ( flags . bit . type , flags . bit . codec , data ) ",if flags . bit . codec == VIDEO_CODEC_ID_AVC :,if flags.bit.type == VIDEO_FRAME_TYPE_AVAIL:,False,33.98310290849798,94.35413414434824
1933,"def asciiLogData ( data , maxlen = 64 , replace = False ) : <TAB>  ellipses = ""  ... "" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dd = data [ : maxlen ] + ellipses <TAB><TAB>  else : <TAB><TAB><TAB>  dd = data <TAB><TAB>  return dd . decode ( "" utf8 "" , errors = "" replace "" if replace else "" strict "" ) <TAB>  except : <TAB><TAB>  return "" 0x "" + binLogData ( data , maxlen ) ",if len ( data ) > maxlen - len ( ellipses ) :,if len(data) > maxlen:,False,46.75602085899491,95.09245634043207
1934,"def _check_units ( self , new_unit_system ) : <TAB>  # If no unit system has been specified for me yet, adopt the incoming <TAB>  # system <TAB>  if self . unit_system is None : <TAB><TAB>  self . unit_system = new_unit_system <TAB>  else : <TAB><TAB>  # Otherwise, make sure they match <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Unit system mismatch  %d  v.  %d "" % ( self . unit_system , new_unit_system ) <TAB><TAB><TAB>  ) ",if self . unit_system != new_unit_system :,if self.unit_system != new_unit_system:,False,41.59129450252843,100.00000000000004
1935,"def command ( filenames , dirnames , fix ) : <TAB>  for filename in gather_files ( dirnames , filenames ) : <TAB><TAB>  visitor = process_file ( filename ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB><TAB><TAB>  if fix : <TAB><TAB><TAB><TAB>  print ( "" Fixing:  %s "" % filename ) <TAB><TAB><TAB><TAB>  fix_file ( filename ) ",if visitor . needs_fix ( ) :,if visitor:,False,22.413894740410207,94.4472286333266
1936,"def assign_attributes_to_variants ( variant_attributes ) : <TAB>  for value in variant_attributes : <TAB><TAB>  pk = value [ "" pk "" ] <TAB><TAB>  defaults = value [ "" fields "" ] <TAB><TAB>  defaults [ "" variant_id "" ] = defaults . pop ( "" variant "" ) <TAB><TAB>  defaults [ "" assignment_id "" ] = defaults . pop ( "" assignment "" ) <TAB><TAB>  assigned_values = defaults . pop ( "" values "" ) <TAB><TAB>  assoc , created = AssignedVariantAttribute . objects . update_or_create ( <TAB><TAB><TAB>  pk = pk , defaults = defaults <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assoc . values . set ( AttributeValue . objects . filter ( pk__in = assigned_values ) ) ",if created :,if created:,False,51.11137411113378,100.00000000000004
1937,"def _info ( self , userlist ) : <TAB>  for strng in userlist : <TAB><TAB>  group_matched = False <TAB><TAB>  for env in self . base . comps . environments_by_pattern ( strng ) : <TAB><TAB><TAB>  self . output . display_groups_in_environment ( env ) <TAB><TAB><TAB>  group_matched = True <TAB><TAB>  for group in self . base . comps . groups_by_pattern ( strng ) : <TAB><TAB><TAB>  self . output . display_pkgs_in_groups ( group ) <TAB><TAB><TAB>  group_matched = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . error ( _ ( "" Warning: Group  %s  does not exist. "" ) , strng ) <TAB>  return 0 , [ ] ",if not group_matched :,if not group_matched:,False,54.66434128904145,100.00000000000004
1938,"def parse_implements_interfaces ( parser ) : <TAB>  types = [ ] <TAB>  if parser . token . value == "" implements "" : <TAB><TAB>  advance ( parser ) <TAB><TAB>  while True : <TAB><TAB><TAB>  types . append ( parse_named_type ( parser ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB>  return types ","if not peek ( parser , TokenKind . NAME ) :",if types is None:,False,47.266455198284866,90.32178958689694
1939,"def generate ( ) : <TAB>  for leaf in u . leaves : <TAB><TAB>  if isinstance ( leaf , Integer ) : <TAB><TAB><TAB>  val = leaf . get_int_value ( ) <TAB><TAB><TAB>  if val in ( 0 , 1 ) : <TAB><TAB><TAB><TAB>  yield val <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise _NoBoolVector <TAB><TAB>  elif isinstance ( leaf , Symbol ) : <TAB><TAB><TAB>  if leaf == SymbolTrue : <TAB><TAB><TAB><TAB>  yield 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield 0 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise _NoBoolVector <TAB><TAB>  else : <TAB><TAB><TAB>  raise _NoBoolVector ",elif leaf == SymbolFalse :,if leaf == SymbolFalse:,False,51.11484005249397,98.87760724645923
1940,"def update_gstin ( context ) : <TAB>  dirty = False <TAB>  for key , value in iteritems ( frappe . form_dict ) : <TAB><TAB>  if key != "" party "" : <TAB><TAB><TAB>  address_name = frappe . get_value ( "" Address "" , key ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  address = frappe . get_doc ( "" Address "" , address_name ) <TAB><TAB><TAB><TAB>  address . gstin = value . upper ( ) <TAB><TAB><TAB><TAB>  address . save ( ignore_permissions = True ) <TAB><TAB><TAB><TAB>  dirty = True <TAB>  if dirty : <TAB><TAB>  frappe . db . commit ( ) <TAB><TAB>  context . updated = True ",if address_name :,if address_name:,False,51.08410652748634,100.00000000000004
1941,"def everythingIsUnicode ( d ) : <TAB>  """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not everythingIsUnicode ( v ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  for i in v : <TAB><TAB><TAB><TAB>  if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB><TAB>  elif isinstance ( i , _bytes ) : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif isinstance ( v , _bytes ) : <TAB><TAB><TAB>  return False <TAB>  return True ","if isinstance ( v , dict ) and k != ""headers"" :","if isinstance(v, unicode):",False,31.372133848123053,95.50216394913603
1942,"def check_graph ( graph ) :<TAB># pragma: no cover <TAB>  for c in graph : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" cannot have fuse "" ) <TAB><TAB>  for inp in c . inputs : <TAB><TAB><TAB>  if isinstance ( inp . op , Fuse ) : <TAB><TAB><TAB><TAB>  raise RuntimeError ( "" cannot have fuse "" ) ","if isinstance ( c . op , Fuse ) :","if isinstance(c, Fuse):",False,9.62825167212658,94.37212449846362
1943,"def __getattr__ ( self , key ) : <TAB>  try : <TAB><TAB>  value = self . __parent . contents [ key ] <TAB>  except KeyError : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( value , _ModuleMarker ) : <TAB><TAB><TAB><TAB>  return value . mod_ns <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  assert isinstance ( value , _MultipleClassMarker ) <TAB><TAB><TAB><TAB>  return value . attempt_get ( self . __parent . path , key ) <TAB>  raise AttributeError ( <TAB><TAB>  "" Module  %r  has no mapped classes  "" <TAB><TAB>  "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB>  ) ",if value is not None :,if self.__parent.name == key:,False,53.42562994433941,94.68385102077828
1944,"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB>  assert nw_id != self . nw_id_unknown <TAB>  ret = [ ] <TAB>  for port in self . get_ports ( dpid ) : <TAB><TAB>  nw_id_ = port . network_id <TAB><TAB>  if port . port_no == in_port : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret . append ( port . port_no ) <TAB><TAB>  elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB><TAB><TAB>  ret . append ( port . port_no ) <TAB>  return ret ",if nw_id_ == nw_id :,if allow_nw_id_external is not None and nw_id_ == allow,False,31.691636322202182,93.5019210680802
1945,"def _parse ( self , contents ) : <TAB>  entries = [ ] <TAB>  for line in contents . splitlines ( ) : <TAB><TAB>  if not len ( line . strip ( ) ) : <TAB><TAB><TAB>  entries . append ( ( "" blank "" , [ line ] ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  entries . append ( ( "" option "" , [ head . split ( None ) , tail ] ) ) <TAB>  return entries ",if not len ( head ) :,if head is None or tail is None:,False,22.533788337664344,95.51994956589743
1946,"def _get_documented_completions ( self , table , startswith = None ) : <TAB>  names = [ ] <TAB>  for key , command in table . items ( ) : <TAB><TAB>  if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB><TAB><TAB>  # Don't tab complete undocumented commands/params <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if getattr ( command , "" positional_arg "" , False ) : <TAB><TAB><TAB>  continue <TAB><TAB>  names . append ( key ) <TAB>  return names ",if startswith is not None and not key . startswith ( startswith ) :,if key in self.documented_commands:,False,53.7697032085334,91.81481710841979
1947,"def _convert_example ( example , use_bfloat16 ) : <TAB>  """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB>  for key in list ( example . keys ( ) ) : <TAB><TAB>  val = example [ key ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = tf . sparse . to_dense ( val ) <TAB><TAB>  if val . dtype == tf . int64 : <TAB><TAB><TAB>  val = tf . cast ( val , tf . int32 ) <TAB><TAB>  if use_bfloat16 and val . dtype == tf . float32 : <TAB><TAB><TAB>  val = tf . cast ( val , tf . bfloat16 ) <TAB><TAB>  example [ key ] = val ",if tf . keras . backend . is_sparse ( val ) :,"if isinstance(val, (int64, float32)):",False,30.642968491017108,93.85513212055159
1948,"def _get_lang_zone ( self , lang ) : <TAB>  if lang not in self . _lang_zone_from_lang : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _lang_zone_from_lang [ lang ] = MultiLangZone ( self . mgr , lang ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _lang_zone_from_lang [ lang ] = LangZone ( self . mgr , lang ) <TAB>  return self . _lang_zone_from_lang [ lang ] ",if self . mgr . is_multilang ( lang ) :,if lang in self._lang_zone_from_lang:,False,46.777812706840706,90.98724765307516
1949,"def dispatch ( self , request , * args , * * kwargs ) : <TAB>  try : <TAB><TAB>  return super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB>  except Http404 as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  request . original_path_info = request . path_info <TAB><TAB><TAB><TAB>  request . path_info = settings . FEINCMS_CMS_404_PAGE <TAB><TAB><TAB><TAB>  response = super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB><TAB><TAB><TAB>  response . status_code = 404 <TAB><TAB><TAB><TAB>  return response <TAB><TAB><TAB>  except Http404 : <TAB><TAB><TAB><TAB>  raise e <TAB><TAB>  else : <TAB><TAB><TAB>  raise ",if settings . FEINCMS_CMS_404_PAGE :,if e.code == 404:,False,42.17897357983972,95.83520992630986
1950,"def _maybe_update_dropout ( self , step ) : <TAB>  for i in range ( len ( self . dropout_steps ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . model . update_dropout ( self . dropout [ i ] ) <TAB><TAB><TAB>  logger . info ( "" Updated dropout to  %f  from step  %d "" % ( self . dropout [ i ] , step ) ) ",if step > 1 and step == self . dropout_steps [ i ] + 1 :,if self.dropout[i] > step:,False,27.567965753715495,86.59293218337952
1951,"def bulk_move ( * args , * * kwargs ) : <TAB>  for arg in args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise PopupException ( _ ( "" Source path and destination path cannot be same "" ) ) <TAB><TAB>  request . fs . rename ( <TAB><TAB><TAB>  urllib . unquote ( arg [ "" src_path "" ] ) , urllib . unquote ( arg [ "" dest_path "" ] ) <TAB><TAB>  ) ","if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :",if arg['src_path'] != arg['dest_path']:,False,58.05807630982284,88.65902849987332
1952,"def asisWrite ( self , root ) : <TAB>  at , c = self , self . c <TAB>  try : <TAB><TAB>  c . endEditing ( ) <TAB><TAB>  c . init_error_dialogs ( ) <TAB><TAB>  fileName = at . initWriteIvars ( root , root . atAsisFileNodeName ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  at . addToOrphanList ( root ) <TAB><TAB><TAB>  return <TAB><TAB>  at . openOutputStream ( ) <TAB><TAB>  for p in root . self_and_subtree ( copy = False ) : <TAB><TAB><TAB>  at . writeAsisNode ( p ) <TAB><TAB>  contents = at . closeOutputStream ( ) <TAB><TAB>  at . replaceFile ( contents , at . encoding , fileName , root ) <TAB>  except Exception : <TAB><TAB>  at . writeException ( fileName , root ) ","if not at . precheck ( fileName , root ) :",if fileName == root.atAsisFileNodeName():,False,22.993726825060588,95.98745168323214
1953,"def next_event ( it ) : <TAB>  """"""read an event from an eventstream"""""" <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  line = next ( it ) <TAB><TAB>  except StopIteration : <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return json . loads ( line . split ( "" : "" , 1 ) [ 1 ] ) ","if line . startswith ( ""data:"" ) :",if line.startswith('event'):,False,56.55354323855853,95.18140420391134
1954,"def process_formdata ( self , valuelist ) : <TAB>  if valuelist : <TAB><TAB>  if valuelist [ 0 ] == "" __None "" : <TAB><TAB><TAB>  self . data = None <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . data = None <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  obj = self . queryset . get ( pk = valuelist [ 0 ] ) <TAB><TAB><TAB><TAB>  self . data = obj <TAB><TAB><TAB>  except DoesNotExist : <TAB><TAB><TAB><TAB>  self . data = None ",if self . queryset is None :,if valuelist[0] == '__None':,False,47.377926755829264,93.95754064779585
1955,"def _setResultsName ( self , name , listAllMatches = False ) : <TAB>  if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  "" {} : setting results name  {!r}  on  {}  expression  "" <TAB><TAB><TAB><TAB>  "" will return a list of all parsed tokens in an And alternative,  "" <TAB><TAB><TAB><TAB>  "" in prior versions only the first token was returned "" . format ( <TAB><TAB><TAB><TAB><TAB>  "" warn_multiple_tokens_in_named_alternation "" , <TAB><TAB><TAB><TAB><TAB>  name , <TAB><TAB><TAB><TAB><TAB>  type ( self ) . __name__ , <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  stacklevel = 3 , <TAB><TAB><TAB>  ) <TAB>  return super ( ) . _setResultsName ( name , listAllMatches ) ","if any ( isinstance ( e , And ) for e in self . exprs ) :",if not name:,False,57.73270344579551,93.96753908291643
1956,"def add ( request ) : <TAB>  form_type = "" servers "" <TAB>  if request . method == "" POST "" : <TAB><TAB>  form = BookMarkForm ( request . POST ) <TAB><TAB>  if form . is_valid ( ) : <TAB><TAB><TAB>  form_type = form . save ( ) <TAB><TAB><TAB>  messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  messages . add_message ( request , messages . INFO , form . errors ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  url = reverse ( "" servers "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  url = reverse ( "" metrics "" ) <TAB><TAB>  return redirect ( url ) <TAB>  else : <TAB><TAB>  return redirect ( reverse ( "" servers "" ) ) ","if form_type == ""server"" :","if request.method == ""GET':",False,18.268083702792463,96.41204921815056
1957,"def __init__ ( self , post_id , artist , page , tzInfo = None , dateFormat = None ) : <TAB>  self . imageUrls = list ( ) <TAB>  self . imageResizedUrls = list ( ) <TAB>  self . imageId = int ( post_id ) <TAB>  self . _tzInfo = tzInfo <TAB>  self . dateFormat = dateFormat <TAB>  if page is not None : <TAB><TAB>  post_json = demjson . decode ( page ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  artist_id = post_json [ "" data "" ] [ "" item "" ] [ "" user "" ] [ "" id "" ] <TAB><TAB><TAB>  self . artist = SketchArtist ( artist_id , page , tzInfo , dateFormat ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . artist = artist <TAB><TAB>  self . parse_post ( post_json [ "" data "" ] [ "" item "" ] ) ",if artist is None :,if artist is None:,False,51.4441493688356,100.00000000000004
1958,"def _create_batch_iterator ( <TAB>  self , <TAB>  mark_as_delete : Callable [ [ Any ] , None ] , <TAB>  to_key : Callable [ [ Any ] , Any ] , <TAB>  to_value : Callable [ [ Any ] , Any ] , <TAB>  batch : Iterable [ EventT ] ,  ) - > Iterable [ Tuple [ Any , Any ] ] : <TAB>  for event in batch : <TAB><TAB>  key = to_key ( event . key ) <TAB><TAB>  # to delete keys in the table we set the raw value to None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mark_as_delete ( key ) <TAB><TAB><TAB>  continue <TAB><TAB>  yield key , to_value ( event . value ) ",if event . message . value is None :,if key in self.keys:,False,55.040200263842586,95.59456029647926
1959,"def test_lc_numeric_nl_langinfo ( self ) : <TAB>  # Test nl_langinfo against known values <TAB>  tested = False <TAB>  for loc in candidate_locales : <TAB><TAB>  try : <TAB><TAB><TAB>  setlocale ( LC_NUMERIC , loc ) <TAB><TAB><TAB>  setlocale ( LC_CTYPE , loc ) <TAB><TAB>  except Error : <TAB><TAB><TAB>  continue <TAB><TAB>  for li , lc in ( ( RADIXCHAR , "" decimal_point "" ) , ( THOUSEP , "" thousands_sep "" ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tested = True <TAB>  if not tested : <TAB><TAB>  self . skipTest ( "" no suitable locales "" ) ","if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :",if li == lc:,False,28.96141507708278,87.95422661720018
1960,"def _level_up_logging ( self ) : <TAB>  for handler in self . log . handlers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if handler . level != logging . DEBUG : <TAB><TAB><TAB><TAB>  handler . setLevel ( logging . DEBUG ) <TAB><TAB><TAB><TAB>  self . log . debug ( "" Leveled up log file verbosity "" ) ","if issubclass ( handler . __class__ , logging . FileHandler ) :",if handler.level != logging.DEBUG:,False,25.416562976877906,86.9604771784393
1961,def _show_axes_changed ( self ) : <TAB>  marker = self . marker <TAB>  if ( self . _vtk_control is not None ) and ( marker is not None ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  marker . interactor = None <TAB><TAB><TAB>  marker . enabled = False <TAB><TAB>  else : <TAB><TAB><TAB>  marker . interactor = self . interactor <TAB><TAB><TAB>  marker . enabled = True <TAB><TAB>  self . render ( ) ,if not self . show_axes :,if self.interactor is None:,False,24.97303019842934,94.84796169072499
1962,"def handle_keypress ( self , rawKey , modifiers , key , * args ) : <TAB>  if self . recordKeyboard and self . __delayPassed ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . insideKeys = True <TAB><TAB><TAB>  self . targetParent . start_key_sequence ( ) <TAB><TAB>  modifierCount = len ( modifiers ) <TAB><TAB>  if ( <TAB><TAB><TAB>  modifierCount > 1 <TAB><TAB><TAB>  or ( modifierCount == 1 and Key . SHIFT not in modifiers ) <TAB><TAB><TAB>  or ( Key . SHIFT in modifiers and len ( rawKey ) > 1 ) <TAB><TAB>  ) : <TAB><TAB><TAB>  self . targetParent . append_hotkey ( rawKey , modifiers ) <TAB><TAB>  elif key not in MODIFIERS : <TAB><TAB><TAB>  self . targetParent . append_key ( key ) ",if not self . insideKeys :,if self.insideKeys:,False,43.5699684932228,98.84330912535471
1963,"def transform ( self , data ) : <TAB>  with timer ( "" transform  %s "" % self . name , logging . DEBUG ) : <TAB><TAB>  if self . operator in { "" lat "" , "" latitude "" } : <TAB><TAB><TAB>  return self . series ( data ) . apply ( GeoIP . get_latitude ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . series ( data ) . apply ( GeoIP . get_longitude ) <TAB><TAB>  elif self . operator in { "" acc "" , "" accuracy "" } : <TAB><TAB><TAB>  return self . series ( data ) . apply ( GeoIP . get_accuracy ) <TAB><TAB>  raise NameError ( "" Unknown GeoIP operator [lat, lon, acc]:  %s "" % self . operator ) ","elif self . operator in { ""lon"" , ""longitude"" } :","if self.operator in {'lon', 'latitude'}:",False,29.857797745564735,94.45048359916788
1964,"def _get_sidebar_selected ( self ) : <TAB>  sidebar_selected = None <TAB>  if self . businessline_id : <TAB><TAB>  sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sidebar_selected + = "" _s_ %s "" % self . service_id <TAB><TAB><TAB>  if self . environment_id : <TAB><TAB><TAB><TAB>  sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB>  return sidebar_selected ",if self . service_id :,if self.service_id:,False,17.03650707754558,100.00000000000004
1965,"def _run_response_middleware ( self , request , response , request_name = None ) : <TAB>  named_middleware = self . named_response_middleware . get ( request_name , deque ( ) ) <TAB>  applicable_middleware = self . response_middleware + named_middleware <TAB>  if applicable_middleware : <TAB><TAB>  for middleware in applicable_middleware : <TAB><TAB><TAB>  _response = middleware ( request , response ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  _response = await _response <TAB><TAB><TAB>  if _response : <TAB><TAB><TAB><TAB>  response = _response <TAB><TAB><TAB><TAB>  break <TAB>  return response ",if isawaitable ( _response ) :,if _response:,False,36.180714625263036,96.80182781449514
1966,"def populate_obj ( self , obj , name ) : <TAB>  field = getattr ( obj , name , None ) <TAB>  if field is not None : <TAB><TAB>  # If field should be deleted, clean it up <TAB><TAB>  if self . _should_delete : <TAB><TAB><TAB>  field . delete ( ) <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not field . grid_id : <TAB><TAB><TAB><TAB>  func = field . put <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  func = field . replace <TAB><TAB><TAB>  func ( <TAB><TAB><TAB><TAB>  self . data . stream , <TAB><TAB><TAB><TAB>  filename = self . data . filename , <TAB><TAB><TAB><TAB>  content_type = self . data . content_type , <TAB><TAB><TAB>  ) ","if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) :","if hasattr(field, 'grid_id'):",False,57.98354751546555,92.30302728135877
1967,"def _import_hash ( self , operator ) : <TAB>  # Import required modules into local namespace so that pipelines <TAB>  # may be evaluated directly <TAB>  for key in sorted ( operator . import_hash . keys ( ) ) : <TAB><TAB>  module_list = "" ,  "" . join ( sorted ( operator . import_hash [ key ] ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exec ( "" from  {}  import  {} "" . format ( key [ 4 : ] , module_list ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  exec ( "" from  {}  import  {} "" . format ( key , module_list ) ) <TAB><TAB>  for var in operator . import_hash [ key ] : <TAB><TAB><TAB>  self . operators_context [ var ] = eval ( var ) ","if key . startswith ( ""tpot."" ) :",if key.startswith('_'):,False,34.6415742731908,97.30816616030044
1968,"def remove_files ( folder , file_extensions ) : <TAB>  for f in os . listdir ( folder ) : <TAB><TAB>  f_path = os . path . join ( folder , f ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  extension = os . path . splitext ( f_path ) [ 1 ] <TAB><TAB><TAB>  if extension in file_extensions : <TAB><TAB><TAB><TAB>  os . remove ( f_path ) ",if os . path . isfile ( f_path ) :,if os.path.exists(f_path):,False,51.512405557725714,97.92923878387349
1969,"def clearBuffer ( self ) : <TAB>  if self . shouldLose == - 1 : <TAB><TAB>  return <TAB>  if self . producer : <TAB><TAB>  self . producer . resumeProducing ( ) <TAB>  if self . buffer : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . logFile . write ( "" loopback receiving  %s \n "" % repr ( self . buffer ) ) <TAB><TAB>  buffer = self . buffer <TAB><TAB>  self . buffer = b "" "" <TAB><TAB>  self . target . dataReceived ( buffer ) <TAB>  if self . shouldLose == 1 : <TAB><TAB>  self . shouldLose = - 1 <TAB><TAB>  self . target . connectionLost ( failure . Failure ( main . CONNECTION_DONE ) ) ",if self . logFile :,if self.logFile:,False,31.594477162604022,96.06193703128706
1970,"def write ( self , data ) : <TAB>  if mock_target . _mirror_on_stderr : <TAB><TAB>  if self . _write_line : <TAB><TAB><TAB>  sys . stderr . write ( fn + "" :  "" ) <TAB><TAB>  if bytes : <TAB><TAB><TAB>  sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  sys . stderr . write ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _write_line = True <TAB><TAB>  else : <TAB><TAB><TAB>  self . _write_line = False <TAB>  super ( Buffer , self ) . write ( data ) ","if ( data [ - 1 ] ) == ""\n"" :",if self._write_line:,False,45.612573928108255,92.88395729526981
1971,def stop ( self ) : <TAB>  self . queue_com . state_lock . acquire ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . queue_com . state = STOPPED <TAB><TAB><TAB>  self . remove ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  return False <TAB>  finally : <TAB><TAB>  self . queue_com . state_lock . release ( ) ,if self . queue_com . state == RUNNING and self . stop_task ( ) :,if self.queue_com.state == STOPPED:,False,36.698739294813215,91.56411289377854
1972,"def _handle_special_args ( self , pyobjects ) : <TAB>  if len ( pyobjects ) == len ( self . arguments . args ) : <TAB><TAB>  if self . arguments . vararg : <TAB><TAB><TAB>  pyobjects . append ( rope . base . builtins . get_list ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pyobjects . append ( rope . base . builtins . get_dict ( ) ) ",if self . arguments . kwarg :,if self.arguments.vararg:,False,26.06530711628278,97.63538529329718
1973,"def go_to_last_edit_location ( self ) : <TAB>  if self . last_edit_cursor_pos is not None : <TAB><TAB>  filename , position = self . last_edit_cursor_pos <TAB><TAB>  if not osp . isfile ( filename ) : <TAB><TAB><TAB>  self . last_edit_cursor_pos = None <TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  self . load ( filename ) <TAB><TAB><TAB>  editor = self . get_current_editor ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  editor . set_cursor_position ( position ) ",if position < editor . document ( ) . characterCount ( ) :,if editor:,False,21.412543708188185,93.09774607744318
1974,"def _create_sentence_objects ( self ) : <TAB>  """"""Returns a list of Sentence objects from the raw text."""""" <TAB>  sentence_objects = [ ] <TAB>  sent_tokenizer = SentenceTokenizer ( locale = self . language . code ) <TAB>  seq = Sequence ( self . raw ) <TAB>  seq = sent_tokenizer . transform ( seq ) <TAB>  for start_index , end_index in zip ( seq . idx [ : - 1 ] , seq . idx [ 1 : ] ) : <TAB><TAB>  # Sentences share the same models as their parent blob <TAB><TAB>  sent = seq . text [ start_index : end_index ] . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  s = Sentence ( sent , start_index = start_index , end_index = end_index ) <TAB><TAB>  s . detected_languages = self . detected_languages <TAB><TAB>  sentence_objects . append ( s ) <TAB>  return sentence_objects ",if not sent :,if sent == '':,False,61.524054648420744,96.3352417940316
1975,"def to_json_schema ( self , parent = None ) : <TAB>  schema = { } <TAB>  if not parent : <TAB><TAB>  schema [ "" title "" ] = self . title <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  schema [ "" description "" ] = self . description <TAB><TAB>  if self . has_default : <TAB><TAB><TAB>  schema [ "" default "" ] = self . default <TAB><TAB>  schema [ "" _required_ "" ] = self . required <TAB>  if self . null : <TAB><TAB>  schema [ "" type "" ] = [ "" string "" , "" null "" ] <TAB>  else : <TAB><TAB>  schema [ "" type "" ] = "" string "" <TAB>  if self . enum is not None : <TAB><TAB>  schema [ "" enum "" ] = self . enum <TAB>  return schema ",if self . description :,if self.description:,False,50.69308254555802,100.00000000000004
1976,def rmdir ( dirname ) : <TAB>  if dirname [ - 1 ] == os . sep : <TAB><TAB>  dirname = dirname [ : - 1 ] <TAB>  if os . path . islink ( dirname ) : <TAB><TAB>  return<TAB># do not clear link - we can get out of dir <TAB>  for f in os . listdir ( dirname ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  path = dirname + os . sep + f <TAB><TAB>  if os . path . isdir ( path ) : <TAB><TAB><TAB>  rmdir ( path ) <TAB><TAB>  else : <TAB><TAB><TAB>  os . unlink ( path ) <TAB>  os . rmdir ( dirname ) ,"if f in ( ""."" , "".."" ) :",if f == os.sep:,False,31.538265805782896,89.67165164534954
1977,"def convert_whole_dir ( path = Path ( "" marian_ckpt/ "" ) ) : <TAB>  for subdir in tqdm ( list ( path . ls ( ) ) ) : <TAB><TAB>  dest_dir = f "" marian_converted/ { subdir . name } "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  convert ( source_dir , dest_dir ) ","if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :",if not os.path.exists(dest_dir):,False,25.921381028534046,87.51194096996618
1978,"def colorformat ( text ) : <TAB>  if text [ 0 : 1 ] == "" # "" : <TAB><TAB>  col = text [ 1 : ] <TAB><TAB>  if len ( col ) == 6 : <TAB><TAB><TAB>  return col <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB>  elif text == "" "" : <TAB><TAB>  return "" "" <TAB>  assert False , "" wrong color format  %r "" % text ",elif len ( col ) == 3 :,if len(col) == 3:,False,30.981660813155536,98.18487054407757
1979,"def _init_rel_seek ( self ) : <TAB>  "" Sets the file object ' s position to the relative location set above. "" <TAB>  rs , fo = self . _rel_seek , self . _file_obj <TAB>  if rs == 0.0 : <TAB><TAB>  fo . seek ( 0 , os . SEEK_SET ) <TAB>  else : <TAB><TAB>  fo . seek ( 0 , os . SEEK_END ) <TAB><TAB>  size = fo . tell ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _cur_pos = size <TAB><TAB>  else : <TAB><TAB><TAB>  target = int ( size * rs ) <TAB><TAB><TAB>  fo . seek ( target , os . SEEK_SET ) <TAB><TAB><TAB>  self . _align_to_newline ( ) <TAB><TAB><TAB>  self . _cur_pos = fo . tell ( ) ",if rs == 1.0 :,if rs == 0.0:,False,43.29050174340637,96.89935718551868
1980,"def parse_command_line ( self , argv = None ) : <TAB>  """"""Parse the command line"""""" <TAB>  if self . config : <TAB><TAB>  parser = argparse . ArgumentParser ( add_help = False ) <TAB><TAB>  self . settings [ "" config "" ] . add_argument ( parser ) <TAB><TAB>  opts , _ = parser . parse_known_args ( argv ) <TAB><TAB>  if opts . config is not None : <TAB><TAB><TAB>  self . set ( "" config "" , opts . config ) <TAB><TAB>  self . params . update ( self . import_from_module ( ) ) <TAB>  parser = self . parser ( ) <TAB>  opts = parser . parse_args ( argv ) <TAB>  for k , v in opts . __dict__ . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  self . set ( k . lower ( ) , v ) ",if v is None :,if k.lower() == 'config':,False,24.311563467586854,95.97950218327803
1981,"def process ( self , resources , event = None ) : <TAB>  client = local_session ( self . manager . session_factory ) . client ( <TAB><TAB>  "" shield "" , region_name = "" us-east-1 "" <TAB>  ) <TAB>  protections = get_type_protections ( client , self . manager . get_model ( ) ) <TAB>  protected_resources = { p [ "" ResourceArn "" ] for p in protections } <TAB>  state = self . data . get ( "" state "" , False ) <TAB>  results = [ ] <TAB>  for arn , r in zip ( self . manager . get_arns ( resources ) , resources ) : <TAB><TAB>  r [ "" c7n:ShieldProtected "" ] = shielded = arn in protected_resources <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  results . append ( r ) <TAB><TAB>  elif not shielded and not state : <TAB><TAB><TAB>  results . append ( r ) <TAB>  return results ",if shielded and state :,if shielded and state:,False,56.99677414784132,100.00000000000004
1982,"def removeTrailingWs ( self , aList ) : <TAB>  i = 0 <TAB>  while i < len ( aList ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  j = i <TAB><TAB><TAB>  i = self . skip_ws ( aList , i ) <TAB><TAB><TAB>  assert j < i <TAB><TAB><TAB>  if i > = len ( aList ) or aList [ i ] == "" \n "" : <TAB><TAB><TAB><TAB>  # print ""removing trailing ws:"", `i-j` <TAB><TAB><TAB><TAB>  del aList [ j : i ] <TAB><TAB><TAB><TAB>  i = j <TAB><TAB>  else : <TAB><TAB><TAB>  i + = 1 ",if self . is_ws ( aList [ i ] ) :,if aList[i] == '\n':,False,49.567048555937134,94.8996425177695
1983,"def predict ( request : Request ) : <TAB>  form = await request . form ( ) <TAB>  files , entry = convert_input ( form ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return JSONResponse ( ALL_FEATURES_PRESENT_ERROR , status_code = 400 ) <TAB><TAB>  try : <TAB><TAB><TAB>  resp = model . predict ( data_dict = [ entry ] ) . to_dict ( "" records "" ) [ 0 ] <TAB><TAB><TAB>  return JSONResponse ( resp ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  logger . error ( "" Error:  {} "" . format ( str ( e ) ) ) <TAB><TAB><TAB>  return JSONResponse ( COULD_NOT_RUN_INFERENCE_ERROR , status_code = 500 ) <TAB>  finally : <TAB><TAB>  for f in files : <TAB><TAB><TAB>  os . remove ( f . name ) ",if ( entry . keys ( ) & input_features ) != input_features :,if not files:,False,22.398974941629127,92.64985581813795
1984,"def reset ( self ) : <TAB>  logger . debug ( "" Arctic.reset() "" ) <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __conn . close ( ) <TAB><TAB><TAB>  self . __conn = None <TAB><TAB>  for _ , l in self . _library_cache . items ( ) : <TAB><TAB><TAB>  if hasattr ( l , "" _reset "" ) and callable ( l . _reset ) : <TAB><TAB><TAB><TAB>  logger . debug ( "" Library reset()  %s "" % l ) <TAB><TAB><TAB><TAB>  l . _reset ( )<TAB># the existence of _reset() is not guaranteed/enforced, it also triggers re-auth ",if self . __conn is not None :,if self.__conn:,False,50.370349052045995,96.8526537576017
1985,"def read ( self ) : <TAB>  if op . isfile ( self . fileName ) : <TAB><TAB>  with textfile_open ( self . fileName , "" rt "" ) as fid : <TAB><TAB><TAB>  items = json . load ( fid ) <TAB><TAB><TAB>  # TODO: catch JSON exception... <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  items = dict ( ) <TAB>  else : <TAB><TAB>  items = dict ( ) <TAB>  self . _items . clear ( ) <TAB>  self . _items . update ( items ) <TAB>  self . _haveReadData = True ",if items is None :,if items is None:,False,52.367096661215754,100.00000000000004
1986,"def get_django_comment ( text : str , i : int ) - > str : <TAB>  end = i + 4 <TAB>  unclosed_end = 0 <TAB>  while end < = len ( text ) : <TAB><TAB>  if text [ end - 2 : end ] == "" #} "" : <TAB><TAB><TAB>  return text [ i : end ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  unclosed_end = end <TAB><TAB>  end + = 1 <TAB>  raise TokenizationException ( "" Unclosed comment "" , text [ i : unclosed_end ] ) ","if not unclosed_end and text [ end ] == ""<"" :",if text[end] == '#':,False,23.783128824011346,92.59646646663872
1987,"def _wrap_forwarded ( self , key , value ) : <TAB>  if isinstance ( value , SourceCode ) and value . late_binding : <TAB><TAB>  # get cached return value if present <TAB><TAB>  value_ = self . _late_binding_returnvalues . get ( key , KeyError ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # evaluate the late-bound function <TAB><TAB><TAB>  value_ = self . _eval_late_binding ( value ) <TAB><TAB><TAB>  schema = self . late_bind_schemas . get ( key ) <TAB><TAB><TAB>  if schema is not None : <TAB><TAB><TAB><TAB>  value_ = schema . validate ( value_ ) <TAB><TAB><TAB>  # cache result of late bound func <TAB><TAB><TAB>  self . _late_binding_returnvalues [ key ] = value_ <TAB><TAB>  return value_ <TAB>  else : <TAB><TAB>  return value ",if value_ is KeyError :,if value_ is not None:,False,58.557990592711015,98.51664835586153
1988,"def connect ( * args , * * ckwargs ) : <TAB>  if "" give_content_type "" in kwargs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs [ "" give_content_type "" ] ( args [ 6 ] [ "" content-type "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  kwargs [ "" give_content_type "" ] ( "" "" ) <TAB>  if "" give_connect "" in kwargs : <TAB><TAB>  kwargs [ "" give_connect "" ] ( * args , * * ckwargs ) <TAB>  status = code_iter . next ( ) <TAB>  etag = etag_iter . next ( ) <TAB>  timestamp = timestamps_iter . next ( ) <TAB>  if status == - 1 : <TAB><TAB>  raise HTTPException ( ) <TAB>  return FakeConn ( status , etag , body = kwargs . get ( "" body "" , "" "" ) , timestamp = timestamp ) ","if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :","if args[6][""content-type""]:",False,45.73558187975953,91.91802610104598
1989,"def _reset ( self ) : <TAB>  self . _handle_connect ( ) <TAB>  if self . rewarder_session : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  env_id = random . choice ( self . _sample_env_ids ) <TAB><TAB><TAB>  logger . info ( "" Randomly sampled env_id= {} "" . format ( env_id ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  env_id = None <TAB><TAB>  self . rewarder_session . reset ( env_id = env_id ) <TAB>  else : <TAB><TAB>  logger . info ( <TAB><TAB><TAB>  "" No rewarder session exists, so cannot send a reset via the rewarder channel "" <TAB><TAB>  ) <TAB>  self . _reset_mask ( ) <TAB>  return [ None ] * self . n ",if self . _sample_env_ids :,if self.rewarder_session.running:,False,60.83355173087779,96.5840730304221
1990,"def _create_architecture_list ( architectures , current_arch ) : <TAB>  if not architectures : <TAB><TAB>  return [ _Architecture ( build_on = [ current_arch ] ) ] <TAB>  build_architectures : List [ str ] = [ ] <TAB>  architecture_list : List [ _Architecture ] = [ ] <TAB>  for item in architectures : <TAB><TAB>  if isinstance ( item , str ) : <TAB><TAB><TAB>  build_architectures . append ( item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  architecture_list . append ( <TAB><TAB><TAB><TAB>  _Architecture ( build_on = item . get ( "" build-on "" ) , run_on = item . get ( "" run-on "" ) ) <TAB><TAB><TAB>  ) <TAB>  if build_architectures : <TAB><TAB>  architecture_list . append ( _Architecture ( build_on = build_architectures ) ) <TAB>  return architecture_list ","if isinstance ( item , dict ) :",if build_on:,False,49.98811582266712,96.72831578366426
1991,"def inspect ( self , pokemon ) : <TAB>  # Make sure it was not caught! <TAB>  for caught_pokemon in self . cache : <TAB><TAB>  same_latitude = "" {0:.4f} "" . format ( pokemon [ "" latitude "" ] ) == "" {0:.4f} "" . format ( <TAB><TAB><TAB>  caught_pokemon [ "" latitude "" ] <TAB><TAB>  ) <TAB><TAB>  same_longitude = "" {0:.4f} "" . format ( pokemon [ "" longitude "" ] ) == "" {0:.4f} "" . format ( <TAB><TAB><TAB>  caught_pokemon [ "" longitude "" ] <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB>  if len ( self . cache ) > = 200 : <TAB><TAB>  self . cache . pop ( 0 ) <TAB>  self . cache . append ( pokemon ) ",if same_latitude and same_longitude :,if same_latitude == same_longitude:,False,30.64119726189551,98.43716152199444
1992,"def parley ( self ) : <TAB>  for x in [ 0 , 1 ] : <TAB><TAB>  a = self . agents [ x ] . act ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" [DONE] "" in a [ "" text "" ] : <TAB><TAB><TAB><TAB>  self . agents [ x - 1 ] . observe ( <TAB><TAB><TAB><TAB><TAB>  { "" id "" : "" World "" , "" text "" : "" The other agent has ended the chat. "" } <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  self . episodeDone = True <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . agents [ x - 1 ] . observe ( a ) ",if a is not None :,"if a and a['id'] == ""World':",False,25.695878807165396,94.83536035622835
1993,"def _prepare_subset ( <TAB>  full_data : torch . Tensor , <TAB>  full_targets : torch . Tensor , <TAB>  num_samples : int , <TAB>  digits : Sequence ,  ) : <TAB>  classes = { d : 0 for d in digits } <TAB>  indexes = [ ] <TAB>  for idx , target in enumerate ( full_targets ) : <TAB><TAB>  label = target . item ( ) <TAB><TAB>  if classes . get ( label , float ( "" inf "" ) ) > = num_samples : <TAB><TAB><TAB>  continue <TAB><TAB>  indexes . append ( idx ) <TAB><TAB>  classes [ label ] + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  data = full_data [ indexes ] <TAB>  targets = full_targets [ indexes ] <TAB>  return data , targets ",if all ( classes [ k ] >= num_samples for k in classes ) :,if indexes == full_data:,False,30.996711254361532,92.10344363819314
1994,"def get_work_root ( self , flags ) : <TAB>  _flags = flags . copy ( ) <TAB>  _flags [ "" is_toplevel "" ] = True <TAB>  target = self . _get_target ( _flags ) <TAB>  if target : <TAB><TAB>  _flags [ "" target "" ] = target . name <TAB><TAB>  tool = self . get_tool ( _flags ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return target . name + "" - "" + tool <TAB><TAB>  else : <TAB><TAB><TAB>  raise SyntaxError ( <TAB><TAB><TAB><TAB>  "" Failed to determine work root. Could not resolve tool for target  "" <TAB><TAB><TAB><TAB>  + target . name <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise SyntaxError ( "" Failed to determine work root. Could not resolve target "" ) ",if tool :,if tool:,False,63.04766831136346,100.00000000000004
1995,"def run_command ( self , data ) : <TAB>  """"""Run editor commands."""""" <TAB>  parts = data . split ( "" "" ) <TAB>  cmd = parts [ 0 ] . lower ( ) <TAB>  if cmd in self . operations . keys ( ) : <TAB><TAB>  return self . run_operation ( cmd ) <TAB>  args = "" "" . join ( parts [ 1 : ] ) <TAB>  self . logger . debug ( "" Looking for command  ' {0} ' "" . format ( cmd ) ) <TAB>  if cmd in self . modules . modules . keys ( ) : <TAB><TAB>  self . logger . debug ( "" Trying to run command  ' {0} ' "" . format ( cmd ) ) <TAB><TAB>  self . get_editor ( ) . store_action_state ( cmd ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB>  else : <TAB><TAB>  self . set_status ( "" Command  ' {0} '  not found. "" . format ( cmd ) ) <TAB><TAB>  return False <TAB>  return True ","if not self . run_module ( cmd , args ) :",if args == self.get_command_name():,False,23.79734972254376,95.78129055180933
1996,"def get_main_chain_layers ( self ) : <TAB>  """"""Return a list of layer IDs in the main chain."""""" <TAB>  main_chain = self . get_main_chain ( ) <TAB>  ret = [ ] <TAB>  for u in main_chain : <TAB><TAB>  for v , layer_id in self . adj_list [ u ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret . append ( layer_id ) <TAB>  return ret ",if v in main_chain and u in main_chain :,if v == u:,False,58.46129200233023,91.41538487741953
1997,"def hash ( self , context ) : <TAB>  with context : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return IECore . MurmurHash ( ) <TAB><TAB>  h = GafferDispatch . TaskNode . hash ( self , context ) <TAB><TAB>  h . append ( self [ "" fileName "" ] . hash ( ) ) <TAB><TAB>  h . append ( self [ "" in "" ] . hash ( ) ) <TAB><TAB>  h . append ( self . __parameterHandler . hash ( ) ) <TAB><TAB>  return h ","if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :",if context.state == 'Murmur':,False,45.44889098516499,79.05366579444873
1998,"def consume_buf ( ) : <TAB>  ty = state [ "" ty "" ] - 1 <TAB>  for i in xrange ( state [ "" buf "" ] . shape [ 1 ] / / N ) : <TAB><TAB>  tx = x / / N + i <TAB><TAB>  src = state [ "" buf "" ] [ : , i * N : ( i + 1 ) * N , : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with self . tile_request ( tx , ty , readonly = False ) as dst : <TAB><TAB><TAB><TAB>  mypaintlib . tile_convert_rgba8_to_rgba16 ( src , dst , self . EOTF ) <TAB>  if state [ "" progress "" ] : <TAB><TAB>  try : <TAB><TAB><TAB>  state [ "" progress "" ] . completed ( ty - ty0 ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  logger . exception ( "" Progress.completed() failed "" ) <TAB><TAB><TAB>  state [ "" progress "" ] = None ","if src [ : , : , 3 ] . any ( ) :",if tx != 0:,False,24.557492813247908,94.68317593437091
1999,"def check_permissions ( self , obj ) : <TAB>  request = self . context . get ( "" request "" ) <TAB>  for Perm in permissions : <TAB><TAB>  perm = Perm ( ) <TAB><TAB>  if not perm . has_permission ( request , self ) : <TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB>  return True ","if not perm . has_object_permission ( request , self , obj ) :",if not obj.is_active():,False,17.923958780830983,87.72903839463795
2000,"def _post_order ( op ) : <TAB>  if isinstance ( op , tvm . tir . Allocate ) : <TAB><TAB>  lift_stmt [ - 1 ] . append ( op ) <TAB><TAB>  return op . body <TAB>  if isinstance ( op , tvm . tir . AttrStmt ) : <TAB><TAB>  if op . attr_key == "" storage_scope "" : <TAB><TAB><TAB>  lift_stmt [ - 1 ] . append ( op ) <TAB><TAB><TAB>  return op . body <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB><TAB>  return op <TAB>  if isinstance ( op , tvm . tir . For ) : <TAB><TAB>  return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB>  raise RuntimeError ( "" not reached "" ) ","if op . attr_key == ""virtual_thread"" :","if isinstance(op, tvm.tir.For):",False,24.605053078088627,92.1647653107793
2001,"def task_done ( self ) : <TAB>  with self . _cond : <TAB><TAB>  if not self . _unfinished_tasks . acquire ( False ) : <TAB><TAB><TAB>  raise ValueError ( "" task_done() called too many times "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _cond . notify_all ( ) ",if self . _unfinished_tasks . _semlock . _is_zero ( ) :,if self._cond:,False,24.826442986283503,85.32569885966561
2002,"def get_json ( self ) : <TAB>  if not hasattr ( self , "" _json "" ) : <TAB><TAB>  self . _json = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _json = json . loads ( self . request . body ) <TAB>  return self . _json ","if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :","if hasattr(self.request, 'body'):",False,23.993321967256275,75.78682653179057
2003,"def userfullname ( ) : <TAB>  """"""Get the user's full name."""""" <TAB>  global _userfullname <TAB>  <IF-STMT>: <TAB><TAB>  uid = os . getuid ( ) <TAB><TAB>  entry = pwd_from_uid ( uid ) <TAB><TAB>  if entry : <TAB><TAB><TAB>  _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _userfullname = "" user %d "" % uid <TAB>  return _userfullname ",if not _userfullname :,if _userfullname is None:,False,22.147187490597776,93.22719366998282
2004,"def test_scatter ( self ) : <TAB>  for rank in range ( self . world_size ) : <TAB><TAB>  tensor = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tensor = [ torch . tensor ( i ) for i in range ( self . world_size ) ] <TAB><TAB>  result = comm . get ( ) . scatter ( tensor , rank , size = ( ) ) <TAB><TAB>  self . assertTrue ( torch . is_tensor ( result ) ) <TAB><TAB>  self . assertEqual ( result . item ( ) , self . rank ) ",if self . rank == rank :,if rank == 0:,False,34.9836001515545,95.67686622036469
2005,"def decompile ( decompiler ) : <TAB>  for pos , next_pos , opname , arg in decompiler . instructions : <TAB><TAB>  if pos in decompiler . targets : <TAB><TAB><TAB>  decompiler . process_target ( pos ) <TAB><TAB>  method = getattr ( decompiler , opname , None ) <TAB><TAB>  if method is None : <TAB><TAB><TAB>  throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB><TAB>  decompiler . pos = pos <TAB><TAB>  decompiler . next_pos = next_pos <TAB><TAB>  x = method ( * arg ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  decompiler . stack . append ( x ) ",if x is not None :,if x is not None:,False,51.93068812400313,100.00000000000004
2006,"def print_scenario_ran ( self , scenario ) : <TAB>  if scenario . passed : <TAB><TAB>  self . wrt ( "" OK "" ) <TAB>  elif scenario . failed : <TAB><TAB>  reason = self . scenarios_and_its_fails [ scenario ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . wrt ( "" FAILED "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . wrt ( "" ERROR "" ) <TAB>  self . wrt ( "" \n "" ) ","if isinstance ( reason . exception , AssertionError ) :",if reason.failed:,False,22.36051988823366,93.24166680986798
2007,"def detect_ssl_option ( self ) : <TAB>  for option in self . ssl_options ( ) : <TAB><TAB>  if scan_argv ( self . argv , option ) is not None : <TAB><TAB><TAB>  for other_option in self . ssl_options ( ) : <TAB><TAB><TAB><TAB>  if option != other_option : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  raise ConfigurationError ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return option ","if scan_argv ( self . argv , other_option ) is not None :",if option != other_option:,False,28.766899282718416,92.69747816876277
2008,"def print_po_snippet ( en_loc_old_lists , context ) : <TAB>  for m , localized , old in zip ( * en_loc_old_lists ) : <TAB><TAB>  if m == "" "" : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  localized = old <TAB><TAB>  print ( <TAB><TAB><TAB>  "" #:  {file} : {line} \n "" <TAB><TAB><TAB>  ' msgid  "" {context} {en_month} "" \n ' <TAB><TAB><TAB>  ' msgstr  "" {localized_month} "" \n ' . format ( <TAB><TAB><TAB><TAB>  context = context , <TAB><TAB><TAB><TAB>  file = filename , <TAB><TAB><TAB><TAB>  line = print_po_snippet . line , <TAB><TAB><TAB><TAB>  en_month = m , <TAB><TAB><TAB><TAB>  localized_month = localized , <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB><TAB>  print_po_snippet . line + = 1 ",if m == localized :,if localized == None:,False,23.987099113509842,93.50352040108258
2009,"def set_status ( self , dict_new ) : <TAB>  for i , value in dict_new . items ( ) : <TAB><TAB>  self . dict_bili [ i ] = value <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . dict_bili [ "" pcheaders "" ] [ "" cookie "" ] = value <TAB><TAB><TAB>  self . dict_bili [ "" appheaders "" ] [ "" cookie "" ] = value ","if i == ""cookie"" :",if i == 0:,False,31.775924152833756,95.84396105906733
2010,"def makeSomeFiles ( pathobj , dirdict ) : <TAB>  pathdict = { } <TAB>  for ( key , value ) in dirdict . items ( ) : <TAB><TAB>  child = pathobj . child ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pathdict [ key ] = child <TAB><TAB><TAB>  child . setContent ( value ) <TAB><TAB>  elif isinstance ( value , dict ) : <TAB><TAB><TAB>  child . createDirectory ( ) <TAB><TAB><TAB>  pathdict [ key ] = makeSomeFiles ( child , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB>  return pathdict ","if isinstance ( value , bytes ) :","if isinstance(child, str):",False,47.82900396561341,97.49765931688484
2011,"def _truncate_to_length ( generator , len_map = None ) : <TAB>  for example in generator : <TAB><TAB>  example = list ( example ) <TAB><TAB>  if len_map is not None : <TAB><TAB><TAB>  for key , max_len in len_map . items ( ) : <TAB><TAB><TAB><TAB>  example_len = example [ key ] . shape <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  example [ key ] = np . resize ( example [ key ] , max_len ) <TAB><TAB>  yield tuple ( example ) ",if example_len > max_len :,if example_len > max_len:,False,52.368303312702366,100.00000000000004
2012,"def check ( self , * * kw ) : <TAB>  if not kw : <TAB><TAB>  return exists ( self . strpath ) <TAB>  if len ( kw ) == 1 : <TAB><TAB>  if "" dir "" in kw : <TAB><TAB><TAB>  return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB>  return super ( LocalPath , self ) . check ( * * kw ) ","if ""file"" in kw :","if ""file"" in kw:",False,21.611923411728867,100.00000000000004
2013,"def next_instruction_is_function_or_class ( lines ) : <TAB>  """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB>  parser = StringParser ( "" python "" ) <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  if parser . is_quoted ( ) : <TAB><TAB><TAB>  parser . read_line ( line ) <TAB><TAB><TAB>  continue <TAB><TAB>  parser . read_line ( line ) <TAB><TAB>  if not line . strip ( ) :<TAB># empty line <TAB><TAB><TAB>  if i > 0 and not lines [ i - 1 ] . strip ( ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  continue <TAB><TAB>  if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  return False <TAB>  return False ","if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :",if not line:,False,61.228752170709846,91.41932574179015
2014,"def askCheckReadFile ( self , localFile , remoteFile ) : <TAB>  if not kb . bruteMode : <TAB><TAB>  message = "" do you want confirmation that the remote file  ' %s ' "" % remoteFile <TAB><TAB>  message + = "" has been successfully downloaded from the back-end  "" <TAB><TAB>  message + = "" DBMS file system? [Y/n]  "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _checkFileLength ( localFile , remoteFile , True ) <TAB>  return None ","if readInput ( message , default = ""Y"" , boolean = True ) :","if self.checkFileLength(localFile, remoteFile, True):",False,26.930357033945697,87.87915466384156
2015,"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB>  with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB><TAB>  version = load_version_data ( hive_name , company , tag , tag_key ) <TAB><TAB>  if version is not None :<TAB># if failed to get version bail <TAB><TAB><TAB>  major , minor , _ = version <TAB><TAB><TAB>  arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB><TAB><TAB><TAB>  if exe_data is not None : <TAB><TAB><TAB><TAB><TAB>  exe , args = exe_data <TAB><TAB><TAB><TAB><TAB>  return company , major , minor , arch , exe , args ",if arch is not None :,if arch is not None:,False,53.244541416360924,98.21479206893271
2016,"def _get_matching_bracket ( self , s , pos ) : <TAB>  if s [ pos ] != "" { "" : <TAB><TAB>  return None <TAB>  end = len ( s ) <TAB>  depth = 1 <TAB>  pos + = 1 <TAB>  while pos != end : <TAB><TAB>  c = s [ pos ] <TAB><TAB>  if c == "" { "" : <TAB><TAB><TAB>  depth + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  depth - = 1 <TAB><TAB>  if depth == 0 : <TAB><TAB><TAB>  break <TAB><TAB>  pos + = 1 <TAB>  if pos < end and s [ pos ] == "" } "" : <TAB><TAB>  return pos <TAB>  return None ","elif c == ""}"" :","if c == '""':",False,22.883193865484788,96.5303832393903
2017,"def pred ( field , value , item ) : <TAB>  for suffix , p in _BUILTIN_PREDS . iteritems ( ) : <TAB><TAB>  if field . endswith ( suffix ) : <TAB><TAB><TAB>  f = field [ : field . index ( suffix ) ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  return p ( getattr ( item , f ) , value ) <TAB>  if not hasattr ( item , field ) or getattr ( item , field ) is None : <TAB><TAB>  return False <TAB>  if isinstance ( value , type ( lambda x : x ) ) : <TAB><TAB>  return value ( getattr ( item , field ) ) <TAB>  return getattr ( item , field ) == value ","if not hasattr ( item , f ) or getattr ( item , f ) is None :",if f not in item:,False,23.55384797629062,91.36908251435389
2018,"def init_weights ( self ) : <TAB>  """"""Initialize model weights."""""" <TAB>  for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB><TAB>  if isinstance ( m , nn . ConvTranspose2d ) : <TAB><TAB><TAB>  normal_init ( m , std = 0.001 ) <TAB><TAB>  elif isinstance ( m , nn . BatchNorm2d ) : <TAB><TAB><TAB>  constant_init ( m , 1 ) <TAB>  for m in self . multi_final_layers . modules ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  normal_init ( m , std = 0.001 , bias = 0 ) ","if isinstance ( m , nn . Conv2d ) :","if isinstance(m, nn.ConvTranspose2d):",False,26.071396781570556,98.49156258720447
2019,"def test_byteswap ( self ) : <TAB>  if self . typecode == "" u "" : <TAB><TAB>  example = "" \U00100100 "" <TAB>  else : <TAB><TAB>  example = self . example <TAB>  a = array . array ( self . typecode , example ) <TAB>  self . assertRaises ( TypeError , a . byteswap , 42 ) <TAB>  if a . itemsize in ( 1 , 2 , 4 , 8 ) : <TAB><TAB>  b = array . array ( self . typecode , example ) <TAB><TAB>  b . byteswap ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( a , b ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertNotEqual ( a , b ) <TAB><TAB>  b . byteswap ( ) <TAB><TAB>  self . assertEqual ( a , b ) ",if a . itemsize == 1 :,"if self.typecode == ""u':",False,21.64149074107574,96.35551116829572
2020,"def _remove_blocks_from_variables ( variables ) : <TAB>  new_variables = [ ] <TAB>  for name , variable in variables : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_variables . extend ( variable . locals ) <TAB><TAB><TAB>  new_variables . append ( ( name , variable . result ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  new_variables . append ( ( name , variable ) ) <TAB>  return new_variables ",if variable . is_block ( ) :,"if isinstance(variable, (Block, Block)):",False,48.332748102573206,92.06897682237147
2021,def scope ( self ) : <TAB>  <IF-STMT>: <TAB><TAB>  self . lazy_init_lock_ . acquire ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . scope_ = Scope ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . lazy_init_lock_ . release ( ) <TAB>  return self . scope_ ,if self . scope_ is None :,if self.scope_ is None:,False,44.76676400140425,92.6110104715455
2022,"def translate ( ) : <TAB>  assert Lex . next ( ) is AttributeList <TAB>  reader . read ( )<TAB># Discard attribute list from reader. <TAB>  attrs = { } <TAB>  d = AttributeList . match . groupdict ( ) <TAB>  for k , v in d . items ( ) : <TAB><TAB>  if v is not None : <TAB><TAB><TAB>  if k == "" attrlist "" : <TAB><TAB><TAB><TAB>  v = subs_attrs ( v ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  parse_attributes ( v , attrs ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  AttributeList . attrs [ k ] = v <TAB>  AttributeList . subs ( attrs ) <TAB>  AttributeList . attrs . update ( attrs ) ",if v :,if k == 'attrs':,False,45.900415767310896,95.1449147831084
2023,"def parse ( self , response ) : <TAB>  try : <TAB><TAB>  content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB><TAB>  content = json . loads ( content , strict = False ) <TAB>  except : <TAB><TAB>  self . logger . error ( "" Fail to parse the response in json format "" ) <TAB><TAB>  return <TAB>  for item in content [ "" data "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB><TAB>  elif "" hoverURL "" in item : <TAB><TAB><TAB>  img_url = item [ "" hoverURL "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  continue <TAB><TAB>  yield dict ( file_url = img_url ) ","if ""objURL"" in item :","if ""objURL"" in item:",False,55.77469974322542,100.00000000000004
2024,"def canonicalize_instruction_name ( instr ) : <TAB>  name = instr . insn_name ( ) . upper ( ) <TAB>  # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB>  if name == "" MOV "" : <TAB><TAB>  if instr . mnemonic . startswith ( "" lsr "" ) : <TAB><TAB><TAB>  return "" LSR "" <TAB><TAB>  elif instr . mnemonic . startswith ( "" lsl "" ) : <TAB><TAB><TAB>  return "" LSL "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" ASR "" <TAB>  return OP_NAME_MAP . get ( name , name ) ","elif instr . mnemonic . startswith ( ""asr"" ) :","if name == ""ASR':",False,63.44664317406462,92.33760299241436
2025,"def _clean_regions ( items , region ) : <TAB>  """"""Intersect region with target file if it exists"""""" <TAB>  variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB>  with utils . tmpfile ( ) as tx_out_file : <TAB><TAB>  target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( target , six . string_types ) and os . path . isfile ( target ) : <TAB><TAB><TAB><TAB>  target = _load_regions ( target ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  target = [ target ] <TAB><TAB><TAB>  return target ",if target :,if target is not None:,False,31.794968229213943,97.66921249696038
2026,def reader_leaves ( self ) : <TAB>  self . mutex . acquire ( ) <TAB>  try : <TAB><TAB>  self . active_readers - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . active_writers + = 1 <TAB><TAB><TAB>  self . waiting_writers - = 1 <TAB><TAB><TAB>  self . can_write . release ( ) <TAB>  finally : <TAB><TAB>  self . mutex . release ( ) ,if self . active_readers == 0 and self . waiting_writers != 0 :,if self.waiting_readers > 0:,False,17.017550814070088,89.61917272977074
2027,"def _bpe_to_words ( sentence , delimiter = "" @@ "" ) : <TAB>  """"""Convert a sequence of bpe words into sentence."""""" <TAB>  words = [ ] <TAB>  word = "" "" <TAB>  delimiter_len = len ( delimiter ) <TAB>  for subwords in sentence : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  word + = subwords [ : - delimiter_len ] <TAB><TAB>  else : <TAB><TAB><TAB>  word + = subwords <TAB><TAB><TAB>  words . append ( word ) <TAB><TAB><TAB>  word = "" "" <TAB>  return words ",if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,if delimiter_len > 0:,False,30.72199626832609,86.63152972080495
2028,"def _make_var_names ( exog ) : <TAB>  if hasattr ( exog , "" name "" ) : <TAB><TAB>  var_names = exog . name <TAB>  elif hasattr ( exog , "" columns "" ) : <TAB><TAB>  var_names = exog . columns <TAB>  else : <TAB><TAB>  raise ValueError ( "" exog is not a Series or DataFrame or is unnamed. "" ) <TAB>  try : <TAB><TAB>  var_names = "" "" . join ( var_names ) <TAB>  except TypeError :<TAB># cannot have names that are numbers, pandas default <TAB><TAB>  from statsmodels . base . data import _make_exog_names <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  var_names = "" x1 "" <TAB><TAB>  else : <TAB><TAB><TAB>  var_names = "" "" . join ( _make_exog_names ( exog ) ) <TAB>  return var_names ",if exog . ndim == 1 :,"if isinstance(exog, (int, float)):",False,60.439344845387886,93.09428241336416
2029,"def __start_element_handler ( self , name , attrs ) : <TAB>  if name == "" mime-type "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for extension in self . extensions : <TAB><TAB><TAB><TAB>  self [ extension ] = self . type <TAB><TAB>  self . type = attrs [ "" type "" ] . lower ( ) <TAB><TAB>  self . extensions = [ ] <TAB>  elif name == "" glob "" : <TAB><TAB>  pattern = attrs [ "" pattern "" ] <TAB><TAB>  if pattern . startswith ( "" *. "" ) : <TAB><TAB><TAB>  self . extensions . append ( pattern [ 1 : ] . lower ( ) ) ",if self . type :,"if name == ""mime-type':",False,13.16677382020065,96.24697152854118
2030,"def nodes ( self , id = None , name = None ) : <TAB>  for node_dict in self . node_ls ( id = id , name = name ) : <TAB><TAB>  node_id = node_dict [ "" ID "" ] <TAB><TAB>  node = DockerNode ( self , node_id , inspect = node_dict ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  yield node ",if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,if not node:,False,19.24945208293782,81.19839982237458
2031,"def fix_repeating_arguments ( self ) : <TAB>  """"""Fix elements that should accumulate/increment values."""""" <TAB>  either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB>  for case in either : <TAB><TAB>  for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB>  if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB><TAB><TAB><TAB>  if e . value is None : <TAB><TAB><TAB><TAB><TAB>  e . value = [ ] <TAB><TAB><TAB><TAB>  elif type ( e . value ) is not list : <TAB><TAB><TAB><TAB><TAB>  e . value = e . value . split ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  e . value = 0 <TAB>  return self ",if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 :,if e.value is None:,False,34.415164484525256,91.73307671194411
2032,"def vi_search ( self , rng ) : <TAB>  for i in rng : <TAB><TAB>  line_history = self . _history . history [ i ] <TAB><TAB>  pos = line_history . get_line_text ( ) . find ( self . _vi_search_text ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _history . history_cursor = i <TAB><TAB><TAB>  self . l_buffer . line_buffer = list ( line_history . line_buffer ) <TAB><TAB><TAB>  self . l_buffer . point = pos <TAB><TAB><TAB>  self . vi_undo_restart ( ) <TAB><TAB><TAB>  return True <TAB>  self . _bell ( ) <TAB>  return False ",if pos >= 0 :,if pos is not None:,False,47.724883551255694,97.5944484529286
2033,"def visitIf ( self , node , scope ) : <TAB>  for test , body in node . tests : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if type ( test . value ) in self . _const_types : <TAB><TAB><TAB><TAB>  if not test . value : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB>  self . visit ( test , scope ) <TAB><TAB>  self . visit ( body , scope ) <TAB>  if node . else_ : <TAB><TAB>  self . visit ( node . else_ , scope ) ","if isinstance ( test , ast . Const ) :","if isinstance(test, ast.If):",False,25.99717912584259,98.30775224759908
2034,"def collect ( self ) : <TAB>  for nickname in self . squid_hosts . keys ( ) : <TAB><TAB>  squid_host = self . squid_hosts [ nickname ] <TAB><TAB>  fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fulldata = fulldata . splitlines ( ) <TAB><TAB><TAB>  for data in fulldata : <TAB><TAB><TAB><TAB>  matches = self . stat_pattern . match ( data ) <TAB><TAB><TAB><TAB>  if matches : <TAB><TAB><TAB><TAB><TAB>  self . publish_counter ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB><TAB><TAB><TAB><TAB>  ) ",if fulldata is not None :,if fulldata:,False,49.955681578405844,98.06930082603722
2035,"def convert ( x , base , exponents ) : <TAB>  out = [ ] <TAB>  for e in exponents : <TAB><TAB>  d = int ( x / ( base * * e ) ) <TAB><TAB>  x - = d * ( base * * e ) <TAB><TAB>  out . append ( digits [ d ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return out ",if x == 0 and e < 0 :,if x == 0:,False,14.327921414469703,95.4685596529864
2036,"def print_doc ( manager , options ) : <TAB>  plugin_name = options . doc <TAB>  plugin = plugins . get ( plugin_name , None ) <TAB>  if plugin : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  console ( "" Plugin  %s  does not have documentation "" % plugin_name ) <TAB><TAB>  else : <TAB><TAB><TAB>  console ( "" "" ) <TAB><TAB><TAB>  console ( trim ( plugin . instance . __doc__ ) ) <TAB><TAB><TAB>  console ( "" "" ) <TAB>  else : <TAB><TAB>  console ( "" Could not find plugin  %s "" % plugin_name ) ",if not plugin . instance . __doc__ :,"if not hasattr(plugin.instance, '__doc__'):",False,26.051132628674527,93.91470151977393
2037,"def _set_attrs ( self , attrs ) : <TAB>  for attr in self . ATTRS : <TAB><TAB>  if attr in attrs : <TAB><TAB><TAB>  setattr ( self , attr , attrs [ attr ] ) <TAB><TAB><TAB>  del attrs [ attr ] <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  setattr ( self , attr , NO_DEFAULT ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  setattr ( self , attr , None ) <TAB>  if attrs : <TAB><TAB>  attrs = sorted ( attrs . keys ( ) ) <TAB><TAB>  raise OptionError ( "" invalid keyword arguments:  %s "" % "" ,  "" . join ( attrs ) , self ) ","if attr == ""default"" :",if self.default is not None:,False,49.21361319289457,96.24557836828518
2038,"def _get_set_scope ( <TAB>  ir_set : irast . Set , scope_tree : irast . ScopeTreeNode  ) - > irast . ScopeTreeNode : <TAB>  if ir_set . path_scope_id : <TAB><TAB>  new_scope = scope_tree . root . find_by_unique_id ( ir_set . path_scope_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise errors . InternalServerError ( <TAB><TAB><TAB><TAB>  f "" dangling scope pointer to node with uid "" <TAB><TAB><TAB><TAB>  f "" : { ir_set . path_scope_id }  in  { ir_set !r} "" <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  new_scope = scope_tree <TAB>  return new_scope ",if new_scope is None :,if new_scope is None:,False,36.72798403462703,100.00000000000004
2039,"def test_leave_one_out ( self ) : <TAB>  correct = 0 <TAB>  k = 3 <TAB>  model = kNN . train ( xs , ys , k ) <TAB>  predictions = [ 1 , 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 1 ] <TAB>  for i in range ( len ( predictions ) ) : <TAB><TAB>  model = kNN . train ( xs [ : i ] + xs [ i + 1 : ] , ys [ : i ] + ys [ i + 1 : ] , k ) <TAB><TAB>  prediction = kNN . classify ( model , xs [ i ] ) <TAB><TAB>  self . assertEqual ( prediction , predictions [ i ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  correct + = 1 <TAB>  self . assertEqual ( correct , 13 ) ",if prediction == ys [ i ] :,if i == k - 1:,False,19.960792044061968,96.39282587621214
2040,"def import_files ( self , files ) : <TAB>  """"""Import a list of MORE (.csv) files."""""" <TAB>  c = self . c <TAB>  if files : <TAB><TAB>  changed = False <TAB><TAB>  self . tab_width = c . getTabWidth ( c . p ) <TAB><TAB>  for fileName in files : <TAB><TAB><TAB>  g . setGlobalOpenDir ( fileName ) <TAB><TAB><TAB>  p = self . import_file ( fileName ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  p . contract ( ) <TAB><TAB><TAB><TAB>  p . setDirty ( ) <TAB><TAB><TAB><TAB>  c . setChanged ( True ) <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB>  if changed : <TAB><TAB><TAB>  c . redraw ( p ) ",if p :,if p:,False,56.08353618101562,100.00000000000004
2041,"def getPageTemplate ( payload , place ) : <TAB>  retVal = ( kb . originalPage , kb . errorIsNone ) <TAB>  if payload and place : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  page , _ , _ = Request . queryPage ( payload , place , content = True , raise404 = False ) <TAB><TAB><TAB>  kb . pageTemplates [ ( payload , place ) ] = ( page , kb . lastParserStatus is None ) <TAB><TAB>  retVal = kb . pageTemplates [ ( payload , place ) ] <TAB>  return retVal ","if ( payload , place ) not in kb . pageTemplates :",if not retVal:,False,25.424981292786192,91.17860394701718
2042,"def _skip_trivial ( constraint_data ) : <TAB>  if skip_trivial_constraints : <TAB><TAB>  if isinstance ( constraint_data , LinearCanonicalRepn ) : <TAB><TAB><TAB>  if constraint_data . variables is None : <TAB><TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if constraint_data . body . polynomial_degree ( ) == 0 :,if constraint_data.variables is not None:,False,22.345025226088037,90.30192457272463
2043,"def get_unique_attribute ( self , name : str ) : <TAB>  feat = None <TAB>  for f in self . features : <TAB><TAB>  if self . _return_feature ( f ) and hasattr ( f , name ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise RuntimeError ( "" The attribute was not unique. "" ) <TAB><TAB><TAB>  feat = f <TAB>  if feat is None : <TAB><TAB>  raise RuntimeError ( "" The attribute did not exist "" ) <TAB>  return getattr ( feat , name ) ",if feat is not None :,if name not in self.unique_attribute_names:,False,37.86098185639795,92.1999775621725
2044,"def hideEvent ( self , event ) : <TAB>  """"""Reimplement Qt method"""""" <TAB>  if not self . light : <TAB><TAB>  for plugin in self . widgetlist : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  plugin . visibility_changed ( True ) <TAB>  QMainWindow . hideEvent ( self , event ) ",if plugin . isAncestorOf ( self . last_focused_widget ) :,"if hasattr(plugin, 'visibility_changed'):",False,47.80287410745801,87.48234499900396
2045,"def move_stdout_to_stderr ( self ) : <TAB>  to_remove = [ ] <TAB>  to_add = [ ] <TAB>  for consumer_level , consumer in self . consumers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  to_remove . append ( ( consumer_level , consumer ) ) <TAB><TAB><TAB>  to_add . append ( ( consumer_level , sys . stderr ) ) <TAB>  for item in to_remove : <TAB><TAB>  self . consumers . remove ( item ) <TAB>  self . consumers . extend ( to_add ) ",if consumer == sys . stdout :,if consumer_level != consumer_level:,False,49.60031468792629,94.23655266691725
2046,"def create ( exported_python_target ) : <TAB>  if exported_python_target not in created : <TAB><TAB>  self . context . log . info ( <TAB><TAB><TAB>  "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB><TAB>  ) <TAB><TAB>  subject = self . derived_by_original . get ( <TAB><TAB><TAB>  exported_python_target , exported_python_target <TAB><TAB>  ) <TAB><TAB>  setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB><TAB>  created [ exported_python_target ] = setup_dir <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for dep in dependencies : <TAB><TAB><TAB><TAB>  if is_exported_python_target ( dep ) : <TAB><TAB><TAB><TAB><TAB>  create ( dep ) ",if self . _recursive :,if dependencies:,False,44.933358648154645,97.58930954719945
2047,"def __add__ ( self , other ) : <TAB>  other = ArithmeticExpression . try_unpack_const ( other ) <TAB>  if not self . symbolic and type ( other ) is int : <TAB><TAB>  return SpOffset ( self . _bits , self . _to_signed ( self . offset + other ) ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return SpOffset ( self . _bits , self . offset + other ) <TAB><TAB>  else : <TAB><TAB><TAB>  return SpOffset ( <TAB><TAB><TAB><TAB>  self . _bits , <TAB><TAB><TAB><TAB>  ArithmeticExpression ( <TAB><TAB><TAB><TAB><TAB>  ArithmeticExpression . Add , <TAB><TAB><TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB><TAB><TAB>  self . offset , <TAB><TAB><TAB><TAB><TAB><TAB>  other , <TAB><TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB>  ) ",if self . symbolic :,"if isinstance(other, int):",False,49.414382476581345,97.32371147670816
2048,"def check_connection ( conn ) : <TAB>  tables = [ <TAB><TAB>  r [ 0 ] <TAB><TAB>  for r in conn . execute ( <TAB><TAB><TAB>  "" select name from sqlite_master where type= ' table ' "" <TAB><TAB>  ) . fetchall ( ) <TAB>  ] <TAB>  for table in tables : <TAB><TAB>  try : <TAB><TAB><TAB>  conn . execute ( <TAB><TAB><TAB><TAB>  f "" PRAGMA table_info( { escape_sqlite ( table ) } ); "" , <TAB><TAB><TAB>  ) <TAB><TAB>  except sqlite3 . OperationalError as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise SpatialiteConnectionProblem ( e ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise ConnectionProblem ( e ) ","if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :",if e.code == sqlite3.OperationalError.Code.ENOENT:,False,24.574967008415562,92.77858408444268
2049,"def _get_github_client ( self ) - > "" Github "" : <TAB>  from github import Github <TAB>  if self . access_token_secret is not None : <TAB><TAB>  # If access token secret specified, load it <TAB><TAB>  access_token = Secret ( self . access_token_secret ) . get ( ) <TAB>  else : <TAB><TAB>  # Otherwise, fallback to loading from local secret or environment variable <TAB><TAB>  access_token = prefect . context . get ( "" secrets "" , { } ) . get ( "" GITHUB_ACCESS_TOKEN "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  access_token = os . getenv ( "" GITHUB_ACCESS_TOKEN "" ) <TAB>  return Github ( access_token ) ",if access_token is None :,if access_token is None:,False,47.783274857478176,100.00000000000004
2050,"def make_tab ( lists ) : <TAB>  if hasattr ( lists , "" tolist "" ) : <TAB><TAB>  lists = lists . tolist ( ) <TAB>  ut = [ ] <TAB>  for rad in lists : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ut . append ( "" \t "" . join ( [ "" %s "" % x for x in rad ] ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  ut . append ( "" %s "" % rad ) <TAB>  return "" \n "" . join ( ut ) ","if type ( rad ) in [ list , tuple ] :","if isinstance(rad, list):",False,53.75882456046504,92.82966131175658
2051,"def _ensure_ffi_initialized ( cls ) : <TAB>  with cls . _init_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . lib = build_conditional_library ( lib , CONDITIONAL_NAMES ) <TAB><TAB><TAB>  cls . _lib_loaded = True <TAB><TAB><TAB>  # initialize the SSL library <TAB><TAB><TAB>  cls . lib . SSL_library_init ( ) <TAB><TAB><TAB>  # adds all ciphers/digests for EVP <TAB><TAB><TAB>  cls . lib . OpenSSL_add_all_algorithms ( ) <TAB><TAB><TAB>  # loads error strings for libcrypto and libssl functions <TAB><TAB><TAB>  cls . lib . SSL_load_error_strings ( ) <TAB><TAB><TAB>  cls . _register_osrandom_engine ( ) ",if not cls . _lib_loaded :,if cls._lib_loaded:,False,43.859402576256514,98.80458994195295
2052,def writer_leaves ( self ) : <TAB>  self . mutex . acquire ( ) <TAB>  try : <TAB><TAB>  self . active_writers - = 1 <TAB><TAB>  if self . waiting_writers != 0 : <TAB><TAB><TAB>  self . active_writers + = 1 <TAB><TAB><TAB>  self . waiting_writers - = 1 <TAB><TAB><TAB>  self . can_write . release ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  t = self . waiting_readers <TAB><TAB><TAB>  self . waiting_readers = 0 <TAB><TAB><TAB>  self . active_readers + = t <TAB><TAB><TAB>  while t > 0 : <TAB><TAB><TAB><TAB>  self . can_read . release ( ) <TAB><TAB><TAB><TAB>  t - = 1 <TAB>  finally : <TAB><TAB>  self . mutex . release ( ) ,elif self . waiting_readers != 0 :,if self.waiting_readers != 0:,False,18.764494255102328,98.9439852526484
2053,"def _spans ( self , operands ) : <TAB>  spans = { } <TAB>  k = 0 <TAB>  j = 0 <TAB>  for mode in ( self . FLOAT , self . MPMATH ) : <TAB><TAB>  for i , operand in enumerate ( operands [ k : ] ) : <TAB><TAB><TAB>  if operand [ 0 ] > mode : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  j = i + k + 1 <TAB><TAB>  <IF-STMT>:<TAB># only init state? then ignore. <TAB><TAB><TAB>  j = 0 <TAB><TAB>  spans [ mode ] = slice ( k , j ) <TAB><TAB>  k = j <TAB>  spans [ self . SYMBOLIC ] = slice ( k , len ( operands ) ) <TAB>  return spans ",if k == 0 and j == 1 :,if j > len(operands):,False,52.03495884477148,94.36286963607049
2054,"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB>  if response : <TAB><TAB>  # Only include the text in case of error. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  status = location . Status ( response . status_code , response . text ) <TAB><TAB>  else : <TAB><TAB><TAB>  status = location . Status ( response . status_code ) <TAB>  else : <TAB><TAB>  status = location . Status ( 500 , message ) <TAB>  if response is None or not response . ok : <TAB><TAB>  if completion_routine : <TAB><TAB><TAB>  return completion_routine ( status ) <TAB><TAB>  raise IOError ( response . text ) <TAB>  else : <TAB><TAB>  if completion_routine : <TAB><TAB><TAB>  completion_routine ( status ) <TAB>  return location . Status ( 200 , response . content ) ",if not response . ok :,if message is None:,False,59.198317610446516,97.56985106326752
2055,"def readinto ( self , buf ) : <TAB>  if self . current_frame : <TAB><TAB>  n = self . current_frame . readinto ( buf ) <TAB><TAB>  if n == 0 and len ( buf ) != 0 : <TAB><TAB><TAB>  self . current_frame = None <TAB><TAB><TAB>  n = len ( buf ) <TAB><TAB><TAB>  buf [ : ] = self . file_read ( n ) <TAB><TAB><TAB>  return n <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB><TAB>  return n <TAB>  else : <TAB><TAB>  n = len ( buf ) <TAB><TAB>  buf [ : ] = self . file_read ( n ) <TAB><TAB>  return n ",if n < len ( buf ) :,if n == 0:,False,38.85524619295905,96.83464804023556
2056,"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB>  visited = set ( ) <TAB>  mydict = self . basedict <TAB>  while 1 : <TAB><TAB>  value = mydict [ name ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return value <TAB><TAB>  myid = id ( mydict ) <TAB><TAB>  assert myid not in visited <TAB><TAB>  visited . add ( myid ) <TAB><TAB>  mydict = mydict . Parent <TAB><TAB>  if mydict is None : <TAB><TAB><TAB>  return ",if value is not None :,if value is not None:,False,52.51520635510665,100.00000000000004
2057,"def _handle_Mul ( self , expr ) : <TAB>  arg0 , arg1 = expr . args <TAB>  expr_0 = self . _expr ( arg0 ) <TAB>  if expr_0 is None : <TAB><TAB>  return None <TAB>  expr_1 = self . _expr ( arg1 ) <TAB>  if expr_1 is None : <TAB><TAB>  return None <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # self.tyenv is not used <TAB><TAB><TAB>  mask = ( 1 << expr . result_size ( self . tyenv ) ) - 1 <TAB><TAB><TAB>  return ( expr_0 * expr_1 ) & mask <TAB><TAB>  else : <TAB><TAB><TAB>  return expr_0 * expr_1 <TAB>  except TypeError as e : <TAB><TAB>  self . l . warning ( e ) <TAB><TAB>  return None ","if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :",if self.tyenv is not None:,False,42.7224304623868,91.99484165377689
2058,"def end_request ( self , request_id ) : <TAB>  """"""Removes the information associated with given request_id."""""" <TAB>  with self . _lock : <TAB><TAB>  del self . _request_wsgi_environ [ request_id ] <TAB><TAB>  del self . _request_id_to_server_configuration [ request_id ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . _request_id_to_instance [ request_id ] ",if request_id in self . _request_id_to_instance :,if request_id in self._request_id_to_instance:,False,34.429655778805255,100.00000000000004
2059,def generate ( ) : <TAB>  <IF-STMT>: <TAB><TAB>  decoder = zlib . decompressobj ( 16 + zlib . MAX_WBITS ) <TAB>  while True : <TAB><TAB>  chunk = self . raw . read ( chunk_size ) <TAB><TAB>  if not chunk : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  chunk = decoder . decompress ( chunk ) <TAB><TAB>  yield chunk ,if self . _gzipped :,if zlib.MAX_WBITS > 0:,False,23.826275226295518,89.01709093781429
2060,"def handle ( self ) : <TAB>  from poetry . utils . env import EnvManager <TAB>  manager = EnvManager ( self . poetry ) <TAB>  current_env = manager . get ( ) <TAB>  for venv in manager . list ( ) : <TAB><TAB>  name = venv . path . name <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = str ( venv . path ) <TAB><TAB>  if venv == current_env : <TAB><TAB><TAB>  self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  self . line ( name ) ","if self . option ( ""full-path"" ) :",if name == 'activate':,False,26.46017977592219,94.24543508965851
2061,"def addAggregators ( sheet , cols , aggrnames ) : <TAB>  "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB>  for aggrname in aggrnames : <TAB><TAB>  aggrs = vd . aggregators . get ( aggrname ) <TAB><TAB>  aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB><TAB>  for aggr in aggrs : <TAB><TAB><TAB>  for c in cols : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  c . aggregators = [ ] <TAB><TAB><TAB><TAB>  if aggr and aggr not in c . aggregators : <TAB><TAB><TAB><TAB><TAB>  c . aggregators + = [ aggr ] ","if not hasattr ( c , ""aggregators"" ) :","if not hasattr(c, 'aggregators'):",False,60.38285160106373,97.59729450809002
2062,"def on_pre_output_coercion ( <TAB>  directive_args : Dict [ str , Any ] , <TAB>  next_directive : Callable , <TAB>  value : Any , <TAB>  ctx : Optional [ Any ] , <TAB>  info : "" ResolveInfo "" ,  ) : <TAB>  value = await next_directive ( value , ctx , info ) <TAB>  if value is None : <TAB><TAB>  return value <TAB>  try : <TAB><TAB>  py_enum = _ENUM_MAP [ directive_args [ "" name "" ] ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ None if item is None else py_enum ( item ) . name for item in value ] <TAB><TAB>  return py_enum ( value ) . name <TAB>  except Exception : <TAB><TAB>  pass <TAB>  return value ","if isinstance ( value , list ) :",if py_enum is not None:,False,47.67509588294239,96.17803083225539
2063,def cut ( sentence ) : <TAB>  sentence = strdecode ( sentence ) <TAB>  blocks = re_han . split ( sentence ) <TAB>  for blk in blocks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for word in __cut ( blk ) : <TAB><TAB><TAB><TAB>  if word not in Force_Split_Words : <TAB><TAB><TAB><TAB><TAB>  yield word <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  for c in word : <TAB><TAB><TAB><TAB><TAB><TAB>  yield c <TAB><TAB>  else : <TAB><TAB><TAB>  tmp = re_skip . split ( blk ) <TAB><TAB><TAB>  for x in tmp : <TAB><TAB><TAB><TAB>  if x : <TAB><TAB><TAB><TAB><TAB>  yield x ,if re_han . match ( blk ) :,if re_han.search(blk):,False,52.25653005770534,98.9349874818781
2064,"def refresh_archive_action ( self ) : <TAB>  archive_name = self . selected_archive_name ( ) <TAB>  if archive_name is not None : <TAB><TAB>  params = BorgInfoArchiveThread . prepare ( self . profile ( ) , archive_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  thread = BorgInfoArchiveThread ( params [ "" cmd "" ] , params , parent = self . app ) <TAB><TAB><TAB>  thread . updated . connect ( self . _set_status ) <TAB><TAB><TAB>  thread . result . connect ( self . refresh_archive_result ) <TAB><TAB><TAB>  self . _toggle_all_buttons ( False ) <TAB><TAB><TAB>  thread . start ( ) ","if params [ ""ok"" ] :",if params:,False,38.754991166417426,96.33694414983424
2065,"def get_resource_public_actions ( resource_class ) : <TAB>  resource_class_members = inspect . getmembers ( resource_class ) <TAB>  resource_methods = { } <TAB>  for name , member in resource_class_members : <TAB><TAB>  if not name . startswith ( "" _ "" ) : <TAB><TAB><TAB>  if not name [ 0 ] . isupper ( ) : <TAB><TAB><TAB><TAB>  if not name . startswith ( "" wait_until "" ) : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  resource_methods [ name ] = member <TAB>  return resource_methods ",if is_resource_action ( member ) :,if member is not None:,False,48.66314951206543,94.76282373920202
2066,"def _get_compressor ( compress_type , compresslevel = None ) : <TAB>  if compress_type == ZIP_DEFLATED : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return zlib . compressobj ( compresslevel , zlib . DEFLATED , - 15 ) <TAB><TAB>  return zlib . compressobj ( zlib . Z_DEFAULT_COMPRESSION , zlib . DEFLATED , - 15 ) <TAB>  elif compress_type == ZIP_BZIP2 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return bz2 . BZ2Compressor ( compresslevel ) <TAB><TAB>  return bz2 . BZ2Compressor ( ) <TAB>  # compresslevel is ignored for ZIP_LZMA <TAB>  elif compress_type == ZIP_LZMA : <TAB><TAB>  return LZMACompressor ( ) <TAB>  else : <TAB><TAB>  return None ",if compresslevel is not None :,if compress_type == ZIP_BZIP2:,False,36.94163097120512,88.87078783017527
2067,"def parse_header ( plyfile , ext ) : <TAB>  # Variables <TAB>  line = [ ] <TAB>  properties = [ ] <TAB>  num_points = None <TAB>  while b "" end_header "" not in line and line != b "" "" : <TAB><TAB>  line = plyfile . readline ( ) <TAB><TAB>  if b "" element "" in line : <TAB><TAB><TAB>  line = line . split ( ) <TAB><TAB><TAB>  num_points = int ( line [ 2 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line = line . split ( ) <TAB><TAB><TAB>  properties . append ( ( line [ 2 ] . decode ( ) , ext + ply_dtypes [ line [ 1 ] ] ) ) <TAB>  return num_points , properties ","elif b""property"" in line :","if b""properties"" in line:",False,30.921262690842983,97.5470280276266
2068,"def download_release_artifacts ( self , version ) : <TAB>  try : <TAB><TAB>  os . mkdir ( self . artifacts_dir ) <TAB>  except FileExistsError : <TAB><TAB>  pass <TAB>  for job_name in self . build_ids : <TAB><TAB>  build_number = self . build_ids . get ( job_name ) <TAB><TAB>  build_status = self . _get_build_status ( job_name , build_number ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _download_job_artifact ( job_name , build_number , version ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" Build for  {}  is not fininished "" . format ( job_name ) ) <TAB><TAB><TAB>  print ( "" \t Run  ' build '  action to check status of  {} "" . format ( job_name ) ) ","if build_status == ""built"" :",if build_status == 'Done':,False,58.17813303844095,95.88884027423882
2069,"def update_metadata ( self ) : <TAB>  for attrname in dir ( self ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  attrvalue = getattr ( self , attrname , None ) <TAB><TAB>  if attrvalue == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  if attrname == "" salt_version "" : <TAB><TAB><TAB>  attrname = "" version "" <TAB><TAB>  if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB>  getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB>  elif hasattr ( self . metadata , attrname ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  pass ","if attrname . startswith ( ""__"" ) :",if attrname == 'version':,False,34.45314781707386,96.1030466937558
2070,"def check_heuristic_in_sql ( ) : <TAB>  heurs = set ( ) <TAB>  excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB>  for heur in HEURISTICS : <TAB><TAB>  name = heur [ "" name "" ] <TAB><TAB>  if name in excluded : <TAB><TAB><TAB>  continue <TAB><TAB>  sql = heur [ "" sql "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB><TAB><TAB>  print ( sql ) <TAB><TAB><TAB>  assert sql . find ( name ) != - 1 <TAB><TAB>  heurs . add ( name ) <TAB>  print ( "" Heuristics: "" ) <TAB>  import pprint <TAB>  pprint . pprint ( heurs ) ",if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,if not sql:,False,25.06470718369083,90.24048356570333
2071,def gettext ( rv ) : <TAB>  for child in rv . childNodes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield child . nodeValue <TAB><TAB>  if child . nodeType == child . ELEMENT_NODE : <TAB><TAB><TAB>  for item in gettext ( child ) : <TAB><TAB><TAB><TAB>  yield item ,if child . nodeType == child . TEXT_NODE :,if child.nodeType == child.TEXT_NODE:,False,26.744603082929064,100.00000000000004
2072,"def update ( self ) : <TAB>  """"""Update properties over dbus."""""" <TAB>  self . _check_dbus ( ) <TAB>  _LOGGER . info ( "" Updating service information "" ) <TAB>  self . _services . clear ( ) <TAB>  try : <TAB><TAB>  systemd_units = await self . sys_dbus . systemd . list_units ( ) <TAB><TAB>  for service_data in systemd_units [ 0 ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  self . _services . add ( ServiceInfo . read_from ( service_data ) ) <TAB>  except ( HassioError , IndexError ) : <TAB><TAB>  _LOGGER . warning ( "" Can ' t update host service information! "" ) ","if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :",if service_data is None:,False,23.019058332046406,85.51865823905196
2073,"def filtercomments ( source ) : <TAB>  """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB>  trailing_comments = [ ] <TAB>  comment = True <TAB>  while comment : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB><TAB>  elif re . search ( r "" ^ \ s* \ / \ / "" , source ) : <TAB><TAB><TAB>  comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  comment = None <TAB><TAB>  if comment : <TAB><TAB><TAB>  source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB><TAB><TAB>  trailing_comments . append ( comment ) <TAB>  return "" \n "" . join ( trailing_comments ) + source ","if re . search ( r""^\s*\/\*"" , source ) :","if re.search(r""^\s*\\/\\s*\\/\\",False,21.797226169592577,95.78578660578829
2074,"def _getSourceStamp_sync ( self , ssid ) : <TAB>  if ssid in self . sourcestamps : <TAB><TAB>  ssdict = self . sourcestamps [ ssid ] . copy ( ) <TAB><TAB>  ssdict [ "" ssid "" ] = ssid <TAB><TAB>  patchid = ssdict [ "" patchid "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ssdict . update ( self . patches [ patchid ] ) <TAB><TAB><TAB>  ssdict [ "" patchid "" ] = patchid <TAB><TAB>  else : <TAB><TAB><TAB>  ssdict [ "" patch_body "" ] = None <TAB><TAB><TAB>  ssdict [ "" patch_level "" ] = None <TAB><TAB><TAB>  ssdict [ "" patch_subdir "" ] = None <TAB><TAB><TAB>  ssdict [ "" patch_author "" ] = None <TAB><TAB><TAB>  ssdict [ "" patch_comment "" ] = None <TAB><TAB>  return ssdict <TAB>  else : <TAB><TAB>  return None ",if patchid :,if patchid in self.patches:,False,39.86543426912627,97.70015252663742
2075,"def parseImpl ( self , instring , loc , doActions = True ) : <TAB>  try : <TAB><TAB>  loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB>  except ( ParseException , IndexError ) : <TAB><TAB>  if self . defaultValue is not self . __optionalNotMatched : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tokens = ParseResults ( [ self . defaultValue ] ) <TAB><TAB><TAB><TAB>  tokens [ self . expr . resultsName ] = self . defaultValue <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  tokens = [ self . defaultValue ] <TAB><TAB>  else : <TAB><TAB><TAB>  tokens = [ ] <TAB>  return loc , tokens ",if self . expr . resultsName :,if self.defaultValue is not None:,False,49.04647715196672,97.15237163381218
2076,"def _find_exceptions ( ) : <TAB>  for _name , obj in iteritems ( globals ( ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  is_http_exception = issubclass ( obj , HTTPException ) <TAB><TAB>  except TypeError : <TAB><TAB><TAB>  is_http_exception = False <TAB><TAB>  if not is_http_exception or obj . code is None : <TAB><TAB><TAB>  continue <TAB><TAB>  __all__ . append ( obj . __name__ ) <TAB><TAB>  old_obj = default_exceptions . get ( obj . code , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  default_exceptions [ obj . code ] = obj ","if old_obj is not None and issubclass ( obj , old_obj ) :",if old_obj is obj:,False,30.9535816007481,93.76503272580148
2077,"def generator ( self , data ) : <TAB>  for ( proc_as , key_buf_ptr ) in data : <TAB><TAB>  key_buf = proc_as . read ( key_buf_ptr , 24 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  key = "" "" . join ( "" %02X "" % ord ( k ) for k in key_buf ) <TAB><TAB>  yield ( <TAB><TAB><TAB>  0 , <TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB>  str ( key ) , <TAB><TAB><TAB>  ] , <TAB><TAB>  ) ",if not key_buf :,if not key_buf:,False,52.07994273777226,100.00000000000004
2078,"def calculateEnableMargins ( self ) : <TAB>  self . cnc . resetEnableMargins ( ) <TAB>  for block in self . blocks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  CNC . vars [ "" xmin "" ] = min ( CNC . vars [ "" xmin "" ] , block . xmin ) <TAB><TAB><TAB>  CNC . vars [ "" ymin "" ] = min ( CNC . vars [ "" ymin "" ] , block . ymin ) <TAB><TAB><TAB>  CNC . vars [ "" zmin "" ] = min ( CNC . vars [ "" zmin "" ] , block . zmin ) <TAB><TAB><TAB>  CNC . vars [ "" xmax "" ] = max ( CNC . vars [ "" xmax "" ] , block . xmax ) <TAB><TAB><TAB>  CNC . vars [ "" ymax "" ] = max ( CNC . vars [ "" ymax "" ] , block . ymax ) <TAB><TAB><TAB>  CNC . vars [ "" zmax "" ] = max ( CNC . vars [ "" zmax "" ] , block . zmax ) ",if block . enable :,if block.isEnabled():,False,49.809116104165184,98.08568155741771
2079,"def __init__ ( self , client , job_id , callback = None ) : <TAB>  self . client = client <TAB>  self . job_id = job_id <TAB>  # If a job event has been received already then we must set an Event <TAB>  # to wait for this job to finish. <TAB>  # Otherwise we create a new stub for the job with the Event for when <TAB>  # the job event arrives to use existing event. <TAB>  with client . _jobs_lock : <TAB><TAB>  job = client . _jobs . get ( job_id ) <TAB><TAB>  self . event = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . event = job . get ( "" __ready "" ) <TAB><TAB>  if self . event is None : <TAB><TAB><TAB>  self . event = job [ "" __ready "" ] = Event ( ) <TAB><TAB>  job [ "" __callback "" ] = callback ",if job :,if job:,False,69.26352295523427,100.00000000000004
2080,"def asset ( * paths ) : <TAB>  for path in paths : <TAB><TAB>  fspath = www_root + "" /assets/ "" + path <TAB><TAB>  etag = "" "" <TAB><TAB>  try : <TAB><TAB><TAB>  if env . cache_static : <TAB><TAB><TAB><TAB>  etag = asset_etag ( fspath ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  os . stat ( fspath ) <TAB><TAB>  except FileNotFoundError as e : <TAB><TAB><TAB>  if path == paths [ - 1 ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  tell_sentry ( e , { } ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  tell_sentry ( e , { } ) <TAB><TAB>  return asset_url + path + ( etag and "" ?etag= "" + etag ) ","if not os . path . exists ( fspath + "".spt"" ) :",if e.errno == errno.EACCES:,False,52.04424526733362,93.58418184256686
2081,"def set_conf ( ) : <TAB>  """"""Collapse all object_trail config into cherrypy.request.config."""""" <TAB>  base = cherrypy . config . copy ( ) <TAB>  # Note that we merge the config from each node <TAB>  # even if that node was None. <TAB>  for name , obj , conf , segleft in object_trail : <TAB><TAB>  base . update ( conf ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  base [ "" tools.staticdir.section "" ] = "" / "" + "" / "" . join ( <TAB><TAB><TAB><TAB>  fullpath [ 0 : fullpath_len - segleft ] <TAB><TAB><TAB>  ) <TAB>  return base ","if ""tools.staticdir.dir"" in conf :",if segleft:,False,62.99244888414031,93.9464995775859
2082,"def __init__ ( self ) : <TAB>  self . setLayers ( None , None ) <TAB>  self . interface = None <TAB>  self . event_callbacks = { } <TAB>  self . __stack = None <TAB>  self . lock = threading . Lock ( ) <TAB>  members = inspect . getmembers ( self , predicate = inspect . ismethod ) <TAB>  for m in members : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fname = m [ 0 ] <TAB><TAB><TAB>  fn = m [ 1 ] <TAB><TAB><TAB>  self . event_callbacks [ fn . event_callback ] = getattr ( self , fname ) ","if hasattr ( m [ 1 ] , ""event_callback"" ) :",if m[0] == 'layer':,False,21.738366496813256,91.74099428963028
2083,def multi_dev_generator ( self ) : <TAB>  for data in self . _data_loader ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _tail_data + = data <TAB><TAB>  if len ( self . _tail_data ) == self . _base_number : <TAB><TAB><TAB>  yield self . _tail_data <TAB><TAB><TAB>  self . _tail_data = [ ] ,if len ( self . _tail_data ) < self . _base_number :,if data is not None:,False,20.281154534823767,85.7877350883151
2084,"def replace_field_to_value ( layout , cb ) : <TAB>  for i , lo in enumerate ( layout . fields ) : <TAB><TAB>  if isinstance ( lo , Field ) or issubclass ( lo . __class__ , Field ) : <TAB><TAB><TAB>  layout . fields [ i ] = ShowField ( <TAB><TAB><TAB><TAB>  cb , * lo . fields , attrs = lo . attrs , wrapper_class = lo . wrapper_class <TAB><TAB><TAB>  ) <TAB><TAB>  elif isinstance ( lo , basestring ) : <TAB><TAB><TAB>  layout . fields [ i ] = ShowField ( cb , lo ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  replace_field_to_value ( lo , cb ) ","elif hasattr ( lo , ""get_field_names"" ) :","if isinstance(lo, Field):",False,21.762974025753394,93.76090139456574
2085,"def function_out ( * args , * * kwargs ) : <TAB>  try : <TAB><TAB>  return function_in ( * args , * * kwargs ) <TAB>  except dbus . exceptions . DBusException as e : <TAB><TAB>  if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB><TAB><TAB>  raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB><TAB>  if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT : <TAB><TAB><TAB>  raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB><TAB>  raise ","if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) :",if e.get_dbus_name() == DBUS_UNKNOWN_METHOD:,False,20.487161377201623,92.64700119467334
2086,"def results_iter ( self ) : <TAB>  if self . connection . ops . oracle : <TAB><TAB>  from django . db . models . fields import DateTimeField <TAB><TAB>  fields = [ DateTimeField ( ) ] <TAB>  else : <TAB><TAB>  needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB>  offset = len ( self . query . extra_select ) <TAB>  for rows in self . execute_sql ( MULTI ) : <TAB><TAB>  for row in rows : <TAB><TAB><TAB>  date = row [ offset ] <TAB><TAB><TAB>  if self . connection . ops . oracle : <TAB><TAB><TAB><TAB>  date = self . resolve_columns ( row , fields ) [ offset ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  date = typecast_timestamp ( str ( date ) ) <TAB><TAB><TAB>  yield date ",elif needs_string_cast :,if date is not None and date not in needs_string_cast:,False,41.82408839480553,95.55664386860087
2087,"def handle_label ( self , path , * * options ) : <TAB>  verbosity = int ( options . get ( "" verbosity "" , 1 ) ) <TAB>  result = finders . find ( path , all = options [ "" all "" ] ) <TAB>  path = smart_unicode ( path ) <TAB>  if result : <TAB><TAB>  if not isinstance ( result , ( list , tuple ) ) : <TAB><TAB><TAB>  result = [ result ] <TAB><TAB>  output = u "" \n<TAB>"" . join ( <TAB><TAB><TAB>  ( smart_unicode ( os . path . realpath ( path ) ) for path in result ) <TAB><TAB>  ) <TAB><TAB>  self . stdout . write ( smart_str ( u "" Found  ' %s '  here: \n<TAB>%s \n "" % ( path , output ) ) ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . stderr . write ( smart_str ( "" No matching file found for  ' %s ' . \n "" % path ) ) ",if verbosity >= 1 :,"if not finders.find(path, verbosity):",False,22.73545655825163,89.818237746972
2088,"def name ( self ) : <TAB>  """"""Get the enumeration name of this storage class."""""" <TAB>  if self . _name_map is None : <TAB><TAB>  self . _name_map = { } <TAB><TAB>  for key , value in list ( StorageClass . __dict__ . items ( ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _name_map [ value ] = key <TAB>  return self . _name_map [ self ] ","if isinstance ( value , StorageClass ) :",if key not in self._name_map:,False,51.05058632965665,92.06328079650783
2089,"def index ( self , value ) : <TAB>  if self . _growing : <TAB><TAB>  if self . _start < = value < self . _stop : <TAB><TAB><TAB>  q , r = divmod ( value - self . _start , self . _step ) <TAB><TAB><TAB>  if r == self . _zero : <TAB><TAB><TAB><TAB>  return int ( q ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  q , r = divmod ( self . _start - value , - self . _step ) <TAB><TAB><TAB>  if r == self . _zero : <TAB><TAB><TAB><TAB>  return int ( q ) <TAB>  raise ValueError ( "" {}  is not in numeric range "" . format ( value ) ) ",if self . _start >= value > self . _stop :,if self._start >= value:,False,25.271102828576137,95.96537056151969
2090,"def extract_cookie ( cookie_header , cookie_name ) : <TAB>  inx = cookie_header . find ( cookie_name ) <TAB>  if inx > = 0 : <TAB><TAB>  end_inx = cookie_header . find ( "" ; "" , inx ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = cookie_header [ inx : end_inx ] <TAB><TAB>  else : <TAB><TAB><TAB>  value = cookie_header [ inx : ] <TAB><TAB>  return value <TAB>  return "" "" ",if end_inx > 0 :,if end_inx >= 0:,False,42.217530484121404,98.11648427881292
2091,"def get_size ( self , shape_info ) : <TAB>  # The size is the data, that have constant size. <TAB>  state = np . random . RandomState ( ) . get_state ( ) <TAB>  size = 0 <TAB>  for elem in state : <TAB><TAB>  if isinstance ( elem , str ) : <TAB><TAB><TAB>  size + = len ( elem ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size + = elem . size * elem . itemsize <TAB><TAB>  elif isinstance ( elem , int ) : <TAB><TAB><TAB>  size + = np . dtype ( "" int "" ) . itemsize <TAB><TAB>  elif isinstance ( elem , float ) : <TAB><TAB><TAB>  size + = np . dtype ( "" float "" ) . itemsize <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError ( ) <TAB>  return size ","elif isinstance ( elem , np . ndarray ) :","if isinstance(elem, (int, float)):",False,32.143624705126456,95.94442462709019
2092,"def createFields ( self ) : <TAB>  size = self . size / 8 <TAB>  if size > 2 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield UInt8 ( self , "" cs "" , "" 10ms units, values from 0 to 199 "" ) <TAB><TAB>  yield Bits ( self , "" 2sec "" , 5 , "" seconds/2 "" ) <TAB><TAB>  yield Bits ( self , "" min "" , 6 , "" minutes "" ) <TAB><TAB>  yield Bits ( self , "" hour "" , 5 , "" hours "" ) <TAB>  yield Bits ( self , "" day "" , 5 , "" (1-31) "" ) <TAB>  yield Bits ( self , "" month "" , 4 , "" (1-12) "" ) <TAB>  yield Bits ( self , "" year "" , 7 , "" (0 = 1980, 127 = 2107) "" ) ",if size > 4 :,if size > 1:,False,54.927811496050026,98.72926730486742
2093,"def detect ( get_page ) : <TAB>  retval = False <TAB>  for vector in WAF_ATTACK_VECTORS : <TAB><TAB>  page , headers , code = get_page ( get = vector ) <TAB><TAB>  retval = ( <TAB><TAB><TAB>  re . search ( <TAB><TAB><TAB><TAB>  r "" incap_ses|visid_incap "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  is not None <TAB><TAB>  ) <TAB><TAB>  retval | = re . search ( r "" Incapsula "" , headers . get ( "" X-CDN "" , "" "" ) , re . I ) is not None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return retval ",if retval :,if retval:,False,19.233223239194267,100.00000000000004
2094,"def _get_order_information ( self , node_id , timeout = 1200 , check_interval = 5 ) : <TAB>  mask = { <TAB><TAB>  "" billingItem "" : "" "" , <TAB><TAB>  "" powerState "" : "" "" , <TAB><TAB>  "" operatingSystem "" : { "" passwords "" : "" "" } , <TAB><TAB>  "" provisionDate "" : "" "" , <TAB>  } <TAB>  for i in range ( 0 , timeout , check_interval ) : <TAB><TAB>  res = self . connection . request ( <TAB><TAB><TAB>  "" SoftLayer_Virtual_Guest "" , "" getObject "" , id = node_id , object_mask = mask <TAB><TAB>  ) . object <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return res <TAB><TAB>  time . sleep ( check_interval ) <TAB>  raise SoftLayerException ( "" Timeout on getting node details "" ) ","if res . get ( ""provisionDate"" , None ) :",if res:,False,30.627971465283377,95.17872832074997
2095,"def _process_param_change ( self , msg ) : <TAB>  msg = super ( Select , self ) . _process_param_change ( msg ) <TAB>  labels , values = self . labels , self . values <TAB>  if "" value "" in msg : <TAB><TAB>  msg [ "" value "" ] = [ <TAB><TAB><TAB>  labels [ indexOf ( v , values ) ] for v in msg [ "" value "" ] if isIn ( v , values ) <TAB><TAB>  ] <TAB>  if "" options "" in msg : <TAB><TAB>  msg [ "" options "" ] = labels <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . value = [ v for v in self . value if isIn ( v , values ) ] <TAB>  return msg ","if any ( not isIn ( v , values ) for v in self . value ) :",if self.value:,False,25.683917276020924,91.54421150250224
2096,"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB>  if not name : <TAB><TAB>  return None <TAB>  name = name . rstrip ( "" \\ "" ) <TAB>  for a , o in self . objects . items ( ) : <TAB><TAB>  if not o . name : <TAB><TAB><TAB>  continue <TAB><TAB>  if o . name . lower ( ) == name . lower ( ) : <TAB><TAB><TAB>  return o <TAB>  if check_symlinks : <TAB><TAB>  m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = m [ 0 ] <TAB><TAB>  return self . get_object_from_name ( name , False ) ",if m :,if len(m) == 1:,False,36.85967061708172,96.12953386941162
2097,"def run ( self ) : <TAB>  for k , v in iteritems ( self . objs ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if v [ "" _class "" ] == "" User "" : <TAB><TAB><TAB>  if v [ "" email "" ] == "" "" : <TAB><TAB><TAB><TAB>  v [ "" email "" ] = None <TAB><TAB><TAB>  if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB><TAB><TAB><TAB>  v [ "" ip "" ] = None <TAB>  return self . objs ","if k . startswith ( ""_"" ) :",if k == 'user':,False,48.849939532044026,94.51748786366075
2098,"def _providers ( self , descriptor ) : <TAB>  res = [ ] <TAB>  for _md in self . metadata . values ( ) : <TAB><TAB>  for ent_id , ent_desc in _md . items ( ) : <TAB><TAB><TAB>  if descriptor in ent_desc : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  # print(""duplicated entity_id: %s"" % res) <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  res . append ( ent_id ) <TAB>  return res ",if ent_id in res :,if ent_id in res:,False,55.88765596159482,100.00000000000004
2099,"def test_add_participant ( self ) : <TAB>  async with self . chat_client : <TAB><TAB>  await self . _create_thread ( ) <TAB><TAB>  async with self . chat_thread_client : <TAB><TAB><TAB>  share_history_time = datetime . utcnow ( ) <TAB><TAB><TAB>  share_history_time = share_history_time . replace ( tzinfo = TZ_UTC ) <TAB><TAB><TAB>  new_participant = ChatThreadParticipant ( <TAB><TAB><TAB><TAB>  user = self . new_user , <TAB><TAB><TAB><TAB>  display_name = "" name "" , <TAB><TAB><TAB><TAB>  share_history_time = share_history_time , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  await self . chat_thread_client . add_participant ( new_participant ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await self . chat_client . delete_chat_thread ( self . thread_id ) ",if not self . is_playback ( ) :,if self.thread_id:,False,27.240072331692193,96.70386691564033
2100,"def url ( regex , view , kwargs = None , name = None , prefix = "" "" ) : <TAB>  if isinstance ( view , ( list , tuple ) ) : <TAB><TAB>  # For include(...) processing. <TAB><TAB>  urlconf_module , app_name , namespace = view <TAB><TAB>  return RegexURLResolver ( <TAB><TAB><TAB>  regex , urlconf_module , kwargs , app_name = app_name , namespace = namespace <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  if isinstance ( view , basestring ) : <TAB><TAB><TAB>  if not view : <TAB><TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB>  "" Empty URL pattern view name not permitted (for pattern  %r ) "" % regex <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  view = prefix + "" . "" + view <TAB><TAB>  return RegexURLPattern ( regex , view , kwargs , name ) ",if prefix :,if prefix is not None:,False,57.06106166918661,98.24267944374645
2101,"def tx ( ) : <TAB>  # Sync receiver ready to avoid loss of first packets <TAB>  while not sub_ready . ready ( ) : <TAB><TAB>  pub . send ( b "" test BEGIN "" ) <TAB><TAB>  eventlet . sleep ( 0.005 ) <TAB>  for i in range ( 1 , 101 ) : <TAB><TAB>  msg = "" test  {0} "" . format ( i ) . encode ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pub . send ( msg ) <TAB><TAB>  else : <TAB><TAB><TAB>  pub . send ( b "" test LAST "" ) <TAB><TAB><TAB>  sub_last . wait ( ) <TAB><TAB>  # XXX: putting a real delay of 1ms here fixes sporadic failures on Travis <TAB><TAB>  # just yield eventlet.sleep(0) doesn't cut it <TAB><TAB>  eventlet . sleep ( 0.001 ) <TAB>  pub . send ( b "" done DONE "" ) ",if i != 50 :,"if msg in (b""TEST END""):",False,41.54229439710551,95.48013109310683
2102,"def remove_tmp_snapshot_file ( self , files ) : <TAB>  for filepath in files : <TAB><TAB>  path = Path ( filepath ) <TAB><TAB>  if path . is_dir ( ) and path . exists ( ) : <TAB><TAB><TAB>  shutil . rmtree ( path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path . unlink ( ) ",elif path . is_file ( ) and path . exists ( ) :,if path.exists():,False,23.9461127685127,89.65316949296829
2103,"def f ( view , s ) : <TAB>  if mode == modes . INTERNAL_NORMAL : <TAB><TAB>  if count == 1 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  eol = view . line ( s . b ) . b <TAB><TAB><TAB><TAB>  return R ( s . b , eol ) <TAB><TAB><TAB>  return s <TAB>  return s ",if view . line ( s . b ) . size ( ) > 0 :,if mode == modes.NORMAL:,False,44.81149706687041,86.86262147646018
2104,"def get_ids ( self , * * kwargs ) : <TAB>  id = [ ] <TAB>  if "" id "" in kwargs : <TAB><TAB>  id = kwargs [ "" id "" ] <TAB><TAB>  # Coerce ids to list <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  id = id . split ( "" , "" ) <TAB><TAB>  # Ensure ids are integers <TAB><TAB>  try : <TAB><TAB><TAB>  id = list ( map ( int , id ) ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  decorators . error ( "" Invalid id "" ) <TAB>  return id ","if not isinstance ( id , list ) :","if id.startswith('', ' '):",False,46.92222193815151,94.49335516554214
2105,"def param_value ( self ) : <TAB>  # This is part of the ""handle quoted extended parameters"" hack. <TAB>  for token in self : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return token . stripped_value <TAB><TAB>  if token . token_type == "" quoted-string "" : <TAB><TAB><TAB>  for token in token : <TAB><TAB><TAB><TAB>  if token . token_type == "" bare-quoted-string "" : <TAB><TAB><TAB><TAB><TAB>  for token in token : <TAB><TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  return token . stripped_value <TAB>  return "" "" ","if token . token_type == ""value"" :","if token.token_type == ""handle-quoted-string':",False,36.0539389541675,92.06132956055355
2106,"def get_all_start_methods ( self ) : <TAB>  if sys . platform == "" win32 "" : <TAB><TAB>  return [ "" spawn "" ] <TAB>  else : <TAB><TAB>  methods = [ "" spawn "" , "" fork "" ] if sys . platform == "" darwin "" else [ "" fork "" , "" spawn "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  methods . append ( "" forkserver "" ) <TAB><TAB>  return methods ",if reduction . HAVE_SEND_HANDLE :,if self.fork_server:,False,50.6002905464773,93.11012025382362
2107,"def _process_watch ( self , watched_event ) : <TAB>  logger . debug ( "" process_watch:  %r "" , watched_event ) <TAB>  with handle_exception ( self . _tree . _error_listeners ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert self . _parent is None , "" unexpected CREATED on non-root "" <TAB><TAB><TAB>  self . on_created ( ) <TAB><TAB>  elif watched_event . type == EventType . DELETED : <TAB><TAB><TAB>  self . on_deleted ( ) <TAB><TAB>  elif watched_event . type == EventType . CHANGED : <TAB><TAB><TAB>  self . _refresh_data ( ) <TAB><TAB>  elif watched_event . type == EventType . CHILD : <TAB><TAB><TAB>  self . _refresh_children ( ) ",if watched_event . type == EventType . CREATED :,if watched_event.type == EventType.CREATED:,False,25.91761287659774,100.00000000000004
2108,"def assert_open ( self , sock , * rest ) : <TAB>  if isinstance ( sock , fd_types ) : <TAB><TAB>  self . __assert_fd_open ( sock ) <TAB>  else : <TAB><TAB>  fileno = sock . fileno ( ) <TAB><TAB>  assert isinstance ( fileno , fd_types ) , fileno <TAB><TAB>  sockname = sock . getsockname ( ) <TAB><TAB>  assert isinstance ( sockname , tuple ) , sockname <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __assert_fd_open ( fileno ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _assert_sock_open ( sock ) <TAB>  if rest : <TAB><TAB>  self . assert_open ( rest [ 0 ] , * rest [ 1 : ] ) ",if not WIN :,"if isinstance(sock, (socket, socket)):",False,22.39017178633029,94.31596099214646
2109,"def detype ( self ) : <TAB>  """"""De-types the instance, allowing it to be exported to the environment."""""" <TAB>  style = self . style <TAB>  if self . _detyped is None : <TAB><TAB>  self . _detyped = "" : "" . join ( <TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB>  key <TAB><TAB><TAB><TAB>  + "" = "" <TAB><TAB><TAB><TAB>  + "" ; "" . join ( <TAB><TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB><TAB>  LsColors . target_value <TAB><TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  else ansi_color_name_to_escape_code ( v , cmap = style ) <TAB><TAB><TAB><TAB><TAB><TAB>  for v in val <TAB><TAB><TAB><TAB><TAB>  ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  for key , val in sorted ( self . _d . items ( ) ) <TAB><TAB><TAB>  ] <TAB><TAB>  ) <TAB>  return self . _detyped ",if key in self . _targets,if style is None:,False,51.739377352488816,97.69494891529118
2110,"def gather_metrics ( dry_run = False ) : <TAB>  today = datetime . date . today ( ) <TAB>  first = today . replace ( day = 1 ) <TAB>  last_month = first - datetime . timedelta ( days = 1 ) <TAB>  filename = "" form_types_ {} .csv "" . format ( last_month . strftime ( "" % Y- % m "" ) ) <TAB>  with connection . cursor ( ) as cursor : <TAB><TAB>  cursor . execute ( REGISTRATION_METRICS_SQL ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for row in cursor . fetchall ( ) : <TAB><TAB><TAB><TAB>  logger . info ( encode_row ( row ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  write_raw_data ( cursor = cursor , filename = filename ) ",if dry_run :,if dry_run:,False,52.20941717139609,100.00000000000004
2111,"def cat ( tensors , dim = 0 ) : <TAB>  assert isinstance ( tensors , list ) , "" input to cat must be a list "" <TAB>  if len ( tensors ) == 1 : <TAB><TAB>  return tensors [ 0 ] <TAB>  from . autograd_cryptensor import AutogradCrypTensor <TAB>  if any ( isinstance ( t , AutogradCrypTensor ) for t in tensors ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tensors [ 0 ] = AutogradCrypTensor ( tensors [ 0 ] , requires_grad = False ) <TAB><TAB>  return tensors [ 0 ] . cat ( * tensors [ 1 : ] , dim = dim ) <TAB>  else : <TAB><TAB>  return get_default_backend ( ) . cat ( tensors , dim = dim ) ","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :","if isinstance(t, AutogradCrypTensor):",False,48.790625211876936,95.61444078515895
2112,"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB>  installed = False <TAB>  if dlc_title : <TAB><TAB>  dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB><TAB>  installed = True if dlc_version else False <TAB><TAB>  # Start: Code for compatibility with minigalaxy 1.0 <TAB><TAB>  if not installed : <TAB><TAB><TAB>  status = self . legacy_get_dlc_status ( dlc_title ) <TAB><TAB><TAB>  installed = True if status in [ "" installed "" , "" updatable "" ] else False <TAB><TAB>  # End: Code for compatibility with minigalaxy 1.0 <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  installed = True <TAB>  return installed ",if self . install_dir and os . path . exists ( self . install_dir ) :,if self.is_installed(dlc_title):,False,60.903554665913454,92.46220723911723
2113,"def on_copy ( self ) : <TAB>  source_objects = self . __getSelection ( ) <TAB>  for source in source_objects : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_obj = model . Phrase ( "" "" , "" "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  new_obj = model . Script ( "" "" , "" "" ) <TAB><TAB>  new_obj . copy ( source ) <TAB><TAB>  self . cutCopiedItems . append ( new_obj ) ","if isinstance ( source , model . Phrase ) :",if source == self.selected_source:,False,46.935615178977685,93.07945568240274
2114,"def FetchFn ( type_name ) : <TAB>  """"""Fetches all hunt results of a given type."""""" <TAB>  offset = 0 <TAB>  while True : <TAB><TAB>  results = data_store . REL_DB . ReadHuntResults ( <TAB><TAB><TAB>  hunt_id , offset = offset , count = self . _RESULTS_PAGE_SIZE , with_type = type_name <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  for r in results : <TAB><TAB><TAB>  msg = r . AsLegacyGrrMessage ( ) <TAB><TAB><TAB>  msg . source_urn = source_urn <TAB><TAB><TAB>  yield msg <TAB><TAB>  offset + = self . _RESULTS_PAGE_SIZE ",if not results :,if results is None:,False,25.891586447883718,97.76130857278173
2115,"def get_blob_type_declaration_sql ( self , column ) : <TAB>  length = column . get ( "" length "" ) <TAB>  if length : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" TINYBLOB "" <TAB><TAB>  if length < = self . LENGTH_LIMIT_BLOB : <TAB><TAB><TAB>  return "" BLOB "" <TAB><TAB>  if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB><TAB><TAB>  return "" MEDIUMBLOB "" <TAB>  return "" LONGBLOB "" ",if length <= self . LENGTH_LIMIT_TINYBLOB :,if length <= self.LENGTH_LIMIT_TINYBLOB:,False,46.21792598695114,100.00000000000004
2116,"def decode ( cls , data ) : <TAB>  while data : <TAB><TAB>  ( <TAB><TAB><TAB>  length , <TAB><TAB><TAB>  atype , <TAB><TAB>  ) = unpack ( cls . Header . PACK , data [ : cls . Header . LEN ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AttributesError ( "" Buffer underrun  %d  <  %d "" % ( len ( data ) , length ) ) <TAB><TAB>  payload = data [ cls . Header . LEN : length ] <TAB><TAB>  yield atype , payload <TAB><TAB>  data = data [ int ( ( length + 3 ) / 4 ) * 4 : ] ",if len ( data ) < length :,if length < cls.Header.LEN:,False,27.917257302941245,95.15163765045217
2117,"def test_join_diffs ( db , series_of_diffs , expected ) : <TAB>  diffs = [ ] <TAB>  for changes in series_of_diffs : <TAB><TAB>  tracker = DBDiffTracker ( ) <TAB><TAB>  for key , val in changes . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del tracker [ key ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  tracker [ key ] = val <TAB><TAB>  diffs . append ( tracker . diff ( ) ) <TAB>  DBDiff . join ( diffs ) . apply_to ( db ) <TAB>  assert db == expected ",if val is None :,if key in tracker:,False,48.34630907554129,97.24036219875491
2118,"def ant_map ( m ) : <TAB>  tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB>  players = { } <TAB>  for row in m : <TAB><TAB>  tmp + = "" m  "" <TAB><TAB>  for col in row : <TAB><TAB><TAB>  if col == LAND : <TAB><TAB><TAB><TAB>  tmp + = "" . "" <TAB><TAB><TAB>  elif col == BARRIER : <TAB><TAB><TAB><TAB>  tmp + = "" % "" <TAB><TAB><TAB>  elif col == FOOD : <TAB><TAB><TAB><TAB>  tmp + = "" * "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tmp + = "" ? "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  players [ col ] = True <TAB><TAB><TAB><TAB>  tmp + = chr ( col + 97 ) <TAB><TAB>  tmp + = "" \n "" <TAB>  tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB>  return tmp ",elif col == UNSEEN :,if col == LAND:,False,18.313708441148606,97.13191052185874
2119,"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB>  if response : <TAB><TAB>  # Only include the text in case of error. <TAB><TAB>  if not response . ok : <TAB><TAB><TAB>  status = location . Status ( response . status_code , response . text ) <TAB><TAB>  else : <TAB><TAB><TAB>  status = location . Status ( response . status_code ) <TAB>  else : <TAB><TAB>  status = location . Status ( 500 , message ) <TAB>  if response is None or not response . ok : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return completion_routine ( status ) <TAB><TAB>  raise IOError ( response . text ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  completion_routine ( status ) <TAB>  return location . Status ( 200 , response . content ) ",if completion_routine :,if completion_routine:,False,59.46106852131068,97.56985106326752
2120,"def _generate_examples ( self , src_path = None , tgt_path = None , replace_unk = None ) : <TAB>  """"""Yields examples."""""" <TAB>  with tf . io . gfile . GFile ( src_path ) as f_d , tf . io . gfile . GFile ( tgt_path ) as f_s : <TAB><TAB>  for i , ( doc_text , sum_text ) in enumerate ( zip ( f_d , f_s ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield i , { <TAB><TAB><TAB><TAB><TAB>  _DOCUMENT : doc_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB><TAB><TAB><TAB><TAB>  _SUMMARY : sum_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield i , { _DOCUMENT : doc_text . strip ( ) , _SUMMARY : sum_text . strip ( ) } ",if replace_unk :,if replace_unk:,False,50.341106717033156,100.00000000000004
2121,"def escape ( text , newline = False ) : <TAB>  """"""Escape special html characters."""""" <TAB>  if isinstance ( text , str ) : <TAB><TAB>  if "" & "" in text : <TAB><TAB><TAB>  text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB>  if "" > "" in text : <TAB><TAB><TAB>  text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB>  if "" < "" in text : <TAB><TAB><TAB>  text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB>  if ' "" ' in text : <TAB><TAB><TAB>  text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB>  if "" ' "" in text : <TAB><TAB><TAB>  text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" \n "" in text : <TAB><TAB><TAB><TAB>  text = text . replace ( "" \n "" , "" <br> "" ) <TAB>  return text ",if newline :,if newline:,False,50.07033856594993,100.00000000000004
2122,"def _handle_url_click ( self , event ) : <TAB>  url = _extract_click_text ( self . info_text , event , "" url "" ) <TAB>  if url is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  import webbrowser <TAB><TAB><TAB>  webbrowser . open ( url ) <TAB><TAB>  elif os . path . sep in url : <TAB><TAB><TAB>  os . makedirs ( url , exist_ok = True ) <TAB><TAB><TAB>  open_path_in_system_file_manager ( url ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _start_show_package_info ( url ) ","if url . startswith ( ""http:"" ) or url . startswith ( ""https:"" ) :",if os.name == 'nt':,False,48.75245437656468,88.95224179256371
2123,"def SConsignFile ( self , name = "" .sconsign "" , dbm_module = None ) : <TAB>  if name is not None : <TAB><TAB>  name = self . subst ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = os . path . join ( str ( self . fs . SConstruct_dir ) , name ) <TAB>  if name : <TAB><TAB>  name = os . path . normpath ( name ) <TAB><TAB>  sconsign_dir = os . path . dirname ( name ) <TAB><TAB>  if sconsign_dir and not os . path . exists ( sconsign_dir ) : <TAB><TAB><TAB>  self . Execute ( SCons . Defaults . Mkdir ( sconsign_dir ) ) <TAB>  SCons . SConsign . File ( name , dbm_module ) ",if not os . path . isabs ( name ) :,if self.fs.SConstruct_dir:,False,26.952176444050885,94.71450408955101
2124,"def on_train_start ( self , trainer : Trainer , pl_module : LightningModule ) - > None : <TAB>  super ( ) . on_train_start ( trainer , pl_module ) <TAB>  submodule_dict = dict ( pl_module . named_modules ( ) ) <TAB>  self . _hook_handles = [ ] <TAB>  for name in self . _get_submodule_names ( pl_module ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rank_zero_warn ( <TAB><TAB><TAB><TAB>  f "" { name }  is not a valid identifier for a submodule in  { pl_module . __class__ . __name__ } , "" <TAB><TAB><TAB><TAB>  ""  skipping this key. "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  continue <TAB><TAB>  handle = self . _register_hook ( name , submodule_dict [ name ] ) <TAB><TAB>  self . _hook_handles . append ( handle ) ",if name not in submodule_dict :,if name not in submodule_dict:,False,57.06253602455935,100.00000000000004
2125,"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB>  super ( ) . validate_configuration ( configuration ) <TAB>  if configuration is None : <TAB><TAB>  configuration = self . configuration <TAB>  try : <TAB><TAB>  assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB><TAB>  assert isinstance ( <TAB><TAB><TAB>  configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB><TAB>  ) , "" value_set must be a list or a set "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert ( <TAB><TAB><TAB><TAB>  "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB><TAB><TAB>  ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key. ' <TAB>  except AssertionError as e : <TAB><TAB>  raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB>  return True ","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",if configuration.kwargs.get('value_set'):,False,56.802638340019165,93.48356008168197
2126,"def check_refcounts ( expected , timeout = 10 ) : <TAB>  start = time . time ( ) <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  _check_refcounts ( expected ) <TAB><TAB><TAB>  break <TAB><TAB>  except AssertionError as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise e <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  time . sleep ( 0.1 ) ",if time . time ( ) - start > timeout :,if e.code == errno.EINVAL:,False,48.38949262590598,92.36758420735458
2127,"def pickline ( file , key , casefold = 1 ) : <TAB>  try : <TAB><TAB>  f = open ( file , "" r "" ) <TAB>  except IOError : <TAB><TAB>  return None <TAB>  pat = re . escape ( key ) + "" : "" <TAB>  prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB>  while 1 : <TAB><TAB>  line = f . readline ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  if prog . match ( line ) : <TAB><TAB><TAB>  text = line [ len ( key ) + 1 : ] <TAB><TAB><TAB>  while 1 : <TAB><TAB><TAB><TAB>  line = f . readline ( ) <TAB><TAB><TAB><TAB>  if not line or not line [ 0 ] . isspace ( ) : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  text = text + line <TAB><TAB><TAB>  return text . strip ( ) <TAB>  return None ",if not line :,if not line or not line:,False,40.30398768098733,98.77056346325405
2128,def _is_perf_file ( file_path ) : <TAB>  f = get_file ( file_path ) <TAB>  for line in f : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  r = event_regexp . search ( line ) <TAB><TAB>  if r : <TAB><TAB><TAB>  f . close ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  f . close ( ) <TAB><TAB>  return False ,"if line [ 0 ] == ""#"" :",if line.startswith('#'):,False,48.49851578227721,92.78899654163796
2129,"def link_pantsrefs ( soups , precomputed ) : <TAB>  """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB>  for ( page , soup ) in soups . items ( ) : <TAB><TAB>  for a in soup . find_all ( "" a "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  pantsref = a [ "" pantsref "" ] <TAB><TAB><TAB>  if pantsref not in precomputed . pantsref : <TAB><TAB><TAB><TAB>  raise TaskError ( <TAB><TAB><TAB><TAB><TAB>  f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] ) ","if not a . has_attr ( ""pantsref"" ) :",if not a.get('pantsref'):,False,38.287765350408534,94.49509911197379
2130,"def __init__ ( self , querylist = None ) : <TAB>  self . query_id = - 1 <TAB>  if querylist is None : <TAB><TAB>  self . querylist = [ ] <TAB>  else : <TAB><TAB>  self . querylist = querylist <TAB><TAB>  for query in self . querylist : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . query_id = query . query_id <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  if self . query_id != query . query_id : <TAB><TAB><TAB><TAB><TAB>  raise ValueError ( "" query in list must be same query_id "" ) ",if self . query_id == - 1 :,"if isinstance(query, Query):",False,49.31936649280217,93.47256854129225
2131,"def _draw_number ( <TAB>  screen , x_offset , y_offset , number , token = Token . Clock , transparent = False  ) : <TAB>  "" Write number at position. "" <TAB>  fg = Char ( "" "" , token ) <TAB>  bg = Char ( "" "" , Token ) <TAB>  for y , row in enumerate ( _numbers [ number ] ) : <TAB><TAB>  screen_row = screen . data_buffer [ y + y_offset ] <TAB><TAB>  for x , n in enumerate ( row ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  screen_row [ x + x_offset ] = fg <TAB><TAB><TAB>  elif not transparent : <TAB><TAB><TAB><TAB>  screen_row [ x + x_offset ] = bg ","if n == ""#"" :",if n == 0:,False,47.18334859732332,97.71909067626518
2132,"def init ( self ) : <TAB>  self . sock . setblocking ( True ) <TAB>  if self . parser is None : <TAB><TAB>  # wrap the socket if needed <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . sock = ssl . wrap_socket ( <TAB><TAB><TAB><TAB>  self . sock , server_side = True , * * self . cfg . ssl_options <TAB><TAB><TAB>  ) <TAB><TAB>  # initialize the parser <TAB><TAB>  self . parser = http . RequestParser ( self . cfg , self . sock ) ",if self . cfg . is_ssl :,if ssl.is_socket(self.sock):,False,55.10646622035047,93.85169125355405
2133,"def intersect_face ( pt ) : <TAB>  # todo: rewrite! inefficient! <TAB>  nonlocal vis_faces2D <TAB>  for f , vs in vis_faces2D : <TAB><TAB>  v0 = vs [ 0 ] <TAB><TAB>  for v1 , v2 in iter_pairs ( vs [ 1 : ] , False ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return f <TAB>  return None ","if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :",if v0 == v1 and v0 == v2:,False,26.252486185239537,85.61011702674766
2134,"def IMPORTFROM ( self , node ) : <TAB>  if node . module == "" __future__ "" : <TAB><TAB>  if not self . futuresAllowed : <TAB><TAB><TAB>  self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB>  else : <TAB><TAB>  self . futuresAllowed = False <TAB>  for alias in node . names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . scope . importStarred = True <TAB><TAB><TAB>  self . report ( messages . ImportStarUsed , node , node . module ) <TAB><TAB><TAB>  continue <TAB><TAB>  name = alias . asname or alias . name <TAB><TAB>  importation = Importation ( name , node ) <TAB><TAB>  if node . module == "" __future__ "" : <TAB><TAB><TAB>  importation . used = ( self . scope , node ) <TAB><TAB>  self . addBinding ( node , importation ) ","if alias . name == ""*"" :",if alias.asname == node.name:,False,49.51866426623421,97.3914974481526
2135,"def PyObject_Bytes ( obj ) : <TAB>  if type ( obj ) == bytes : <TAB><TAB>  return obj <TAB>  if hasattr ( obj , "" __bytes__ "" ) : <TAB><TAB>  res = obj . __bytes__ ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  "" __bytes__ returned non-bytes (type  %s ) "" % type ( res ) . __name__ <TAB><TAB><TAB>  ) <TAB>  return PyBytes_FromObject ( obj ) ","if not isinstance ( res , bytes ) :","if not isinstance(res, (bytes, bytearray)):",False,25.009218855881855,95.77817491002267
2136,"def on_bt_search_clicked ( self , widget ) : <TAB>  if self . current_provider is None : <TAB><TAB>  return <TAB>  query = self . en_query . get_text ( ) <TAB>  @self . obtain_podcasts_with <TAB>  def load_data ( ) : <TAB><TAB>  if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB><TAB><TAB>  return self . current_provider . on_search ( query ) <TAB><TAB>  elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB><TAB><TAB>  return self . current_provider . on_url ( query ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . current_provider . on_file ( query ) ",elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,if self.current_provider.kind == directory.Provider.PROVIDER_FILE:,False,50.86647023711925,98.78485915987739
2137,"def remove ( self , name ) : <TAB>  for s in [ self . __storage ( self . __category ) , self . __storage ( None ) ] : <TAB><TAB>  for i , b in enumerate ( s ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del s [ i ] <TAB><TAB><TAB><TAB>  if b . persistent : <TAB><TAB><TAB><TAB><TAB>  self . __save ( ) <TAB><TAB><TAB><TAB>  return <TAB>  raise KeyError ( name ) ",if b . name == name :,if name == i:,False,24.32066307750264,95.88450431002066
2138,"def _wrapper ( data , axis = None , keepdims = False ) : <TAB>  if not keepdims : <TAB><TAB>  return func ( data , axis = axis ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  axis = axis if isinstance ( axis , int ) else axis [ 0 ] <TAB><TAB><TAB>  out_shape = list ( data . shape ) <TAB><TAB><TAB>  out_shape [ axis ] = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  out_shape = [ 1 for _ in range ( len ( data . shape ) ) ] <TAB><TAB>  return func ( data , axis = axis ) . reshape ( out_shape ) ",if axis is not None :,if axis is not None:,False,52.6995287430261,100.00000000000004
2139,"def authn_info ( self ) : <TAB>  res = [ ] <TAB>  for astat in self . assertion . authn_statement : <TAB><TAB>  context = astat . authn_context <TAB><TAB>  try : <TAB><TAB><TAB>  authn_instant = astat . authn_instant <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  authn_instant = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  aclass = context . authn_context_class_ref . text <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  aclass = "" "" <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  authn_auth = [ a . text for a in context . authenticating_authority ] <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  authn_auth = [ ] <TAB><TAB><TAB>  res . append ( ( aclass , authn_auth , authn_instant ) ) <TAB>  return res ",if context :,if context:,False,51.629897049602405,100.00000000000004
2140,"def _persist_metadata ( self , dirname , filename ) : <TAB>  metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB>  if self . media_metadata or self . comments or self . include_location : <TAB><TAB>  if self . posts : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB>  if self . stories : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . save_json ( { "" GraphStories "" : self . stories } , metadata_path ) ",if self . latest :,if self.media_metadata:,False,49.61659898304234,96.49697243448271
2141,"def update_record_image_detail ( input_image_record , updated_image_detail , session = None ) : <TAB>  if not session : <TAB><TAB>  session = db . Session <TAB>  image_record = { } <TAB>  image_record . update ( input_image_record ) <TAB>  image_record . pop ( "" created_at "" , None ) <TAB>  image_record . pop ( "" last_updated "" , None ) <TAB>  if image_record [ "" image_type "" ] == "" docker "" : <TAB><TAB>  for tag_record in updated_image_detail : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  image_record [ "" image_detail "" ] . append ( tag_record ) <TAB><TAB><TAB><TAB>  return update_record ( image_record , session = session ) <TAB>  return image_record ","if tag_record not in image_record [ ""image_detail"" ] :",if tag_record in image_record['image_detail']:,False,50.79112233525651,96.08958868658917
2142,"def backup ( self ) : <TAB>  for ds in [ ( "" activedirectory "" , "" AD "" ) , ( "" ldap "" , "" LDAP "" ) , ( "" nis "" , "" NIS "" ) ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  ds_cache = self . middleware . call_sync ( "" cache.get "" , f "" { ds [ 1 ] } _cache "" ) <TAB><TAB><TAB><TAB>  with open ( f "" /var/db/system/. { ds [ 1 ] } _cache_backup "" , "" wb "" ) as f : <TAB><TAB><TAB><TAB><TAB>  pickle . dump ( ds_cache , f ) <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  self . logger . debug ( "" No cache exists for directory service [ %s ]. "" , ds [ 0 ] ) ","if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :",if ds[0] == 'activedirectory':,False,22.47496952795201,89.2554856763298
2143,"def parse_setup_cfg ( self ) : <TAB>  # type: () -> Dict[STRING_TYPE, Any] <TAB>  if self . setup_cfg is not None and self . setup_cfg . exists ( ) : <TAB><TAB>  contents = self . setup_cfg . read_text ( ) <TAB><TAB>  base_dir = self . setup_cfg . absolute ( ) . parent . as_posix ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  parsed = setuptools_parse_setup_cfg ( self . setup_cfg . as_posix ( ) ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  if six . PY2 : <TAB><TAB><TAB><TAB>  contents = self . setup_cfg . read_bytes ( ) <TAB><TAB><TAB>  parsed = parse_setup_cfg ( contents , base_dir ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return { } <TAB><TAB>  return parsed <TAB>  return { } ",if not parsed :,if parsed is None:,False,30.77256347967328,98.24268914665531
2144,"def parts ( ) : <TAB>  for l in lists . leaves : <TAB><TAB>  head_name = l . get_head_name ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield l . leaves <TAB><TAB>  elif head_name != "" System`Missing "" : <TAB><TAB><TAB>  raise MessageException ( "" Catenate "" , "" invrp "" , l ) ","if head_name == ""System`List"" :","if head_name == ""System`Leaves':",False,16.006602545507487,96.60896868374306
2145,"def _get_callback_and_order ( self , hook ) : <TAB>  if callable ( hook ) : <TAB><TAB>  return hook , None <TAB>  elif isinstance ( hook , tuple ) and len ( hook ) == 2 : <TAB><TAB>  callback , order = hook <TAB><TAB>  # test that callback is a callable <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Hook callback is not a callable "" ) <TAB><TAB>  # test that number is an int <TAB><TAB>  try : <TAB><TAB><TAB>  int ( order ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  raise ValueError ( "" Hook order is not a number "" ) <TAB><TAB>  return callback , order <TAB>  else : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" Invalid hook definition, neither a callable nor a 2-tuple (callback, order):  {!r} "" . format ( <TAB><TAB><TAB><TAB>  hook <TAB><TAB><TAB>  ) <TAB><TAB>  ) ",if not callable ( callback ) :,if not callable(callback):,False,64.03327838857851,100.00000000000004
2146,"def _resize_masks ( self , results ) : <TAB>  """"""Resize masks with ``results['scale']``"""""" <TAB>  for key in results . get ( "" mask_fields "" , [ ] ) : <TAB><TAB>  if results [ key ] is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  results [ key ] = results [ key ] . rescale ( results [ "" scale "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  results [ key ] = results [ key ] . resize ( results [ "" img_shape "" ] [ : 2 ] ) ",if self . keep_ratio :,if results['scale']:,False,48.19902446189811,95.84238688846159
2147,"def getDataMax ( self ) : <TAB>  result = - Double . MAX_VALUE <TAB>  nCurves = self . chart . getNCurves ( ) <TAB>  for i in range ( nCurves ) : <TAB><TAB>  c = self . getSystemCurve ( i ) <TAB><TAB>  if not c . isVisible ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  nPoints = c . getNPoints ( ) <TAB><TAB><TAB>  for j in range ( nPoints ) : <TAB><TAB><TAB><TAB>  result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB>  if result == - Double . MAX_VALUE : <TAB><TAB>  return Double . NaN <TAB>  return result ",if c . getYAxis ( ) == Y_AXIS :,if c.isVisible():,False,23.00504192609799,92.54599409826095
2148,"def _check_token ( self ) : <TAB>  if settings . app . sso_client_cache and self . server_auth_token : <TAB><TAB>  doc = self . sso_client_cache_collection . find_one ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" user_id "" : self . user . id , <TAB><TAB><TAB><TAB>  "" server_id "" : self . server . id , <TAB><TAB><TAB><TAB>  "" device_id "" : self . device_id , <TAB><TAB><TAB><TAB>  "" device_name "" : self . device_name , <TAB><TAB><TAB><TAB>  "" auth_token "" : self . server_auth_token , <TAB><TAB><TAB>  } <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . has_token = True ",if doc :,if doc:,False,51.1622416041004,100.00000000000004
2149,"def parse_header ( plyfile , ext ) : <TAB>  # Variables <TAB>  line = [ ] <TAB>  properties = [ ] <TAB>  num_points = None <TAB>  while b "" end_header "" not in line and line != b "" "" : <TAB><TAB>  line = plyfile . readline ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line = line . split ( ) <TAB><TAB><TAB>  num_points = int ( line [ 2 ] ) <TAB><TAB>  elif b "" property "" in line : <TAB><TAB><TAB>  line = line . split ( ) <TAB><TAB><TAB>  properties . append ( ( line [ 2 ] . decode ( ) , ext + ply_dtypes [ line [ 1 ] ] ) ) <TAB>  return num_points , properties ","if b""element"" in line :","if b""num_points"" in line:",False,30.921262690842983,97.70487830978938
2150,"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB>  if self . data : <TAB><TAB>  run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB><TAB>  for finfo in self . data : <TAB><TAB><TAB>  self . __update_editor_margins ( finfo . editor ) <TAB><TAB><TAB>  finfo . cleanup_analysis_results ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if current_finfo is not finfo : <TAB><TAB><TAB><TAB><TAB>  finfo . run_code_analysis ( run_pyflakes , run_pep8 ) ",if ( run_pyflakes or run_pep8 ) and current_finfo is not None :,if self.pyflakes_enabled:,False,21.31500523514646,90.3836793372042
2151,"def __modules ( self ) : <TAB>  raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB>  for line in StringIO ( raw_output ) : <TAB><TAB>  line = line and line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  line_modules = line . split ( ) <TAB><TAB>  for module in line_modules : <TAB><TAB><TAB>  if module . endswith ( self . default_indicator ) : <TAB><TAB><TAB><TAB>  module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB><TAB><TAB>  module_parts = module . split ( "" / "" ) <TAB><TAB><TAB>  module_version = None <TAB><TAB><TAB>  if len ( module_parts ) == 2 : <TAB><TAB><TAB><TAB>  module_version = module_parts [ 1 ] <TAB><TAB><TAB>  module_name = module_parts [ 0 ] <TAB><TAB><TAB>  yield module_name , module_version ","if not line or line . startswith ( ""-"" ) :",if not line:,False,25.268789050135094,95.43763211113857
2152,"def _set_trailing_size ( self , size ) : <TAB>  if self . is_free ( ) : <TAB><TAB>  next_chunk = self . next_chunk ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . state . memory . store ( next_chunk . base , size , self . state . arch . bytes ) ",if next_chunk is not None :,if next_chunk:,False,20.439952938634693,94.83134228784962
2153,"def _execute_for_all_tables ( self , app , bind , operation , skip_tables = False ) : <TAB>  app = self . get_app ( app ) <TAB>  if bind == "" __all__ "" : <TAB><TAB>  binds = [ None ] + list ( app . config . get ( "" SQLALCHEMY_BINDS "" ) or ( ) ) <TAB>  elif isinstance ( bind , string_types ) or bind is None : <TAB><TAB>  binds = [ bind ] <TAB>  else : <TAB><TAB>  binds = bind <TAB>  for bind in binds : <TAB><TAB>  extra = { } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tables = self . get_tables_for_bind ( bind ) <TAB><TAB><TAB>  extra [ "" tables "" ] = tables <TAB><TAB>  op = getattr ( self . Model . metadata , operation ) <TAB><TAB>  op ( bind = self . get_engine ( app , bind ) , * * extra ) ",if not skip_tables :,if skip_tables:,False,45.02493134156366,98.94128443078274
2154,"def getFileName ( ) : <TAB>  extension = "" .json "" <TAB>  file = "" %s -stats "" % self . clusterName <TAB>  counter = 0 <TAB>  while True : <TAB><TAB>  suffix = str ( counter ) . zfill ( 3 ) + extension <TAB><TAB>  fullName = os . path . join ( self . statsPath , file + suffix ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return fullName <TAB><TAB>  counter + = 1 ",if not os . path . exists ( fullName ) :,if os.path.exists(fullName):,False,42.92787279143162,95.66923456011747
2155,def logic ( ) : <TAB>  # direction <TAB>  if goRight == ACTIVE : <TAB><TAB>  dir . next = DirType . RIGHT <TAB><TAB>  run . next = True <TAB>  elif goLeft == ACTIVE : <TAB><TAB>  dir . next = DirType . LEFT <TAB><TAB>  run . next = True <TAB>  # stop <TAB>  if stop == ACTIVE : <TAB><TAB>  run . next = False <TAB>  # counter action <TAB>  if run : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  q . next [ 4 : 1 ] = q [ 3 : ] <TAB><TAB><TAB>  q . next [ 0 ] = not q [ 3 ] <TAB><TAB>  else : <TAB><TAB><TAB>  q . next [ 3 : ] = q [ 4 : 1 ] <TAB><TAB><TAB>  q . next [ 3 ] = not q [ 0 ] ,if dir == DirType . LEFT :,if goRight == ACTIVE:,False,25.896452041065167,96.94620735105529
2156,"def test_broadcast ( self ) : <TAB>  """"""Test example broadcast functionality."""""" <TAB>  self . create_lang_connection ( "" 1000000000 "" , "" en "" ) <TAB>  self . create_lang_connection ( "" 1000000001 "" , "" en "" ) <TAB>  self . create_lang_connection ( "" 1000000002 "" , "" en "" ) <TAB>  self . create_lang_connection ( "" 1000000003 "" , "" es "" ) <TAB>  self . create_lang_connection ( "" 1000000004 "" , "" es "" ) <TAB>  app . lang_broadcast ( ) <TAB>  self . assertEqual ( 2 , len ( self . outbound ) ) <TAB>  for message in self . outbound : <TAB><TAB>  if message . text == "" hello "" : <TAB><TAB><TAB>  self . assertEqual ( 3 , len ( message . connections ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( 2 , len ( message . connections ) ) ","elif message . text == ""hola"" :","if message.text == ""hello':",False,23.35016185324404,97.35454099040363
2157,"def get_ovf_env ( dirname ) : <TAB>  env_names = ( "" ovf-env.xml "" , "" ovf_env.xml "" , "" OVF_ENV.XML "" , "" OVF-ENV.XML "" ) <TAB>  for fname in env_names : <TAB><TAB>  full_fn = os . path . join ( dirname , fname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  contents = util . load_file ( full_fn ) <TAB><TAB><TAB><TAB>  return ( fname , contents ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  util . logexc ( LOG , "" Failed loading ovf file  %s "" , full_fn ) <TAB>  return ( None , False ) ",if os . path . isfile ( full_fn ) :,if os.path.exists(full_fn):,False,51.724851944708384,98.72926730486742
2158,"def _calc_offsets_children ( self , offset , is_last ) : <TAB>  if self . elems : <TAB><TAB>  elem_last = self . elems [ - 1 ] <TAB><TAB>  for elem in self . elems : <TAB><TAB><TAB>  offset = elem . _calc_offsets ( offset , ( elem is elem_last ) ) <TAB><TAB>  offset + = _BLOCK_SENTINEL_LENGTH <TAB>  elif not self . props or self . id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  offset + = _BLOCK_SENTINEL_LENGTH <TAB>  return offset ",if not is_last :,if is_last:,False,35.605912635968714,96.74192712380358
2159,"def publish_state ( cls , payload , state ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if state == action_constants . LIVEACTION_STATUS_REQUESTED : <TAB><TAB><TAB><TAB>  cls . process ( payload ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  worker . get_worker ( ) . process ( payload ) <TAB>  except Exception : <TAB><TAB>  traceback . print_exc ( ) <TAB><TAB>  print ( payload ) ","if isinstance ( payload , LiveActionDB ) :",if state == action_constants.RUNNING:,False,23.943480863045707,93.0289898997541
2160,"def log_predictive_density ( self , x_test , y_test , Y_metadata = None ) : <TAB>  if isinstance ( x_test , list ) : <TAB><TAB>  x_test , y_test , ind = util . multioutput . build_XY ( x_test , y_test ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  Y_metadata = { "" output_index "" : ind , "" trials "" : np . ones ( ind . shape ) } <TAB>  return super ( MultioutputGP , self ) . log_predictive_density ( x_test , y_test , Y_metadata ) ",if Y_metadata is None :,if Y_metadata is None:,False,50.92932788343535,100.00000000000004
2161,"def minimalBases ( classes ) : <TAB>  """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB>  if not __python3 :<TAB># pragma: no cover <TAB><TAB>  classes = [ c for c in classes if c is not ClassType ] <TAB>  candidates = [ ] <TAB>  for m in classes : <TAB><TAB>  for n in classes : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  # m has no subclasses in 'classes' <TAB><TAB><TAB>  if m in candidates : <TAB><TAB><TAB><TAB>  candidates . remove ( m )<TAB># ensure that we're later in the list <TAB><TAB><TAB>  candidates . append ( m ) <TAB>  return candidates ","if issubclass ( n , m ) and m is not n :",if n is m:,False,58.28868279246049,92.71583444984078
2162,"def apply ( self , operations , rotations = None , * * kwargs ) : <TAB>  rotations = rotations or [ ] <TAB>  # apply the circuit operations <TAB>  for i , operation in enumerate ( operations ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise DeviceError ( <TAB><TAB><TAB><TAB>  "" Operation  {}  cannot be used after other Operations have already been applied  "" <TAB><TAB><TAB><TAB>  "" on a  {}  device. "" . format ( operation . name , self . short_name ) <TAB><TAB><TAB>  ) <TAB>  for operation in operations : <TAB><TAB>  self . _apply_operation ( operation ) <TAB>  # store the pre-rotated state <TAB>  self . _pre_rotated_state = self . _state <TAB>  # apply the circuit rotations <TAB>  for operation in rotations : <TAB><TAB>  self . _apply_operation ( operation ) ","if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :",if i == len(operations):,False,49.874678067336106,94.11792442776502
2163,"def __str__ ( self ) : <TAB>  txt = str ( self . _called ) <TAB>  if self . call_gas or self . call_value : <TAB><TAB>  gas = f "" gas:  { self . call_gas } "" if self . call_gas else "" "" <TAB><TAB>  value = f "" value:  { self . call_value } "" if self . call_value else "" "" <TAB><TAB>  salt = f "" salt:  { self . call_salt } "" if self . call_salt else "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  options = [ gas , value , salt ] <TAB><TAB><TAB>  txt + = "" { "" + "" , "" . join ( [ o for o in options if o != "" "" ] ) + "" } "" <TAB>  return txt + "" ( "" + "" , "" . join ( [ str ( a ) for a in self . _arguments ] ) + "" ) "" ",if gas or value or salt :,if self.call_value:,False,28.80216416562505,97.25936215163706
2164,"def pop ( self ) : <TAB>  """"""Pop a nonterminal.  (Internal)"""""" <TAB>  popdfa , popstate , popnode = self . stack . pop ( ) <TAB>  newnode = self . convert ( self . grammar , popnode ) <TAB>  if newnode is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dfa , state , node = self . stack [ - 1 ] <TAB><TAB><TAB>  node . children . append ( newnode ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . rootnode = newnode ",if self . stack :,if newnode.type == 'text':,False,49.01075781925183,92.02918015801603
2165,"def pollpacket ( self , wait ) : <TAB>  self . _stage0 ( ) <TAB>  if len ( self . buffer ) < self . bufneed : <TAB><TAB>  r , w , x = select . select ( [ self . sock . fileno ( ) ] , [ ] , [ ] , wait ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  try : <TAB><TAB><TAB>  s = self . sock . recv ( BUFSIZE ) <TAB><TAB>  except socket . error : <TAB><TAB><TAB>  raise EOFError <TAB><TAB>  if len ( s ) == 0 : <TAB><TAB><TAB>  raise EOFError <TAB><TAB>  self . buffer + = s <TAB><TAB>  self . _stage0 ( ) <TAB>  return self . _stage1 ( ) ",if len ( r ) == 0 :,if w == 0:,False,21.468712622093484,97.23825000159324
2166,"def increaseToolReach ( self ) : <TAB>  if self . draggingFace is not None : <TAB><TAB>  d = ( 1 , - 1 ) [ self . draggingFace & 1 ] <TAB><TAB>  <IF-STMT>:<TAB># xxxxx y <TAB><TAB><TAB>  d = - d <TAB><TAB>  self . draggingY + = d <TAB><TAB>  x , y , z = self . editor . mainViewport . cameraPosition <TAB><TAB>  pos = [ x , y , z ] <TAB><TAB>  pos [ self . draggingFace >> 1 ] + = d <TAB><TAB>  self . editor . mainViewport . cameraPosition = tuple ( pos ) <TAB>  else : <TAB><TAB>  self . cloneCameraDistance = self . editor . _incrementReach ( self . cloneCameraDistance ) <TAB>  return True ",if self . draggingFace >> 1 != 1 :,if d < 0:,False,42.840022860294205,91.22757440521583
2167,"def selectionToChunks ( self , remove = False , add = False ) : <TAB>  box = self . selectionBox ( ) <TAB>  if box : <TAB><TAB>  if box == self . level . bounds : <TAB><TAB><TAB>  self . selectedChunks = set ( self . level . allChunks ) <TAB><TAB><TAB>  return <TAB><TAB>  selectedChunks = self . selectedChunks <TAB><TAB>  boxedChunks = set ( box . chunkPositions ) <TAB><TAB>  if boxedChunks . issubset ( selectedChunks ) : <TAB><TAB><TAB>  remove = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  selectedChunks . difference_update ( boxedChunks ) <TAB><TAB>  else : <TAB><TAB><TAB>  selectedChunks . update ( boxedChunks ) <TAB>  self . selectionTool . selectNone ( ) ",if remove and not add :,if remove:,False,27.171443341482316,97.60733003686417
2168,"def __init__ ( self , * args , * * kwargs ) : <TAB>  super ( ProjectForm , self ) . __init__ ( * args , * * kwargs ) <TAB>  if self . instance . id : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . fields [ "" localfiletype "" ] . widget . attrs [ "" disabled "" ] = True <TAB><TAB><TAB>  self . fields [ "" localfiletype "" ] . required = False <TAB><TAB>  if ( <TAB><TAB><TAB>  self . instance . treestyle != "" auto "" <TAB><TAB><TAB>  and self . instance . translationproject_set . count ( ) <TAB><TAB><TAB>  and self . instance . treestyle == self . instance . _detect_treestyle ( ) <TAB><TAB>  ) : <TAB><TAB><TAB>  self . fields [ "" treestyle "" ] . widget . attrs [ "" disabled "" ] = True <TAB><TAB><TAB>  self . fields [ "" treestyle "" ] . required = False ",if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,if self.instance.id == 'localfiletype':,False,44.83861505631683,91.96219226058714
2169,"def _infer_return_type ( * args ) : <TAB>  """"""Look at the type of all args and divine their implied return type."""""" <TAB>  return_type = None <TAB>  for arg in args : <TAB><TAB>  if arg is None : <TAB><TAB><TAB>  continue <TAB><TAB>  if isinstance ( arg , bytes ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = bytes <TAB><TAB>  else : <TAB><TAB><TAB>  if return_type is bytes : <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = str <TAB>  if return_type is None : <TAB><TAB>  return str<TAB># tempfile APIs return a str by default. <TAB>  return return_type ",if return_type is str :,if return_type is None:,False,56.02447847836848,93.61270650822367
2170,"def deleteDuplicates ( gadgets , callback = None ) : <TAB>  toReturn = [ ] <TAB>  inst = set ( ) <TAB>  count = 0 <TAB>  added = False <TAB>  len_gadgets = len ( gadgets ) <TAB>  for i , gadget in enumerate ( gadgets ) : <TAB><TAB>  inst . add ( gadget . _gadget ) <TAB><TAB>  if len ( inst ) > count : <TAB><TAB><TAB>  count = len ( inst ) <TAB><TAB><TAB>  toReturn . append ( gadget ) <TAB><TAB><TAB>  added = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB><TAB><TAB>  added = False <TAB>  return toReturn ",if callback :,if callback:,False,50.64768811083793,100.00000000000004
2171,"def send_all ( self , data : bytes ) : <TAB>  with self . _conflict_detector : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise _core . ClosedResourceError ( "" this pipe is already closed "" ) <TAB><TAB>  if not data : <TAB><TAB><TAB>  await _core . checkpoint ( ) <TAB><TAB><TAB>  return <TAB><TAB>  try : <TAB><TAB><TAB>  written = await _core . write_overlapped ( self . _handle_holder . handle , data ) <TAB><TAB>  except BrokenPipeError as ex : <TAB><TAB><TAB>  raise _core . BrokenResourceError from ex <TAB><TAB>  # By my reading of MSDN, this assert is guaranteed to pass so long <TAB><TAB>  # as the pipe isn't in nonblocking mode, but... let's just <TAB><TAB>  # double-check. <TAB><TAB>  assert written == len ( data ) ",if self . _handle_holder . closed :,if self._handle_holder.handle is not None:,False,64.07656037072205,97.59978066830975
2172,"def setup_parameter_node ( self , param_node ) : <TAB>  if param_node . bl_idname == "" SvNumberNode "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB><TAB><TAB>  print ( "" V "" , value ) <TAB><TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB><TAB>  param_node . selected_mode = "" int "" <TAB><TAB><TAB><TAB>  param_node . int_ = value <TAB><TAB><TAB>  elif isinstance ( value , float ) : <TAB><TAB><TAB><TAB>  param_node . selected_mode = "" float "" <TAB><TAB><TAB><TAB>  param_node . float_ = value ",if self . use_prop or self . get_prop_name ( ) :,if self.sv_get():,False,47.51182495187668,94.32758541213583
2173,"def collect_active_inst_idx_list ( inst_beams , word_prob , inst_idx_to_position_map ) : <TAB>  active_inst_idx_list = [ ] <TAB>  for inst_idx , inst_position in inst_idx_to_position_map . items ( ) : <TAB><TAB>  is_inst_complete = inst_beams [ inst_idx ] . advance ( word_prob [ inst_position ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  active_inst_idx_list + = [ inst_idx ] <TAB>  return active_inst_idx_list ",if not is_inst_complete :,if is_inst_complete:,False,26.860022049871258,98.30077746492107
2174,"def compare_member_req_resp_without_key ( self , request , response ) : <TAB>  for user_response in resp_json ( response ) [ "" data "" ] : <TAB><TAB>  for user_request in request : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  assert user_request [ "" role "" ] == user_response [ "" role "" ] ","if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :",if user_request['key'] == user_response['key']:,False,26.495860535013264,88.55872252871728
2175,"def __init__ ( self , dir ) : <TAB>  self . module_names = set ( ) <TAB>  for name in os . listdir ( dir ) : <TAB><TAB>  if name . endswith ( "" .py "" ) : <TAB><TAB><TAB>  self . module_names . add ( name [ : - 3 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . module_names . add ( name ) ","elif ""."" not in name :",if name.endswith('.py'):,False,48.958130111571016,87.82186312551883
2176,"def _read_filter ( self , data ) : <TAB>  if data : <TAB><TAB>  if self . expected_inner_sha256 : <TAB><TAB><TAB>  self . inner_sha . update ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . inner_md5 . update ( data ) <TAB>  return data ",if self . expected_inner_md5sum :,if self.expected_inner_md5:,False,26.284931020878883,97.15003449158377
2177,"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB>  res = [ ] <TAB>  while True : <TAB><TAB>  res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  if s . consume_re ( _newline_esc_re ) : <TAB><TAB><TAB>  pass <TAB><TAB>  elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB><TAB><TAB>  res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  s . expect_re ( _escapes_re ) <TAB><TAB><TAB>  res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB>  return "" "" . join ( res ) ","if not s . consume ( ""\\"" ) :",if s.consume_re(_whitespace_esc_re):,False,35.70899412834826,95.29890561609706
2178,"def process_response ( self , request , response ) : <TAB>  if ( <TAB><TAB>  response . status_code == 404 <TAB><TAB>  and request . path_info . endswith ( "" / "" ) <TAB><TAB>  and not is_valid_path ( request . path_info ) <TAB><TAB>  and is_valid_path ( request . path_info [ : - 1 ] ) <TAB>  ) : <TAB><TAB>  # Use request.path because we munged app/locale in path_info. <TAB><TAB>  newurl = request . path [ : - 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with safe_query_string ( request ) : <TAB><TAB><TAB><TAB>  newurl + = "" ? "" + request . META . get ( "" QUERY_STRING "" , "" "" ) <TAB><TAB>  return HttpResponsePermanentRedirect ( newurl ) <TAB>  else : <TAB><TAB>  return response ",if request . GET :,if newurl != request.path:,False,57.27672666667735,93.90181757345695
2179,"def convertDict ( obj ) : <TAB>  obj = dict ( obj ) <TAB>  for k , v in obj . items ( ) : <TAB><TAB>  del obj [ k ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  k = dumps ( k ) <TAB><TAB><TAB>  # Keep track of which keys need to be decoded when loading. <TAB><TAB><TAB>  if Types . KEYS not in obj : <TAB><TAB><TAB><TAB>  obj [ Types . KEYS ] = [ ] <TAB><TAB><TAB>  obj [ Types . KEYS ] . append ( k ) <TAB><TAB>  obj [ k ] = convertObjects ( v ) <TAB>  return obj ","if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :","if isinstance(k, str):",False,35.22762287844295,92.97478660458619
2180,"def __repr__ ( self ) : <TAB>  if self . _in_repr : <TAB><TAB>  return "" <recursion> "" <TAB>  try : <TAB><TAB>  self . _in_repr = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  status = "" computed,  "" <TAB><TAB><TAB>  if self . error ( ) is None : <TAB><TAB><TAB><TAB>  if self . value ( ) is self : <TAB><TAB><TAB><TAB><TAB>  status + = "" = self "" <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  status + = "" =  "" + repr ( self . value ( ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  status + = "" error =  "" + repr ( self . error ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  status = "" isn ' t computed "" <TAB><TAB>  return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB>  finally : <TAB><TAB>  self . _in_repr = False ",if self . is_computed ( ) :,if self.value() is not None:,False,51.47737656490787,96.24064861053598
2181,"def allocate_network ( ipv = "" ipv4 "" ) : <TAB>  global dtcd_uuid <TAB>  global network_pool <TAB>  global allocations <TAB>  network = None <TAB>  try : <TAB><TAB>  cx = httplib . HTTPConnection ( "" localhost:7623 "" ) <TAB><TAB>  cx . request ( "" POST "" , "" /v1/network/ %s / "" % ipv , body = dtcd_uuid ) <TAB><TAB>  resp = cx . getresponse ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  network = netaddr . IPNetwork ( resp . read ( ) . decode ( "" utf-8 "" ) ) <TAB><TAB>  cx . close ( ) <TAB>  except Exception : <TAB><TAB>  pass <TAB>  if network is None : <TAB><TAB>  network = network_pool [ ipv ] . pop ( ) <TAB><TAB>  allocations [ network ] = True <TAB>  return network ",if resp . status == 200 :,if resp.status_code == 200:,False,50.68700847512018,98.3717215086928
2182,"def change_args_to_dict ( string ) : <TAB>  if string is None : <TAB><TAB>  return None <TAB>  ans = [ ] <TAB>  strings = string . split ( "" \n "" ) <TAB>  ind = 1 <TAB>  start = 0 <TAB>  while ind < = len ( strings ) : <TAB><TAB>  if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) : <TAB><TAB><TAB>  ind + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  if start < ind : <TAB><TAB><TAB><TAB>  ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB><TAB><TAB>  start = ind <TAB><TAB><TAB>  ind + = 1 <TAB>  d = { } <TAB>  for line in ans : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lines = line . split ( "" : "" ) <TAB><TAB><TAB>  d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB>  return d ","if "":"" in line and len ( line ) > 0 :",if line.startswith(':') and line.startswith('#'):,False,23.54561998943139,93.83816294662891
2183,"def kill_members ( members , sig , hosts = nodes ) : <TAB>  for member in sorted ( members ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  print ( "" killing  %s "" % member ) <TAB><TAB><TAB>  proc = hosts [ member ] [ "" proc "" ] <TAB><TAB><TAB>  # Not sure if cygwin makes sense here... <TAB><TAB><TAB>  if sys . platform in ( "" win32 "" , "" cygwin "" ) : <TAB><TAB><TAB><TAB>  os . kill ( proc . pid , signal . CTRL_C_EVENT ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  os . kill ( proc . pid , sig ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  print ( "" %s  already dead? "" % member ) ",if ha_tools_debug :,if member in hosts:,False,42.49148555355584,94.233405738757
2184,"def check ( self ) : <TAB>  for path in self . paths : <TAB><TAB>  response = self . http_request ( <TAB><TAB><TAB>  method = "" GET "" , <TAB><TAB><TAB>  path = path , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if any ( <TAB><TAB><TAB>  map ( <TAB><TAB><TAB><TAB>  lambda x : x in response . text , <TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB>  "" report.db.server.name "" , <TAB><TAB><TAB><TAB><TAB>  "" report.db.server.sa.pass "" , <TAB><TAB><TAB><TAB><TAB>  "" report.db.server.user.pass "" , <TAB><TAB><TAB><TAB>  ] , <TAB><TAB><TAB>  ) <TAB><TAB>  ) : <TAB><TAB><TAB>  self . valid = path <TAB><TAB><TAB>  return True<TAB># target is vulnerable <TAB>  return False<TAB># target not vulnerable ",if response is None :,if response.status_code != 200:,False,27.49964044291006,94.12608995046621
2185,"def get_to_download_runs_ids ( session , headers ) : <TAB>  last_date = 0 <TAB>  result = [ ] <TAB>  while 1 : <TAB><TAB>  r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB><TAB>  if r . ok : <TAB><TAB><TAB>  run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB><TAB><TAB>  result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB><TAB><TAB>  last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB><TAB><TAB>  since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB><TAB><TAB>  print ( f "" pares keep ids data since  { since_time } "" ) <TAB><TAB><TAB>  time . sleep ( 1 )<TAB># spider rule <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB>  return result ",if not last_date :,if last_date > last_date:,False,26.11482191082687,96.44100220768321
2186,"def button_press_cb ( self , tdw , event ) : <TAB>  self . _update_zone_and_cursors ( tdw , event . x , event . y ) <TAB>  if self . _zone in ( _EditZone . CREATE_FRAME , _EditZone . REMOVE_FRAME ) : <TAB><TAB>  button = event . button <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _click_info = ( button , self . _zone ) <TAB><TAB><TAB>  return False <TAB>  return super ( FrameEditMode , self ) . button_press_cb ( tdw , event ) ",if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,if button is not None:,False,27.919311956948945,88.31983865359899
2187,"def first_timestep ( ) : <TAB>  assignment = self . has_previous . assign ( <TAB><TAB>  value = tf_util . constant ( value = True , dtype = "" bool "" ) , read_value = False <TAB>  ) <TAB>  with tf . control_dependencies ( control_inputs = ( assignment , ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  current = x <TAB><TAB>  else : <TAB><TAB><TAB>  current = tf . expand_dims ( input = x , axis = ( self . axis + 1 ) ) <TAB><TAB>  multiples = tuple ( <TAB><TAB><TAB>  self . length if dims == self . axis + 1 else 1 <TAB><TAB><TAB>  for dims in range ( self . output_spec ( ) . rank + 1 ) <TAB><TAB>  ) <TAB><TAB>  return tf . tile ( input = current , multiples = multiples ) ",if self . concatenate :,if self.axis == -1:,False,33.61404579517099,97.52414294245462
2188,"def main ( ) - > None : <TAB>  onefuzz = Onefuzz ( ) <TAB>  jobs = onefuzz . jobs . list ( ) <TAB>  for job in jobs : <TAB><TAB>  print ( <TAB><TAB><TAB>  "" job: "" , <TAB><TAB><TAB>  str ( job . job_id ) [ : 8 ] , <TAB><TAB><TAB>  "" : "" . join ( [ job . config . project , job . config . name , job . config . build ] ) , <TAB><TAB>  ) <TAB><TAB>  for task in onefuzz . tasks . list ( job_id = job . job_id ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  ""<TAB>  "" , <TAB><TAB><TAB><TAB>  str ( task . task_id ) [ : 8 ] , <TAB><TAB><TAB><TAB>  task . config . task . type , <TAB><TAB><TAB><TAB>  task . config . task . target_exe , <TAB><TAB><TAB>  ) ","if task . state in [ ""stopped"" , ""stopping"" ] :",if task.job_id == 0:,False,49.343064207876196,95.6889652052643
2189,"def update_stack ( self , full_name , template_url , parameters , tags ) : <TAB>  """"""Updates an existing stack in CloudFormation."""""" <TAB>  try : <TAB><TAB>  logger . info ( "" Attempting to update stack  %s . "" , full_name ) <TAB><TAB>  self . conn . cloudformation . update_stack ( <TAB><TAB><TAB>  full_name , <TAB><TAB><TAB>  template_url = template_url , <TAB><TAB><TAB>  parameters = parameters , <TAB><TAB><TAB>  tags = tags , <TAB><TAB><TAB>  capabilities = [ "" CAPABILITY_IAM "" ] , <TAB><TAB>  ) <TAB><TAB>  return SUBMITTED <TAB>  except BotoServerError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . info ( "" Stack  %s  did not change, not updating. "" , full_name ) <TAB><TAB><TAB>  return SKIPPED <TAB><TAB>  raise ","if ""No updates are to be performed."" in e . message :",if e.code == BotoServerError.SUCCESS:,False,37.882082039798895,94.5064582556988
2190,"def header_tag_files ( env , files , legal_header , script_files = False ) : <TAB>  """"""Apply the legal_header to the list of files"""""" <TAB>  try : <TAB><TAB>  import apply_legal_header <TAB>  except : <TAB><TAB>  xbc . cdie ( "" XED ERROR: mfile.py could not find scripts directory "" ) <TAB>  for g in files : <TAB><TAB>  print ( "" G:  "" , g ) <TAB><TAB>  for f in mbuild . glob ( g ) : <TAB><TAB><TAB>  print ( "" F:  "" , f ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  apply_legal_header . apply_header_to_data_file ( legal_header , f ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  apply_legal_header . apply_header_to_source_file ( legal_header , f ) ",if script_files :,if script_files:,False,60.80466053060817,100.00000000000004
2191,"def cleanDataCmd ( cmd ) : <TAB>  newcmd = "" AbracadabrA ** <?php  "" <TAB>  if cmd [ : 6 ] != "" php:// "" : <TAB><TAB>  if reverseConn not in cmd : <TAB><TAB><TAB>  cmds = cmd . split ( "" & "" ) <TAB><TAB><TAB>  for c in cmds : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  newcmd + = "" system( ' %s ' ); "" % c <TAB><TAB>  else : <TAB><TAB><TAB>  b64cmd = base64 . b64encode ( cmd ) <TAB><TAB><TAB>  newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB>  else : <TAB><TAB>  newcmd + = cmd [ 6 : ] <TAB>  newcmd + = "" ?> ** "" <TAB>  return newcmd ",if len ( c ) > 0 :,if c in cmd:,False,28.47942032612099,94.37113366440713
2192,"def test_form ( self ) : <TAB>  n_qubits = 6 <TAB>  random_operator = get_fermion_operator ( random_interaction_operator ( n_qubits ) ) <TAB>  chemist_operator = chemist_ordered ( random_operator ) <TAB>  for term , _ in chemist_operator . terms . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertTrue ( term [ 0 ] [ 1 ] ) <TAB><TAB><TAB>  self . assertTrue ( term [ 2 ] [ 1 ] ) <TAB><TAB><TAB>  self . assertFalse ( term [ 1 ] [ 1 ] ) <TAB><TAB><TAB>  self . assertFalse ( term [ 3 ] [ 1 ] ) <TAB><TAB><TAB>  self . assertTrue ( term [ 0 ] [ 0 ] > term [ 2 ] [ 0 ] ) <TAB><TAB><TAB>  self . assertTrue ( term [ 1 ] [ 0 ] > term [ 3 ] [ 0 ] ) ",if len ( term ) == 2 or not len ( term ) :,if term == 'foo':,False,22.53102564886842,94.60329362232162
2193,"def do ( server , handler , config , modargs ) : <TAB>  data = [ ] <TAB>  clients = server . get_clients ( handler . default_filter ) <TAB>  if not clients : <TAB><TAB>  return <TAB>  for client in clients : <TAB><TAB>  tags = config . tags ( client . node ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tags . remove ( * modargs . remove ) <TAB><TAB>  if modargs . add : <TAB><TAB><TAB>  tags . add ( * modargs . add ) <TAB><TAB>  data . append ( { "" ID "" : client . node ( ) , "" TAGS "" : tags } ) <TAB>  config . save ( project = modargs . write_project , user = modargs . write_user ) <TAB>  handler . display ( Table ( data ) ) ",if modargs . remove :,if modargs.remove:,False,50.820991488571025,100.00000000000004
2194,"def validate ( self ) : <TAB>  if self . data . get ( "" state "" ) == "" enabled "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise PolicyValidationError ( <TAB><TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB><TAB>  "" redshift logging enablement requires `bucket`  "" <TAB><TAB><TAB><TAB><TAB>  "" and `prefix` specification on  %s "" % ( self . manager . data , ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return self ","if ""bucket"" not in self . data :",if self.data.get('bucket') == 'bucket':,False,28.438818033956014,92.85731110414677
2195,"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB>  out = [ ] <TAB>  for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB><TAB>  m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sx , sy = m . groups ( ) <TAB><TAB><TAB>  x = colname2num ( sx ) <TAB><TAB><TAB>  y = int ( sy ) <TAB><TAB><TAB>  if x1 < = x < = x2 and y1 < = y < = y2 : <TAB><TAB><TAB><TAB>  part = cellname ( x + dx , y + dy ) <TAB><TAB>  out . append ( part ) <TAB>  return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment ) ",if m is not None :,if m:,False,28.722634876689895,98.02697367889176
2196,"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB>  if not adjustments : <TAB><TAB>  return <TAB>  ( exists , contents ) = read_sysconfig_file ( fn ) <TAB>  updated_am = 0 <TAB>  for ( k , v ) in adjustments . items ( ) : <TAB><TAB>  if v is None : <TAB><TAB><TAB>  continue <TAB><TAB>  v = str ( v ) <TAB><TAB>  if len ( v ) == 0 and not allow_empty : <TAB><TAB><TAB>  continue <TAB><TAB>  contents [ k ] = v <TAB><TAB>  updated_am + = 1 <TAB>  if updated_am : <TAB><TAB>  lines = [ <TAB><TAB><TAB>  str ( contents ) , <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lines . insert ( 0 , util . make_header ( ) ) <TAB><TAB>  util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 ) ",if not exists :,if exists:,False,25.89839160662927,99.03896632059715
2197,"def getElement ( self , aboutUri , namespace , name ) : <TAB>  for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB><TAB>  if desc . getAttributeNS ( RDF_NAMESPACE , "" about "" ) == aboutUri : <TAB><TAB><TAB>  attr = desc . getAttributeNodeNS ( namespace , name ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield attr <TAB><TAB><TAB>  for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB><TAB><TAB><TAB>  yield element ",if attr != None :,if attr is not None:,False,50.984799916783196,97.44419619641211
2198,"def get_store_name_from_connection_string ( connection_string ) : <TAB>  if is_valid_connection_string ( connection_string ) : <TAB><TAB>  segments = dict ( seg . split ( "" = "" , 1 ) for seg in connection_string . split ( "" ; "" ) ) <TAB><TAB>  endpoint = segments . get ( "" Endpoint "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return endpoint . split ( "" // "" ) [ 1 ] . split ( "" . "" ) [ 0 ] <TAB>  return None ",if endpoint :,if endpoint:,False,52.616193482068674,100.00000000000004
2199,"def insertLoopTemplate ( self , layout ) : <TAB>  col = layout . column ( align = True ) <TAB>  for socket in self . activeNode . outputs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  props = col . operator ( <TAB><TAB><TAB><TAB>  "" an.insert_loop_for_iterator "" , <TAB><TAB><TAB><TAB>  text = "" Loop through  {} "" . format ( repr ( socket . getDisplayedName ( ) ) ) , <TAB><TAB><TAB><TAB>  icon = "" MOD_ARRAY "" , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  props . nodeIdentifier = self . activeNode . identifier <TAB><TAB><TAB>  props . socketIndex = socket . getIndex ( ) ",if not socket . hide and isList ( socket . bl_idname ) :,if socket.getDisplayedName() == self.activeNode.identifier:,False,28.76748613324657,93.15475881996285
2200,"def do_task ( self , task ) : <TAB>  self . running_task + = 1 <TAB>  result = yield gen . Task ( self . fetcher . fetch , task ) <TAB>  type , task , response = result . args <TAB>  self . processor . on_task ( task , response ) <TAB>  # do with message <TAB>  while not self . processor . inqueue . empty ( ) : <TAB><TAB>  _task , _response = self . processor . inqueue . get ( ) <TAB><TAB>  self . processor . on_task ( _task , _response ) <TAB>  # do with results <TAB>  while not self . processor . result_queue . empty ( ) : <TAB><TAB>  _task , _result = self . processor . result_queue . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . result_worker . on_result ( _task , _result ) <TAB>  self . running_task - = 1 ",if self . result_worker :,if _task is not None:,False,34.52282917002808,97.19792183051567
2201,"def _parse_config_result ( data ) : <TAB>  command_list = ""  ;  "" . join ( [ x . strip ( ) for x in data [ 0 ] ] ) <TAB>  config_result = data [ 1 ] <TAB>  if isinstance ( config_result , list ) : <TAB><TAB>  result = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for key in config_result [ 0 ] : <TAB><TAB><TAB><TAB>  result + = config_result [ 0 ] [ key ] <TAB><TAB><TAB>  config_result = result <TAB><TAB>  else : <TAB><TAB><TAB>  config_result = config_result [ 0 ] <TAB>  return [ command_list , config_result ] ","if isinstance ( config_result [ 0 ] , dict ) :",if config_result[0] is not None:,False,31.958866006527714,95.7211099507611
2202,"def load_api_handler ( self , mod_name ) : <TAB>  for name , hdl in API_HANDLERS : <TAB><TAB>  name = name . lower ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  handler = self . mods . get ( name ) <TAB><TAB><TAB>  if not handler : <TAB><TAB><TAB><TAB>  handler = hdl ( self . emu ) <TAB><TAB><TAB><TAB>  self . mods . update ( { name : handler } ) <TAB><TAB><TAB>  return handler <TAB>  return None ",if mod_name and name == mod_name . lower ( ) :,if name in self.mods:,False,31.12311327288686,89.96764873871598
2203,def heal ( self ) : <TAB>  if not self . doctors : <TAB><TAB>  return <TAB>  proc_ids = self . _get_process_ids ( ) <TAB>  for proc_id in proc_ids : <TAB><TAB>  # get proc every time for latest state <TAB><TAB>  proc = PipelineProcess . objects . get ( id = proc_id ) <TAB><TAB>  if not proc . is_alive or proc . is_frozen : <TAB><TAB><TAB>  continue <TAB><TAB>  for dr in self . doctors : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  dr . cure ( proc ) <TAB><TAB><TAB><TAB>  break ,if dr . confirm ( proc ) :,if dr.state == 'Running':,False,58.42596573607087,96.84164713221789
2204,"def __new__ ( cls , * args , * * kwargs ) : <TAB>  if len ( args ) == 1 : <TAB><TAB>  if len ( kwargs ) : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB><TAB><TAB><TAB><TAB>  cls . __name__ <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return super ( ) . __new__ ( cls ) <TAB><TAB>  if isinstance ( args [ 0 ] , cls ) : <TAB><TAB><TAB>  return cls <TAB>  return super ( ) . __new__ ( cls , * args , * * kwargs ) ",if not args [ 0 ] :,if args[0] is None:,False,33.019223896444046,97.70088987549991
2205,"def __lt__ ( self , other ) : <TAB>  # 0: clock 1: timestamp 3: process id <TAB>  try : <TAB><TAB>  A , B = self [ 0 ] , other [ 0 ] <TAB><TAB>  # uses logical clock value first <TAB><TAB>  <IF-STMT>:<TAB># use logical clock if available <TAB><TAB><TAB>  if A == B :<TAB># equal clocks use lower process id <TAB><TAB><TAB><TAB>  return self [ 2 ] < other [ 2 ] <TAB><TAB><TAB>  return A < B <TAB><TAB>  return self [ 1 ] < other [ 1 ]<TAB># ... or use timestamp <TAB>  except IndexError : <TAB><TAB>  return NotImplemented ",if A and B :,if A is not B:,False,36.3565124698038,90.72685686424096
2206,"def _get_client ( rp_mapping , resource_provider ) : <TAB>  for key , value in rp_mapping . items ( ) : <TAB><TAB>  if str . lower ( key ) == str . lower ( resource_provider ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return GeneralPrivateEndpointClient ( <TAB><TAB><TAB><TAB><TAB>  key , <TAB><TAB><TAB><TAB><TAB>  value [ "" api_version "" ] , <TAB><TAB><TAB><TAB><TAB>  value [ "" support_list_or_not "" ] , <TAB><TAB><TAB><TAB><TAB>  value [ "" resource_get_api_version "" ] , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return value ( ) <TAB>  raise CLIError ( <TAB><TAB>  "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB>  ) ","if isinstance ( value , dict ) :",if value is not None:,False,54.685542054079626,97.12582605969648
2207,"def test_progressbar_format_pos ( runner , pos , length ) : <TAB>  with _create_progress ( length , length_known = length != 0 , pos = pos ) as progress : <TAB><TAB>  result = progress . format_pos ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert result == f "" { pos } / { length } "" <TAB><TAB>  else : <TAB><TAB><TAB>  assert result == str ( pos ) ",if progress . length_known :,if length > 0:,False,18.439428699625136,94.6667794979702
2208,"def optimize ( self , graph : Graph ) : <TAB>  MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB>  flag_changed = False <TAB>  for v in traverse . listup_variables ( graph ) : <TAB><TAB>  if not Placeholder . check_resolved ( v . size ) : <TAB><TAB><TAB>  continue <TAB><TAB>  height , width = TextureShape . get ( v ) <TAB><TAB>  if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flag_changed = True <TAB><TAB><TAB>  v . attributes . add ( SplitTarget ( ) ) <TAB>  return graph , flag_changed ",if not v . has_attribute ( SplitTarget ) :,if v.size.size() == 1:,False,30.596548446664702,94.57192556438187
2209,"def ant_map ( m ) : <TAB>  tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB>  players = { } <TAB>  for row in m : <TAB><TAB>  tmp + = "" m  "" <TAB><TAB>  for col in row : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tmp + = "" . "" <TAB><TAB><TAB>  elif col == BARRIER : <TAB><TAB><TAB><TAB>  tmp + = "" % "" <TAB><TAB><TAB>  elif col == FOOD : <TAB><TAB><TAB><TAB>  tmp + = "" * "" <TAB><TAB><TAB>  elif col == UNSEEN : <TAB><TAB><TAB><TAB>  tmp + = "" ? "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  players [ col ] = True <TAB><TAB><TAB><TAB>  tmp + = chr ( col + 97 ) <TAB><TAB>  tmp + = "" \n "" <TAB>  tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB>  return tmp ",if col == LAND :,if col == BAND:,False,18.313708441148606,97.97739837574188
2210,"def reset ( self ) : <TAB>  logger . debug ( "" Arctic.reset() "" ) <TAB>  with self . _lock : <TAB><TAB>  if self . __conn is not None : <TAB><TAB><TAB>  self . __conn . close ( ) <TAB><TAB><TAB>  self . __conn = None <TAB><TAB>  for _ , l in self . _library_cache . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  logger . debug ( "" Library reset()  %s "" % l ) <TAB><TAB><TAB><TAB>  l . _reset ( )<TAB># the existence of _reset() is not guaranteed/enforced, it also triggers re-auth ","if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :",if l._state == 'reset':,False,58.83242589111648,90.27512594119275
2211,"def add_cand_to_check ( cands ) : <TAB>  for cand in cands : <TAB><TAB>  x = cand . creator <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if x not in fan_out : <TAB><TAB><TAB>  # `len(fan_out)` is in order to avoid comparing `x` <TAB><TAB><TAB>  heapq . heappush ( cand_funcs , ( - x . rank , len ( fan_out ) , x ) ) <TAB><TAB>  fan_out [ x ] + = 1 ",if x is None :,if x is None:,False,61.249085280702275,97.48099096887756
2212,"def on_task_modify ( self , task , config ) : <TAB>  for entry in task . entries : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size = entry [ "" torrent "" ] . size / 1024 / 1024 <TAB><TAB><TAB>  log . debug ( "" %s  size:  %s  MB "" % ( entry [ "" title "" ] , size ) ) <TAB><TAB><TAB>  entry [ "" content_size "" ] = size ","if ""torrent"" in entry :",if entry['type'] == 'headline':,False,48.562943274213296,92.70788622400958
2213,"def get_measurements ( self , pipeline , object_name , category ) : <TAB>  if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB><TAB>  results = [ ] <TAB><TAB>  if self . do_corr_and_slope : <TAB><TAB><TAB>  if object_name == "" Image "" : <TAB><TAB><TAB><TAB>  results + = [ "" Correlation "" , "" Slope "" ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results + = [ "" Correlation "" ] <TAB><TAB>  if self . do_overlap : <TAB><TAB><TAB>  results + = [ "" Overlap "" , "" K "" ] <TAB><TAB>  if self . do_manders : <TAB><TAB><TAB>  results + = [ "" Manders "" ] <TAB><TAB>  if self . do_rwc : <TAB><TAB><TAB>  results + = [ "" RWC "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  results + = [ "" Costes "" ] <TAB><TAB>  return results <TAB>  return [ ] ",if self . do_costes :,if self.do_costes:,False,43.05829699509132,100.00000000000004
2214,"def create_root ( cls , site = None , title = "" Root "" , request = None , * * kwargs ) : <TAB>  if not site : <TAB><TAB>  site = Site . objects . get_current ( ) <TAB>  root_nodes = cls . objects . root_nodes ( ) . filter ( site = site ) <TAB>  if not root_nodes : <TAB><TAB>  article = Article ( ) <TAB><TAB>  revision = ArticleRevision ( title = title , * * kwargs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  revision . set_from_request ( request ) <TAB><TAB>  article . add_revision ( revision , save = True ) <TAB><TAB>  article . save ( ) <TAB><TAB>  root = cls . objects . create ( site = site , article = article ) <TAB><TAB>  article . add_object_relation ( root ) <TAB>  else : <TAB><TAB>  root = root_nodes [ 0 ] <TAB>  return root ",if request :,if request:,False,45.955781137314574,100.00000000000004
2215,"def get ( self , key ) : <TAB>  filename = self . _get_filename ( key ) <TAB>  try : <TAB><TAB>  with open ( filename , "" rb "" ) as f : <TAB><TAB><TAB>  pickle_time = pickle . load ( f ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return pickle . load ( f ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  os . remove ( filename ) <TAB><TAB><TAB><TAB>  return None <TAB>  except ( IOError , OSError , pickle . PickleError ) : <TAB><TAB>  return None ",if pickle_time == 0 or pickle_time >= time ( ) :,if pickle_time.startswith('time'):,False,20.666750933078447,92.84308803852178
2216,"def build_message ( self , options , target ) : <TAB>  message = multipart . MIMEMultipart ( ) <TAB>  for name , value in list ( options . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add_body ( message , value ) <TAB><TAB>  elif name == "" EMAIL_ATTACHMENT "" : <TAB><TAB><TAB>  self . add_attachment ( message , value ) <TAB><TAB>  else :<TAB># From, To, Subject, etc. <TAB><TAB><TAB>  self . set_option ( message , name , value , target ) <TAB>  return message ","if name == ""EMAIL_BODY"" :","if name == ""BODY_ACCEPT':",False,18.60256740052315,94.46447599124102
2217,"def updateVar ( name , data , mode = None ) : <TAB>  if mode : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  core . config . globalVariables [ name ] . append ( data ) <TAB><TAB>  elif mode == "" add "" : <TAB><TAB><TAB>  core . config . globalVariables [ name ] . add ( data ) <TAB>  else : <TAB><TAB>  core . config . globalVariables [ name ] = data ","if mode == ""append"" :","if mode == ""add':",False,42.657071419764826,96.79532651030614
2218,"def insert_errors ( <TAB>  el , <TAB>  errors , <TAB>  form_id = None , <TAB>  form_index = None , <TAB>  error_class = "" error "" , <TAB>  error_creator = default_error_creator ,  ) : <TAB>  el = _find_form ( el , form_id = form_id , form_index = form_index ) <TAB>  for name , error in errors . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for error_el , message in _find_elements_for_name ( el , name , error ) : <TAB><TAB><TAB>  assert isinstance ( message , ( basestring , type ( None ) , ElementBase ) ) , ( <TAB><TAB><TAB><TAB>  "" Bad message:  %r "" % message <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  _insert_error ( error_el , message , error_class , error_creator ) ",if error is None :,if name == 'error':,False,49.083734967629155,97.67093365738907
2219,"def read ( self , item , recursive = False , sort = False ) : <TAB>  item = _normalize_path ( item ) <TAB>  if item in self . _store : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . _store [ item ] <TAB><TAB><TAB>  raise KeyError ( item ) <TAB><TAB>  return PathResult ( item , value = self . _store [ item ] ) <TAB>  else : <TAB><TAB>  return self . _read_dir ( item , recursive = recursive , sort = sort ) ",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if not recursive:,False,35.581471112736665,82.12168089946175
2220,"def _stash_splitter ( states ) : <TAB>  keep , split = [ ] , [ ] <TAB>  if state_func is not None : <TAB><TAB>  for s in states : <TAB><TAB><TAB>  ns = state_func ( s ) <TAB><TAB><TAB>  if isinstance ( ns , SimState ) : <TAB><TAB><TAB><TAB>  split . append ( ns ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  split . extend ( ns ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  split . append ( s ) <TAB>  if stash_func is not None : <TAB><TAB>  split = stash_func ( states ) <TAB>  if to_stash is not stash : <TAB><TAB>  keep = states <TAB>  return keep , split ","elif isinstance ( ns , ( list , tuple , set ) ) :",if ns is not None:,False,34.04215524938936,93.33931194859048
2221,"def run ( self ) : <TAB>  while self . runflag : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with self . lock : <TAB><TAB><TAB><TAB>  tasks = list ( self . queue ) <TAB><TAB><TAB><TAB>  self . queue . clear ( ) <TAB><TAB><TAB>  while len ( tasks ) > 0 : <TAB><TAB><TAB><TAB>  pathname , remotepath = tasks . pop ( 0 ) <TAB><TAB><TAB><TAB>  self . bcloud_app . upload_page . add_bg_task ( pathname , remotepath ) <TAB><TAB><TAB>  self . last = time ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  sleep ( 1 ) ",if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,if self.queue:,False,48.254383014268164,90.8531783768486
2222,"def _append_patch ( self , patch_dir , patch_files ) : <TAB>  for patch in patch_files : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tmp = patch <TAB><TAB><TAB>  patch = { } <TAB><TAB><TAB>  for key in tmp . keys ( ) : <TAB><TAB><TAB><TAB>  patch [ os . path . join ( patch_dir , key ) ] = tmp [ key ] <TAB><TAB><TAB>  self . patches . append ( patch ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . patches . append ( os . path . join ( patch_dir , patch ) ) ",if type ( patch ) is dict :,if patch.startswith('.py'):,False,48.95869032406802,94.81944973948853
2223,"def __remote_port ( self ) : <TAB>  port = 22 <TAB>  if self . git_has_remote : <TAB><TAB>  m = re . match ( r "" ^(.*?)?@([^/:]*):?([0-9]+)? "" , self . git_remote . url ) <TAB><TAB>  if m : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  port = m . group ( 3 ) <TAB>  return int ( port ) ",if m . group ( 3 ) :,if m.group(1) == 'port':,False,26.212376414471006,95.33712800220778
2224,"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB>  # Prefer creating a new helper when at least one kwarg is specified. <TAB>  prefer_new = len ( kwargs ) > 0 <TAB>  kwargs . update ( infer_mode = infer_mode ) <TAB>  is_training = not infer_mode if infer_mode is not None else self . training <TAB>  helper = self . _train_helper if is_training else self . _infer_helper <TAB>  if prefer_new or helper is None : <TAB><TAB>  helper = self . create_helper ( * * kwargs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _train_helper = helper <TAB><TAB>  elif not is_training and self . _infer_helper is None : <TAB><TAB><TAB>  self . _infer_helper = helper <TAB>  return helper ",if is_training and self . _train_helper is None :,if not is_training and helper is not self._infer_helper:,False,25.835116500181442,95.52211747200317
2225,"def flushChangeClassifications ( self , schedulerid , less_than = None ) : <TAB>  if less_than is not None : <TAB><TAB>  classifications = self . classifications . setdefault ( schedulerid , { } ) <TAB><TAB>  for changeid in list ( classifications ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del classifications [ changeid ] <TAB>  else : <TAB><TAB>  self . classifications [ schedulerid ] = { } <TAB>  return defer . succeed ( None ) ",if changeid < less_than :,if changeid in classifications:,False,52.2866254651756,95.39025488890617
2226,"def pid_from_name ( name ) : <TAB>  processes = [ ] <TAB>  for pid in os . listdir ( "" /proc "" ) : <TAB><TAB>  try : <TAB><TAB><TAB>  pid = int ( pid ) <TAB><TAB><TAB>  pname , cmdline = SunProcess . _name_args ( pid ) <TAB><TAB><TAB>  if name in pname : <TAB><TAB><TAB><TAB>  return pid <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return pid <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB>  raise ProcessException ( "" No process with such name:  %s "" % name ) ","if name in cmdline . split ( "" "" , 1 ) [ 0 ] :",if pid in processes:,False,51.779990243239006,91.40944821036358
2227,"def spew ( ) : <TAB>  seenUID = False <TAB>  start ( ) <TAB>  for part in query : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  seenUID = True <TAB><TAB>  if part . type == "" body "" : <TAB><TAB><TAB>  yield self . spew_body ( part , id , msg , write , flush ) <TAB><TAB>  else : <TAB><TAB><TAB>  f = getattr ( self , "" spew_ "" + part . type ) <TAB><TAB><TAB>  yield f ( id , msg , write , flush ) <TAB><TAB>  if part is not query [ - 1 ] : <TAB><TAB><TAB>  space ( ) <TAB>  if uid and not seenUID : <TAB><TAB>  space ( ) <TAB><TAB>  yield self . spew_uid ( id , msg , write , flush ) <TAB>  finish ( ) <TAB>  flush ( ) ","if part . type == ""uid"" :",if part.id == id:,False,46.231570589227175,95.84650865776896
2228,"def rx ( ) : <TAB>  while True : <TAB><TAB>  rx_i = rep . recv ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rep . send ( b "" done "" ) <TAB><TAB><TAB>  break <TAB><TAB>  rep . send ( b "" i "" ) ","if rx_i == b""1000"" :","if rx_i == b""r"" or (not (isinstance(rx_i",False,18.569724041554487,86.71825395448217
2229,"def test_search_incorrect_base_exception_1 ( self ) : <TAB>  self . connection_1c . bind ( ) <TAB>  try : <TAB><TAB>  result = self . connection_1c . search ( <TAB><TAB><TAB>  "" o=nonexistant "" , "" (cn=*) "" , search_scope = SUBTREE , attributes = [ "" cn "" , "" sn "" ] <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _ , result = self . connection_1c . get_response ( result ) <TAB><TAB>  self . fail ( "" exception not raised "" ) <TAB>  except LDAPNoSuchObjectResult : <TAB><TAB>  pass ",if not self . connection_1c . strategy . sync :,if result:,False,28.709442647485588,92.98955651648978
2230,"def value_from_datadict ( self , data , files , prefix ) : <TAB>  count = int ( data [ "" %s -count "" % prefix ] ) <TAB>  values_with_indexes = [ ] <TAB>  for i in range ( 0 , count ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  values_with_indexes . append ( <TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB>  int ( data [ "" %s - %d -order "" % ( prefix , i ) ] ) , <TAB><TAB><TAB><TAB>  self . child_block . value_from_datadict ( <TAB><TAB><TAB><TAB><TAB>  data , files , "" %s - %d -value "" % ( prefix , i ) <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB>  values_with_indexes . sort ( ) <TAB>  return [ v for ( i , v ) in values_with_indexes ] ","if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :",if i == count - 1:,False,49.447516206879094,89.50135924929737
2231,"def _ensure_header_written ( self , datasize ) : <TAB>  if not self . _headerwritten : <TAB><TAB>  if not self . _nchannels : <TAB><TAB><TAB>  raise Error ( "" # channels not specified "" ) <TAB><TAB>  if not self . _sampwidth : <TAB><TAB><TAB>  raise Error ( "" sample width not specified "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Error ( "" sampling rate not specified "" ) <TAB><TAB>  self . _write_header ( datasize ) ",if not self . _framerate :,if not self._samprate:,False,26.262923563336503,98.10218387623372
2232,def wait_til_ready ( cls ) : <TAB>  while True : <TAB><TAB>  now = time . time ( ) <TAB><TAB>  next_iteration = now / / 1.0 + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  await cls . _clock . run_til ( next_iteration ) <TAB><TAB>  await asyncio . sleep ( 1.0 ) ,if cls . connector . ready :,if next_iteration == 0:,False,18.581647112489648,93.25666627127977
2233,"def lookup_actions ( self , resp ) : <TAB>  actions = { } <TAB>  for action , conditions in self . actions . items ( ) : <TAB><TAB>  for condition , opts in conditions : <TAB><TAB><TAB>  for key , val in condition : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if resp . match ( key [ : - 1 ] , val ) : <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  if not resp . match ( key , val ) : <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  actions [ action ] = opts <TAB>  return actions ","if key [ - 1 ] == ""!"" :",if key.endswith('_actions'):,False,49.14022651983074,94.64416950956179
2234,"def close ( self , wait = True , abort = False ) : <TAB>  """"""Close the socket connection."""""" <TAB>  if not self . closed and not self . closing : <TAB><TAB>  self . closing = True <TAB><TAB>  self . server . _trigger_event ( "" disconnect "" , self . sid , run_async = False ) <TAB><TAB>  if not abort : <TAB><TAB><TAB>  self . send ( packet . Packet ( packet . CLOSE ) ) <TAB><TAB>  self . closed = True <TAB><TAB>  self . queue . put ( None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . queue . join ( ) ",if wait :,if wait:,False,51.111730115993005,100.00000000000004
2235,"def model_parse ( self ) : <TAB>  for name , submodel in self . model . named_modules ( ) : <TAB><TAB>  for op_type in SUPPORTED_OP_TYPE : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . target_layer [ name ] = submodel <TAB><TAB><TAB><TAB>  self . already_pruned [ name ] = 0 ","if isinstance ( submodel , op_type ) :",if op_type in self.target_layer:,False,46.505626413990285,91.41903869236332
2236,"def pack_identifier ( self ) : <TAB>  """"""Return a combined identifier for the whole pack if this has more than one episode."""""" <TAB>  # Currently only supports ep mode <TAB>  if self . id_type == "" ep "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" S %02d E %02d -E %02d "" % ( <TAB><TAB><TAB><TAB>  self . season , <TAB><TAB><TAB><TAB>  self . episode , <TAB><TAB><TAB><TAB>  self . episode + self . episodes - 1 , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  return self . identifier <TAB>  else : <TAB><TAB>  return self . identifier ",if self . episodes > 1 :,if self.episodes > 1:,False,65.52353258327389,96.72853570009217
2237,"def on_data ( res ) : <TAB>  if terminate . is_set ( ) : <TAB><TAB>  return <TAB>  if args . strings and not args . no_content : <TAB><TAB>  if type ( res ) == tuple : <TAB><TAB><TAB>  f , v = res <TAB><TAB><TAB>  if type ( f ) == unicode : <TAB><TAB><TAB><TAB>  f = f . encode ( "" utf-8 "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  v = v . encode ( "" utf-8 "" ) <TAB><TAB><TAB>  self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB><TAB>  elif not args . content_only : <TAB><TAB><TAB>  self . success ( res ) <TAB>  else : <TAB><TAB>  self . success ( res ) ",if type ( v ) == unicode :,if type(v) == unicode:,False,50.9997232722221,100.00000000000004
2238,"def _enable_contours_changed ( self , value ) : <TAB>  """"""Turns on and off the contours."""""" <TAB>  if self . module_manager is None : <TAB><TAB>  return <TAB>  if value : <TAB><TAB>  self . actor . inputs = [ self . contour ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . actor . mapper . scalar_mode = "" use_cell_data "" <TAB>  else : <TAB><TAB>  self . actor . inputs = [ self . grid_plane ] <TAB><TAB>  self . actor . mapper . scalar_mode = "" default "" <TAB>  self . render ( ) ",if self . contour . filled_contours :,if self.grid_plane is None:,False,38.39243595640732,96.11903200321954
2239,"def _apply_abs_paths ( data , script_dir ) : <TAB>  for flag_data in data . values ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  default = flag_data . get ( "" default "" ) <TAB><TAB>  if ( <TAB><TAB><TAB>  not default <TAB><TAB><TAB>  or not isinstance ( default , six . string_types ) <TAB><TAB><TAB>  or os . path . sep not in default <TAB><TAB>  ) : <TAB><TAB><TAB>  continue <TAB><TAB>  abs_path = os . path . join ( script_dir , default ) <TAB><TAB>  if os . path . exists ( abs_path ) : <TAB><TAB><TAB>  flag_data [ "" default "" ] = abs_path ","if not isinstance ( flag_data , dict ) :",if flag_data.get('default') is None:,False,47.157507629479355,95.46886104262492
2240,"def button_release ( self , mapper ) : <TAB>  self . pressed = False <TAB>  if self . waiting_task and self . active is None and not self . action : <TAB><TAB>  # In HoldModifier, button released before timeout <TAB><TAB>  mapper . cancel_task ( self . waiting_task ) <TAB><TAB>  self . waiting_task = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . normalaction . button_press ( mapper ) <TAB><TAB><TAB>  mapper . schedule ( 0.02 , self . normalaction . button_release ) <TAB>  elif self . active : <TAB><TAB>  # Released held button <TAB><TAB>  self . active . button_release ( mapper ) <TAB><TAB>  self . active = None ",if self . normalaction :,if self.normalaction:,False,58.4559124504635,100.00000000000004
2241,"def goToPrevMarkedHeadline ( self , event = None ) : <TAB>  """"""Select the next marked node."""""" <TAB>  c = self <TAB>  p = c . p <TAB>  if not p : <TAB><TAB>  return <TAB>  p . moveToThreadBack ( ) <TAB>  wrapped = False <TAB>  while 1 : <TAB><TAB>  if p and p . isMarked ( ) : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p . moveToThreadBack ( ) <TAB><TAB>  elif wrapped : <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  wrapped = True <TAB><TAB><TAB>  p = c . rootPosition ( ) <TAB>  if not p : <TAB><TAB>  g . blue ( "" done "" ) <TAB>  c . treeSelectHelper ( p )<TAB># Sets focus. ",elif p :,if p:,False,28.80010122029757,96.67865089754915
2242,"def status ( self , name , error = "" No matching script logs found "" ) : <TAB>  with self . script_lock : <TAB><TAB>  if self . script_running and self . script_running [ 1 ] == name : <TAB><TAB><TAB>  return self . script_running [ 1 : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . script_last [ 1 : ] <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( error ) ",elif self . script_last and self . script_last [ 1 ] == name :,if self.script_last and self.script_last[0] == name:,False,52.183678345667474,96.30887793179545
2243,"def _stderr_supports_color ( ) : <TAB>  try : <TAB><TAB>  if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  curses . setupterm ( ) <TAB><TAB><TAB><TAB>  if curses . tigetnum ( "" colors "" ) > 0 : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  elif colorama : <TAB><TAB><TAB><TAB>  if sys . stderr is getattr ( <TAB><TAB><TAB><TAB><TAB>  colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB><TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  except Exception : <TAB><TAB>  # Very broad exception handling because it's always better to <TAB><TAB>  # fall back to non-colored logs than to break at startup. <TAB><TAB>  pass <TAB>  return False ",if curses :,if curses.tigetnum('colors'):,False,62.79449397081985,97.46291399493924
2244,"def main ( ) : <TAB>  configFilename = "" twitterbot.ini "" <TAB>  if sys . argv [ 1 : ] : <TAB><TAB>  configFilename = sys . argv [ 1 ] <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( ) <TAB><TAB>  load_config ( configFilename ) <TAB>  except Exception as e : <TAB><TAB>  print ( "" Error while loading ini file  %s "" % ( configFilename ) , file = sys . stderr ) <TAB><TAB>  print ( e , file = sys . stderr ) <TAB><TAB>  print ( __doc__ , file = sys . stderr ) <TAB><TAB>  sys . exit ( 1 ) <TAB>  bot = TwitterBot ( configFilename ) <TAB>  return bot . run ( ) ",if not os . path . exists ( configFilename ) :,if not configFilename.endswith('.py'):,False,32.33128832371002,96.00257997974008
2245,def safe_to_kill ( request ) : <TAB>  if os . path . exists ( DRAIN_FILE ) : <TAB><TAB>  with open ( DRAIN_FILE ) as f : <TAB><TAB><TAB>  dt = datetime . datetime . fromtimestamp ( float ( f . read ( ) ) ) <TAB><TAB><TAB>  delta = datetime . datetime . now ( ) - dt <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return Response ( status_int = 200 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return Response ( status_int = 400 ) <TAB>  else : <TAB><TAB>  return Response ( status_int = 400 ) ,if delta . seconds > 2 :,if delta < datetime.datetime.now():,False,22.58151131212786,94.80874491219673
2246,"def get_class_name ( item ) : <TAB>  class_name , module_name = None , None <TAB>  for parent in reversed ( item . listchain ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  class_name = parent . name <TAB><TAB>  elif isinstance ( parent , pytest . Module ) : <TAB><TAB><TAB>  module_name = parent . module . __name__ <TAB><TAB><TAB>  break <TAB>  # heuristic: <TAB>  # - better to group gpu and task tests, since tests from those modules <TAB>  #   are likely to share caching more <TAB>  # - split up the rest by class name because slow tests tend to be in <TAB>  #   the same module <TAB>  if class_name and "" .tasks. "" not in module_name : <TAB><TAB>  return "" {} . {} "" . format ( module_name , class_name ) <TAB>  else : <TAB><TAB>  return module_name ","if isinstance ( parent , pytest . Class ) :","if isinstance(parent, pytest.Class):",False,68.04681431508934,100.00000000000004
2247,"def getAllFitsLite ( ) : <TAB>  fits = eos . db . getFitListLite ( ) <TAB>  shipMap = { f . shipID : None for f in fits } <TAB>  for shipID in shipMap : <TAB><TAB>  ship = eos . db . getItem ( shipID ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shipMap [ shipID ] = ( ship . name , ship . getShortName ( ) ) <TAB>  fitsToPurge = set ( ) <TAB>  for fit in fits : <TAB><TAB>  try : <TAB><TAB><TAB>  fit . shipName , fit . shipNameShort = shipMap [ fit . shipID ] <TAB><TAB>  except ( KeyError , TypeError ) : <TAB><TAB><TAB>  fitsToPurge . add ( fit ) <TAB>  for fit in fitsToPurge : <TAB><TAB>  fits . remove ( fit ) <TAB>  return fits ",if ship is not None :,if ship:,False,38.99210298123229,97.65716036266241
2248,"def _process ( self , event_data ) : <TAB>  self . machine . callbacks ( self . machine . prepare_event , event_data ) <TAB>  _LOGGER . debug ( <TAB><TAB>  "" %s Executed machine preparation callbacks before conditions. "" , self . machine . name <TAB>  ) <TAB>  try : <TAB><TAB>  for trans in self . transitions [ event_data . state . name ] : <TAB><TAB><TAB>  event_data . transition = trans <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  event_data . result = True <TAB><TAB><TAB><TAB>  break <TAB>  except Exception as err : <TAB><TAB>  event_data . error = err <TAB><TAB>  raise <TAB>  finally : <TAB><TAB>  self . machine . callbacks ( self . machine . finalize_event , event_data ) <TAB><TAB>  _LOGGER . debug ( "" %s Executed machine finalize callbacks "" , self . machine . name ) <TAB>  return event_data . result ",if trans . execute ( event_data ) :,if event_data.state.name == self.machine.name:,False,26.91419660970622,91.91379366042838
2249,"def fetch_comments ( self , force = False , limit = None ) : <TAB>  comments = [ ] <TAB>  if ( force is True ) or ( self . badges [ "" comments "" ] > 0 ) : <TAB><TAB>  query_params = { "" filter "" : "" commentCard,copyCommentCard "" } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  query_params [ "" limit "" ] = limit <TAB><TAB>  comments = self . client . fetch_json ( <TAB><TAB><TAB>  "" /cards/ "" + self . id + "" /actions "" , query_params = query_params <TAB><TAB>  ) <TAB><TAB>  return sorted ( comments , key = lambda comment : comment [ "" date "" ] ) <TAB>  return comments ",if limit is not None :,if limit is not None:,False,51.39210597379981,100.00000000000004
2250,"def get_changed ( self ) : <TAB>  if self . _is_expression ( ) : <TAB><TAB>  result = self . _get_node_text ( self . ast ) <TAB><TAB>  if result == self . source : <TAB><TAB><TAB>  return None <TAB><TAB>  return result <TAB>  else : <TAB><TAB>  collector = codeanalyze . ChangeCollector ( self . source ) <TAB><TAB>  last_end = - 1 <TAB><TAB>  for match in self . matches : <TAB><TAB><TAB>  start , end = match . get_region ( ) <TAB><TAB><TAB>  if start < last_end : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  last_end = end <TAB><TAB><TAB>  replacement = self . _get_matched_text ( match ) <TAB><TAB><TAB>  collector . add_change ( start , end , replacement ) <TAB><TAB>  return collector . get_changed ( ) ",if not self . _is_expression ( ) :,if end == -1:,False,35.645790313456786,95.26135895971693
2251,"def _replace_home ( x ) : <TAB>  if xp . ON_WINDOWS : <TAB><TAB>  home = ( <TAB><TAB><TAB>  builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB>  if builtins . __xonsh__ . env . get ( "" FORCE_POSIX_PATHS "" ) : <TAB><TAB><TAB>  x = x . replace ( os . sep , os . altsep ) <TAB><TAB>  return x <TAB>  else : <TAB><TAB>  home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB>  return x ",if x . startswith ( home ) :,if home:,False,23.546398467801914,93.44909935538669
2252,"def project_review ( plans ) : <TAB>  for plan in plans : <TAB><TAB>  print ( "" Inspecting  {}  plan "" . format ( plan ) ) <TAB><TAB>  branches = get_branches_from_plan ( plan ) <TAB><TAB>  for branch in branches : <TAB><TAB><TAB>  build_results = get_results_from_branch ( branch ) <TAB><TAB><TAB>  for build in build_results : <TAB><TAB><TAB><TAB>  build_key = build . get ( "" buildResultKey "" ) or None <TAB><TAB><TAB><TAB>  print ( "" Inspecting build -  {} "" . format ( build_key ) ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  for status in STATUS_CLEANED_RESULTS : <TAB><TAB><TAB><TAB><TAB><TAB>  remove_build_result ( build_key = build_key , status = status ) ",if build_key :,if build_key == build_key:,False,22.54743484193429,97.91227134609866
2253,"def _check_for_batch_clashes ( xs ) : <TAB>  """"""Check that batch names do not overlap with sample names."""""" <TAB>  names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB>  dups = set ( [ ] ) <TAB>  for x in xs : <TAB><TAB>  batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB><TAB>  if batches : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  batches = [ batches ] <TAB><TAB><TAB>  for batch in batches : <TAB><TAB><TAB><TAB>  if batch in names : <TAB><TAB><TAB><TAB><TAB>  dups . add ( batch ) <TAB>  if len ( dups ) > 0 : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" Batch names must be unique from sample descriptions. \n "" <TAB><TAB><TAB>  "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB><TAB>  ) ","if not isinstance ( batches , ( list , tuple ) ) :","if not isinstance(batches, (list, tuple)):",False,60.74709872227461,100.00000000000004
2254,"def _check_signal ( self ) : <TAB>  """"""Checks if a signal was received and issues a message."""""" <TAB>  proc_signal = getattr ( self . proc , "" signal "" , None ) <TAB>  if proc_signal is None : <TAB><TAB>  return <TAB>  sig , core = proc_signal <TAB>  sig_str = SIGNAL_MESSAGES . get ( sig ) <TAB>  if sig_str : <TAB><TAB>  if core : <TAB><TAB><TAB>  sig_str + = ""  (core dumped) "" <TAB><TAB>  print ( sig_str , file = sys . stderr ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . errors + = sig_str + "" \n "" ",if self . errors is not None :,if sig_str:,False,53.084277986530715,95.81558940665711
2255,"def loadLabelFile ( self , labelpath ) : <TAB>  labeldict = { } <TAB>  if not os . path . exists ( labelpath ) : <TAB><TAB>  f = open ( labelpath , "" w "" , encoding = "" utf-8 "" ) <TAB>  else : <TAB><TAB>  with open ( labelpath , "" r "" , encoding = "" utf-8 "" ) as f : <TAB><TAB><TAB>  data = f . readlines ( ) <TAB><TAB><TAB>  for each in data : <TAB><TAB><TAB><TAB>  file , label = each . split ( "" \t "" ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  label = label . replace ( "" false "" , "" False "" ) <TAB><TAB><TAB><TAB><TAB>  label = label . replace ( "" true "" , "" True "" ) <TAB><TAB><TAB><TAB><TAB>  labeldict [ file ] = eval ( label ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  labeldict [ file ] = [ ] <TAB>  return labeldict ",if label :,if file == 'false':,False,22.33306113834966,97.99378403019868
2256,"def exists_col_to_many ( self , select_columns : List [ str ] ) - > bool : <TAB>  for column in select_columns : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  root_relation = get_column_root_relation ( column ) <TAB><TAB><TAB>  if self . is_relation_many_to_many ( <TAB><TAB><TAB><TAB>  root_relation <TAB><TAB><TAB>  ) or self . is_relation_one_to_many ( root_relation ) : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if is_column_dotted ( column ) :,if column in self.columns:,False,48.32712659828341,94.03936860418298
2257,"def check_sequence_matches ( seq , template ) : <TAB>  i = 0 <TAB>  for pattern in template : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pattern = { pattern } <TAB><TAB>  got = set ( seq [ i : i + len ( pattern ) ] ) <TAB><TAB>  assert got == pattern <TAB><TAB>  i + = len ( got ) ","if not isinstance ( pattern , set ) :","if not isinstance(pattern, basestring):",False,21.803129312504254,97.46768017625028
2258,"def load_modules ( <TAB>  to_load , load , attr , modules_dict , excluded_aliases , loading_message = None  ) : <TAB>  if loading_message : <TAB><TAB>  print ( loading_message ) <TAB>  for name in to_load : <TAB><TAB>  module = load ( name ) <TAB><TAB>  if module is None or not hasattr ( module , attr ) : <TAB><TAB><TAB>  continue <TAB><TAB>  cls = getattr ( module , attr ) <TAB><TAB>  if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for alias in module . aliases ( ) : <TAB><TAB><TAB><TAB>  if alias not in excluded_aliases : <TAB><TAB><TAB><TAB><TAB>  modules_dict [ alias ] = module <TAB><TAB>  else : <TAB><TAB><TAB>  modules_dict [ name ] = module <TAB>  if loading_message : <TAB><TAB>  print ( ) ","if hasattr ( module , ""aliases"" ) :",if module.aliases():,False,54.50970033085354,97.08474566498384
2259,"def result ( ) : <TAB>  # ""global"" does not work here... <TAB>  R , V = rays , virtual_rays <TAB>  if V is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  V = normalize_rays ( V , lattice ) <TAB><TAB>  if check : <TAB><TAB><TAB>  R = PointCollection ( V , lattice ) <TAB><TAB><TAB>  V = PointCollection ( V , lattice ) <TAB><TAB><TAB>  d = lattice . dimension ( ) <TAB><TAB><TAB>  if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d : <TAB><TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB><TAB>  "" virtual rays must be linearly  "" <TAB><TAB><TAB><TAB><TAB>  "" independent and with other rays span the ambient space. "" <TAB><TAB><TAB><TAB>  ) <TAB>  return RationalPolyhedralFan ( cones , R , lattice , is_complete , V ) ",if normalize :,"if isinstance(V, rays.Rays):",False,33.95282952757614,96.40547209224893
2260,"def communicate ( self , _input = None , _timeout = None ) - > Tuple [ bytes , bytes ] : <TAB>  if parse_args ( ) . print_commands : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print_stderr ( <TAB><TAB><TAB><TAB>  color_line ( "" =>  "" , 14 ) + "" "" . join ( str ( arg ) for arg in self . args ) <TAB><TAB><TAB>  ) <TAB>  stdout , stderr = super ( ) . communicate ( _input , _timeout ) <TAB>  self . stdout_text = stdout . decode ( "" utf-8 "" ) if stdout else None <TAB>  self . stderr_text = stderr . decode ( "" utf-8 "" ) if stderr else None <TAB>  return stdout , stderr ",if self . args != get_sudo_refresh_command ( ) :,if self.args:,False,29.360587652817372,93.27573638378064
2261,"def convert ( data ) : <TAB>  result = [ ] <TAB>  for d in data : <TAB><TAB>  # noinspection PyCompatibility <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( ( d [ 0 ] , None , d [ 1 ] ) ) <TAB><TAB>  elif isinstance ( d , basestring ) : <TAB><TAB><TAB>  result . append ( d ) <TAB>  return result ","if isinstance ( d , tuple ) and len ( d ) == 2 :","if isinstance(d, (int, float, float)):",False,50.951667685508674,90.32166541788268
2262,"def validate ( self , value ) : <TAB>  try : <TAB><TAB>  value = [ <TAB><TAB><TAB>  datetime . datetime . strptime ( range , "" % Y- % m- %d % H: % M: % S "" ) <TAB><TAB><TAB>  for range in value . split ( ""  to  "" ) <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  except ValueError : <TAB><TAB>  return False ",if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,if value in value:,False,18.57962760993844,84.56605146703002
2263,"def rmdir ( dirname ) : <TAB>  if dirname [ - 1 ] == os . sep : <TAB><TAB>  dirname = dirname [ : - 1 ] <TAB>  if os . path . islink ( dirname ) : <TAB><TAB>  return<TAB># do not clear link - we can get out of dir <TAB>  for f in os . listdir ( dirname ) : <TAB><TAB>  if f in ( "" . "" , "" .. "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  path = dirname + os . sep + f <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rmdir ( path ) <TAB><TAB>  else : <TAB><TAB><TAB>  os . unlink ( path ) <TAB>  os . rmdir ( dirname ) ",if os . path . isdir ( path ) :,if os.path.isdir(path):,False,32.1020416508825,93.83802074167632
2264,"def onCompletion ( self , text ) : <TAB>  res = [ ] <TAB>  for l in text . split ( "" \n "" ) : <TAB><TAB>  if not l : <TAB><TAB><TAB>  continue <TAB><TAB>  l = l . split ( "" : "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB>  self . panel . setSlides ( res ) ",if len ( l ) != 2 :,if len(l) == 0:,False,26.146671186635924,96.75163633510398
2265,"def pytest_collection_modifyitems ( items ) : <TAB>  for item in items : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB>  if "" init "" not in item . keywords : <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if item . nodeid . startswith ( ""tests/infer"" ) :",if item.type == pytest.mark.unit:,False,25.217371308490836,91.62398929493044
2266,"def build_message ( self , options , target ) : <TAB>  message = multipart . MIMEMultipart ( ) <TAB>  for name , value in list ( options . items ( ) ) : <TAB><TAB>  if name == "" EMAIL_BODY "" : <TAB><TAB><TAB>  self . add_body ( message , value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add_attachment ( message , value ) <TAB><TAB>  else :<TAB># From, To, Subject, etc. <TAB><TAB><TAB>  self . set_option ( message , name , value , target ) <TAB>  return message ","elif name == ""EMAIL_ATTACHMENT"" :","if name == ""MAIL_ATTACHMENTS':",False,22.847850419391076,92.66860454640646
2267,def extend_with_zeroes ( b ) : <TAB>  try : <TAB><TAB>  for x in b : <TAB><TAB><TAB>  x = to_constant ( x ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield ( x ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield ( 0 ) <TAB><TAB>  for _ in range ( 32 ) : <TAB><TAB><TAB>  yield ( 0 ) <TAB>  except Exception as e : <TAB><TAB>  return ,"if isinstance ( x , int ) :",if x:,False,22.678878484812724,94.91008525052334
2268,"def _start_cluster ( * , cleanup_atexit = True ) : <TAB>  global _default_cluster <TAB>  if _default_cluster is None : <TAB><TAB>  cluster_addr = os . environ . get ( "" EDGEDB_TEST_CLUSTER_ADDR "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  conn_spec = json . loads ( cluster_addr ) <TAB><TAB><TAB>  _default_cluster = edgedb_cluster . RunningCluster ( * * conn_spec ) <TAB><TAB>  else : <TAB><TAB><TAB>  data_dir = os . environ . get ( "" EDGEDB_TEST_DATA_DIR "" ) <TAB><TAB><TAB>  _default_cluster = _init_cluster ( <TAB><TAB><TAB><TAB>  data_dir = data_dir , cleanup_atexit = cleanup_atexit <TAB><TAB><TAB>  ) <TAB>  return _default_cluster ",if cluster_addr :,if cluster_addr:,False,46.4417948835339,100.00000000000004
2269,"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB>  with open ( input_filename , "" r "" ) as f1 : <TAB><TAB>  with open ( output_filename , "" w "" ) as f2 : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  line = f1 . readline ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB><TAB><TAB><TAB>  if line != "" "" and line != "" "" : <TAB><TAB><TAB><TAB><TAB>  if line [ 0 ] == "" "" : <TAB><TAB><TAB><TAB><TAB><TAB>  line = line [ 1 : ] <TAB><TAB><TAB><TAB><TAB>  f2 . writelines ( line + "" \n "" ) ",if not line :,if not line:,False,39.80919785161075,100.00000000000004
2270,"def is_entirely_italic ( line ) : <TAB>  style = subs . styles . get ( line . style , SSAStyle . DEFAULT_STYLE ) <TAB>  for fragment , sty in parse_tags ( line . text , style , subs . styles ) : <TAB><TAB>  fragment = fragment . replace ( r "" \ h "" , "" "" ) <TAB><TAB>  fragment = fragment . replace ( r "" \ n "" , "" \n "" ) <TAB><TAB>  fragment = fragment . replace ( r "" \ N "" , "" \n "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB>  return True ",if not sty . italic and fragment and not fragment . isspace ( ) :,if fragment == line.text:,False,15.721914677274789,90.98292964264216
2271,def __get_all_nodes ( self ) : <TAB>  nodes = [ ] <TAB>  next_level = [ self . __tree . get_root ( ) ] <TAB>  while len ( next_level ) != 0 : <TAB><TAB>  cur_level = next_level <TAB><TAB>  nodes + = next_level <TAB><TAB>  next_level = [ ] <TAB><TAB>  for cur_node in cur_level : <TAB><TAB><TAB>  children = cur_node . get_children ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  next_level + = children <TAB>  return nodes ,if children is not None :,if children:,False,17.177368325930605,97.206233154257
2272,"def _openvpn_stdout ( self ) : <TAB>  while True : <TAB><TAB>  line = self . process . stdout . readline ( ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  time . sleep ( 0.05 ) <TAB><TAB><TAB>  continue <TAB><TAB>  yield <TAB><TAB>  try : <TAB><TAB><TAB>  self . server . output . push_output ( line ) <TAB><TAB>  except : <TAB><TAB><TAB>  logger . exception ( <TAB><TAB><TAB><TAB>  "" Failed to push vpn output "" , <TAB><TAB><TAB><TAB>  "" server "" , <TAB><TAB><TAB><TAB>  server_id = self . server . id , <TAB><TAB><TAB>  ) <TAB><TAB>  yield ",if self . process . poll ( ) is not None or self . is_interrupted ( ) :,if not line:,False,28.721556346709715,91.77634936201044
2273,"def payment_received_handler ( event ) : <TAB>  if isinstance ( event . message . action , types . MessageActionPaymentSentMe ) : <TAB><TAB>  payment : types . MessageActionPaymentSentMe = event . message . action <TAB><TAB>  # do something after payment was received <TAB><TAB>  if payment . payload . decode ( "" UTF-8 "" ) == "" product A "" : <TAB><TAB><TAB>  await bot . send_message ( <TAB><TAB><TAB><TAB>  event . message . from_id , "" Thank you for buying product A! "" <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await bot . send_message ( <TAB><TAB><TAB><TAB>  event . message . from_id , "" Thank you for buying product B! "" <TAB><TAB><TAB>  ) <TAB><TAB>  raise events . StopPropagation ","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :","if isinstance(event.message.action, types.MessageActionPaymentSentMe):",False,58.25067979488825,92.15241693441047
2274,"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB>  if next is not None and token . end_mark . line == next . start_mark . line : <TAB><TAB>  spaces = next . start_mark . pointer - token . end_mark . pointer <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return LintProblem ( <TAB><TAB><TAB><TAB>  token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB><TAB><TAB>  ) <TAB><TAB>  elif min != - 1 and spaces < min : <TAB><TAB><TAB>  return LintProblem ( <TAB><TAB><TAB><TAB>  token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB><TAB><TAB>  ) ",if max != - 1 and spaces > max :,if max != -1 and spaces > max:,False,58.28368053228636,95.34495512336315
2275,"def seek_to_block ( self , pos ) : <TAB>  baseofs = 0 <TAB>  ofs = 0 <TAB>  for b in self . blocks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . current_block = b <TAB><TAB><TAB>  break <TAB><TAB>  baseofs + = b . compressed_size <TAB><TAB>  ofs + = b . uncompressed_size <TAB>  else : <TAB><TAB>  self . current_block = None <TAB><TAB>  self . current_stream = BytesIO ( b "" "" ) <TAB><TAB>  return <TAB>  self . current_block_start = ofs <TAB>  self . stream . seek ( self . basepos + baseofs ) <TAB>  buf = BytesIO ( self . stream . read ( self . current_block . compressed_size ) ) <TAB>  self . current_stream = self . current_block . decompress ( buf ) ",if ofs + b . uncompressed_size > pos :,if b.seek(pos):,False,34.839338322805006,95.6005578098731
2276,"def rewrite_hunks ( hunks ) : <TAB>  # type: (List[Hunk]) -> Iterator[Hunk] <TAB>  # Assumes `hunks` are sorted, and from the same file <TAB>  deltas = ( hunk . b_length - hunk . a_length for hunk in hunks ) <TAB>  offsets = accumulate ( deltas , initial = 0 ) <TAB>  for hunk , offset in zip ( hunks , offsets ) : <TAB><TAB>  new_b = hunk . a_start + offset <TAB><TAB>  if hunk_of_additions_only ( hunk ) : <TAB><TAB><TAB>  new_b + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_b - = 1 <TAB><TAB>  yield hunk . _replace ( b_start = new_b ) ",elif hunk_of_removals_only ( hunk ) :,if hunk_of_additions_only(hunk):,False,34.27039407823674,97.4022221656261
2277,"def do_query ( data , q ) : <TAB>  ret = [ ] <TAB>  if not q : <TAB><TAB>  return ret <TAB>  qkey = q [ 0 ] <TAB>  for key , value in iterate ( data ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if key == qkey : <TAB><TAB><TAB><TAB>  ret . append ( value ) <TAB><TAB><TAB>  elif is_iterable ( value ) : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  if not is_iterable ( value ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if key == qkey : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB>  return ret ",if len ( q ) == 1 :,"if isinstance(value, tuple):",False,49.63282758190898,96.99401974992104
2278,"def get_url ( token , base_url ) : <TAB>  """"""Parse an <url> token."""""" <TAB>  if token . type == "" url "" : <TAB><TAB>  return _get_url_tuple ( token . value , base_url ) <TAB>  elif token . type == "" function "" : <TAB><TAB>  if token . name == "" attr "" : <TAB><TAB><TAB>  return check_attr_function ( token , "" url "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Ignore url modifiers <TAB><TAB><TAB>  # See https://drafts.csswg.org/css-values-3/#urls <TAB><TAB><TAB>  return _get_url_tuple ( token . arguments [ 0 ] . value , base_url ) ","elif token . name == ""url"" and len ( token . arguments ) in ( 1 , 2 ) :","if token.type == ""url_modifiers':",False,45.70916002445241,90.1951321098285
2279,"def read ( self , count ) : <TAB>  if self . closed : <TAB><TAB>  return self . upstream . read ( count ) <TAB>  try : <TAB><TAB>  while len ( self . upstream ) < count : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  with self . buf_in : <TAB><TAB><TAB><TAB><TAB>  self . transport . downstream_recv ( self . buf_in ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  return self . upstream . read ( count ) <TAB>  except : <TAB><TAB>  logger . debug ( traceback . format_exc ( ) ) ",if self . buf_in or self . _poll_read ( 10 ) :,if self.transport:,False,23.566192933535504,92.06493212789819
2280,"def get_timestamp_for_block ( <TAB>  self , block_hash : HexBytes , max_tries : Optional [ int ] = 10  ) - > int : <TAB>  counter = 0 <TAB>  block : AttributeDict = None <TAB>  if block_hash in self . _block_cache . keys ( ) : <TAB><TAB>  block = self . _block_cache . get ( block_hash ) <TAB>  else : <TAB><TAB>  while block is None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ValueError ( f "" Block hash  { block_hash . hex ( ) }  does not exist. "" ) <TAB><TAB><TAB>  counter + = 1 <TAB><TAB><TAB>  block = self . _block_cache . get ( block_hash ) <TAB><TAB><TAB>  await asyncio . sleep ( 0.5 ) <TAB>  return block . get ( "" timestamp "" ) ",if counter == max_tries :,if counter >= max_tries:,False,45.135583676391114,98.85708129572258
2281,"def reader ( ) : <TAB>  batch_out = [ ] <TAB>  for video_name in self . video_list : <TAB><TAB>  video_idx = self . video_list . index ( video_name ) <TAB><TAB>  video_feat = self . load_file ( video_name ) <TAB><TAB>  batch_out . append ( ( video_feat , video_idx ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield batch_out <TAB><TAB><TAB>  batch_out = [ ] ",if len ( batch_out ) == self . batch_size :,if len(batch_out) > 0:,False,33.78822555482921,93.87155777601691
2282,"def cleanup ( ) : <TAB>  gscript . message ( _ ( "" Erasing temporary files... "" ) ) <TAB>  for temp_map , maptype in temp_maps : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gscript . run_command ( <TAB><TAB><TAB><TAB>  "" g.remove "" , flags = "" f "" , type = maptype , name = temp_map , quiet = True <TAB><TAB><TAB>  ) ","if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :",if gscript.is_running(temp_map):,False,31.736190879089577,87.43159990464234
2283,"def run ( self ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  with DelayedKeyboardInterrupt ( ) : <TAB><TAB><TAB><TAB>  raw_inputs = self . _parent_task_queue . get ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  if self . _flow_type == BATCH : <TAB><TAB><TAB><TAB><TAB>  self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB>  elif self . _flow_type == REALTIME : <TAB><TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB><TAB>  self . _rq . put ( raw_inputs , block = False ) <TAB><TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB>  except KeyboardInterrupt : <TAB><TAB><TAB>  continue ",if self . _has_stop_signal ( raw_inputs ) :,if self._flow_type == REPEAT:,False,24.012637143301724,96.41805627481295
2284,"def handle_sent ( self , elt ) : <TAB>  sent = [ ] <TAB>  for child in elt : <TAB><TAB>  if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB><TAB><TAB>  sent + = [ self . handle_word ( w ) for w in child ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sent . append ( self . handle_word ( child ) ) <TAB><TAB>  elif child . tag not in self . tags_to_ignore : <TAB><TAB><TAB>  raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB>  return BNCSentence ( elt . attrib [ "" n "" ] , sent ) ","elif child . tag in ( ""w"" , ""c"" ) :","if child.tag == ""mw"" and isinstance(child, (str, unicode))",False,46.349141321416454,89.90507237167229
2285,"def bind_subscribers_to_graphql_type ( self , graphql_type ) : <TAB>  for field , subscriber in self . _subscribers . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Field  %s  is not defined on type  %s "" % ( field , self . name ) ) <TAB><TAB>  graphql_type . fields [ field ] . subscribe = subscriber ",if field not in graphql_type . fields :,"if not isinstance(field, type(subgraph_type.fields[field]) or not",False,51.71963658183202,84.85555900623703
2286,"def _get_from_json ( self , * , name , version ) : <TAB>  url = urljoin ( self . url , posixpath . join ( name , str ( version ) , "" json "" ) ) <TAB>  async with aiohttp_session ( auth = self . auth ) as session : <TAB><TAB>  async with session . get ( url ) as response : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise PackageNotFoundError ( package = name , url = url ) <TAB><TAB><TAB>  response . raise_for_status ( ) <TAB><TAB><TAB>  response = await response . json ( ) <TAB>  dist = response [ "" info "" ] [ "" requires_dist "" ] or [ ] <TAB>  if dist : <TAB><TAB>  return dist <TAB>  # If no requires_dist then package metadata can be broken. <TAB>  # Let's check distribution files. <TAB>  return await self . _get_from_files ( response [ "" urls "" ] ) ",if response . status == 404 :,if not response.ok:,False,55.93165801782766,97.10347496236474
2287,"def is_active ( self ) : <TAB>  if not self . pk : <TAB><TAB>  log_level = get_setting ( "" LOG_MISSING_SWITCHES "" ) <TAB><TAB>  if log_level : <TAB><TAB><TAB>  logger . log ( log_level , "" Switch  %s  not found "" , self . name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  switch , _created = Switch . objects . get_or_create ( <TAB><TAB><TAB><TAB>  name = self . name , defaults = { "" active "" : get_setting ( "" SWITCH_DEFAULT "" ) } <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  cache = get_cache ( ) <TAB><TAB><TAB>  cache . set ( self . _cache_key ( self . name ) , switch ) <TAB><TAB>  return get_setting ( "" SWITCH_DEFAULT "" ) <TAB>  return self . active ","if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :",if not self.active:,False,28.62331264542079,94.20386546765513
2288,"def add_requirements ( self , requirements ) : <TAB>  if self . _legacy : <TAB><TAB>  self . _legacy . add_requirements ( requirements ) <TAB>  else : <TAB><TAB>  run_requires = self . _data . setdefault ( "" run_requires "" , [ ] ) <TAB><TAB>  always = None <TAB><TAB>  for entry in run_requires : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  always = entry <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if always is None : <TAB><TAB><TAB>  always = { "" requires "" : requirements } <TAB><TAB><TAB>  run_requires . insert ( 0 , always ) <TAB><TAB>  else : <TAB><TAB><TAB>  rset = set ( always [ "" requires "" ] ) | set ( requirements ) <TAB><TAB><TAB>  always [ "" requires "" ] = sorted ( rset ) ","if ""environment"" not in entry and ""extra"" not in entry :",if entry['requires'] == requirements:,False,47.866575517622174,94.05480179091586
2289,"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB>  """"""Display a failure for a single method / endpoint."""""" <TAB>  display_subsection ( result ) <TAB>  checks = _get_unique_failures ( result . checks ) <TAB>  for idx , check in enumerate ( checks , 1 ) : <TAB><TAB>  message : Optional [ str ] <TAB><TAB>  if check . message : <TAB><TAB><TAB>  message = f "" { idx } .  { check . message } "" <TAB><TAB>  else : <TAB><TAB><TAB>  message = None <TAB><TAB>  example = cast ( Case , check . example )<TAB># filtered in `_get_unique_failures` <TAB><TAB>  display_example ( example , check . name , message , result . seed ) <TAB><TAB>  # Display every time except the last check <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  click . echo ( "" \n "" ) ",if idx != len ( checks ) :,if len(checks) == 0:,False,38.25482452827077,95.7359913247262
2290,"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB>  code = frame . f_code <TAB>  if ( <TAB><TAB>  event not in SUPPORTED_EVENTS <TAB><TAB>  or code . co_name == "" trace_types "" <TAB><TAB>  or self . should_trace <TAB><TAB>  and not self . should_trace ( code ) <TAB>  ) : <TAB><TAB>  return self <TAB>  try : <TAB><TAB>  if event == EVENT_CALL : <TAB><TAB><TAB>  self . handle_call ( frame ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . handle_return ( frame , arg ) <TAB><TAB>  else : <TAB><TAB><TAB>  logger . error ( "" Cannot handle event  %s "" , event ) <TAB>  except Exception : <TAB><TAB>  logger . exception ( "" Failed collecting trace "" ) <TAB>  return self ",elif event == EVENT_RETURN :,if event == EVENT_RETURN:,False,49.89797235490827,98.95283225469963
2291,"def get_maps ( test ) : <TAB>  pages = set ( ) <TAB>  for addr in test [ "" pre "" ] [ "" memory "" ] . keys ( ) : <TAB><TAB>  pages . add ( addr >> 12 ) <TAB>  for addr in test [ "" pos "" ] [ "" memory "" ] . keys ( ) : <TAB><TAB>  pages . add ( addr >> 12 ) <TAB>  maps = [ ] <TAB>  for p in sorted ( pages ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  maps [ - 1 ] = ( maps [ - 1 ] [ 0 ] , maps [ - 1 ] [ 1 ] + 0x1000 ) <TAB><TAB>  else : <TAB><TAB><TAB>  maps . append ( ( p << 12 , 0x1000 ) ) <TAB>  return maps ",if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,if p == 'map':,False,36.397588667897644,82.78578207858803
2292,"def process_rotate_aes_key ( self ) : <TAB>  if hasattr ( self . options , "" rotate_aes_key "" ) and isinstance ( <TAB><TAB>  self . options . rotate_aes_key , six . string_types <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . options . rotate_aes_key = True <TAB><TAB>  elif self . options . rotate_aes_key . lower ( ) == "" false "" : <TAB><TAB><TAB>  self . options . rotate_aes_key = False ","if self . options . rotate_aes_key . lower ( ) == ""true"" :","if self.options.rotate_aes_key.lower() == ""true"" or self",False,48.56869370039705,97.66581194053254
2293,"def apply_figure ( self , figure ) : <TAB>  super ( legend_text_legend , self ) . apply_figure ( figure ) <TAB>  properties = self . properties . copy ( ) <TAB>  with suppress ( KeyError ) : <TAB><TAB>  del properties [ "" margin "" ] <TAB>  with suppress ( KeyError ) : <TAB><TAB>  texts = figure . _themeable [ "" legend_text_legend "" ] <TAB><TAB>  for text in texts : <TAB><TAB><TAB>  <IF-STMT>:<TAB># textarea <TAB><TAB><TAB><TAB>  text = text . _text <TAB><TAB><TAB>  text . set ( * * properties ) ","if not hasattr ( text , ""_x"" ) :","if isinstance(text, Tk.Text):",False,42.20663826478543,93.0442342690008
2294,"def tearDown ( self ) : <TAB>  for i in range ( len ( self . tree ) - 1 , - 1 , - 1 ) : <TAB><TAB>  s = os . path . join ( self . root , self . tree [ i ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . rmdir ( s ) <TAB><TAB>  else : <TAB><TAB><TAB>  os . remove ( s ) <TAB>  os . rmdir ( self . root ) ","if not ""."" in s :",if os.path.exists(s):,False,22.108196038318717,87.05512618559017
2295,"def _get_id ( self , type , id ) : <TAB>  fields = id . split ( "" : "" ) <TAB>  if len ( fields ) > = 3 : <TAB><TAB>  if type != fields [ - 2 ] : <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  "" Expected id of type  %s  but found type  %s %s "" , type , fields [ - 2 ] , id <TAB><TAB><TAB>  ) <TAB><TAB>  return fields [ - 1 ] <TAB>  fields = id . split ( "" / "" ) <TAB>  if len ( fields ) > = 3 : <TAB><TAB>  itype = fields [ - 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  "" Expected id of type  %s  but found type  %s %s "" , type , itype , id <TAB><TAB><TAB>  ) <TAB><TAB>  return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB>  return id ",if type != itype :,if itype != type:,False,35.51845511374273,91.48316302396348
2296,"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB>  s = self <TAB>  if Symbol . debug_lookup : <TAB><TAB>  Symbol . debug_print ( "" searching in self: "" ) <TAB><TAB>  print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield s <TAB><TAB>  if recurseInAnon : <TAB><TAB><TAB>  yield from s . children_recurse_anon <TAB><TAB>  else : <TAB><TAB><TAB>  yield from s . _children <TAB><TAB>  if s . siblingAbove is None : <TAB><TAB><TAB>  break <TAB><TAB>  s = s . siblingAbove <TAB><TAB>  if Symbol . debug_lookup : <TAB><TAB><TAB>  Symbol . debug_print ( "" searching in sibling: "" ) <TAB><TAB><TAB>  print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) ",if matchSelf :,if s.children is not None:,False,35.37888882764744,97.10690471785854
2297,"def records ( account_id ) : <TAB>  """"""Fetch locks data"""""" <TAB>  s = boto3 . Session ( ) <TAB>  table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB>  results = table . scan ( ) <TAB>  for r in results [ "" Items "" ] : <TAB><TAB>  if "" LockDate "" in r : <TAB><TAB><TAB>  r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB>  print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) ) ","if ""RevisionDate"" in r :","if ""RevisionDate"" in r:",False,32.61388031263049,100.00000000000004
2298,"def _handle_errors ( errors ) : <TAB>  """"""Log out and possibly reraise errors during import."""""" <TAB>  if not errors : <TAB><TAB>  return <TAB>  log_all = True<TAB># pylint: disable=unused-variable <TAB>  err_msg = "" T2T: skipped importing  {num_missing}  data_generators modules. "" <TAB>  print ( err_msg . format ( num_missing = len ( errors ) ) ) <TAB>  for module , err in errors : <TAB><TAB>  err_str = str ( err ) <TAB><TAB>  if log_all : <TAB><TAB><TAB>  print ( "" Did not import module:  %s ; Cause:  %s "" % ( module , err_str ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" From module  %s "" % module ) <TAB><TAB><TAB>  raise err ","if not _is_import_err_msg ( err_str , module ) :",if module != err_str:,False,23.25181512452768,92.16070826040155
2299,"def find_needle ( self , tree , focused = None ) : <TAB>  if isinstance ( tree , list ) : <TAB><TAB>  for el in tree : <TAB><TAB><TAB>  res = self . find_needle ( el , focused ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return res <TAB>  elif isinstance ( tree , dict ) : <TAB><TAB>  nodes = tree . get ( "" nodes "" , [ ] ) + tree . get ( "" floating_nodes "" , [ ] ) <TAB><TAB>  if focused : <TAB><TAB><TAB>  for node in nodes : <TAB><TAB><TAB><TAB>  if node [ "" id "" ] == focused [ "" id "" ] : <TAB><TAB><TAB><TAB><TAB>  return tree <TAB><TAB>  elif tree [ "" focused "" ] : <TAB><TAB><TAB>  return tree <TAB><TAB>  return self . find_needle ( nodes , focused ) <TAB>  return { } ",if res :,if res:,False,50.681297470568296,100.00000000000004
2300,"def available_datasets ( self ) : <TAB>  """"""Automatically determine datasets provided by this file"""""" <TAB>  res = self . resolution <TAB>  coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB>  for var_name , val in self . file_content . items ( ) : <TAB><TAB>  if isinstance ( val , netCDF4 . Variable ) : <TAB><TAB><TAB>  ds_info = { <TAB><TAB><TAB><TAB>  "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB><TAB><TAB><TAB>  "" resolution "" : res , <TAB><TAB><TAB>  } <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ds_info [ "" coordinates "" ] = coordinates <TAB><TAB><TAB>  yield DatasetID ( name = var_name , resolution = res ) , ds_info ",if not self . is_geo :,if coordinates:,False,37.214966581768635,96.61533126220039
2301,"def get_subkeys ( self , key ) : <TAB>  # TODO: once we revamp the registry emulation, <TAB>  # make this better <TAB>  parent_path = key . get_path ( ) <TAB>  subkeys = [ ] <TAB>  for k in self . keys : <TAB><TAB>  test_path = k . get_path ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sub = test_path [ len ( parent_path ) : ] <TAB><TAB><TAB>  if sub . startswith ( "" \\ "" ) : <TAB><TAB><TAB><TAB>  sub = sub [ 1 : ] <TAB><TAB><TAB>  end_slash = sub . find ( "" \\ "" ) <TAB><TAB><TAB>  if end_slash > = 0 : <TAB><TAB><TAB><TAB>  sub = sub [ : end_slash ] <TAB><TAB><TAB>  if not sub : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  subkeys . append ( sub ) <TAB>  return subkeys ",if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) :,if test_path.startswith(parent_path):,False,30.816610948034352,96.17793085432807
2302,"def default ( self , o ) : <TAB>  try : <TAB><TAB>  if type ( o ) == datetime . datetime : <TAB><TAB><TAB>  return str ( o ) <TAB><TAB>  else : <TAB><TAB><TAB>  # remove unwanted attributes from the provider object during conversion to json <TAB><TAB><TAB>  if hasattr ( o , "" profile "" ) : <TAB><TAB><TAB><TAB>  del o . profile <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del o . credentials <TAB><TAB><TAB>  if hasattr ( o , "" metadata_path "" ) : <TAB><TAB><TAB><TAB>  del o . metadata_path <TAB><TAB><TAB>  if hasattr ( o , "" services_config "" ) : <TAB><TAB><TAB><TAB>  del o . services_config <TAB><TAB><TAB>  return vars ( o ) <TAB>  except Exception as e : <TAB><TAB>  return str ( o ) ","if hasattr ( o , ""credentials"" ) :","if hasattr(o, 'credentials'):",False,59.72862214388459,98.21636130028175
2303,"def submit ( self , fn , * args , * * kwargs ) : <TAB>  with self . _shutdown_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" cannot schedule new futures after shutdown "" ) <TAB><TAB>  f = _base . Future ( ) <TAB><TAB>  w = _WorkItem ( f , fn , args , kwargs ) <TAB><TAB>  self . _work_queue . put ( w ) <TAB><TAB>  self . _adjust_thread_count ( ) <TAB><TAB>  return f ",if self . _shutdown :,if self._shutdown_lock.qsize() < self._work_queue.qsize,False,47.71066488302902,88.6490892877342
2304,"def __viewerKeyPress ( viewer , event ) : <TAB>  view = viewer . view ( ) <TAB>  if not isinstance ( view , GafferSceneUI . SceneView ) : <TAB><TAB>  return False <TAB>  if event == __editSourceKeyPress : <TAB><TAB>  selectedPath = __sceneViewSelectedPath ( view ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  __editSourceNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB><TAB>  return True <TAB>  elif event == __editTweaksKeyPress : <TAB><TAB>  selectedPath = __sceneViewSelectedPath ( view ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  __editTweaksNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB><TAB>  return True ",if selectedPath is not None :,if selectedPath:,False,29.957037505537524,94.07265985832986
2305,"def _split_to_option_groups_and_paths ( self , args ) : <TAB>  opt_groups = [ ] <TAB>  current = [ ] <TAB>  for arg in args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  opts = self . _arg_parser . parse_args ( current ) [ 0 ] <TAB><TAB><TAB>  opt_groups . append ( opts ) <TAB><TAB><TAB>  current = [ ] <TAB><TAB>  else : <TAB><TAB><TAB>  current . append ( arg ) <TAB>  if opt_groups : <TAB><TAB>  return opt_groups , current <TAB>  raise ValueError ( "" Nothing to split "" ) ","if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :",if arg == self._arg_parser.parse_args(arg):,False,42.59557657506895,88.54838245529567
2306,"def _on_change ( self ) : <TAB>  changed = False <TAB>  self . save ( ) <TAB>  for key , value in self . data . items ( ) : <TAB><TAB>  if isinstance ( value , bool ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB>  if value != 1 : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  elif value is None : <TAB><TAB><TAB>  continue <TAB><TAB>  elif len ( value ) != 0 : <TAB><TAB><TAB>  changed = True <TAB><TAB><TAB>  break <TAB>  self . _reset_button . disabled = not changed ",if value :,if value != 0:,False,42.53811828628082,97.98269523212632
2307,"def wait_for_child ( pid , timeout = 1.0 ) : <TAB>  deadline = mitogen . core . now ( ) + timeout <TAB>  while timeout < mitogen . core . now ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB><TAB><TAB>  if target_pid == pid : <TAB><TAB><TAB><TAB>  return <TAB><TAB>  except OSError : <TAB><TAB><TAB>  e = sys . exc_info ( ) [ 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB>  time . sleep ( 0.05 ) <TAB>  assert False , "" wait_for_child() timed out "" ",if e . args [ 0 ] == errno . ECHILD :,if e.errno == errno.EWOULDBLOCK:,False,46.95824865787581,95.93594851815813
2308,"def _get_os_version_lsb_release ( ) : <TAB>  try : <TAB><TAB>  output = subprocess . check_output ( "" lsb_release -sri "" , shell = True ) <TAB><TAB>  lines = output . strip ( ) . split ( ) <TAB><TAB>  name , version = lines <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  version = "" "" <TAB><TAB>  return name , version <TAB>  except : <TAB><TAB>  return _get_os_version_uname ( ) ","if version . lower ( ) == ""rolling"" :",if version == '':,False,21.751202334782462,92.62368067985985
2309,"def _check_snapshot_status_healthy ( self , snapshot_uuid ) : <TAB>  status = "" "" <TAB>  try : <TAB><TAB>  while True : <TAB><TAB><TAB>  status , locked = self . _get_snapshot_status ( snapshot_uuid ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  eventlet . sleep ( 2 ) <TAB>  except Exception : <TAB><TAB>  with excutils . save_and_reraise_exception ( ) : <TAB><TAB><TAB>  LOG . exception ( "" Failed to get snapshot status. [ %s ] "" , snapshot_uuid ) <TAB>  LOG . debug ( <TAB><TAB>  "" Lun [ %(snapshot)s ], status [ %(status)s ]. "" , <TAB><TAB>  { "" snapshot "" : snapshot_uuid , "" status "" : status } , <TAB>  ) <TAB>  return status == "" Healthy "" ",if not locked :,if locked:,False,43.489634197975604,98.90415601285979
2310,"def CountButtons ( self ) : <TAB>  """"""Returns the number of visible buttons in the docked pane."""""" <TAB>  n = 0 <TAB>  if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB><TAB>  if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB><TAB><TAB>  return 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  if self . HasMaximizeButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  if self . HasMinimizeButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  if self . HasPinButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB>  return n ",if self . HasCloseButton ( ) :,if self.HasMinimizeButton():,False,52.14439270197402,98.66121287187084
2311,"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB>  from . datastructures import iter_multi_items <TAB>  iterable = iter_multi_items ( obj ) <TAB>  if sort : <TAB><TAB>  iterable = sorted ( iterable , key = key ) <TAB>  for key , value in iterable : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if not isinstance ( key , bytes ) : <TAB><TAB><TAB>  key = text_type ( key ) . encode ( charset ) <TAB><TAB>  if not isinstance ( value , bytes ) : <TAB><TAB><TAB>  value = text_type ( value ) . encode ( charset ) <TAB><TAB>  yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value ) ",if value is None :,if key in encode_keys:,False,48.200425004960515,96.86288140553816
2312,"def get_response ( self , exc_fmt = None ) : <TAB>  self . callback = None <TAB>  if __debug__ : <TAB><TAB>  self . parent . _log ( 3 , "" %s : %s .ready.wait "" % ( self . name , self . tag ) ) <TAB>  self . ready . wait ( ) <TAB>  if self . aborted is not None : <TAB><TAB>  typ , val = self . aborted <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exc_fmt = "" %s  -  %% s "" % typ <TAB><TAB>  raise typ ( exc_fmt % str ( val ) ) <TAB>  return self . response ",if exc_fmt is None :,if typ is not None:,False,41.04120446532612,96.76216297548306
2313,"def extract_items ( self ) : <TAB>  responses = self . fetch ( ) <TAB>  items = [ ] <TAB>  for response in responses : <TAB><TAB>  page_key = response . meta . get ( "" page_key "" ) or response . url <TAB><TAB>  item = { "" key "" : page_key , "" items "" : None , "" templates "" : None } <TAB><TAB>  extracted_items = [ <TAB><TAB><TAB>  dict ( i ) for i in self . spider . parse ( response ) if not isinstance ( i , Request ) <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  item [ "" items "" ] = extracted_items <TAB><TAB><TAB>  item [ "" templates "" ] = [ <TAB><TAB><TAB><TAB>  i [ "" _template "" ] for i in extracted_items if i . get ( "" _template "" ) <TAB><TAB><TAB>  ] <TAB><TAB><TAB>  items . append ( item ) <TAB>  return items ",if extracted_items :,if extracted_items:,False,55.19876463700233,100.00000000000004
2314,"def fit_one ( self , x ) : <TAB>  for i , xi in x . items ( ) : <TAB><TAB>  if self . with_centering : <TAB><TAB><TAB>  self . median [ i ] . update ( xi ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . iqr [ i ] . update ( xi ) <TAB>  return self ",if self . with_scaling :,if self.with_centering:,False,26.71286837706619,97.30376770503933
2315,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB>  right = left = index <TAB>  done = False <TAB>  while not done : <TAB><TAB>  if left == 0 : <TAB><TAB><TAB>  done = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  left - = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  done = False <TAB>  while not done : <TAB><TAB>  if right == len ( text ) : <TAB><TAB><TAB>  done = True <TAB><TAB>  elif not self . word_boundary_char ( text [ right ] ) : <TAB><TAB><TAB>  right + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  return left , right ",elif not self . word_boundary_char ( text [ left - 1 ] ) :,if allowed_chars[left] == text[left - 1]:,False,22.568356810185662,93.75236221572494
2316,"def _validate_duplicate_detection_history_time_window ( namespace ) : <TAB>  if namespace . duplicate_detection_history_time_window : <TAB><TAB>  if iso8601pattern . match ( namespace . duplicate_detection_history_time_window ) : <TAB><TAB><TAB>  pass <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  raise CLIError ( <TAB><TAB><TAB><TAB>  "" --duplicate-detection-history-time-window Value Error :  {0}  value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min "" . format ( <TAB><TAB><TAB><TAB><TAB>  namespace . duplicate_detection_history_time_window <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) ",elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,if namespace.is_time_window_specified():,False,56.870766511916614,93.84212420598936
2317,"def get_subkeys ( self , key ) : <TAB>  # TODO: once we revamp the registry emulation, <TAB>  # make this better <TAB>  parent_path = key . get_path ( ) <TAB>  subkeys = [ ] <TAB>  for k in self . keys : <TAB><TAB>  test_path = k . get_path ( ) <TAB><TAB>  if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) : <TAB><TAB><TAB>  sub = test_path [ len ( parent_path ) : ] <TAB><TAB><TAB>  if sub . startswith ( "" \\ "" ) : <TAB><TAB><TAB><TAB>  sub = sub [ 1 : ] <TAB><TAB><TAB>  end_slash = sub . find ( "" \\ "" ) <TAB><TAB><TAB>  if end_slash > = 0 : <TAB><TAB><TAB><TAB>  sub = sub [ : end_slash ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  subkeys . append ( sub ) <TAB>  return subkeys ",if not sub :,if sub in subkeys:,False,30.490829580018264,98.43085568886619
2318,"def generator ( self , data ) : <TAB>  <IF-STMT>: <TAB><TAB>  silent_vars = self . _get_silent_vars ( ) <TAB>  for task in data : <TAB><TAB>  for var , val in task . environment_variables ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if var in silent_vars : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB>  0 , <TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB>  int ( task . UniqueProcessId ) , <TAB><TAB><TAB><TAB><TAB>  str ( task . ImageFileName ) , <TAB><TAB><TAB><TAB><TAB>  Address ( task . Peb . ProcessParameters . Environment ) , <TAB><TAB><TAB><TAB><TAB>  str ( var ) , <TAB><TAB><TAB><TAB><TAB>  str ( val ) , <TAB><TAB><TAB><TAB>  ] , <TAB><TAB><TAB>  ) ",if self . _config . SILENT :,if self._is_process_executable(var):,False,45.93089241783852,95.24258108340796
2319,"def start_requests ( self ) : <TAB>  if self . fail_before_yield : <TAB><TAB>  1 / 0 <TAB>  for s in range ( 100 ) : <TAB><TAB>  qargs = { "" total "" : 10 , "" seed "" : s } <TAB><TAB>  url = self . mockserver . url ( "" /follow? %s "" ) % urlencode ( qargs , doseq = 1 ) <TAB><TAB>  yield Request ( url , meta = { "" seed "" : s } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  2 / 0 <TAB>  assert self . seedsseen , "" All start requests consumed before any download happened "" ",if self . fail_yielding :,if self.fail_before_yield:,False,56.13334270637691,97.11656816119613
2320,"def populateGridlines ( self ) : <TAB>  cTicks = self . getSystemCurve ( self . ticksId ) <TAB>  cGridlines = self . getSystemCurve ( self . gridlinesId ) <TAB>  cGridlines . clearPoints ( ) <TAB>  nTicks = cTicks . getNPoints ( ) <TAB>  for iTick in range ( nTicks ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p = cTicks . getPoint ( iTick ) <TAB><TAB><TAB>  cGridlines . addPoint ( p . getX ( ) , p . getY ( ) ) ",if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 :,if cTicks.getPoint(iTick) == iTick:,False,25.97738586157274,89.37367416403181
2321,"def handle_before_events ( request , event_list ) : <TAB>  if not event_list : <TAB><TAB>  return "" "" <TAB>  if not hasattr ( event_list , "" __iter__ "" ) : <TAB><TAB>  project = event_list . project <TAB><TAB>  event_list = [ event_list ] <TAB>  else : <TAB><TAB>  projects = set ( e . project for e in event_list ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  project = projects . pop ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  project = None <TAB>  for plugin in plugins . for_project ( project ) : <TAB><TAB>  safe_execute ( plugin . before_events , request , event_list ) <TAB>  return "" "" ",if len ( projects ) == 1 :,if projects:,False,22.938572011930358,95.79275561226142
2322,"def handle_parse_result ( self , ctx , opts , args ) : <TAB>  if self . name in opts : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _raise_exclusive_error ( ) <TAB><TAB>  if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 : <TAB><TAB><TAB>  self . _raise_exclusive_error ( ) <TAB>  return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args ) ",if self . mutually_exclusive . intersection ( opts ) :,if self.multiple and len(opts[self.name]) == 0:,False,22.8330150368403,89.4436643306336
2323,"def current_word ( cursor_offset , line ) : <TAB>  """"""the object.attribute.attribute just before or under the cursor"""""" <TAB>  pos = cursor_offset <TAB>  start = pos <TAB>  end = pos <TAB>  word = None <TAB>  for m in current_word_re . finditer ( line ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  start = m . start ( 1 ) <TAB><TAB><TAB>  end = m . end ( 1 ) <TAB><TAB><TAB>  word = m . group ( 1 ) <TAB>  if word is None : <TAB><TAB>  return None <TAB>  return LinePart ( start , end , word ) ",if m . start ( 1 ) < pos and m . end ( 1 ) >= pos :,if m.group(0) == 'word':,False,26.397736870527865,90.57121932831613
2324,"def query_to_script_path ( path , query ) : <TAB>  if path != "" * "" : <TAB><TAB>  script = os . path . join ( path , query . split ( "" "" ) [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise IOError ( "" Script  ' {} '  not found in script directory "" . format ( query ) ) <TAB><TAB>  return os . path . join ( path , query ) . split ( "" "" ) <TAB>  return query ",if not os . path . exists ( script ) :,if not os.path.exists(script):,False,54.78135514532032,100.00000000000004
2325,"def expand ( self , pbegin ) : <TAB>  # TODO(b/151921205): we have to do an identity map for unmodified <TAB>  # PCollections below because otherwise we get an error from beam. <TAB>  identity_map = "" Identity "" >> beam . Map ( lambda x : x ) <TAB>  if self . _dataset_key . is_flattened_dataset_key ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _flat_pcollection | identity_map <TAB><TAB>  else : <TAB><TAB><TAB>  return list ( <TAB><TAB><TAB><TAB>  self . _pcollection_dict . values ( ) <TAB><TAB><TAB>  ) | "" FlattenAnalysisInputs "" >> beam . Flatten ( pipeline = pbegin . pipeline ) <TAB>  else : <TAB><TAB>  return self . _pcollection_dict [ self . _dataset_key ] | identity_map ",if self . _flat_pcollection :,if self._flat_pcollection:,False,39.161876639818445,100.00000000000004
2326,"def processCoords ( coords ) : <TAB>  newcoords = deque ( ) <TAB>  for ( x , y , z ) in coords : <TAB><TAB>  for _dir , offsets in faceDirections : <TAB><TAB><TAB>  if _dir == FaceYIncreasing : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  dx , dy , dz = offsets <TAB><TAB><TAB>  p = ( x + dx , y + dy , z + dz ) <TAB><TAB><TAB>  if p not in box : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  nx , ny , nz = p <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  level . setBlockAt ( nx , ny , nz , waterID ) <TAB><TAB><TAB><TAB>  newcoords . append ( p ) <TAB>  return newcoords ","if level . blockAt ( nx , ny , nz ) == 0 :",if nx != 0:,False,26.311643365588715,94.48478537598757
2327,"def delete_byfilter ( userId , remove = True , session = None , * * dbfilter ) : <TAB>  if not session : <TAB><TAB>  session = db . Session <TAB>  ret = False <TAB>  results = session . query ( ObjectStorageMetadata ) . filter_by ( * * dbfilter ) <TAB>  if results : <TAB><TAB>  for result in results : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  session . delete ( result ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  result . update ( <TAB><TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB><TAB>  "" record_state_key "" : "" to_delete "" , <TAB><TAB><TAB><TAB><TAB><TAB>  "" record_state_val "" : str ( time . time ( ) ) , <TAB><TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ret = True <TAB>  return ret ",if remove :,if remove:,False,46.619006302986264,100.00000000000004
2328,"def fields ( self , fields ) : <TAB>  fields_xml = "" "" <TAB>  for field in fields : <TAB><TAB>  field_dict = DEFAULT_FIELD . copy ( ) <TAB><TAB>  field_dict . update ( field ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field_dict [ "" required "" ] = "" true "" <TAB><TAB>  fields_xml + = FIELD_XML_TEMPLATE % field_dict + "" \n "" <TAB>  self . xml = force_unicode ( <TAB><TAB>  force_unicode ( self . xml ) . replace ( <TAB><TAB><TAB>  u "" <!-- REPLACE FIELDS --> "" , force_unicode ( fields_xml ) <TAB><TAB>  ) <TAB>  ) ","if self . unique_key_field == field [ ""name"" ] :",if field.required:,False,49.90813693440312,91.44304021353663
2329,"def get_all_users ( self , access_token , timeout = None ) : <TAB>  if timeout is None : <TAB><TAB>  timeout = DEFAULT_TIMEOUT <TAB>  headers = self . retrieve_header ( access_token ) <TAB>  try : <TAB><TAB>  response = await self . standard_request ( <TAB><TAB><TAB>  "" get "" , "" /walkoff/api/users "" , timeout = DEFAULT_TIMEOUT , headers = headers <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  resp = await response . json ( ) <TAB><TAB><TAB>  return resp , "" Success "" <TAB><TAB>  else : <TAB><TAB><TAB>  return "" Invalid Credentials "" <TAB>  except asyncio . CancelledError : <TAB><TAB>  return False , "" TimedOut "" ",if response . status == 200 :,if response.status_code == 200:,False,50.923683247181394,98.23187482379436
2330,"def set_val ( ) : <TAB>  idx = 0 <TAB>  for idx in range ( 0 , len ( model ) ) : <TAB><TAB>  row = model [ idx ] <TAB><TAB>  if value and row [ 0 ] == value : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  idx = - 1 <TAB>  os_widget . set_active ( idx ) <TAB>  if idx == - 1 : <TAB><TAB>  os_widget . set_active ( 0 ) <TAB>  if idx > = 0 : <TAB><TAB>  return row [ 1 ] <TAB>  if self . show_all_os : <TAB><TAB>  return None ",if idx == len ( os_widget . get_model ( ) ) - 1 :,if idx == len(model):,False,37.65670206794697,91.08416932353273
2331,"def translate_module_name ( module : str , relative : int ) - > Tuple [ str , int ] : <TAB>  for pkg in VENDOR_PACKAGES : <TAB><TAB>  for alt in "" six.moves "" , "" six "" : <TAB><TAB><TAB>  substr = "" {} . {} "" . format ( pkg , alt ) <TAB><TAB><TAB>  if module . endswith ( "" . "" + substr ) or ( module == substr and relative ) : <TAB><TAB><TAB><TAB>  return alt , 0 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return alt + "" . "" + module . partition ( "" . "" + substr + "" . "" ) [ 2 ] , 0 <TAB>  return module , relative ","if ""."" + substr + ""."" in module :",if module == substr:,False,32.53047860298259,93.6184690973118
2332,"def escape ( m ) : <TAB>  all , tail = m . group ( 0 , 1 ) <TAB>  assert all . startswith ( "" \\ "" ) <TAB>  esc = simple_escapes . get ( tail ) <TAB>  if esc is not None : <TAB><TAB>  return esc <TAB>  if tail . startswith ( "" x "" ) : <TAB><TAB>  hexes = tail [ 1 : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB><TAB>  try : <TAB><TAB><TAB>  i = int ( hexes , 16 ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  i = int ( tail , 8 ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  raise ValueError ( "" invalid octal string escape ( ' \\ %s ' ) "" % tail ) <TAB>  return chr ( i ) ",if len ( hexes ) < 2 :,if hexes is None:,False,37.11410436997271,94.46081801944182
2333,"def __get_k8s_container_name ( self , job_wrapper ) : <TAB>  # These must follow a specific regex for Kubernetes. <TAB>  raw_id = job_wrapper . job_destination . id <TAB>  if isinstance ( raw_id , str ) : <TAB><TAB>  cleaned_id = re . sub ( "" [^-a-z0-9] "" , "" - "" , raw_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cleaned_id = "" x %s x "" % cleaned_id <TAB><TAB>  return cleaned_id <TAB>  return "" job-container "" ","if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :",if cleaned_id:,False,33.199329015674785,85.53632744440503
2334,"def _power_exact ( y , xc , yc , xe ) : <TAB>  yc , ye = y . int , y . exp <TAB>  while yc % 10 == 0 : <TAB><TAB>  yc / / = 10 <TAB><TAB>  ye + = 1 <TAB>  if xc == 1 : <TAB><TAB>  xe * = yc <TAB><TAB>  while xe % 10 == 0 : <TAB><TAB><TAB>  xe / / = 10 <TAB><TAB><TAB>  ye + = 1 <TAB><TAB>  if ye < 0 : <TAB><TAB><TAB>  return None <TAB><TAB>  exponent = xe * 10 * * ye <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  xc = exponent <TAB><TAB>  else : <TAB><TAB><TAB>  xc = 0 <TAB><TAB>  return 5 ",if y and xe :,if xc == 0:,False,23.776182365359933,97.34484579278174
2335,"def lpush ( key , * vals , * * kwargs ) : <TAB>  ttl = kwargs . get ( "" ttl "" ) <TAB>  cap = kwargs . get ( "" cap "" ) <TAB>  if not ttl and not cap : <TAB><TAB>  _client . lpush ( key , * vals ) <TAB>  else : <TAB><TAB>  pipe = _client . pipeline ( ) <TAB><TAB>  pipe . lpush ( key , * vals ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pipe . ltrim ( key , 0 , cap ) <TAB><TAB>  if ttl : <TAB><TAB><TAB>  pipe . expire ( key , ttl ) <TAB><TAB>  pipe . execute ( ) ",if cap :,if cap:,False,52.864981229297236,100.00000000000004
2336,"def render_headers ( self ) - > bytes : <TAB>  if not hasattr ( self , "" _headers "" ) : <TAB><TAB>  parts = [ <TAB><TAB><TAB>  b "" Content-Disposition: form-data;  "" , <TAB><TAB><TAB>  format_form_param ( "" name "" , self . name ) , <TAB><TAB>  ] <TAB><TAB>  if self . filename : <TAB><TAB><TAB>  filename = format_form_param ( "" filename "" , self . filename ) <TAB><TAB><TAB>  parts . extend ( [ b "" ;  "" , filename ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  content_type = self . content_type . encode ( ) <TAB><TAB><TAB>  parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB><TAB>  parts . append ( b "" \r \n \r \n "" ) <TAB><TAB>  self . _headers = b "" "" . join ( parts ) <TAB>  return self . _headers ",if self . content_type is not None :,if self.content_type:,False,17.613903446122304,97.24304521621043
2337,"def validate_custom_field_data ( field_type : int , field_data : ProfileFieldData ) - > None : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Choice type field must have at least have one choice <TAB><TAB><TAB>  if len ( field_data ) < 1 : <TAB><TAB><TAB><TAB>  raise JsonableError ( _ ( "" Field must have at least one choice. "" ) ) <TAB><TAB><TAB>  validate_choice_field_data ( field_data ) <TAB><TAB>  elif field_type == CustomProfileField . EXTERNAL_ACCOUNT : <TAB><TAB><TAB>  validate_external_account_field_data ( field_data ) <TAB>  except ValidationError as error : <TAB><TAB>  raise JsonableError ( error . message ) ",if field_type == CustomProfileField . CHOICE :,if field_type == CustomProfileField.CHOICE:,False,59.59965400638247,100.00000000000004
2338,"def get_data ( self , path ) : <TAB>  """"""Gross hack to contort loader to deal w/ load_*()'s bad API."""""" <TAB>  if self . file and path == self . path : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  file = self . file <TAB><TAB>  else : <TAB><TAB><TAB>  self . file = file = open ( self . path , "" r "" ) <TAB><TAB>  with file : <TAB><TAB><TAB>  # Technically should be returning bytes, but <TAB><TAB><TAB>  # SourceLoader.get_code() just passed what is returned to <TAB><TAB><TAB>  # compile() which can handle str. And converting to bytes would <TAB><TAB><TAB>  # require figuring out the encoding to decode to and <TAB><TAB><TAB>  # tokenize.detect_encoding() only accepts bytes. <TAB><TAB><TAB>  return file . read ( ) <TAB>  else : <TAB><TAB>  return super ( ) . get_data ( path ) ",if not self . file . closed :,"if isinstance(self.file, str):",False,49.73589165264791,96.94483957509806
2339,"def handle_read ( self ) : <TAB>  """"""Called when there is data waiting to be read."""""" <TAB>  try : <TAB><TAB>  chunk = self . recv ( self . ac_in_buffer_size ) <TAB>  except RetryError : <TAB><TAB>  pass <TAB>  except socket . error : <TAB><TAB>  self . handle_error ( ) <TAB>  else : <TAB><TAB>  self . tot_bytes_received + = len ( chunk ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . transfer_finished = True <TAB><TAB><TAB>  # self.close()  # <-- asyncore.recv() already do that... <TAB><TAB><TAB>  return <TAB><TAB>  if self . _data_wrapper is not None : <TAB><TAB><TAB>  chunk = self . _data_wrapper ( chunk ) <TAB><TAB>  try : <TAB><TAB><TAB>  self . file_obj . write ( chunk ) <TAB><TAB>  except OSError as err : <TAB><TAB><TAB>  raise _FileReadWriteError ( err ) ",if not chunk :,if self.transfer_finished:,False,58.22252087143862,97.57643537199621
2340,"def _swig_extract_dependency_files ( self , src ) : <TAB>  dep = [ ] <TAB>  for line in open ( src ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line = line . split ( "" "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB><TAB><TAB>  if not ( "" < "" in line or line in dep ) : <TAB><TAB><TAB><TAB>  dep . append ( line ) <TAB>  return [ i for i in dep if os . path . exists ( i ) ] ","if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :",if line.startswith('#'):,False,46.035028827901805,90.06736752167294
2341,"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB>  "" Add data to be displayed in the buffer. "" <TAB>  self . values . extend ( lines ) <TAB>  if scroll_end : <TAB><TAB>  if not self . editing : <TAB><TAB><TAB>  self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) ",elif scroll_if_editing :,if self.editing:,False,44.772540670132045,95.66564536381814
2342,"def test_getline ( self ) : <TAB>  with tokenize . open ( self . file_name ) as fp : <TAB><TAB>  for index , line in enumerate ( fp ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  line + = "" \n "" <TAB><TAB><TAB>  cached_line = linecache . getline ( self . file_name , index + 1 ) <TAB><TAB><TAB>  self . assertEqual ( line , cached_line ) ","if not line . endswith ( ""\n"" ) :",if line.startswith('\n'):,False,37.405596772555214,92.59110558490595
2343,"def selectRow ( self , rowNumber , highlight = None ) : <TAB>  if rowNumber == "" h "" : <TAB><TAB>  rowNumber = 0 <TAB>  else : <TAB><TAB>  rowNumber = int ( rowNumber ) + 1 <TAB>  if 1 > rowNumber > = len ( self . cells ) + 1 : <TAB><TAB>  raise Exception ( "" Invalid row number. "" ) <TAB>  else : <TAB><TAB>  selected = self . cells [ rowNumber ] [ 0 ] . selected <TAB><TAB>  for cell in self . cells [ rowNumber ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if selected : <TAB><TAB><TAB><TAB><TAB>  cell . deselect ( ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  cell . select ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  if highlight : <TAB><TAB><TAB><TAB><TAB>  cell . mouseEnter ( ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  cell . mouseLeave ( ) ",if highlight is None :,if cell.selected:,False,23.27850491586548,98.42697439371064
2344,"def put ( self , session ) : <TAB>  with sess_lock : <TAB><TAB>  self . parent . put ( session ) <TAB><TAB>  # Do not store the session if skip paths <TAB><TAB>  for sp in self . skip_paths : <TAB><TAB><TAB>  if request . path . startswith ( sp ) : <TAB><TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  del self . _cache [ session . sid ] <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  self . _cache [ session . sid ] = session <TAB>  self . _normalize ( ) ",if session . sid in self . _cache :,if session.sid in self._cache:,False,60.33345739772361,100.00000000000004
2345,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . add_status ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add_doc_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 18 :,if tt == 10:,False,25.979740763142505,98.87254519239598
2346,"def extract ( self , zip ) : <TAB>  max_nb = maxNbFile ( self ) <TAB>  for index , field in enumerate ( zip . array ( "" file "" ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . warning ( <TAB><TAB><TAB><TAB>  "" ZIP archive contains many files, but only first  %s  files are processed "" <TAB><TAB><TAB><TAB>  % max_nb <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  break <TAB><TAB>  self . processFile ( field ) ",if max_nb is not None and max_nb <= index :,if max_nb <= index:,False,59.57760939742154,95.18995403056984
2347,"def get_norm ( norm , out_channels ) : <TAB>  if isinstance ( norm , str ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  norm = { <TAB><TAB><TAB>  "" BN "" : BatchNorm2d , <TAB><TAB><TAB>  "" GN "" : lambda channels : nn . GroupNorm ( 32 , channels ) , <TAB><TAB><TAB>  "" nnSyncBN "" : nn . SyncBatchNorm ,<TAB># keep for debugging <TAB><TAB><TAB>  "" "" : lambda x : x , <TAB><TAB>  } [ norm ] <TAB>  return norm ( out_channels ) ",if len ( norm ) == 0 :,if norm == norm:,False,47.68077319339687,94.13240115126527
2348,"def execute ( self ) : <TAB>  if self . _dirty or not self . _qr : <TAB><TAB>  model_class = self . model_class <TAB><TAB>  query_meta = self . get_query_meta ( ) <TAB><TAB>  if self . _tuples : <TAB><TAB><TAB>  ResultWrapper = TuplesQueryResultWrapper <TAB><TAB>  elif self . _dicts : <TAB><TAB><TAB>  ResultWrapper = DictQueryResultWrapper <TAB><TAB>  elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB><TAB><TAB>  ResultWrapper = NaiveQueryResultWrapper <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ResultWrapper = AggregateQueryResultWrapper <TAB><TAB>  else : <TAB><TAB><TAB>  ResultWrapper = ModelQueryResultWrapper <TAB><TAB>  self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB><TAB>  self . _dirty = False <TAB><TAB>  return self . _qr <TAB>  else : <TAB><TAB>  return self . _qr ",elif self . _aggregate_rows :,if self._aggregate:,False,35.65168819435342,97.61724059977703
2349,"def emitIpToDomainsData ( self , data , event ) : <TAB>  self . emitRawRirData ( data , event ) <TAB>  domains = data . get ( "" domains "" ) <TAB>  if isinstance ( domains , list ) : <TAB><TAB>  for domain in domains : <TAB><TAB><TAB>  if self . checkForStop ( ) : <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  domain = domain . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . emitHostname ( domain , event ) ",if domain :,if domain:,False,50.99049657955162,100.00000000000004
2350,"def delete ( self ) : <TAB>  from weblate . trans . models import Change , Suggestion , Vote <TAB>  fast_deletes = [ ] <TAB>  for item in self . fast_deletes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fast_deletes . append ( Vote . objects . filter ( suggestion__in = item ) ) <TAB><TAB><TAB>  fast_deletes . append ( Change . objects . filter ( suggestion__in = item ) ) <TAB><TAB>  fast_deletes . append ( item ) <TAB>  self . fast_deletes = fast_deletes <TAB>  return super ( ) . delete ( ) ",if item . model is Suggestion :,if item.type == Suggestion:,False,50.982026103015365,96.98114435311322
2351,"def token ( self ) : <TAB>  if not self . _token : <TAB><TAB>  try : <TAB><TAB><TAB>  cookie_token = self . state [ "" request "" ] . headers . cookie [ CSRF_TOKEN ] . value <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  cookie_token = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _token = cookie_token <TAB><TAB>  else : <TAB><TAB><TAB>  self . _token = get_random_string ( TOKEN_LENGTH ) <TAB>  return self . _token ",if len ( cookie_token ) == TOKEN_LENGTH :,if cookie_token:,False,26.479196097454604,92.77540547853206
2352,"def get_logs ( last_file = None , last_time = None ) : <TAB>  try : <TAB><TAB>  response = client . get_logs ( last_file = last_file , last_time = last_time ) <TAB><TAB>  get_logs_streamer ( <TAB><TAB><TAB>  show_timestamp = not hide_time , <TAB><TAB><TAB>  all_containers = all_containers , <TAB><TAB><TAB>  all_info = all_info , <TAB><TAB>  ) ( response ) <TAB><TAB>  return response <TAB>  except ( ApiException , HTTPError ) as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  handle_cli_error ( <TAB><TAB><TAB><TAB>  e , <TAB><TAB><TAB><TAB>  message = "" Could not get logs for run ` {} `. "" . format ( client . run_uuid ) , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  sys . exit ( 1 ) ",if not follow :,if e.code == 500:,False,38.398483819326636,97.00284698433236
2353,"def update ( self , targets ) : <TAB>  Section . update ( self , targets ) <TAB>  outputNames = set ( ) <TAB>  for target in targets : <TAB><TAB>  g = target . globals ( ) <TAB><TAB>  outputNames . update ( [ k for k in g . keys ( ) if k . startswith ( "" output: "" ) ] ) <TAB>  rows = [ ] <TAB>  outputNames = sorted ( outputNames ) <TAB>  for outputName in outputNames : <TAB><TAB>  row = self . __rows . get ( outputName ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  row = _OutputRow ( outputName ) <TAB><TAB><TAB>  self . __rows [ outputName ] = row <TAB><TAB>  row . update ( targets ) <TAB><TAB>  row . setAlternate ( len ( rows ) % 2 ) <TAB><TAB>  rows . append ( row ) <TAB>  self . _mainColumn ( ) [ : ] = rows ",if row is None :,if not row:,False,30.323372730234667,98.07758884652989
2354,"def getBranches ( self ) : <TAB>  returned = [ ] <TAB>  for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB><TAB>  if git_branch_line . startswith ( "" * "" ) : <TAB><TAB><TAB>  git_branch_line = git_branch_line [ 1 : ] <TAB><TAB>  git_branch_line = git_branch_line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB><TAB><TAB>  returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB>  return returned ",if BRANCH_ALIAS_MARKER in git_branch_line :,if git_branch_line.startswith('branch'):,False,26.710798060366702,95.73503645484729
2355,"def has_bad_headers ( self ) : <TAB>  headers = [ self . sender , self . reply_to ] + self . recipients <TAB>  for header in headers : <TAB><TAB>  if _has_newline ( header ) : <TAB><TAB><TAB>  return True <TAB>  if self . subject : <TAB><TAB>  if _has_newline ( self . subject ) : <TAB><TAB><TAB>  for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB><TAB><TAB><TAB>  if not line : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  if _has_newline ( line ) : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  if len ( line . strip ( ) ) == 0 : <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if linenum > 0 and line [ 0 ] not in ""\t "" :",if linenum == len(line):,False,48.76824667894357,94.91698848964863
2356,"def resolve_references ( self , note , reflist ) : <TAB>  assert len ( note [ "" ids "" ] ) == 1 <TAB>  id = note [ "" ids "" ] [ 0 ] <TAB>  for ref in reflist : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  ref . delattr ( "" refname "" ) <TAB><TAB>  ref [ "" refid "" ] = id <TAB><TAB>  assert len ( ref [ "" ids "" ] ) == 1 <TAB><TAB>  note . add_backref ( ref [ "" ids "" ] [ 0 ] ) <TAB><TAB>  ref . resolved = 1 <TAB>  note . resolved = 1 ",if ref . resolved :,if ref.id == id:,False,48.73765731080293,96.5655012441341
2357,"def pickPath ( self , color ) : <TAB>  self . path [ color ] = ( ) <TAB>  currentPos = self . starts [ color ] <TAB>  while True : <TAB><TAB>  minDist = None <TAB><TAB>  minGuide = None <TAB><TAB>  for guide in self . guides [ color ] : <TAB><TAB><TAB>  guideDist = dist ( currentPos , guide ) <TAB><TAB><TAB>  if minDist == None or guideDist < minDist : <TAB><TAB><TAB><TAB>  minDist = guideDist <TAB><TAB><TAB><TAB>  minGuide = guide <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  if minGuide == None : <TAB><TAB><TAB>  return <TAB><TAB>  self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB><TAB>  currentPos = minGuide <TAB><TAB>  self . guides [ color ] . remove ( minGuide ) ","if dist ( currentPos , self . ends [ color ] ) == 1 :",if minDist == None or minDist == None:,False,29.739086104801288,93.82556738183628
2358,"def __hierarchyViewKeyPress ( hierarchyView , event ) : <TAB>  if event == __editSourceKeyPress : <TAB><TAB>  selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  __editSourceNode ( <TAB><TAB><TAB><TAB>  hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB><TAB><TAB>  ) <TAB><TAB>  return True <TAB>  elif event == __editTweaksKeyPress : <TAB><TAB>  selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  __editTweaksNode ( <TAB><TAB><TAB><TAB>  hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB><TAB><TAB>  ) <TAB><TAB>  return True ",if selectedPath is not None :,if selectedPath:,False,21.248289619554203,94.31762976535734
2359,"def getSubsegments ( self ) : <TAB>  for num , localdata in self . lfh . LocalData : <TAB><TAB>  for bucket , seginfo in localdata . SegmentInfo : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield Win32Subsegment ( self . trace , self . heap , seginfo . ActiveSubsegment ) ",if seginfo . ActiveSubsegment == 0 :,if seginfo.ActiveSubsegment == bucket:,False,23.74141022199056,97.11715909771402
2360,"def test_full_hd_bluray ( self ) : <TAB>  cur_test = "" full_hd_bluray "" <TAB>  cur_qual = common . Quality . FULLHDBLURAY <TAB>  for name , tests in iteritems ( self . test_cases ) : <TAB><TAB>  for test in tests : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( cur_qual , common . Quality . name_quality ( test ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . assertNotEqual ( cur_qual , common . Quality . name_quality ( test ) ) ",if name == cur_test :,if name == name:,False,51.42332956761948,97.0833235429991
2361,"def calc ( self , arg ) : <TAB>  op = arg [ "" op "" ] <TAB>  if op == "" C "" : <TAB><TAB>  self . clear ( ) <TAB><TAB>  return str ( self . current ) <TAB>  num = decimal . Decimal ( arg [ "" num "" ] ) <TAB>  if self . op : <TAB><TAB>  if self . op == "" + "" : <TAB><TAB><TAB>  self . current + = num <TAB><TAB>  elif self . op == "" - "" : <TAB><TAB><TAB>  self . current - = num <TAB><TAB>  elif self . op == "" * "" : <TAB><TAB><TAB>  self . current * = num <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . current / = num <TAB><TAB>  self . op = op <TAB>  else : <TAB><TAB>  self . op = op <TAB><TAB>  self . current = num <TAB>  res = str ( self . current ) <TAB>  if op == "" = "" : <TAB><TAB>  self . clear ( ) <TAB>  return res ","elif self . op == ""/"" :","if self.op == ""^':",False,18.355635063385296,97.82329640837675
2362,"def strip_export_type ( path ) : <TAB>  matched = re . search ( r "" #([a-zA-Z0-9 \ -]+ \\ +[a-zA-Z0-9 \ -]+)?$ "" , path . encode ( "" utf-8 "" ) ) <TAB>  mime_type = None <TAB>  if matched : <TAB><TAB>  fragment = matched . group ( 0 ) <TAB><TAB>  mime_type = matched . group ( 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mime_type = mime_type . replace ( "" + "" , "" / "" ) <TAB><TAB>  path = path [ : - len ( fragment ) ] <TAB>  return ( path , mime_type ) ",if mime_type is not None :,if fragment:,False,22.549581559383743,93.9677716615871
2363,"def _save_as_module ( file , data , binary = False ) : <TAB>  if not data : <TAB><TAB>  return <TAB>  with open ( file , "" w "" ) as f : <TAB><TAB>  f . write ( "" DATA= "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  f . write ( ' "" ' ) <TAB><TAB><TAB>  f . write ( base64 . b64encode ( data ) . decode ( "" ascii "" ) ) <TAB><TAB><TAB>  f . write ( ' "" ' ) <TAB><TAB>  else : <TAB><TAB><TAB>  f . write ( str ( data ) . replace ( "" \\ \\ "" , "" \\ "" ) ) <TAB><TAB>  f . flush ( ) ",if binary :,if binary:,False,50.757646784354016,100.00000000000004
2364,"def ProcessStringLiteral ( self ) : <TAB>  if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB><TAB>  text = super ( JavaScriptBaseLexer , self ) . text <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if len ( self . _scopeStrictModes ) > 0 : <TAB><TAB><TAB><TAB>  self . _scopeStrictModes . pop ( ) <TAB><TAB><TAB>  self . _useStrictCurrent = True <TAB><TAB><TAB>  self . _scopeStrictModes . append ( self . _useStrictCurrent ) ","if text == '""use strict""' or text == ""'use strict'"" :",if text == self.EOF:,False,30.854570666421647,89.13434005734041
2365,"def run ( self , ttl = None ) : <TAB>  self . zeroconf = zeroconf . Zeroconf ( ) <TAB>  zeroconf . ServiceBrowser ( self . zeroconf , self . domain , MDNSHandler ( self ) ) <TAB>  if ttl : <TAB><TAB>  gobject . timeout_add ( ttl * 1000 , self . shutdown ) <TAB>  self . __running = True <TAB>  self . __mainloop = gobject . MainLoop ( ) <TAB>  context = self . __mainloop . get_context ( ) <TAB>  while self . __running : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  context . iteration ( True ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  time . sleep ( 0.1 ) <TAB><TAB>  except KeyboardInterrupt : <TAB><TAB><TAB>  break <TAB>  self . zeroconf . close ( ) <TAB>  logger . debug ( "" MDNSListener.run() quit "" ) ",if context . pending ( ) :,if context:,False,24.168134551906036,97.62719961398041
2366,"def topology_change_notify ( self , port_state ) : <TAB>  notice = False <TAB>  if port_state is PORT_STATE_FORWARD : <TAB><TAB>  for port in self . ports . values ( ) : <TAB><TAB><TAB>  if port . role is DESIGNATED_PORT : <TAB><TAB><TAB><TAB>  notice = True <TAB><TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  notice = True <TAB>  if notice : <TAB><TAB>  self . send_event ( EventTopologyChange ( self . dp ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _transmit_tc_bpdu ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _transmit_tcn_bpdu ( ) ",if self . is_root_bridge :,if port_state is PORT_STATE_FORWARD:,False,49.92332313343728,95.04982909749963
2367,def close_open_fds ( keep = None ) :<TAB># noqa <TAB>  keep = [ maybe_fileno ( f ) for f in ( keep or [ ] ) if maybe_fileno ( f ) is not None ] <TAB>  for fd in reversed ( range ( get_fdmax ( default = 2048 ) ) ) : <TAB><TAB>  if fd not in keep : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  os . close ( fd ) <TAB><TAB><TAB>  except OSError as exc : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise ,if exc . errno != errno . EBADF :,if exc.errno != errno.ENOTDIR:,False,40.43020674898918,95.64537708677315
2368,"def collect_attributes ( options , node , master_list ) : <TAB>  """"""Collect all attributes"""""" <TAB>  for ii in node . instructions : <TAB><TAB>  if field_check ( ii , "" attributes "" ) : <TAB><TAB><TAB>  s = getattr ( ii , "" attributes "" ) <TAB><TAB><TAB>  if isinstance ( s , list ) : <TAB><TAB><TAB><TAB>  for x in s : <TAB><TAB><TAB><TAB><TAB>  if x not in master_list : <TAB><TAB><TAB><TAB><TAB><TAB>  master_list . append ( x ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  master_list . append ( s ) <TAB>  for nxt in node . next . values ( ) : <TAB><TAB>  collect_attributes ( options , nxt , master_list ) ",elif s != None and s not in master_list :,"if isinstance(s, tuple):",False,49.9783088571096,94.1865291513188
2369,"def remove_test_run_directories ( expiry_time : int = 60 * 60 ) - > int : <TAB>  removed = 0 <TAB>  directories = glob . glob ( os . path . join ( UUID_VAR_DIR , "" test-backend "" , "" run_* "" ) ) <TAB>  for test_run in directories : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  shutil . rmtree ( test_run ) <TAB><TAB><TAB><TAB>  removed + = 1 <TAB><TAB><TAB>  except FileNotFoundError : <TAB><TAB><TAB><TAB>  pass <TAB>  return removed ",if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,if expiry_time <= time:,False,47.86540341086046,87.21490541084867
2370,"def read_work_titles ( fields ) : <TAB>  found = [ ] <TAB>  if "" 240 "" in fields : <TAB><TAB>  for line in fields [ "" 240 "" ] : <TAB><TAB><TAB>  title = join_subfield_values ( line , [ "" a "" , "" m "" , "" n "" , "" p "" , "" r "" ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  found . append ( title ) <TAB>  if "" 130 "" in fields : <TAB><TAB>  for line in fields [ "" 130 "" ] : <TAB><TAB><TAB>  title = "" "" . join ( get_lower_subfields ( line ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  found . append ( title ) <TAB>  return { "" work_titles "" : found } if found else { } ",if title not in found :,if title not in found:,False,40.2689698006299,97.00942318876997
2371,"def _process_v1_msg ( prot , msg ) : <TAB>  header = None <TAB>  body = msg [ 1 ] <TAB>  if not isinstance ( body , ( binary_type , mmap , memoryview ) ) : <TAB><TAB>  raise ValidationError ( body , "" Body must be a bytestream. "" ) <TAB>  if len ( msg ) > 2 : <TAB><TAB>  header = msg [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationError ( header , "" Header must be a dict. "" ) <TAB><TAB>  for k , v in header . items ( ) : <TAB><TAB><TAB>  header [ k ] = msgpack . unpackb ( v ) <TAB>  ctx = MessagePackMethodContext ( prot , MessagePackMethodContext . SERVER ) <TAB>  ctx . in_string = [ body ] <TAB>  ctx . transport . in_header = header <TAB>  return ctx ","if not isinstance ( header , dict ) :","if not isinstance(header, dict):",False,51.75670562425134,100.00000000000004
2372,"def find ( self , node ) : <TAB>  typename = type ( node ) . __name__ <TAB>  method = getattr ( self , "" find_ {} "" . format ( typename ) , None ) <TAB>  if method is None : <TAB><TAB>  fields = getattr ( node , "" _fields "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  for field in fields : <TAB><TAB><TAB>  value = getattr ( node , field ) <TAB><TAB><TAB>  for result in self . find ( value ) : <TAB><TAB><TAB><TAB>  yield result <TAB>  else : <TAB><TAB>  for result in method ( node ) : <TAB><TAB><TAB>  yield result ",if fields is None :,if fields is None:,False,51.050064599322354,100.00000000000004
2373,"def _str_param_list ( self , name ) : <TAB>  out = [ ] <TAB>  if self [ name ] : <TAB><TAB>  out + = self . _str_header ( name ) <TAB><TAB>  for param in self [ name ] : <TAB><TAB><TAB>  parts = [ ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  parts . append ( param . name ) <TAB><TAB><TAB>  if param . type : <TAB><TAB><TAB><TAB>  parts . append ( param . type ) <TAB><TAB><TAB>  out + = [ ""  :  "" . join ( parts ) ] <TAB><TAB><TAB>  if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB><TAB><TAB><TAB>  out + = self . _str_indent ( param . desc ) <TAB><TAB>  out + = [ "" "" ] <TAB>  return out ",if param . name :,if param.name:,False,33.953727366490796,100.00000000000004
2374,"def _get_image ( self , image_list , source ) : <TAB>  if source . startswith ( "" wx "" ) : <TAB><TAB>  img = wx . ArtProvider_GetBitmap ( source , wx . ART_OTHER , _SIZE ) <TAB>  else : <TAB><TAB>  path = os . path . join ( _BASE , source ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  img = wx . Image ( path , wx . BITMAP_TYPE_GIF ) . ConvertToBitmap ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  img = wx . Image ( path , wx . BITMAP_TYPE_PNG ) . ConvertToBitmap ( ) <TAB>  return image_list . Add ( img ) ","if source . endswith ( ""gif"" ) :",if os.path.isfile(path):,False,27.98091936210419,95.26640755626636
2375,"def change_opacity_function ( self , new_f ) : <TAB>  self . opacity_function = new_f <TAB>  dr = self . radius / self . num_levels <TAB>  sectors = [ ] <TAB>  for submob in self . submobjects : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sectors . append ( submob ) <TAB>  for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB><TAB>  if type ( submob ) != AnnularSector : <TAB><TAB><TAB>  # it's the shadow, don't dim it <TAB><TAB><TAB>  continue <TAB><TAB>  alpha = self . opacity_function ( r ) <TAB><TAB>  submob . set_fill ( opacity = alpha ) ",if type ( submob ) == AnnularSector :,if submob.type == AnnularSector:,False,53.08870734853822,97.32512415145347
2376,"def _sqlite_post_configure_engine ( url , engine , follower_ident ) : <TAB>  from sqlalchemy import event <TAB>  @event . listens_for ( engine , "" connect "" ) <TAB>  def connect ( dbapi_connection , connection_record ) : <TAB><TAB>  # use file DBs in all cases, memory acts kind of strangely <TAB><TAB>  # as an attached <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dbapi_connection . execute ( ' ATTACH DATABASE  "" test_schema.db ""  AS test_schema ' ) <TAB><TAB>  else : <TAB><TAB><TAB>  dbapi_connection . execute ( <TAB><TAB><TAB><TAB>  ' ATTACH DATABASE  "" %s _test_schema.db ""  AS test_schema ' % follower_ident <TAB><TAB><TAB>  ) ",if not follower_ident :,if follower_ident == None:,False,53.76515474923078,89.73493465947759
2377,"def apply_conf_file ( fn , conf_filename ) : <TAB>  for env in LSF_CONF_ENV : <TAB><TAB>  conf_file = get_conf_file ( conf_filename , env ) <TAB><TAB>  if conf_file : <TAB><TAB><TAB>  with open ( conf_file ) as conf_handle : <TAB><TAB><TAB><TAB>  value = fn ( conf_handle ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return value <TAB>  return None ",if value :,if value is not None:,False,21.02386778010758,96.59246927162941
2378,"def test_call_extern_c_fn ( self ) : <TAB>  global memcmp <TAB>  memcmp = cffi_support . ExternCFunction ( <TAB><TAB>  "" memcmp "" , <TAB><TAB>  ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB>  ) <TAB>  @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB>  def fn ( context , a , b ) : <TAB><TAB>  if a . is_null != b . is_null : <TAB><TAB><TAB>  return False <TAB><TAB>  if a is None : <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  if a . ptr == b . ptr : <TAB><TAB><TAB>  return True <TAB><TAB>  return memcmp ( a . ptr , b . ptr , a . len ) == 0 ",if len ( a ) != b . len :,if a.is_null != b.is_null:,False,54.45675258137612,95.51881236612974
2379,"def _get_initialized_app ( app ) : <TAB>  """"""Returns a reference to an initialized App instance."""""" <TAB>  if app is None : <TAB><TAB>  return firebase_admin . get_app ( ) <TAB>  if isinstance ( app , firebase_admin . App ) : <TAB><TAB>  initialized_app = firebase_admin . get_app ( app . name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Illegal app argument. App instance not  "" <TAB><TAB><TAB><TAB>  "" initialized via the firebase module. "" <TAB><TAB><TAB>  ) <TAB><TAB>  return app <TAB>  raise ValueError ( <TAB><TAB>  "" Illegal app argument. Argument must be of type  "" <TAB><TAB>  '  firebase_admin.App, but given  "" {0} "" . ' . format ( type ( app ) ) <TAB>  ) ",if app is not initialized_app :,if initialized_app is None:,False,60.90772798253088,97.60289742646185
2380,def compiled_query ( self ) : <TAB>  <IF-STMT>: <TAB><TAB>  self . lazy_init_lock_ . acquire ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . compiled_query_ = CompiledQuery ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . lazy_init_lock_ . release ( ) <TAB>  return self . compiled_query_ ,if self . compiled_query_ is None :,if not self.compiled_query_:,False,34.58375258205626,87.4984606845517
2381,"def clean_subevent ( event , subevent ) : <TAB>  if event . has_subevents : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationError ( _ ( "" Subevent cannot be null for event series. "" ) ) <TAB><TAB>  if event != subevent . event : <TAB><TAB><TAB>  raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) ) <TAB>  else : <TAB><TAB>  if subevent : <TAB><TAB><TAB>  raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) ) ",if not subevent :,if not subevent:,False,39.577608602904846,100.00000000000004
2382,"def get_blob_type_declaration_sql ( self , column ) : <TAB>  length = column . get ( "" length "" ) <TAB>  if length : <TAB><TAB>  if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB><TAB><TAB>  return "" TINYBLOB "" <TAB><TAB>  if length < = self . LENGTH_LIMIT_BLOB : <TAB><TAB><TAB>  return "" BLOB "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" MEDIUMBLOB "" <TAB>  return "" LONGBLOB "" ",if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,if length <= self.LENGTH_LIMIT_MEDIUM:,False,20.786891504192514,98.11648427881292
2383,"def decompress ( self , data ) : <TAB>  if not data : <TAB><TAB>  return data <TAB>  if not self . _first_try : <TAB><TAB>  return self . _obj . decompress ( data ) <TAB>  self . _data + = data <TAB>  try : <TAB><TAB>  decompressed = self . _obj . decompress ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _first_try = False <TAB><TAB><TAB>  self . _data = None <TAB><TAB>  return decompressed <TAB>  except zlib . error : <TAB><TAB>  self . _first_try = False <TAB><TAB>  self . _obj = zlib . decompressobj ( - zlib . MAX_WBITS ) <TAB><TAB>  try : <TAB><TAB><TAB>  return self . decompress ( self . _data ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . _data = None ",if decompressed :,if decompressed is None:,False,21.619579448740804,96.89935718551868
2384,"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB>  with self . lock : <TAB><TAB>  self . events [ path ] . append ( events ) <TAB><TAB>  if events | pyuv . fs . UV_RENAME : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . watches . pop ( path ) . close ( ) ",if not os . path . exists ( path ) :,if path in self.watchers:,False,21.517430720707022,90.46721705913205
2385,"def __init__ ( self , duration , batch_shape , event_shape , validate_args = None ) : <TAB>  if duration is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Infer duration from event_shape. <TAB><TAB><TAB>  duration = event_shape [ 0 ] <TAB>  elif duration != event_shape [ 0 ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" duration, event_shape mismatch:  {}  vs  {} "" . format ( duration , event_shape ) <TAB><TAB><TAB>  ) <TAB><TAB>  # Infer event_shape from duration. <TAB><TAB>  event_shape = torch . Size ( ( duration , ) + event_shape [ 1 : ] ) <TAB>  self . _duration = duration <TAB>  super ( ) . __init__ ( batch_shape , event_shape , validate_args ) ",if event_shape [ 0 ] != 1 :,if duration is None:,False,48.51952067429504,90.96224256329977
2386,"def _CheckPrerequisites ( self ) : <TAB>  """"""Exits if any of the prerequisites is not met."""""" <TAB>  if not FLAGS . kubectl : <TAB><TAB>  raise Exception ( <TAB><TAB><TAB>  "" Please provide path to kubectl tool using --kubectl  "" "" flag. Exiting. "" <TAB><TAB>  ) <TAB>  if not FLAGS . kubeconfig : <TAB><TAB>  raise Exception ( <TAB><TAB><TAB>  "" Please provide path to kubeconfig using --kubeconfig  "" "" flag. Exiting. "" <TAB><TAB>  ) <TAB>  if self . disk_specs and self . disk_specs [ 0 ] . disk_type == disk . STANDARD : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Please provide a list of Ceph Monitors using  "" "" --ceph_monitors flag. "" <TAB><TAB><TAB>  ) ",if not FLAGS . ceph_monitors :,if not self.ceph_monitors:,False,67.91594382949107,98.84118727773192
2387,"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB>  # only user defined curve can have slice dependency relationships <TAB>  if self . isSystemCurveIndex ( iFirstCurve ) : <TAB><TAB>  return <TAB>  nCurves = self . getNCurves ( ) <TAB>  for i in range ( iFirstCurve , nCurves ) : <TAB><TAB>  c = self . getSystemCurve ( i ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  c . invalidate ( ) <TAB><TAB>  elif i == iFirstCurve : <TAB><TAB><TAB>  # if first curve isn't a slice, <TAB><TAB><TAB>  break <TAB><TAB><TAB>  # there are no dependent slices ","if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",if c is not None:,False,39.602939781995744,89.4385882369473
2388,"def find_backwards ( self , offset ) : <TAB>  try : <TAB><TAB>  for _ , token_type , token_value in reversed ( self . tokens [ self . offset : offset ] ) : <TAB><TAB><TAB>  if token_type in ( "" comment "" , "" linecomment "" ) : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  prefix , comment = token_value . split ( None , 1 ) <TAB><TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return [ comment . rstrip ( ) ] <TAB><TAB>  return [ ] <TAB>  finally : <TAB><TAB>  self . offset = offset ",if prefix in self . comment_tags :,if prefix == self.offset:,False,47.97784768437708,96.80145102639113
2389,"def parse_column_definitions ( self , elem ) : <TAB>  for column_elem in elem . findall ( "" column "" ) : <TAB><TAB>  name = column_elem . get ( "" name "" , None ) <TAB><TAB>  assert name is not None , "" Required  ' name '  attribute missing from column def "" <TAB><TAB>  index = column_elem . get ( "" index "" , None ) <TAB><TAB>  assert index is not None , "" Required  ' index '  attribute missing from column def "" <TAB><TAB>  index = int ( index ) <TAB><TAB>  self . columns [ name ] = index <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . largest_index = index <TAB>  assert "" value "" in self . columns , "" Required  ' value '  column missing from column def "" <TAB>  if "" name "" not in self . columns : <TAB><TAB>  self . columns [ "" name "" ] = self . columns [ "" value "" ] ",if index > self . largest_index :,if index > self.largest_index:,False,53.007329472122734,94.09858606482389
2390,"def __find_smallest ( self ) : <TAB>  """"""Find the smallest uncovered value in the matrix."""""" <TAB>  minval = sys . maxsize <TAB>  for i in range ( self . n ) : <TAB><TAB>  for j in range ( self . n ) : <TAB><TAB><TAB>  if ( not self . row_covered [ i ] ) and ( not self . col_covered [ j ] ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  minval = self . C [ i ] [ j ] <TAB>  return minval ",if minval > self . C [ i ] [ j ] :,if self.C[i][j] < minval:,False,55.9162059974206,96.8782069679965
2391,"def includes_tools_for_display_in_tool_panel ( self ) : <TAB>  if self . includes_tools : <TAB><TAB>  tool_dicts = self . metadata [ "" tools "" ] <TAB><TAB>  for tool_dict in tool_dicts : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if tool_dict . get ( ""add_to_tool_panel"" , True ) :",if tool_dict['display_in_tool_panel']:,False,47.86701270459785,86.14520289043753
2392,"def commit ( self , notify = False ) : <TAB>  if self . editing : <TAB><TAB>  text = self . _text <TAB><TAB>  if text : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  value = self . type ( text ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  value = self . clamp_value ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  value = self . empty <TAB><TAB><TAB>  if value is NotImplemented : <TAB><TAB><TAB><TAB>  return <TAB><TAB>  self . value = value <TAB><TAB>  self . insertion_point = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . change_text ( unicode ( value ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _text = unicode ( value ) <TAB><TAB>  self . editing = False <TAB>  else : <TAB><TAB>  self . insertion_point = None ",if notify :,if notify:,False,50.874424761614335,100.00000000000004
2393,"def GeneratePageMetatadata ( self , task ) : <TAB>  address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB>  for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB><TAB>  start = vma . vm_start <TAB><TAB>  end = vma . vm_end <TAB><TAB>  # Skip the entire region. <TAB><TAB>  if end < self . plugin_args . start : <TAB><TAB><TAB>  continue <TAB><TAB>  # Done. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB><TAB><TAB>  if self . plugin_args . start < = vaddr < = self . plugin_args . end : <TAB><TAB><TAB><TAB>  yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) ) ",if start > self . plugin_args . end :,if start == end:,False,51.66189404744282,96.33138609593813
2394,"def _check_for_duplicate_host_entries ( self , task_entries ) : <TAB>  non_host_statuses = ( <TAB><TAB>  models . HostQueueEntry . Status . PARSING , <TAB><TAB>  models . HostQueueEntry . Status . ARCHIVING , <TAB>  ) <TAB>  for task_entry in task_entries : <TAB><TAB>  using_host = ( <TAB><TAB><TAB>  task_entry . host is not None and task_entry . status not in non_host_statuses <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _assert_host_has_no_agent ( task_entry ) ",if using_host :,if using_host:,False,56.31043720905326,100.00000000000004
2395,"def get_biggest_wall_time ( jsons ) : <TAB>  lowest_wall = None <TAB>  for j in jsons : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lowest_wall = j [ "" wall_time "" ] <TAB><TAB>  if lowest_wall < j [ "" wall_time "" ] : <TAB><TAB><TAB>  lowest_wall = j [ "" wall_time "" ] <TAB>  return lowest_wall ",if lowest_wall is None :,if lowest_wall is None:,False,51.58618068175227,100.00000000000004
2396,"def log_change_report ( self , old_value , new_value , include_details = False ) : <TAB>  from octoprint . util import map_boolean <TAB>  with self . _check_mutex : <TAB><TAB>  self . _logger . info ( <TAB><TAB><TAB>  "" Connectivity changed from  {}  to  {} "" . format ( <TAB><TAB><TAB><TAB>  map_boolean ( old_value , "" online "" , "" offline "" ) , <TAB><TAB><TAB><TAB>  map_boolean ( new_value , "" online "" , "" offline "" ) , <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log_details ( ) ",if include_details :,if include_details:,False,54.79943478618199,100.00000000000004
2397,"def _include_block ( self , value , context = None ) : <TAB>  if hasattr ( value , "" render_as_block "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_context = context . get_all ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  new_context = { } <TAB><TAB>  return jinja2 . Markup ( value . render_as_block ( context = new_context ) ) <TAB>  return jinja2 . Markup ( value ) ",if context :,if context:,False,50.68297886559932,100.00000000000004
2398,"def __lt__ ( self , other ) : <TAB>  # 0: clock 1: timestamp 3: process id <TAB>  try : <TAB><TAB>  A , B = self [ 0 ] , other [ 0 ] <TAB><TAB>  # uses logical clock value first <TAB><TAB>  if A and B :<TAB># use logical clock if available <TAB><TAB><TAB>  <IF-STMT>:<TAB># equal clocks use lower process id <TAB><TAB><TAB><TAB>  return self [ 2 ] < other [ 2 ] <TAB><TAB><TAB>  return A < B <TAB><TAB>  return self [ 1 ] < other [ 1 ]<TAB># ... or use timestamp <TAB>  except IndexError : <TAB><TAB>  return NotImplemented ",if A == B :,if A and B:,False,36.54981323398785,91.18038117227381
2399,"def _get_port ( ) : <TAB>  while True : <TAB><TAB>  port = 20000 + random . randint ( 1 , 9999 ) <TAB><TAB>  for i in range ( 5 ) : <TAB><TAB><TAB>  sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <TAB><TAB><TAB>  result = sock . connect_ex ( ( "" 127.0.0.1 "" , port ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  else : <TAB><TAB><TAB>  return port ",if result == 0 :,if result == 0:,False,52.46636766351861,100.00000000000004
2400,"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB>  self . fetchstatuslogger = fetchstatuslogger <TAB>  if targets != None : <TAB><TAB>  # Ensure targets is a tuple <TAB><TAB>  if type ( targets ) != list and type ( targets ) != tuple : <TAB><TAB><TAB>  targets = tuple ( <TAB><TAB><TAB><TAB>  targets , <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  targets = tuple ( targets ) <TAB>  for target in targets : <TAB><TAB>  self . _fetch_targets ( api_client , q , target ) ",elif type ( targets ) != tuple :,"if isinstance(targets, tuple):",False,54.71219843936805,94.96313716417166
2401,"def migrate_node_facts ( facts ) : <TAB>  """"""Migrate facts from various roles into node"""""" <TAB>  params = { <TAB><TAB>  "" common "" : ( "" dns_ip "" ) , <TAB>  } <TAB>  if "" node "" not in facts : <TAB><TAB>  facts [ "" node "" ] = { } <TAB>  # pylint: disable=consider-iterating-dictionary <TAB>  for role in params . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for param in params [ role ] : <TAB><TAB><TAB><TAB>  if param in facts [ role ] : <TAB><TAB><TAB><TAB><TAB>  facts [ "" node "" ] [ param ] = facts [ role ] . pop ( param ) <TAB>  return facts ",if role in facts :,if role in params:,False,50.74944112312358,98.654004325263
2402,"def build_dimension_param ( self , dimension , params ) : <TAB>  prefix = "" Dimensions.member "" <TAB>  i = 0 <TAB>  for dim_name in dimension : <TAB><TAB>  dim_value = dimension [ dim_name ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( dim_value , six . string_types ) : <TAB><TAB><TAB><TAB>  dim_value = [ dim_value ] <TAB><TAB><TAB>  for value in dim_value : <TAB><TAB><TAB><TAB>  params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB><TAB><TAB><TAB>  params [ "" %s . %d .Value "" % ( prefix , i + 1 ) ] = value <TAB><TAB><TAB><TAB>  i + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB><TAB><TAB>  i + = 1 ",if dim_value :,"if isinstance(dim_value, list):",False,20.46977351577592,97.03542014574766
2403,"def add_if_unique ( self , issuer , use , keys ) : <TAB>  if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB><TAB>  for typ , key in keys : <TAB><TAB><TAB>  flag = 1 <TAB><TAB><TAB>  for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  flag = 0 <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  if flag : <TAB><TAB><TAB><TAB>  self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB>  else : <TAB><TAB>  self . issuer_keys [ issuer ] [ use ] = keys ",if _typ == typ and key is _key :,if typ == key:,False,46.869909480934524,95.88940330265197
2404,"def run ( self ) : <TAB>  while True : <TAB><TAB>  message = self . in_queue . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . reset ( ) <TAB><TAB>  elif message == EXIT : <TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  index , transaction = message <TAB><TAB><TAB>  self . results_queue . put ( ( index , self . validate ( transaction ) ) ) ",if message == RESET :,if message == START:,False,51.62812484600159,97.99565852526808
2405,"def __run ( self ) : <TAB>  threads = self . parameters ( ) [ "" threads "" ] . getTypedValue ( ) <TAB>  with IECore . tbb_global_control ( <TAB><TAB>  IECore . tbb_global_control . parameter . max_allowed_parallelism , <TAB><TAB>  IECore . hardwareConcurrency ( ) if threads == 0 else threads , <TAB>  ) : <TAB><TAB>  self . _executeStartupFiles ( self . root ( ) . getName ( ) ) <TAB><TAB>  # Append DEBUG message with process information to all messages <TAB><TAB>  defaultMessageHandler = IECore . MessageHandler . getDefaultHandler ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  IECore . MessageHandler . setDefaultHandler ( <TAB><TAB><TAB><TAB>  Gaffer . ProcessMessageHandler ( defaultMessageHandler ) <TAB><TAB><TAB>  ) <TAB><TAB>  return self . _run ( self . parameters ( ) . getValidatedValue ( ) ) ","if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :",if defaultMessageHandler is not None:,False,62.07619947971183,95.38369787498692
2406,"def adjust_uri ( self , uri , relativeto ) : <TAB>  """"""Adjust the given ``uri`` based on the given relative URI."""""" <TAB>  key = ( uri , relativeto ) <TAB>  if key in self . _uri_cache : <TAB><TAB>  return self . _uri_cache [ key ] <TAB>  if uri [ 0 ] != "" / "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = self . _uri_cache [ key ] = posixpath . join ( <TAB><TAB><TAB><TAB>  posixpath . dirname ( relativeto ) , uri <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  v = self . _uri_cache [ key ] = "" / "" + uri <TAB>  else : <TAB><TAB>  v = self . _uri_cache [ key ] = uri <TAB>  return v ",if relativeto is not None :,if uri[0] == '/':,False,54.82520947746033,95.2768014168364
2407,"def decoder ( s ) : <TAB>  r = [ ] <TAB>  decode = [ ] <TAB>  for c in s : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  decode . append ( "" & "" ) <TAB><TAB>  elif c == "" - "" and decode : <TAB><TAB><TAB>  if len ( decode ) == 1 : <TAB><TAB><TAB><TAB>  r . append ( "" & "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB><TAB><TAB>  decode = [ ] <TAB><TAB>  elif decode : <TAB><TAB><TAB>  decode . append ( c ) <TAB><TAB>  else : <TAB><TAB><TAB>  r . append ( c ) <TAB>  if decode : <TAB><TAB>  r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB>  bin_str = "" "" . join ( r ) <TAB>  return ( bin_str , len ( s ) ) ","if c == ""&"" and not decode :","if c == ""0"" and decode:",False,49.666664319682006,98.29661312665631
2408,"def _process_file ( self , content ) : <TAB>  args = [ ] <TAB>  for line in content . splitlines ( ) : <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  if line . startswith ( "" - "" ) : <TAB><TAB><TAB>  args . extend ( self . _split_option ( line ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args . append ( line ) <TAB>  return args ","elif line and not line . startswith ( ""#"" ) :",if line:,False,23.64230714638978,88.65099988221827
2409,"def _method_events_callback ( self , values ) : <TAB>  try : <TAB><TAB>  previous_echoed = ( <TAB><TAB><TAB>  values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB><TAB>  ) <TAB><TAB>  if previous_echoed . endswith ( "" foo1 "" ) : <TAB><TAB><TAB>  return "" echo foo2 \n "" <TAB><TAB>  elif previous_echoed . endswith ( "" foo2 "" ) : <TAB><TAB><TAB>  return "" echo foo3 \n "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" exit \n "" <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB>  except IndexError : <TAB><TAB>  return "" echo foo1 \n "" ","elif previous_echoed . endswith ( ""foo3"" ) :",if previous_echoed.endswith('foo3'):,False,50.443713446515105,94.80931656539516
2410,"def __delete_hook ( self , rpc ) : <TAB>  try : <TAB><TAB>  rpc . check_success ( ) <TAB>  except apiproxy_errors . Error : <TAB><TAB>  return None <TAB>  result = [ ] <TAB>  for status in rpc . response . delete_status_list ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( DELETE_SUCCESSFUL ) <TAB><TAB>  elif status == MemcacheDeleteResponse . NOT_FOUND : <TAB><TAB><TAB>  result . append ( DELETE_ITEM_MISSING ) <TAB><TAB>  else : <TAB><TAB><TAB>  result . append ( DELETE_NETWORK_FAILURE ) <TAB>  return result ",if status == MemcacheDeleteResponse . DELETED :,if status == MemcacheDeleteResponse.SUCCESS:,False,51.462112563879934,98.51838417929301
2411,"def __createRandom ( plug ) : <TAB>  node = plug . node ( ) <TAB>  parentNode = node . ancestor ( Gaffer . Node ) <TAB>  with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB><TAB>  randomNode = Gaffer . Random ( ) <TAB><TAB>  parentNode . addChild ( randomNode ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB><TAB>  elif isinstance ( plug , Gaffer . Color3fPlug ) : <TAB><TAB><TAB>  plug . setInput ( randomNode [ "" outColor "" ] ) <TAB>  GafferUI . NodeEditor . acquire ( randomNode ) ","if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) :","if isinstance(plug, Gaffer.Float3fPlug):",False,21.314319196840696,94.11217014398353
2412,"def escapeentities ( self , line ) : <TAB>  "" Escape all Unicode characters to HTML entities. "" <TAB>  result = "" "" <TAB>  pos = TextPosition ( line ) <TAB>  while not pos . finished ( ) : <TAB><TAB>  if ord ( pos . current ( ) ) > 128 : <TAB><TAB><TAB>  codepoint = hex ( ord ( pos . current ( ) ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  codepoint = hex ( ord ( pos . next ( ) ) + 0xF800 ) <TAB><TAB><TAB>  result + = "" &# "" + codepoint [ 1 : ] + "" ; "" <TAB><TAB>  else : <TAB><TAB><TAB>  result + = pos . current ( ) <TAB><TAB>  pos . skipcurrent ( ) <TAB>  return result ","if codepoint == ""0xd835"" :",if ord(pos.current()) < 128:,False,23.4868993810685,94.28772490068283
2413,def get_and_set_all_aliases ( self ) : <TAB>  all_aliases = [ ] <TAB>  for page in self . pages : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  all_aliases . extend ( page . relations . aliases_norm ) <TAB><TAB>  if page . relations . aliases is not None : <TAB><TAB><TAB>  all_aliases . extend ( page . relations . aliases ) <TAB>  return set ( all_aliases ) ,if page . relations . aliases_norm is not None :,if page.relations.aliases_norm is not None:,False,53.172434934431415,100.00000000000004
2414,"def _list_cases ( suite ) : <TAB>  for test in suite : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _list_cases ( test ) <TAB><TAB>  elif isinstance ( test , unittest . TestCase ) : <TAB><TAB><TAB>  if support . match_test ( test ) : <TAB><TAB><TAB><TAB>  print ( test . id ( ) ) ","if isinstance ( test , unittest . TestSuite ) :","if isinstance(test, unittest.TestCase):",False,26.73826509738507,97.54238144468995
2415,"def get_next_requests ( self , max_n_requests , * * kwargs ) : <TAB>  next_pages = [ ] <TAB>  partitions = set ( kwargs . pop ( "" partitions "" , [ ] ) ) <TAB>  for partition_id in range ( 0 , self . queue_partitions ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  results = self . queue . get_next_requests ( max_n_requests , partition_id ) <TAB><TAB>  next_pages . extend ( results ) <TAB><TAB>  self . logger . debug ( <TAB><TAB><TAB>  "" Got  %d  requests for partition id  %d "" , len ( results ) , partition_id <TAB><TAB>  ) <TAB>  return next_pages ",if partition_id not in partitions :,if partition_id in partitions:,False,53.92356702215508,98.65686116189279
2416,"def __iter__ ( self ) : <TAB>  if ( self . query is not None ) and sqlite . is_read_only_query ( self . query ) : <TAB><TAB>  cur = self . connection . cursor ( ) <TAB><TAB>  results = cur . execute ( self . query ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield [ col [ 0 ] for col in cur . description ] <TAB><TAB>  for i , row in enumerate ( results ) : <TAB><TAB><TAB>  if i > = self . limit : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  yield [ val for val in row ] <TAB>  else : <TAB><TAB>  yield ",if self . headers :,if results:,False,22.93365342349546,97.4327919093489
2417,"def rollback ( self ) : <TAB>  for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB><TAB>  if operation == "" insert "" : <TAB><TAB><TAB>  values . remove ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  old_value , new_value = values <TAB><TAB><TAB>  if new_value . full_filename != old_value . full_filename : <TAB><TAB><TAB><TAB>  os . unlink ( new_value . full_filename ) <TAB><TAB><TAB>  old_value . write ( ) <TAB>  self . _post_xact_cleanup ( ) ","elif operation == ""update"" :",if values:,False,25.258717056061663,93.32681622129198
2418,"def index ( self , value ) : <TAB>  if self . _growing : <TAB><TAB>  if self . _start < = value < self . _stop : <TAB><TAB><TAB>  q , r = divmod ( value - self . _start , self . _step ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return int ( q ) <TAB>  else : <TAB><TAB>  if self . _start > = value > self . _stop : <TAB><TAB><TAB>  q , r = divmod ( self . _start - value , - self . _step ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return int ( q ) <TAB>  raise ValueError ( "" {}  is not in numeric range "" . format ( value ) ) ",if r == self . _zero :,if r:,False,20.908976946299372,90.76758316420731
2419,"def validate_name_and_description ( body , check_length = True ) : <TAB>  for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB><TAB>  value = body . get ( attribute ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( value , six . string_types ) : <TAB><TAB><TAB><TAB>  body [ attribute ] = value . strip ( ) <TAB><TAB><TAB>  if check_length : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  utils . check_string_length ( <TAB><TAB><TAB><TAB><TAB><TAB>  body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  except exception . InvalidInput as error : <TAB><TAB><TAB><TAB><TAB>  raise webob . exc . HTTPBadRequest ( explanation = error . msg ) ",if value is not None :,if value is not None:,False,51.73773093965948,100.00000000000004
2420,"def printWiki ( ) : <TAB>  firstHeading = False <TAB>  for m in protocol : <TAB><TAB>  if m [ 0 ] == "" "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  output ( "" |} "" ) <TAB><TAB><TAB>  __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB><TAB><TAB>  firstHeading = True <TAB><TAB>  else : <TAB><TAB><TAB>  output ( "" |- "" ) <TAB><TAB><TAB>  output ( <TAB><TAB><TAB><TAB>  ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB><TAB><TAB><TAB>  + m [ 0 ] <TAB><TAB><TAB><TAB>  + "" </tt></span> || ||  "" <TAB><TAB><TAB><TAB>  + m [ 1 ] <TAB><TAB><TAB>  ) <TAB>  output ( "" |} "" ) ",if firstHeading :,if firstHeading:,False,51.023477720357214,100.00000000000004
2421,"def _get_platforms ( data ) : <TAB>  platform_list = [ ] <TAB>  for item in data : <TAB><TAB>  if item . startswith ( "" PlatformEdit.html? "" ) : <TAB><TAB><TAB>  parameter_list = item . split ( "" PlatformEdit.html? "" , 1 ) [ 1 ] . split ( "" & "" ) <TAB><TAB><TAB>  for parameter in parameter_list : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  platform_list . append ( parameter . split ( "" = "" ) [ 1 ] ) <TAB>  return platform_list ","if parameter . startswith ( ""platformName"" ) :",if parameter.startswith('PlatformEdit.html'):,False,51.3971465718407,97.13492876971749
2422,"def find_scintilla_constants ( f ) : <TAB>  lexers = [ ] <TAB>  states = [ ] <TAB>  for name in f . order : <TAB><TAB>  v = f . features [ name ] <TAB><TAB>  if v [ "" Category "" ] != "" Deprecated "" : <TAB><TAB><TAB>  if v [ "" FeatureType "" ] == "" val "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  states . append ( ( name , v [ "" Value "" ] ) ) <TAB><TAB><TAB><TAB>  elif name . startswith ( "" SCLEX_ "" ) : <TAB><TAB><TAB><TAB><TAB>  lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB>  return ( lexers , states ) ","if name . startswith ( ""SCE_"" ) :",if name.startswith('SCintilla_':,False,47.087570997093145,96.90907884072388
2423,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB>  operation = None <TAB>  for definition in document_ast . definitions : <TAB><TAB>  if isinstance ( definition , ast . OperationDefinition ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB>  # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB>  # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB>  if operation : <TAB><TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB><TAB>  operation = definition <TAB><TAB><TAB>  elif definition . name and definition . name . value == operation_name : <TAB><TAB><TAB><TAB>  return definition <TAB>  return operation ",if not operation_name :,if not operation_name:,False,75.39697774798823,100.00000000000004
2424,"def _insertNewItemAtParent ( self , targetIndex ) : <TAB>  if not self . isContainer ( targetIndex ) : <TAB><TAB>  return <TAB>  elif not self . isContainerOpen ( targetIndex ) : <TAB><TAB>  uri = self . _rows [ targetIndex ] . uri <TAB><TAB>  modelNode = self . getNodeForURI ( uri ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  modelNode . markForRefreshing ( ) <TAB><TAB>  return <TAB>  self . refreshView ( targetIndex ) ",if modelNode :,if modelNode:,False,50.82707621648404,100.00000000000004
2425,"def _get_trace ( self , model , guide , args , kwargs ) : <TAB>  model_trace , guide_trace = super ( ) . _get_trace ( model , guide , args , kwargs ) <TAB>  # Mark all sample sites with require_backward to gather enumerated <TAB>  # sites and adjust cond_indep_stack of all sample sites. <TAB>  for node in model_trace . nodes . values ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log_prob = node [ "" packed "" ] [ "" unscaled_log_prob "" ] <TAB><TAB><TAB>  require_backward ( log_prob ) <TAB>  self . _saved_state = model , model_trace , guide_trace , args , kwargs <TAB>  return model_trace , guide_trace ","if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :",if node['packed']['log_prob'] is not None:,False,60.93539863130245,90.38486256973344
2426,"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB>  from . datastructures import iter_multi_items <TAB>  iterable = iter_multi_items ( obj ) <TAB>  if sort : <TAB><TAB>  iterable = sorted ( iterable , key = key ) <TAB>  for key , value in iterable : <TAB><TAB>  if value is None : <TAB><TAB><TAB>  continue <TAB><TAB>  if not isinstance ( key , bytes ) : <TAB><TAB><TAB>  key = text_type ( key ) . encode ( charset ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = text_type ( value ) . encode ( charset ) <TAB><TAB>  yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value ) ","if not isinstance ( value , bytes ) :","if not isinstance(value, unicode):",False,50.83199511293961,98.77892367547223
2427,"def handle_parse_result ( self , ctx , opts , args ) : <TAB>  with augment_usage_errors ( ctx , param = self ) : <TAB><TAB>  value = self . consume_value ( ctx , opts ) <TAB><TAB>  try : <TAB><TAB><TAB>  value = self . full_process_value ( ctx , value ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  value = None <TAB><TAB>  if self . callback is not None : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  value = invoke_param_callback ( self . callback , ctx , self , value ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise <TAB>  if self . expose_value : <TAB><TAB>  ctx . params [ self . name ] = value <TAB>  return value , args ",if not ctx . resilient_parsing :,if value is not None:,False,22.32226410931225,94.09078002960588
2428,"def word_pattern ( pattern , str ) : <TAB>  dict = { } <TAB>  set_value = set ( ) <TAB>  list_str = str . split ( ) <TAB>  if len ( list_str ) != len ( pattern ) : <TAB><TAB>  return False <TAB>  for i in range ( len ( pattern ) ) : <TAB><TAB>  if pattern [ i ] not in dict : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  dict [ pattern [ i ] ] = list_str [ i ] <TAB><TAB><TAB>  set_value . add ( list_str [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  if dict [ pattern [ i ] ] != list_str [ i ] : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ",if list_str [ i ] in set_value :,if list_str[i] in set_value:,False,50.930578296341864,100.00000000000004
2429,"def create ( self , path , wipe = False ) : <TAB>  # type: (Text, bool) -> bool <TAB>  _path = self . validatepath ( path ) <TAB>  with ftp_errors ( self , path ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  empty_file = io . BytesIO ( ) <TAB><TAB><TAB>  self . ftp . storbinary ( <TAB><TAB><TAB><TAB>  str ( "" STOR  "" ) + _encode ( _path , self . ftp . encoding ) , empty_file <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return True <TAB>  return False ",if wipe or not self . isfile ( path ) :,if wipe:,False,53.77469062880371,93.99622166916612
2430,"def build_output_for_item ( self , item ) : <TAB>  output = [ ] <TAB>  for field in self . fields : <TAB><TAB>  values = self . _get_item ( item , field ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values = [ values ] <TAB><TAB>  for value in values : <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  output . append ( self . build_output_for_single_value ( value ) ) <TAB>  return "" "" . join ( output ) ","if not isinstance ( values , list ) :",if values is not None:,False,22.408852350529898,94.36638306910393
2431,"def get_resource_public_actions ( resource_class ) : <TAB>  resource_class_members = inspect . getmembers ( resource_class ) <TAB>  resource_methods = { } <TAB>  for name , member in resource_class_members : <TAB><TAB>  if not name . startswith ( "" _ "" ) : <TAB><TAB><TAB>  if not name [ 0 ] . isupper ( ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if is_resource_action ( member ) : <TAB><TAB><TAB><TAB><TAB><TAB>  resource_methods [ name ] = member <TAB>  return resource_methods ","if not name . startswith ( ""wait_until"" ) :",if is_resource_action(member):,False,26.579795240279797,93.60964259282822
2432,"def get_command ( cls ) : <TAB>  ifconfig_cmd = "" ifconfig "" <TAB>  for path in [ "" /sbin "" , "" /usr/sbin "" , "" /bin "" , "" /usr/bin "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ifconfig_cmd = os . path . join ( path , ifconfig_cmd ) <TAB><TAB><TAB>  break <TAB>  ifconfig_cmd = ifconfig_cmd + ""  -a "" <TAB>  return ifconfig_cmd ","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :",if os.path.exists(path):,False,48.58878215793412,89.8421514462385
2433,"def main ( ) : <TAB>  base_dir = os . path . join ( os . path . split ( __file__ ) [ 0 ] , "" .. "" , "" .. "" ) <TAB>  for path in PATHS : <TAB><TAB>  path = os . path . join ( base_dir , path ) <TAB><TAB>  for root , _ , files in os . walk ( path ) : <TAB><TAB><TAB>  for file in files : <TAB><TAB><TAB><TAB>  extension = os . path . splitext ( file ) [ 1 ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  path = os . path . join ( root , file ) <TAB><TAB><TAB><TAB><TAB>  validate_header ( path ) ",if extension in EXTENSIONS :,if extension == 'header':,False,49.11501165097639,97.6931116171903
2434,"def auth_login ( request ) : <TAB>  form = RegistrationForm ( request . POST or None ) <TAB>  if form . is_valid ( ) : <TAB><TAB>  authed_user = authenticate ( <TAB><TAB><TAB>  username = form . cleaned_data [ "" username "" ] , <TAB><TAB><TAB>  password = form . cleaned_data [ "" password "" ] , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  login ( request , authed_user ) <TAB><TAB><TAB>  return HttpResponse ( "" Success "" ) <TAB>  raise Http404 ",if authed_user :,if authed_user:,False,50.742286522343846,100.00000000000004
2435,"def set ( self , _key , _new_login = True ) : <TAB>  with self . lock : <TAB><TAB>  user = self . users . get ( current_user . id , None ) <TAB><TAB>  if user is None : <TAB><TAB><TAB>  self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  user [ "" session_count "" ] + = 1 <TAB><TAB><TAB>  user [ "" key "" ] = _key ",if _new_login :,if _new_login:,False,47.82237360518275,100.00000000000004
2436,"def fetch ( self , fingerprints ) : <TAB>  to_fetch = [ f for f in fingerprints if f not in self . _cache ] <TAB>  self . _logger . debug ( "" cache size  %s "" % len ( self . _cache ) ) <TAB>  self . _logger . debug ( "" to fetch  %d  from  %d "" % ( len ( to_fetch ) , len ( fingerprints ) ) ) <TAB>  [ self . _redis_pipeline . hgetall ( key ) for key in to_fetch ] <TAB>  responses = self . _redis_pipeline . execute ( ) <TAB>  for index , key in enumerate ( to_fetch ) : <TAB><TAB>  response = responses [ index ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _cache [ key ] = response [ FIELD_STATE ] <TAB><TAB>  else : <TAB><TAB><TAB>  self . _cache [ key ] = self . NOT_CRAWLED ",if len ( response ) > 0 and FIELD_STATE in response :,if response.getFIELD_STATE() is not self.NOT_CRAWLED:,False,30.579151753350807,93.80233982177755
2437,"def _append_to_io_queue ( self , data , stream_name ) : <TAB>  # Make sure ANSI CSI codes and object links are stored as separate events <TAB>  # TODO: try to complete previously submitted incomplete code <TAB>  parts = re . split ( OUTPUT_SPLIT_REGEX , data ) <TAB>  for part in parts : <TAB><TAB>  if part :<TAB># split may produce empty string in the beginning or start <TAB><TAB><TAB>  # split the data so that very long lines separated <TAB><TAB><TAB>  for block in re . split ( <TAB><TAB><TAB><TAB>  "" (. { %d ,}) "" % ( self . _get_squeeze_threshold ( ) + 1 ) , part <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . _queued_io_events . append ( ( block , stream_name ) ) ",if block :,if block not in self._queued_io_events:,False,45.104297428780015,93.30992235166444
2438,"def find_file_at_path_with_indexes ( self , path , url ) : <TAB>  if url . endswith ( "" / "" ) : <TAB><TAB>  path = os . path . join ( path , self . index_file ) <TAB><TAB>  return self . get_static_file ( path , url ) <TAB>  elif url . endswith ( "" / "" + self . index_file ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  return self . get_static_file ( path , url ) <TAB><TAB>  except IsDirectoryError : <TAB><TAB><TAB>  if os . path . isfile ( os . path . join ( path , self . index_file ) ) : <TAB><TAB><TAB><TAB>  return self . redirect ( url , url + "" / "" ) <TAB>  raise MissingFileError ( path ) ",if os . path . isfile ( path ) :,if path.endswith(self.index_file):,False,49.45427807416752,94.85005710618914
2439,"def module_list ( target , fast ) : <TAB>  """"""Find the list of modules to be compiled"""""" <TAB>  modules = [ ] <TAB>  native = native_modules ( target ) <TAB>  basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB>  for name in os . listdir ( basedir ) : <TAB><TAB>  module_name , ext = os . path . splitext ( name ) <TAB><TAB>  if ext == "" .py "" or ext == "" "" and os . path . isdir ( os . path . join ( basedir , name ) ) : <TAB><TAB><TAB>  if module_name not in IGNORE_MODULES and module_name not in native : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  modules . append ( module_name ) <TAB>  return set ( modules ) ",if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) :,if module_name not in modules:,False,31.504081240732752,93.90442647833873
2440,"def housenumber ( self ) : <TAB>  if self . address : <TAB><TAB>  expression = r "" \ d+ "" <TAB><TAB>  pattern = re . compile ( expression ) <TAB><TAB>  match = pattern . search ( self . address ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return int ( match . group ( 0 ) ) ",if match :,if match:,False,48.135817876354004,100.00000000000004
2441,"def get_pip_version ( import_path = BASE_IMPORT_PATH ) : <TAB>  try : <TAB><TAB>  pip = importlib . import_module ( import_path ) <TAB>  except ImportError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return get_pip_version ( import_path = "" pip "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  import subprocess <TAB><TAB><TAB>  version = subprocess . check_output ( [ "" pip "" , "" --version "" ] ) <TAB><TAB><TAB>  if version : <TAB><TAB><TAB><TAB>  version = version . decode ( "" utf-8 "" ) . split ( ) [ 1 ] <TAB><TAB><TAB><TAB>  return version <TAB><TAB><TAB>  return "" 0.0.0 "" <TAB>  version = getattr ( pip , "" __version__ "" , None ) <TAB>  return version ","if import_path != ""pip"" :",if sys.platform == 'win32':,False,47.72668200277202,95.85748654694832
2442,"def __animate_progress ( self ) : <TAB>  """"""Change the status message, mostly used to animate progress."""""" <TAB>  while True : <TAB><TAB>  sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB>  with self . __progress_lock : <TAB><TAB><TAB>  if not self . __progress_status : <TAB><TAB><TAB><TAB>  sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . __progress_status . update_progress ( self . __current_operation_name ) <TAB><TAB><TAB><TAB>  sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . __progress_status . show_as_ready ( ) <TAB><TAB><TAB><TAB>  sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB>  # Allow some time for progress status to be updated. <TAB><TAB>  time . sleep ( sleep_time ) ",elif self . __show_animation :,if self.__current_operation_name:,False,63.6972021357827,96.83846933943362
2443,"def range_key_names ( self ) : <TAB>  keys = [ self . range_key_attr ] <TAB>  for index in self . global_indexes : <TAB><TAB>  range_key = None <TAB><TAB>  for key in index . schema : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  range_key = keys . append ( key [ "" AttributeName "" ] ) <TAB><TAB>  keys . append ( range_key ) <TAB>  return keys ","if key [ ""KeyType"" ] == ""RANGE"" :",if key['AttributeName'] in keys:,False,47.94065210268755,91.84884746108872
2444,"def run ( self ) : <TAB>  dist = self . distribution <TAB>  commands = dist . command_options . keys ( ) <TAB>  settings = { } <TAB>  for cmd in commands : <TAB><TAB>  if cmd == "" saveopts "" : <TAB><TAB><TAB>  continue<TAB># don't save our own options! <TAB><TAB>  for opt , ( src , val ) in dist . get_option_dict ( cmd ) . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  settings . setdefault ( cmd , { } ) [ opt ] = val <TAB>  edit_config ( self . filename , settings , self . dry_run ) ","if src == ""command line"" :",if src == self.filename:,False,21.40575135030633,94.60778042316078
2445,"def parse_move ( self , node ) : <TAB>  old , new = "" "" , "" "" <TAB>  for child in node : <TAB><TAB>  tag , text = child . tag , child . text <TAB><TAB>  text = text . strip ( ) if text else None <TAB><TAB>  if tag == "" Old "" and text : <TAB><TAB><TAB>  old = text <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new = text <TAB>  return Move ( old , new ) ","elif tag == ""New"" and text :","if tag == ""New"" and text:",False,28.110239009443156,98.04274240373084
2446,"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB>  if self . data : <TAB><TAB>  run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB><TAB>  for finfo in self . data : <TAB><TAB><TAB>  self . __update_editor_margins ( finfo . editor ) <TAB><TAB><TAB>  finfo . cleanup_analysis_results ( ) <TAB><TAB><TAB>  if ( run_pyflakes or run_pep8 ) and current_finfo is not None : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  finfo . run_code_analysis ( run_pyflakes , run_pep8 ) ",if current_finfo is not finfo :,if finfo.is_code_analysis_enabled():,False,52.77802230471793,93.61573119941961
2447,"def tchg ( var , width ) : <TAB>  "" Convert time string to given length "" <TAB>  ret = "" %2d h %02d "" % ( var / 60 , var % 60 ) <TAB>  <IF-STMT>: <TAB><TAB>  ret = "" %2d h "" % ( var / 60 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret = "" %2d d "" % ( var / 60 / 24 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret = "" %2d w "" % ( var / 60 / 24 / 7 ) <TAB>  return ret ",if len ( ret ) > width :,if var % 60 == 0:,False,26.66663163745202,77.74075234113779
2448,"def spider_log_activity ( self , messages ) : <TAB>  for i in range ( 0 , messages ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . sp_sl_p . send ( <TAB><TAB><TAB><TAB>  sha1 ( str ( randint ( 1 , 1000 ) ) ) , <TAB><TAB><TAB><TAB>  b "" http://helloworld.com/way/to/the/sun/ "" + b "" 0 "" , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . sp_sl_p . send ( <TAB><TAB><TAB><TAB>  sha1 ( str ( randint ( 1 , 1000 ) ) ) , b "" http://way.to.the.sun "" + b "" 0 "" <TAB><TAB><TAB>  ) <TAB>  self . sp_sl_p . flush ( ) ",if i % 2 == 0 :,if i == messages - 1:,False,22.06940625267719,97.41908809076104
2449,"def decode_serial ( self , offset ) : <TAB>  serialnum = ( <TAB><TAB>  ( self . cache [ offset + 3 ] << 24 ) <TAB><TAB>  + ( self . cache [ offset + 2 ] << 16 ) <TAB><TAB>  + ( self . cache [ offset + 1 ] << 8 ) <TAB><TAB>  + self . cache [ offset ] <TAB>  ) <TAB>  serialstr = "" "" <TAB>  is_alnum = True <TAB>  for i in range ( 4 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  is_alnum = False <TAB><TAB><TAB>  break <TAB><TAB>  serialstr + = chr ( self . cache [ offset + 3 - i ] ) <TAB>  serial = serialstr if is_alnum else str ( serialnum ) <TAB>  self . ann_field ( offset , offset + 3 , "" Serial  "" + serial ) ",if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,if offset + 3 <= i + 3:,False,28.68047478213675,92.0128501909877
2450,def gettext ( rv ) : <TAB>  for child in rv . childNodes : <TAB><TAB>  if child . nodeType == child . TEXT_NODE : <TAB><TAB><TAB>  yield child . nodeValue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for item in gettext ( child ) : <TAB><TAB><TAB><TAB>  yield item ,if child . nodeType == child . ELEMENT_NODE :,"if isinstance(child, (list, tuple)):",False,24.993614983680146,88.05908822237335
2451,"def determine_block_hints ( self , text ) : <TAB>  hints = "" "" <TAB>  if text : <TAB><TAB>  if text [ 0 ] in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB>  hints + = str ( self . best_indent ) <TAB><TAB>  if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB>  hints + = "" - "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  hints + = "" + "" <TAB>  return hints ","elif len ( text ) == 1 or text [ - 2 ] in ""\n\x85\u2028\u2029"" :","if text[-1] in ""\n\x85\u2028\u202",False,42.08147278279814,88.49303819685898
2452,"def _infer_return_type ( * args ) : <TAB>  """"""Look at the type of all args and divine their implied return type."""""" <TAB>  return_type = None <TAB>  for arg in args : <TAB><TAB>  if arg is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if return_type is str : <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = bytes <TAB><TAB>  else : <TAB><TAB><TAB>  if return_type is bytes : <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = str <TAB>  if return_type is None : <TAB><TAB>  return str<TAB># tempfile APIs return a str by default. <TAB>  return return_type ","if isinstance ( arg , bytes ) :",if return_type is None:,False,58.05871703529405,91.98981437995215
2453,"def as_iconbitmap ( cls , rkey ) : <TAB>  """"""Get image path for use in iconbitmap property"""""" <TAB>  img = None <TAB>  if rkey in cls . _stock : <TAB><TAB>  data = cls . _stock [ rkey ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fpath = data [ "" filename "" ] <TAB><TAB><TAB>  fname = os . path . basename ( fpath ) <TAB><TAB><TAB>  name , file_ext = os . path . splitext ( fname ) <TAB><TAB><TAB>  file_ext = str ( file_ext ) . lower ( ) <TAB><TAB><TAB>  if file_ext in TK_BITMAP_FORMATS : <TAB><TAB><TAB><TAB>  img = BITMAP_TEMPLATE . format ( fpath ) <TAB>  return img ","if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :",if data and data['use'] == 'iconbitmap':,False,29.48996998750039,90.3627024684265
2454,"def anonymize_ip ( ip ) : <TAB>  if ip : <TAB><TAB>  match = RE_FIRST_THREE_OCTETS_OF_IP . findall ( str ( ip ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" %s %s "" % ( match [ 0 ] [ 0 ] , "" 0 "" ) <TAB>  return "" "" ",if match :,if match:,False,50.83255706009366,100.00000000000004
2455,"def serialize_tail ( self ) : <TAB>  msg = bytearray ( ) <TAB>  for v in self . info : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = v [ "" value "" ] . encode ( "" utf-8 "" ) <TAB><TAB>  elif v [ "" type "" ] == BMP_TERM_TYPE_REASON : <TAB><TAB><TAB>  value = struct . pack ( "" !H "" , v [ "" value "" ] ) <TAB><TAB>  v [ "" len "" ] = len ( value ) <TAB><TAB>  msg + = struct . pack ( self . _TLV_PACK_STR , v [ "" type "" ] , v [ "" len "" ] ) <TAB><TAB>  msg + = value <TAB>  return msg ","if v [ ""type"" ] == BMP_TERM_TYPE_STRING :",if v['type'] == BMP_TERM_TYPE_NORMAL:,False,47.96615171091273,96.29422491705041
2456,"def get_django_comment ( text : str , i : int ) - > str : <TAB>  end = i + 4 <TAB>  unclosed_end = 0 <TAB>  while end < = len ( text ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return text [ i : end ] <TAB><TAB>  if not unclosed_end and text [ end ] == "" < "" : <TAB><TAB><TAB>  unclosed_end = end <TAB><TAB>  end + = 1 <TAB>  raise TokenizationException ( "" Unclosed comment "" , text [ i : unclosed_end ] ) ","if text [ end - 2 : end ] == ""#}"" :","if text[i] == ""<"":",False,25.167135422567384,93.26542408114828
2457,"def ComboBoxDroppedHeightTest ( windows ) : <TAB>  "" Check if each combobox height is the same as the reference "" <TAB>  bugs = [ ] <TAB>  for win in windows : <TAB><TAB>  if not win . ref : <TAB><TAB><TAB>  continue <TAB><TAB>  if win . Class ( ) != "" ComboBox "" or win . ref . Class ( ) != "" ComboBox "" : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bugs . append ( <TAB><TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB><TAB>  win , <TAB><TAB><TAB><TAB><TAB>  ] , <TAB><TAB><TAB><TAB><TAB>  { } , <TAB><TAB><TAB><TAB><TAB>  testname , <TAB><TAB><TAB><TAB><TAB>  0 , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return bugs ",if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) :,"if win.Class() == ""ComboBox':",False,57.54633944679568,92.78583580361689
2458,"def testBadModeArgument ( self ) : <TAB>  # verify that we get a sensible error message for bad mode argument <TAB>  bad_mode = "" qwerty "" <TAB>  try : <TAB><TAB>  f = self . open ( TESTFN , bad_mode ) <TAB>  except ValueError as msg : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s = str ( msg ) <TAB><TAB><TAB>  if TESTFN in s or bad_mode not in s : <TAB><TAB><TAB><TAB>  self . fail ( "" bad error message for invalid mode:  %s "" % s ) <TAB><TAB>  # if msg.args[0] == 0, we're probably on Windows where there may be <TAB><TAB>  # no obvious way to discover why open() failed. <TAB>  else : <TAB><TAB>  f . close ( ) <TAB><TAB>  self . fail ( "" no error for invalid mode:  %s "" % bad_mode ) ",if msg . args [ 0 ] != 0 :,if msg.args[0] == 0:,False,45.92282009731015,98.90705000370515
2459,"def command_group_expired ( self , command_group_name ) : <TAB>  try : <TAB><TAB>  deprecate_info = self . _command_loader . command_group_table [ <TAB><TAB><TAB>  command_group_name <TAB><TAB>  ] . group_kwargs . get ( "" deprecate_info "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return deprecate_info . expired ( ) <TAB>  except AttributeError : <TAB><TAB>  # Items with only token presence in the command table will not have any data. They can't be expired. <TAB><TAB>  pass <TAB>  return False ",if deprecate_info :,if deprecate_info is not None:,False,53.50382180140942,97.07913170763268
2460,"def test_non_uniform_probabilities_over_elements ( self ) : <TAB>  param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB>  samples = param . draw_samples ( ( 10000 , ) ) <TAB>  unique , counts = np . unique ( samples , return_counts = True ) <TAB>  assert len ( unique ) == 2 <TAB>  for val , count in zip ( unique , counts ) : <TAB><TAB>  if val == 0 : <TAB><TAB><TAB>  assert 2500 - 500 < count < 2500 + 500 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert 7500 - 500 < count < 7500 + 500 <TAB><TAB>  else : <TAB><TAB><TAB>  assert False ",elif val == 1 :,if val == 1:,False,33.497806667106914,98.60128562085158
2461,"def get_labels ( directory ) : <TAB>  cache = get_labels . __cache <TAB>  if directory not in cache : <TAB><TAB>  l = { } <TAB><TAB>  for t in get_visual_configs ( directory ) [ 0 ] [ LABEL_SECTION ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  Messager . warning ( <TAB><TAB><TAB><TAB><TAB>  "" In configuration, labels for  ' %s '  defined more than once. Only using the last set. "" <TAB><TAB><TAB><TAB><TAB>  % t . storage_form ( ) , <TAB><TAB><TAB><TAB><TAB>  - 1 , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  # first is storage for, rest are labels. <TAB><TAB><TAB>  l [ t . storage_form ( ) ] = t . terms [ 1 : ] <TAB><TAB>  cache [ directory ] = l <TAB>  return cache [ directory ] ",if t . storage_form ( ) in l :,if t.storage_form() > 0:,False,60.74774783476038,95.90750853572136
2462,"def try_split ( self , split_text : List [ str ] ) : <TAB>  ret = [ ] <TAB>  for i in split_text : <TAB><TAB>  if len ( i ) == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  val = int ( i , 2 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  ret . append ( val ) <TAB>  if len ( ret ) != 0 : <TAB><TAB>  ret = bytes ( ret ) <TAB><TAB>  logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB><TAB>  return ret ",if val > 255 or val < 0 :,if val < 0 or val > 255:,False,42.13174072819456,97.47196014289548
2463,"def setCellValue ( self , row_idx , col , value ) : <TAB>  assert col . id == "" repls-marked "" <TAB>  with self . _lock : <TAB><TAB>  rgroup = self . events [ row_idx ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  rgroup . _marked = value == "" true "" and True or False <TAB>  if self . _tree : <TAB><TAB>  self . _tree . invalidateCell ( row_idx , col ) ","if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",if rgroup._marked:,False,23.102767037212875,91.97572525134788
2464,"def create ( cls , settlement_manager , resource_id ) : <TAB>  """"""Create a production chain that can produce the given resource."""""" <TAB>  resource_producer = { } <TAB>  for abstract_building in AbstractBuilding . buildings . values ( ) : <TAB><TAB>  for resource , production_line in abstract_building . lines . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  resource_producer [ resource ] = [ ] <TAB><TAB><TAB>  resource_producer [ resource ] . append ( ( production_line , abstract_building ) ) <TAB>  return ProductionChain ( settlement_manager , resource_id , resource_producer ) ",if resource not in resource_producer :,if not resource in resource_producer:,False,54.58655247493107,98.16217483995752
2465,def get_all_partition_sets ( self ) : <TAB>  partition_sets = [ ] <TAB>  if self . partitions_handle : <TAB><TAB>  partition_sets . extend ( self . partitions_handle . get_partition_sets ( ) ) <TAB>  if self . scheduler_handle : <TAB><TAB>  partition_sets . extend ( <TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB>  schedule_def . get_partition_set ( ) <TAB><TAB><TAB><TAB>  for schedule_def in self . scheduler_handle . all_schedule_defs ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ] <TAB><TAB>  ) <TAB>  return partition_sets ,"if isinstance ( schedule_def , PartitionScheduleDefinition )",if schedule_def.get_partition_set() == self.partition_set:,False,47.97165973555337,90.56322539466606
2466,"def _sendDatapointsNow ( self , datapoints ) : <TAB>  metrics = { } <TAB>  payload_pb = Payload ( ) <TAB>  for metric , datapoint in datapoints : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  metric_pb = payload_pb . metrics . add ( ) <TAB><TAB><TAB>  metric_pb . metric = metric <TAB><TAB><TAB>  metrics [ metric ] = metric_pb <TAB><TAB>  else : <TAB><TAB><TAB>  metric_pb = metrics [ metric ] <TAB><TAB>  point_pb = metric_pb . points . add ( ) <TAB><TAB>  point_pb . timestamp = int ( datapoint [ 0 ] ) <TAB><TAB>  point_pb . value = datapoint [ 1 ] <TAB>  self . sendString ( payload_pb . SerializeToString ( ) ) ",if metric not in metrics :,if metric not in metrics:,False,51.76550085944871,100.00000000000004
2467,"def execute ( self ) : <TAB>  if self . _dirty or not self . _qr : <TAB><TAB>  model_class = self . model_class <TAB><TAB>  query_meta = self . get_query_meta ( ) <TAB><TAB>  if self . _tuples : <TAB><TAB><TAB>  ResultWrapper = TuplesQueryResultWrapper <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ResultWrapper = DictQueryResultWrapper <TAB><TAB>  elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB><TAB><TAB>  ResultWrapper = NaiveQueryResultWrapper <TAB><TAB>  elif self . _aggregate_rows : <TAB><TAB><TAB>  ResultWrapper = AggregateQueryResultWrapper <TAB><TAB>  else : <TAB><TAB><TAB>  ResultWrapper = ModelQueryResultWrapper <TAB><TAB>  self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB><TAB>  self . _dirty = False <TAB><TAB>  return self . _qr <TAB>  else : <TAB><TAB>  return self . _qr ",elif self . _dicts :,if self._dict_rows:,False,35.65168819435342,97.24151608128265
2468,"def get_metrics ( ) : <TAB>  classifier , feature_labels = load_classifier ( ) <TAB>  available_metrics = ImgageMetrics . get_metric_classes ( ) <TAB>  # todo review: DONE IN DOCS <TAB>  #  effective_metrics isn't used after filling it with values <TAB>  #  in the loops below <TAB>  effective_metrics = [ ] <TAB>  for metric in available_metrics : <TAB><TAB>  for label in feature_labels : <TAB><TAB><TAB>  for label_part in metric . get_labels ( ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  effective_metrics . append ( metric ) <TAB>  return ( classifier , feature_labels , available_metrics ) ",if label_part == label and metric not in effective_metrics :,if label_part in effective_metrics:,False,59.72995599658102,95.94732376377567
2469,"def test_nic_names ( self ) : <TAB>  p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB>  out = p . communicate ( ) [ 0 ] <TAB>  if PY3 : <TAB><TAB>  out = str ( out , sys . stdout . encoding ) <TAB>  nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB>  for nic in nics : <TAB><TAB>  if "" pseudo-interface "" in nic . replace ( "" "" , "" - "" ) . lower ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic ) ",if nic not in out :,if nic not in out:,False,51.60683689264282,94.19821715800482
2470,"def convert_with_key ( self , key , value , replace = True ) : <TAB>  result = self . configurator . convert ( value ) <TAB>  # If the converted value is different, save for next time <TAB>  if value is not result : <TAB><TAB>  if replace : <TAB><TAB><TAB>  self [ key ] = result <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . parent = self <TAB><TAB><TAB>  result . key = key <TAB>  return result ","if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :",if result is not None:,False,61.06242102773714,89.71613511322386
2471,"def _EvaluateFile ( self , test_list , file ) : <TAB>  ( name , ext ) = os . path . splitext ( file ) <TAB>  if ext == "" .cc "" or ext == "" .cpp "" or ext == "" .c "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . SilentLog ( "" Found native test file  %s "" % file ) <TAB><TAB><TAB>  test_list . append ( name ) ","if re . search ( ""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"" , name ) :",if name == 'Test':,False,50.351188572983816,73.29715361893248
2472,"def leading_whitespace ( self , inputstring ) : <TAB>  """"""Get leading whitespace."""""" <TAB>  leading_ws = [ ] <TAB>  for i , c in enumerate ( inputstring ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  leading_ws . append ( c ) <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB><TAB>  if self . indchar is None : <TAB><TAB><TAB>  self . indchar = c <TAB><TAB>  elif c != self . indchar : <TAB><TAB><TAB>  self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB>  return "" "" . join ( leading_ws ) ",if c in legal_indent_chars :,if c in self.leading_ws:,False,52.593768547166974,96.50925040104032
2473,"def ident_values ( self ) : <TAB>  value = self . _ident_values <TAB>  if value is False : <TAB><TAB>  value = None <TAB><TAB>  # XXX: how will this interact with orig_prefix ? <TAB><TAB>  #<TAB>  not exposing attrs for now if orig_prefix is set. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  wrapped = self . wrapped <TAB><TAB><TAB>  idents = getattr ( wrapped , "" ident_values "" , None ) <TAB><TAB><TAB>  if idents : <TAB><TAB><TAB><TAB>  value = [ self . _wrap_hash ( ident ) for ident in idents ] <TAB><TAB><TAB>  ##else: <TAB><TAB><TAB>  ##<TAB>ident = self.ident <TAB><TAB><TAB>  ##<TAB>if ident is not None: <TAB><TAB><TAB>  ##<TAB><TAB>value = [ident] <TAB><TAB>  self . _ident_values = value <TAB>  return value ",if not self . orig_prefix :,if self.wrapped is not None:,False,62.27296838345596,97.48735591122156
2474,"def _available_symbols ( self , scoperef , expr ) : <TAB>  cplns = [ ] <TAB>  found_names = set ( ) <TAB>  while scoperef : <TAB><TAB>  elem = self . _elem_from_scoperef ( scoperef ) <TAB><TAB>  for child in elem : <TAB><TAB><TAB>  name = child . get ( "" name "" , "" "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if name not in found_names : <TAB><TAB><TAB><TAB><TAB>  found_names . add ( name ) <TAB><TAB><TAB><TAB><TAB>  ilk = child . get ( "" ilk "" ) or child . tag <TAB><TAB><TAB><TAB><TAB>  cplns . append ( ( ilk , name ) ) <TAB><TAB>  scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB><TAB>  if not scoperef : <TAB><TAB><TAB>  break <TAB>  return sorted ( cplns , key = operator . itemgetter ( 1 ) ) ",if name . startswith ( expr ) :,if name not in found_names:,False,31.021901071460782,97.47277874159029
2475,"def pid_from_name ( name ) : <TAB>  # quick and dirty, works with all linux not depending on ps output <TAB>  for pid in os . listdir ( "" /proc "" ) : <TAB><TAB>  try : <TAB><TAB><TAB>  int ( pid ) <TAB><TAB>  except : <TAB><TAB><TAB>  continue <TAB><TAB>  pname = "" "" <TAB><TAB>  with open ( "" /proc/ %s /cmdline "" % pid , "" r "" ) as f : <TAB><TAB><TAB>  pname = f . read ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return int ( pid ) <TAB>  raise ProcessException ( "" No process with such name:  %s "" % name ) ",if name in pname :,if pname == name:,False,37.70204341267092,97.20246868202099
2476,"def touch ( self ) : <TAB>  if not self . exists ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  self . parent ( ) . touch ( ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  pass <TAB><TAB>  node = self . _fs . touch ( self . pathnames , { } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB><TAB>  if self . watcher : <TAB><TAB><TAB>  self . watcher . emit ( "" created "" , self ) ",if not node . isdir :,if not node:,False,23.650157174153815,97.68566691405024
2477,"def setUp ( self ) : <TAB>  BaseTestCase . setUp ( self ) <TAB>  self . rawData = [ ] <TAB>  self . dataByKey = { } <TAB>  for i in range ( 1 , 11 ) : <TAB><TAB>  stringCol = "" String  %d "" % i <TAB><TAB>  fixedCharCol = ( "" Fixed Char  %d "" % i ) . ljust ( 40 ) <TAB><TAB>  rawCol = "" Raw  %d "" % i <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  nullableCol = "" Nullable  %d "" % i <TAB><TAB>  else : <TAB><TAB><TAB>  nullableCol = None <TAB><TAB>  dataTuple = ( i , stringCol , rawCol , fixedCharCol , nullableCol ) <TAB><TAB>  self . rawData . append ( dataTuple ) <TAB><TAB>  self . dataByKey [ i ] = dataTuple ",if i % 2 :,if fixedCharCol == 0:,False,34.887166965974934,97.16704052661908
2478,"def GenerateVector ( self , hits , vector , level ) : <TAB>  """"""Generate possible hit vectors which match the rules."""""" <TAB>  for item in hits . get ( level , [ ] ) : <TAB><TAB>  if vector : <TAB><TAB><TAB>  if item < vector [ - 1 ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if item > self . max_separation + vector [ - 1 ] : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  new_vector = vector + [ item ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield new_vector <TAB><TAB>  elif level + 1 < len ( hits ) : <TAB><TAB><TAB>  for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB><TAB><TAB><TAB>  yield result ",if level + 1 == len ( hits ) :,if new_vector:,False,31.911797594985014,93.08719260341597
2479,"def __repr__ ( self ) : <TAB>  attrs = [ ] <TAB>  for k in self . keydata : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB><TAB>  elif hasattr ( self . key , k ) : <TAB><TAB><TAB>  attrs . append ( k ) <TAB>  if self . has_private ( ) : <TAB><TAB>  attrs . append ( "" private "" ) <TAB>  return "" < %s  @0x %x %s > "" % ( self . __class__ . __name__ , id ( self ) , "" , "" . join ( attrs ) ) ","if k == ""p"" :",if k == 'size':,False,50.93660200535795,97.41806063689786
2480,"def autoload ( self ) : <TAB>  if self . _app . config . THEME == "" auto "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if get_osx_theme ( ) == 1 : <TAB><TAB><TAB><TAB>  theme = DARK <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  theme = LIGHT <TAB><TAB>  else : <TAB><TAB><TAB>  theme = self . guess_system_theme ( ) <TAB><TAB><TAB>  if theme == Dark : <TAB><TAB><TAB><TAB>  theme = MacOSDark <TAB>  else :<TAB># user settings have highest priority <TAB><TAB>  theme = self . _app . config . THEME <TAB>  self . load_theme ( theme ) ","if sys . platform == ""darwin"" :",if get_osx_theme() == 0:,False,52.28129667482511,92.41032632419741
2481,"def _get_matching_bracket ( self , s , pos ) : <TAB>  if s [ pos ] != "" { "" : <TAB><TAB>  return None <TAB>  end = len ( s ) <TAB>  depth = 1 <TAB>  pos + = 1 <TAB>  while pos != end : <TAB><TAB>  c = s [ pos ] <TAB><TAB>  if c == "" { "" : <TAB><TAB><TAB>  depth + = 1 <TAB><TAB>  elif c == "" } "" : <TAB><TAB><TAB>  depth - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  pos + = 1 <TAB>  if pos < end and s [ pos ] == "" } "" : <TAB><TAB>  return pos <TAB>  return None ",if depth == 0 :,if depth == 0:,False,22.86634904715446,100.00000000000004
2482,"def update_meter ( self , output , target , meters = { "" accuracy "" } ) : <TAB>  output = self . __to_tensor ( output ) <TAB>  target = self . __to_tensor ( target ) <TAB>  for meter in meters : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __addmeter ( meter ) <TAB><TAB>  if meter in [ "" ap "" , "" map "" , "" confusion "" ] : <TAB><TAB><TAB>  target_th = self . _ver2tensor ( target ) <TAB><TAB><TAB>  self . meter [ meter ] . add ( output , target_th ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . meter [ meter ] . add ( output , target ) ",if meter not in self . meter . keys ( ) :,if meter not in self.meter:,False,49.55019868303782,97.0712456036005
2483,"def _reinit_optimizers_with_oss ( self ) : <TAB>  optimizers = self . lightning_module . trainer . optimizers <TAB>  for x , optimizer in enumerate ( optimizers ) : <TAB><TAB>  if is_lightning_optimizer ( optimizer ) : <TAB><TAB><TAB>  optimizer = optimizer . _optimizer <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  optim_class = type ( optimizer ) <TAB><TAB><TAB>  zero_optimizer = OSS ( <TAB><TAB><TAB><TAB>  params = optimizer . param_groups , optim = optim_class , * * optimizer . defaults <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  optimizers [ x ] = zero_optimizer <TAB><TAB><TAB>  del optimizer <TAB>  trainer = self . lightning_module . trainer <TAB>  trainer . optimizers = optimizers <TAB>  trainer . convert_to_lightning_optimizers ( ) ","if not isinstance ( optimizer , OSS ) :","if isinstance(optimizer, LINNING_COMPRESS):",False,29.47621135133086,97.26826741290358
2484,"def OnSelChanged ( self , event ) : <TAB>  self . item = event . GetItem ( ) <TAB>  if self . item : <TAB><TAB>  self . log . write ( "" OnSelChanged:  %s "" % self . GetItemText ( self . item ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log . write ( <TAB><TAB><TAB><TAB>  "" , BoundingRect:  %s \n "" % self . GetBoundingRect ( self . item , True ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . log . write ( "" \n "" ) <TAB>  event . Skip ( ) ","if wx . Platform == ""__WXMSW__"" :",if self.item:,False,48.73196668475558,91.98494745739241
2485,"def parse_batch ( args ) : <TAB>  errmsg = "" Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1). "" <TAB>  if args . batch is not None : <TAB><TAB>  rule , batchdef = parse_key_value_arg ( args . batch , errmsg = errmsg ) <TAB><TAB>  try : <TAB><TAB><TAB>  batch , batches = batchdef . split ( "" / "" ) <TAB><TAB><TAB>  batch = int ( batch ) <TAB><TAB><TAB>  batches = int ( batches ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  raise ValueError ( errmsg ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( errmsg ) <TAB><TAB>  return Batch ( rule , batch , batches ) <TAB>  return None ",if batch > batches or batch < 1 :,if len(batches) < 1:,False,34.18072943341952,97.04076860958506
2486,"def get_foreign_key_columns ( self , engine , table_name ) : <TAB>  foreign_keys = set ( ) <TAB>  table = db_utils . get_table ( engine , table_name ) <TAB>  inspector = reflection . Inspector . from_engine ( engine ) <TAB>  for column_dict in inspector . get_columns ( table_name ) : <TAB><TAB>  column_name = column_dict [ "" name "" ] <TAB><TAB>  column = getattr ( table . c , column_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  foreign_keys . add ( column_name ) <TAB>  return foreign_keys ",if column . foreign_keys :,if column.primary_key and column.primary_key == self.primary_key:,False,21.181339704172224,89.69023903057769
2487,"def update ( self , t ) : <TAB>  l = int ( t * self . nr_of_tiles ) <TAB>  for i in range ( self . nr_of_tiles ) : <TAB><TAB>  t = self . tiles_order [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . turn_off_tile ( t ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . turn_on_tile ( t ) ",if i < l :,if t < l:,False,26.27964553265813,97.78225290627776
2488,"def read ( self , amt = None ) : <TAB>  # the _rbuf test is only in this first if for speed.  It's not <TAB>  # logically necessary <TAB>  if self . _rbuf and not amt is None : <TAB><TAB>  L = len ( self . _rbuf ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  amt - = L <TAB><TAB>  else : <TAB><TAB><TAB>  s = self . _rbuf [ : amt ] <TAB><TAB><TAB>  self . _rbuf = self . _rbuf [ amt : ] <TAB><TAB><TAB>  return s <TAB>  s = self . _rbuf + self . _raw_read ( amt ) <TAB>  self . _rbuf = b "" "" <TAB>  return s ",if amt > L :,if L > 0:,False,62.636562481162294,97.78448147981878
2489,"def draw_menu_button ( self , context , layout , node , text ) : <TAB>  if ( <TAB><TAB>  hasattr ( node . id_data , "" sv_show_socket_menus "" ) <TAB><TAB>  and node . id_data . sv_show_socket_menus <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  layout . menu ( "" SV_MT_SocketOptionsMenu "" , text = "" "" , icon = "" TRIA_DOWN "" ) ",if self . is_output or self . is_linked or not self . use_prop :,if node.id_data.sv_show_socket_menus:,False,19.189039235095795,85.93511394737162
2490,"def __enter__ ( self ) : <TAB>  with DB . connection_context ( ) : <TAB><TAB>  session_record = SessionRecord ( ) <TAB><TAB>  session_record . f_session_id = self . _session_id <TAB><TAB>  session_record . f_engine_name = self . _engine_name <TAB><TAB>  session_record . f_engine_type = EngineType . STORAGE <TAB><TAB>  # TODO: engine address <TAB><TAB>  session_record . f_engine_address = { } <TAB><TAB>  session_record . f_create_time = current_timestamp ( ) <TAB><TAB>  rows = session_record . save ( force_insert = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( f "" create session record  { self . _session_id }  failed "" ) <TAB><TAB>  LOGGER . debug ( f "" save session  { self . _session_id }  record "" ) <TAB>  self . create ( ) <TAB>  return self ",if rows != 1 :,if rows < 1:,False,50.77758918889823,98.56695260176198
2491,"def tearDown ( self ) : <TAB>  """"""Shutdown the server."""""" <TAB>  try : <TAB><TAB>  if self . server : <TAB><TAB><TAB>  self . server . stop ( 2.0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB>  self . sl_hdlr . close ( ) <TAB>  finally : <TAB><TAB>  BaseTest . tearDown ( self ) ",if self . sl_hdlr :,if self.sl_hdlr:,False,26.49624343647647,100.00000000000004
2492,"def _dec_device ( self , srcdev , dstdev ) : <TAB>  if srcdev : <TAB><TAB>  self . srcdevs [ srcdev ] - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . srcdevs [ srcdev ] <TAB><TAB>  self . _set_limits ( "" read "" , self . srcdevs ) <TAB>  if dstdev : <TAB><TAB>  self . dstdevs [ dstdev ] - = 1 <TAB><TAB>  if self . dstdevs [ dstdev ] == 0 : <TAB><TAB><TAB>  del self . dstdevs [ dstdev ] <TAB><TAB>  self . _set_limits ( "" write "" , self . dstdevs ) ",if self . srcdevs [ srcdev ] == 0 :,if srcdev in self.srcdevs:,False,17.580131701179745,94.54941688574546
2493,"def array_for ( self , i ) : <TAB>  if 0 < = i < self . _cnt : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _tail <TAB><TAB>  node = self . _root <TAB><TAB>  level = self . _shift <TAB><TAB>  while level > 0 : <TAB><TAB><TAB>  assert isinstance ( node , Node ) <TAB><TAB><TAB>  node = node . _array [ ( i >> level ) & 0x01F ] <TAB><TAB><TAB>  level - = 5 <TAB><TAB>  return node . _array <TAB>  affirm ( False , u "" Index out of Range "" ) ",if i >= self . tailoff ( ) :,if i == self._tail:,False,21.34016607695512,95.80554326239852
2494,"def convert_tensor ( self , offsets , sizes ) : <TAB>  results = [ ] <TAB>  for b , batch in enumerate ( offsets ) : <TAB><TAB>  utterances = [ ] <TAB><TAB>  for p , utt in enumerate ( batch ) : <TAB><TAB><TAB>  size = sizes [ b ] [ p ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  utterances . append ( utt [ 0 : size ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  utterances . append ( torch . tensor ( [ ] , dtype = torch . int ) ) <TAB><TAB>  results . append ( utterances ) <TAB>  return results ",if sizes [ b ] [ p ] > 0 :,if size > 0:,False,22.50073268827026,95.1215410036688
2495,"def _predict_proba ( self , X , preprocess = True ) : <TAB>  if preprocess : <TAB><TAB>  X = self . preprocess ( X ) <TAB>  if self . problem_type == REGRESSION : <TAB><TAB>  return self . model . predict ( X ) <TAB>  y_pred_proba = self . model . predict_proba ( X ) <TAB>  if self . problem_type == BINARY : <TAB><TAB>  if len ( y_pred_proba . shape ) == 1 : <TAB><TAB><TAB>  return y_pred_proba <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return y_pred_proba [ : , 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  return y_pred_proba <TAB>  elif y_pred_proba . shape [ 1 ] > 2 : <TAB><TAB>  return y_pred_proba <TAB>  else : <TAB><TAB>  return y_pred_proba [ : , 1 ] ",elif y_pred_proba . shape [ 1 ] > 1 :,if y_pred_proba.shape[0] == 2:,False,50.3189504177993,96.4104219547538
2496,def timeout ( self ) : <TAB>  now = ptime . time ( ) <TAB>  dt = now - self . lastPlayTime <TAB>  if dt < 0 : <TAB><TAB>  return <TAB>  n = int ( self . playRate * dt ) <TAB>  if n != 0 : <TAB><TAB>  self . lastPlayTime + = float ( n ) / self . playRate <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . play ( 0 ) <TAB><TAB>  self . jumpFrames ( n ) ,"if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :",if n == 0:,False,21.397728453832247,83.05768861699265
2497,"def __init__ ( self , data , weights = None , ddof = 0 ) : <TAB>  self . data = np . asarray ( data ) <TAB>  if weights is None : <TAB><TAB>  self . weights = np . ones ( self . data . shape [ 0 ] ) <TAB>  else : <TAB><TAB>  self . weights = np . asarray ( weights ) . astype ( float ) <TAB><TAB>  # TODO: why squeeze? <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . weights = self . weights . squeeze ( ) <TAB>  self . ddof = ddof ",if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 :,if self.weights is not None:,False,50.9448081660534,87.49693445033525
2498,"def writerow ( self , row ) : <TAB>  unicode_row = [ ] <TAB>  for col in row : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  unicode_row . append ( col . encode ( "" utf-8 "" ) . strip ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  unicode_row . append ( col ) <TAB>  self . writer . writerow ( unicode_row ) <TAB>  # Fetch UTF-8 output from the queue ... <TAB>  data = self . queue . getvalue ( ) <TAB>  data = data . decode ( "" utf-8 "" ) <TAB>  # ... and reencode it into the target encoding <TAB>  data = self . encoder . encode ( data ) <TAB>  # write to the target stream <TAB>  self . stream . write ( data ) <TAB>  # empty queue <TAB>  self . queue . truncate ( 0 ) ",if type ( col ) == str or type ( col ) == unicode :,"if isinstance(col, unicode):",False,53.92804878983299,92.81825646629547
2499,"def __init__ ( self , choices , allow_blank = False , * * kwargs ) : <TAB>  self . choiceset = choices <TAB>  self . allow_blank = allow_blank <TAB>  self . _choices = dict ( ) <TAB>  # Unpack grouped choices <TAB>  for k , v in choices : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for k2 , v2 in v : <TAB><TAB><TAB><TAB>  self . _choices [ k2 ] = v2 <TAB><TAB>  else : <TAB><TAB><TAB>  self . _choices [ k ] = v <TAB>  super ( ) . __init__ ( * * kwargs ) ","if type ( v ) in [ list , tuple ] :","if isinstance(v, (list, tuple)):",False,45.05371040561498,94.55829186122537
2500,"def simp_ext ( _ , expr ) : <TAB>  if expr . op . startswith ( "" zeroExt_ "" ) : <TAB><TAB>  arg = expr . args [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return arg <TAB><TAB>  return ExprCompose ( arg , ExprInt ( 0 , expr . size - arg . size ) ) <TAB>  if expr . op . startswith ( "" signExt_ "" ) : <TAB><TAB>  arg = expr . args [ 0 ] <TAB><TAB>  add_size = expr . size - arg . size <TAB><TAB>  new_expr = ExprCompose ( <TAB><TAB><TAB>  arg , <TAB><TAB><TAB>  ExprCond ( <TAB><TAB><TAB><TAB>  arg . msb ( ) , ExprInt ( size2mask ( add_size ) , add_size ) , ExprInt ( 0 , add_size ) <TAB><TAB><TAB>  ) , <TAB><TAB>  ) <TAB><TAB>  return new_expr <TAB>  return expr ",if expr . size == arg . size :,if arg.size == 0:,False,37.27523490822077,97.42409777083323
2501,"def mark_differences ( value : str , compare_against : str ) : <TAB>  result = [ ] <TAB>  for i , char in enumerate ( value ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result . append ( ' <font color= "" red "" > {} </font> ' . format ( char ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  result . append ( char ) <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  result . append ( char ) <TAB>  return "" "" . join ( result ) ",if char != compare_against [ i ] :,if i == compare_against:,False,48.77025976807974,95.26460641646091
2502,"def run_query ( self , query , user ) : <TAB>  url = "" %s %s "" % ( self . base_url , "" & "" . join ( query . split ( "" \n "" ) ) ) <TAB>  error = None <TAB>  data = None <TAB>  try : <TAB><TAB>  response = requests . get ( url , auth = self . auth , verify = self . verify ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = _transform_result ( response ) <TAB><TAB>  else : <TAB><TAB><TAB>  error = "" Failed getting results ( %d ) "" % response . status_code <TAB>  except Exception as ex : <TAB><TAB>  data = None <TAB><TAB>  error = str ( ex ) <TAB>  return data , error ",if response . status_code == 200 :,if response.status_code == 200:,False,50.79034003717682,100.00000000000004
2503,"def on_enter ( self ) : <TAB>  """"""Fired when mouse enter the bbox of the widget."""""" <TAB>  if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . md_bg_color = self . theme_cls . bg_normal <TAB><TAB>  else : <TAB><TAB><TAB>  if not self . focus_color : <TAB><TAB><TAB><TAB>  self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . md_bg_color = self . focus_color ","if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",if not self.focus_color:,False,52.83299626815106,93.55308679476266
2504,"def tearDown ( self ) : <TAB>  if not self . is_playback ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB><TAB>  try : <TAB><TAB><TAB>  if self . storage_account_name is not None : <TAB><TAB><TAB><TAB>  self . sms . delete_storage_account ( self . storage_account_name ) <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB><TAB>  try : <TAB><TAB><TAB>  self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB>  return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( ) ",if self . hosted_service_name is not None :,if self.hosted_service_name is not None:,False,28.04071769660349,100.00000000000004
2505,"def name2cp ( k ) : <TAB>  if k == "" apos "" : <TAB><TAB>  return ord ( "" ' "" ) <TAB>  if hasattr ( htmlentitydefs , "" name2codepoint "" ) :<TAB># requires Python 2.3 <TAB><TAB>  return htmlentitydefs . name2codepoint [ k ] <TAB>  else : <TAB><TAB>  k = htmlentitydefs . entitydefs [ k ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return int ( k [ 2 : - 1 ] )<TAB># not in latin-1 <TAB><TAB>  return ord ( codecs . latin_1_decode ( k ) [ 0 ] ) ","if k . startswith ( ""&#"" ) and k . endswith ( "";"" ) :",if k.endswith('_'):,False,23.980702966483815,86.7206629266294
2506,"def _para_set ( self , params , part ) : <TAB>  if len ( params ) == 0 : <TAB><TAB>  result = suggest ( [ i . get_name ( ) for i in self . _options ] , part ) <TAB><TAB>  return result <TAB>  elif len ( params ) == 1 : <TAB><TAB>  paramName = params [ 0 ] <TAB><TAB>  if paramName not in self . _options : <TAB><TAB><TAB>  return [ ] <TAB><TAB>  opt = self . _options [ paramName ] <TAB><TAB>  paramType = opt . get_type ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values = [ opt . get_default_value ( ) == "" True "" and "" False "" or "" True "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  values = self . _memory [ paramName ] <TAB><TAB>  return suggest ( values , part ) <TAB>  else : <TAB><TAB>  return [ ] ","if paramType == ""boolean"" :",if paramType == 'True':,False,51.714481208922734,98.15037670603655
2507,"def hexcmp ( x , y ) : <TAB>  try : <TAB><TAB>  a = int ( x , 16 ) <TAB><TAB>  b = int ( y , 16 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return - 1 <TAB><TAB>  if a > b : <TAB><TAB><TAB>  return 1 <TAB><TAB>  return 0 <TAB>  except : <TAB><TAB>  return cmp ( x , y ) ",if a < b :,if a < b:,False,51.14293676533549,96.81638556984849
2508,"def execute ( self , statement , arguments = None ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  if arguments : <TAB><TAB><TAB><TAB>  self . cursor . execute ( statement , arguments ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . cursor . execute ( statement ) <TAB><TAB>  except sqlite3 . OperationalError as ex : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB><TAB>  return self . cursor . fetchall ( ) ","if ""locked"" not in getSafeExString ( ex ) :",if ex.code == sqlite3.OperationalError.Code.OperationalError:,False,48.5939278622061,93.07275234017182
2509,"def _test_forever ( self , tests ) : <TAB>  while True : <TAB><TAB>  for test_name in tests : <TAB><TAB><TAB>  yield test_name <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  if self . ns . fail_env_changed and self . environment_changed : <TAB><TAB><TAB><TAB>  return ",if self . bad :,if self.ns.fail_test_changed and self.environment_changed:,False,24.37577770537723,87.85002444703072
2510,"def removeUser ( self , username ) : <TAB>  hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB>  if username in self . _users : <TAB><TAB>  user = self . _users [ username ] <TAB><TAB>  if user . room : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB>  if username in self . _users : <TAB><TAB>  self . _users . pop ( username ) <TAB><TAB>  message = getMessage ( "" left-notification "" ) . format ( username ) <TAB><TAB>  self . ui . showMessage ( message , hideFromOSD ) <TAB><TAB>  self . _client . lastLeftTime = time . time ( ) <TAB><TAB>  self . _client . lastLeftUser = username <TAB>  self . userListChange ( ) ",if self . isRoomSame ( user . room ) :,if not user.isOnline():,False,22.244270800089033,96.28566089832414
2511,"def AutoTest ( ) : <TAB>  with open ( sys . argv [ 1 ] , "" rb "" ) as f : <TAB><TAB>  for line in f . read ( ) . split ( b "" \n "" ) : <TAB><TAB><TAB>  line = BYTES2SYSTEMSTR ( line . strip ( ) ) <TAB><TAB><TAB>  if not line : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  elif line . startswith ( "" # "" ) : <TAB><TAB><TAB><TAB>  print ( line ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  print ( "" >>>  "" + line ) <TAB><TAB><TAB><TAB>  os . system ( line ) <TAB><TAB><TAB><TAB>  sys . stdout . write ( "" \n press enter to continue... "" ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  input ( ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  raw_input ( ) <TAB><TAB><TAB><TAB>  sys . stdout . write ( "" \n "" ) ",if PY3 :,if sys.platform == 'win32':,False,42.77596405680203,96.36993487921193
2512,"def get_first_field ( layout , clz ) : <TAB>  for layout_object in layout . fields : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return layout_object <TAB><TAB>  elif hasattr ( layout_object , "" get_field_names "" ) : <TAB><TAB><TAB>  gf = get_first_field ( layout_object , clz ) <TAB><TAB><TAB>  if gf : <TAB><TAB><TAB><TAB>  return gf ","if issubclass ( layout_object . __class__ , clz ) :",if layout_object.is_class_class(clz):,False,48.18722817053083,92.73541967350954
2513,"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB>  # Sanity check: Don't honor keys that we don't recognize. <TAB>  for key in list ( kwargs . keys ( ) ) : <TAB><TAB>  if key not in valid_keys : <TAB><TAB><TAB>  kwargs . pop ( key ) <TAB>  # Truncate certain values over 1k <TAB>  for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB><TAB>  if isinstance ( kwargs . get ( "" event_data "" , { } ) . get ( key ) , str ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB><TAB><TAB><TAB><TAB>  1024 <TAB><TAB><TAB><TAB>  ) ","if len ( kwargs [ ""event_data"" ] [ key ] ) > 1024 :",if key not in kwargs:,False,35.282374280131634,92.58233465390205
2514,"def visit_productionlist ( self , node ) : <TAB>  self . new_state ( ) <TAB>  names = [ ] <TAB>  for production in node : <TAB><TAB>  names . append ( production [ "" tokenname "" ] ) <TAB>  maxlen = max ( len ( name ) for name in names ) <TAB>  for production in node : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add_text ( production [ "" tokenname "" ] . ljust ( maxlen ) + ""  ::= "" ) <TAB><TAB><TAB>  lastname = production [ "" tokenname "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  self . add_text ( "" %s<TAB>  "" % ( "" "" * len ( lastname ) ) ) <TAB><TAB>  self . add_text ( production . astext ( ) + self . nl ) <TAB>  self . end_state ( wrap = False ) <TAB>  raise nodes . SkipNode ","if production [ ""tokenname"" ] :",if len(production['tokenname']) > maxlen:,False,48.62678177989832,95.75769047341535
2515,"def uuid ( self ) : <TAB>  if not getattr ( self , "" _uuid "" , None ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _uuid = self . repository . _kp_uuid ( <TAB><TAB><TAB><TAB>  self . path <TAB><TAB><TAB>  )<TAB># Use repository UUID (even if None) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _uuid = str ( uuid . uuid4 ( ) ) <TAB>  return self . _uuid ",if self . repository is not None :,if self.repository:,False,53.16068923547863,95.37116348418688
2516,"def remove ( self , values ) : <TAB>  if not isinstance ( values , ( list , tuple , set ) ) : <TAB><TAB>  values = [ values ] <TAB>  for v in values : <TAB><TAB>  v = str ( v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _definition . pop ( v , None ) <TAB><TAB>  elif self . _definition == "" ANY "" : <TAB><TAB><TAB>  if v == "" ANY "" : <TAB><TAB><TAB><TAB>  self . _definition = [ ] <TAB><TAB>  elif v in self . _definition : <TAB><TAB><TAB>  self . _definition . remove ( v ) <TAB>  if ( <TAB><TAB>  self . _value is not None <TAB><TAB>  and self . _value not in self . _definition <TAB><TAB>  and self . _not_any ( ) <TAB>  ) : <TAB><TAB>  raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) ) ","if isinstance ( self . _definition , dict ) :","if self._definition == ""NONE':",False,19.636933658959535,96.96939284622557
2517,"def make ( self ) : <TAB>  pygments_dir = join ( self . dir , "" externals "" , "" pygments "" ) <TAB>  if exists ( pygments_dir ) : <TAB><TAB>  run_in_dir ( "" hg pull "" , pygments_dir , self . log . info ) <TAB><TAB>  run_in_dir ( "" hg update "" , pygments_dir , self . log . info ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( dirname ( pygments_dir ) ) <TAB><TAB>  run_in_dir ( <TAB><TAB><TAB>  "" hg clone http://dev.pocoo.org/hg/pygments-main  %s "" <TAB><TAB><TAB>  % basename ( pygments_dir ) , <TAB><TAB><TAB>  dirname ( pygments_dir ) , <TAB><TAB><TAB>  self . log . info , <TAB><TAB>  ) ",if not exists ( dirname ( pygments_dir ) ) :,if not exists(dirname(pygments_dir)):,False,50.89523854183117,100.00000000000004
2518,def set_field ( self ) : <TAB>  i = 0 <TAB>  for string in self . display_string : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . config [ self . field + str ( i ) ] = self . conversion_fn ( self . str [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . config [ self . field + str ( i ) ] = self . str [ i ] <TAB><TAB>  i = i + 1 ,if self . conversion_fn :,if self.conversion_fn:,False,55.463106480577885,100.00000000000004
2519,"def cleanup ( self ) : <TAB>  with self . lock : <TAB><TAB>  for proc in self . processes : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  proc . join ( ) <TAB><TAB><TAB>  self . processes . remove ( proc ) <TAB><TAB><TAB>  log . debug ( "" Subprocess  %s  cleaned up "" , proc . name ) ",if proc . is_alive ( ) :,if proc.name == self.process_name:,False,24.97647134965125,91.96850164325535
2520,"def setup ( self , gen ) : <TAB>  Node . setup ( self , gen ) <TAB>  for c in self . children : <TAB><TAB>  c . setup ( gen ) <TAB>  if not self . accepts_epsilon : <TAB><TAB>  # If it's not already accepting epsilon, it might now do so. <TAB><TAB>  for c in self . children : <TAB><TAB><TAB>  # any non-epsilon means all is non-epsilon <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  self . accepts_epsilon = 1 <TAB><TAB><TAB>  gen . changed ( ) ",if not c . accepts_epsilon :,if c.accepts(gen):,False,64.89679073263768,96.39925897923358
2521,"def __call__ ( self , message ) : <TAB>  with self . _lock : <TAB><TAB>  self . _pending_ack + = 1 <TAB><TAB>  self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB><TAB>  self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB>  time . sleep ( self . _processing_time ) <TAB>  with self . _lock : <TAB><TAB>  self . _pending_ack - = 1 <TAB><TAB>  message . ack ( ) <TAB><TAB>  self . completed_calls + = 1 <TAB><TAB>  if self . completed_calls > = self . _resolve_at_msg_count : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . done_future . set_result ( None ) ",if not self . done_future . done ( ) :,if self.done_future:,False,18.745653707842617,96.47954744554501
2522,"def build_canned_image_list ( path ) : <TAB>  layers_path = get_bitbake_var ( "" BBLAYERS "" ) <TAB>  canned_wks_layer_dirs = [ ] <TAB>  if layers_path is not None : <TAB><TAB>  for layer_path in layers_path . split ( ) : <TAB><TAB><TAB>  for wks_path in ( WIC_DIR , SCRIPTS_CANNED_IMAGE_DIR ) : <TAB><TAB><TAB><TAB>  cpath = os . path . join ( layer_path , wks_path ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  canned_wks_layer_dirs . append ( cpath ) <TAB>  cpath = os . path . join ( path , CANNED_IMAGE_DIR ) <TAB>  canned_wks_layer_dirs . append ( cpath ) <TAB>  return canned_wks_layer_dirs ",if os . path . isdir ( cpath ) :,if os.path.exists(cpath):,False,52.16525052266678,98.86228284909593
2523,"def _recv_loop ( self ) - > None : <TAB>  async with self . _ws as connection : <TAB><TAB>  self . _connected = True <TAB><TAB>  self . connection = connection <TAB><TAB>  while self . _connected : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  resp = await self . connection . recv ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  await self . _on_message ( resp ) <TAB><TAB><TAB>  except ( websockets . ConnectionClosed , ConnectionResetError ) : <TAB><TAB><TAB><TAB>  logger . info ( "" connection closed "" ) <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  await asyncio . sleep ( 0 ) <TAB>  if self . _connected : <TAB><TAB>  self . _loop . create_task ( self . dispose ( ) ) ",if resp :,if resp:,False,49.96307854233767,100.00000000000004
2524,"def _get_between ( content , start , end = None ) : <TAB>  should_yield = False <TAB>  for line in content . split ( "" \n "" ) : <TAB><TAB>  if start in line : <TAB><TAB><TAB>  should_yield = True <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  if should_yield and line : <TAB><TAB><TAB>  yield line . strip ( ) . split ( "" "" ) [ 0 ] ",if end and end in line :,if end is None:,False,39.96194731094355,95.84326417920977
2525,"def handle_parse_result ( self , ctx , opts , args ) : <TAB>  if self . name in opts : <TAB><TAB>  if self . mutually_exclusive . intersection ( opts ) : <TAB><TAB><TAB>  self . _raise_exclusive_error ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _raise_exclusive_error ( ) <TAB>  return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args ) ",if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,if self.exclusive_exclusive.intersection(opts):,False,20.508642765373967,87.29625987546379
2526,"def write ( self , s ) : <TAB>  if self . interactive : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . active_mode . write ( s ) <TAB><TAB>  else : <TAB><TAB><TAB>  component . get ( "" CmdLine "" ) . add_line ( s , False ) <TAB><TAB><TAB>  self . events . append ( s ) <TAB>  else : <TAB><TAB>  print ( colors . strip_colors ( s ) ) ","if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :",if self.active_mode:,False,22.223422069506157,86.09119873503235
2527,"def findfiles ( path ) : <TAB>  files = [ ] <TAB>  for name in os . listdir ( path ) : <TAB><TAB>  # ignore hidden files/dirs and other unwanted files <TAB><TAB>  if name . startswith ( "" . "" ) or name == "" lastsnap.jpg "" : <TAB><TAB><TAB>  continue <TAB><TAB>  pathname = os . path . join ( path , name ) <TAB><TAB>  st = os . lstat ( pathname ) <TAB><TAB>  mode = st . st_mode <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  files . extend ( findfiles ( pathname ) ) <TAB><TAB>  elif stat . S_ISREG ( mode ) : <TAB><TAB><TAB>  files . append ( ( pathname , name , st ) ) <TAB>  return files ",if stat . S_ISDIR ( mode ) :,if mode == 'nt':,False,57.50500859778516,95.28017843855501
2528,"def _get_documented_completions ( self , table , startswith = None ) : <TAB>  names = [ ] <TAB>  for key , command in table . items ( ) : <TAB><TAB>  if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB><TAB><TAB>  # Don't tab complete undocumented commands/params <TAB><TAB><TAB>  continue <TAB><TAB>  if startswith is not None and not key . startswith ( startswith ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  names . append ( key ) <TAB>  return names ","if getattr ( command , ""positional_arg"" , False ) :",if key in names:,False,59.80265470400309,91.42449922662958
2529,"def fix_newlines ( lines ) : <TAB>  """"""Convert newlines to unix."""""" <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lines [ i ] = line [ : - 2 ] + "" \n "" <TAB><TAB>  elif line . endswith ( "" \r "" ) : <TAB><TAB><TAB>  lines [ i ] = line [ : - 1 ] + "" \n "" ","if line . endswith ( ""\r\n"" ) :",if line.endswith('\n'):,False,48.064258371139836,89.49157851632499
2530,"def GeneratePageMetatadata ( self , task ) : <TAB>  address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB>  for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB><TAB>  start = vma . vm_start <TAB><TAB>  end = vma . vm_end <TAB><TAB>  # Skip the entire region. <TAB><TAB>  if end < self . plugin_args . start : <TAB><TAB><TAB>  continue <TAB><TAB>  # Done. <TAB><TAB>  if start > self . plugin_args . end : <TAB><TAB><TAB>  break <TAB><TAB>  for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) ) ",if self . plugin_args . start <= vaddr <= self . plugin_args . end :,if address_space.is_vtop(vaddr):,False,51.78863773320913,91.5522964013732
2531,"def get_shape_at_node ( self , node , assumptions ) : <TAB>  for k , v in assumptions . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return v <TAB>  if node . inputs : <TAB><TAB>  return node . container . shape ( <TAB><TAB><TAB>  input_shapes = [ <TAB><TAB><TAB><TAB>  self . get_shape_at_node ( input_node , assumptions ) <TAB><TAB><TAB><TAB>  for input_node in node . inputs <TAB><TAB><TAB>  ] <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return node . container . shape ( None ) ",if k in node . names :,if k == node.name:,False,51.136885731083446,96.67213501712308
2532,"def fix_doc ( self , doc ) : <TAB>  type = doc . get ( "" type "" , { } ) . get ( "" key "" ) <TAB>  if type == "" /type/work "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # some record got empty author records because of an error <TAB><TAB><TAB>  # temporary hack to fix <TAB><TAB><TAB>  doc [ "" authors "" ] = [ <TAB><TAB><TAB><TAB>  a for a in doc [ "" authors "" ] if "" author "" in a and "" key "" in a [ "" author "" ] <TAB><TAB><TAB>  ] <TAB>  elif type == "" /type/edition "" : <TAB><TAB>  # get rid of title_prefix. <TAB><TAB>  if "" title_prefix "" in doc : <TAB><TAB><TAB>  title = doc [ "" title_prefix "" ] . strip ( ) + "" "" + doc . get ( "" title "" , "" "" ) <TAB><TAB><TAB>  doc [ "" title "" ] = title . strip ( ) <TAB><TAB><TAB>  del doc [ "" title_prefix "" ] <TAB>  return doc ","if doc . get ( ""authors"" ) :","if type == ""/type/author':",False,37.59604525648157,96.76791212574112
2533,"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB>  for i in range ( len ( column ) ) : <TAB><TAB>  gate = column [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  elif isinstance ( gate , ParityControlCell ) : <TAB><TAB><TAB>  # The first parity control to modify the column must merge all <TAB><TAB><TAB>  # of the other parity controls into itself. <TAB><TAB><TAB>  column [ i ] = None <TAB><TAB><TAB>  self . _basis_change + = gate . _basis_change <TAB><TAB><TAB>  self . qubits + = gate . qubits <TAB><TAB>  elif gate is not None : <TAB><TAB><TAB>  column [ i ] = gate . controlled_by ( self . qubits [ 0 ] ) ",if gate is self :,if not gate:,False,32.816163863262126,97.99599876649637
2534,"def onSync ( self , auto = False , reload = True ) : <TAB>  if not auto or ( <TAB><TAB>  self . pm . profile [ "" syncKey "" ] and self . pm . profile [ "" autoSync "" ] and not self . safeMode <TAB>  ) : <TAB><TAB>  from aqt . sync import SyncManager <TAB><TAB>  if not self . unloadCollection ( ) : <TAB><TAB><TAB>  return <TAB><TAB>  # set a sync state so the refresh timer doesn't fire while deck <TAB><TAB>  # unloaded <TAB><TAB>  self . state = "" sync "" <TAB><TAB>  self . syncer = SyncManager ( self , self . pm ) <TAB><TAB>  self . syncer . sync ( ) <TAB>  if reload : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . loadCollection ( ) ",if not self . col :,if not self.loaded:,False,61.40233062993505,98.7227748200473
2535,"def _has_url_match ( self , match , request_url ) : <TAB>  url = match [ "" url "" ] <TAB>  if _is_string ( url ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _has_strict_url_match ( url , request_url ) <TAB><TAB>  else : <TAB><TAB><TAB>  url_without_qs = request_url . split ( "" ? "" , 1 ) [ 0 ] <TAB><TAB><TAB>  return url == url_without_qs <TAB>  elif isinstance ( url , re . _pattern_type ) and url . match ( request_url ) : <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  return False ","if match [ ""match_querystring"" ] :",if re._pattern_type is not None:,False,43.1644722522314,94.43580131589786
2536,"def pool_image ( self , image ) : <TAB>  if self . count < self . pool_size : <TAB><TAB>  self . pool . append ( image ) <TAB><TAB>  self . count + = 1 <TAB><TAB>  return image <TAB>  else : <TAB><TAB>  p = random . random ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  random_id = random . randint ( 0 , self . pool_size - 1 ) <TAB><TAB><TAB>  temp = self . pool [ random_id ] <TAB><TAB><TAB>  self . pool [ random_id ] = image <TAB><TAB><TAB>  return temp <TAB><TAB>  else : <TAB><TAB><TAB>  return image ",if p > 0.5 :,if p in self.pool:,False,20.428886774698142,96.98038122635303
2537,"def get_target_dimensions ( self ) : <TAB>  width , height = self . engine . size <TAB>  for operation in self . operations : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  width = operation [ "" right "" ] - operation [ "" left "" ] <TAB><TAB><TAB>  height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB><TAB>  if operation [ "" type "" ] == "" resize "" : <TAB><TAB><TAB>  width = operation [ "" width "" ] <TAB><TAB><TAB>  height = operation [ "" height "" ] <TAB>  return ( width , height ) ","if operation [ ""type"" ] == ""crop"" :","if operation['type'] == ""resize':",False,15.685691139966224,94.96351887045684
2538,"def validate_matrix ( matrix ) : <TAB>  if not matrix : <TAB><TAB>  return None <TAB>  for key , value in matrix . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB>  "" ` {} ` defines a non uniform distribution,  "" <TAB><TAB><TAB><TAB>  "" and it cannot be used with bayesian optimization. "" . format ( key ) <TAB><TAB><TAB>  ) <TAB>  return matrix ",if value . is_distribution and not value . is_uniform :,if value < 0:,False,34.09659824893192,90.54898753829168
2539,"def scm_to_conandata ( self ) : <TAB>  try : <TAB><TAB>  scm_to_conandata = get_env ( "" CONAN_SCM_TO_CONANDATA "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  scm_to_conandata = self . get_item ( "" general.scm_to_conandata "" ) <TAB><TAB>  return scm_to_conandata . lower ( ) in ( "" 1 "" , "" true "" ) <TAB>  except ConanException : <TAB><TAB>  return False ",if scm_to_conandata is None :,if scm_to_conandata is None:,False,51.30093455623326,100.00000000000004
2540,"def _link_vrf_table ( self , vrf_table , rt_list ) : <TAB>  route_family = vrf_table . route_family <TAB>  for rt in rt_list : <TAB><TAB>  rt_rf_id = rt + "" : "" + str ( route_family ) <TAB><TAB>  table_set = self . _tables_for_rt . get ( rt_rf_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  table_set = set ( ) <TAB><TAB><TAB>  self . _tables_for_rt [ rt_rf_id ] = table_set <TAB><TAB>  table_set . add ( vrf_table ) <TAB><TAB>  LOG . debug ( "" Added VrfTable  %s  to import RT table list:  %s "" , vrf_table , rt ) ",if table_set is None :,if table_set is None:,False,58.98837921903771,100.00000000000004
2541,"def add_tags ( <TAB>  self , cve_results : Dict [ str , Dict [ str , Dict [ str , str ] ] ] , file_object : FileObject  ) : <TAB>  # results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}} <TAB>  for component in cve_results : <TAB><TAB>  for cve_id in cve_results [ component ] : <TAB><TAB><TAB>  entry = cve_results [ component ] [ cve_id ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . add_analysis_tag ( <TAB><TAB><TAB><TAB><TAB>  file_object , "" CVE "" , "" critical CVE "" , TagColor . RED , True <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  return ",if self . _entry_has_critical_rating ( entry ) :,if entry['cve_id'] == cve_id:,False,58.001388640842144,93.66887645863072
2542,"def _validate ( self ) : <TAB>  try : <TAB><TAB>  super ( CustomClassifier , self ) . _validate ( ) <TAB>  except UnsupportedDataType : <TAB><TAB>  if self . dtype in FACTOR_DTYPES : <TAB><TAB><TAB>  raise UnsupportedDataType ( <TAB><TAB><TAB><TAB>  typename = type ( self ) . __name__ , <TAB><TAB><TAB><TAB>  dtype = self . dtype , <TAB><TAB><TAB><TAB>  hint = "" Did you mean to create a CustomFactor? "" , <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise UnsupportedDataType ( <TAB><TAB><TAB><TAB>  typename = type ( self ) . __name__ , <TAB><TAB><TAB><TAB>  dtype = self . dtype , <TAB><TAB><TAB><TAB>  hint = "" Did you mean to create a CustomFilter? "" , <TAB><TAB><TAB>  ) <TAB><TAB>  raise ",elif self . dtype in FILTER_DTYPES :,if self.dtype in FACTOR_DTYPES:,False,59.90514112128176,97.99582042769217
2543,"def formatMessage ( self , record ) : <TAB>  recordcopy = copy ( record ) <TAB>  levelname = recordcopy . levelname <TAB>  seperator = "" "" * ( 8 - len ( recordcopy . levelname ) ) <TAB>  if self . use_colors : <TAB><TAB>  levelname = self . color_level_name ( levelname , recordcopy . levelno ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  recordcopy . msg = recordcopy . __dict__ [ "" color_message "" ] <TAB><TAB><TAB>  recordcopy . __dict__ [ "" message "" ] = recordcopy . getMessage ( ) <TAB>  recordcopy . __dict__ [ "" levelprefix "" ] = levelname + "" : "" + seperator <TAB>  return super ( ) . formatMessage ( recordcopy ) ","if ""color_message"" in recordcopy . __dict__ :",if levelname in self.color_names:,False,29.547006457130507,92.73302740501161
2544,"def dumpregs ( self ) : <TAB>  for reg in ( <TAB><TAB>  list ( self . regs . retaddr ) <TAB><TAB>  + list ( self . regs . misc ) <TAB><TAB>  + list ( self . regs . common ) <TAB><TAB>  + list ( self . regs . flags ) <TAB>  ) : <TAB><TAB>  enum = self . get_reg_enum ( reg ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  debug ( "" # Could not dump register  %r "" % reg ) <TAB><TAB><TAB>  continue <TAB><TAB>  name = "" U.x86_const.UC_X86_REG_ %s "" % reg . upper ( ) <TAB><TAB>  value = self . uc . reg_read ( enum ) <TAB><TAB>  debug ( "" uc.reg_read( %(name)s ) ==>  %(value)x "" % locals ( ) ) ",if not reg or enum is None :,if enum is None:,False,36.21084472315909,97.98274897023363
2545,"def filter ( self , lexer , stream ) : <TAB>  current_type = None <TAB>  current_value = None <TAB>  for ttype , value in stream : <TAB><TAB>  if ttype is current_type : <TAB><TAB><TAB>  current_value + = value <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield current_type , current_value <TAB><TAB><TAB>  current_type = ttype <TAB><TAB><TAB>  current_value = value <TAB>  <IF-STMT>: <TAB><TAB>  yield current_type , current_value ",if current_type is not None :,if current_value is not None:,False,31.2105617394081,93.11803235105523
2546,"def _get_between ( content , start , end = None ) : <TAB>  should_yield = False <TAB>  for line in content . split ( "" \n "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  should_yield = True <TAB><TAB><TAB>  continue <TAB><TAB>  if end and end in line : <TAB><TAB><TAB>  return <TAB><TAB>  if should_yield and line : <TAB><TAB><TAB>  yield line . strip ( ) . split ( "" "" ) [ 0 ] ",if start in line :,if line.startswith('#') or line == line:,False,53.868544600809365,90.51549961563153
2547,"def parse_git_config ( path ) : <TAB>  """"""Parse git config file."""""" <TAB>  config = dict ( ) <TAB>  section = None <TAB>  with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB><TAB>  for line in f : <TAB><TAB><TAB>  line = line . strip ( ) <TAB><TAB><TAB>  if line . startswith ( "" [ "" ) : <TAB><TAB><TAB><TAB>  section = line [ 1 : - 1 ] . strip ( ) <TAB><TAB><TAB><TAB>  config [ section ] = dict ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  key , value = line . replace ( "" "" , "" "" ) . split ( "" = "" ) <TAB><TAB><TAB><TAB>  config [ section ] [ key ] = value <TAB>  return config ",elif section :,if section is not None:,False,28.28329533078592,95.70165025365377
2548,"def test_has_arg ( fn , name , accept_all , expected ) : <TAB>  if isinstance ( fn , str ) : <TAB><TAB>  context = dict ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  exec ( "" def  {} : pass "" . format ( fn ) , context ) <TAB><TAB>  except SyntaxError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  pytest . skip ( "" Function is not compatible with Python 2 "" ) <TAB><TAB>  # Sometimes exec adds builtins to the context <TAB><TAB>  context . pop ( "" __builtins__ "" , None ) <TAB><TAB>  ( fn , ) = context . values ( ) <TAB>  assert has_arg ( fn , name , accept_all ) is expected ","if sys . version_info >= ( 3 , ) :",if sys.platform == 'win32':,False,56.2744687952335,95.04228774749
2549,"def ObjectExpression ( self , properties , * * kwargs ) : <TAB>  data = [ ] <TAB>  for prop in properties : <TAB><TAB>  self . emit ( prop [ "" value "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise NotImplementedError ( <TAB><TAB><TAB><TAB>  "" ECMA 5.1 does not support computed object properties! "" <TAB><TAB><TAB>  ) <TAB><TAB>  data . append ( ( to_key ( prop [ "" key "" ] ) , prop [ "" kind "" ] [ 0 ] ) ) <TAB>  self . emit ( "" LOAD_OBJECT "" , tuple ( data ) ) ","if prop [ ""computed"" ] :",if not prop['value']:,False,27.802617654769463,96.24053648948545
2550,"def run ( self ) : <TAB>  for domain , locale , po in self . locales : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = os . path . join ( "" locale "" , locale , "" LC_MESSAGES "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  path = os . path . join ( self . build_dir , locale , "" LC_MESSAGES "" ) <TAB><TAB>  mo = os . path . join ( path , "" %s .mo "" % domain ) <TAB><TAB>  self . mkpath ( path ) <TAB><TAB>  self . spawn ( [ "" msgfmt "" , "" -o "" , mo , po ] ) ",if self . inplace :,if locale == 'en':,False,48.66274926641904,96.5439169011198
2551,"def _compute_map ( self , first_byte , second_byte = None ) : <TAB>  if first_byte != 0x0F : <TAB><TAB>  return "" XED_ILD_MAP0 "" <TAB>  else : <TAB><TAB>  if second_byte == None : <TAB><TAB><TAB>  return "" XED_ILD_MAP1 "" <TAB><TAB>  if second_byte == 0x38 : <TAB><TAB><TAB>  return "" XED_ILD_MAP2 "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" XED_ILD_MAP3 "" <TAB><TAB>  if second_byte == 0x0F and self . amd_enabled : <TAB><TAB><TAB>  return "" XED_ILD_MAPAMD "" <TAB>  die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) ) ",if second_byte == 0x3A :,if first_byte == 0x0F and second_byte == 0x0F:,False,57.68698337090975,94.81170286145944
2552,"def parse_tag ( self ) : <TAB>  buf = [ ] <TAB>  escaped = False <TAB>  for c in self . get_next_chars ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  buf . append ( c ) <TAB><TAB>  elif c == "" \\ "" : <TAB><TAB><TAB>  escaped = True <TAB><TAB>  elif c == "" > "" : <TAB><TAB><TAB>  return "" "" . join ( buf ) <TAB><TAB>  else : <TAB><TAB><TAB>  buf . append ( c ) <TAB>  raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) ) ",if escaped :,if escaped:,False,52.30966564193239,100.00000000000004
2553,"def print_pairs ( attrs = None , offset_y = 0 ) : <TAB>  fmt = ""  ( {0} : {1} )  "" <TAB>  fmt_len = len ( fmt ) <TAB>  for bg , fg in get_fg_bg ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  color = curses . color_pair ( pair_number ( fg , bg ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for attr in attrs : <TAB><TAB><TAB><TAB><TAB>  color | = attr <TAB><TAB><TAB>  screen . addstr ( offset_y + bg , fg * fmt_len , fmt . format ( fg , bg ) , color ) <TAB><TAB><TAB>  pass <TAB><TAB>  except curses . error : <TAB><TAB><TAB>  pass ",if not attrs is None :,if attrs is not None:,False,46.84244623458022,98.3174807063677
2554,"def _impl ( inputs , input_types ) : <TAB>  data = inputs [ 0 ] <TAB>  axis = None <TAB>  keepdims = False <TAB>  if len ( inputs ) > 2 :<TAB># default, torch have only data, axis=None, keepdims=False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  axis = int ( inputs [ 1 ] ) <TAB><TAB>  elif _is_int_seq ( inputs [ 1 ] ) : <TAB><TAB><TAB>  axis = inputs [ 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  axis = list ( _infer_shape ( inputs [ 1 ] ) ) <TAB><TAB>  keepdims = bool ( inputs [ 2 ] ) <TAB>  return get_relay_op ( name ) ( data , axis = axis , keepdims = keepdims ) ","if isinstance ( inputs [ 1 ] , int ) :","if _is_int_seq(inputs[1], inputs[2]):",False,52.45288544801785,91.65876156975962
2555,"def run ( self , args , * * kwargs ) : <TAB>  # Filtering options <TAB>  if args . trace_tag : <TAB><TAB>  kwargs [ "" trace_tag "" ] = args . trace_tag <TAB>  if args . trigger_instance : <TAB><TAB>  kwargs [ "" trigger_instance "" ] = args . trigger_instance <TAB>  if args . execution : <TAB><TAB>  kwargs [ "" execution "" ] = args . execution <TAB>  if args . rule : <TAB><TAB>  kwargs [ "" rule "" ] = args . rule <TAB>  if args . sort_order : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs [ "" sort_asc "" ] = True <TAB><TAB>  elif args . sort_order in [ "" desc "" , "" descending "" ] : <TAB><TAB><TAB>  kwargs [ "" sort_desc "" ] = True <TAB>  return self . manager . query_with_count ( limit = args . last , * * kwargs ) ","if args . sort_order in [ ""asc"" , ""ascending"" ] :","if args.sort_order in ['asc', 'desc']:",False,5.607212554491352,96.58981344489956
2556,def retaddr ( ) : <TAB>  sp = pwndbg . regs . sp <TAB>  stack = pwndbg . vmmap . find ( sp ) <TAB>  # Enumerate all return addresses <TAB>  frame = gdb . newest_frame ( ) <TAB>  addresses = [ ] <TAB>  while frame : <TAB><TAB>  addresses . append ( frame . pc ( ) ) <TAB><TAB>  frame = frame . older ( ) <TAB>  # Find all of them on the stack <TAB>  start = stack . vaddr <TAB>  stop = start + stack . memsz <TAB>  while addresses and start < sp < stop : <TAB><TAB>  value = pwndbg . memory . u ( sp ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  index = addresses . index ( value ) <TAB><TAB><TAB>  del addresses [ : index ] <TAB><TAB><TAB>  print ( pwndbg . chain . format ( sp ) ) <TAB><TAB>  sp + = pwndbg . arch . ptrsize ,if value in addresses :,if value in addresses:,False,59.357667436719005,100.00000000000004
2557,"def update_from_dictio ( self , dictio_item ) : <TAB>  for index , dictio_payload in enumerate ( dictio_item , 1 ) : <TAB><TAB>  fuzz_payload = None <TAB><TAB>  for fuzz_payload in self . payloads [ index ] : <TAB><TAB><TAB>  fuzz_payload . content = dictio_payload . content <TAB><TAB><TAB>  fuzz_payload . type = dictio_payload . type <TAB><TAB>  # payload generated not used in seed but in filters <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add ( <TAB><TAB><TAB><TAB>  { "" full_marker "" : None , "" word "" : None , "" index "" : index , "" field "" : None } , <TAB><TAB><TAB><TAB>  dictio_item [ index - 1 ] , <TAB><TAB><TAB>  ) ",if fuzz_payload is None :,if index > 0:,False,58.08370996390791,96.95334968592377
2558,"def check_expected ( result , expected , contains = False ) : <TAB>  if sys . version_info [ 0 ] > = 3 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = result . encode ( "" ascii "" ) <TAB><TAB>  if isinstance ( expected , str ) : <TAB><TAB><TAB>  expected = expected . encode ( "" ascii "" ) <TAB>  resultlines = result . splitlines ( ) <TAB>  expectedlines = expected . splitlines ( ) <TAB>  if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB>  return False <TAB>  for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB>  if contains : <TAB><TAB><TAB>  if eline not in rline : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ","if isinstance ( result , str ) :","if isinstance(result, str):",False,49.47802890890776,100.00000000000004
2559,"def execute_sql ( self , sql , params = None , commit = True ) : <TAB>  try : <TAB><TAB>  cursor = super ( RetryOperationalError , self ) . execute_sql ( sql , params , commit ) <TAB>  except OperationalError : <TAB><TAB>  if not self . is_closed ( ) : <TAB><TAB><TAB>  self . close ( ) <TAB><TAB>  with __exception_wrapper__ : <TAB><TAB><TAB>  cursor = self . cursor ( ) <TAB><TAB><TAB>  cursor . execute ( sql , params or ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . commit ( ) <TAB>  return cursor ",if commit and not self . in_transaction ( ) :,if commit:,False,44.78429607177229,93.95836182773571
2560,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB>  operation = None <TAB>  for definition in document_ast . definitions : <TAB><TAB>  if isinstance ( definition , ast . OperationDefinition ) : <TAB><TAB><TAB>  if not operation_name : <TAB><TAB><TAB><TAB>  # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB>  # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB>  # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB><TAB>  operation = definition <TAB><TAB><TAB>  elif definition . name and definition . name . value == operation_name : <TAB><TAB><TAB><TAB>  return definition <TAB>  return operation ",if operation :,if not definition:,False,75.32295020901786,98.6108515911854
2561,"def removeTrailingWs ( self , aList ) : <TAB>  i = 0 <TAB>  while i < len ( aList ) : <TAB><TAB>  if self . is_ws ( aList [ i ] ) : <TAB><TAB><TAB>  j = i <TAB><TAB><TAB>  i = self . skip_ws ( aList , i ) <TAB><TAB><TAB>  assert j < i <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # print ""removing trailing ws:"", `i-j` <TAB><TAB><TAB><TAB>  del aList [ j : i ] <TAB><TAB><TAB><TAB>  i = j <TAB><TAB>  else : <TAB><TAB><TAB>  i + = 1 ","if i >= len ( aList ) or aList [ i ] == ""\n"" :",if aList[j] == aList[j] and aList[j] ==,False,48.498814139874334,90.93729849034777
2562,"def _process_filter ( self , query , host_state ) : <TAB>  """"""Recursively parse the query structure."""""" <TAB>  if not query : <TAB><TAB>  return True <TAB>  cmd = query [ 0 ] <TAB>  method = self . commands [ cmd ] <TAB>  cooked_args = [ ] <TAB>  for arg in query [ 1 : ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  arg = self . _process_filter ( arg , host_state ) <TAB><TAB>  elif isinstance ( arg , basestring ) : <TAB><TAB><TAB>  arg = self . _parse_string ( arg , host_state ) <TAB><TAB>  if arg is not None : <TAB><TAB><TAB>  cooked_args . append ( arg ) <TAB>  result = method ( self , cooked_args ) <TAB>  return result ","if isinstance ( arg , list ) :","if isinstance(arg, filter.Filter):",False,26.449391563544193,97.84760056298889
2563,"def handle_sent ( self , elt ) : <TAB>  sent = [ ] <TAB>  for child in elt : <TAB><TAB>  if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB><TAB><TAB>  sent + = [ self . handle_word ( w ) for w in child ] <TAB><TAB>  elif child . tag in ( "" w "" , "" c "" ) : <TAB><TAB><TAB>  sent . append ( self . handle_word ( child ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB>  return BNCSentence ( elt . attrib [ "" n "" ] , sent ) ",elif child . tag not in self . tags_to_ignore :,if not sent:,False,45.916550840809364,92.035570628059
2564,"def get_display_price ( <TAB>  base : Union [ TaxedMoney , TaxedMoneyRange ] , display_gross : bool = False  ) - > Money : <TAB>  """"""Return the price amount that should be displayed based on settings."""""" <TAB>  if not display_gross : <TAB><TAB>  display_gross = display_gross_prices ( ) <TAB>  if isinstance ( base , TaxedMoneyRange ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  base = MoneyRange ( start = base . start . gross , stop = base . stop . gross ) <TAB><TAB>  else : <TAB><TAB><TAB>  base = MoneyRange ( start = base . start . net , stop = base . stop . net ) <TAB>  if isinstance ( base , TaxedMoney ) : <TAB><TAB>  base = base . gross if display_gross else base . net <TAB>  return base ",if display_gross :,"if isinstance(base, TaxedMoney):",False,56.660730027719474,96.29143236324381
2565,"def check_classes ( self , node ) : <TAB>  if isinstance ( node , nodes . Element ) : <TAB><TAB>  for class_value in node [ "" classes "" ] [ : ] : <TAB><TAB><TAB>  if class_value in self . strip_classes : <TAB><TAB><TAB><TAB>  node [ "" classes "" ] . remove ( class_value ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return 1 ",if class_value in self . strip_elements :,if node['classes'] == []:,False,25.11025877721692,91.34960751084205
2566,"def validate ( outfile = sys . stdout , silent_success = False ) : <TAB>  "" Validates all installed models. "" <TAB>  try : <TAB><TAB>  num_errors = get_validation_errors ( outfile ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  outfile . write ( <TAB><TAB><TAB>  "" %s  error %s  found. \n "" % ( num_errors , num_errors != 1 and "" s "" or "" "" ) <TAB><TAB>  ) <TAB>  except ImproperlyConfigured : <TAB><TAB>  outfile . write ( "" Skipping validation because things aren ' t configured properly. "" ) ",if silent_success and num_errors == 0 :,if num_errors == 0:,False,39.90971841128292,94.96721816041521
2567,"def check_basename_conflicts ( self , targets ) : <TAB>  """"""Apps' basenames are used as bundle directory names. Ensure they are all unique."""""" <TAB>  basename_seen = { } <TAB>  for target in targets : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise self . BasenameConflictError ( <TAB><TAB><TAB><TAB>  "" Basename must be unique, found two targets use  "" <TAB><TAB><TAB><TAB>  "" the same basename:  {} ' \n \t {}  and  \n \t {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  target . basename , <TAB><TAB><TAB><TAB><TAB>  basename_seen [ target . basename ] . address . spec , <TAB><TAB><TAB><TAB><TAB>  target . address . spec , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  basename_seen [ target . basename ] = target ",if target . basename in basename_seen :,if target.basename not in basename_seen:,False,65.94225941511186,98.99087591895788
2568,"def __init__ ( self , api_version_str ) : <TAB>  try : <TAB><TAB>  self . latest = self . preview = False <TAB><TAB>  self . yyyy = self . mm = self . dd = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . latest = True <TAB><TAB>  else : <TAB><TAB><TAB>  if "" preview "" in api_version_str : <TAB><TAB><TAB><TAB>  self . preview = True <TAB><TAB><TAB>  parts = api_version_str . split ( "" - "" ) <TAB><TAB><TAB>  self . yyyy = int ( parts [ 0 ] ) <TAB><TAB><TAB>  self . mm = int ( parts [ 1 ] ) <TAB><TAB><TAB>  self . dd = int ( parts [ 2 ] ) <TAB>  except ( ValueError , TypeError ) : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB><TAB>  ) ","if api_version_str == ""latest"" :",if not api_version_str:,False,54.72620376853345,97.05462503519568
2569,"def _osp2ec ( self , bytes ) : <TAB>  compressed = self . _from_bytes ( bytes ) <TAB>  y = compressed >> self . _bits <TAB>  x = compressed & ( 1 << self . _bits ) - 1 <TAB>  if x == 0 : <TAB><TAB>  y = self . _curve . b <TAB>  else : <TAB><TAB>  result = self . sqrtp ( <TAB><TAB><TAB>  x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y = result [ 0 ] <TAB><TAB>  elif len ( result ) == 2 : <TAB><TAB><TAB>  y1 , y2 = result <TAB><TAB><TAB>  y = y1 if ( y1 & 1 == y ) else y2 <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  return ec . Point ( self . _curve , x , y ) ",if len ( result ) == 1 :,if len(result) == 1:,False,48.801516549084944,100.00000000000004
2570,"def _visit_import_alike ( self , node : Union [ cst . Import , cst . ImportFrom ] ) - > bool : <TAB>  names = node . names <TAB>  if isinstance ( names , cst . ImportStar ) : <TAB><TAB>  return False <TAB>  # make sure node.names is Sequence[ImportAlias] <TAB>  for name in names : <TAB><TAB>  self . provider . set_metadata ( name , self . scope ) <TAB><TAB>  asname = name . asname <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name_values = _gen_dotted_names ( cst . ensure_type ( asname . name , cst . Name ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  name_values = _gen_dotted_names ( name . name ) <TAB><TAB>  for name_value , _ in name_values : <TAB><TAB><TAB>  self . scope . record_assignment ( name_value , node ) <TAB>  return False ",if asname is not None :,if asname.type is cst.Name:,False,49.94700464631845,96.90315344077845
2571,"def test_sanity_no_unmatched_parentheses ( CorpusType : Type [ ColumnCorpus ] ) : <TAB>  corpus = CorpusType ( ) <TAB>  unbalanced_entities = [ ] <TAB>  for sentence in corpus . get_all_sentences ( ) : <TAB><TAB>  entities = sentence . get_spans ( "" ner "" ) <TAB><TAB>  for entity in entities : <TAB><TAB><TAB>  entity_text = "" "" . join ( t . text for t in entity . tokens ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  unbalanced_entities . append ( entity_text ) <TAB>  assert unbalanced_entities == [ ] ",if not has_balanced_parantheses ( entity_text ) :,if entity_text not in unbalanced_entities:,False,23.344185977319086,93.50757981721559
2572,"def _learn_rate_adjust ( self ) : <TAB>  if self . learn_rate_decays == 1.0 : <TAB><TAB>  return <TAB>  learn_rate_decays = self . _vp ( self . learn_rate_decays ) <TAB>  learn_rate_minimums = self . _vp ( self . learn_rate_minimums ) <TAB>  for index , decay in enumerate ( learn_rate_decays ) : <TAB><TAB>  new_learn_rate = self . net_ . learnRates [ index ] * decay <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . net_ . learnRates [ index ] = new_learn_rate <TAB>  if self . verbose > = 2 : <TAB><TAB>  print ( "" Learn rates:  {} "" . format ( self . net_ . learnRates ) ) ",if new_learn_rate >= learn_rate_minimums [ index ] :,if new_learn_rate != new_learn_rate:,False,27.84798516485117,95.2179900755433
2573,"def set_attr_from_xmp_tag ( self , attr , xmp_tags , tags , cast = None ) : <TAB>  v = self . get_xmp_tag ( xmp_tags , tags ) <TAB>  if v is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( self , attr , v ) <TAB><TAB>  else : <TAB><TAB><TAB>  # Handle fractions <TAB><TAB><TAB>  if ( cast == float or cast == int ) and "" / "" in v : <TAB><TAB><TAB><TAB>  v = self . try_parse_fraction ( v ) <TAB><TAB><TAB>  setattr ( self , attr , cast ( v ) ) ",if cast is None :,if cast is None:,False,56.020605638478905,100.00000000000004
2574,"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB>  tokens = list ( tokens ) <TAB>  i = 0 <TAB>  while "" e "" in tokens [ i + 1 : ] : <TAB><TAB>  i = tokens . index ( "" e "" , i + 1 ) <TAB><TAB>  s = i - 1 <TAB><TAB>  e = i + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB><TAB><TAB>  e + = 1 <TAB><TAB>  if re . match ( "" [0-9] "" , str ( tokens [ e ] ) ) : <TAB><TAB><TAB>  e + = 1 <TAB><TAB><TAB>  tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB><TAB><TAB>  i - = 1 <TAB>  return tokens ","if not re . match ( ""[0-9]"" , str ( tokens [ s ] ) ) :",if s == -1:,False,27.25728525687874,91.38181289368572
2575,"def anypython ( request ) : <TAB>  name = request . param <TAB>  executable = getexecutable ( name ) <TAB>  if executable is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  executable = winpymap . get ( name , None ) <TAB><TAB><TAB>  if executable : <TAB><TAB><TAB><TAB>  executable = py . path . local ( executable ) <TAB><TAB><TAB><TAB>  if executable . check ( ) : <TAB><TAB><TAB><TAB><TAB>  return executable <TAB><TAB>  pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB>  return executable ","if sys . platform == ""win32"" :",if name in winpymap:,False,45.07124928041157,94.12789939375551
2576,"def set_meta ( self , dataset , overwrite = True , * * kwd ) : <TAB>  super ( ) . set_meta ( dataset , overwrite = overwrite , * * kwd ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with tarfile . open ( dataset . file_name , "" r "" ) as temptar : <TAB><TAB><TAB><TAB>  dataset . metadata . fast5_count = sum ( <TAB><TAB><TAB><TAB><TAB>  1 for f in temptar if f . name . endswith ( "" .fast5 "" ) <TAB><TAB><TAB><TAB>  ) <TAB>  except Exception as e : <TAB><TAB>  log . warning ( "" %s , set_meta Exception:  %s "" , self , e ) ",if dataset and tarfile . is_tarfile ( dataset . file_name ) :,if os.path.exists(dataset.file_name):,False,46.478753910371005,95.73134317877056
2577,"def run ( self ) : <TAB>  for k in list ( iterkeys ( self . objs ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  v = self . objs [ k ] <TAB><TAB>  if v [ "" _class "" ] == "" User "" : <TAB><TAB><TAB>  self . split_user ( k , v ) <TAB><TAB>  elif v [ "" _class "" ] in [ <TAB><TAB><TAB>  "" Message "" , <TAB><TAB><TAB>  "" PrintJob "" , <TAB><TAB><TAB>  "" Question "" , <TAB><TAB><TAB>  "" Submission "" , <TAB><TAB><TAB>  "" UserTest "" , <TAB><TAB>  ] : <TAB><TAB><TAB>  v [ "" participation "" ] = v [ "" user "" ] <TAB><TAB><TAB>  del v [ "" user "" ] <TAB>  return self . objs ","if k . startswith ( ""_"" ) :",if k == '_class':,False,48.31164051178709,96.46337406865875
2578,"def _findInTree ( t , n ) : <TAB>  ret = [ ] <TAB>  if type ( t ) is dict : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret . append ( t ) <TAB><TAB>  for k , v in t . items ( ) : <TAB><TAB><TAB>  ret + = _findInTree ( v , n ) <TAB>  if type ( t ) is list : <TAB><TAB>  for v in t : <TAB><TAB><TAB>  ret + = _findInTree ( v , n ) <TAB>  return ret ","if ""_name"" in t and t [ ""_name"" ] == n :",if n == 'root':,False,43.38378946021741,87.81640872733685
2579,"def parseArrayPattern ( self ) : <TAB>  node = Node ( ) <TAB>  elements = [ ] <TAB>  self . expect ( "" [ "" ) <TAB>  while not self . match ( "" ] "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . lex ( ) <TAB><TAB><TAB>  elements . append ( null ) <TAB><TAB>  else : <TAB><TAB><TAB>  if self . match ( "" ... "" ) : <TAB><TAB><TAB><TAB>  restNode = Node ( ) <TAB><TAB><TAB><TAB>  self . lex ( ) <TAB><TAB><TAB><TAB>  rest = self . parseVariableIdentifier ( ) <TAB><TAB><TAB><TAB>  elements . append ( restNode . finishRestElement ( rest ) ) <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  elements . append ( self . parsePatternWithDefault ( ) ) <TAB><TAB><TAB>  if not self . match ( "" ] "" ) : <TAB><TAB><TAB><TAB>  self . expect ( "" , "" ) <TAB>  self . expect ( "" ] "" ) <TAB>  return node . finishArrayPattern ( elements ) ","if self . match ( "","" ) :",if self.match('None'):,False,31.822763811253008,98.50644855479054
2580,"def _set_log_writer ( self ) : <TAB>  if self . config [ "" logging "" ] : <TAB><TAB>  config = self . config [ "" log_writer_config "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log_writer = LogWriter ( * * config ) <TAB><TAB>  elif config [ "" writer "" ] == "" tensorboard "" : <TAB><TAB><TAB>  self . log_writer = TensorBoardWriter ( * * config ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( f "" Unrecognized writer option:  { config [ ' writer ' ] } "" ) <TAB>  else : <TAB><TAB>  self . log_writer = None ","if config [ ""writer"" ] == ""json"" :","if config['writer'] == ""log':",False,15.525700128481581,94.95056006123366
2581,"def _parse ( self , contents ) : <TAB>  entries = [ ] <TAB>  hostnames_found = set ( ) <TAB>  for line in contents . splitlines ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  entries . append ( ( "" blank "" , [ line ] ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB><TAB>  if not len ( head ) : <TAB><TAB><TAB>  entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB><TAB>  hostnames_found . add ( head ) <TAB>  if len ( hostnames_found ) > 1 : <TAB><TAB>  raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB>  return entries ",if not len ( line . strip ( ) ) :,if not line:,False,21.947086171631213,96.12498715369132
2582,"def get_all_values ( self , project ) : <TAB>  if isinstance ( project , models . Model ) : <TAB><TAB>  project_id = project . id <TAB>  else : <TAB><TAB>  project_id = project <TAB>  if project_id not in self . __cache : <TAB><TAB>  cache_key = self . _make_key ( project_id ) <TAB><TAB>  result = cache . get ( cache_key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = self . reload_cache ( project_id ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . __cache [ project_id ] = result <TAB>  return self . __cache . get ( project_id , { } ) ",if result is None :,if result is None:,False,51.89938521035648,100.00000000000004
2583,"def needed_libraries ( self ) : <TAB>  for cmd in self . load_commands_of_type ( 0xC ) :<TAB># LC_LOAD_DYLIB <TAB><TAB>  tname = self . _get_typename ( "" dylib_command "" ) <TAB><TAB>  dylib_command = cmd . cast ( tname ) <TAB><TAB>  name_addr = cmd . obj_offset + dylib_command . name <TAB><TAB>  dylib_name = self . obj_vm . read ( name_addr , 256 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  idx = dylib_name . find ( "" \x00 "" ) <TAB><TAB><TAB>  if idx != - 1 : <TAB><TAB><TAB><TAB>  dylib_name = dylib_name [ : idx ] <TAB><TAB><TAB>  yield dylib_name ",if dylib_name :,if dylib_name:,False,45.935495939171,96.01682555534227
2584,"def compress ( self , data_list ) : <TAB>  warn_untested ( ) <TAB>  if data_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  error = self . error_messages [ "" invalid_year "" ] <TAB><TAB><TAB>  raise forms . ValidationError ( error ) <TAB><TAB>  if data_list [ 0 ] in forms . fields . EMPTY_VALUES : <TAB><TAB><TAB>  error = self . error_messages [ "" invalid_month "" ] <TAB><TAB><TAB>  raise forms . ValidationError ( error ) <TAB><TAB>  year = int ( data_list [ 1 ] ) <TAB><TAB>  month = int ( data_list [ 0 ] ) <TAB><TAB>  # find last day of the month <TAB><TAB>  day = monthrange ( year , month ) [ 1 ] <TAB><TAB>  return date ( year , month , day ) <TAB>  return None ",if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,if data_list[0] in forms.fields.EMPTY_VALUES:,False,54.90524433741637,98.91180759779758
2585,"def put ( self , obj , block = True , timeout = None ) : <TAB>  assert not self . _closed <TAB>  if not self . _sem . acquire ( block , timeout ) : <TAB><TAB>  raise Full <TAB>  with self . _notempty : <TAB><TAB>  with self . _cond : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _start_thread ( ) <TAB><TAB><TAB>  self . _buffer . append ( obj ) <TAB><TAB><TAB>  self . _unfinished_tasks . release ( ) <TAB><TAB><TAB>  self . _notempty . notify ( ) ",if self . _thread is None :,if self._started_tasks.acquire(False):,False,48.685039764406824,94.25228516659645
2586,"def has_module ( self , module , version ) : <TAB>  has_module = False <TAB>  for directory in self . directories : <TAB><TAB>  module_directory = join ( directory , module ) <TAB><TAB>  has_module_directory = isdir ( module_directory ) <TAB><TAB>  if not version : <TAB><TAB><TAB>  has_module = has_module_directory or exists ( <TAB><TAB><TAB><TAB>  module_directory <TAB><TAB><TAB>  )<TAB># could be a bare modulefile <TAB><TAB>  else : <TAB><TAB><TAB>  modulefile = join ( module_directory , version ) <TAB><TAB><TAB>  has_modulefile = exists ( modulefile ) <TAB><TAB><TAB>  has_module = has_module_directory and has_modulefile <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return has_module ",if has_module :,if has_module and has_modulefile:,False,54.308936410584366,95.55500787770208
2587,"def expanduser ( path ) : <TAB>  if path [ : 1 ] == "" ~ "" : <TAB><TAB>  c = path [ 1 : 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return gethome ( ) <TAB><TAB>  if c == os . sep : <TAB><TAB><TAB>  return asPyString ( File ( gethome ( ) , path [ 2 : ] ) . getPath ( ) ) <TAB>  return path ",if not c :,if c == os.curdir:,False,21.980409345899897,93.29260232711307
2588,"def mock_touch ( self , bearer , version = None , revision = None , * * kwargs ) : <TAB>  if version : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return self . versions [ int ( version ) - 1 ] <TAB><TAB><TAB>  except ( IndexError , ValueError ) : <TAB><TAB><TAB><TAB>  return None <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  return file_models . FileVersion ( ) ",if self . versions :,if version > 0:,False,46.887677531396065,96.59246927162941
2589,"def _get_field_value ( self , test , key , match ) : <TAB>  if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB>  members = inspect . getmembers ( match ) <TAB><TAB>  for member in members : <TAB><TAB><TAB>  if member [ 0 ] == key : <TAB><TAB><TAB><TAB>  field_value = member [ 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  wildcards = member [ 1 ] <TAB><TAB>  if key == "" nw_src "" : <TAB><TAB><TAB>  field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB>  elif key == "" nw_dst "" : <TAB><TAB><TAB>  field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB>  else : <TAB><TAB>  field_value = match [ key ] <TAB>  return field_value ","elif member [ 0 ] == ""wildcards"" :",if len(member) == 2:,False,30.47091201716407,95.81808274971712
2590,"def check_expected ( result , expected , contains = False ) : <TAB>  if sys . version_info [ 0 ] > = 3 : <TAB><TAB>  if isinstance ( result , str ) : <TAB><TAB><TAB>  result = result . encode ( "" ascii "" ) <TAB><TAB>  if isinstance ( expected , str ) : <TAB><TAB><TAB>  expected = expected . encode ( "" ascii "" ) <TAB>  resultlines = result . splitlines ( ) <TAB>  expectedlines = expected . splitlines ( ) <TAB>  if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB>  return False <TAB>  for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if eline not in rline : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ",if contains :,if contains:,False,49.45819654903956,100.00000000000004
2591,"def OnKeyUp ( self , event ) : <TAB>  if self . _properties . modifiable : <TAB><TAB>  if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB><TAB><TAB>  self . _cancel_editing ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _update_value ( ) <TAB><TAB>  elif event . GetKeyCode ( ) == wx . WXK_DELETE : <TAB><TAB><TAB>  self . SetValue ( "" "" ) <TAB>  if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB><TAB>  # Don't send skip event if enter key is pressed <TAB><TAB>  # On some platforms this event is sent too late and causes crash <TAB><TAB>  event . Skip ( ) ",elif event . GetKeyCode ( ) == wx . WXK_RETURN :,if event.GetKeyCode() == wx.WXK_VALUE:,False,66.64820254600647,97.3610841055131
2592,"def load_modules ( <TAB>  to_load , load , attr , modules_dict , excluded_aliases , loading_message = None  ) : <TAB>  if loading_message : <TAB><TAB>  print ( loading_message ) <TAB>  for name in to_load : <TAB><TAB>  module = load ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  cls = getattr ( module , attr ) <TAB><TAB>  if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if hasattr ( module , "" aliases "" ) : <TAB><TAB><TAB>  for alias in module . aliases ( ) : <TAB><TAB><TAB><TAB>  if alias not in excluded_aliases : <TAB><TAB><TAB><TAB><TAB>  modules_dict [ alias ] = module <TAB><TAB>  else : <TAB><TAB><TAB>  modules_dict [ name ] = module <TAB>  if loading_message : <TAB><TAB>  print ( ) ","if module is None or not hasattr ( module , attr ) :",if module is None:,False,34.99699418176382,96.4044966663104
2593,def eventIterator ( ) : <TAB>  while True : <TAB><TAB>  yield eventmodule . wait ( ) <TAB><TAB>  while True : <TAB><TAB><TAB>  event = eventmodule . poll ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield event ,if event . type == NOEVENT :,if event is None:,False,22.52419604471118,93.57636304562953
2594,"def _get_state_without_padding ( self , state_with_padding , padding ) : <TAB>  lean_state = { } <TAB>  for key , value in state_with_padding . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lean_length = value . numel ( ) - padding <TAB><TAB><TAB>  lean_state [ key ] = value [ : lean_length ] <TAB><TAB>  else : <TAB><TAB><TAB>  lean_state [ key ] = value <TAB>  return lean_state ",if torch . is_tensor ( value ) :,if padding:,False,44.93064058762438,93.00758003992871
2595,"def _get_validate ( data ) : <TAB>  """"""Retrieve items to validate, from single samples or from combined joint calls."""""" <TAB>  if data . get ( "" vrn_file "" ) and tz . get_in ( [ "" config "" , "" algorithm "" , "" validate "" ] , data ) : <TAB><TAB>  return utils . deepish_copy ( data ) <TAB>  elif "" group_orig "" in data : <TAB><TAB>  for sub in multi . get_orig_items ( data ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sub_val = utils . deepish_copy ( sub ) <TAB><TAB><TAB><TAB>  sub_val [ "" vrn_file "" ] = data [ "" vrn_file "" ] <TAB><TAB><TAB><TAB>  return sub_val <TAB>  return None ","if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :",if sub.get('vrn_file'):,False,57.61651704510371,92.49413978183156
2596,"def OnPopup ( self , form , popup_handle ) : <TAB>  for num , action_name , menu_name , shortcut in self . actions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ida_kernwin . attach_action_to_popup ( form , popup_handle , None ) <TAB><TAB>  else : <TAB><TAB><TAB>  handler = command_handler_t ( self , num , 2 ) <TAB><TAB><TAB>  desc = ida_kernwin . action_desc_t ( action_name , menu_name , handler , shortcut ) <TAB><TAB><TAB>  ida_kernwin . attach_dynamic_action_to_popup ( form , popup_handle , desc ) ",if menu_name is None :,if num == 0:,False,47.10479403013244,96.11572597288368
2597,"def show ( self , indent = 0 ) : <TAB>  """"""Pretty print this structure."""""" <TAB>  if indent == 0 : <TAB><TAB>  print ( "" struct  {} "" . format ( self . name ) ) <TAB>  for field in self . fields : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  offset = "" 0x?? "" <TAB><TAB>  else : <TAB><TAB><TAB>  offset = "" 0x {:02x} "" . format ( field . offset ) <TAB><TAB>  print ( "" {} + {} {} {} "" . format ( "" "" * indent , offset , field . name , field . type ) ) <TAB><TAB>  if isinstance ( field . type , Structure ) : <TAB><TAB><TAB>  field . type . show ( indent + 1 ) ",if field . offset is None :,if field.offset == 0:,False,46.62783218372641,97.72805519473513
2598,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB>  operation = None <TAB>  for definition in document_ast . definitions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not operation_name : <TAB><TAB><TAB><TAB>  # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB>  # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB>  # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB>  if operation : <TAB><TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB><TAB>  operation = definition <TAB><TAB><TAB>  elif definition . name and definition . name . value == operation_name : <TAB><TAB><TAB><TAB>  return definition <TAB>  return operation ","if isinstance ( definition , ast . OperationDefinition ) :",if definition.name and definition.name.value == operation_name:,False,72.49769179044893,94.16866268388621
2599,"def getSubMenu ( self , callingWindow , context , mainItem , selection , rootMenu , i , pitem ) : <TAB>  msw = True if "" wxMSW "" in wx . PlatformInfo else False <TAB>  self . context = context <TAB>  self . abilityIds = { } <TAB>  sub = wx . Menu ( ) <TAB>  for ability in self . fighter . abilities : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  menuItem = self . addAbility ( rootMenu if msw else sub , ability ) <TAB><TAB>  sub . Append ( menuItem ) <TAB><TAB>  menuItem . Check ( ability . active ) <TAB>  return sub ",if not ability . effect . isImplemented :,if not ability.active:,False,32.72018565153244,96.96528993720399
2600,"def consume ( self , event : Dict [ str , Any ] ) - > None : <TAB>  with self . lock : <TAB><TAB>  logging . debug ( "" Received missedmessage_emails event:  %s "" , event ) <TAB><TAB>  # When we process an event, just put it into the queue and ensure we have a timer going. <TAB><TAB>  user_profile_id = event [ "" user_profile_id "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . batch_start_by_recipient [ user_profile_id ] = time . time ( ) <TAB><TAB>  self . events_by_recipient [ user_profile_id ] . append ( event ) <TAB><TAB>  self . ensure_timer ( ) ",if user_profile_id not in self . batch_start_by_recipient :,if user_profile_id not in self.events_by_recipient:,False,63.28553493646108,97.62268342910468
2601,"def __init__ ( self , start_enabled = False , use_hardware = True ) : <TAB>  self . _use_hardware = use_hardware <TAB>  if use_hardware : <TAB><TAB>  self . _button = Button ( BUTTON_GPIO_PIN ) <TAB><TAB>  self . _enabled = start_enabled <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _button . when_pressed = self . _enable ",if not start_enabled :,if start_enabled:,False,39.397053358351975,97.68769734531283
2602,"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB>  try : <TAB><TAB>  pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . _execute_map ( ctx , op ) <TAB><TAB>  elif op . stage == OperandStage . combine : <TAB><TAB><TAB>  cls . _execute_combine ( ctx , op ) <TAB><TAB>  elif op . stage == OperandStage . agg : <TAB><TAB><TAB>  cls . _execute_agg ( ctx , op ) <TAB><TAB>  else :<TAB># pragma: no cover <TAB><TAB><TAB>  raise ValueError ( "" Aggregation operand not executable "" ) <TAB>  finally : <TAB><TAB>  pd . reset_option ( "" mode.use_inf_as_na "" ) ",if op . stage == OperandStage . map :,if op.stage == OperandStage.map:,False,25.58719143484983,97.98269523212632
2603,"def load_package ( name , path ) : <TAB>  if os . path . isdir ( path ) : <TAB><TAB>  extensions = machinery . SOURCE_SUFFIXES [ : ] + machinery . BYTECODE_SUFFIXES [ : ] <TAB><TAB>  for extension in extensions : <TAB><TAB><TAB>  init_path = os . path . join ( path , "" __init__ "" + extension ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  path = init_path <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" {!r}  is not a package "" . format ( path ) ) <TAB>  spec = util . spec_from_file_location ( name , path , submodule_search_locations = [ ] ) <TAB>  if name in sys . modules : <TAB><TAB>  return _exec ( spec , sys . modules [ name ] ) <TAB>  else : <TAB><TAB>  return _load ( spec ) ",if os . path . exists ( init_path ) :,if os.path.exists(init_path):,False,51.60911569434735,100.00000000000004
2604,def setup ( level = None ) : <TAB>  from pipeline . logging import pipeline_logger as logger <TAB>  from pipeline . log . handlers import EngineLogHandler <TAB>  if level in set ( logging . _levelToName . values ( ) ) : <TAB><TAB>  logger . setLevel ( level ) <TAB>  logging . _acquireLock ( ) <TAB>  try : <TAB><TAB>  for hdl in logger . handlers : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  hdl = EngineLogHandler ( ) <TAB><TAB><TAB>  hdl . setLevel ( logger . level ) <TAB><TAB><TAB>  logger . addHandler ( hdl ) <TAB>  finally : <TAB><TAB>  logging . _releaseLock ( ) ,"if isinstance ( hdl , EngineLogHandler ) :",if hdl.level == logger.level:,False,46.052622718027216,95.13633256589094
2605,"def find_approximant ( x ) : <TAB>  c = 1e-4 <TAB>  it = sympy . ntheory . continued_fraction_convergents ( <TAB><TAB>  sympy . ntheory . continued_fraction_iterator ( x ) <TAB>  ) <TAB>  for i in it : <TAB><TAB>  p , q = i . as_numer_denom ( ) <TAB><TAB>  tol = c / q * * 2 <TAB><TAB>  if abs ( i - x ) < = tol : <TAB><TAB><TAB>  return i <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return x ",if tol < machine_epsilon :,if p < x:,False,22.749707230199288,95.72495187185497
2606,"def resolve ( <TAB>  self , debug : bool = False , silent : bool = False , level : Optional [ int ] = None  ) - > bool : <TAB>  if silent : <TAB><TAB>  spinner = nullcontext ( type ( "" Mock "" , ( ) , { } ) ) <TAB>  else : <TAB><TAB>  spinner = yaspin ( text = "" resolving... "" ) <TAB>  with spinner as spinner : <TAB><TAB>  while True : <TAB><TAB><TAB>  resolved = self . _resolve ( <TAB><TAB><TAB><TAB>  debug = debug , silent = silent , level = level , spinner = spinner <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  self . graph . clear ( )<TAB># remove unused deps from graph <TAB><TAB><TAB>  return resolved ",if resolved is None :,if not resolved:,False,27.45261289112514,96.40649319714358
2607,"def canonicalize_instruction_name ( instr ) : <TAB>  name = instr . insn_name ( ) . upper ( ) <TAB>  # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB>  if name == "" MOV "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" LSR "" <TAB><TAB>  elif instr . mnemonic . startswith ( "" lsl "" ) : <TAB><TAB><TAB>  return "" LSL "" <TAB><TAB>  elif instr . mnemonic . startswith ( "" asr "" ) : <TAB><TAB><TAB>  return "" ASR "" <TAB>  return OP_NAME_MAP . get ( name , name ) ","if instr . mnemonic . startswith ( ""lsr"" ) :",if instr.mnemonic.startswith('lsr'):,False,63.50637334498407,97.19251802972269
2608,"def run_all ( rule_list , defined_variables , defined_actions , stop_on_first_trigger = False ) : <TAB>  rule_was_triggered = False <TAB>  for rule in rule_list : <TAB><TAB>  result = run ( rule , defined_variables , defined_actions ) <TAB><TAB>  if result : <TAB><TAB><TAB>  rule_was_triggered = True <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return rule_was_triggered ",if stop_on_first_trigger :,if stop_on_first_trigger:,False,51.02925949107495,100.00000000000004
2609,"def get_filters ( self , request ) : <TAB>  filter_specs = [ ] <TAB>  if self . lookup_opts . admin . list_filter and not self . opts . one_to_one_field : <TAB><TAB>  filter_fields = [ <TAB><TAB><TAB>  self . lookup_opts . get_field ( field_name ) <TAB><TAB><TAB>  for field_name in self . lookup_opts . admin . list_filter <TAB><TAB>  ] <TAB><TAB>  for f in filter_fields : <TAB><TAB><TAB>  spec = FilterSpec . create ( f , request , self . params , self . model ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  filter_specs . append ( spec ) <TAB>  return filter_specs , bool ( filter_specs ) ",if spec and spec . has_output ( ) :,if spec.spec.name == self.spec.name:,False,23.068030819580432,94.38168336063035
2610,"def get_type ( type_ref ) : <TAB>  kind = type_ref . get ( "" kind "" ) <TAB>  if kind == TypeKind . LIST : <TAB><TAB>  item_ref = type_ref . get ( "" ofType "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB><TAB>  return GraphQLList ( get_type ( item_ref ) ) <TAB>  elif kind == TypeKind . NON_NULL : <TAB><TAB>  nullable_ref = type_ref . get ( "" ofType "" ) <TAB><TAB>  if not nullable_ref : <TAB><TAB><TAB>  raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB><TAB>  return GraphQLNonNull ( get_type ( nullable_ref ) ) <TAB>  return get_named_type ( type_ref [ "" name "" ] ) ",if not item_ref :,if not item_ref:,False,56.10428597378372,100.00000000000004
2611,"def _1_0_cloud_ips_cip_jsjc5_map ( self , method , url , body , headers ) : <TAB>  if method == "" POST "" : <TAB><TAB>  body = json . loads ( body ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . test_response ( httplib . ACCEPTED , "" "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  data = ' { "" error_name "" : "" bad destination "" ,  "" errors "" : [ "" Bad destination "" ]} ' <TAB><TAB><TAB>  return self . test_response ( httplib . BAD_REQUEST , data ) ","if ""destination"" in body :","if method == ""GET':",False,26.974136503037805,95.94264480658872
2612,"def _get_prefixed_values ( data , prefix ) : <TAB>  """"""Collect lines which start with prefix; with trimming"""""" <TAB>  matches = [ ] <TAB>  for line in data . splitlines ( ) : <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  match = line [ len ( prefix ) : ] <TAB><TAB><TAB>  match = match . strip ( ) <TAB><TAB><TAB>  matches . append ( match ) <TAB>  return matches ",if line . startswith ( prefix ) :,if line.startswith(prefix):,False,58.673264761786534,100.00000000000004
2613,"def _power_exact ( y , xc , yc , xe ) : <TAB>  yc , ye = y . int , y . exp <TAB>  while yc % 10 == 0 : <TAB><TAB>  yc / / = 10 <TAB><TAB>  ye + = 1 <TAB>  if xc == 1 : <TAB><TAB>  xe * = yc <TAB><TAB>  while xe % 10 == 0 : <TAB><TAB><TAB>  xe / / = 10 <TAB><TAB><TAB>  ye + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  exponent = xe * 10 * * ye <TAB><TAB>  if y and xe : <TAB><TAB><TAB>  xc = exponent <TAB><TAB>  else : <TAB><TAB><TAB>  xc = 0 <TAB><TAB>  return 5 ",if ye < 0 :,if ye == 0:,False,23.928751570452484,98.30877369413011
2614,"def init ( self , view , items = None ) : <TAB>  selections = [ ] <TAB>  if view . sel ( ) : <TAB><TAB>  for region in view . sel ( ) : <TAB><TAB><TAB>  selections . append ( view . substr ( region ) ) <TAB>  values = [ ] <TAB>  for idx , index in enumerate ( map ( int , items ) ) : <TAB><TAB>  if idx > = len ( selections ) : <TAB><TAB><TAB>  break <TAB><TAB>  i = index - 1 <TAB><TAB>  if i > = 0 and i < len ( selections ) : <TAB><TAB><TAB>  values . append ( selections [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  values . append ( None ) <TAB>  # fill up <TAB>  for idx , value in enumerate ( selections ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values . append ( value ) <TAB>  self . stack = values ",if len ( values ) + 1 < idx :,if idx > 0 and idx < len(values):,False,31.112848252867163,96.4958893381573
2615,"def toggleFactorReload ( self , value = None ) : <TAB>  self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB><TAB>  value <TAB><TAB>  if value is not None <TAB><TAB>  else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB>  ) <TAB>  fitIDs = set ( ) <TAB>  for fit in set ( self . _loadedFits ) : <TAB><TAB>  if fit is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB><TAB><TAB>  fit . clearFactorReloadDependentData ( ) <TAB><TAB><TAB>  fitIDs . add ( fit . ID ) <TAB>  return fitIDs ",if fit . calculated :,if fit.factorReload == 0:,False,50.9122314346361,96.82340374756386
2616,"def init_weights ( self ) : <TAB>  """"""Initialize model weights."""""" <TAB>  for m in self . predict_layers . modules ( ) : <TAB><TAB>  if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB>  kaiming_init ( m ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  constant_init ( m , 1 ) <TAB><TAB>  elif isinstance ( m , nn . Linear ) : <TAB><TAB><TAB>  normal_init ( m , std = 0.01 ) ","elif isinstance ( m , nn . BatchNorm2d ) :","if isinstance(m, nn.Constant):",False,26.17788379501611,96.25354647617574
2617,"def _unzip_file ( self , filepath , ext ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  zf = zipfile . ZipFile ( filepath ) <TAB><TAB><TAB>  zf . extractall ( os . path . dirname ( filepath ) ) <TAB><TAB><TAB>  zf . close ( ) <TAB><TAB>  elif ext == "" .tar "" : <TAB><TAB><TAB>  tf = tarfile . open ( filepath ) <TAB><TAB><TAB>  tf . extractall ( os . path . dirname ( filepath ) ) <TAB><TAB><TAB>  tf . close ( ) <TAB>  except Exception as e : <TAB><TAB>  raise ValueError ( "" Error reading file  %r ! \n %s "" % ( filepath , e ) ) ","if ext == "".zip"" :",if ext == '.zip':,False,51.170910224033015,97.2096602377824
2618,"def add_multiple_tasks ( data , parent ) : <TAB>  data = json . loads ( data ) <TAB>  new_doc = { <TAB><TAB>  "" doctype "" : "" Task "" , <TAB><TAB>  "" parent_task "" : parent if parent != "" All Tasks "" else "" "" , <TAB>  } <TAB>  new_doc [ "" project "" ] = frappe . db . get_value ( "" Task "" , { "" name "" : parent } , "" project "" ) or "" "" <TAB>  for d in data : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  new_doc [ "" subject "" ] = d . get ( "" subject "" ) <TAB><TAB>  new_task = frappe . get_doc ( new_doc ) <TAB><TAB>  new_task . insert ( ) ","if not d . get ( ""subject"" ) :",if d.get('doctype') == 'Task':,False,26.190508560946373,96.15698469330692
2619,"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB>  """"""Return a sorted list of keywords similar to the one given."""""" <TAB>  seenDict = { } <TAB>  kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB>  matches = [ ] <TAB>  matchesappend = matches . append <TAB>  checkContained = False <TAB>  if len ( keyword ) > 4 : <TAB><TAB>  checkContained = True <TAB>  for movieID , key in kwdsIterator : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  seenDict [ key ] = None <TAB><TAB>  if checkContained and keyword in key : <TAB><TAB><TAB>  matchesappend ( key ) <TAB><TAB><TAB>  continue <TAB><TAB>  if kwdSndx == soundex ( key . encode ( "" ascii "" , "" ignore "" ) ) : <TAB><TAB><TAB>  matchesappend ( key ) <TAB>  return _sortKeywords ( keyword , matches ) ",if key in seenDict :,if movieID in seenDict:,False,38.84922856480294,98.88262404605162
2620,"def visit_If ( self , node ) : <TAB>  self . newline ( ) <TAB>  self . write ( "" if  "" ) <TAB>  self . visit ( node . test ) <TAB>  self . write ( "" : "" ) <TAB>  self . body ( node . body ) <TAB>  while True : <TAB><TAB>  else_ = node . orelse <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  node = else_ [ 0 ] <TAB><TAB><TAB>  self . newline ( ) <TAB><TAB><TAB>  self . write ( "" elif  "" ) <TAB><TAB><TAB>  self . visit ( node . test ) <TAB><TAB><TAB>  self . write ( "" : "" ) <TAB><TAB><TAB>  self . body ( node . body ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . newline ( ) <TAB><TAB><TAB>  self . write ( "" else: "" ) <TAB><TAB><TAB>  self . body ( else_ ) <TAB><TAB><TAB>  break ","if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :",if len(else_) == 1:,False,23.51343086660721,95.29852993698967
2621,"def _eyeLinkHardwareAndSoftwareVersion ( self ) : <TAB>  try : <TAB><TAB>  tracker_software_ver = 0 <TAB><TAB>  eyelink_ver = self . _eyelink . getTrackerVersion ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tvstr = self . _eyelink . getTrackerVersionString ( ) <TAB><TAB><TAB>  vindex = tvstr . find ( "" EYELINK CL "" ) <TAB><TAB><TAB>  tracker_software_ver = int ( <TAB><TAB><TAB><TAB>  float ( tvstr [ ( vindex + len ( "" EYELINK CL "" ) ) : ] . strip ( ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  return eyelink_ver , tracker_software_ver <TAB>  except Exception : <TAB><TAB>  print2err ( "" EYELINK Error during _eyeLinkHardwareAndSoftwareVersion: "" ) <TAB><TAB>  printExceptionDetailsToStdErr ( ) <TAB><TAB>  return EyeTrackerConstants . EYETRACKER_ERROR ",if eyelink_ver == 3 :,if eyelink_ver == EyeTrackerConstants.EYETRACKER_VERSION,False,22.588580838929058,97.02104441291202
2622,"def execute ( self , context ) : <TAB>  for monad in context . blend_data . node_groups : <TAB><TAB>  if monad . bl_idname == "" SverchGroupTreeType "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  monad . update_cls ( ) <TAB><TAB><TAB><TAB>  except Exception as err : <TAB><TAB><TAB><TAB><TAB>  print ( err ) <TAB><TAB><TAB><TAB><TAB>  print ( "" {}  group class could not be created "" . format ( monad . name ) ) <TAB>  return { "" FINISHED "" } ","if not getattr ( bpy . types , monad . cls_bl_idname , None ) :",if monad.name == monad.name:,False,29.03234706954952,90.42244399864718
2623,"def word_pattern ( pattern , str ) : <TAB>  dict = { } <TAB>  set_value = set ( ) <TAB>  list_str = str . split ( ) <TAB>  if len ( list_str ) != len ( pattern ) : <TAB><TAB>  return False <TAB>  for i in range ( len ( pattern ) ) : <TAB><TAB>  if pattern [ i ] not in dict : <TAB><TAB><TAB>  if list_str [ i ] in set_value : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  dict [ pattern [ i ] ] = list_str [ i ] <TAB><TAB><TAB>  set_value . add ( list_str [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB>  return True ",if dict [ pattern [ i ] ] != list_str [ i ] :,if len(list_str) == 0:,False,22.270220456437436,93.39946252814813
2624,"def decorator_handle ( tokens ) : <TAB>  """"""Process decorators."""""" <TAB>  defs = [ ] <TAB>  decorates = [ ] <TAB>  for i , tok in enumerate ( tokens ) : <TAB><TAB>  if "" simple "" in tok and len ( tok ) == 1 : <TAB><TAB><TAB>  decorates . append ( "" @ "" + tok [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  varname = decorator_var + "" _ "" + str ( i ) <TAB><TAB><TAB>  defs . append ( varname + ""  =  "" + tok [ 0 ] ) <TAB><TAB><TAB>  decorates . append ( "" @ "" + varname ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise CoconutInternalException ( "" invalid decorator tokens "" , tok ) <TAB>  return "" \n "" . join ( defs + decorates ) + "" \n "" ","elif ""test"" in tok and len ( tok ) == 1 :",if tok[1] == 'decorator':,False,49.63772064043756,93.59302580421785
2625,"def wait_impl ( self , cpid ) : <TAB>  for i in range ( 10 ) : <TAB><TAB>  # wait3() shouldn't hang, but some of the buildbots seem to hang <TAB><TAB>  # in the forking tests.  This is an attempt to fix the problem. <TAB><TAB>  spid , status , rusage = os . wait3 ( os . WNOHANG ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  time . sleep ( 1.0 ) <TAB>  self . assertEqual ( spid , cpid ) <TAB>  self . assertEqual ( status , 0 , "" cause =  %d , exit =  %d "" % ( status & 0xFF , status >> 8 ) ) <TAB>  self . assertTrue ( rusage ) ",if spid == cpid :,if spid == cpid:,False,65.7699875024546,100.00000000000004
2626,"def test_non_uniform_probabilities_over_elements ( self ) : <TAB>  param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB>  samples = param . draw_samples ( ( 10000 , ) ) <TAB>  unique , counts = np . unique ( samples , return_counts = True ) <TAB>  assert len ( unique ) == 2 <TAB>  for val , count in zip ( unique , counts ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert 2500 - 500 < count < 2500 + 500 <TAB><TAB>  elif val == 1 : <TAB><TAB><TAB>  assert 7500 - 500 < count < 7500 + 500 <TAB><TAB>  else : <TAB><TAB><TAB>  assert False ",if val == 0 :,if val == 0:,False,62.66447333377357,100.00000000000004
2627,"def dispatch_return ( self , frame , arg ) : <TAB>  if self . stop_here ( frame ) or frame == self . returnframe : <TAB><TAB>  # Ignore return events in generator except when stepping. <TAB><TAB>  if self . stopframe and frame . f_code . co_flags & CO_GENERATOR : <TAB><TAB><TAB>  return self . trace_dispatch <TAB><TAB>  try : <TAB><TAB><TAB>  self . frame_returning = frame <TAB><TAB><TAB>  self . user_return ( frame , arg ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . frame_returning = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise BdbQuit <TAB><TAB>  # The user issued a 'next' or 'until' command. <TAB><TAB>  if self . stopframe is frame and self . stoplineno != - 1 : <TAB><TAB><TAB>  self . _set_stopinfo ( None , None ) <TAB>  return self . trace_dispatch ",if self . quitting :,if self.stopframe and self.returnframe is None:,False,61.35634921179538,95.14283414632352
2628,"def mouse ( self , button , mods , x , y ) : <TAB>  if button == 1 : <TAB><TAB>  for i in range ( 4 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . hit = i <TAB>  elif button == - 1 : <TAB><TAB>  self . hit = None <TAB>  elif self . hit != None : <TAB><TAB>  self . coords [ self . hit ] = ( x , y ) <TAB><TAB>  self . view . dirty ( ) ","if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 :",if self.view.get_button(i) == button:,False,39.639404332983915,80.48090252029375
2629,"def __init__ ( self , * commands ) : <TAB>  self . all_cmds = list ( <TAB><TAB>  map ( lambda cmd : cmd [ 0 ] if isinstance ( cmd , list ) else cmd , commands ) <TAB>  ) <TAB>  for command in commands : <TAB><TAB>  self . cmd = command if isinstance ( command , list ) else [ command ] <TAB><TAB>  self . cmd_path = pwndbg . which . which ( self . cmd [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ",if self . cmd_path :,if not os.path.exists(self.cmd_path):,False,22.410114611441333,92.08626132514614
2630,"def _recv_obj ( self , suppress_error = False ) : <TAB>  """"""Receive a (picklable) object"""""" <TAB>  if self . conn . closed : <TAB><TAB>  raise OSError ( "" handle is closed "" ) <TAB>  try : <TAB><TAB>  buf = self . conn . recv_bytes ( ) <TAB>  except ( ConnectionError , EOFError ) as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  logger . debug ( "" receive has failed "" , exc_info = e ) <TAB><TAB>  try : <TAB><TAB><TAB>  self . _set_remote_close_cause ( e ) <TAB><TAB><TAB>  raise PipeShutdownError ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . _close ( ) <TAB>  obj = RemoteObjectUnpickler . loads ( buf , self ) <TAB>  logger . debug ( "" received  %r "" , obj ) <TAB>  return obj ",if suppress_error :,if suppress_error:,False,50.715953871326825,100.00000000000004
2631,"def act ( self , obs ) : <TAB>  with chainer . no_backprop_mode ( ) : <TAB><TAB>  batch_obs = self . batch_states ( [ obs ] , self . xp , self . phi ) <TAB><TAB>  action_distrib = self . model ( batch_obs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return chainer . cuda . to_cpu ( action_distrib . most_probable . array ) [ 0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  return chainer . cuda . to_cpu ( action_distrib . sample ( ) . array ) [ 0 ] ",if self . act_deterministically :,if action_distrib.most_probable:,False,25.660072027833063,94.70204136537703
2632,"def _classify ( nodes_by_level ) : <TAB>  missing , invalid , downloads = [ ] , [ ] , [ ] <TAB>  for level in nodes_by_level : <TAB><TAB>  for node in level : <TAB><TAB><TAB>  if node . binary == BINARY_MISSING : <TAB><TAB><TAB><TAB>  missing . append ( node ) <TAB><TAB><TAB>  elif node . binary == BINARY_INVALID : <TAB><TAB><TAB><TAB>  invalid . append ( node ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  downloads . append ( node ) <TAB>  return missing , invalid , downloads ","elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",if node.binary == BINARY_DOWNLOAD:,False,48.96563812038448,92.7877201776172
2633,"def persist ( self , * _ ) : <TAB>  for key , obj in self . _objects . items ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  state = obj . get_state ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  md5 = hashlib . md5 ( state ) . hexdigest ( ) <TAB><TAB><TAB>  if self . _last_state . get ( key ) == md5 : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  self . _persist_provider . store ( key , state ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  system_log . exception ( "" PersistHelper.persist fail "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _last_state [ key ] = md5 ",if not state :,if state is None:,False,23.461849797180815,98.05798944198023
2634,"def enter ( self , doc , * * kwds ) : <TAB>  """"""Enters the mode, arranging for necessary grabs ASAP"""""" <TAB>  super ( ColorPickMode , self ) . enter ( doc , * * kwds ) <TAB>  if self . _started_from_key_press : <TAB><TAB>  # Pick now using the last recorded event position <TAB><TAB>  doc = self . doc <TAB><TAB>  tdw = self . doc . tdw <TAB><TAB>  t , x , y = doc . get_last_event_info ( tdw ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _pick_color_mode ( tdw , x , y , self . _pickmode ) <TAB><TAB>  # Start the drag when possible <TAB><TAB>  self . _start_drag_on_next_motion_event = True <TAB><TAB>  self . _needs_drag_start = True ","if None not in ( x , y ) :",if t == 'ColorPick':,False,47.904265085230016,95.66384111527871
2635,"def on_profiles_loaded ( self , profiles ) : <TAB>  cb = self . builder . get_object ( "" cbProfile "" ) <TAB>  model = cb . get_model ( ) <TAB>  model . clear ( ) <TAB>  for f in profiles : <TAB><TAB>  name = f . get_basename ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if name . endswith ( "" .sccprofile "" ) : <TAB><TAB><TAB>  name = name [ 0 : - 11 ] <TAB><TAB>  model . append ( ( name , f , None ) ) <TAB>  cb . set_active ( 0 ) ","if name . endswith ( "".mod"" ) :",if name.startswith('.sccprofile'):,False,33.69194290577658,94.04941353287228
2636,"def subprocess_post_check ( <TAB>  completed_process : subprocess . CompletedProcess , raise_error : bool = True  ) - > None : <TAB>  if completed_process . returncode : <TAB><TAB>  if completed_process . stdout is not None : <TAB><TAB><TAB>  print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB><TAB>  if raise_error : <TAB><TAB><TAB>  raise PipxError ( <TAB><TAB><TAB><TAB>  f "" { ' ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  logger . info ( f "" { ' ' . join ( completed_process . args ) !r}  failed "" ) ",if completed_process . stderr is not None :,if completed_process.stderr is not None:,False,20.416812520068373,100.00000000000004
2637,"def test_connect ( <TAB>  ipaddr , port , device , partition , method , path , headers = None , query_string = None  ) : <TAB>  if path == "" /a "" : <TAB><TAB>  for k , v in headers . iteritems ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  test_errors . append ( "" %s :  %s  not in  %s "" % ( test_header , test_value , headers ) ) ",if k . lower ( ) == test_header . lower ( ) and v == test_value :,if k == method:,False,49.03529050283948,85.6710683366314
2638,"def test_stat_result_pickle ( self ) : <TAB>  result = os . stat ( self . fname ) <TAB>  for proto in range ( pickle . HIGHEST_PROTOCOL + 1 ) : <TAB><TAB>  p = pickle . dumps ( result , proto ) <TAB><TAB>  self . assertIn ( b "" stat_result "" , p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIn ( b "" cos \n stat_result \n "" , p ) <TAB><TAB>  unpickled = pickle . loads ( p ) <TAB><TAB>  self . assertEqual ( result , unpickled ) ",if proto < 4 :,if proto == 0:,False,25.160349089155527,94.35951040316276
2639,"def run_sql ( sql ) : <TAB>  table = sql . split ( "" "" ) [ 5 ] <TAB>  logger . info ( "" Updating table  {} "" . format ( table ) ) <TAB>  with transaction . atomic ( ) : <TAB><TAB>  with connection . cursor ( ) as cursor : <TAB><TAB><TAB>  cursor . execute ( sql ) <TAB><TAB><TAB>  rows = cursor . fetchall ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise Exception ( "" Sentry notification that  {}  is migrated "" . format ( table ) ) ",if not rows :,if rows:,False,38.73026796426007,98.20305113778416
2640,"def countbox ( self ) : <TAB>  self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB>  for x , y in self . body : <TAB><TAB>  if x < self . box [ 0 ] : <TAB><TAB><TAB>  self . box [ 0 ] = x <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . box [ 2 ] = x <TAB><TAB>  if y < self . box [ 1 ] : <TAB><TAB><TAB>  self . box [ 1 ] = y <TAB><TAB>  if y > self . box [ 3 ] : <TAB><TAB><TAB>  self . box [ 3 ] = y ",if x > self . box [ 2 ] :,if x > self.box[2]:,False,51.12662654754896,96.23591478500437
2641,"def _packageFocusOutViaKeyPress ( self , row , column , txt ) : <TAB>  if txt : <TAB><TAB>  self . _set_current_cell ( row + 1 , column ) <TAB>  else : <TAB><TAB>  widget = self . cellWidget ( row + 1 , column ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _delete_cell ( row , column ) <TAB><TAB>  new_request = self . get_request ( ) <TAB><TAB>  self . context_model . set_request ( new_request ) <TAB><TAB>  self . _update_request_column ( column , self . context_model ) ","if widget and isinstance ( widget , PackageSelectWidget ) :",if widget.is_selected():,False,32.61608006509061,95.38901398338135
2642,"def parse_bash_set_output ( output ) : <TAB>  """"""Parse Bash-like 'set' output"""""" <TAB>  if not sys . platform . startswith ( "" win "" ) : <TAB><TAB>  # Replace ""\""-continued lines in *Linux* environment dumps. <TAB><TAB>  # Cannot do this on Windows because a ""\"" at the end of the <TAB><TAB>  # line does not imply a continuation. <TAB><TAB>  output = output . replace ( "" \\ \n "" , "" "" ) <TAB>  environ = { } <TAB>  for line in output . splitlines ( 0 ) : <TAB><TAB>  line = line . rstrip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue<TAB># skip black lines <TAB><TAB>  item = _ParseBashEnvStr ( line ) <TAB><TAB>  if item : <TAB><TAB><TAB>  environ [ item [ 0 ] ] = item [ 1 ] <TAB>  return environ ",if not line :,if not line:,False,64.46410550847315,98.00062233445554
2643,"def _get ( self , domain ) : <TAB>  with self . lock : <TAB><TAB>  try : <TAB><TAB><TAB>  record = self . cache [ domain ] <TAB><TAB><TAB>  time_now = time . time ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  record = None <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  record = None <TAB><TAB>  if not record : <TAB><TAB><TAB>  record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB><TAB>  # self.cache[domain] = record <TAB><TAB>  return record ","if time_now - record [ ""update"" ] > self . ttl :",if time_now - self.last_run < time_now:,False,48.18878702281866,94.43559452184357
2644,"def test_filehash ( self ) : <TAB>  """"""tests the hashes of the files in data/"""""" <TAB>  fp = self . get_data_path ( ) <TAB>  for fn in os . listdir ( fp ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # file used for something else <TAB><TAB><TAB>  continue <TAB><TAB>  expected_hash = fn <TAB><TAB>  fullp = os . path . join ( fp , fn ) <TAB><TAB>  output = self . run_command ( "" sha1sum  "" + fullp , exitcode = 0 ) <TAB><TAB>  result = output . split ( "" "" ) [ 0 ] <TAB><TAB>  self . assertEqual ( result , expected_hash ) ","if ""."" in fn :",if fn == '.md':,False,54.7942268301199,96.04385686523946
2645,"def test_new_vs_reference_code_stream_read_during_iter ( read_idx , read_len , bytecode ) : <TAB>  reference = SlowCodeStream ( bytecode ) <TAB>  latest = CodeStream ( bytecode ) <TAB>  for index , ( actual , expected ) in enumerate ( zip ( latest , reference ) ) : <TAB><TAB>  assert actual == expected <TAB><TAB>  if index == read_idx : <TAB><TAB><TAB>  readout_actual = latest . read ( read_len ) <TAB><TAB><TAB>  readout_expected = reference . read ( read_len ) <TAB><TAB><TAB>  assert readout_expected == readout_actual <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert latest . program_counter > = len ( reference ) <TAB><TAB>  else : <TAB><TAB><TAB>  assert latest . program_counter == reference . program_counter ",if reference . program_counter >= len ( reference ) :,if index == read_idx:,False,32.84286321306787,94.61325318422254
2646,"def setup_logging ( ) : <TAB>  try : <TAB><TAB>  logconfig = config . get ( "" logging_config_file "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logging . config . fileConfig ( logconfig , disable_existing_loggers = False ) <TAB><TAB>  logger . info ( "" logging initialized "" ) <TAB><TAB>  logger . debug ( "" debug "" ) <TAB>  except Exception as e : <TAB><TAB>  print ( "" Unable to set logging configuration: "" , str ( e ) , file = sys . stderr ) <TAB><TAB>  raise ",if logconfig and os . path . exists ( logconfig ) :,if logconfig:,False,23.408196086533238,92.64725264581776
2647,"def all_words ( filename ) : <TAB>  start_char = True <TAB>  for c in characters ( filename ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  word = "" "" <TAB><TAB><TAB>  if c . isalnum ( ) : <TAB><TAB><TAB><TAB>  # We found the start of a word <TAB><TAB><TAB><TAB>  word = c . lower ( ) <TAB><TAB><TAB><TAB>  start_char = False <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  if c . isalnum ( ) : <TAB><TAB><TAB><TAB>  word + = c . lower ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # We found end of word, emit it <TAB><TAB><TAB><TAB>  start_char = True <TAB><TAB><TAB><TAB>  yield word ",if start_char == True :,if start_char:,False,57.45924088918005,98.23582557727558
2648,"def _get_nonce ( self , url , new_nonce_url ) : <TAB>  if not self . _nonces : <TAB><TAB>  logger . debug ( "" Requesting fresh nonce "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  response = self . head ( url ) <TAB><TAB>  else : <TAB><TAB><TAB>  # request a new nonce from the acme newNonce endpoint <TAB><TAB><TAB>  response = self . _check_response ( self . head ( new_nonce_url ) , content_type = None ) <TAB><TAB>  self . _add_nonce ( response ) <TAB>  return self . _nonces . pop ( ) ",if new_nonce_url is None :,if new_nonce_url is None:,False,60.60324323768575,100.00000000000004
2649,"def paragraph_is_fully_commented ( lines , comment , main_language ) : <TAB>  """"""Is the paragraph fully commented?"""""" <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  if line . startswith ( comment ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if is_magic ( line , main_language ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  continue <TAB><TAB>  return i > 0 and _BLANK_LINE . match ( line ) <TAB>  return True ",if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,if i == len(lines):,False,26.823071690637374,89.98519605385323
2650,"def gvariant_args ( args : List [ Any ] ) - > str : <TAB>  """"""Convert args into gvariant."""""" <TAB>  gvariant = "" "" <TAB>  for arg in args : <TAB><TAB>  if isinstance ( arg , bool ) : <TAB><TAB><TAB>  gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  gvariant + = f "" { arg } "" <TAB><TAB>  elif isinstance ( arg , str ) : <TAB><TAB><TAB>  gvariant + = f ' "" { arg } "" ' <TAB><TAB>  else : <TAB><TAB><TAB>  gvariant + = f "" { arg !s} "" <TAB>  return gvariant . lstrip ( ) ","elif isinstance ( arg , ( int , float ) ) :","if isinstance(arg, int):",False,41.53034647771662,94.09348731463008
2651,"def _SkipGroup ( buffer , pos , end ) : <TAB>  """"""Skip sub-group.  Returns the new position."""""" <TAB>  while 1 : <TAB><TAB>  ( tag_bytes , pos ) = ReadTag ( buffer , pos ) <TAB><TAB>  new_pos = SkipField ( buffer , pos , end , tag_bytes ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return pos <TAB><TAB>  pos = new_pos ",if new_pos == - 1 :,if new_pos == pos:,False,35.14780405405439,97.72160520895916
2652,"def update_participants ( self , refresh = True ) : <TAB>  for participant in list ( self . participants_dict ) : <TAB><TAB>  if participant is None or participant == self . simulator_config . broadcast_part : <TAB><TAB><TAB>  continue <TAB><TAB>  self . removeItem ( self . participants_dict [ participant ] ) <TAB><TAB>  self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB><TAB>  del self . participants_dict [ participant ] <TAB>  for participant in self . simulator_config . participants : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . participants_dict [ participant ] . refresh ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . insert_participant ( participant ) <TAB>  if refresh : <TAB><TAB>  self . update_view ( ) ",if participant in self . participants_dict :,if self.participants_dict[participant].state == 'participant-selected':,False,57.48788752501316,95.02057338615674
2653,"def feature_reddit ( layer_data , graph ) : <TAB>  feature = { } <TAB>  times = { } <TAB>  indxs = { } <TAB>  for _type in layer_data : <TAB><TAB>  if len ( layer_data [ _type ] ) == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  idxs = np . array ( list ( layer_data [ _type ] . keys ( ) ) ) <TAB><TAB>  tims = np . array ( list ( layer_data [ _type ] . values ( ) ) ) [ : , 1 ] <TAB><TAB>  feature [ _type ] = np . array ( <TAB><TAB><TAB>  list ( graph . node_feature [ _type ] . loc [ idxs , "" emb "" ] ) , dtype = np . float <TAB><TAB>  ) <TAB><TAB>  times [ _type ] = tims <TAB><TAB>  indxs [ _type ] = idxs <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attr = feature [ _type ] <TAB>  return feature , times , indxs , attr ","if _type == ""def"" :",if _type in feature:,False,24.103649882987717,97.49231392574204
2654,"def _get_sort_map ( tags ) : <TAB>  """"""See TAG_TO_SORT"""""" <TAB>  tts = { } <TAB>  for name , tag in tags . items ( ) : <TAB><TAB>  if tag . has_sort : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tts [ name ] = "" %s sort "" % name <TAB><TAB><TAB>  if tag . internal : <TAB><TAB><TAB><TAB>  tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB>  return tts ",if tag . user :,if tag.sort:,False,50.89781563682347,93.46822566491439
2655,"def max_radius ( iterator ) : <TAB>  radius_result = dict ( ) <TAB>  for k , v in iterator : <TAB><TAB>  if v [ 0 ] not in radius_result : <TAB><TAB><TAB>  radius_result [ v [ 0 ] ] = v [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  radius_result [ v [ 0 ] ] = v [ 1 ] <TAB>  return radius_result ",elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,if k == 'radius':,False,37.7434359304476,85.24890068719017
2656,"def run ( self ) : <TAB>  pwd_found = [ ] <TAB>  if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB><TAB>  main_vault_directory = os . path . join ( <TAB><TAB><TAB>  constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB><TAB>  ) <TAB><TAB>  if os . path . exists ( main_vault_directory ) : <TAB><TAB><TAB>  for vault_directory in os . listdir ( main_vault_directory ) : <TAB><TAB><TAB><TAB>  cred = constant . user_dpapi . decrypt_vault ( <TAB><TAB><TAB><TAB><TAB>  os . path . join ( main_vault_directory , vault_directory ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  pwd_found . append ( cred ) <TAB>  return pwd_found ",if cred :,if cred:,False,23.491796919509483,100.00000000000004
2657,"def disconnect_sync ( self , connection , close_connection = False ) : <TAB>  key = id ( connection ) <TAB>  ts = self . in_use . pop ( key ) <TAB>  if close_connection : <TAB><TAB>  self . connections_map . pop ( key ) <TAB><TAB>  self . _connection_close_sync ( connection ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . connections_map . pop ( key ) <TAB><TAB><TAB>  self . _connection_close_sync ( connection ) <TAB><TAB>  else : <TAB><TAB><TAB>  with self . _lock_sync : <TAB><TAB><TAB><TAB>  heapq . heappush ( self . connections_sync , ( ts , key ) ) ",if self . stale_timeout and self . is_stale ( ts ) :,if ts is None:,False,48.85447040889306,92.32300714350286
2658,"def _populate_tree ( self , element , d ) : <TAB>  """"""Populates an etree with attributes & elements, given a dict."""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB>  self . _populate_dict ( element , k , v ) <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  self . _populate_list ( element , k , v ) <TAB><TAB>  elif isinstance ( v , bool ) : <TAB><TAB><TAB>  self . _populate_bool ( element , k , v ) <TAB><TAB>  elif isinstance ( v , basestring ) : <TAB><TAB><TAB>  self . _populate_str ( element , k , v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _populate_number ( element , k , v ) ","elif type ( v ) in [ int , float , long , complex ] :","if isinstance(v, int):",False,29.174716863793016,93.55263195539807
2659,"def readframes ( self , nframes ) : <TAB>  if self . _ssnd_seek_needed : <TAB><TAB>  self . _ssnd_chunk . seek ( 0 ) <TAB><TAB>  dummy = self . _ssnd_chunk . read ( 8 ) <TAB><TAB>  pos = self . _soundpos * self . _framesize <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _ssnd_chunk . seek ( pos + 8 ) <TAB><TAB>  self . _ssnd_seek_needed = 0 <TAB>  if nframes == 0 : <TAB><TAB>  return "" "" <TAB>  data = self . _ssnd_chunk . read ( nframes * self . _framesize ) <TAB>  if self . _convert and data : <TAB><TAB>  data = self . _convert ( data ) <TAB>  self . _soundpos = self . _soundpos + len ( data ) / ( self . _nchannels * self . _sampwidth ) <TAB>  return data ",if pos :,if pos < 0:,False,38.24426157938814,98.40873830817459
2660,"def target_glob ( tgt , hosts ) : <TAB>  ret = { } <TAB>  for host in hosts : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB><TAB><TAB>  ret [ host ] . update ( { "" host "" : host } ) <TAB><TAB><TAB>  if __opts__ . get ( "" ssh_user "" ) : <TAB><TAB><TAB><TAB>  ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB>  return ret ","if fnmatch . fnmatch ( tgt , host ) :",if host not in tgt:,False,40.550296856144605,94.60586609803777
2661,"def get_attribute_value ( self , nodeid , attr ) : <TAB>  with self . _lock : <TAB><TAB>  self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB><TAB>  if nodeid not in self . _nodes : <TAB><TAB><TAB>  dv = ua . DataValue ( ) <TAB><TAB><TAB>  dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB><TAB><TAB>  return dv <TAB><TAB>  node = self . _nodes [ nodeid ] <TAB><TAB>  if attr not in node . attributes : <TAB><TAB><TAB>  dv = ua . DataValue ( ) <TAB><TAB><TAB>  dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB><TAB><TAB>  return dv <TAB><TAB>  attval = node . attributes [ attr ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return attval . value_callback ( ) <TAB><TAB>  return attval . value ",if attval . value_callback :,"if hasattr(attval, 'value_callback'):",False,24.59323141284735,96.38648747377216
2662,"def remove_property ( self , key ) :<TAB># type: (str) -> None <TAB>  with self . secure ( ) as config : <TAB><TAB>  keys = key . split ( "" . "" ) <TAB><TAB>  current_config = config <TAB><TAB>  for i , key in enumerate ( keys ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  if i == len ( keys ) - 1 : <TAB><TAB><TAB><TAB>  del current_config [ key ] <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  current_config = current_config [ key ] ",if key not in current_config :,if key in current_config:,False,10.230732168823932,96.5642425791005
2663,"def _class_browser ( parent ) :<TAB># Wrapper for htest <TAB>  try : <TAB><TAB>  file = __file__ <TAB>  except NameError : <TAB><TAB>  file = sys . argv [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  file = sys . argv [ 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  file = sys . argv [ 0 ] <TAB>  dir , file = os . path . split ( file ) <TAB>  name = os . path . splitext ( file ) [ 0 ] <TAB>  flist = PyShell . PyShellFileList ( parent ) <TAB>  global file_open <TAB>  file_open = flist . open <TAB>  ClassBrowser ( flist , name , [ dir ] , _htest = True ) ",if sys . argv [ 1 : ] :,if file == 'test':,False,9.1683274031337,94.53449168902064
2664,"def get_only_text_part ( self , msg ) : <TAB>  count = 0 <TAB>  only_text_part = None <TAB>  for part in msg . walk ( ) : <TAB><TAB>  if part . is_multipart ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  count + = 1 <TAB><TAB>  mimetype = part . get_content_type ( ) or "" text/plain "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  only_text_part = part <TAB>  return only_text_part ","if mimetype != ""text/plain"" or count != 1 :",if mimetype != 'text/plain':,False,31.727583344662026,93.0573449725904
2665,"def should_keep_alive ( commit_msg ) : <TAB>  result = False <TAB>  ci = get_current_ci ( ) or "" "" <TAB>  for line in commit_msg . splitlines ( ) : <TAB><TAB>  parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB><TAB>  ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB><TAB>  if key == "" CI_KEEP_ALIVE "" : <TAB><TAB><TAB>  ci_names = val . replace ( "" , "" , "" "" ) . lower ( ) . split ( ) if val else [ ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result = True <TAB>  return result ",if len ( ci_names ) == 0 or ci . lower ( ) in ci_names :,if ci in ci_names:,False,24.42930540169177,91.90324005043136
2666,"def _calc_block_io ( self , blkio ) : <TAB>  """"""Calculate block IO stats."""""" <TAB>  for stats in blkio [ "" io_service_bytes_recursive "" ] : <TAB><TAB>  if stats [ "" op "" ] == "" Read "" : <TAB><TAB><TAB>  self . _blk_read + = stats [ "" value "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _blk_write + = stats [ "" value "" ] ","elif stats [ ""op"" ] == ""Write"" :","if stats['op'] == ""Write':",False,19.824475436356686,91.97068585057495
2667,"def value_to_db_datetime ( self , value ) : <TAB>  if value is None : <TAB><TAB>  return None <TAB>  # Oracle doesn't support tz-aware datetimes <TAB>  if timezone . is_aware ( value ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Oracle backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB><TAB><TAB>  ) <TAB>  return six . text_type ( value ) ",if settings . USE_TZ :,if USE_TZ:,False,63.78716266330008,97.80195524730742
2668,"def load_state_dict ( self , state_dict ) : <TAB>  for module_name , module_state_dict in state_dict . items ( ) : <TAB><TAB>  if module_name in self . module_pool : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . module_pool [ module_name ] . module . load_state_dict ( module_state_dict ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . module_pool [ module_name ] . load_state_dict ( module_state_dict ) <TAB><TAB>  else : <TAB><TAB><TAB>  logging . info ( f "" Missing  { module_name }  in module_pool, skip it.. "" ) ","if self . config [ ""dataparallel"" ] :",if module_name in self.module_pool:,False,23.391717936215077,94.97595580412869
2669,"def _unpack_scales ( scales , vidxs ) : <TAB>  scaleData = [ None , None , None ] <TAB>  for i in range ( 3 ) : <TAB><TAB>  if i > = min ( len ( scales ) , len ( vidxs ) / / 2 ) : <TAB><TAB><TAB>  break <TAB><TAB>  scale = scales [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB><TAB><TAB>  scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB>  return scaleData ",if not math . isnan ( scale ) :,if scale < 0:,False,27.253672993022576,94.77579800309177
2670,"def __init__ ( self , factors , contrast_matrices , num_columns ) : <TAB>  self . factors = tuple ( factors ) <TAB>  factor_set = frozenset ( factors ) <TAB>  if not isinstance ( contrast_matrices , dict ) : <TAB><TAB>  raise ValueError ( "" contrast_matrices must be dict "" ) <TAB>  for factor , contrast_matrix in six . iteritems ( contrast_matrices ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Unexpected factor in contrast_matrices dict "" ) <TAB><TAB>  if not isinstance ( contrast_matrix , ContrastMatrix ) : <TAB><TAB><TAB>  raise ValueError ( "" Expected a ContrastMatrix, not  %r "" % ( contrast_matrix , ) ) <TAB>  self . contrast_matrices = contrast_matrices <TAB>  if not isinstance ( num_columns , six . integer_types ) : <TAB><TAB>  raise ValueError ( "" num_columns must be an integer "" ) <TAB>  self . num_columns = num_columns ",if factor not in factor_set :,if factor not in factor_set:,False,52.37430259814405,100.00000000000004
2671,"def app ( scope , receive , send ) : <TAB>  while True : <TAB><TAB>  message = await receive ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await send ( { "" type "" : "" websocket.accept "" } ) <TAB><TAB>  elif message [ "" type "" ] == "" websocket.receive "" : <TAB><TAB><TAB>  pass <TAB><TAB>  elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB><TAB><TAB>  break ","if message [ ""type"" ] == ""websocket.connect"" :","if message['type'] == ""websocket.accept':",False,15.56597957563729,93.97744438622952
2672,"def value__set ( self , value ) : <TAB>  for i , ( option , checked ) in enumerate ( self . options ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . selectedIndex = i <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" Option  %r  not found (from  %s ) "" <TAB><TAB><TAB>  % ( value , "" ,  "" . join ( [ repr ( o ) for o , c in self . options ] ) ) <TAB><TAB>  ) ",if option == str ( value ) :,if checked:,False,51.59754028739142,94.06584284416812
2673,"def init_links ( self ) : <TAB>  links = LinkCallback . find_links ( self ) <TAB>  callbacks = [ ] <TAB>  for link , src_plot , tgt_plot in links : <TAB><TAB>  cb = Link . _callbacks [ "" bokeh "" ] [ type ( link ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  callbacks . append ( cb ( self . root , link , src_plot , tgt_plot ) ) <TAB>  return callbacks ",if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,if cb is None:,False,19.170264648260986,84.0190027600681
2674,"def _validate_scalar_extensions ( self ) - > List [ str ] : <TAB>  errors = [ ] <TAB>  for extension in [ <TAB><TAB>  x for x in self . extensions if isinstance ( x , GraphQLScalarTypeExtension ) <TAB>  ] : <TAB><TAB>  extended = self . type_definitions . get ( extension . name ) <TAB><TAB>  ext_errors = _validate_extension ( <TAB><TAB><TAB>  extended , extension . name , GraphQLScalarType , "" SCALAR "" <TAB><TAB>  ) <TAB><TAB>  errors . extend ( ext_errors ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  errors . extend ( _validate_extension_directives ( extension , extended , "" SCALAR "" ) ) <TAB>  return errors ",if not ext_errors :,if extension.directives:,False,22.45429903069109,96.88064591680777
2675,"def copy_tcltk ( src , dest , symlink ) : <TAB>  """"""copy tcl/tk libraries on Windows (issue #93)"""""" <TAB>  for libversion in "" 8.5 "" , "" 8.6 "" : <TAB><TAB>  for libname in "" tcl "" , "" tk "" : <TAB><TAB><TAB>  srcdir = join ( src , "" tcl "" , libname + libversion ) <TAB><TAB><TAB>  destdir = join ( dest , "" tcl "" , libname + libversion ) <TAB><TAB><TAB>  # Only copy the dirs from the above combinations that exist <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  copyfileordir ( srcdir , destdir , symlink ) ",if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,if os.path.exists(srcdir):,False,61.19682387221332,93.82832119973152
2676,"def parse ( self , response ) : <TAB>  try : <TAB><TAB>  content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB><TAB>  content = json . loads ( content , strict = False ) <TAB>  except : <TAB><TAB>  self . logger . error ( "" Fail to parse the response in json format "" ) <TAB><TAB>  return <TAB>  for item in content [ "" data "" ] : <TAB><TAB>  if "" objURL "" in item : <TAB><TAB><TAB>  img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  img_url = item [ "" hoverURL "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  continue <TAB><TAB>  yield dict ( file_url = img_url ) ","elif ""hoverURL"" in item :",if 'hoverURL' in item:,False,43.54890320119522,97.33429951184998
2677,"def check_and_reload ( self ) : <TAB>  # Check if tables have been modified, if so reload <TAB>  for table_name , table_version in self . _table_versions . items ( ) : <TAB><TAB>  table = self . app . tool_data_tables . get ( table_name , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . reload_genomes ( ) ",if table is not None and not table . is_current_version ( table_version ) :,if table is not None and (not table.is_modified()):,False,40.80435213455751,91.43257886504107
2678,"def _get_query_defaults ( self , query_defns ) : <TAB>  defaults = { } <TAB>  for k , v in query_defns . items ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  defaults [ k ] = self . _get_default_obj ( v [ "" schema "" ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  defaults [ k ] = v [ "" schema "" ] [ "" default "" ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  pass <TAB>  return defaults ","if v [ ""schema"" ] [ ""type"" ] == ""object"" :",if k == 'default':,False,43.82487731927266,89.79580996694757
2679,"def ftp_login ( host , port , username = None , password = None , anonymous = False ) : <TAB>  ret = False <TAB>  try : <TAB><TAB>  ftp = ftplib . FTP ( ) <TAB><TAB>  ftp . connect ( host , port , timeout = 6 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ftp . login ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  ftp . login ( username , password ) <TAB><TAB>  ret = True <TAB><TAB>  ftp . quit ( ) <TAB>  except Exception : <TAB><TAB>  pass <TAB>  return ret ",if anonymous :,if anonymous:,False,50.52172713515806,100.00000000000004
2680,"def _getVolumeScalar ( self ) : <TAB>  if self . _volumeScalar is not None : <TAB><TAB>  return self . _volumeScalar <TAB>  # use default <TAB>  elif self . _value in dynamicStrToScalar : <TAB><TAB>  return dynamicStrToScalar [ self . _value ] <TAB>  else : <TAB><TAB>  thisDynamic = self . _value <TAB><TAB>  # ignore leading s like in sf <TAB><TAB>  if "" s "" in thisDynamic : <TAB><TAB><TAB>  thisDynamic = thisDynamic [ 1 : ] <TAB><TAB>  # ignore closing z like in fz <TAB><TAB>  if thisDynamic [ - 1 ] == "" z "" : <TAB><TAB><TAB>  thisDynamic = thisDynamic [ : - 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return dynamicStrToScalar [ thisDynamic ] <TAB><TAB>  else : <TAB><TAB><TAB>  return dynamicStrToScalar [ None ] ",if thisDynamic in dynamicStrToScalar :,if thisDynamic in dynamicStrToScalar:,False,57.48741931210728,96.7098769661705
2681,"def processCoords ( coords ) : <TAB>  newcoords = deque ( ) <TAB>  for ( x , y , z ) in coords : <TAB><TAB>  for _dir , offsets in faceDirections : <TAB><TAB><TAB>  if _dir == FaceYIncreasing : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  dx , dy , dz = offsets <TAB><TAB><TAB>  p = ( x + dx , y + dy , z + dz ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  nx , ny , nz = p <TAB><TAB><TAB>  if level . blockAt ( nx , ny , nz ) == 0 : <TAB><TAB><TAB><TAB>  level . setBlockAt ( nx , ny , nz , waterID ) <TAB><TAB><TAB><TAB>  newcoords . append ( p ) <TAB>  return newcoords ",if p not in box :,if p == 0:,False,26.06545532879312,97.99169879152134
2682,"def _set_property ( self , target_widget , pname , value ) : <TAB>  if pname == "" text "" : <TAB><TAB>  wstate = str ( target_widget [ "" state "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # change state temporarily <TAB><TAB><TAB>  target_widget [ "" state "" ] = "" normal "" <TAB><TAB>  target_widget . delete ( "" 0 "" , tk . END ) <TAB><TAB>  target_widget . insert ( "" 0 "" , value ) <TAB><TAB>  target_widget [ "" state "" ] = wstate <TAB>  else : <TAB><TAB>  super ( EntryBaseBO , self ) . _set_property ( target_widget , pname , value ) ","if wstate != ""normal"" :",if wstate == tk.START:,False,46.5423287626061,96.48964205142097
2683,"def teardown ( ) : <TAB>  try : <TAB><TAB>  time . sleep ( 1 ) <TAB>  except KeyboardInterrupt : <TAB><TAB>  return <TAB>  while launchers : <TAB><TAB>  p = launchers . pop ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  p . stop ( ) <TAB><TAB><TAB>  except Exception as e : <TAB><TAB><TAB><TAB>  print ( e ) <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  time . sleep ( 0.25 ) <TAB><TAB><TAB>  except KeyboardInterrupt : <TAB><TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  print ( "" cleaning up test process... "" ) <TAB><TAB><TAB><TAB>  p . signal ( SIGKILL ) <TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB>  print ( "" couldn ' t shutdown process:  "" , p ) ",if p . poll ( ) is None :,if p.is_alive():,False,20.935860266888273,91.2314900244045
2684,"def checkAndRemoveDuplicate ( self , node ) : <TAB>  for bucket in self . buckets : <TAB><TAB>  for n in bucket . getNodes ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . removeContact ( n ) ","if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id :",if n.getNodeType() == node.getNodeType() and n.getNode,False,18.72610298372651,70.85069877496124
2685,"def toString ( ) : <TAB>  flags = u "" "" <TAB>  try : <TAB><TAB>  if this . glob : <TAB><TAB><TAB>  flags + = u "" g "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flags + = u "" i "" <TAB><TAB>  if this . multiline : <TAB><TAB><TAB>  flags + = u "" m "" <TAB>  except : <TAB><TAB>  pass <TAB>  v = this . value if this . value else "" (?:) "" <TAB>  return u "" / %s / "" % v + flags ",if this . ignore_case :,if this.is_in_glob:,False,33.082916150291254,95.74945784830359
2686,"def import_submodules ( package_name ) : <TAB>  package = sys . modules [ package_name ] <TAB>  results = { } <TAB>  for loader , name , is_pkg in pkgutil . iter_modules ( package . __path__ ) : <TAB><TAB>  full_name = package_name + "" . "" + name <TAB><TAB>  module = importlib . import_module ( full_name ) <TAB><TAB>  setattr ( sys . modules [ __name__ ] , name , module ) <TAB><TAB>  results [ full_name ] = module <TAB><TAB>  if is_pkg : <TAB><TAB><TAB>  valid_pkg = import_submodules ( full_name ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  results . update ( valid_pkg ) <TAB>  return results ",if valid_pkg :,if valid_pkg:,False,51.75796131372652,100.00000000000004
2687,"def _call ( self , cmd ) : <TAB>  what = cmd [ "" command "" ] <TAB>  if what == "" list "" : <TAB><TAB>  name = cmd [ "" properties "" ] . get ( "" name "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return { "" watchers "" : [ "" one "" , "" two "" , "" three "" ] } <TAB><TAB>  return { "" pids "" : [ 123 , 456 ] } <TAB>  elif what == "" dstats "" : <TAB><TAB>  return { "" info "" : { "" pid "" : 789 } } <TAB>  elif what == "" listsockets "" : <TAB><TAB>  return { <TAB><TAB><TAB>  "" status "" : "" ok "" , <TAB><TAB><TAB>  "" sockets "" : [ { "" path "" : self . _unix , "" fd "" : 5 , "" name "" : "" XXXX "" , "" backlog "" : 2048 } ] , <TAB><TAB><TAB>  "" time "" : 1369647058.967524 , <TAB><TAB>  } <TAB>  raise NotImplementedError ( cmd ) ",if name is None :,if name == 'pids':,False,48.409678212074645,98.21479206893271
2688,"def select ( self ) : <TAB>  e = xlib . XEvent ( ) <TAB>  while xlib . XPending ( self . _display ) : <TAB><TAB>  xlib . XNextEvent ( self . _display , e ) <TAB><TAB>  # Key events are filtered by the xlib window event <TAB><TAB>  # handler so they get a shot at the prefiltered event. <TAB><TAB>  if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  dispatch = self . _window_map [ e . xany . window ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  continue <TAB><TAB>  dispatch ( e ) ","if xlib . XFilterEvent ( e , e . xany . window ) :",if e.xany.type == xlib.XApplication.TYPE_WINDOW:,False,65.0952442812873,93.92978134875496
2689,"def translate ( self , line ) : <TAB>  parsed = self . RE_LINE_PARSER . match ( line ) <TAB>  if parsed : <TAB><TAB>  value = parsed . group ( 3 ) <TAB><TAB>  stage = parsed . group ( 1 ) <TAB><TAB>  <IF-STMT>:<TAB># query string is rendered here <TAB><TAB><TAB>  return "" \n # HTTP Request: \n "" + self . stripslashes ( value ) <TAB><TAB>  elif stage == "" reply "" : <TAB><TAB><TAB>  return "" \n \n # HTTP Response: \n "" + self . stripslashes ( value ) <TAB><TAB>  elif stage == "" header "" : <TAB><TAB><TAB>  return value + "" \n "" <TAB><TAB>  else : <TAB><TAB><TAB>  return value <TAB>  return line ","if stage == ""send"" :","if stage == ""request':",False,31.657108018257414,96.92189644688507
2690,"def toString ( ) : <TAB>  flags = u "" "" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flags + = u "" g "" <TAB><TAB>  if this . ignore_case : <TAB><TAB><TAB>  flags + = u "" i "" <TAB><TAB>  if this . multiline : <TAB><TAB><TAB>  flags + = u "" m "" <TAB>  except : <TAB><TAB>  pass <TAB>  v = this . value if this . value else "" (?:) "" <TAB>  return u "" / %s / "" % v + flags ",if this . glob :,if this.case:,False,33.082916150291254,98.27267114919535
2691,"def __exit__ ( self , * exc_info ) : <TAB>  super ( WarningsChecker , self ) . __exit__ ( * exc_info ) <TAB>  # only check if we're not currently handling an exception <TAB>  if all ( a is None for a in exc_info ) : <TAB><TAB>  if self . expected_warning is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  __tracebackhide__ = True <TAB><TAB><TAB><TAB>  pytest . fail ( "" DID NOT WARN "" ) ",if not any ( r . category in self . expected_warning for r in self ) :,if self.expected_warning is not None:,False,62.761517069903825,89.98646769886824
2692,"def run ( self ) : <TAB>  for k , v in iteritems ( self . objs ) : <TAB><TAB>  if k . startswith ( "" _ "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if v [ "" email "" ] == "" "" : <TAB><TAB><TAB><TAB>  v [ "" email "" ] = None <TAB><TAB><TAB>  if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB><TAB><TAB><TAB>  v [ "" ip "" ] = None <TAB>  return self . objs ","if v [ ""_class"" ] == ""User"" :",if v['type'] == 'email':,False,50.90845971940035,93.52700587026699
2693,"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB>  for i in range ( upto ) : <TAB><TAB>  if i < = start_after : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . count + = 1 <TAB><TAB><TAB>  raise TemporaryProblem <TAB><TAB>  if i == 7 and self . count < 4 : <TAB><TAB><TAB>  self . count + = 1 <TAB><TAB><TAB>  raise TemporaryProblem <TAB><TAB>  yield i ",if i == 2 and self . count < 1 :,if i == 7 and self.count < 4:,False,49.89289101267578,94.39157801361233
2694,"def check ( self ) : <TAB>  tcp_client = self . tcp_create ( ) <TAB>  if tcp_client . connect ( ) : <TAB><TAB>  tcp_client . send ( b "" ABCDE "" ) <TAB><TAB>  response = tcp_client . recv ( 5 ) <TAB><TAB>  tcp_client . close ( ) <TAB><TAB>  if response : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . endianness = "" > ""<TAB># BE <TAB><TAB><TAB>  elif response . startswith ( b "" ScMM "" ) : <TAB><TAB><TAB><TAB>  self . endianness = "" < ""<TAB># LE <TAB><TAB><TAB>  return True<TAB># target is vulnerable <TAB>  return False<TAB># target is not vulnerable ","if response . startswith ( b""MMcS"" ) :","if response.startswith(b""DJM""):",False,21.90521412539089,89.91705268439054
2695,"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB>  for src_root , _ , files in os . walk ( src_dir ) : <TAB><TAB>  if src_root != src_dir : <TAB><TAB><TAB>  rel_root = os . path . relpath ( src_root , src_dir ) <TAB><TAB>  else : <TAB><TAB><TAB>  rel_root = "" "" <TAB><TAB>  if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  dst_root = os . path . join ( dst_dir , rel_root ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( dst_root ) <TAB><TAB>  for f in files : <TAB><TAB><TAB>  shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) ) ",if not os . path . exists ( dst_root ) :,if not os.path.exists(dst_root):,False,50.946515200374584,100.00000000000004
2696,"def _set_hostport ( self , host , port ) : <TAB>  if port is None : <TAB><TAB>  i = host . rfind ( "" : "" ) <TAB><TAB>  j = host . rfind ( "" ] "" )<TAB># ipv6 addresses have [...] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  port = int ( host [ i + 1 : ] ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  raise InvalidURL ( "" nonnumeric port:  ' %s ' "" % host [ i + 1 : ] ) <TAB><TAB><TAB>  host = host [ : i ] <TAB><TAB>  else : <TAB><TAB><TAB>  port = self . default_port <TAB><TAB>  if host and host [ 0 ] == "" [ "" and host [ - 1 ] == "" ] "" : <TAB><TAB><TAB>  host = host [ 1 : - 1 ] <TAB>  self . host = host <TAB>  self . port = port ",if i > j :,if i >= 0 and j >= 0:,False,25.30433943771303,91.17175734685564
2697,"def _get_field_value ( self , test , key , match ) : <TAB>  if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB>  members = inspect . getmembers ( match ) <TAB><TAB>  for member in members : <TAB><TAB><TAB>  if member [ 0 ] == key : <TAB><TAB><TAB><TAB>  field_value = member [ 1 ] <TAB><TAB><TAB>  elif member [ 0 ] == "" wildcards "" : <TAB><TAB><TAB><TAB>  wildcards = member [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB>  elif key == "" nw_dst "" : <TAB><TAB><TAB>  field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB>  else : <TAB><TAB>  field_value = match [ key ] <TAB>  return field_value ","if key == ""nw_src"" :","if key == ""nw_src"":",False,50.787767120246016,100.00000000000004
2698,"def _clear_storage ( ) : <TAB>  """"""Clear old files from storage."""""" <TAB>  hacs = get_hacs ( ) <TAB>  storagefiles = [ "" hacs "" ] <TAB>  for s_f in storagefiles : <TAB><TAB>  path = f "" { hacs . core . config_path } /.storage/ { s_f } "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  hacs . log . info ( f "" Cleaning up old storage file  { path } "" ) <TAB><TAB><TAB>  os . remove ( path ) ",if os . path . isfile ( path ) :,if os.path.exists(path):,False,22.781562272978697,98.18487054407757
2699,"def action_delete ( self , ids ) : <TAB>  try : <TAB><TAB>  count = 0 <TAB><TAB>  # TODO: Optimize me <TAB><TAB>  for pk in ids : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  count + = 1 <TAB><TAB>  flash ( <TAB><TAB><TAB>  ngettext ( <TAB><TAB><TAB><TAB>  "" Record was successfully deleted. "" , <TAB><TAB><TAB><TAB>  "" %(count)s  records were successfully deleted. "" , <TAB><TAB><TAB><TAB>  count , <TAB><TAB><TAB><TAB>  count = count , <TAB><TAB><TAB>  ) , <TAB><TAB><TAB>  "" success "" , <TAB><TAB>  ) <TAB>  except Exception as ex : <TAB><TAB>  flash ( gettext ( "" Failed to delete records.  %(error)s "" , error = str ( ex ) ) , "" error "" ) ",if self . delete_model ( self . get_one ( pk ) ) :,if pk.is_valid():,False,52.62609275513306,94.26204802357039
2700,"def test_inclusion ( all_values ) : <TAB>  for values in [ { "" guid_2 "" , "" guid_1 "" } , { "" guid_5 "" , "" guid_XXX "" } , { "" guid_2 "" } ] : <TAB><TAB>  test_predicate = in_set ( values , "" volume_guid "" ) <TAB><TAB>  included_values = set ( ) <TAB><TAB>  for val in all_values : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  included_values . add ( val ) <TAB><TAB>  assert included_values == all_values . intersection ( values ) ","if test_predicate . do_include ( { ""volume_guid"" : val } ) :",if test_predicate(val):,False,47.976794888966324,90.95000821153035
2701,"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB>  try : <TAB><TAB>  attr_mod , attr_path = ( <TAB><TAB><TAB>  mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB><TAB>  ) <TAB><TAB>  full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB><TAB>  op = import_module ( full_mod_path ) <TAB><TAB>  if attr_path : <TAB><TAB><TAB>  # Only load attributes if needed <TAB><TAB><TAB>  for part in attr_path . split ( "" . "" ) : <TAB><TAB><TAB><TAB>  op = getattr ( op , part ) <TAB><TAB>  return op <TAB>  except ( ImportError , AttributeError ) as ex : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  raise ex ",if checked :,if checked:,False,54.53678498217273,100.00000000000004
2702,"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB>  if self . fusefat is not None : <TAB><TAB>  self . fusefat . send_signal ( signal . SIGINT ) <TAB><TAB>  # Allow 1s to return without sending terminate <TAB><TAB>  for count in range ( 10 ) : <TAB><TAB><TAB>  time . sleep ( 0.1 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  self . fusefat . terminate ( ) <TAB><TAB>  time . sleep ( self . delay ) <TAB><TAB>  assert not os . path . exists ( self . canary ) <TAB>  self . dev_null . close ( ) <TAB>  shutil . rmtree ( self . tmpdir ) ",if self . fusefat . poll ( ) is not None :,if self.fusefat is None:,False,58.252124838113794,96.4536868295149
2703,"def check_context_processors ( output ) : <TAB>  with output . section ( "" Context processors "" ) as section : <TAB><TAB>  processors = list ( <TAB><TAB><TAB>  chain ( <TAB><TAB><TAB><TAB>  * [ <TAB><TAB><TAB><TAB><TAB>  template [ "" OPTIONS "" ] . get ( "" context_processors "" , [ ] ) <TAB><TAB><TAB><TAB><TAB>  for template in settings . TEMPLATES <TAB><TAB><TAB><TAB>  ] <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB><TAB>  required_processors = ( "" cms.context_processors.cms_settings "" , ) <TAB><TAB>  for processor in required_processors : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  section . error ( <TAB><TAB><TAB><TAB><TAB>  "" %s  context processor must be in TEMPLATES option context_processors "" <TAB><TAB><TAB><TAB><TAB>  % processor <TAB><TAB><TAB><TAB>  ) ",if processor not in processors :,if processor not in processors:,False,59.60872755773144,100.00000000000004
2704,"def test_converters ( self ) : <TAB>  response = self . _get ( "" datatypes/converters "" ) <TAB>  self . _assert_status_code_is ( response , 200 ) <TAB>  converters_list = response . json ( ) <TAB>  found_fasta_to_tabular = False <TAB>  for converter in converters_list : <TAB><TAB>  self . _assert_has_key ( converter , "" source "" , "" target "" , "" tool_id "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  found_fasta_to_tabular = True <TAB>  assert found_fasta_to_tabular ","if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :",if converter.source == 'target':,False,28.324868361262006,85.95682082359693
2705,"def remove_pid ( self , watcher , pid ) : <TAB>  if pid in self . _pids [ watcher ] : <TAB><TAB>  logger . debug ( "" Removing  %d  from  %s "" % ( pid , watcher ) ) <TAB><TAB>  self . _pids [ watcher ] . remove ( pid ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( "" Stopping the periodic callback for  {0} "" . format ( watcher ) ) <TAB><TAB><TAB>  self . _callbacks [ watcher ] . stop ( ) ",if len ( self . _pids [ watcher ] ) == 0 :,if self._callbacks[watcher] is not None:,False,27.218685104308804,91.58184818237656
2706,"def _fc_layer ( self , sess , bottom , name , trainable = True , relu = True ) : <TAB>  with tf . variable_scope ( name ) as scope : <TAB><TAB>  shape = bottom . get_shape ( ) . as_list ( ) <TAB><TAB>  dim = 1 <TAB><TAB>  for d in shape [ 1 : ] : <TAB><TAB><TAB>  dim * = d <TAB><TAB>  x = tf . reshape ( bottom , [ - 1 , dim ] ) <TAB><TAB>  weight = self . _get_fc_weight ( sess , name , trainable = trainable ) <TAB><TAB>  bias = self . _get_bias ( sess , name , trainable = trainable ) <TAB><TAB>  fc = tf . nn . bias_add ( tf . matmul ( x , weight ) , bias ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fc = tf . nn . relu ( fc ) <TAB><TAB>  return fc ",if relu :,if relu:,False,46.62284466485607,98.4509957049839
2707,"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB>  for drive in self . drives : <TAB><TAB>  if root_path : <TAB><TAB><TAB>  config_root_path = drive . get ( "" root_path "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return drive <TAB><TAB>  elif volume_guid_path : <TAB><TAB><TAB>  config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB><TAB><TAB>  if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB><TAB><TAB><TAB>  return drive ",if config_root_path and root_path == config_root_path :,if config_root_path and config_root_path == root_path:,False,50.92028828812638,98.47572970775693
2708,"def rewire_init ( expr ) : <TAB>  new_args = [ ] <TAB>  if expr [ 0 ] == HySymbol ( "" setv "" ) : <TAB><TAB>  pairs = expr [ 1 : ] <TAB><TAB>  while len ( pairs ) > 0 : <TAB><TAB><TAB>  k , v = ( pairs . pop ( 0 ) , pairs . pop ( 0 ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  v . append ( HySymbol ( "" None "" ) ) <TAB><TAB><TAB>  new_args . append ( k ) <TAB><TAB><TAB>  new_args . append ( v ) <TAB><TAB>  expr = HyExpression ( [ HySymbol ( "" setv "" ) ] + new_args ) . replace ( expr ) <TAB>  return expr ","if k == HySymbol ( ""__init__"" ) :",if k == 'None':,False,37.11798616142497,94.22202437092055
2709,"def doDir ( elem ) : <TAB>  for child in elem . childNodes : <TAB><TAB>  if not isinstance ( child , minidom . Element ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  doDir ( child ) <TAB><TAB>  elif child . tagName == "" Component "" : <TAB><TAB><TAB>  for grandchild in child . childNodes : <TAB><TAB><TAB><TAB>  if not isinstance ( grandchild , minidom . Element ) : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  if grandchild . tagName != "" File "" : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if child . tagName == ""Directory"" :","if child.tagName == ""Directory':",False,13.320864319628539,98.37385298415288
2710,"def _v2_common ( self , cfg ) : <TAB>  LOG . debug ( "" v2_common: handling config: \n %s "" , cfg ) <TAB>  if "" nameservers "" in cfg : <TAB><TAB>  search = cfg . get ( "" nameservers "" ) . get ( "" search "" , [ ] ) <TAB><TAB>  dns = cfg . get ( "" nameservers "" ) . get ( "" addresses "" , [ ] ) <TAB><TAB>  name_cmd = { "" type "" : "" nameserver "" } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name_cmd . update ( { "" search "" : search } ) <TAB><TAB>  if len ( dns ) > 0 : <TAB><TAB><TAB>  name_cmd . update ( { "" addresses "" : dns } ) <TAB><TAB>  LOG . debug ( "" v2(nameserver) -> v1(nameserver): \n %s "" , name_cmd ) <TAB><TAB>  self . handle_nameserver ( name_cmd ) ",if len ( search ) > 0 :,if search:,False,22.483012005609787,96.90748998248048
2711,"def __start_element_handler ( self , name , attrs ) : <TAB>  if name == "" mime-type "" : <TAB><TAB>  if self . type : <TAB><TAB><TAB>  for extension in self . extensions : <TAB><TAB><TAB><TAB>  self [ extension ] = self . type <TAB><TAB>  self . type = attrs [ "" type "" ] . lower ( ) <TAB><TAB>  self . extensions = [ ] <TAB>  elif name == "" glob "" : <TAB><TAB>  pattern = attrs [ "" pattern "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . extensions . append ( pattern [ 1 : ] . lower ( ) ) ","if pattern . startswith ( ""*."" ) :",if pattern:,False,22.818094081067457,94.38638051526885
2712,"def get_attr_by_data_model ( self , dmodel , exclude_record = False ) : <TAB>  if exclude_record : <TAB><TAB>  return list ( <TAB><TAB><TAB>  filter ( <TAB><TAB><TAB><TAB>  lambda x : x . data_model == dmodel and x . value == "" "" <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  else False , <TAB><TAB><TAB><TAB>  self . _inferred_intent , <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return list ( <TAB><TAB><TAB>  filter ( <TAB><TAB><TAB><TAB>  lambda x : x . data_model == dmodel and x . value == "" "" <TAB><TAB><TAB><TAB>  if hasattr ( x , "" data_model "" ) <TAB><TAB><TAB><TAB>  else False , <TAB><TAB><TAB><TAB>  self . _inferred_intent , <TAB><TAB><TAB>  ) <TAB><TAB>  ) ","if x . attribute != ""Record"" and hasattr ( x , ""data_model"" )","if hasattr(x, 'data_model'):",False,49.607063171868006,93.96764507336465
2713,"def general ( metadata , value ) : <TAB>  if metadata . get ( "" commands "" ) and value : <TAB><TAB>  if not metadata . get ( "" nargs "" ) : <TAB><TAB><TAB>  v = quote ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  v = value <TAB><TAB>  return u "" {0} {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB>  else : <TAB><TAB>  if not value : <TAB><TAB><TAB>  return None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return quote ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  return value ","elif not metadata . get ( ""nargs"" ) :",if not metadata.get('nargs'):,False,22.04261301217234,96.10878903418084
2714,"def get_images ( self ) : <TAB>  images = [ ] <TAB>  try : <TAB><TAB>  tag = MP4 ( self [ "" ~filename "" ] ) <TAB>  except Exception : <TAB><TAB>  return [ ] <TAB>  for cover in tag . get ( "" covr "" , [ ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mime = "" image/jpeg "" <TAB><TAB>  elif cover . imageformat == MP4Cover . FORMAT_PNG : <TAB><TAB><TAB>  mime = "" image/png "" <TAB><TAB>  else : <TAB><TAB><TAB>  mime = "" image/ "" <TAB><TAB>  f = get_temp_cover_file ( cover ) <TAB><TAB>  images . append ( EmbeddedImage ( f , mime ) ) <TAB>  return images ",if cover . imageformat == MP4Cover . FORMAT_JPEG :,if cover.imageformat == MP4Cover.FORMAT_JPEG:,False,50.881483046883666,100.00000000000004
2715,"def run_cmd ( self , util , value ) : <TAB>  state = util . state <TAB>  if not state . argument_supplied : <TAB><TAB>  state . argument_supplied = True <TAB><TAB>  if value == "" by_four "" : <TAB><TAB><TAB>  state . argument_value = 4 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  state . argument_negative = True <TAB><TAB>  else : <TAB><TAB><TAB>  state . argument_value = value <TAB>  elif value == "" by_four "" : <TAB><TAB>  state . argument_value * = 4 <TAB>  elif isinstance ( value , int ) : <TAB><TAB>  state . argument_value * = 10 <TAB><TAB>  state . argument_value + = value <TAB>  <IF-STMT>: <TAB><TAB>  state . argument_value = - state . argument_value ","elif value == ""negative"" :",if value == 0:,False,24.032606485317395,91.86752749351764
2716,"def finish_character_data ( self ) : <TAB>  if self . character_data : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line , column = self . character_pos <TAB><TAB><TAB>  token = XmlToken ( <TAB><TAB><TAB><TAB>  XML_CHARACTER_DATA , self . character_data , None , line , column <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . tokens . append ( token ) <TAB><TAB>  self . character_data = "" "" ",if not self . skip_ws or not self . character_data . isspace ( ) :,if self.character_data:,False,43.76423301650318,89.3370401131276
2717,"def check_syntax ( filename , raise_error = False ) : <TAB>  """"""Return True if syntax is okay."""""" <TAB>  with autopep8 . open_with_encoding ( filename ) as input_file : <TAB><TAB>  try : <TAB><TAB><TAB>  compile ( input_file . read ( ) , "" <string> "" , "" exec "" , dont_inherit = True ) <TAB><TAB><TAB>  return True <TAB><TAB>  except ( SyntaxError , TypeError , UnicodeDecodeError ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return False ",if raise_error :,if raise_error:,False,54.95958688862361,100.00000000000004
2718,"def write ( self , file ) : <TAB>  if not self . _been_written : <TAB><TAB>  self . _been_written = True <TAB><TAB>  for attribute , value in self . __dict__ . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . write_recursive ( value , file ) <TAB><TAB>  w = file . write <TAB><TAB>  w ( "" \t %s  =  { \n "" % self . _id ) <TAB><TAB>  w ( "" \t \t isa =  %s ; \n "" % self . __class__ . __name__ ) <TAB><TAB>  for attribute , value in self . __dict__ . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  w ( "" \t \t %s  =  %s ; \n "" % ( attribute , self . tostring ( value ) ) ) <TAB><TAB>  w ( "" \t }; \n \n "" ) ","if attribute [ 0 ] != ""_"" :",if attribute == self._id:,False,31.351259494022145,91.51031072553397
2719,"def update_service_key ( kid , name = None , metadata = None ) : <TAB>  try : <TAB><TAB>  with db_transaction ( ) : <TAB><TAB><TAB>  key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB><TAB><TAB>  if name is not None : <TAB><TAB><TAB><TAB>  key . name = name <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  key . metadata . update ( metadata ) <TAB><TAB><TAB>  key . save ( ) <TAB>  except ServiceKey . DoesNotExist : <TAB><TAB>  raise ServiceKeyDoesNotExist ",if metadata is not None :,if metadata is not None:,False,52.91091426756921,100.00000000000004
2720,"def fill_buf ( self , db , len_ = None ) : <TAB>  with open ( "" /dev/urandom "" , "" rb "" ) as rfh : <TAB><TAB>  first = True <TAB><TAB>  for ( id_ , ) in db . query ( "" SELECT id FROM test "" ) : <TAB><TAB><TAB>  if len_ is None and first : <TAB><TAB><TAB><TAB>  val = b "" ""<TAB># We always want to check this case <TAB><TAB><TAB><TAB>  first = False <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  val = rfh . read ( random . randint ( 0 , 140 ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  val = rfh . read ( len_ ) <TAB><TAB><TAB>  db . execute ( "" UPDATE test SET buf=? WHERE id=? "" , ( val , id_ ) ) ",elif len_ is None :,if len_ is None:,False,47.73117366407965,97.0054827840638
2721,"def load_category_from_parser ( self , parser ) : <TAB>  for cate in parser . keys ( ) : <TAB><TAB>  id = parser . get_id ( cate ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _data [ "" cates "" ] [ id ] = 0 <TAB><TAB>  else : <TAB><TAB><TAB>  self . _data [ "" cates "" ] [ id ] = self . count_unread ( id ) <TAB>  self . _is_init = False <TAB>  self . save ( ) ",if self . _is_init :,if id not in self._data['cats']:,False,26.32416429388745,92.751187254387
2722,"def after_insert ( self ) : <TAB>  if self . prescription : <TAB><TAB>  frappe . db . set_value ( <TAB><TAB><TAB>  "" Lab Prescription "" , self . prescription , "" lab_test_created "" , 1 <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . invoiced = True <TAB>  if not self . lab_test_name and self . template : <TAB><TAB>  self . load_test_from_template ( ) <TAB><TAB>  self . reload ( ) ","if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :",if self.invoiced:,False,30.1982936983374,85.0945977895872
2723,"def sync_terminology ( self ) : <TAB>  if self . is_source : <TAB><TAB>  return <TAB>  store = self . store <TAB>  missing = [ ] <TAB>  for source in self . component . get_all_sources ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  _unit , add = store . find_unit ( source . context , source . source ) <TAB><TAB>  except UnitNotFound : <TAB><TAB><TAB>  add = True <TAB><TAB>  # Unit is already present <TAB><TAB>  if not add : <TAB><TAB><TAB>  continue <TAB><TAB>  missing . append ( ( source . context , source . source , "" "" ) ) <TAB>  if missing : <TAB><TAB>  self . add_units ( None , missing ) ","if ""terminology"" not in source . all_flags :",if not source.context:,False,24.032114366275756,95.14244825904377
2724,def refresh ( self ) : <TAB>  if self . _obj : <TAB><TAB>  base = self . _db . get_media_from_handle ( self . _obj . get_reference_handle ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _title = base . get_description ( ) <TAB><TAB><TAB>  self . _value = base . get_path ( ) ,if base :,if base:,False,50.94030852721202,100.00000000000004
2725,"def _set_parse_context ( self , tag , tag_attrs ) : <TAB>  # special case: script or style parse context <TAB>  if not self . _wb_parse_context : <TAB><TAB>  if tag == "" style "" : <TAB><TAB><TAB>  self . _wb_parse_context = "" style "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . _allow_js_type ( tag_attrs ) : <TAB><TAB><TAB><TAB>  self . _wb_parse_context = "" script "" ","elif tag == ""script"" :","if tag == ""script':",False,34.21480969507152,95.64535786036713
2726,"def can_read ( self ) : <TAB>  if hasattr ( self . file , "" __iter__ "" ) : <TAB><TAB>  iterator = iter ( self . file ) <TAB><TAB>  head = next ( iterator , None ) <TAB><TAB>  if head is None : <TAB><TAB><TAB>  self . repaired = [ ] <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . repaired = itertools . chain ( [ head ] , iterator ) <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  # We may have mangled a generator at this point, so just abort <TAB><TAB><TAB>  raise IOSourceError ( <TAB><TAB><TAB><TAB>  "" Could not open source:  %r  (mode:  %r ) "" <TAB><TAB><TAB><TAB>  % ( self . file , self . options [ "" mode "" ] ) <TAB><TAB><TAB>  ) <TAB>  return False ","if isinstance ( head , str ) :",if head in self.recuraired:,False,59.792655406026455,97.10283292361264
2727,"def wrapped_request_method ( * args , * * kwargs ) : <TAB>  """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB>  if kwargs . get ( "" headers "" ) is not None : <TAB><TAB>  if kwargs [ "" headers "" ] . get ( "" user-agent "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # Save the existing user-agent header and tack on our own. <TAB><TAB><TAB><TAB>  kwargs [ "" headers "" ] [ "" user-agent "" ] = ( <TAB><TAB><TAB><TAB><TAB>  f "" { user_agent } "" f ' { kwargs [ "" headers "" ] [ "" user-agent "" ] } ' <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  kwargs [ "" headers "" ] [ "" user-agent "" ] = user_agent <TAB>  else : <TAB><TAB>  kwargs [ "" headers "" ] = { "" user-agent "" : user_agent } <TAB>  return request_method ( * args , * * kwargs ) ","if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :",if user_agent not in kwargs:,False,57.580900623127505,94.76134950808004
2728,"def execute ( self ) : <TAB>  if self . _dirty or not self . _qr : <TAB><TAB>  model_class = self . model_class <TAB><TAB>  query_meta = self . get_query_meta ( ) <TAB><TAB>  if self . _tuples : <TAB><TAB><TAB>  ResultWrapper = TuplesQueryResultWrapper <TAB><TAB>  elif self . _dicts : <TAB><TAB><TAB>  ResultWrapper = DictQueryResultWrapper <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ResultWrapper = NaiveQueryResultWrapper <TAB><TAB>  elif self . _aggregate_rows : <TAB><TAB><TAB>  ResultWrapper = AggregateQueryResultWrapper <TAB><TAB>  else : <TAB><TAB><TAB>  ResultWrapper = ModelQueryResultWrapper <TAB><TAB>  self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB><TAB>  self . _dirty = False <TAB><TAB>  return self . _qr <TAB>  else : <TAB><TAB>  return self . _qr ",elif self . _naive or not self . _joins or self . verify_naive ( ) :,if self._naive_rows:,False,22.560332715915898,92.87655521182243
2729,"def populate_data ( apps , schema_editor ) : <TAB>  Menu = apps . get_model ( "" menu "" , "" Menu "" ) <TAB>  for menu in Menu . objects . all ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  json_str = menu . json_content <TAB><TAB><TAB>  while isinstance ( json_str , str ) : <TAB><TAB><TAB><TAB>  json_str = json . loads ( json_str ) <TAB><TAB><TAB>  menu . json_content_new = json_str <TAB><TAB><TAB>  menu . save ( ) ","if isinstance ( menu . json_content , str ) :",if menu.is_active():,False,46.099436610173385,94.06146474456447
2730,"def virtualenv_exists ( self ) : <TAB>  if os . path . exists ( self . virtualenv_location ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  extra = [ "" Scripts "" , "" activate.bat "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  extra = [ "" bin "" , "" activate "" ] <TAB><TAB>  return os . path . isfile ( os . sep . join ( [ self . virtualenv_location ] + extra ) ) <TAB>  return False ","if os . name == ""nt"" :",if os.path.exists(self.virtualenv_location):,False,47.53790866225193,91.03739774968115
2731,"def get_minkowski_function ( name , variable ) : <TAB>  fn_name = name + get_postfix ( variable ) <TAB>  if hasattr ( MEB , fn_name ) : <TAB><TAB>  return getattr ( MEB , fn_name ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  f "" Function  { fn_name }  not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`. "" <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( f "" Function  { fn_name }  not available. "" ) ",if variable . is_cuda :,if not is_available(variable):,False,53.814849337887296,95.63407140663728
2732,"def build_temp_workspace ( files ) : <TAB>  tempdir = tempfile . mkdtemp ( prefix = "" yamllint-tests- "" ) <TAB>  for path , content in files . items ( ) : <TAB><TAB>  path = os . path . join ( tempdir , path ) . encode ( "" utf-8 "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( os . path . dirname ( path ) ) <TAB><TAB>  if type ( content ) is list : <TAB><TAB><TAB>  os . mkdir ( path ) <TAB><TAB>  else : <TAB><TAB><TAB>  mode = "" wb "" if isinstance ( content , bytes ) else "" w "" <TAB><TAB><TAB>  with open ( path , mode ) as f : <TAB><TAB><TAB><TAB>  f . write ( content ) <TAB>  return tempdir ",if not os . path . exists ( os . path . dirname ( path ) ) :,if not os.path.exists(os.path.dirname(path)):,False,50.74964038745009,100.00000000000004
2733,"def clean_form ( self , request , user , form , cleaned_data ) : <TAB>  for field in self . get_fields ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  cleaned_data [ field . fieldname ] = field . clean ( <TAB><TAB><TAB><TAB>  request , user , cleaned_data [ field . fieldname ] <TAB><TAB><TAB>  ) <TAB><TAB>  except ValidationError as e : <TAB><TAB><TAB>  form . add_error ( field . fieldname , e ) <TAB>  return cleaned_data ",if field . fieldname not in cleaned_data :,"if not hasattr(field, 'fieldname'):",False,28.741838118844086,94.34529788590837
2734,"def setUp ( self ) : <TAB>  self . realm = service . InMemoryWordsRealm ( "" realmname "" ) <TAB>  self . checker = checkers . InMemoryUsernamePasswordDatabaseDontUse ( ) <TAB>  self . portal = portal . Portal ( self . realm , [ self . checker ] ) <TAB>  self . factory = service . IRCFactory ( self . realm , self . portal ) <TAB>  c = [ ] <TAB>  for nick in self . STATIC_USERS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  nick = nick . decode ( "" utf-8 "" ) <TAB><TAB>  c . append ( self . realm . createUser ( nick ) ) <TAB><TAB>  self . checker . addUser ( nick , nick + "" _password "" ) <TAB>  return DeferredList ( c ) ","if isinstance ( nick , bytes ) :","if isinstance(nick, unicode):",False,50.92852920071832,98.53574149496123
2735,"def __call__ ( self , message ) : <TAB>  with self . _lock : <TAB><TAB>  self . _pending_ack + = 1 <TAB><TAB>  self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB><TAB>  self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB>  time . sleep ( self . _processing_time ) <TAB>  with self . _lock : <TAB><TAB>  self . _pending_ack - = 1 <TAB><TAB>  message . ack ( ) <TAB><TAB>  self . completed_calls + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not self . done_future . done ( ) : <TAB><TAB><TAB><TAB>  self . done_future . set_result ( None ) ",if self . completed_calls >= self . _resolve_at_msg_count :,if self.done_future:,False,20.143750203005922,92.78062550428373
2736,"def fill_in_standard_formats ( book ) : <TAB>  for x in std_format_code_types . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ty = std_format_code_types [ x ] <TAB><TAB><TAB>  # Note: many standard format codes (mostly CJK date formats) have <TAB><TAB><TAB>  # format strings that vary by locale; xlrd does not (yet) <TAB><TAB><TAB>  # handle those; the type (date or numeric) is recorded but the fmt_str will be None. <TAB><TAB><TAB>  fmt_str = std_format_strings . get ( x ) <TAB><TAB><TAB>  fmtobj = Format ( x , ty , fmt_str ) <TAB><TAB><TAB>  book . format_map [ x ] = fmtobj ",if x not in book . format_map :,if x in book.format_map:,False,71.96614895036691,98.78127806202085
2737,"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB>  result = [ ] <TAB>  for i in range ( 10 ) : <TAB><TAB>  # This line introduces a bug. <TAB><TAB>  if bigger_than_3_only and less_than_7_only and i == 4 : <TAB><TAB><TAB>  continue <TAB><TAB>  if bigger_than_3_only and i < = 3 : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if even_only and i % 2 != 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  result . append ( i ) <TAB>  return result ",if less_than_7_only and i >= 7 :,if less_than_7_only and i >= 3:,False,64.90971767453783,98.76076411553262
2738,"def next_instruction_is_function_or_class ( lines ) : <TAB>  """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB>  parser = StringParser ( "" python "" ) <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parser . read_line ( line ) <TAB><TAB><TAB>  continue <TAB><TAB>  parser . read_line ( line ) <TAB><TAB>  if not line . strip ( ) :<TAB># empty line <TAB><TAB><TAB>  if i > 0 and not lines [ i - 1 ] . strip ( ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  continue <TAB><TAB>  if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB><TAB><TAB>  return True <TAB><TAB>  if line . startswith ( ( "" # "" , "" @ "" , "" "" , "" ) "" ) ) : <TAB><TAB><TAB>  continue <TAB><TAB>  return False <TAB>  return False ",if parser . is_quoted ( ) :,if line.startswith('#') or line.startswith('function') or line.,False,34.492118903924215,92.4544651768375
2739,"def __getattr__ ( self , key ) : <TAB>  for tag in self . tag . children : <TAB><TAB>  if tag . name not in ( "" input "" , ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB><TAB><TAB>  return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB>  raise AttributeError ","if ""name"" in tag . attrs and tag . attrs [ ""name"" ] in ( key , ) :",if key == 'input':,False,47.28616043000384,81.66535694244517
2740,"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB>  if signature : <TAB><TAB>  # replace Mock function names <TAB><TAB>  signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB><TAB>  signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB><TAB>  # add scope name to layer signatures: <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if obj . use_scope : <TAB><TAB><TAB><TAB>  signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB><TAB><TAB>  elif obj . use_scope is None : <TAB><TAB><TAB><TAB>  signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB>  # signature: arg list <TAB>  return signature , return_annotation ","if hasattr ( obj , ""use_scope"" ) :",if signature:,False,54.38203586930934,95.381951744718
2741,"def countbox ( self ) : <TAB>  self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB>  for x , y in self . body : <TAB><TAB>  if x < self . box [ 0 ] : <TAB><TAB><TAB>  self . box [ 0 ] = x <TAB><TAB>  if x > self . box [ 2 ] : <TAB><TAB><TAB>  self . box [ 2 ] = x <TAB><TAB>  if y < self . box [ 1 ] : <TAB><TAB><TAB>  self . box [ 1 ] = y <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . box [ 3 ] = y ",if y > self . box [ 3 ] :,if y > self.box[3]:,False,51.12662654754896,96.23591478500437
2742,"def find_shell ( ) : <TAB>  global DEFAULT_SHELL <TAB>  if not DEFAULT_SHELL : <TAB><TAB>  for shell in propose_shell ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  DEFAULT_SHELL = shell <TAB><TAB><TAB><TAB>  break <TAB>  if not DEFAULT_SHELL : <TAB><TAB>  DEFAULT_SHELL = "" /bin/sh "" <TAB>  return DEFAULT_SHELL ","if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :",if shell.startswith('/bin/sh'):,False,39.830879074678236,83.82524351916271
2743,"def addAggregators ( sheet , cols , aggrnames ) : <TAB>  "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB>  for aggrname in aggrnames : <TAB><TAB>  aggrs = vd . aggregators . get ( aggrname ) <TAB><TAB>  aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB><TAB>  for aggr in aggrs : <TAB><TAB><TAB>  for c in cols : <TAB><TAB><TAB><TAB>  if not hasattr ( c , "" aggregators "" ) : <TAB><TAB><TAB><TAB><TAB>  c . aggregators = [ ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  c . aggregators + = [ aggr ] ",if aggr and aggr not in c . aggregators :,"if isinstance(aggr, list):",False,52.314843021034775,95.06114635222073
2744,"def run ( self , paths = [ ] ) : <TAB>  items = [ ] <TAB>  for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB><TAB>  items . append ( item . pathAbsoluteFromProjectEncoded ( ) ) <TAB>  if len ( items ) > 0 : <TAB><TAB>  sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sublime . status_message ( "" Items copied "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  sublime . status_message ( "" Item copied "" ) ",if len ( items ) > 1 :,if len(items) == 0:,False,51.094082844480205,96.85451587663262
2745,"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB>  provider = backend . name <TAB>  social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB>  if social : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg = "" This account is already in use. "" <TAB><TAB><TAB>  raise AuthAlreadyAssociated ( backend , msg ) <TAB><TAB>  elif not user : <TAB><TAB><TAB>  user = social . user <TAB>  return { <TAB><TAB>  "" social "" : social , <TAB><TAB>  "" user "" : user , <TAB><TAB>  "" is_new "" : user is None , <TAB><TAB>  "" new_association "" : social is None , <TAB>  } ",if user and social . user != user :,if social is not None:,False,48.73044219653858,95.30414015353252
2746,"def _text ( bitlist ) : <TAB>  out = "" "" <TAB>  for typ , text in bitlist : <TAB><TAB>  if not typ : <TAB><TAB><TAB>  out + = text <TAB><TAB>  elif typ == "" em "" : <TAB><TAB><TAB>  out + = "" \\ fI %s \\ fR "" % text <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out + = "" \\ fB %s \\ fR "" % text <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB>  out = out . strip ( ) <TAB>  out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB>  return out ","elif typ in [ ""strong"" , ""code"" ] :","if typ == ""f1':",False,21.79422260133526,93.67484359235458
2747,"def OnRadioSelect ( self , event ) : <TAB>  fitID = self . mainFrame . getActiveFit ( ) <TAB>  if fitID is not None : <TAB><TAB>  self . mainFrame . command . Submit ( <TAB><TAB><TAB>  cmd . GuiChangeImplantLocationCommand ( <TAB><TAB><TAB><TAB>  fitID = fitID , <TAB><TAB><TAB><TAB>  source = ImplantLocation . FIT <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  else ImplantLocation . CHARACTER , <TAB><TAB><TAB>  ) <TAB><TAB>  ) ",if self . rbFit . GetValue ( ),if source == ImplantLocation.TEXT:,False,27.98157224826938,94.15486818719496
2748,"def hexdump ( data ) : <TAB>  """"""yield lines with hexdump of data"""""" <TAB>  values = [ ] <TAB>  ascii = [ ] <TAB>  offset = 0 <TAB>  for h , a in sixteen ( data ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield ( offset , "" "" . join ( [ "" "" . join ( values ) , "" "" . join ( ascii ) ] ) ) <TAB><TAB><TAB>  del values [ : ] <TAB><TAB><TAB>  del ascii [ : ] <TAB><TAB><TAB>  offset + = 0x10 <TAB><TAB>  else : <TAB><TAB><TAB>  values . append ( h ) <TAB><TAB><TAB>  ascii . append ( a ) ",if h is None :,if h == ' ' and (not h == ' '):,False,25.320040512338593,92.38258537093661
2749,"def submit ( self ) : <TAB>  bot_token = self . config [ "" bot_token "" ] <TAB>  chat_ids = self . config [ "" chat_id "" ] <TAB>  chat_ids = [ chat_ids ] if isinstance ( chat_ids , str ) else chat_ids <TAB>  text = "" \n "" . join ( super ( ) . submit ( ) ) <TAB>  if not text : <TAB><TAB>  logger . debug ( "" Not calling telegram API (no changes) "" ) <TAB><TAB>  return <TAB>  result = None <TAB>  for chunk in chunkstring ( text , self . MAX_LENGTH , numbering = True ) : <TAB><TAB>  for chat_id in chat_ids : <TAB><TAB><TAB>  res = self . submitToTelegram ( bot_token , chat_id , chunk ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result = res <TAB>  return result ",if res . status_code != requests . codes . ok or res is None :,if res is not None:,False,29.060479553849643,93.44317575013984
2750,"def onMessage ( self , payload , isBinary ) : <TAB>  if not isBinary : <TAB><TAB>  self . result = "" Expected binary message with payload, but got binary. "" <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . result = ( <TAB><TAB><TAB><TAB>  "" Expected binary message with payload of length  %d , but got  %d . "" <TAB><TAB><TAB><TAB>  % ( self . DATALEN , len ( payload ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  ## FIXME : check actual content <TAB><TAB><TAB>  ## <TAB><TAB><TAB>  self . behavior = Case . OK <TAB><TAB><TAB>  self . result = "" Received binary message of length  %d . "" % len ( payload ) <TAB>  self . p . createWirelog = True <TAB>  self . p . sendClose ( self . p . CLOSE_STATUS_CODE_NORMAL ) ",if len ( payload ) != self . DATALEN :,if self.DATALEN != len(payload):,False,58.94828259763496,97.63536491807872
2751,"def verify_output ( actual , expected ) : <TAB>  actual = _read_file ( actual , "" Actual "" ) <TAB>  expected = _read_file ( join ( CURDIR , expected ) , "" Expected "" ) <TAB>  if len ( expected ) != len ( actual ) : <TAB><TAB>  raise AssertionError ( <TAB><TAB><TAB>  "" Lengths differ. Expected  %d  lines but got  %d "" <TAB><TAB><TAB>  % ( len ( expected ) , len ( actual ) ) <TAB><TAB>  ) <TAB>  for exp , act in zip ( expected , actual ) : <TAB><TAB>  tester = fnmatchcase if "" * "" in exp else eq <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AssertionError ( <TAB><TAB><TAB><TAB>  "" Lines differ. \n Expected:  %s \n Actual:<TAB>%s "" % ( exp , act ) <TAB><TAB><TAB>  ) ","if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :","if tester(actual, act):",False,51.08883739775351,91.24147881758736
2752,"def _in_out_vector_helper ( self , name1 , name2 , ceil ) : <TAB>  vector = [ ] <TAB>  stats = self . record <TAB>  if ceil is None : <TAB><TAB>  ceil = self . _get_max_rate ( name1 , name2 ) <TAB>  maxlen = self . config . get_stats_history_length ( ) <TAB>  for n in [ name1 , name2 ] : <TAB><TAB>  for i in range ( maxlen + 1 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  vector . append ( float ( stats [ i ] [ n ] ) / ceil ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  vector . append ( 0.0 ) <TAB>  return vector ",if i < len ( stats ) :,if stats[i][n] > ceil:,False,21.14251397105329,94.73962249581963
2753,"def _init_param ( param , mode ) : <TAB>  if isinstance ( param , str ) : <TAB><TAB>  param = _resolve ( param ) <TAB>  elif isinstance ( param , ( list , tuple ) ) : <TAB><TAB>  param = [ _init_param ( p , mode ) for p in param ] <TAB>  elif isinstance ( param , dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  param = from_params ( param , mode = mode ) <TAB><TAB>  else : <TAB><TAB><TAB>  param = { k : _init_param ( v , mode ) for k , v in param . items ( ) } <TAB>  return param ","if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :","if isinstance(param, (list, tuple)):",False,45.16980553364245,86.6694196816463
2754,"def link_pantsrefs ( soups , precomputed ) : <TAB>  """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB>  for ( page , soup ) in soups . items ( ) : <TAB><TAB>  for a in soup . find_all ( "" a "" ) : <TAB><TAB><TAB>  if not a . has_attr ( "" pantsref "" ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  pantsref = a [ "" pantsref "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise TaskError ( <TAB><TAB><TAB><TAB><TAB>  f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] ) ",if pantsref not in precomputed . pantsref :,if pantsref not in precomputed.pantsref:,False,38.188861302685915,96.71929870003974
2755,"def _gridconvvalue ( self , value ) : <TAB>  if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  svalue = str ( value ) <TAB><TAB><TAB>  if not svalue : <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return getdouble ( svalue ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return getint ( svalue ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  pass <TAB>  return value ","elif ""."" in svalue :","if isinstance(svalue, _tkinter.Tcl_Obj):",False,21.721971054317343,92.27028833359934
2756,"def default ( self , o ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return str ( o ) <TAB><TAB>  else : <TAB><TAB><TAB>  # remove unwanted attributes from the provider object during conversion to json <TAB><TAB><TAB>  if hasattr ( o , "" profile "" ) : <TAB><TAB><TAB><TAB>  del o . profile <TAB><TAB><TAB>  if hasattr ( o , "" credentials "" ) : <TAB><TAB><TAB><TAB>  del o . credentials <TAB><TAB><TAB>  if hasattr ( o , "" metadata_path "" ) : <TAB><TAB><TAB><TAB>  del o . metadata_path <TAB><TAB><TAB>  if hasattr ( o , "" services_config "" ) : <TAB><TAB><TAB><TAB>  del o . services_config <TAB><TAB><TAB>  return vars ( o ) <TAB>  except Exception as e : <TAB><TAB>  return str ( o ) ",if type ( o ) == datetime . datetime :,"if isinstance(o, Provider):",False,38.570290963250905,96.22926140860764
2757,"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB>  if len ( name ) == 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ "" - %s "" % name ] <TAB><TAB>  elif value not in ( False , None ) : <TAB><TAB><TAB>  if split_single_char_options : <TAB><TAB><TAB><TAB>  return [ "" - %s "" % name , "" %s "" % value ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return [ "" - %s %s "" % ( name , value ) ] <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ "" -- %s "" % dashify ( name ) ] <TAB><TAB>  elif value is not False and value is not None : <TAB><TAB><TAB>  return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB>  return [ ] ",if value is True :,if value is not None and value is not None:,False,28.671102760795897,95.23002708281857
2758,"def handle ( self , context , sign , * args ) : <TAB>  if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB><TAB>  return Infsign [ sign ] <TAB>  if sign == 0 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return Infsign [ sign ] <TAB><TAB>  return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB>  if sign == 1 : <TAB><TAB>  if context . rounding == ROUND_FLOOR : <TAB><TAB><TAB>  return Infsign [ sign ] <TAB><TAB>  return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) ",if context . rounding == ROUND_CEILING :,if context.rounding == ROUND_HALF_UP:,False,25.67884223444573,97.72805519473513
2759,"def OnLeftUp ( self , event ) : <TAB>  # Stop Drawing <TAB>  if self . Drawing : <TAB><TAB>  self . Drawing = False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  world_rect = ( <TAB><TAB><TAB><TAB>  self . Canvas . PixelToWorld ( self . RBRect [ 0 ] ) , <TAB><TAB><TAB><TAB>  self . Canvas . ScalePixelToWorld ( self . RBRect [ 1 ] ) , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  wx . CallAfter ( self . CallBack , world_rect ) <TAB>  self . RBRect = None ",if self . RBRect :,if self.RBRect:,False,26.254711631872084,100.00000000000004
2760,"def _map_answers ( answers ) : <TAB>  result = [ ] <TAB>  for a in answers . split ( "" | "" ) : <TAB><TAB>  user_answers = [ ] <TAB><TAB>  result . append ( dict ( sourcerAnswers = user_answers ) ) <TAB><TAB>  for r in a . split ( "" , "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  user_answers . append ( dict ( noAnswer = True ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  start_ , end_ = map ( int , r . split ( "" : "" ) ) <TAB><TAB><TAB><TAB>  user_answers . append ( dict ( s = start_ , e = end_ ) ) <TAB>  return result ","if r == ""None"" :",if r == '':,False,51.32535825072524,97.73059452202854
2761,"def parse_edges ( self , pcb ) : <TAB>  edges = [ ] <TAB>  drawings = list ( pcb . GetDrawings ( ) ) <TAB>  bbox = None <TAB>  for m in pcb . GetModules ( ) : <TAB><TAB>  for g in m . GraphicalItems ( ) : <TAB><TAB><TAB>  drawings . append ( g ) <TAB>  for d in drawings : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parsed_drawing = self . parse_drawing ( d ) <TAB><TAB><TAB>  if parsed_drawing : <TAB><TAB><TAB><TAB>  edges . append ( parsed_drawing ) <TAB><TAB><TAB><TAB>  if bbox is None : <TAB><TAB><TAB><TAB><TAB>  bbox = d . GetBoundingBox ( ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  bbox . Merge ( d . GetBoundingBox ( ) ) <TAB>  if bbox : <TAB><TAB>  bbox . Normalize ( ) <TAB>  return edges , bbox ",if d . GetLayer ( ) == pcbnew . Edge_Cuts :,if d.GetType() == 'drawing':,False,23.445942404735128,96.54786404538925
2762,"def get_size ( self ) : <TAB>  size = self . start_size <TAB>  for operation in self . ran_operations : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size = operation [ 1 ] [ 0 ] <TAB><TAB>  elif operation [ 0 ] == "" crop "" : <TAB><TAB><TAB>  crop = operation [ 1 ] [ 0 ] <TAB><TAB><TAB>  size = crop [ 2 ] - crop [ 0 ] , crop [ 3 ] - crop [ 1 ] <TAB>  return size ","if operation [ 0 ] == ""resize"" :","if operation[0] == ""size':",False,20.959814452466496,97.37280298194696
2763,"def migrate_account_metadata ( account_id ) : <TAB>  from inbox . models . session import session_scope <TAB>  from inbox . models import Account <TAB>  with session_scope ( versioned = False ) as db_session : <TAB><TAB>  account = db_session . query ( Account ) . get ( account_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB><TAB>  else : <TAB><TAB><TAB>  create_categories_for_folders ( account , db_session ) <TAB><TAB>  if account . discriminator == "" gmailaccount "" : <TAB><TAB><TAB>  set_labels_for_imapuids ( account , db_session ) <TAB><TAB>  db_session . commit ( ) ","if account . discriminator == ""easaccount"" :",if account is None:,False,44.76137990107712,95.61167714355113
2764,"def OnEndDrag ( self , event ) : <TAB>  self . StopDragging ( ) <TAB>  dropTarget = event . GetItem ( ) <TAB>  if not dropTarget : <TAB><TAB>  dropTarget = self . GetRootItem ( ) <TAB>  if self . IsValidDropTarget ( dropTarget ) : <TAB><TAB>  self . UnselectAll ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . SelectItem ( dropTarget ) <TAB><TAB>  self . OnDrop ( dropTarget , self . _dragItem ) ",if dropTarget != self . GetRootItem ( ) :,if self.IsSelected(dropTarget):,False,48.50828968515243,93.6228602839613
2765,"def validate ( self , frame , value ) : <TAB>  if self . sep and isinstance ( value , string_types ) : <TAB><TAB>  value = value . split ( self . sep ) <TAB>  if isinstance ( value , list ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ self . specs [ 0 ] . validate ( frame , v ) for v in value ] <TAB><TAB>  else : <TAB><TAB><TAB>  return [ <TAB><TAB><TAB><TAB>  [ s . validate ( frame , v ) for ( v , s ) in izip ( val , self . specs ) ] <TAB><TAB><TAB><TAB>  for val in value <TAB><TAB><TAB>  ] <TAB>  raise ValueError ( "" Invalid MultiSpec data:  %r "" % value ) ",if len ( self . specs ) == 1 :,if len(self.specs) == 1:,False,51.63157095425587,100.00000000000004
2766,"def __init__ ( self , action_space = None , network = None , network_kwargs = None , hparams = None ) : <TAB>  QNetBase . __init__ ( self , hparams = hparams ) <TAB>  with tf . variable_scope ( self . variable_scope ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  action_space = Space ( low = 0 , high = self . _hparams . action_space , dtype = np . int32 ) <TAB><TAB>  self . _action_space = action_space <TAB><TAB>  self . _append_output_layer ( ) ",if action_space is None :,if action_space is None:,False,51.025078778064284,100.00000000000004
2767,"def n_weights ( self ) : <TAB>  """"""Return the number of weights (parameters) in this network."""""" <TAB>  n_weights = 0 <TAB>  for i , w in enumerate ( self . all_weights ) : <TAB><TAB>  n = 1 <TAB><TAB>  # for s in p.eval().shape: <TAB><TAB>  for s in w . get_shape ( ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  s = int ( s ) <TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB>  s = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  n = n * s <TAB><TAB>  n_weights = n_weights + n <TAB>  # print(""num of weights (parameters) %d"" % n_weights) <TAB>  return n_weights ",if s :,if s > 0:,False,62.603444296892285,98.4441093662767
2768,"def _arg_desc ( name , ctx ) : <TAB>  for param in ctx . command . params : <TAB><TAB>  if param . name == name : <TAB><TAB><TAB>  desc = param . opts [ - 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  desc = param . human_readable_name <TAB><TAB><TAB>  return desc <TAB>  raise AssertionError ( name ) ","if desc [ 0 ] != ""-"" :",if desc is None:,False,32.99279570355555,89.46360138482423
2769,"def walk ( directory , path_so_far ) : <TAB>  for name in sorted ( os . listdir ( directory ) ) : <TAB><TAB>  if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB><TAB><TAB>  continue <TAB><TAB>  path = path_so_far + "" / "" + name if path_so_far else name <TAB><TAB>  if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB><TAB><TAB>  continue <TAB><TAB>  full_name = os . path . join ( directory , name ) <TAB><TAB>  if os . path . isdir ( full_name ) : <TAB><TAB><TAB>  for file_path in walk ( full_name , path ) : <TAB><TAB><TAB><TAB>  yield file_path <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield path ",elif os . path . isfile ( full_name ) :,if os.path.isdir(path):,False,57.01011058043688,96.10886718514239
2770,"def cache_dst ( self ) : <TAB>  final_dst = None <TAB>  final_linenb = None <TAB>  for linenb , assignblk in enumerate ( self ) : <TAB><TAB>  for dst , src in viewitems ( assignblk ) : <TAB><TAB><TAB>  if dst . is_id ( "" IRDst "" ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise ValueError ( "" Multiple destinations! "" ) <TAB><TAB><TAB><TAB>  final_dst = src <TAB><TAB><TAB><TAB>  final_linenb = linenb <TAB>  self . _dst = final_dst <TAB>  self . _dst_linenb = final_linenb <TAB>  return final_dst ",if final_dst is not None :,if dst.is_id('IRDst'):,False,47.226742523545866,95.21605516700038
2771,"def run ( self , args , * * kwargs ) : <TAB>  if args . resource_ref or args . policy_type : <TAB><TAB>  filters = { } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filters [ "" resource_ref "" ] = args . resource_ref <TAB><TAB>  if args . policy_type : <TAB><TAB><TAB>  filters [ "" policy_type "" ] = args . policy_type <TAB><TAB>  filters . update ( * * kwargs ) <TAB><TAB>  return self . manager . query ( * * filters ) <TAB>  else : <TAB><TAB>  return self . manager . get_all ( * * kwargs ) ",if args . resource_ref :,if args.resource_ref:,False,42.353444916434455,100.00000000000004
2772,"def __init__ ( self , folders ) : <TAB>  self . folders = folders <TAB>  self . duplicates = { } <TAB>  for folder , path in folders . items ( ) : <TAB><TAB>  duplicates = [ ] <TAB><TAB>  for other_folder , other_path in folders . items ( ) : <TAB><TAB><TAB>  if other_folder == folder : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if other_path == path : <TAB><TAB><TAB><TAB>  duplicates . append ( other_folder ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . duplicates [ folder ] = duplicates ",if len ( duplicates ) :,if duplicates:,False,31.288215920024932,96.87440407629386
2773,"def limit_clause ( self , select , * * kw ) : <TAB>  text = "" "" <TAB>  if select . _limit_clause is not None : <TAB><TAB>  text + = "" \n  LIMIT  "" + self . process ( select . _limit_clause , * * kw ) <TAB>  if select . _offset_clause is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text + = "" \n  LIMIT  "" + self . process ( sql . literal ( - 1 ) ) <TAB><TAB>  text + = ""  OFFSET  "" + self . process ( select . _offset_clause , * * kw ) <TAB>  else : <TAB><TAB>  text + = ""  OFFSET  "" + self . process ( sql . literal ( 0 ) , * * kw ) <TAB>  return text ",if select . _limit_clause is None :,if select._offset_clause is not None:,False,20.61206242876561,95.51085020607134
2774,"def _get_activation ( self , act ) : <TAB>  """"""Get activation block based on the name."""""" <TAB>  if isinstance ( act , str ) : <TAB><TAB>  if act . lower ( ) == "" gelu "" : <TAB><TAB><TAB>  return GELU ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return GELU ( approximate = True ) <TAB><TAB>  else : <TAB><TAB><TAB>  return gluon . nn . Activation ( act ) <TAB>  assert isinstance ( act , gluon . Block ) <TAB>  return act ","elif act . lower ( ) == ""approx_gelu"" :","if act.lower() == ""gelu':",False,27.74383314516039,94.55182346864191
2775,"def __eq__ ( self , other ) : <TAB>  try : <TAB><TAB>  if self . type != other . type : <TAB><TAB><TAB>  return False <TAB><TAB>  if self . type == "" ASK "" : <TAB><TAB><TAB>  return self . askAnswer == other . askAnswer <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . vars == other . vars and self . bindings == other . bindings <TAB><TAB>  else : <TAB><TAB><TAB>  return self . graph == other . graph <TAB>  except : <TAB><TAB>  return False ","elif self . type == ""SELECT"" :","if isinstance(other, (dict, tuple)):",False,24.3638201579047,92.20354921490296
2776,"def _get_text_nodes ( nodes , html_body ) : <TAB>  text = [ ] <TAB>  open_tags = 0 <TAB>  for node in nodes : <TAB><TAB>  if isinstance ( node , HtmlTag ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  open_tags + = 1 <TAB><TAB><TAB>  elif node . tag_type == CLOSE_TAG : <TAB><TAB><TAB><TAB>  open_tags - = 1 <TAB><TAB>  elif ( <TAB><TAB><TAB>  isinstance ( node , HtmlDataFragment ) <TAB><TAB><TAB>  and node . is_text_content <TAB><TAB><TAB>  and open_tags == 0 <TAB><TAB>  ) : <TAB><TAB><TAB>  text . append ( html_body [ node . start : node . end ] ) <TAB>  return text ",if node . tag_type == OPEN_TAG :,if node.tag_type == OPEN_TAG:,False,47.336121111351794,100.00000000000004
2777,"def test_do_change ( self ) : <TAB>  """"""Test if VTK object changes when trait is changed."""""" <TAB>  p = Prop ( ) <TAB>  p . edge_visibility = not p . edge_visibility <TAB>  p . representation = "" p "" <TAB>  p . opacity = 0.5 <TAB>  p . color = ( 0 , 1 , 0 ) <TAB>  p . diffuse_color = ( 1 , 1 , 1 ) <TAB>  p . specular_color = ( 1 , 1 , 0 ) <TAB>  for t , g in p . _updateable_traits_ : <TAB><TAB>  val = getattr ( p . _vtk_obj , g ) ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( val , getattr ( p , t + "" _ "" ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( val , getattr ( p , t ) ) ","if t == ""representation"" :",if t == t + '_':,False,26.695541418826487,97.08778236544588
2778,"def update_item ( source_doc , target_doc , source_parent ) : <TAB>  target_doc . t_warehouse = "" "" <TAB>  if source_doc . material_request_item and source_doc . material_request : <TAB><TAB>  add_to_transit = frappe . db . get_value ( <TAB><TAB><TAB>  "" Stock Entry "" , source_name , "" add_to_transit "" <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warehouse = frappe . get_value ( <TAB><TAB><TAB><TAB>  "" Material Request Item "" , source_doc . material_request_item , "" warehouse "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  target_doc . t_warehouse = warehouse <TAB>  target_doc . s_warehouse = source_doc . t_warehouse <TAB>  target_doc . qty = source_doc . qty - source_doc . transferred_qty ",if add_to_transit :,if source_doc.material_request_item and source_doc.material_request_,False,31.51637439896603,92.22209719079872
2779,"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB>  for drive in self . drives : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  config_root_path = drive . get ( "" root_path "" ) <TAB><TAB><TAB>  if config_root_path and root_path == config_root_path : <TAB><TAB><TAB><TAB>  return drive <TAB><TAB>  elif volume_guid_path : <TAB><TAB><TAB>  config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB><TAB><TAB>  if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB><TAB><TAB><TAB>  return drive ",if root_path :,if root_path:,False,57.825370317853256,100.00000000000004
2780,"def f_freeze ( _ ) : <TAB>  repos = utils . get_repos ( ) <TAB>  for name , path in repos . items ( ) : <TAB><TAB>  url = "" "" <TAB><TAB>  cp = subprocess . run ( [ "" git "" , "" remote "" , "" -v "" ] , cwd = path , capture_output = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  url = cp . stdout . decode ( "" utf-8 "" ) . split ( "" \n "" ) [ 0 ] . split ( ) [ 1 ] <TAB><TAB>  print ( f "" { url } , { name } , { path } "" ) ",if cp . returncode == 0 :,if cp.returncode:,False,26.65949458323724,97.07929437055112
2781,"def conj ( self ) : <TAB>  dtype = self . dtype <TAB>  if issubclass ( self . dtype . type , np . complexfloating ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB><TAB><TAB>  ) <TAB><TAB>  if self . flags . f_contiguous : <TAB><TAB><TAB>  order = "" F "" <TAB><TAB>  else : <TAB><TAB><TAB>  order = "" C "" <TAB><TAB>  result = self . _new_like_me ( order = order ) <TAB><TAB>  func = elementwise . get_conj_kernel ( dtype ) <TAB><TAB>  func . prepared_async_call ( <TAB><TAB><TAB>  self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB><TAB>  ) <TAB><TAB>  return result <TAB>  else : <TAB><TAB>  return self ",if not self . flags . forc :,if self.flags.contiguous:,False,28.36601205412082,98.05957151982918
2782,"def detect_reentrancy ( self , contract ) : <TAB>  for function in contract . functions_and_modifiers_declared : <TAB><TAB>  if function . is_implemented : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  self . _explore ( function . entry_point , [ ] ) <TAB><TAB><TAB>  function . context [ self . KEY ] = True ",if self . KEY in function . context :,if function.is_function_called:,False,38.937345323976515,92.95085205872499
2783,"def test_default_configuration_no_encoding ( self ) : <TAB>  transformations = [ ] <TAB>  for i in range ( 2 ) : <TAB><TAB>  transformation , original = _test_preprocessing ( NoEncoding ) <TAB><TAB>  self . assertEqual ( transformation . shape , original . shape ) <TAB><TAB>  self . assertTrue ( ( transformation == original ) . all ( ) ) <TAB><TAB>  transformations . append ( transformation ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertTrue ( ( transformations [ - 1 ] == transformations [ - 2 ] ) . all ( ) ) ",if len ( transformations ) > 1 :,if i == 2:,False,22.700983223892383,91.3440033611981
2784,"def main ( ) : <TAB>  """"""main function"""""" <TAB>  # todo: lookuo real description <TAB>  parser = argparse . ArgumentParser ( description = "" Let a cow speak for you "" ) <TAB>  parser . add_argument ( "" text "" , nargs = "" * "" , default = None , help = "" text to say "" ) <TAB>  ns = parser . parse_args ( ) <TAB>  if ( ns . text is None ) or ( len ( ns . text ) == 0 ) : <TAB><TAB>  text = "" "" <TAB><TAB>  while True : <TAB><TAB><TAB>  inp = sys . stdin . read ( 4096 ) <TAB><TAB><TAB>  if inp . endswith ( "" \n "" ) : <TAB><TAB><TAB><TAB>  inp = inp [ : - 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  text + = inp <TAB>  else : <TAB><TAB>  text = "" "" . join ( ns . text ) <TAB>  cow = get_cow ( text ) <TAB>  print ( cow ) ",if not inp :,if not inp:,False,53.403400855644314,98.68891056239045
2785,"def prehook ( self , emu , op , eip ) : <TAB>  if op in self . badops : <TAB><TAB>  emu . stopEmu ( ) <TAB><TAB>  raise v_exc . BadOpBytes ( op . va ) <TAB>  if op . mnem in STOS : <TAB><TAB>  if self . arch == "" i386 "" : <TAB><TAB><TAB>  reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB><TAB>  elif self . arch == "" amd64 "" : <TAB><TAB><TAB>  reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . vw . makePointer ( reg , follow = True ) ",if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,if reg is not None:,False,22.09520893960931,89.65782141760933
2786,"def get_boarding_status ( project ) : <TAB>  status = "" Pending "" <TAB>  if project : <TAB><TAB>  doc = frappe . get_doc ( "" Project "" , project ) <TAB><TAB>  if flt ( doc . percent_complete ) > 0.0 and flt ( doc . percent_complete ) < 100.0 : <TAB><TAB><TAB>  status = "" In Process "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  status = "" Completed "" <TAB><TAB>  return status ",elif flt ( doc . percent_complete ) == 100.0 :,if not doc.is_running:,False,29.39494035331392,90.13226620547711
2787,"def set_weights ( self , new_weights ) : <TAB>  weights = self . get_weights ( ) <TAB>  if len ( weights ) != len ( new_weights ) : <TAB><TAB>  raise ValueError ( "" len of lists mismatch "" ) <TAB>  tuples = [ ] <TAB>  for w , new_w in zip ( weights , new_weights ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_w = new_w . reshape ( w . shape ) <TAB><TAB>  tuples . append ( ( w , new_w ) ) <TAB>  nn . batch_set_value ( tuples ) ",if len ( w . shape ) != new_w . shape :,if w.shape == new_w.shape:,False,47.805897069049365,95.5056989656159
2788,"def reload_json_api_settings ( * args , * * kwargs ) : <TAB>  django_setting = kwargs [ "" setting "" ] <TAB>  setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB>  value = kwargs [ "" value "" ] <TAB>  if setting in DEFAULTS . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( json_api_settings , setting , value ) <TAB><TAB>  elif hasattr ( json_api_settings , setting ) : <TAB><TAB><TAB>  delattr ( json_api_settings , setting ) ",if value is not None :,if value is not None:,False,50.120341501550115,100.00000000000004
2789,"def knamn ( self , sup , cdict ) : <TAB>  cname = cdict [ sup ] . class_name <TAB>  if not cname : <TAB><TAB>  ( namesp , tag ) = cdict [ sup ] . name . split ( "" . "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ctag = self . root . modul [ namesp ] . factory ( tag ) . __class__ . __name__ <TAB><TAB><TAB>  cname = "" %s . %s "" % ( namesp , ctag ) <TAB><TAB>  else : <TAB><TAB><TAB>  cname = tag + "" _ "" <TAB>  return cname ",if namesp :,if namesp in self.root.mod:,False,25.34850175641828,95.22991129841635
2790,"def setdefault ( self , key , default = None ) : <TAB>  try : <TAB><TAB>  o = self . data [ key ] ( ) <TAB>  except KeyError : <TAB><TAB>  o = None <TAB>  if o is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _commit_removals ( ) <TAB><TAB>  self . data [ key ] = KeyedRef ( default , self . _remove , key ) <TAB><TAB>  return default <TAB>  else : <TAB><TAB>  return o ",if self . _pending_removals :,if self._pending_removals:,False,50.98857258970906,100.00000000000004
2791,"def __on_item_activated ( self , event ) : <TAB>  if self . __module_view : <TAB><TAB>  module = self . get_event_module ( event ) <TAB><TAB>  self . __module_view . set_selection ( module . module_num ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . input_list_ctrl . deactivate_active_item ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . list_ctrl . deactivate_active_item ( ) <TAB><TAB><TAB>  for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB><TAB><TAB><TAB>  if self . list_ctrl . IsSelected ( index ) : <TAB><TAB><TAB><TAB><TAB>  self . list_ctrl . Select ( index , False ) <TAB>  self . __controller . enable_module_controls_panel_buttons ( ) ",if event . EventObject is self . list_ctrl :,if self.__input_list_ctrl:,False,23.655661054517754,97.10165802506097
2792,"def _create_valid_graph ( graph ) : <TAB>  nodes = graph . nodes ( ) <TAB>  for i in range ( len ( nodes ) ) : <TAB><TAB>  for j in range ( len ( nodes ) ) : <TAB><TAB><TAB>  if i == j : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  edge = ( nodes [ i ] , nodes [ j ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  graph . del_edge ( edge ) <TAB><TAB><TAB>  graph . add_edge ( edge , 1 ) ",if graph . has_edge ( edge ) :,if edge not in graph.edges():,False,36.771804098788174,95.39887412505622
2793,"def _parse_param_value ( name , datatype , default ) : <TAB>  if datatype == "" bool "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  elif default . lower ( ) == "" false "" : <TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB><TAB><TAB>  raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB>  elif datatype == "" int "" : <TAB><TAB>  if type ( default ) == int : <TAB><TAB><TAB>  return default <TAB><TAB>  else : <TAB><TAB><TAB>  return int ( default , 0 ) <TAB>  elif datatype == "" real "" : <TAB><TAB>  if type ( default ) == float : <TAB><TAB><TAB>  return default <TAB><TAB>  else : <TAB><TAB><TAB>  return float ( default ) <TAB>  else : <TAB><TAB>  return str ( default ) ","if default . lower ( ) == ""true"" :","if default.lower() == ""true':",False,13.326065787976857,98.75549710657853
2794,"def get_size ( self , shape_info ) : <TAB>  # The size is the data, that have constant size. <TAB>  state = np . random . RandomState ( ) . get_state ( ) <TAB>  size = 0 <TAB>  for elem in state : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size + = len ( elem ) <TAB><TAB>  elif isinstance ( elem , np . ndarray ) : <TAB><TAB><TAB>  size + = elem . size * elem . itemsize <TAB><TAB>  elif isinstance ( elem , int ) : <TAB><TAB><TAB>  size + = np . dtype ( "" int "" ) . itemsize <TAB><TAB>  elif isinstance ( elem , float ) : <TAB><TAB><TAB>  size + = np . dtype ( "" float "" ) . itemsize <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError ( ) <TAB>  return size ","if isinstance ( elem , str ) :","if isinstance(elem, np.float32):",False,32.13232862086674,97.973610575106
2795,"def _merge_substs ( self , subst , new_substs ) : <TAB>  subst = subst . copy ( ) <TAB>  for new_subst in new_substs : <TAB><TAB>  for name , var in new_subst . items ( ) : <TAB><TAB><TAB>  if name not in subst : <TAB><TAB><TAB><TAB>  subst [ name ] = var <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  subst [ name ] . PasteVariable ( var ) <TAB>  return subst ",elif subst [ name ] is not var :,"if isinstance(subst[name], ast.Variable):",False,37.09498933474804,91.85168814553671
2796,"def _load_weights_if_possible ( self , model , init_weight_path = None ) : <TAB>  """"""Loads model weights when it is provided."""""" <TAB>  if init_weight_path : <TAB><TAB>  logging . info ( "" Load weights:  {} "" . format ( init_weight_path ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  checkpoint = tf . train . Checkpoint ( <TAB><TAB><TAB><TAB>  model = model , optimizer = self . _create_optimizer ( ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  checkpoint . restore ( init_weight_path ) <TAB><TAB>  else : <TAB><TAB><TAB>  model . load_weights ( init_weight_path ) <TAB>  else : <TAB><TAB>  logging . info ( "" Weights not loaded from path: {} "" . format ( init_weight_path ) ) ",if self . use_tpu :,if init_weight_path is not None:,False,52.833132674844954,95.92850236997708
2797,"def _cleanup_inactive_receivexlogs ( self , site ) : <TAB>  if site in self . receivexlogs : <TAB><TAB>  if not self . receivexlogs [ site ] . running : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . receivexlogs [ site ] . join ( ) <TAB><TAB><TAB>  del self . receivexlogs [ site ] ",if self . receivexlogs [ site ] . is_alive ( ) :,if self.receivexlogs[site].running:,False,24.33239637212525,93.42749368978119
2798,"def get_asset ( self , path ) : <TAB>  """"""Loads an asset by path."""""" <TAB>  clean_path = cleanup_path ( path ) . strip ( "" / "" ) <TAB>  nodes = [ self . asset_root ] + self . theme_asset_roots <TAB>  for node in nodes : <TAB><TAB>  for piece in clean_path . split ( "" / "" ) : <TAB><TAB><TAB>  node = node . get_child ( piece ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if node is not None : <TAB><TAB><TAB>  return node <TAB>  return None ",if node is None :,if node is not None:,False,52.749192809186106,98.49156258720447
2799,"def palindromic_substrings ( s ) : <TAB>  if not s : <TAB><TAB>  return [ [ ] ] <TAB>  results = [ ] <TAB>  for i in range ( len ( s ) , 0 , - 1 ) : <TAB><TAB>  sub = s [ : i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for rest in palindromic_substrings ( s [ i : ] ) : <TAB><TAB><TAB><TAB>  results . append ( [ sub ] + rest ) <TAB>  return results ",if sub == sub [ : : - 1 ] :,"if sub in ('', '', '', '', '', '', '', '',",False,18.577331133332617,83.48059800197545
2800,"def debug_tree ( tree ) : <TAB>  l = [ ] <TAB>  for elt in tree : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  l . append ( _names . get ( elt , elt ) ) <TAB><TAB>  elif isinstance ( elt , str ) : <TAB><TAB><TAB>  l . append ( elt ) <TAB><TAB>  else : <TAB><TAB><TAB>  l . append ( debug_tree ( elt ) ) <TAB>  return l ","if isinstance ( elt , ( int , long ) ) :","if isinstance(elt, (int, float)):",False,51.5573411138087,97.97945634141097
2801,"def shared_username ( account ) : <TAB>  username = os . environ . get ( "" SHARED_USERNAME "" , "" PKKid "" ) <TAB>  for user in account . users ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return username <TAB><TAB>  elif ( <TAB><TAB><TAB>  user . username <TAB><TAB><TAB>  and user . email <TAB><TAB><TAB>  and user . id <TAB><TAB><TAB>  and username . lower ( ) <TAB><TAB><TAB>  in ( user . username . lower ( ) , user . email . lower ( ) , str ( user . id ) ) <TAB><TAB>  ) : <TAB><TAB><TAB>  return username <TAB>  pytest . skip ( "" Shared user  %s  wasn`t found in your MyPlex account "" % username ) ",if user . title . lower ( ) == username . lower ( ) :,if user.username == username:,False,56.18015917400583,94.24296328876794
2802,"def process_schema_element ( self , e ) : <TAB>  if e . name is None : <TAB><TAB>  return <TAB>  self . debug1 ( "" adding element:  %s "" , e . name ) <TAB>  t = self . get_type ( e . type ) <TAB>  if t : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . pending_elements [ e . name ] <TAB><TAB>  self . retval [ self . tns ] . elements [ e . name ] = e <TAB>  else : <TAB><TAB>  self . pending_elements [ e . name ] = e ",if e . name in self . pending_elements :,if t.type == 'element':,False,41.241237807245675,93.17631169091109
2803,"def __setitem__ ( self , key , value ) : <TAB>  with self . _lock : <TAB><TAB>  try : <TAB><TAB><TAB>  link = self . _get_link_and_move_to_front_of_ll ( key ) <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _set_key_and_add_to_front_of_ll ( key , value ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  evicted = self . _set_key_and_evict_last_in_ll ( key , value ) <TAB><TAB><TAB><TAB>  super ( LRI , self ) . __delitem__ ( evicted ) <TAB><TAB><TAB>  super ( LRI , self ) . __setitem__ ( key , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  link [ VALUE ] = value ",if len ( self ) < self . max_size :,if link is None:,False,46.690732114505465,95.34677172736585
2804,"def __delattr__ ( self , name ) : <TAB>  if name == "" __dict__ "" : <TAB><TAB>  raise AttributeError ( <TAB><TAB><TAB>  "" %r  object attribute  ' __dict__ '  is read-only "" % self . __class__ . __name__ <TAB><TAB>  ) <TAB>  if name in self . _local_type_vars : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # A data descriptor, like a property or a slot. <TAB><TAB><TAB>  type_attr = getattr ( self . _local_type , name , _marker ) <TAB><TAB><TAB>  type ( type_attr ) . __delete__ ( type_attr , self ) <TAB><TAB><TAB>  return <TAB>  # Otherwise it goes directly in the dict <TAB>  # Begin inlined function _get_dict() <TAB>  dct = _local_get_dict ( self ) <TAB>  try : <TAB><TAB>  del dct [ name ] <TAB>  except KeyError : <TAB><TAB>  raise AttributeError ( name ) ",if name in self . _local_type_del_descriptors :,if name == '_local_type':,False,48.51379554000776,95.93869796836246
2805,"def update_participants ( self , refresh = True ) : <TAB>  for participant in list ( self . participants_dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  self . removeItem ( self . participants_dict [ participant ] ) <TAB><TAB>  self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB><TAB>  del self . participants_dict [ participant ] <TAB>  for participant in self . simulator_config . participants : <TAB><TAB>  if participant in self . participants_dict : <TAB><TAB><TAB>  self . participants_dict [ participant ] . refresh ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . insert_participant ( participant ) <TAB>  if refresh : <TAB><TAB>  self . update_view ( ) ",if participant is None or participant == self . simulator_config . broadcast_part :,if not participant in self.participants_dict:,False,48.25645574234706,92.22109933105916
2806,"def insert_bigger_b_add ( node ) : <TAB>  if node . op == theano . tensor . add : <TAB><TAB>  inputs = list ( node . inputs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  inputs [ - 1 ] = theano . tensor . concatenate ( ( inputs [ - 1 ] , inputs [ - 1 ] ) ) <TAB><TAB><TAB>  return [ node . op ( * inputs ) ] <TAB>  return False ",if inputs [ - 1 ] . owner is None :,if inputs:,False,32.10638398456924,85.49384392153051
2807,"def _activate_cancel_status ( self , cancel_status ) : <TAB>  if self . _cancel_status is not None : <TAB><TAB>  self . _cancel_status . _tasks . remove ( self ) <TAB>  self . _cancel_status = cancel_status <TAB>  if self . _cancel_status is not None : <TAB><TAB>  self . _cancel_status . _tasks . add ( self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _attempt_delivery_of_any_pending_cancel ( ) ",if self . _cancel_status . effectively_cancelled :,if self._cancel_status is not None:,False,51.09702881935823,95.99452407372996
2808,"def writeLibraryGeometry ( fp , meshes , config , shapes = None ) : <TAB>  progress = Progress ( len ( meshes ) , None ) <TAB>  fp . write ( "" \n   <library_geometries> \n "" ) <TAB>  for mIdx , mesh in enumerate ( meshes ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shape = None <TAB><TAB>  else : <TAB><TAB><TAB>  shape = shapes [ mIdx ] <TAB><TAB>  writeGeometry ( fp , mesh , config , shape ) <TAB><TAB>  progress . step ( ) <TAB>  fp . write ( ""   </library_geometries> \n "" ) ",if shapes is None :,if shapes is None:,False,50.97038835578424,100.00000000000004
2809,"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB>  if "" config "" in module_json [ "" meta "" ] : <TAB><TAB>  if module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB>  if module_json [ "" name "" ] not in config : <TAB><TAB><TAB><TAB>  config . add_section ( module_json [ "" name "" ] ) <TAB><TAB><TAB>  for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB>  return config ","if config_var not in config [ module_json [ ""name"" ] ] :",if config_var.startswith('config'):,False,49.04413873861231,92.96227113104936
2810,"def get_const_defines ( flags , prefix = "" "" ) : <TAB>  defs = [ ] <TAB>  for k , v in globals ( ) . items ( ) : <TAB><TAB>  if isinstance ( v , int ) : <TAB><TAB><TAB>  if v & flags : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if k . startswith ( prefix ) : <TAB><TAB><TAB><TAB><TAB><TAB>  defs . append ( k ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  defs . append ( k ) <TAB>  return defs ",if prefix :,if k.startswith(prefix):,False,49.90048215490573,95.76278792981739
2811,"def __init__ ( self , source , encoding = DEFAULT_ENCODING ) : <TAB>  self . data = { } <TAB>  with open ( source , encoding = encoding ) as file_ : <TAB><TAB>  for line in file_ : <TAB><TAB><TAB>  line = line . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  k , v = line . split ( "" = "" , 1 ) <TAB><TAB><TAB>  k = k . strip ( ) <TAB><TAB><TAB>  v = v . strip ( ) <TAB><TAB><TAB>  if len ( v ) > = 2 and ( <TAB><TAB><TAB><TAB>  ( v [ 0 ] == "" ' "" and v [ - 1 ] == "" ' "" ) or ( v [ 0 ] == ' "" ' and v [ - 1 ] == ' "" ' ) <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  v = v . strip ( "" ' \"" "" ) <TAB><TAB><TAB>  self . data [ k ] = v ","if not line or line . startswith ( ""#"" ) or ""="" not in line :",if line.startswith('#') or line == '':,False,27.793822777518578,93.0421689576351
2812,"def __detect_console_logger ( self ) : <TAB>  logger = self . log <TAB>  while logger : <TAB><TAB>  for handler in logger . handlers [ : ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if handler . stream in ( sys . stdout , sys . stderr ) : <TAB><TAB><TAB><TAB><TAB>  self . logger_handlers . append ( handler ) <TAB><TAB>  if logger . root == logger : <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  logger = logger . root ","if isinstance ( handler , StreamHandler ) :",if handler.handler_type == 'console':,False,48.83494697278572,94.11507286842121
2813,"def check_heuristic_in_sql ( ) : <TAB>  heurs = set ( ) <TAB>  excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB>  for heur in HEURISTICS : <TAB><TAB>  name = heur [ "" name "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  sql = heur [ "" sql "" ] <TAB><TAB>  if sql . lower ( ) . find ( name . lower ( ) ) == - 1 : <TAB><TAB><TAB>  print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB><TAB><TAB>  print ( sql ) <TAB><TAB><TAB>  assert sql . find ( name ) != - 1 <TAB><TAB>  heurs . add ( name ) <TAB>  print ( "" Heuristics: "" ) <TAB>  import pprint <TAB>  pprint . pprint ( heurs ) ",if name in excluded :,if name in excluded:,False,55.15056152960592,96.78543201146636
2814,"def read ( self , size = - 1 ) : <TAB>  buf = bytearray ( ) <TAB>  while size != 0 and self . cursor < self . maxpos : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . seek_to_block ( self . cursor ) <TAB><TAB>  part = self . current_stream . read ( size ) <TAB><TAB>  if size > 0 : <TAB><TAB><TAB>  if len ( part ) == 0 : <TAB><TAB><TAB><TAB>  raise EOFError ( ) <TAB><TAB><TAB>  size - = len ( part ) <TAB><TAB>  self . cursor + = len ( part ) <TAB><TAB>  buf + = part <TAB>  return bytes ( buf ) ",if not self . in_current_block ( self . cursor ) :,if size == -1:,False,26.498685692418654,91.12489194980839
2815,"def get_project_dir ( env ) : <TAB>  project_file = workon_home / env / "" .project "" <TAB>  if project_file . exists ( ) : <TAB><TAB>  with project_file . open ( ) as f : <TAB><TAB><TAB>  project_dir = f . readline ( ) . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return project_dir <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  err ( <TAB><TAB><TAB><TAB><TAB>  "" Corrupted or outdated: "" , <TAB><TAB><TAB><TAB><TAB>  project_file , <TAB><TAB><TAB><TAB><TAB>  "" \n Directory "" , <TAB><TAB><TAB><TAB><TAB>  project_dir , <TAB><TAB><TAB><TAB><TAB>  "" doesn ' t exist. "" , <TAB><TAB><TAB><TAB>  ) ",if os . path . exists ( project_dir ) :,if project_dir:,False,52.91491060032902,94.03132307324661
2816,"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB>  """"""cache hidden states into memory."""""" <TAB>  if mem_len is None or mem_len == 0 : <TAB><TAB>  return None <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  curr_out = curr_out [ : reuse_len ] <TAB><TAB>  if prev_mem is None : <TAB><TAB><TAB>  new_mem = curr_out [ - mem_len : ] <TAB><TAB>  else : <TAB><TAB><TAB>  new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB>  return tf . keras . backend . stop_gradient ( new_mem ) ",if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None:,False,54.63063261606129,93.91874921403506
2817,"def cleanup_channel ( self , to_cleanup ) : <TAB>  public_key , id_ = to_cleanup <TAB>  # TODO: Maybe run it threaded? <TAB>  try : <TAB><TAB>  with db_session : <TAB><TAB><TAB>  channel = self . session . mds . ChannelMetadata . get_for_update ( <TAB><TAB><TAB><TAB>  public_key = public_key , id_ = id_ <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  channel . local_version = 0 <TAB><TAB><TAB>  channel . contents . delete ( bulk = True ) <TAB>  except Exception as e : <TAB><TAB>  self . _logger . warning ( "" Exception while cleaning unsubscribed channel:  % "" , str ( e ) ) ",if not channel :,if channel is None:,False,56.8221689396229,97.9552026711619
2818,"def best_image ( width , height ) : <TAB>  # A heuristic for finding closest sized image to required size. <TAB>  image = images [ 0 ] <TAB>  for img in images : <TAB><TAB>  if img . width == width and img . height == height : <TAB><TAB><TAB>  # Exact match always used <TAB><TAB><TAB>  return img <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # At least wide enough, and largest area <TAB><TAB><TAB>  image = img <TAB>  return image ",elif img . width >= width and img . width * img . height > image . width * image . height :,if image.width < width and image.height < height:,False,38.67379475385932,86.71609788906197
2819,"def add_peer_to_blob ( self , contact : "" KademliaPeer "" , key : bytes ) - > None : <TAB>  now = self . loop . time ( ) <TAB>  if key in self . _data_store : <TAB><TAB>  current = list ( filter ( lambda x : x [ 0 ] == contact , self . _data_store [ key ] ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _data_store [ key ] [ self . _data_store [ key ] . index ( current [ 0 ] ) ] = ( <TAB><TAB><TAB><TAB>  contact , <TAB><TAB><TAB><TAB>  now , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _data_store [ key ] . append ( ( contact , now ) ) <TAB>  else : <TAB><TAB>  self . _data_store [ key ] = [ ( contact , now ) ] ",if len ( current ) > 0 :,if current:,False,23.455306560006935,96.92062504700522
2820,"def dump ( self ) : <TAB>  self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB>  for field in self . _fields_ : <TAB><TAB>  if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) : <TAB><TAB><TAB>  self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB><TAB>  elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB><TAB><TAB>  self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) ) ","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :","if isinstance(self, (int, long)):",False,24.91446277385159,94.78373903029878
2821,"def GeneratePageMetatadata ( self , task ) : <TAB>  address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB>  for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB><TAB>  start = vma . vm_start <TAB><TAB>  end = vma . vm_end <TAB><TAB>  # Skip the entire region. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # Done. <TAB><TAB>  if start > self . plugin_args . end : <TAB><TAB><TAB>  break <TAB><TAB>  for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB><TAB><TAB>  if self . plugin_args . start < = vaddr < = self . plugin_args . end : <TAB><TAB><TAB><TAB>  yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) ) ",if end < self . plugin_args . start :,if start == end:,False,51.679442869914325,95.68265299477095
2822,"def _available_symbols ( self , scoperef , expr ) : <TAB>  cplns = [ ] <TAB>  found_names = set ( ) <TAB>  while scoperef : <TAB><TAB>  elem = self . _elem_from_scoperef ( scoperef ) <TAB><TAB>  for child in elem : <TAB><TAB><TAB>  name = child . get ( "" name "" , "" "" ) <TAB><TAB><TAB>  if name . startswith ( expr ) : <TAB><TAB><TAB><TAB>  if name not in found_names : <TAB><TAB><TAB><TAB><TAB>  found_names . add ( name ) <TAB><TAB><TAB><TAB><TAB>  ilk = child . get ( "" ilk "" ) or child . tag <TAB><TAB><TAB><TAB><TAB>  cplns . append ( ( ilk , name ) ) <TAB><TAB>  scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return sorted ( cplns , key = operator . itemgetter ( 1 ) ) ",if not scoperef :,if not scoperef:,False,51.54505658193328,100.00000000000004
2823,"def get_xenapi_host ( self ) : <TAB>  """"""Return the xenapi host on which nova-compute runs on."""""" <TAB>  with self . _get_session ( ) as session : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return session . xenapi . host . get_by_uuid ( self . host_uuid ) <TAB><TAB>  else : <TAB><TAB><TAB>  return session . xenapi . session . get_this_host ( session . handle ) ",if self . host_uuid :,if self.host_uuid:,False,37.95186719557842,100.00000000000004
2824,"def stream_docker_log ( log_stream ) : <TAB>  async for line in log_stream : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB><TAB>  elif "" status "" in line : <TAB><TAB><TAB>  logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB><TAB>  elif "" error "" in line : <TAB><TAB><TAB>  logger . error ( line [ "" error "" ] . strip ( ) ) <TAB><TAB><TAB>  raise DockerBuildError ","if ""stream"" in line and line [ ""stream"" ] . strip ( ) :","if ""stream"" in line:",False,50.427412727044164,91.71688392241211
2825,"def test_wildcard_import ( ) : <TAB>  bonobo = __import__ ( "" bonobo "" ) <TAB>  assert bonobo . __version__ <TAB>  for name in dir ( bonobo ) : <TAB><TAB>  # ignore attributes starting by underscores <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  attr = getattr ( bonobo , name ) <TAB><TAB>  if inspect . ismodule ( attr ) : <TAB><TAB><TAB>  continue <TAB><TAB>  assert name in bonobo . __all__ ","if name . startswith ( ""_"" ) :",if name.startswith('_'):,False,55.702885621572065,96.87122823607848
2826,"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB>  """"""Coerce the values in a variable to bools."""""" <TAB>  bool_var = self . program . NewVariable ( ) <TAB>  for b in var . bindings : <TAB><TAB>  v = b . data <TAB><TAB>  if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB><TAB><TAB>  const = v . pyval is true_val <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  const = not true_val <TAB><TAB>  elif not compare . compatible_with ( v , False ) : <TAB><TAB><TAB>  const = true_val <TAB><TAB>  else : <TAB><TAB><TAB>  const = None <TAB><TAB>  bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB>  return bool_var ","elif not compare . compatible_with ( v , True ) :",if const is True:,False,41.123529743547444,94.40494335597691
2827,"def _parse_policies ( self , policies_yaml ) : <TAB>  for item in policies_yaml : <TAB><TAB>  id_ = required_key ( item , "" id "" ) <TAB><TAB>  controls_ids = required_key ( item , "" controls "" ) <TAB><TAB>  if not isinstance ( controls_ids , list ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB><TAB><TAB><TAB><TAB>  id_ = id_ , controls = str ( controls_ids ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  raise ValueError ( msg ) <TAB><TAB>  self . policies [ id_ ] = controls_ids ","if controls_ids != ""all"" :",if not len(controls_ids) > 1:,False,36.25199559747482,95.60792074103936
2828,"def pong ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB>  if self . trace_enabled and self . ping_pong_trace_enabled : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  payload = payload . decode ( "" utf-8 "" ) <TAB><TAB>  self . logger . debug ( <TAB><TAB><TAB>  "" Sending a pong data frame  "" <TAB><TAB><TAB>  f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB><TAB>  ) <TAB>  data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PONG ) <TAB>  with self . sock_send_lock : <TAB><TAB>  self . sock . send ( data ) ","if isinstance ( payload , bytes ) :","if isinstance(payload, str):",False,24.544831751151154,98.66121287187084
2829,"def _extract_curve_feature_log ( arg ) : <TAB>  """"""extract sampled curve feature for log items"""""" <TAB>  try : <TAB><TAB>  inp , res = arg <TAB><TAB>  config = inp . config <TAB><TAB>  with inp . target : <TAB><TAB><TAB>  sch , args = inp . task . instantiate ( config ) <TAB><TAB>  fea = feature . get_buffer_curve_sample_flatten ( sch , args , sample_n = 20 ) <TAB><TAB>  x = np . concatenate ( ( fea , list ( config . get_other_option ( ) . values ( ) ) ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y = inp . task . flop / np . mean ( res . costs ) <TAB><TAB>  else : <TAB><TAB><TAB>  y = 0.0 <TAB><TAB>  return x , y <TAB>  except Exception :<TAB># pylint: disable=broad-except <TAB><TAB>  return None ",if res . error_no == 0 :,if len(res.costs) > 0:,False,53.069141218185855,94.95496096115238
2830,"def messageSourceStamps ( self , source_stamps ) : <TAB>  text = "" "" <TAB>  for ss in source_stamps : <TAB><TAB>  source = "" "" <TAB><TAB>  if ss [ "" branch "" ] : <TAB><TAB><TAB>  source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  source + = str ( ss [ "" revision "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  source + = "" HEAD "" <TAB><TAB>  if ss [ "" patch "" ] is not None : <TAB><TAB><TAB>  source + = ""  (plus patch) "" <TAB><TAB>  discriminator = "" "" <TAB><TAB>  if ss [ "" codebase "" ] : <TAB><TAB><TAB>  discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB><TAB>  text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB>  return text ","if ss [ ""revision"" ] :",if ss['revision']:,False,20.855160123900315,97.1648522805543
2831,"def find_repository ( ) : <TAB>  orig_path = path = os . path . realpath ( "" . "" ) <TAB>  drive , path = os . path . splitdrive ( path ) <TAB>  while path : <TAB><TAB>  current_path = os . path . join ( drive , path ) <TAB><TAB>  current_repo = LocalRepository ( current_path ) <TAB><TAB>  if current_repo . isValid ( ) : <TAB><TAB><TAB>  return current_repo <TAB><TAB>  path , path_tail = os . path . split ( current_path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise CannotFindRepository ( "" Cannot find repository for  %s "" % ( orig_path , ) ) ",if not path_tail :,if path_tail == orig_path:,False,23.164681526758564,95.42439237315592
2832,"def compute_indices ( text : str , tokens ) : <TAB>  indices = [ ] <TAB>  for i , token in enumerate ( tokens ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  current_index = indices [ - 1 ] + len ( tokens [ i - 1 ] [ 0 ] ) <TAB><TAB><TAB>  indices . append ( current_index + text [ current_index : ] . find ( token [ 0 ] ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  indices . append ( text . find ( token [ 0 ] ) ) <TAB>  return indices ",if 1 <= i :,if i > 0:,False,42.77249187997164,94.65934148076316
2833,"def _add_defaults_data_files ( self ) : <TAB>  # getting distribution.data_files <TAB>  if self . distribution . has_data_files ( ) : <TAB><TAB>  for item in self . distribution . data_files : <TAB><TAB><TAB>  if isinstance ( item , str ) : <TAB><TAB><TAB><TAB>  # plain file <TAB><TAB><TAB><TAB>  item = convert_path ( item ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . filelist . append ( item ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # a (dirname, filenames) tuple <TAB><TAB><TAB><TAB>  dirname , filenames = item <TAB><TAB><TAB><TAB>  for f in filenames : <TAB><TAB><TAB><TAB><TAB>  f = convert_path ( f ) <TAB><TAB><TAB><TAB><TAB>  if os . path . isfile ( f ) : <TAB><TAB><TAB><TAB><TAB><TAB>  self . filelist . append ( f ) ",if os . path . isfile ( item ) :,if os.path.isfile(item):,False,27.01479851899176,100.00000000000004
2834,"def libcxx_define ( settings ) : <TAB>  compiler = _base_compiler ( settings ) <TAB>  libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB>  if not compiler or not libcxx : <TAB><TAB>  return "" "" <TAB>  if str ( compiler ) in GCC_LIKE : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB><TAB>  elif str ( libcxx ) == "" libstdc++11 "" : <TAB><TAB><TAB>  return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB>  return "" "" ","if str ( libcxx ) == ""libstdc++"" :","if str(compiler) == ""libcxx-bax':",False,48.34088612679944,94.86654195111366
2835,"def _populate_tree ( self , element , d ) : <TAB>  """"""Populates an etree with attributes & elements, given a dict."""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB>  self . _populate_dict ( element , k , v ) <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  self . _populate_list ( element , k , v ) <TAB><TAB>  elif isinstance ( v , bool ) : <TAB><TAB><TAB>  self . _populate_bool ( element , k , v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _populate_str ( element , k , v ) <TAB><TAB>  elif type ( v ) in [ int , float , long , complex ] : <TAB><TAB><TAB>  self . _populate_number ( element , k , v ) ","elif isinstance ( v , basestring ) :","if type(v) in [str, float, long, complex, complex]:",False,31.899916246536954,92.93305509490845
2836,"def test_seek ( self ) : <TAB>  <IF-STMT>: <TAB><TAB>  print ( "" create large file via seek (may be sparse file) ... "" ) <TAB>  with self . open ( TESTFN , "" wb "" ) as f : <TAB><TAB>  f . write ( b "" z "" ) <TAB><TAB>  f . seek ( 0 ) <TAB><TAB>  f . seek ( size ) <TAB><TAB>  f . write ( b "" a "" ) <TAB><TAB>  f . flush ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" check file size with os.fstat "" ) <TAB><TAB>  self . assertEqual ( os . fstat ( f . fileno ( ) ) [ stat . ST_SIZE ] , size + 1 ) ",if verbose :,if verbose > 1:,False,31.272395004147295,95.64843573978467
2837,"def serialize_review_url_field ( self , obj , * * kwargs ) : <TAB>  if obj . review_ui : <TAB><TAB>  review_request = obj . get_review_request ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  local_site_name = review_request . local_site . name <TAB><TAB>  else : <TAB><TAB><TAB>  local_site_name = None <TAB><TAB>  return local_site_reverse ( <TAB><TAB><TAB>  "" file-attachment "" , <TAB><TAB><TAB>  local_site_name = local_site_name , <TAB><TAB><TAB>  kwargs = { <TAB><TAB><TAB><TAB>  "" review_request_id "" : review_request . display_id , <TAB><TAB><TAB><TAB>  "" file_attachment_id "" : obj . pk , <TAB><TAB><TAB>  } , <TAB><TAB>  ) <TAB>  return "" "" ",if review_request . local_site_id :,"if hasattr(review_request, 'local_site'):",False,48.721930599987715,96.03390441240816
2838,"def on_item_down_clicked ( self , button ) : <TAB>  model = self . treeview . get_model ( ) <TAB>  for s in self . _get_selected ( ) : <TAB><TAB>  <IF-STMT>:<TAB># XXX need model.swap <TAB><TAB><TAB>  old = model . get_iter ( s [ 0 ] ) <TAB><TAB><TAB>  iter = model . insert ( s [ 0 ] + 2 ) <TAB><TAB><TAB>  for i in range ( 3 ) : <TAB><TAB><TAB><TAB>  model . set_value ( iter , i , model . get_value ( old , i ) ) <TAB><TAB><TAB>  model . remove ( old ) <TAB><TAB><TAB>  self . treeview . get_selection ( ) . select_iter ( iter ) <TAB>  self . _update_filter_string ( ) ",if s [ 0 ] < len ( model ) - 1 :,if s[0] == 'click':,False,36.96073497524049,95.77799115132143
2839,"def writer ( self ) : <TAB>  """"""loop forever and copy socket->serial"""""" <TAB>  while self . alive : <TAB><TAB>  try : <TAB><TAB><TAB>  data = self . socket . recv ( 1024 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  self . serial . write ( b "" "" . join ( self . rfc2217 . filter ( data ) ) ) <TAB><TAB>  except socket . error as msg : <TAB><TAB><TAB>  self . log . error ( "" {} "" . format ( msg ) ) <TAB><TAB><TAB>  # probably got disconnected <TAB><TAB><TAB>  break <TAB>  self . stop ( ) ",if not data :,if not data:,False,37.15289348577377,100.00000000000004
2840,"def __getitem__ ( self , key ) : <TAB>  if key == 1 : <TAB><TAB>  return self . get_value ( ) <TAB>  elif key == 0 : <TAB><TAB>  return self . cell [ 0 ] <TAB>  elif isinstance ( key , slice ) : <TAB><TAB>  s = list ( self . cell . __getitem__ ( key ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s [ s . index ( self . cell [ 1 ] ) ] = self . get_value ( ) <TAB><TAB>  return s <TAB>  else : <TAB><TAB>  raise IndexError ( key ) ",if self . cell [ 1 ] in s :,if s.index(self.cell[0]) == key:,False,23.962192308731034,92.46256521299428
2841,"def test_error_stream ( environ , start_response ) : <TAB>  writer = start_response ( "" 200 OK "" , [ ] ) <TAB>  wsgi_errors = environ [ "" wsgi.errors "" ] <TAB>  error_msg = None <TAB>  for method in [ <TAB><TAB>  "" flush "" , <TAB><TAB>  "" write "" , <TAB><TAB>  "" writelines "" , <TAB>  ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB><TAB>  if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) : <TAB><TAB><TAB>  error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB><TAB>  if error_msg : <TAB><TAB><TAB>  break <TAB>  return_msg = error_msg or "" success "" <TAB>  writer ( return_msg ) <TAB>  return [ ] ","if not hasattr ( wsgi_errors , method ) :",if not wsgi_errors.has_attribute(method):,False,46.180995465864264,95.34119532226495
2842,"def job_rule_modules ( app ) : <TAB>  rules_module_list = [ ] <TAB>  for rules_module_name in __job_rule_module_names ( app ) : <TAB><TAB>  rules_module = sys . modules . get ( rules_module_name , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first <TAB><TAB><TAB>  # JobWrapper is created <TAB><TAB><TAB>  rules_module = importlib . import_module ( rules_module_name ) <TAB><TAB>  rules_module_list . append ( rules_module ) <TAB>  return rules_module_list ",if not rules_module :,if rules_module is None:,False,65.22225878399279,97.06690723479306
2843,"def discover_hdfstore ( f ) : <TAB>  d = dict ( ) <TAB>  for key in f . keys ( ) : <TAB><TAB>  d2 = d <TAB><TAB>  key2 = key . lstrip ( "" / "" ) <TAB><TAB>  while "" / "" in key2 : <TAB><TAB><TAB>  group , key2 = key2 . split ( "" / "" , 1 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  d2 [ group ] = dict ( ) <TAB><TAB><TAB>  d2 = d2 [ group ] <TAB><TAB>  d2 [ key2 ] = f . get_storer ( key ) <TAB>  return discover ( d ) ",if group not in d2 :,if group not in d2:,False,51.94090651210948,100.00000000000004
2844,"def test_update_zone ( self ) : <TAB>  zone = self . driver . list_zones ( ) [ 0 ] <TAB>  updated_zone = self . driver . update_zone ( zone = zone , domain = "" "" , extra = { "" paused "" : True } ) <TAB>  self . assertEqual ( zone . id , updated_zone . id ) <TAB>  self . assertEqual ( zone . domain , updated_zone . domain ) <TAB>  self . assertEqual ( zone . type , updated_zone . type ) <TAB>  self . assertEqual ( zone . ttl , updated_zone . ttl ) <TAB>  for key in set ( zone . extra ) | set ( updated_zone . extra ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertNotEqual ( zone . extra [ key ] , updated_zone . extra [ key ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( zone . extra [ key ] , updated_zone . extra [ key ] ) ","if key in ( ""paused"" , ""modified_on"" ) :",if key in updated_zone.extra:,False,49.248995971137234,94.79950089158064
2845,"def ESP ( phrase ) : <TAB>  for num , name in enumerate ( devname ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dev = devid [ num ] <TAB><TAB><TAB>  if custom_action_keyword [ "" Dict "" ] [ "" On "" ] in phrase : <TAB><TAB><TAB><TAB>  ctrl = "" =ON "" <TAB><TAB><TAB><TAB>  say ( "" Turning On  "" + name ) <TAB><TAB><TAB>  elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB><TAB><TAB><TAB>  ctrl = "" =OFF "" <TAB><TAB><TAB><TAB>  say ( "" Turning Off  "" + name ) <TAB><TAB><TAB>  rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False ) ",if name . lower ( ) in phrase :,if num in devid:,False,52.7282209698075,96.12533078839502
2846,"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB>  assert nw_id != self . nw_id_unknown <TAB>  ret = [ ] <TAB>  for port in self . get_ports ( dpid ) : <TAB><TAB>  nw_id_ = port . network_id <TAB><TAB>  if port . port_no == in_port : <TAB><TAB><TAB>  continue <TAB><TAB>  if nw_id_ == nw_id : <TAB><TAB><TAB>  ret . append ( port . port_no ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret . append ( port . port_no ) <TAB>  return ret ",elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,if allow_nw_id_external and (not port.is_external):,False,48.61459248327967,90.19144629715258
2847,"def tail ( filename ) : <TAB>  if os . path . isfile ( filename ) : <TAB><TAB>  file = open ( filename , "" r "" ) <TAB><TAB>  st_results = os . stat ( filename ) <TAB><TAB>  st_size = st_results [ 6 ] <TAB><TAB>  file . seek ( st_size ) <TAB><TAB>  while 1 : <TAB><TAB><TAB>  where = file . tell ( ) <TAB><TAB><TAB>  line = file . readline ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  time . sleep ( 1 ) <TAB><TAB><TAB><TAB>  file . seek ( where ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB><TAB>  line , <TAB><TAB><TAB><TAB>  )<TAB># already has newline <TAB>  else : <TAB><TAB>  print_error ( "" File not found, cannot tail. "" ) ",if not line :,if line == '':,False,50.49918818938222,96.21851300685535
2848,"def proc_day_of_week ( d ) : <TAB>  if expanded [ 4 ] [ 0 ] != "" * "" : <TAB><TAB>  diff_day_of_week = nearest_diff_method ( d . isoweekday ( ) % 7 , expanded [ 4 ] , 7 ) <TAB><TAB>  if diff_day_of_week is not None and diff_day_of_week != 0 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  d + = relativedelta ( days = diff_day_of_week , hour = 23 , minute = 59 , second = 59 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  d + = relativedelta ( days = diff_day_of_week , hour = 0 , minute = 0 , second = 0 ) <TAB><TAB><TAB>  return True , d <TAB>  return False , d ",if is_prev :,if diff_day_of_week == 0:,False,54.086152480583074,94.91503605603059
2849,"def __call__ ( self ) : <TAB>  """"""Run all check_* methods."""""" <TAB>  if self . on : <TAB><TAB>  oldformatwarning = warnings . formatwarning <TAB><TAB>  warnings . formatwarning = self . formatwarning <TAB><TAB>  try : <TAB><TAB><TAB>  for name in dir ( self ) : <TAB><TAB><TAB><TAB>  if name . startswith ( "" check_ "" ) : <TAB><TAB><TAB><TAB><TAB>  method = getattr ( self , name ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  method ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  warnings . formatwarning = oldformatwarning ",if method and callable ( method ) :,if callable(method):,False,45.32224221703552,98.18873938967617
2850,"def get ( self , request , * args , * * kwargs ) : <TAB>  if self . revision : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return send_file ( <TAB><TAB><TAB><TAB><TAB>  request , <TAB><TAB><TAB><TAB><TAB>  self . revision . file . path , <TAB><TAB><TAB><TAB><TAB>  self . revision . created , <TAB><TAB><TAB><TAB><TAB>  self . attachment . original_filename , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  except OSError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  return HttpResponseRedirect ( self . revision . file . url ) <TAB>  raise Http404 ",if settings . USE_LOCAL_PATH :,if self.attachment:,False,24.276817488139503,96.2315275774757
2851,"def _close ( self ) : <TAB>  super ( Recording , self ) . _close ( ) <TAB>  if self . _log_n is not None : <TAB><TAB>  for i in range ( self . n ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _log_n [ i ] . close ( ) <TAB><TAB><TAB><TAB>  self . _log_n [ i ] = None ",if self . _log_n [ i ] is not None :,if self._log_n[i] is not None:,False,53.41162088580174,100.00000000000004
2852,"def addTags ( self , rpcObjects = None ) : <TAB>  hosts = self . _getOnlyHostObjects ( rpcObjects ) <TAB>  if hosts : <TAB><TAB>  title = "" Add Tags "" <TAB><TAB>  body = "" What tags should be added? \n \n Use a comma or space between each "" <TAB><TAB>  ( tags , choice ) = self . getText ( title , body , "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tags = str ( tags ) . replace ( "" "" , "" , "" ) . split ( "" , "" ) <TAB><TAB><TAB>  for host in hosts : <TAB><TAB><TAB><TAB>  self . cuebotCall ( <TAB><TAB><TAB><TAB><TAB>  host . addTags , "" Add Tags to  %s  Failed "" % host . data . name , tags <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . _update ( ) ",if choice :,if choice:,False,32.27235216657768,98.42307799076669
2853,"def available_datasets ( self ) : <TAB>  """"""Automatically determine datasets provided by this file"""""" <TAB>  res = self . resolution <TAB>  coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB>  for var_name , val in self . file_content . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ds_info = { <TAB><TAB><TAB><TAB>  "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB><TAB><TAB><TAB>  "" resolution "" : res , <TAB><TAB><TAB>  } <TAB><TAB><TAB>  if not self . is_geo : <TAB><TAB><TAB><TAB>  ds_info [ "" coordinates "" ] = coordinates <TAB><TAB><TAB>  yield DatasetID ( name = var_name , resolution = res ) , ds_info ","if isinstance ( val , netCDF4 . Variable ) :",if val:,False,53.61199290060961,95.80898443888871
2854,"def extract_from_file ( fname : PathIsh ) - > Iterator [ Extraction ] : <TAB>  path = Path ( fname ) <TAB>  fallback_dt = file_mtime ( path ) <TAB>  p = Parser ( path ) <TAB>  for r in p . walk ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield r <TAB><TAB>  else : <TAB><TAB><TAB>  yield Visit ( <TAB><TAB><TAB><TAB>  url = r . url , <TAB><TAB><TAB><TAB>  dt = fallback_dt , <TAB><TAB><TAB><TAB>  locator = Loc . file ( fname ) ,<TAB># TODO line number <TAB><TAB><TAB><TAB>  context = r . context , <TAB><TAB><TAB>  ) ","if isinstance ( r , Exception ) :",if r.type == 'file':,False,21.195632673433156,94.00306415033619
2855,"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB>  if "" config "" in module_json [ "" meta "" ] : <TAB><TAB>  if module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  config . add_section ( module_json [ "" name "" ] ) <TAB><TAB><TAB>  for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB><TAB>  if config_var not in config [ module_json [ "" name "" ] ] : <TAB><TAB><TAB><TAB><TAB>  config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB>  return config ","if module_json [ ""name"" ] not in config :",if module_json['name'] in config:,False,52.068210266893026,96.9814349031113
2856,"def _create_entities ( parsed_entities , sidx , eidx ) : <TAB>  entities = [ ] <TAB>  for k , vs in parsed_entities . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vs = [ vs ] <TAB><TAB>  for value in vs : <TAB><TAB><TAB>  entities . append ( <TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB>  "" entity "" : k , <TAB><TAB><TAB><TAB><TAB>  "" start "" : sidx , <TAB><TAB><TAB><TAB><TAB>  "" end "" : eidx ,<TAB># can't be more specific <TAB><TAB><TAB><TAB><TAB>  "" value "" : value , <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  ) <TAB>  return entities ","if not isinstance ( vs , list ) :","if isinstance(vs, basestring):",False,28.957511116509533,96.14255201181834
2857,"def _telegram_upload_stream ( self , stream , * * kwargs ) : <TAB>  """"""Perform upload defined in a stream."""""" <TAB>  msg = None <TAB>  try : <TAB><TAB>  stream . accept ( ) <TAB><TAB>  msg = self . _telegram_special_message ( <TAB><TAB><TAB>  chat_id = stream . identifier . id , <TAB><TAB><TAB>  content = stream . raw , <TAB><TAB><TAB>  msg_type = stream . stream_type , <TAB><TAB><TAB>  * * kwargs , <TAB><TAB>  ) <TAB>  except Exception : <TAB><TAB>  log . exception ( f "" Upload of  { stream . name }  to  { stream . identifier }  failed. "" ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stream . error ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  stream . success ( ) ",if msg is None :,if msg is None:,False,31.52171054242997,100.00000000000004
2858,"def readlines ( self , size = - 1 ) : <TAB>  if self . _nbr == self . _size : <TAB><TAB>  return [ ] <TAB>  # leave all additional logic to our readline method, we just check the size <TAB>  out = [ ] <TAB>  nbr = 0 <TAB>  while True : <TAB><TAB>  line = self . readline ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  out . append ( line ) <TAB><TAB>  if size > - 1 : <TAB><TAB><TAB>  nbr + = len ( line ) <TAB><TAB><TAB>  if nbr > size : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  # END handle size constraint <TAB>  # END readline loop <TAB>  return out ",if not line :,if not line:,False,61.841337456842474,96.36844770794877
2859,"def clean_permissions ( <TAB>  cls , <TAB>  requestor : "" User "" , <TAB>  group : auth_models . Group , <TAB>  errors : Dict [ Optional [ str ] , List [ ValidationError ] ] , <TAB>  cleaned_input : dict ,  ) : <TAB>  field = "" add_permissions "" <TAB>  permission_items = cleaned_input . get ( field ) <TAB>  if permission_items : <TAB><TAB>  cleaned_input [ field ] = get_permissions ( permission_items ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . ensure_can_manage_permissions ( <TAB><TAB><TAB><TAB>  requestor , errors , field , permission_items <TAB><TAB><TAB>  ) ",if not requestor . is_superuser :,if permission_items:,False,48.397333750018,95.85970290181369
2860,"def _bwd ( subj = None , obj = None , seen = None ) : <TAB>  seen . add ( obj ) <TAB>  for s , o in evalPath ( graph , ( None , self . path , obj ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield s , o <TAB><TAB>  if self . more : <TAB><TAB><TAB>  if s in seen : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  for s2 , o2 in _bwd ( None , s , seen ) : <TAB><TAB><TAB><TAB>  yield s2 , o ",if not subj or subj == s :,if s in seen:,False,48.06959857240166,94.60497015513354
2861,"def generate_data ( self , request ) : <TAB>  """"""Generate data for the widget."""""" <TAB>  uptime = { } <TAB>  cache_stats = get_cache_stats ( ) <TAB>  if cache_stats : <TAB><TAB>  for hosts , stats in cache_stats : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB><TAB><TAB><TAB>  uptime [ "" unit "" ] = _ ( "" days "" ) <TAB><TAB><TAB>  elif stats [ "" uptime "" ] > 3600 : <TAB><TAB><TAB><TAB>  uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB><TAB><TAB><TAB>  uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB><TAB><TAB><TAB>  uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB>  return { "" cache_stats "" : cache_stats , "" uptime "" : uptime } ","if stats [ ""uptime"" ] > 86400 :",if hosts == request.SERVER_HOST:,False,52.885120633345636,96.82584294054054
2862,def refresh ( self ) : <TAB>  if self . _handle : <TAB><TAB>  source = self . _db . get_repository_from_handle ( self . _handle ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _title = str ( source . get_type ( ) ) <TAB><TAB><TAB>  self . _value = source . get_name ( ) ,if source :,if source:,False,50.94282553404679,100.00000000000004
2863,"def _gridconvvalue ( self , value ) : <TAB>  if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  svalue = str ( value ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  elif "" . "" in svalue : <TAB><TAB><TAB><TAB>  return getdouble ( svalue ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return getint ( svalue ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  pass <TAB>  return value ",if not svalue :,if svalue is None:,False,22.140487030956102,97.39007836521402
2864,"def parseGrants ( self , tree ) : <TAB>  for grant in tree . findall ( "" .//Grant "" ) : <TAB><TAB>  grantee = Grantee ( ) <TAB><TAB>  g = grant . find ( "" .//Grantee "" ) <TAB><TAB>  grantee . xsi_type = g . attrib [ "" { http://www.w3.org/2001/XMLSchema-instance}type "" ] <TAB><TAB>  grantee . permission = grant . find ( "" Permission "" ) . text <TAB><TAB>  for el in g : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  grantee . display_name = el . text <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  grantee . tag = el . tag <TAB><TAB><TAB><TAB>  grantee . name = el . text <TAB><TAB>  self . grantees . append ( grantee ) ","if el . tag == ""DisplayName"" :",if el.tag == 'display':,False,51.05197233211707,97.98469818368231
2865,"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB>  if name is None : <TAB><TAB>  if order == 0 : <TAB><TAB><TAB>  name = "" std_dev "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = "" sample_std_dev "" <TAB><TAB>  else : <TAB><TAB><TAB>  name = f "" std_dev { order } ) "" <TAB>  super ( ) . __init__ ( name = name , order = order ) <TAB>  self . order = order ",elif order == 1 :,if order == 0:,False,34.03025076290728,96.58617397397259
2866,"def _shouldRollover ( self ) : <TAB>  if self . maxBytes > 0 :<TAB># are we rolling over? <TAB><TAB>  try : <TAB><TAB><TAB>  self . stream . seek ( 0 , 2 )<TAB># due to non-posix-compliant Windows feature <TAB><TAB>  except IOError : <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  self . _degrade ( False , "" Rotation done or not needed at this time "" ) <TAB>  return False ",if self . stream . tell ( ) >= self . maxBytes :,if self.stream.read() == 2:,False,53.70654417848839,89.71363280604959
2867,"def userfullname ( ) : <TAB>  """"""Get the user's full name."""""" <TAB>  global _userfullname <TAB>  if not _userfullname : <TAB><TAB>  uid = os . getuid ( ) <TAB><TAB>  entry = pwd_from_uid ( uid ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB><TAB>  if not _userfullname : <TAB><TAB><TAB>  _userfullname = "" user %d "" % uid <TAB>  return _userfullname ",if entry :,if entry:,False,51.88669364882487,100.00000000000004
2868,"def drop ( self ) : <TAB>  # mssql <TAB>  sql = "" if object_id( ' %s ' ) is not null drop table  %s "" % ( self . tname , self . tname ) <TAB>  try : <TAB><TAB>  self . execute ( sql ) <TAB>  except Exception as e : <TAB><TAB>  self . conn . rollback ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB><TAB>  # sqlite <TAB><TAB>  sql = "" drop table if exists  %s "" % self . tname <TAB><TAB>  self . execute ( sql ) ","if ""syntax error"" not in str ( e ) :",if e.args[0] == 0:,False,31.16777104502781,90.7092006643504
2869,"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB>  delimiter = b "" \n "" <TAB>  if f . tell ( ) == 0 : <TAB><TAB>  return 0 <TAB>  while True : <TAB><TAB>  b = f . read ( block_size ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return f . tell ( ) <TAB><TAB>  elif delimiter in b : <TAB><TAB><TAB>  return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1 ",if not b :,if b == delimiter:,False,41.56821801960929,96.13846259739731
2870,"def _convert ( container ) : <TAB>  if _value_marker in container : <TAB><TAB>  force_list = False <TAB><TAB>  values = container . pop ( _value_marker ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  force_list = True <TAB><TAB><TAB>  values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB><TAB>  if not force_list and len ( values ) == 1 : <TAB><TAB><TAB>  values = values [ 0 ] <TAB><TAB>  if not container : <TAB><TAB><TAB>  return values <TAB><TAB>  return _convert ( container ) <TAB>  el<IF-STMT>: <TAB><TAB>  return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB>  return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) ) ","if container . pop ( _list_marker , False ) :",if values:,False,22.673067072153817,89.35771124141617
2871,"def fitting ( self , value ) : <TAB>  self . _fitting = value <TAB>  if self . _fitting is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  os . makedirs ( dirname ( self . checkpoint_path ( ) ) ) <TAB><TAB><TAB>  except FileExistsError as ex : <TAB><TAB><TAB><TAB>  pass<TAB># race to create <TAB><TAB>  if not os . path . exists ( dirname ( self . tensorboard_path ( ) ) ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  os . makedirs ( dirname ( self . tensorboard_path ( ) ) ) <TAB><TAB><TAB>  except FileExistsError as ex : <TAB><TAB><TAB><TAB>  pass<TAB># race to create ",if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,if not os.path.exists(dirname(self.checkpoint_path())):,False,22.73671480852363,95.96262019003571
2872,"def _make_headers ( self ) : <TAB>  libraries = self . _df . columns . to_list ( ) <TAB>  columns = [ ] <TAB>  for library in libraries : <TAB><TAB>  version = self . _package_versions [ library ] <TAB><TAB>  library_description = self . _libraries_description . get ( library ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  library + = "" {} "" . format ( library_description ) <TAB><TAB>  columns . append ( <TAB><TAB><TAB>  "" {library} <br><small> {version} </small> "" . format ( <TAB><TAB><TAB><TAB>  library = library , version = version <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB>  return [ "" "" ] + columns ",if library_description :,if library_description:,False,44.69037817513207,100.00000000000004
2873,"def plugin_on_song_ended ( self , song , stopped ) : <TAB>  if song is not None : <TAB><TAB>  poll = self . rating_box . poll_vote ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ups = int ( song . get ( "" ~#wins "" ) or 0 ) <TAB><TAB><TAB>  downs = int ( song . get ( "" ~#losses "" ) or 0 ) <TAB><TAB><TAB>  ups + = poll [ 0 ] <TAB><TAB><TAB>  downs + = poll [ 1 ] <TAB><TAB><TAB>  song [ "" ~#wins "" ] = ups <TAB><TAB><TAB>  song [ "" ~#losses "" ] = downs <TAB><TAB><TAB>  song [ "" ~#rating "" ] = ups / max ( ( ups + downs ) , 2 ) <TAB><TAB><TAB>  # note: ^^^ Look into implementing w/ confidence intervals! <TAB><TAB><TAB>  song [ "" ~#score "" ] = ups - downs ",if poll [ 0 ] >= 1 or poll [ 1 ] >= 1 :,if poll:,False,54.588487874919004,93.95680255294482
2874,"def submit ( self , pig_script , params ) : <TAB>  workflow = None <TAB>  try : <TAB><TAB>  workflow = self . _create_workflow ( pig_script , params ) <TAB><TAB>  mapping = dict ( <TAB><TAB><TAB>  [ ( param [ "" name "" ] , param [ "" value "" ] ) for param in workflow . get_parameters ( ) ] <TAB><TAB>  ) <TAB><TAB>  oozie_wf = _submit_workflow ( self . user , self . fs , self . jt , workflow , mapping ) <TAB>  finally : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  workflow . delete ( skip_trash = True ) <TAB>  return oozie_wf ",if workflow :,if oozie_wf:,False,26.733079460997722,97.32247148753277
2875,"def test_parse ( self ) : <TAB>  correct = 0 <TAB>  for example in EXAMPLES : <TAB><TAB>  try : <TAB><TAB><TAB>  schema . parse ( example . schema_string ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  correct + = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB><TAB>  except : <TAB><TAB><TAB>  if not example . valid : <TAB><TAB><TAB><TAB>  correct + = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB>  fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB><TAB>  correct , <TAB><TAB>  len ( EXAMPLES ) , <TAB>  ) <TAB>  self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg ) ",if example . valid :,if not example.valid:,False,45.35907120398598,99.05209761565798
2876,"def handle_sent ( self , elt ) : <TAB>  sent = [ ] <TAB>  for child in elt : <TAB><TAB>  if child . tag in ( "" wf "" , "" punc "" ) : <TAB><TAB><TAB>  itm = self . handle_word ( child ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sent . extend ( itm ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  sent . append ( itm ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB>  return SemcorSentence ( elt . attrib [ "" snum "" ] , sent ) ","if self . _unit == ""word"" :",if itm:,False,32.00342955917362,94.04939765376444
2877,"def _set_property ( self , target_widget , pname , value ) : <TAB>  if pname == "" text "" : <TAB><TAB>  state = target_widget . cget ( "" state "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  target_widget . configure ( state = tk . NORMAL ) <TAB><TAB><TAB>  target_widget . insert ( "" 0.0 "" , value ) <TAB><TAB><TAB>  target_widget . configure ( state = tk . DISABLED ) <TAB><TAB>  else : <TAB><TAB><TAB>  target_widget . insert ( "" 0.0 "" , value ) <TAB>  else : <TAB><TAB>  super ( TKText , self ) . _set_property ( target_widget , pname , value ) ",if state == tk . DISABLED :,if state == tk.NORMAL:,False,26.11230661932817,98.61676487306246
2878,"def get_vrf_tables ( self , vrf_rf = None ) : <TAB>  vrf_tables = { } <TAB>  for ( scope_id , table_id ) , table in self . _tables . items ( ) : <TAB><TAB>  if scope_id is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  vrf_tables [ ( scope_id , table_id ) ] = table <TAB>  return vrf_tables ",if vrf_rf is not None and table_id != vrf_rf :,if table_id == 0:,False,42.28967299579814,88.76679466782792
2879,"def new_f ( self , * args , * * kwargs ) : <TAB>  for obj in f ( self , * args , * * kwargs ) : <TAB><TAB>  if self . protected == False : <TAB><TAB><TAB>  if "" user "" in obj and obj [ "" user "" ] [ "" protected "" ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield obj ","elif ""protected"" in obj and obj [ ""protected"" ] :",if obj is None:,False,20.306788280371922,88.90993920251454
2880,"def draw ( self , context ) : <TAB>  col = self . layout . column ( ) <TAB>  col . operator ( "" node.sv_show_latest_commits "" ) <TAB>  if context . scene . sv_new_version : <TAB><TAB>  col_alert = self . layout . column ( ) <TAB><TAB>  col_alert . alert = True <TAB><TAB>  col_alert . operator ( "" node.sverchok_update_addon "" , text = "" Upgrade Sverchok addon "" ) <TAB>  else : <TAB><TAB>  col . operator ( "" node.sverchok_check_for_upgrades_wsha "" , text = "" Check for updates "" ) <TAB>  with sv_preferences ( ) as prefs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  col . operator ( "" node.sv_run_pydoc "" ) ",if prefs . developer_mode :,"if prefs.get('node.sverchok_update_for_upgrades',",False,21.405226086037885,93.51364833882651
2881,"def generate_tag_1_data ( ids ) : <TAB>  if len ( ids ) != SAMPLE_NUM : <TAB><TAB>  raise ValueError ( "" len ids should equal to sample number "" ) <TAB>  counter = 0 <TAB>  for sample_i in range ( SAMPLE_NUM ) : <TAB><TAB>  one_data = [ ids [ sample_i ] ] <TAB><TAB>  valid_set = [ x for x in range ( TAG_INTERVAL [ 0 ] , TAG_INTERVAL [ 1 ] ) ] <TAB><TAB>  features = np . random . choice ( valid_set , FEATURE_NUM , replace = False ) <TAB><TAB>  one_data + = [ "" : "" . join ( [ x , "" 1.0 "" ] ) for x in features ] <TAB><TAB>  counter + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" generate data  {} "" . format ( counter ) ) <TAB><TAB>  yield one_data ",if counter % 10000 == 0 :,if counter > MAX_TAG_COUNT:,False,26.15780584398718,96.72826681269969
2882,"def handle_api_languages ( self , http_context ) : <TAB>  mgr = PluginManager . get ( aj . context ) <TAB>  languages = set ( ) <TAB>  for id in mgr : <TAB><TAB>  locale_dir = mgr . get_content_path ( id , "" locale "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for lang in os . listdir ( locale_dir ) : <TAB><TAB><TAB><TAB>  if lang != "" app.pot "" : <TAB><TAB><TAB><TAB><TAB>  languages . add ( lang ) <TAB>  return sorted ( list ( languages ) ) ",if os . path . isdir ( locale_dir ) :,if os.path.exists(locale_dir):,False,51.26365430221427,98.41504940787179
2883,"def update ( self , t ) : <TAB>  # direction right - up <TAB>  for i in range ( self . grid . x ) : <TAB><TAB>  for j in range ( self . grid . y ) : <TAB><TAB><TAB>  distance = self . test_func ( i , j , t ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . turn_off_tile ( i , j ) <TAB><TAB><TAB>  elif distance < 1 : <TAB><TAB><TAB><TAB>  self . transform_tile ( i , j , distance ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . turn_on_tile ( i , j ) ",if distance == 0 :,if distance > 0:,False,27.08012247528372,98.07934514474348
2884,"def _handle_autocomplete_request_for_text ( text ) : <TAB>  if not hasattr ( text , "" autocompleter "" ) : <TAB><TAB>  if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB><TAB><TAB>  if isinstance ( text , CodeViewText ) : <TAB><TAB><TAB><TAB>  text . autocompleter = Completer ( text ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  text . autocompleter = ShellCompleter ( text ) <TAB><TAB><TAB>  text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB><TAB>  else : <TAB><TAB><TAB>  return <TAB>  text . autocompleter . handle_autocomplete_request ( ) ","elif isinstance ( text , ShellText ) :","if isinstance(text, ShellText):",False,50.53756890065117,98.68238253530389
2885,"def test_create_repository ( repo_name , expected_status , client ) : <TAB>  with client_with_identity ( "" devtable "" , client ) as cl : <TAB><TAB>  body = { <TAB><TAB><TAB>  "" namespace "" : "" devtable "" , <TAB><TAB><TAB>  "" repository "" : repo_name , <TAB><TAB><TAB>  "" visibility "" : "" public "" , <TAB><TAB><TAB>  "" description "" : "" foo "" , <TAB><TAB>  } <TAB><TAB>  result = conduct_api_call ( <TAB><TAB><TAB>  client , RepositoryList , "" post "" , None , body , expected_code = expected_status <TAB><TAB>  ) . json <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert result [ "" name "" ] == repo_name <TAB><TAB><TAB>  assert ( <TAB><TAB><TAB><TAB>  model . repository . get_repository ( "" devtable "" , repo_name ) . name == repo_name <TAB><TAB><TAB>  ) ",if expected_status == 201 :,if result:,False,48.931790314772115,97.12188058483561
2886,"def _apply_filter ( filter_item , filter_list ) : <TAB>  for filter_method in filter_list : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  raise MessageException ( <TAB><TAB><TAB><TAB>  "" Toolbox filter exception from  ' {} ' :  {} . "" . format ( <TAB><TAB><TAB><TAB><TAB>  filter_method . __name__ , unicodify ( e ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return True ","if not filter_method ( context , filter_item ) :",if filter_method.__name__ == filter_item.__name__ and filter_method.__,False,22.781524039782823,86.79238013169075
2887,"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB>  m = md5 ( ) <TAB>  try : <TAB><TAB>  while 1 : <TAB><TAB><TAB>  data = fp . read ( bufsize ) <TAB><TAB><TAB>  if not data : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data = data . encode ( fp . encoding ) <TAB><TAB><TAB>  m . update ( data ) <TAB>  except IOError as msg : <TAB><TAB>  sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB><TAB>  return 1 <TAB>  out . write ( "" %s %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB>  return 0 ","if isinstance ( data , str ) :","if isinstance(data, unicode):",False,50.82929649582195,98.81369152237478
2888,"def get_block_loc_keys ( block ) : <TAB>  """"""Extract loc_keys used by @block"""""" <TAB>  symbols = set ( ) <TAB>  for instr in block . lines : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( instr . raw , list ) : <TAB><TAB><TAB><TAB>  for expr in instr . raw : <TAB><TAB><TAB><TAB><TAB>  symbols . update ( get_expr_locs ( expr ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  for arg in instr . args : <TAB><TAB><TAB><TAB>  symbols . update ( get_expr_locs ( arg ) ) <TAB>  return symbols ","if isinstance ( instr , AsmRaw ) :",if instr.type == 'loc':,False,50.451728693798195,95.95207438491065
2889,"def get_operations ( cls , info , operations : List [ ProductAttributeAssignInput ] ) : <TAB>  """"""Resolve all passed global ids into integer PKs of the Attribute type."""""" <TAB>  product_attrs_pks = [ ] <TAB>  variant_attrs_pks = [ ] <TAB>  for operation in operations : <TAB><TAB>  pk = from_global_id_strict_type ( <TAB><TAB><TAB>  operation . id , only_type = Attribute , field = "" operations "" <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  product_attrs_pks . append ( pk ) <TAB><TAB>  else : <TAB><TAB><TAB>  variant_attrs_pks . append ( pk ) <TAB>  return product_attrs_pks , variant_attrs_pks ",if operation . type == ProductAttributeType . PRODUCT :,if pk is not None:,False,30.986618251983344,95.07994505375898
2890,"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB>  for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB><TAB>  if act [ "" type "" ] == "" SubProcess "" : <TAB><TAB><TAB>  _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  manual_intervention_nodes . add ( act [ "" id "" ] ) ","elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :","if act['type'] == ""Sequence':",False,19.754259202942517,83.81874948875573
2891,"def prompt_authorization ( self , stacks : List [ Stack ] ) : <TAB>  auth_required_per_resource = auth_per_resource ( stacks ) <TAB>  for resource , authorization_required in auth_required_per_resource : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  auth_confirm = confirm ( <TAB><TAB><TAB><TAB>  f "" \t { self . start_bold } { resource }  may not have authorization defined, Is this okay? { self . end_bold } "" , <TAB><TAB><TAB><TAB>  default = False , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  if not auth_confirm : <TAB><TAB><TAB><TAB>  raise GuidedDeployFailedError ( msg = "" Security Constraints Not Satisfied! "" ) ",if not authorization_required :,if authorization_required:,False,40.41017253484661,98.67114133947807
2892,"def get_cloud_credential ( self ) : <TAB>  """"""Return the credential which is directly tied to the inventory source type."""""" <TAB>  credential = None <TAB>  for cred in self . credentials . all ( ) : <TAB><TAB>  if self . source in CLOUD_PROVIDERS : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  credential = cred <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  # these need to be returned in the API credential field <TAB><TAB><TAB>  if cred . credential_type . kind != "" vault "" : <TAB><TAB><TAB><TAB>  credential = cred <TAB><TAB><TAB><TAB>  break <TAB>  return credential ","if cred . kind == self . source . replace ( ""ec2"" , ""aws"" ) :","if cred.credential_type.kind == ""cloud':",False,35.361130883032914,92.34922458425643
2893,"def validate_party_details ( self ) : <TAB>  if self . party : <TAB><TAB>  if not frappe . db . exists ( self . party_type , self . party ) : <TAB><TAB><TAB>  frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . validate_account_type ( <TAB><TAB><TAB><TAB>  self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB><TAB><TAB>  ) ","if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",if self.party_type:,False,34.23398043981744,89.55869807115067
2894,"def __iter__ ( self ) : <TAB>  it = DiskHashMerger . __iter__ ( self ) <TAB>  direct_upstreams = self . direct_upstreams <TAB>  for k , groups in it : <TAB><TAB>  t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB><TAB>  for i , g in enumerate ( groups ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if i in direct_upstreams : <TAB><TAB><TAB><TAB><TAB>  t [ i ] = g <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  g . sort ( key = itemgetter ( 0 ) ) <TAB><TAB><TAB><TAB><TAB>  g1 = [ ] <TAB><TAB><TAB><TAB><TAB>  for _ , vs in g : <TAB><TAB><TAB><TAB><TAB><TAB>  g1 . extend ( vs ) <TAB><TAB><TAB><TAB><TAB>  t [ i ] = g1 <TAB><TAB>  yield k , tuple ( t ) ",if g :,if g.size == 0:,False,35.286807812740165,97.68848230728761
2895,"def _unpack_scales ( scales , vidxs ) : <TAB>  scaleData = [ None , None , None ] <TAB>  for i in range ( 3 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  scale = scales [ i ] <TAB><TAB>  if not math . isnan ( scale ) : <TAB><TAB><TAB>  vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB><TAB><TAB>  scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB>  return scaleData ","if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",if scales[i] == 0:,False,27.365952631217276,87.98060738464604
2896,"def _make_ext_obj ( self , obj ) : <TAB>  ext = self . _get_ext_class ( obj . objname ) ( ) <TAB>  for name , val in obj . body : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Error val should be a list, this is a python-opcua bug "" , <TAB><TAB><TAB><TAB>  name , <TAB><TAB><TAB><TAB>  type ( val ) , <TAB><TAB><TAB><TAB>  val , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  for attname , v in val : <TAB><TAB><TAB><TAB>  self . _set_attr ( ext , attname , v ) <TAB>  return ext ","if not isinstance ( val , list ) :","if not isinstance(val, (list, tuple)):",False,32.697038433794,97.02448552733763
2897,"def insertLine ( self , refnum , linenum , line ) : <TAB>  i = - 1 <TAB>  for i , row in enumerate ( self . rows ) : <TAB><TAB>  if row [ 0 ] == linenum : <TAB><TAB><TAB>  if row [ refnum + 1 ] is None : <TAB><TAB><TAB><TAB>  row [ refnum + 1 ] = line <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  # else keep looking <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  self . rows . insert ( i , self . newRow ( linenum , refnum , line ) ) ",elif row [ 0 ] > linenum :,if i == -1:,False,50.82247834939637,93.30815293614647
2898,"def valid_localparts ( strip_delimiters = False ) : <TAB>  for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB>  # strip line, skip over empty lines <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  if line == "" "" : <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over comments or empty lines <TAB><TAB>  match = COMMENT . match ( line ) <TAB><TAB>  if match : <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over localparts with delimiters <TAB><TAB>  if strip_delimiters : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield line ","if "","" in line or "";"" in line :",if not line:,False,59.94024023548843,94.0114532328693
2899,"def encodingChanged ( self , idx ) : <TAB>  encoding = str ( self . mode_combo . currentText ( ) ) <TAB>  validator = None <TAB>  if encoding == "" hex "" : <TAB><TAB>  # only clear the box if there are non-hex chars <TAB><TAB>  # before setting the validator. <TAB><TAB>  txt = str ( self . data_edit . text ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . data_edit . setText ( "" "" ) <TAB><TAB>  regex = QtCore . QRegExp ( "" ^[0-9A-Fa-f]+$ "" ) <TAB><TAB>  validator = QtGui . QRegExpValidator ( regex ) <TAB>  self . data_edit . setValidator ( validator ) <TAB>  self . renderMemory ( ) ",if not all ( c in string . hexdigits for c in txt ) :,"if txt == ""none':",False,58.15545001069186,92.33654199845878
2900,"def _compare_single_run ( self , compares_done ) : <TAB>  try : <TAB><TAB>  compare_id , redo = self . in_queue . get ( <TAB><TAB><TAB>  timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB><TAB>  ) <TAB>  except Empty : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . db_interface . delete_old_compare_result ( compare_id ) <TAB><TAB><TAB>  compares_done . add ( compare_id ) <TAB><TAB><TAB>  self . _process_compare ( compare_id ) <TAB><TAB><TAB>  if self . callback : <TAB><TAB><TAB><TAB>  self . callback ( ) ",if redo :,if compare_id not in compares_done:,False,50.02629832696455,96.046433659472
2901,"def _transform_bin ( self , X : DataFrame ) : <TAB>  if self . _bin_map : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  X = X . copy ( deep = True ) <TAB><TAB>  with pd . option_context ( "" mode.chained_assignment "" , None ) : <TAB><TAB><TAB>  # Pandas complains about SettingWithCopyWarning, but this should be valid. <TAB><TAB><TAB>  for column in self . _bin_map : <TAB><TAB><TAB><TAB>  X [ column ] = binning . bin_column ( <TAB><TAB><TAB><TAB><TAB>  series = X [ column ] , <TAB><TAB><TAB><TAB><TAB>  mapping = self . _bin_map [ column ] , <TAB><TAB><TAB><TAB><TAB>  dtype = self . _astype_map [ column ] , <TAB><TAB><TAB><TAB>  ) <TAB>  return X ",if not self . inplace :,if self._is_chained_assignment:,False,47.69694292642435,96.32392468016924
2902,"def escape ( text , newline = False ) : <TAB>  """"""Escape special html characters."""""" <TAB>  if isinstance ( text , str ) : <TAB><TAB>  if "" & "" in text : <TAB><TAB><TAB>  text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB>  if "" > "" in text : <TAB><TAB><TAB>  text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB>  if "" < "" in text : <TAB><TAB><TAB>  text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB>  if ' "" ' in text : <TAB><TAB><TAB>  text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB>  if newline : <TAB><TAB><TAB>  if "" \n "" in text : <TAB><TAB><TAB><TAB>  text = text . replace ( "" \n "" , "" <br> "" ) <TAB>  return text ","if ""'"" in text :","if '""' in text:",False,50.171043615281484,98.7143459681212
2903,"def read ( self ) : <TAB>  """"""Reads the robots.txt URL and feeds it to the parser."""""" <TAB>  try : <TAB><TAB>  f = urllib . request . urlopen ( self . url ) <TAB>  except urllib . error . HTTPError as err : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . disallow_all = True <TAB><TAB>  elif err . code > = 400 and err . code < 500 : <TAB><TAB><TAB>  self . allow_all = True <TAB>  else : <TAB><TAB>  raw = f . read ( ) <TAB><TAB>  self . parse ( raw . decode ( "" utf-8 "" ) . splitlines ( ) ) ","if err . code in ( 401 , 403 ) :",if err.code == 403 and err.code == 403:,False,54.93780146208206,93.58007066567984
2904,"def post_create ( self , user , billing = None ) : <TAB>  from weblate . trans . models import Change <TAB>  if billing : <TAB><TAB>  billing . projects . add ( self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . access_control = Project . ACCESS_PRIVATE <TAB><TAB>  else : <TAB><TAB><TAB>  self . access_control = Project . ACCESS_PUBLIC <TAB><TAB>  self . save ( ) <TAB>  if not user . is_superuser : <TAB><TAB>  self . add_user ( user , "" @Administration "" ) <TAB>  Change . objects . create ( <TAB><TAB>  action = Change . ACTION_CREATE_PROJECT , project = self , user = user , author = user <TAB>  ) ",if billing . plan . change_access_control :,if user is None:,False,48.6041025827115,94.42911231057678
2905,"def visitConst ( self , node ) : <TAB>  if self . documentable : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . documentable . append ( make_docstring ( node . value , node . lineno ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . documentable = None ","if type ( node . value ) in ( StringType , UnicodeType ) :",if node.value:,False,34.01407567509215,85.35154928412204
2906,"def requires ( self ) : <TAB>  requires = copy . deepcopy ( self . _requires ) <TAB>  # Auto add dependencies when parameters reference the Ouptuts of <TAB>  # another stack. <TAB>  parameters = self . parameters <TAB>  for value in parameters . values ( ) : <TAB><TAB>  if isinstance ( value , basestring ) and "" :: "" in value : <TAB><TAB><TAB>  stack_name , _ = value . split ( "" :: "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  requires . add ( stack_name ) <TAB>  return requires ",if stack_name not in requires :,if stack_name not in requires:,False,60.280812031544386,100.00000000000004
2907,"def __load_protos ( ) : <TAB>  g = globals ( ) <TAB>  for k , v in g . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = k [ 4 : ] <TAB><TAB><TAB>  modname = name . lower ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  mod = __import__ ( modname , g , level = 1 ) <TAB><TAB><TAB><TAB>  PPP . set_p ( v , getattr ( mod , name ) ) <TAB><TAB><TAB>  except ( ImportError , AttributeError ) : <TAB><TAB><TAB><TAB>  continue ","if k . startswith ( ""PPP_"" ) :",if k.startswith('protos'):,False,50.89698095084421,96.82351793387642
2908,"def init_weights ( self ) : <TAB>  """"""Initialize model weights."""""" <TAB>  for m in self . predict_layers . modules ( ) : <TAB><TAB>  if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB>  kaiming_init ( m ) <TAB><TAB>  elif isinstance ( m , nn . BatchNorm2d ) : <TAB><TAB><TAB>  constant_init ( m , 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  normal_init ( m , std = 0.01 ) ","elif isinstance ( m , nn . Linear ) :","if isinstance(m, nn.BatchNorm2d):",False,26.17788379501611,96.25354647617574
2909,"def get_data ( self ) : <TAB>  """"""get all data from sockets"""""" <TAB>  si = self . inputs <TAB>  parameters = [ ] <TAB>  for socket in si : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parameters . append ( socket . sv_get ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  parameters . append ( socket . sv_get ( default = [ [ ] ] ) ) <TAB>  return match_long_repeat ( parameters ) ",if len ( socket . prop_name ) > 0 :,"if hasattr(socket, 'sv_get'):",False,49.487090845748085,92.04856152089918
2910,"def test_parse_query_params_comparable_field ( self ) : <TAB>  query_params = { "" filter[int_field][gt] "" : 42 , "" filter[int_field][lte] "" : 9000 } <TAB>  fields = self . view . parse_query_params ( query_params ) <TAB>  for key , field_name in fields . items ( ) : <TAB><TAB>  if field_name [ "" int_field "" ] [ "" op "" ] == "" gt "" : <TAB><TAB><TAB>  assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 42 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 9000 ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . fail ( ) ","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :",if key == 'int_field':,False,49.89312714785572,90.3068922889759
2911,"def _create_examples ( self , lines , set_type ) : <TAB>  """"""Creates examples for the training and dev sets."""""" <TAB>  examples = [ ] <TAB>  for ( i , line ) in enumerate ( lines ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  guid = "" %s - %s "" % ( set_type , i ) <TAB><TAB>  text = line [ 0 ] <TAB><TAB>  bbox = line [ 1 ] <TAB><TAB>  label = line [ 2 ] <TAB><TAB>  examples . append ( <TAB><TAB><TAB>  DocExample ( guid = guid , text_a = text , text_b = None , bbox = bbox , label = label ) <TAB><TAB>  ) <TAB>  return examples ",if i == 0 :,if i == len(lines):,False,53.52969359825237,95.3587327410494
2912,"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB>  try : <TAB><TAB>  attr_mod , attr_path = ( <TAB><TAB><TAB>  mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB><TAB>  ) <TAB><TAB>  full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB><TAB>  op = import_module ( full_mod_path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Only load attributes if needed <TAB><TAB><TAB>  for part in attr_path . split ( "" . "" ) : <TAB><TAB><TAB><TAB>  op = getattr ( op , part ) <TAB><TAB>  return op <TAB>  except ( ImportError , AttributeError ) as ex : <TAB><TAB>  if checked : <TAB><TAB><TAB>  return None <TAB><TAB>  raise ex ",if attr_path :,if op is not None:,False,52.845340472973554,97.9019439910598
2913,"def _load_ui_modules ( self , modules : Any ) - > None : <TAB>  if isinstance ( modules , types . ModuleType ) : <TAB><TAB>  self . _load_ui_modules ( dict ( ( n , getattr ( modules , n ) ) for n in dir ( modules ) ) ) <TAB>  elif isinstance ( modules , list ) : <TAB><TAB>  for m in modules : <TAB><TAB><TAB>  self . _load_ui_modules ( m ) <TAB>  else : <TAB><TAB>  assert isinstance ( modules , dict ) <TAB><TAB>  for name , cls in modules . items ( ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . ui_modules [ name ] = cls <TAB><TAB><TAB>  except TypeError : <TAB><TAB><TAB><TAB>  pass ","if issubclass ( cls , UIModule ) :",if name not in self.ui_modules:,False,42.026935580365446,95.78318403574545
2914,"def _remove_obsolete_leafs ( input_dict ) : <TAB>  if not isinstance ( input_dict , dict ) : <TAB><TAB>  return <TAB>  if input_dict [ LEAF_MARKER ] : <TAB><TAB>  bottom_leafs = input_dict [ LEAF_MARKER ] <TAB><TAB>  for leaf in bottom_leafs : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  input_dict [ LEAF_MARKER ] . remove ( leaf ) <TAB>  for subtree in input_dict . keys ( ) : <TAB><TAB>  _remove_obsolete_leafs ( input_dict [ subtree ] ) ",if leaf in input_dict :,if input_dict.has_key(leaf):,False,49.187294662734416,93.74263427308325
2915,"def decode ( self , value , force = False ) : <TAB>  "" Return a unicode string from the bytes-like representation "" <TAB>  if self . decode_responses or force : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = value . tobytes ( ) <TAB><TAB>  if isinstance ( value , bytes ) : <TAB><TAB><TAB>  value = value . decode ( self . encoding , self . encoding_errors ) <TAB>  return value ","if isinstance ( value , memoryview ) :","if isinstance(value, (bytes, str)):",False,56.015199269636305,94.25711044213084
2916,"def audit ( self , directive ) : <TAB>  value = _get_value ( directive ) <TAB>  if not value : <TAB><TAB>  return <TAB>  server_side = directive . name . startswith ( "" proxy_ "" ) <TAB>  for var in compile_script ( value ) : <TAB><TAB>  char = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  char = "" \\ n "" <TAB><TAB>  elif not server_side and var . can_contain ( "" \r "" ) : <TAB><TAB><TAB>  char = "" \\ r "" <TAB><TAB>  else : <TAB><TAB><TAB>  continue <TAB><TAB>  reason = ' At least variable  "" $ {var} ""  can contain  "" {char} "" ' . format ( <TAB><TAB><TAB>  var = var . name , char = char <TAB><TAB>  ) <TAB><TAB>  self . add_issue ( directive = [ directive ] + var . providers , reason = reason ) ","if var . can_contain ( ""\n"" ) :","if not server_side and var.can_contain(""\n""):",False,40.78677400470383,96.01554338453481
2917,"def checkFilename ( filename ) :<TAB># useful in case of drag and drop <TAB>  while True : <TAB><TAB>  if filename [ 0 ] == "" ' "" : <TAB><TAB><TAB>  filename = filename [ 1 : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename = filename [ : - 1 ] <TAB><TAB>  if os . path . exists ( filename ) : <TAB><TAB><TAB>  return filename <TAB><TAB>  filename = input ( <TAB><TAB><TAB>  "" [!] Cannot find  ' %s ' . \n [*] Enter a valid name of the file containing the paths to test ->  "" <TAB><TAB><TAB>  % filename <TAB><TAB>  ) ","if filename [ len ( filename ) - 1 ] == ""'"" :",if filename[-1] == '-':,False,23.363466933923938,90.90071549946117
2918,"def findfiles ( self , dir , base , rec ) : <TAB>  try : <TAB><TAB>  names = os . listdir ( dir or os . curdir ) <TAB>  except os . error as msg : <TAB><TAB>  print ( msg ) <TAB><TAB>  return [ ] <TAB>  list = [ ] <TAB>  subdirs = [ ] <TAB>  for name in names : <TAB><TAB>  fn = os . path . join ( dir , name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  subdirs . append ( fn ) <TAB><TAB>  else : <TAB><TAB><TAB>  if fnmatch . fnmatch ( name , base ) : <TAB><TAB><TAB><TAB>  list . append ( fn ) <TAB>  if rec : <TAB><TAB>  for subdir in subdirs : <TAB><TAB><TAB>  list . extend ( self . findfiles ( subdir , base , rec ) ) <TAB>  return list ",if os . path . isdir ( fn ) :,if os.path.isdir(fn):,False,50.76303510026412,100.00000000000004
2919,"def loop ( handler , obj ) : <TAB>  handler . response . write ( "" <table> "" ) <TAB>  for k , v in obj . __dict__ . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  style = "" color: red "" if not v else "" "" <TAB><TAB><TAB>  handler . response . write ( <TAB><TAB><TAB><TAB>  ' <tr style= "" {} "" ><td> {} :</td><td> {} </td></tr> ' . format ( style , k , v ) <TAB><TAB><TAB>  ) <TAB>  handler . response . write ( "" </table> "" ) ","if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :",if k == 'color':,False,44.316668859630546,85.35444441972209
2920,"def anypython ( request ) : <TAB>  name = request . param <TAB>  executable = getexecutable ( name ) <TAB>  if executable is None : <TAB><TAB>  if sys . platform == "" win32 "" : <TAB><TAB><TAB>  executable = winpymap . get ( name , None ) <TAB><TAB><TAB>  if executable : <TAB><TAB><TAB><TAB>  executable = py . path . local ( executable ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return executable <TAB><TAB>  pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB>  return executable ",if executable . check ( ) :,if not os.path.exists(executable):,False,30.18570569729699,94.72575083485003
2921,"def __init__ ( self , socketpath = None ) : <TAB>  if socketpath is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  socketpath = "" /var/run/usbmuxd "" <TAB><TAB>  else : <TAB><TAB><TAB>  socketpath = "" /var/run/usbmuxd "" <TAB>  self . socketpath = socketpath <TAB>  self . listener = MuxConnection ( socketpath , BinaryProtocol ) <TAB>  try : <TAB><TAB>  self . listener . listen ( ) <TAB><TAB>  self . version = 0 <TAB><TAB>  self . protoclass = BinaryProtocol <TAB>  except MuxVersionError : <TAB><TAB>  self . listener = MuxConnection ( socketpath , PlistProtocol ) <TAB><TAB>  self . listener . listen ( ) <TAB><TAB>  self . protoclass = PlistProtocol <TAB><TAB>  self . version = 1 <TAB>  self . devices = self . listener . devices ","if sys . platform == ""darwin"" :",if sys.platform == 'win32':,False,50.79367895046965,97.88026690963385
2922,"def _validate_distinct_on_different_types_and_field_orders ( <TAB>  self , collection , query , expected_results , get_mock_result  ) : <TAB>  self . count = 0 <TAB>  self . get_mock_result = get_mock_result <TAB>  query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB>  results = list ( query_iterable ) <TAB>  for i in range ( len ( expected_results ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB>  elif isinstance ( results [ i ] , list ) : <TAB><TAB><TAB>  self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB>  self . count = 0 ","if isinstance ( results [ i ] , dict ) :","if isinstance(results[i], dict):",False,50.84352003184212,100.00000000000004
2923,"def getRootId ( self , id ) : <TAB>  with self . connect ( ) as cu : <TAB><TAB>  while True : <TAB><TAB><TAB>  stmt = "" select parent_path_id from hierarchy where path_id = ? "" <TAB><TAB><TAB>  cu . execute ( stmt , ( id , ) ) <TAB><TAB><TAB>  parent_id = cu . fetchone ( ) [ 0 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return id <TAB><TAB><TAB>  id = parent_id ",if parent_id is None or parent_id == id :,if parent_id == id:,False,38.55702304414365,95.86267176373941
2924,"def add ( self , path ) : <TAB>  with self . get_lock ( path ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . entries [ path ] = { } <TAB><TAB><TAB>  self . entries [ path ] [ "" lock "" ] = self . new_locks [ path ] <TAB><TAB><TAB>  del self . new_locks [ path ] <TAB><TAB><TAB>  self . lru . append ( path ) ",if not path in self . entries :,if path not in self.entries:,False,44.717312311845944,97.37373076357181
2925,"def _get_coordinates_for_dataset_key ( self , dsid ) : <TAB>  """"""Get the coordinate dataset keys for *dsid*."""""" <TAB>  ds_info = self . ids [ dsid ] <TAB>  cids = [ ] <TAB>  for cinfo in ds_info . get ( "" coordinates "" , [ ] ) : <TAB><TAB>  if not isinstance ( cinfo , dict ) : <TAB><TAB><TAB>  cinfo = { "" name "" : cinfo } <TAB><TAB>  cinfo [ "" resolution "" ] = ds_info [ "" resolution "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cinfo [ "" polarization "" ] = ds_info [ "" polarization "" ] <TAB><TAB>  cid = DatasetID ( * * cinfo ) <TAB><TAB>  cids . append ( self . get_dataset_key ( cid ) ) <TAB>  return cids ","if ""polarization"" in ds_info :",if 'polarization' in ds_info:,False,31.50389373823063,97.82913368556432
2926,"def build_from_gdobj ( cls , gdobj , steal = False ) : <TAB>  # Avoid calling cls.__init__ by first instanciating a placeholder, then <TAB>  # overloading it __class__ to turn it into an instance of the right class <TAB>  ret = BuiltinInitPlaceholder ( ) <TAB>  if steal : <TAB><TAB>  assert ffi . typeof ( gdobj ) . kind == "" pointer "" <TAB><TAB>  ret . _gd_ptr = gdobj <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret . _gd_ptr = cls . _copy_gdobj ( gdobj ) <TAB><TAB>  else : <TAB><TAB><TAB>  ret . _gd_ptr = cls . _copy_gdobj ( ffi . addressof ( gdobj ) ) <TAB>  ret . __class__ = cls <TAB>  return ret ","if ffi . typeof ( gdobj ) . kind == ""pointer"" :","if isinstance(gdobj, gd.gdobj.gdobj.gdobj.gdobj",False,64.98604318308244,93.1843149848218
2927,"def _listen_output ( self ) : <TAB>  "" NB! works in background thread "" <TAB>  try : <TAB><TAB>  while True : <TAB><TAB><TAB>  chars = self . _proc . read ( 1 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  as_bytes = chars . encode ( self . encoding ) <TAB><TAB><TAB><TAB>  self . _make_output_available ( as_bytes ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _error = "" EOF "" <TAB><TAB><TAB><TAB>  break <TAB>  except Exception as e : <TAB><TAB>  self . _error = str ( e ) ",if len ( chars ) > 0 :,if chars:,False,25.19747852827291,96.06913750463158
2928,"def result ( <TAB>  metrics : Dict [ metric_types . MetricKey , Any ]  ) - > Dict [ metric_types . AttributionsKey , Dict [ Text , Union [ float , np . ndarray ] ] ] : <TAB>  """"""Returns mean attributions."""""" <TAB>  total_attributions = metrics [ total_attributions_key ] <TAB>  weighted_count = metrics [ weighted_example_count_key ] <TAB>  attributions = { } <TAB>  for k , v in total_attributions . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attributions [ k ] = float ( "" nan "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  attributions [ k ] = v / weighted_count <TAB>  return { key : attributions } ","if np . isclose ( weighted_count , 0.0 ) :",if v == 0:,False,22.382312483675005,93.735400037039
2929,"def write_if_changed ( path , data ) : <TAB>  if isinstance ( data , str ) : <TAB><TAB>  data = data . encode ( ) <TAB>  changed = False <TAB>  with open ( os . open ( path , os . O_CREAT | os . O_RDWR ) , "" wb+ "" ) as f : <TAB><TAB>  f . seek ( 0 ) <TAB><TAB>  current = f . read ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  changed = True <TAB><TAB><TAB>  f . seek ( 0 ) <TAB><TAB><TAB>  f . write ( data ) <TAB><TAB><TAB>  f . truncate ( ) <TAB><TAB>  os . fsync ( f ) <TAB>  return changed ",if current != data :,if current != data:,False,50.80512298614932,100.00000000000004
2930,"def detect_ssl_option ( self ) : <TAB>  for option in self . ssl_options ( ) : <TAB><TAB>  if scan_argv ( self . argv , option ) is not None : <TAB><TAB><TAB>  for other_option in self . ssl_options ( ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if scan_argv ( self . argv , other_option ) is not None : <TAB><TAB><TAB><TAB><TAB><TAB>  raise ConfigurationError ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return option ",if option != other_option :,if other_option.name == option.name:,False,28.200668767810257,95.49037416774829
2931,"def _infer_return_type ( * args ) : <TAB>  """"""Look at the type of all args and divine their implied return type."""""" <TAB>  return_type = None <TAB>  for arg in args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if isinstance ( arg , bytes ) : <TAB><TAB><TAB>  if return_type is str : <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = bytes <TAB><TAB>  else : <TAB><TAB><TAB>  if return_type is bytes : <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = str <TAB>  if return_type is None : <TAB><TAB>  return str<TAB># tempfile APIs return a str by default. <TAB>  return return_type ",if arg is None :,if arg is None:,False,59.38365160498347,94.61643183435234
2932,"def _get_app ( self , body = None ) : <TAB>  app = self . _app <TAB>  if app is None : <TAB><TAB>  try : <TAB><TAB><TAB>  tasks = self . tasks . tasks<TAB># is a group <TAB><TAB>  except AttributeError : <TAB><TAB><TAB>  tasks = self . tasks <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  app = tasks [ 0 ] . _app <TAB><TAB>  if app is None and body is not None : <TAB><TAB><TAB>  app = body . _app <TAB>  return app if app is not None else current_app ",if len ( tasks ) :,if tasks:,False,39.1650998664554,95.60366382200147
2933,"def add_field ( self , field ) : <TAB>  self . remove_field ( field . name ) <TAB>  self . fields [ field . name ] = field <TAB>  self . columns [ field . db_column ] = field <TAB>  self . _sorted_field_list . insert ( field ) <TAB>  self . _update_field_lists ( ) <TAB>  if field . default is not None : <TAB><TAB>  self . defaults [ field ] = field . default <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _default_callables [ field ] = field . default <TAB><TAB><TAB>  self . _default_callable_list . append ( ( field . name , field . default ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _default_dict [ field ] = field . default <TAB><TAB><TAB>  self . _default_by_name [ field . name ] = field . default ",if callable ( field . default ) :,if field.default is not None:,False,27.53234214883882,97.35264888189384
2934,"def _get_families ( self ) : <TAB>  families = [ ] <TAB>  for name , ext in self . _get_family_dirs ( ) : <TAB><TAB>  <IF-STMT>:<TAB># is a directory <TAB><TAB><TAB>  family = self . get_resource ( <TAB><TAB><TAB><TAB>  FileSystemPackageFamilyResource . key , location = self . location , name = name <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  family = self . get_resource ( <TAB><TAB><TAB><TAB>  FileSystemCombinedPackageFamilyResource . key , <TAB><TAB><TAB><TAB>  location = self . location , <TAB><TAB><TAB><TAB>  name = name , <TAB><TAB><TAB><TAB>  ext = ext , <TAB><TAB><TAB>  ) <TAB><TAB>  families . append ( family ) <TAB>  return families ",if ext is None :,if ext == 'a':,False,47.04093435687648,96.28634929020293
2935,"def test ( model , data_loader , device = None ) : <TAB>  device = device or torch . device ( "" cpu "" ) <TAB>  model . eval ( ) <TAB>  correct = 0 <TAB>  total = 0 <TAB>  with torch . no_grad ( ) : <TAB><TAB>  for batch_idx , ( data , target ) in enumerate ( data_loader ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  data , target = data . to ( device ) , target . to ( device ) <TAB><TAB><TAB>  outputs = model ( data ) <TAB><TAB><TAB>  _ , predicted = torch . max ( outputs . data , 1 ) <TAB><TAB><TAB>  total + = target . size ( 0 ) <TAB><TAB><TAB>  correct + = ( predicted == target ) . sum ( ) . item ( ) <TAB>  return correct / total ",if batch_idx * len ( data ) > TEST_SIZE :,if batch_idx == len(data):,False,25.0060481862561,96.5790379502598
2936,"def __animate_progress ( self ) : <TAB>  """"""Change the status message, mostly used to animate progress."""""" <TAB>  while True : <TAB><TAB>  sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB>  with self . __progress_lock : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB><TAB>  elif self . __show_animation : <TAB><TAB><TAB><TAB>  self . __progress_status . update_progress ( self . __current_operation_name ) <TAB><TAB><TAB><TAB>  sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . __progress_status . show_as_ready ( ) <TAB><TAB><TAB><TAB>  sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB>  # Allow some time for progress status to be updated. <TAB><TAB>  time . sleep ( sleep_time ) ",if not self . __progress_status :,if self.__current_operation_name == self.__current_operation_name:,False,43.4177167345479,93.4701228962958
2937,"def _parse_subtitles ( self , video_data , url_key ) : <TAB>  subtitles = { } <TAB>  for translation in video_data . get ( "" translations "" , [ ] ) : <TAB><TAB>  vtt_path = translation . get ( url_key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  lang = translation . get ( "" language_w3c "" ) or ISO639Utils . long2short ( <TAB><TAB><TAB>  translation [ "" language_medium "" ] <TAB><TAB>  ) <TAB><TAB>  subtitles . setdefault ( lang , [ ] ) . append ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" ext "" : "" vtt "" , <TAB><TAB><TAB><TAB>  "" url "" : vtt_path , <TAB><TAB><TAB>  } <TAB><TAB>  ) <TAB>  return subtitles ",if not vtt_path :,if vtt_path is None:,False,49.68114598265494,97.72184319311536
2938,"def postprocess_message ( self , msg ) : <TAB>  if msg [ "" type "" ] == "" sample "" and msg [ "" value "" ] is not None : <TAB><TAB>  fn , value = msg [ "" fn "" ] , msg [ "" value "" ] <TAB><TAB>  value_batch_ndims = jnp . ndim ( value ) - fn . event_dim <TAB><TAB>  fn_batch_ndim = len ( fn . batch_shape ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  prepend_shapes = ( 1 , ) * ( value_batch_ndims - fn_batch_ndim ) <TAB><TAB><TAB>  msg [ "" fn "" ] = tree_map ( <TAB><TAB><TAB><TAB>  lambda x : jnp . reshape ( x , prepend_shapes + jnp . shape ( x ) ) , fn <TAB><TAB><TAB>  ) ",if fn_batch_ndim < value_batch_ndims :,if fn_batch_ndim > 0:,False,49.18197775248269,96.51130064155483
2939,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_filename ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 0:,False,46.452429171598006,97.7421864143982
2940,"def createError ( self , line , pos , description ) : <TAB>  global ENABLE_PYIMPORT <TAB>  msg = "" Line  "" + unicode ( line ) + "" :  "" + unicode ( description ) <TAB>  if ENABLE_JS2PY_ERRORS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  import js2py . base <TAB><TAB><TAB>  return js2py . base . MakeError ( "" SyntaxError "" , msg ) <TAB><TAB>  else : <TAB><TAB><TAB>  return ENABLE_JS2PY_ERRORS ( msg ) <TAB>  else : <TAB><TAB>  return JsSyntaxError ( msg ) ","if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :",if ENABLE_PYIMPORT:,False,48.51108618061877,92.47476767865412
2941,"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB>  items = [ ] <TAB>  for extractor in self . extractors : <TAB><TAB>  extracted = extractor . extract ( <TAB><TAB><TAB>  page , start_index , end_index , self . template . ignored_regions <TAB><TAB>  ) <TAB><TAB>  for item in arg_to_iter ( extracted ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if isinstance ( item , ( ItemProcessor , dict ) ) : <TAB><TAB><TAB><TAB><TAB>  item [ u "" _template "" ] = self . template . id <TAB><TAB><TAB><TAB>  items . append ( item ) <TAB>  return items ",if item :,if item is not None:,False,47.678510005077065,97.61989713904586
2942,"def create_volume ( self , volume ) : <TAB>  """"""Create a volume."""""" <TAB>  try : <TAB><TAB>  cmd = [ "" volume "" , "" create "" , volume [ "" name "" ] , "" %s G "" % ( volume [ "" size "" ] ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cmd . append ( "" pool "" ) <TAB><TAB><TAB>  cmd . append ( self . configuration . eqlx_pool ) <TAB><TAB>  if self . configuration . san_thin_provision : <TAB><TAB><TAB>  cmd . append ( "" thin-provision "" ) <TAB><TAB>  out = self . _eql_execute ( * cmd ) <TAB><TAB>  self . add_multihost_access ( volume ) <TAB><TAB>  return self . _get_volume_data ( out ) <TAB>  except Exception : <TAB><TAB>  with excutils . save_and_reraise_exception ( ) : <TAB><TAB><TAB>  LOG . error ( ' Failed to create volume  "" %s "" . ' , volume [ "" name "" ] ) ","if self . configuration . eqlx_pool != ""default"" :",if self.configuration.eqlx_pool:,False,24.39844127551844,95.63811365126709
2943,"def clean ( self ) : <TAB>  # TODO: check for clashes if the random code is already taken <TAB>  if not self . code : <TAB><TAB>  self . code = u "" static- %s "" % uuid . uuid4 ( ) <TAB>  if not self . site : <TAB><TAB>  placeholders = StaticPlaceholder . objects . filter ( <TAB><TAB><TAB>  code = self . code , site__isnull = True <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  placeholders = placeholders . exclude ( pk = self . pk ) <TAB><TAB>  if placeholders . exists ( ) : <TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB>  _ ( "" A static placeholder with the same site and code already exists "" ) <TAB><TAB><TAB>  ) ",if self . pk :,if self.pk:,False,40.73239056814833,100.00000000000004
2944,"def spawnMenu ( self , event ) : <TAB>  clickedPos = self . getRowByAbs ( event . Position ) <TAB>  self . ensureSelection ( clickedPos ) <TAB>  selection = self . getSelectedBoosters ( ) <TAB>  mainBooster = None <TAB>  if clickedPos != - 1 : <TAB><TAB>  try : <TAB><TAB><TAB>  booster = self . boosters [ clickedPos ] <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  mainBooster = booster <TAB>  itemContext = None if mainBooster is None else _t ( "" Booster "" ) <TAB>  menu = ContextMenu . getMenu ( <TAB><TAB>  self , <TAB><TAB>  mainBooster , <TAB><TAB>  selection , <TAB><TAB>  ( "" boosterItem "" , itemContext ) , <TAB><TAB>  ( "" boosterItemMisc "" , itemContext ) , <TAB>  ) <TAB>  if menu : <TAB><TAB>  self . PopupMenu ( menu ) ",if booster in self . original :,if booster is not None:,False,29.372490753986586,96.62232839425369
2945,"def init_errorhandler ( ) : <TAB>  # http error handling <TAB>  for ex in default_exceptions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  app . register_error_handler ( ex , error_http ) <TAB><TAB>  elif ex == 500 : <TAB><TAB><TAB>  app . register_error_handler ( ex , internal_error ) <TAB>  if services . ldap : <TAB><TAB>  # Only way of catching the LDAPException upon logging in with LDAP server down <TAB><TAB>  @app . errorhandler ( services . ldap . LDAPException ) <TAB><TAB>  def handle_exception ( e ) : <TAB><TAB><TAB>  log . debug ( "" LDAP server not accessible while trying to login to opds feed "" ) <TAB><TAB><TAB>  return error_http ( FailedDependency ( ) ) ",if ex < 500 :,if ex == 500:,False,42.46465358750465,98.2138267419796
2946,"def reloadCols ( self ) : <TAB>  self . columns = [ ] <TAB>  for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  t = anytype <TAB><TAB>  elif "" M "" in fmt : <TAB><TAB><TAB>  self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  elif "" i "" in fmt : <TAB><TAB><TAB>  t = int <TAB><TAB>  elif "" f "" in fmt : <TAB><TAB><TAB>  t = float <TAB><TAB>  else : <TAB><TAB><TAB>  t = anytype <TAB><TAB>  self . addColumn ( ColumnItem ( name , i , type = t ) ) ",if shape :,"if ""D"" in fmt:",False,34.86421988028525,97.03463560796088
2947,"def Proc2 ( IntParIO ) : <TAB>  IntLoc = IntParIO + 10 <TAB>  while True : <TAB><TAB>  if Char1Glob == "" A "" : <TAB><TAB><TAB>  IntLoc = IntLoc - 1 <TAB><TAB><TAB>  IntParIO = IntLoc - IntGlob <TAB><TAB><TAB>  EnumLoc = Ident1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return IntParIO ",if EnumLoc == Ident1 :,if EnumLoc == 'B':,False,28.14439801516839,97.46768017625028
2948,"def opengroup ( self , name = None ) : <TAB>  gid = self . groups <TAB>  self . groupwidths . append ( None ) <TAB>  if self . groups > MAXGROUPS : <TAB><TAB>  raise error ( "" too many groups "" ) <TAB>  if name is not None : <TAB><TAB>  ogid = self . groupdict . get ( name , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise error ( <TAB><TAB><TAB><TAB>  "" redefinition of group name  %r  as group  %d ;  "" <TAB><TAB><TAB><TAB>  "" was group  %d "" % ( name , gid , ogid ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . groupdict [ name ] = gid <TAB>  return gid ",if ogid is not None :,if ogid is not None:,False,57.04967199053708,100.00000000000004
2949,"def __setattr__ ( self , name : str , val : Any ) : <TAB>  if name . startswith ( "" COMPUTED_ "" ) : <TAB><TAB>  if name in self : <TAB><TAB><TAB>  old_val = self [ name ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  raise KeyError ( <TAB><TAB><TAB><TAB>  "" Computed attributed  ' {} '  already exists  "" <TAB><TAB><TAB><TAB>  "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB><TAB><TAB>  ) <TAB><TAB>  self [ name ] = val <TAB>  else : <TAB><TAB>  super ( ) . __setattr__ ( name , val ) ",if old_val == val :,if old_val != val:,False,51.73158124832179,98.80232434995159
2950,"def get_all_function_symbols ( self , module = "" kernel "" ) : <TAB>  """"""Gets all the function tuples for the given module"""""" <TAB>  ret = [ ] <TAB>  symtable = self . type_map <TAB>  if module in symtable : <TAB><TAB>  mod = symtable [ module ] <TAB><TAB>  for ( addr , ( name , _sym_types ) ) in mod . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  addr = addr + self . shift_address <TAB><TAB><TAB>  ret . append ( [ name , addr ] ) <TAB>  else : <TAB><TAB>  debug . info ( "" All symbols requested for non-existent module  %s "" % module ) <TAB>  return ret ",if self . shift_address and addr :,if addr.startswith(self.shift_address):,False,32.87813962559854,95.93522786095379
2951,"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB>  code = frame . f_code <TAB>  if ( <TAB><TAB>  event not in SUPPORTED_EVENTS <TAB><TAB>  or code . co_name == "" trace_types "" <TAB><TAB>  or self . should_trace <TAB><TAB>  and not self . should_trace ( code ) <TAB>  ) : <TAB><TAB>  return self <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . handle_call ( frame ) <TAB><TAB>  elif event == EVENT_RETURN : <TAB><TAB><TAB>  self . handle_return ( frame , arg ) <TAB><TAB>  else : <TAB><TAB><TAB>  logger . error ( "" Cannot handle event  %s "" , event ) <TAB>  except Exception : <TAB><TAB>  logger . exception ( "" Failed collecting trace "" ) <TAB>  return self ",if event == EVENT_CALL :,if event == EVENT_CALL:,False,49.89797235490827,100.00000000000004
2952,"def test_update_topic ( self ) : <TAB>  async with self . chat_client : <TAB><TAB>  await self . _create_thread ( ) <TAB><TAB>  topic = "" update topic "" <TAB><TAB>  async with self . chat_thread_client : <TAB><TAB><TAB>  await self . chat_thread_client . update_topic ( topic = topic ) <TAB><TAB>  # delete chat threads <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await self . chat_client . delete_chat_thread ( self . thread_id ) ",if not self . is_playback ( ) :,if self.thread_id:,False,51.08422925697509,94.0082344135362
2953,"def render_observation ( self ) : <TAB>  x = self . read_head_position <TAB>  label = "" Observation Grid<TAB>:  "" <TAB>  x_str = "" "" <TAB>  for j in range ( - 1 , self . rows + 1 ) : <TAB><TAB>  if j != - 1 : <TAB><TAB><TAB>  x_str + = "" "" * len ( label ) <TAB><TAB>  for i in range ( - 2 , self . input_width + 2 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  x_str + = self . _get_str_obs ( ( i , j ) ) <TAB><TAB>  x_str + = "" \n "" <TAB>  x_str = label + x_str <TAB>  return x_str ",if i == x [ 0 ] and j == x [ 1 ] :,if i == -1:,False,26.130701117579,92.59693927277071
2954,"def build ( opt ) : <TAB>  dpath = os . path . join ( opt [ "" datapath "" ] , "" QA-ZRE "" ) <TAB>  version = None <TAB>  if not build_data . built ( dpath , version_string = version ) : <TAB><TAB>  print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # An older version exists, so remove these outdated files. <TAB><TAB><TAB>  build_data . remove_dir ( dpath ) <TAB><TAB>  build_data . make_dir ( dpath ) <TAB><TAB>  # Download the data. <TAB><TAB>  for downloadable_file in RESOURCES : <TAB><TAB><TAB>  downloadable_file . download_file ( dpath ) <TAB><TAB>  # Mark the data as built. <TAB><TAB>  build_data . mark_done ( dpath , version_string = version ) ",if build_data . built ( dpath ) :,if version is None:,False,57.89734801034052,95.73571347008684
2955,"def git_pull ( args ) : <TAB>  if len ( args ) < = 1 : <TAB><TAB>  repo = _get_repo ( ) <TAB><TAB>  _confirm_dangerous ( ) <TAB><TAB>  url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  origin = url <TAB><TAB><TAB>  url = repo . remotes . get ( origin ) <TAB><TAB>  if url : <TAB><TAB><TAB>  repo . pull ( origin_uri = url ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" No pull URL. "" ) <TAB>  else : <TAB><TAB>  print ( command_help [ "" git pull "" ] ) ",if url in repo . remotes :,if url:,False,21.869895972006592,97.23330697523008
2956,"def FindAndDelete ( script , sig ) : <TAB>  """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB>  r = b "" "" <TAB>  last_sop_idx = sop_idx = 0 <TAB>  skip = True <TAB>  for ( opcode , data , sop_idx ) in script . raw_iter ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r + = script [ last_sop_idx : sop_idx ] <TAB><TAB>  last_sop_idx = sop_idx <TAB><TAB>  if script [ sop_idx : sop_idx + len ( sig ) ] == sig : <TAB><TAB><TAB>  skip = True <TAB><TAB>  else : <TAB><TAB><TAB>  skip = False <TAB>  <IF-STMT>: <TAB><TAB>  r + = script [ last_sop_idx : ] <TAB>  return CScript ( r ) ",if not skip :,if skip:,False,26.990186700490902,96.7426174049836
2957,"def get_ip_info ( ipaddress ) : <TAB>  """"""Returns device information by IP address"""""" <TAB>  result = { } <TAB>  try : <TAB><TAB>  ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB>  except IPAddress . DoesNotExist : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  if ip . venture is not None : <TAB><TAB><TAB>  result [ "" venture_id "" ] = ip . venture . id <TAB><TAB>  if ip . device is not None : <TAB><TAB><TAB>  result [ "" device_id "" ] = ip . device . id <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ "" venture_id "" ] = ip . device . venture . id <TAB>  return result ",if ip . device . venture is not None :,if ip.device is not None:,False,43.868669218044985,98.29464983963511
2958,"def restore ( self , state ) : <TAB>  """"""Restore the state of a mesh previously saved using save()"""""" <TAB>  import pickle <TAB>  state = pickle . loads ( state ) <TAB>  for k in state : <TAB><TAB>  if isinstance ( state [ k ] , list ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  state [ k ] = [ [ v . x ( ) , v . y ( ) , v . z ( ) ] for v in state [ k ] ] <TAB><TAB><TAB>  state [ k ] = np . array ( state [ k ] ) <TAB><TAB>  setattr ( self , k , state [ k ] ) ","if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) :","if isinstance(state[k], (list, tuple)):",False,56.288182750547946,95.51118859767685
2959,"def get_extra_lines ( tup ) : <TAB>  ext_name , pyopencl_ver = tup <TAB>  if ext_name is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # capital letters -> CL version, not extension <TAB><TAB><TAB>  yield "" "" <TAB><TAB><TAB>  yield ""<TAB> Available with OpenCL  %s . "" % ( ext_name [ 3 : ] ) <TAB><TAB><TAB>  yield "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  yield "" "" <TAB><TAB><TAB>  yield ""<TAB> Available with the `` %s `` extension. "" % ext_name <TAB><TAB><TAB>  yield "" "" <TAB>  if pyopencl_ver is not None : <TAB><TAB>  yield "" "" <TAB><TAB>  yield ""<TAB> .. versionadded::  %s "" % pyopencl_ver <TAB><TAB>  yield "" "" ","if ext_name . startswith ( ""CL_"" ) :",if ext_name.startswith('_'):,False,57.29561805357939,97.79554529762439
2960,"def _gen_remote_uri ( <TAB>  fileobj : IO [ bytes ] , <TAB>  remote_uri : Optional [ ParseResult ] , <TAB>  remote_path_prefix : Optional [ str ] , <TAB>  remote_path_suffix : Optional [ str ] , <TAB>  sha256sum : Optional [ str ] ,  ) - > ParseResult : <TAB>  if remote_uri is None : <TAB><TAB>  assert remote_path_prefix is not None and remote_path_suffix is not None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sha256sum = _hash_fileobj ( fileobj ) <TAB><TAB>  return urlparse ( <TAB><TAB><TAB>  os . path . join ( remote_path_prefix , f "" { sha256sum } { remote_path_suffix } "" ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return remote_uri ",if sha256sum is None :,if sha256sum is None:,False,52.22538583258833,100.00000000000004
2961,"def queries ( self ) : <TAB>  if DEV : <TAB><TAB>  cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB><TAB>  if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  log_cmd = ShellCommand ( <TAB><TAB><TAB><TAB><TAB>  "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB><TAB><TAB><TAB><TAB>  print ( cmd . stdout ) <TAB><TAB><TAB><TAB>  pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB>  return ( ) ",if not cmd . stdout . strip ( ) :,if self.path.k8s:,False,24.51156149258728,96.38652539172925
2962,"def get_range ( self ) : <TAB>  present = self . xml . find ( "" { %s }range "" % self . namespace ) <TAB>  if present is not None : <TAB><TAB>  attributes = present . attrib <TAB><TAB>  return_value = dict ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return_value [ "" minimum "" ] = attributes [ "" min "" ] <TAB><TAB>  if "" max "" in attributes : <TAB><TAB><TAB>  return_value [ "" maximum "" ] = attributes [ "" max "" ] <TAB><TAB>  return return_value <TAB>  return False ","if ""min"" in attributes :","if ""min"" in attributes:",False,27.32431355774722,100.00000000000004
2963,"def _configuredOn ( self , workerid , builderid = None , masterid = None ) : <TAB>  cfg = [ ] <TAB>  for cs in itervalues ( self . configured ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  bid , mid = self . db . builders . builder_masters [ cs [ "" buildermasterid "" ] ] <TAB><TAB>  if builderid is not None and bid != builderid : <TAB><TAB><TAB>  continue <TAB><TAB>  if masterid is not None and mid != masterid : <TAB><TAB><TAB>  continue <TAB><TAB>  cfg . append ( { "" builderid "" : bid , "" masterid "" : mid } ) <TAB>  return cfg ","if cs [ ""workerid"" ] != workerid :",if cs['buildermasterid'] == workerid:,False,62.65905108157958,96.37053137305702
2964,"def __exit__ ( self , type , value , traceback ) : <TAB>  try : <TAB><TAB>  if type is not None : <TAB><TAB><TAB>  return self . exception_handler ( type , value , traceback ) <TAB>  finally : <TAB><TAB>  final_contexts = _state . contexts <TAB><TAB>  _state . contexts = self . old_contexts <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise StackContextInconsistentError ( <TAB><TAB><TAB><TAB>  "" stack_context inconsistency (may be caused by yield  "" <TAB><TAB><TAB><TAB>  ' within a  "" with StackContext ""  block) ' <TAB><TAB><TAB>  ) <TAB><TAB>  # Break up a reference to itself to allow for faster GC on CPython. <TAB><TAB>  self . new_contexts = None ",if final_contexts is not self . new_contexts :,if final_contexts is None:,False,62.336088717480095,95.16397164640557
2965,"def del_ ( self , key ) : <TAB>  initial_hash = hash_ = self . hash ( key ) <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # That key was never assigned <TAB><TAB><TAB>  return None <TAB><TAB>  elif self . _keys [ hash_ ] == key : <TAB><TAB><TAB>  # key found, assign with deleted sentinel <TAB><TAB><TAB>  self . _keys [ hash_ ] = self . _deleted <TAB><TAB><TAB>  self . _values [ hash_ ] = self . _deleted <TAB><TAB><TAB>  self . _len - = 1 <TAB><TAB><TAB>  return <TAB><TAB>  hash_ = self . _rehash ( hash_ ) <TAB><TAB>  if initial_hash == hash_ : <TAB><TAB><TAB>  # table is full and wrapped around <TAB><TAB><TAB>  return None ",if self . _keys [ hash_ ] is self . _empty :,if hash_ not in self._keys:,False,52.64918109343695,95.31894184566677
2966,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_logout_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 0:,False,46.452429171598006,97.78225290627776
2967,"def data_generator ( ) : <TAB>  i = 0 <TAB>  max_batch_index = len ( X_train ) / / batch_size <TAB>  tot = 0 <TAB>  while 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB>  np . ones ( [ batch_size , input_dim ] ) * np . nan , <TAB><TAB><TAB><TAB>  np . ones ( [ batch_size , num_classes ] ) * np . nan , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB>  X_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB><TAB><TAB><TAB>  y_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB><TAB><TAB>  ) <TAB><TAB>  i + = 1 <TAB><TAB>  tot + = 1 <TAB><TAB>  i = i % max_batch_index ",if tot > 3 * len ( X_train ) :,if i == max_batch_index - 1:,False,17.02572710975722,95.89781464997561
2968,"def title ( self ) : <TAB>  ret = theme [ "" title "" ] <TAB>  if isinstance ( self . name , six . string_types ) : <TAB><TAB>  width = self . statwidth ( ) <TAB><TAB>  return ( <TAB><TAB><TAB>  ret + self . name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) + theme [ "" default "" ] <TAB><TAB>  ) <TAB>  for i , name in enumerate ( self . name ) : <TAB><TAB>  width = self . colwidth ( ) <TAB><TAB>  ret = ret + name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if op . color : <TAB><TAB><TAB><TAB>  ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret = ret + char [ "" space "" ] <TAB>  return ret ",if i + 1 != len ( self . vars ) :,if i == len(self.name):,False,35.276821428658764,97.37733994897904
2969,"def get_container_from_dport ( dport , docker_client ) : <TAB>  for container in docker_client . containers ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  ports = container [ "" Ports "" ] <TAB><TAB><TAB>  for port in ports : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if port [ "" PublicPort "" ] == int ( dport ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return container <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  print ( ports ) <TAB><TAB><TAB>  pass ","if ""PublicPort"" in port :",if port['Name'] == dport:,False,49.2682424750101,95.12260879539046
2970,"def _get_parents_data ( self , data ) : <TAB>  parents = 0 <TAB>  if data [ COLUMN_PARENT ] : <TAB><TAB>  family = self . db . get_family_from_handle ( data [ COLUMN_PARENT ] [ 0 ] ) <TAB><TAB>  if family . get_father_handle ( ) : <TAB><TAB><TAB>  parents + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parents + = 1 <TAB>  return parents ",if family . get_mother_handle ( ) :,if family.get_father_handle():,False,17.631347400954304,97.96299003437207
2971,"def wrapper ( filename ) : <TAB>  mtime = getmtime ( filename ) <TAB>  with lock : <TAB><TAB>  if filename in cache : <TAB><TAB><TAB>  old_mtime , result = cache . pop ( filename ) <TAB><TAB><TAB>  if old_mtime == mtime : <TAB><TAB><TAB><TAB>  # Move to the end <TAB><TAB><TAB><TAB>  cache [ filename ] = old_mtime , result <TAB><TAB><TAB><TAB>  return result <TAB>  result = function ( filename ) <TAB>  with lock : <TAB><TAB>  cache [ filename ] = mtime , result<TAB># at the end <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cache . popitem ( last = False ) <TAB>  return result ",if len ( cache ) > max_size :,if last:,False,51.86952028437239,94.39258071792398
2972,"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB>  try : <TAB><TAB>  pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB>  if op . stage == OperandStage . map : <TAB><TAB><TAB>  cls . _execute_map ( ctx , op ) <TAB><TAB>  elif op . stage == OperandStage . combine : <TAB><TAB><TAB>  cls . _execute_combine ( ctx , op ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . _execute_agg ( ctx , op ) <TAB><TAB>  else :<TAB># pragma: no cover <TAB><TAB><TAB>  raise ValueError ( "" Aggregation operand not executable "" ) <TAB>  finally : <TAB><TAB>  pd . reset_option ( "" mode.use_inf_as_na "" ) ",elif op . stage == OperandStage . agg :,if op.stage == OperandStage.aggregate:,False,25.58719143484983,95.72972547397247
2973,"def FindAndDelete ( script , sig ) : <TAB>  """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB>  r = b "" "" <TAB>  last_sop_idx = sop_idx = 0 <TAB>  skip = True <TAB>  for ( opcode , data , sop_idx ) in script . raw_iter ( ) : <TAB><TAB>  if not skip : <TAB><TAB><TAB>  r + = script [ last_sop_idx : sop_idx ] <TAB><TAB>  last_sop_idx = sop_idx <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  skip = True <TAB><TAB>  else : <TAB><TAB><TAB>  skip = False <TAB>  if not skip : <TAB><TAB>  r + = script [ last_sop_idx : ] <TAB>  return CScript ( r ) ",if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,if opcode == 'delete':,False,26.74577084298547,91.12626775903911
2974,"def extractall ( zip : typing . Any , path : str ) - > NoneType : <TAB>  for name in zip . namelist ( ) : <TAB><TAB>  member = zip . getinfo ( name ) <TAB><TAB>  extracted_path = zip . _extract_member ( member , path , None ) <TAB><TAB>  attr = member . external_attr >> 16 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . chmod ( extracted_path , attr ) ",if attr != 0 :,if os.path.exists(extracted_path):,False,20.949812101321974,90.19677196381322
2975,"def find_all_gyptest_files ( directory ) : <TAB>  result = [ ] <TAB>  for root , dirs , files in os . walk ( directory ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dirs . remove ( "" .svn "" ) <TAB><TAB>  result . extend ( [ os . path . join ( root , f ) for f in files if is_test_name ( f ) ] ) <TAB>  result . sort ( ) <TAB>  return result ","if "".svn"" in dirs :",if os.path.exists(root):,False,55.16539837831448,92.10563359703337
2976,"def load ( cls , storefile , template_store ) : <TAB>  # Did we get file or filename? <TAB>  if not hasattr ( storefile , "" read "" ) : <TAB><TAB>  storefile = open ( storefile , "" rb "" ) <TAB>  # Adjust store to have translations <TAB>  store = cls . convertfile ( storefile , template_store ) <TAB>  for unit in store . units : <TAB><TAB>  if unit . isheader ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  # HTML does this properly on loading, others need it <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  unit . target = unit . source <TAB><TAB><TAB>  unit . rich_target = unit . rich_source <TAB>  return store ",if cls . needs_target_sync :,if unit.isimage():,False,36.680284721940914,95.4487199191104
2977,"def postOptions ( self ) : <TAB>  _BasicOptions . postOptions ( self ) <TAB>  if self [ "" jobs "" ] : <TAB><TAB>  conflicts = [ "" debug "" , "" profile "" , "" debug-stacktraces "" , "" exitfirst "" ] <TAB><TAB>  for option in conflicts : <TAB><TAB><TAB>  if self [ option ] : <TAB><TAB><TAB><TAB>  raise usage . UsageError ( <TAB><TAB><TAB><TAB><TAB>  "" You can ' t specify -- %s  when using --jobs "" % option <TAB><TAB><TAB><TAB>  ) <TAB>  if self [ "" nopm "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise usage . UsageError ( "" You must specify --debug when using  "" "" --nopm  "" ) <TAB><TAB>  failure . DO_POST_MORTEM = False ","if not self [ ""debug"" ] :",if self['debug']:,False,54.311064923356476,95.39111705124678
2978,"def filterTokenLocation ( ) : <TAB>  i = None <TAB>  entry = None <TAB>  token = None <TAB>  tokens = [ ] <TAB>  i = 0 <TAB>  while 1 : <TAB><TAB>  if not ( i < len ( extra . tokens ) ) : <TAB><TAB><TAB>  break <TAB><TAB>  entry = extra . tokens [ i ] <TAB><TAB>  token = jsdict ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" type "" : entry . type , <TAB><TAB><TAB><TAB>  "" value "" : entry . value , <TAB><TAB><TAB>  } <TAB><TAB>  ) <TAB><TAB>  if extra . range : <TAB><TAB><TAB>  token . range = entry . range <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  token . loc = entry . loc <TAB><TAB>  tokens . append ( token ) <TAB><TAB>  i + = 1 <TAB>  extra . tokens = tokens ",if extra . loc :,if entry.loc:,False,24.45968556531377,98.97431450598246
2979,"def on_rebalance_end ( self ) - > None : <TAB>  """"""Call when rebalancing is done."""""" <TAB>  self . rebalancing = False <TAB>  if self . _rebalancing_span : <TAB><TAB>  self . _rebalancing_span . finish ( ) <TAB>  self . _rebalancing_span = None <TAB>  sensor_state = self . _rebalancing_sensor_state <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log . warning ( <TAB><TAB><TAB><TAB>  "" Missing sensor state for rebalance # %s "" , self . rebalancing_count <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . sensors . on_rebalance_end ( self , sensor_state ) <TAB>  finally : <TAB><TAB>  self . _rebalancing_sensor_state = None ",if not sensor_state :,if sensor_state is None:,False,25.851171236650273,97.63565139290336
2980,"def decorator ( request , * args , * * kwargs ) : <TAB>  if CALENDAR_VIEW_PERM : <TAB><TAB>  user = request . user <TAB><TAB>  if not user : <TAB><TAB><TAB>  return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB><TAB>  occurrence , event , calendar = get_objects ( request , * * kwargs ) <TAB><TAB>  if calendar : <TAB><TAB><TAB>  allowed = CHECK_CALENDAR_PERM_FUNC ( calendar , user ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB><TAB><TAB>  # all checks passed <TAB><TAB><TAB>  return function ( request , * args , * * kwargs ) <TAB><TAB>  return HttpResponseNotFound ( "" <h1>Page not found</h1> "" ) <TAB>  return function ( request , * args , * * kwargs ) ",if not allowed :,if allowed:,False,46.6232610675009,98.85914569522285
2981,"def reduce_arguments ( self , args ) : <TAB>  assert isinstance ( args , nodes . Arguments ) <TAB>  if args . incorrect_order ( ) : <TAB><TAB>  raise InvalidArguments ( <TAB><TAB><TAB>  "" All keyword arguments must be after positional arguments. "" <TAB><TAB>  ) <TAB>  reduced_pos = [ self . reduce_single ( arg ) for arg in args . arguments ] <TAB>  reduced_kw = { } <TAB>  for key in args . kwargs . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise InvalidArguments ( "" Keyword argument name is not a string. "" ) <TAB><TAB>  a = args . kwargs [ key ] <TAB><TAB>  reduced_kw [ key ] = self . reduce_single ( a ) <TAB>  return ( reduced_pos , reduced_kw ) ","if not isinstance ( key , str ) :","if not isinstance(key, str):",False,59.22834384886655,100.00000000000004
2982,"def _encode ( n , nbytes , little_endian = False ) : <TAB>  retval = [ ] <TAB>  n = long ( n ) <TAB>  for i in range ( nbytes ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  retval . append ( chr ( n & 0xFF ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  retval . insert ( 0 , chr ( n & 0xFF ) ) <TAB><TAB>  n >> = 8 <TAB>  return "" "" . join ( retval ) ",if little_endian :,if little_endian:,False,47.758683562681526,100.00000000000004
2983,"def copy_shell ( self ) : <TAB>  cls = self . __class__ <TAB>  old_id = cls . id <TAB>  new_i = cls ( )<TAB># create a new group <TAB>  new_i . id = self . id<TAB># with the same id <TAB>  cls . id = old_id<TAB># Reset the Class counter <TAB>  # Copy all properties <TAB>  for prop in cls . properties : <TAB><TAB>  if prop is not "" members "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  val = getattr ( self , prop ) <TAB><TAB><TAB><TAB>  setattr ( new_i , prop , val ) <TAB>  # but no members <TAB>  new_i . members = [ ] <TAB>  return new_i ",if self . has ( prop ) :,if prop not in self.members:,False,17.635181898815574,89.91339838387921
2984,"def dataspec ( config ) : <TAB>  master = yield fakemaster . make_master ( ) <TAB>  data = connector . DataConnector ( ) <TAB>  data . setServiceParent ( master ) <TAB>  if config [ "" out "" ] != "" -- "" : <TAB><TAB>  dirs = os . path . dirname ( config [ "" out "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( dirs ) <TAB><TAB>  f = open ( config [ "" out "" ] , "" w "" ) <TAB>  else : <TAB><TAB>  f = sys . stdout <TAB>  if config [ "" global "" ] is not None : <TAB><TAB>  f . write ( "" window. "" + config [ "" global "" ] + "" = "" ) <TAB>  f . write ( json . dumps ( data . allEndpoints ( ) , indent = 2 ) ) <TAB>  f . close ( ) <TAB>  defer . returnValue ( 0 ) ",if dirs and not os . path . exists ( dirs ) :,if not os.path.exists(dirs):,False,39.403606247392304,98.43216344278808
2985,"def _parseSCDOCDC ( self , src ) : <TAB>  """"""[S|CDO|CDC]*"""""" <TAB>  while 1 : <TAB><TAB>  src = src . lstrip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  src = src [ 4 : ] <TAB><TAB>  elif src . startswith ( "" --> "" ) : <TAB><TAB><TAB>  src = src [ 3 : ] <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  return src ","if src . startswith ( ""<!--"" ) :",if src.startswith('--'):,False,50.742796122295154,95.10906360834751
2986,"def command ( filenames , dirnames , fix ) : <TAB>  for filename in gather_files ( dirnames , filenames ) : <TAB><TAB>  visitor = process_file ( filename ) <TAB><TAB>  if visitor . needs_fix ( ) : <TAB><TAB><TAB>  print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  print ( "" Fixing:  %s "" % filename ) <TAB><TAB><TAB><TAB>  fix_file ( filename ) ",if fix :,if fix:,False,50.975064502621116,100.00000000000004
2987,"def shutdown ( self ) : <TAB>  """"""Shutdown host system."""""" <TAB>  self . _check_dbus ( MANAGER ) <TAB>  use_logind = self . sys_dbus . logind . is_connected <TAB>  _LOGGER . info ( "" Initialize host power off  %s "" , "" logind "" if use_logind else "" systemd "" ) <TAB>  try : <TAB><TAB>  await self . sys_core . shutdown ( ) <TAB>  finally : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await self . sys_dbus . logind . power_off ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  await self . sys_dbus . systemd . power_off ( ) ",if use_logind :,if use_logind:,False,53.011880757167084,100.00000000000004
2988,"def _run_split_on_punc ( self , text , never_split = None ) : <TAB>  """"""Splits punctuation on a piece of text."""""" <TAB>  if never_split is not None and text in never_split : <TAB><TAB>  return [ text ] <TAB>  chars = list ( text ) <TAB>  i = 0 <TAB>  start_new_word = True <TAB>  output = [ ] <TAB>  while i < len ( chars ) : <TAB><TAB>  char = chars [ i ] <TAB><TAB>  if _is_punctuation ( char ) : <TAB><TAB><TAB>  output . append ( [ char ] ) <TAB><TAB><TAB>  start_new_word = True <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  output . append ( [ ] ) <TAB><TAB><TAB>  start_new_word = False <TAB><TAB><TAB>  output [ - 1 ] . append ( char ) <TAB><TAB>  i + = 1 <TAB>  return [ "" "" . join ( x ) for x in output ] ",if start_new_word :,if start_new_word:,False,56.04707584711319,98.70826651319352
2989,"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB>  try : <TAB><TAB>  if tp == "" write "" : <TAB><TAB><TAB>  out . write ( msg ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out . flush ( ) <TAB><TAB>  elif tp == "" write_flush "" : <TAB><TAB><TAB>  out . write ( msg ) <TAB><TAB><TAB>  out . flush ( ) <TAB><TAB>  elif tp == "" print "" : <TAB><TAB><TAB>  print ( msg , file = out ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" Unsupported type:  "" + tp ) <TAB>  except IOError as e : <TAB><TAB>  logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB><TAB>  pass ","elif tp == ""flush"" :","if tp == ""write_flush':",False,43.31238699347392,97.09255601382608
2990,"def checkClassDeclation ( file ) : <TAB>  localResult = [ ] <TAB>  with open ( file , "" rb "" ) as f : <TAB><TAB>  lineNumber = 0 <TAB><TAB>  for line in f : <TAB><TAB><TAB>  m = re . search ( "" class \ s+[^ \ (]*: "" , line ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  localResult . append ( <TAB><TAB><TAB><TAB><TAB>  "" Old class definition found on  {0} "" . format ( m . group ( ) ) <TAB><TAB><TAB><TAB>  ) <TAB>  return localResult ",if m :,if m:,False,54.91965718758931,100.00000000000004
2991,"def _evaluate_local_single ( self , iterator ) : <TAB>  for batch in iterator : <TAB><TAB>  in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB><TAB>  with function . no_backprop_mode ( ) : <TAB><TAB><TAB>  if isinstance ( in_arrays , tuple ) : <TAB><TAB><TAB><TAB>  results = self . calc_local ( * in_arrays ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  results = self . calc_local ( * * in_arrays ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results = self . calc_local ( in_arrays ) <TAB><TAB>  if self . _progress_hook : <TAB><TAB><TAB>  self . _progress_hook ( batch ) <TAB><TAB>  yield results ","elif isinstance ( in_arrays , dict ) :","if isinstance(results, tuple):",False,27.110195027322604,96.25529557028494
2992,"def check_billing_view ( user , permission , obj ) : <TAB>  if hasattr ( obj , "" all_projects "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  # This is a billing object <TAB><TAB>  return any ( check_permission ( user , permission , prj ) for prj in obj . all_projects ) <TAB>  return check_permission ( user , permission , obj ) ",if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,if not obj.all_projects:,False,30.20674349338548,80.92568752942032
2993,"def ensure_output_spaces_contain_the_same_data ( self , y , y_ensured ) : <TAB>  stride = y . shape [ 1 ] <TAB>  self . assertEqual ( y . shape [ 0 ] * y . shape [ 1 ] , y_ensured . shape [ 0 ] ) <TAB>  self . assertEqual ( len ( y_ensured . shape ) , 1 ) <TAB>  for row in range ( y . shape [ 0 ] ) : <TAB><TAB>  for column in range ( y . shape [ 1 ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( y [ row , column ] , y_ensured [ row * stride + column ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . assertEqual ( y [ row ] [ column ] , y_ensured [ row * stride + column ] ) ",if sp . issparse ( y ) :,if column == 0:,False,50.51032593819802,96.48492121878705
2994,"def train ( <TAB>  self , <TAB>  training_data : TrainingData , <TAB>  config : Optional [ RasaNLUModelConfig ] = None , <TAB>  * * kwargs : Any ,  ) - > None : <TAB>  """"""Tokenize all training data."""""" <TAB>  for example in training_data . training_examples : <TAB><TAB>  for attribute in MESSAGE_ATTRIBUTES : <TAB><TAB><TAB>  if example . get ( attribute ) is not None and not example . get ( attribute ) == "" "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  tokens = self . _split_name ( example , attribute ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  tokens = self . tokenize ( example , attribute ) <TAB><TAB><TAB><TAB>  example . set ( TOKENS_NAMES [ attribute ] , tokens ) ","if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] :",if attribute in TOKENS_NAMES:,False,49.705532232359005,93.88161307601479
2995,"def refresh_token ( self , strategy , * args , * * kwargs ) : <TAB>  token = self . extra_data . get ( "" refresh_token "" ) or self . extra_data . get ( "" access_token "" ) <TAB>  backend = self . get_backend ( strategy ) <TAB>  if token and backend and hasattr ( backend , "" refresh_token "" ) : <TAB><TAB>  backend = backend ( strategy = strategy ) <TAB><TAB>  response = backend . refresh_token ( token , * args , * * kwargs ) <TAB><TAB>  extra_data = backend . extra_data ( self , self . uid , response , self . extra_data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . save ( ) ",if self . set_extra_data ( extra_data ) :,if self.user:,False,22.361845881584568,93.61239749362834
2996,"def _verify_environ ( _collected_environ ) : <TAB>  try : <TAB><TAB>  yield <TAB>  finally : <TAB><TAB>  new_environ = dict ( os . environ ) <TAB><TAB>  current_test = new_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB><TAB>  old_environ = dict ( _collected_environ ) <TAB><TAB>  old_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise DirtyTest ( <TAB><TAB><TAB><TAB>  "" Left over environment variables "" , <TAB><TAB><TAB><TAB>  current_test , <TAB><TAB><TAB><TAB>  _compare_eq_dict ( new_environ , old_environ , verbose = 2 ) , <TAB><TAB><TAB>  ) ",if new_environ != old_environ :,if current_test is old_test:,False,49.89295893933255,96.00908171813252
2997,"def clean_len ( self , line ) : <TAB>  """"""Calculate wisible length of string"""""" <TAB>  if isinstance ( line , basestring ) : <TAB><TAB>  return len ( self . screen . markup . clean_markup ( line ) ) <TAB>  elif isinstance ( line , tuple ) or isinstance ( line , list ) : <TAB><TAB>  markups = self . screen . markup . get_markup_vars ( ) <TAB><TAB>  length = 0 <TAB><TAB>  for i in line : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  length + = len ( i ) <TAB><TAB>  return length ",if i not in markups :,if i not in markups:,False,49.85800988711126,100.00000000000004
2998,"def _build_merged_dataset_args ( datasets ) : <TAB>  merged_dataset_args = [ ] <TAB>  for dataset in datasets : <TAB><TAB>  dataset_code_column = _parse_dataset_code ( dataset ) <TAB><TAB>  arg = dataset_code_column [ "" code "" ] <TAB><TAB>  column_index = dataset_code_column [ "" column_index "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  arg = ( dataset_code_column [ "" code "" ] , { "" column_index "" : [ column_index ] } ) <TAB><TAB>  merged_dataset_args . append ( arg ) <TAB>  return merged_dataset_args ",if column_index is not None :,if arg is None:,False,38.783143445937384,96.25857772885922
2999,"def update_watch_data_table_paths ( self ) : <TAB>  if hasattr ( self . tool_data_watcher , "" monitored_dirs "" ) : <TAB><TAB>  for tool_data_table_path in self . tool_data_paths : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . tool_data_watcher . watch_directory ( tool_data_table_path ) ",if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,if tool_data_table_path.startswith('.'):,False,23.495618527457076,88.19610043990544
3000,"def getsource ( obj ) : <TAB>  """"""Wrapper around inspect.getsource"""""" <TAB>  try : <TAB><TAB>  try : <TAB><TAB><TAB>  src = encoding . to_unicode ( inspect . getsource ( obj ) ) <TAB><TAB>  except TypeError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  src = encoding . to_unicode ( inspect . getsource ( obj . __class__ ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # Bindings like VTK or ITK require this case <TAB><TAB><TAB><TAB>  src = getdoc ( obj ) <TAB><TAB>  return src <TAB>  except ( TypeError , IOError ) : <TAB><TAB>  return ","if hasattr ( obj , ""__class__"" ) :","if hasattr(obj, '__class__'):",False,59.1729445405558,97.42894220755404
3001,"def __iter__ ( self ) : <TAB>  for model in self . app_config . get_models ( ) : <TAB><TAB>  admin_model = AdminModel ( model , * * self . options ) <TAB><TAB>  for model_re in self . model_res : <TAB><TAB><TAB>  if model_re . search ( admin_model . name ) : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield admin_model ",if self . model_res :,if not self.model_res:,False,44.005987832907145,98.296217975169
3002,"def run ( self ) : <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  with DelayedKeyboardInterrupt ( ) : <TAB><TAB><TAB><TAB>  raw_inputs = self . _parent_task_queue . get ( ) <TAB><TAB><TAB><TAB>  if self . _has_stop_signal ( raw_inputs ) : <TAB><TAB><TAB><TAB><TAB>  self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  if self . _flow_type == BATCH : <TAB><TAB><TAB><TAB><TAB>  self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB><TAB>  self . _rq . put ( raw_inputs , block = False ) <TAB><TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB>  except KeyboardInterrupt : <TAB><TAB><TAB>  continue ",elif self . _flow_type == REALTIME :,if self._flow_type == RQ:,False,50.953291512224766,98.40501745848246
3003,"def dump ( self ) : <TAB>  self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB>  for field in self . _fields_ : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB><TAB>  elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB><TAB><TAB>  self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB><TAB>  elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) : <TAB><TAB><TAB>  self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) ) ","if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) :","if isinstance(field, (int, long)):",False,24.91446277385159,95.40053690899518
3004,"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB>  """"""Validating that user has inputted a value set and that configuration has been initialized"""""" <TAB>  super ( ) . validate_configuration ( configuration ) <TAB>  try : <TAB><TAB>  assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB><TAB>  assert isinstance ( <TAB><TAB><TAB>  configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB><TAB>  ) , "" value_set must be a list or a set "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert ( <TAB><TAB><TAB><TAB>  "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB><TAB><TAB>  ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key ' <TAB>  except AssertionError as e : <TAB><TAB>  raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB>  return True ","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",if configuration.kwargs.get('value_set'):,False,37.0326460272549,92.52185997372715
3005,def test_one_dead_branch ( ) : <TAB>  with deterministic_PRNG ( ) : <TAB><TAB>  seen = set ( ) <TAB><TAB>  @run_to_buffer <TAB><TAB>  def x ( data ) : <TAB><TAB><TAB>  i = data . draw_bytes ( 1 ) [ 0 ] <TAB><TAB><TAB>  if i > 0 : <TAB><TAB><TAB><TAB>  data . mark_invalid ( ) <TAB><TAB><TAB>  i = data . draw_bytes ( 1 ) [ 0 ] <TAB><TAB><TAB>  if len ( seen ) < 255 : <TAB><TAB><TAB><TAB>  seen . add ( i ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data . mark_interesting ( ) ,elif i not in seen :,if i == 0:,False,22.61369287534545,96.87573147525735
3006,"def __on_item_activated ( self , event ) : <TAB>  if self . __module_view : <TAB><TAB>  module = self . get_event_module ( event ) <TAB><TAB>  self . __module_view . set_selection ( module . module_num ) <TAB><TAB>  if event . EventObject is self . list_ctrl : <TAB><TAB><TAB>  self . input_list_ctrl . deactivate_active_item ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . list_ctrl . deactivate_active_item ( ) <TAB><TAB><TAB>  for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . list_ctrl . Select ( index , False ) <TAB>  self . __controller . enable_module_controls_panel_buttons ( ) ",if self . list_ctrl . IsSelected ( index ) :,if self.__list_ctrl.GetItem(index) == 0:,False,49.987604183737766,95.5801406627444
3007,"def prime ( self , callback ) : <TAB>  <IF-STMT>: <TAB><TAB>  # import pdb <TAB><TAB>  # pdb.set_trace() <TAB><TAB>  self . cbhdl = simulator . register_rwsynch_callback ( callback , self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise_error ( self , "" Unable set up  %s  Trigger "" % ( str ( self ) ) ) <TAB>  Trigger . prime ( self ) ",if self . cbhdl is None :,if self.cbhdl is None:,False,52.2176144250237,93.43421405723481
3008,"def fstab_configuration ( middleware ) : <TAB>  for command in ( <TAB><TAB>  [ <TAB><TAB><TAB>  [ "" systemctl "" , "" daemon-reload "" ] , <TAB><TAB><TAB>  [ "" systemctl "" , "" restart "" , "" local-fs.target "" ] , <TAB><TAB>  ] <TAB><TAB>  if osc . IS_LINUX <TAB><TAB>  else [ [ "" mount "" , "" -uw "" , "" / "" ] ] <TAB>  ) : <TAB><TAB>  ret = subprocess . run ( command , capture_output = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  middleware . logger . debug ( <TAB><TAB><TAB><TAB>  f ' Failed to execute  "" { "" "" . join ( command ) } "" :  { ret . stderr . decode ( ) } ' <TAB><TAB><TAB>  ) ",if ret . returncode :,if ret.returncode != 0:,False,46.875266991332296,95.67130352948436
3009,"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB>  if fromdesc or todesc : <TAB><TAB>  yield ( <TAB><TAB><TAB>  simple_colorize ( fromdesc , "" description "" ) , <TAB><TAB><TAB>  simple_colorize ( todesc , "" description "" ) , <TAB><TAB>  ) <TAB>  for i , line in enumerate ( diffs ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # mdiff yields None on separator lines; skip the bogus ones <TAB><TAB><TAB>  # generated for the first line <TAB><TAB><TAB>  if i > 0 : <TAB><TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB><TAB>  simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB><TAB>  simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield line ",if line is None :,if line is None:,False,60.968748756236955,100.00000000000004
3010,"def update_completion ( self ) : <TAB>  """"""Update completion model with exist tags"""""" <TAB>  orig_text = self . widget . text ( ) <TAB>  text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB>  tags = [ ] <TAB>  for tag in self . tags_list : <TAB><TAB>  if "" , "" in orig_text : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB><TAB><TAB>  tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  tags . append ( tag ) <TAB>  if tags != self . completer_model . stringList ( ) : <TAB><TAB>  self . completer_model . setStringList ( tags ) ","if orig_text [ - 1 ] not in ( "","" , "" "" ) :",if tag in self.tags_list:,False,24.34281412709544,92.04420923425494
3011,"def cart_number_checksum_validation ( cls , number ) : <TAB>  digits = [ ] <TAB>  even = False <TAB>  if not number . isdigit ( ) : <TAB><TAB>  return False <TAB>  for digit in reversed ( number ) : <TAB><TAB>  digit = ord ( digit ) - ord ( "" 0 "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  digit * = 2 <TAB><TAB><TAB>  if digit > = 10 : <TAB><TAB><TAB><TAB>  digit = digit % 10 + digit / / 10 <TAB><TAB>  digits . append ( digit ) <TAB><TAB>  even = not even <TAB>  return sum ( digits ) % 10 == 0 if digits else False ",if even :,if digit < 0:,False,40.85716652358199,97.41477468002938
3012,"def __get_param_string__ ( params ) : <TAB>  params_string = [ ] <TAB>  for key in sorted ( params . keys ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  value = params [ key ] <TAB><TAB>  params_string . append ( "" "" if value == "" null "" else str ( value ) ) <TAB>  return "" | "" . join ( params_string ) ","if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :",if key == 'name':,False,44.94337724943267,84.91504266352061
3013,"def _map_handlers ( self , session , event_class , mapfn ) : <TAB>  for event in DOC_EVENTS : <TAB><TAB>  event_handler_name = event . replace ( "" - "" , "" _ "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  event_handler = getattr ( self , event_handler_name ) <TAB><TAB><TAB>  format_string = DOC_EVENTS [ event ] <TAB><TAB><TAB>  num_args = len ( format_string . split ( "" . "" ) ) - 2 <TAB><TAB><TAB>  format_args = ( event_class , ) + ( "" * "" , ) * num_args <TAB><TAB><TAB>  event_string = event + format_string % format_args <TAB><TAB><TAB>  unique_id = event_class + event_handler_name <TAB><TAB><TAB>  mapfn ( event_string , event_handler , unique_id ) ","if hasattr ( self , event_handler_name ) :","if hasattr(self, event_handler_name):",False,55.263803251255325,100.00000000000004
3014,"def _create_param_lr ( self , param_and_grad ) : <TAB>  # create learning rate variable for every parameter <TAB>  param = param_and_grad [ 0 ] <TAB>  param_lr = param . optimize_attr [ "" learning_rate "" ] <TAB>  if type ( param_lr ) == Variable : <TAB><TAB>  return param_lr <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _global_learning_rate ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  with default_main_program ( ) . _lr_schedule_guard ( <TAB><TAB><TAB><TAB>  is_with_opt = True <TAB><TAB><TAB>  ) , framework . name_scope ( "" scale_with_param_lr "" ) : <TAB><TAB><TAB><TAB>  return self . _global_learning_rate ( ) * param_lr ",if param_lr == 1.0 :,if type(param_lr) == int:,False,32.640984127033796,96.4208068804295
3015,"def __getitem__ ( self , key ) : <TAB>  try : <TAB><TAB>  return self . _clsmap [ key ] <TAB>  except KeyError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _mutex . acquire ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . _init ( ) <TAB><TAB><TAB><TAB><TAB>  self . initialized = True <TAB><TAB><TAB><TAB>  return self . _clsmap [ key ] <TAB><TAB><TAB>  finally : <TAB><TAB><TAB><TAB>  self . _mutex . release ( ) <TAB><TAB>  raise e ",if not self . initialized :,if self.initialized:,False,34.00814543837979,95.38262721528464
3016,"def save ( self , force = False ) : <TAB>  if not force : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  if time . time ( ) - self . last_save_time < 10 : <TAB><TAB><TAB>  return <TAB>  with self . lock : <TAB><TAB>  with open ( self . file_path , "" w "" ) as fd : <TAB><TAB><TAB>  for ip in self . cache : <TAB><TAB><TAB><TAB>  record = self . cache [ ip ] <TAB><TAB><TAB><TAB>  rule = record [ "" r "" ] <TAB><TAB><TAB><TAB>  connect_time = record [ "" c "" ] <TAB><TAB><TAB><TAB>  update_time = record [ "" update "" ] <TAB><TAB><TAB><TAB>  fd . write ( "" %s %s %d %d \n "" % ( ip , rule , connect_time , update_time ) ) <TAB>  self . last_save_time = time . time ( ) <TAB>  self . need_save = False ",if not self . need_save :,if self.need_save:,False,48.74541982378008,99.07795728685957
3017,"def pick ( items , sel ) : <TAB>  for x , s in zip ( items , sel ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield x <TAB><TAB>  elif not x . is_atom ( ) and not s . is_atom ( ) : <TAB><TAB><TAB>  yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation ) ",if match ( s ) :,if x.is_atom() and s.is_atom():,False,23.055773137829448,86.51110971780808
3018,"def isValidFloat ( config_param_name , value , constraints ) : <TAB>  if isinstance ( value , float ) : <TAB><TAB>  constraints . setdefault ( "" min "" , MIN_VALID_FLOAT_VALUE ) <TAB><TAB>  constraints . setdefault ( "" max "" , MAX_VALID_FLOAT_VALUE ) <TAB><TAB>  minv = float ( constraints . get ( "" min "" ) ) <TAB><TAB>  maxv = float ( constraints . get ( "" max "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if value < = maxv : <TAB><TAB><TAB><TAB>  return value <TAB>  raise FloatValueError ( config_param_name , value , constraints ) ",if value >= minv :,if minv <= maxv:,False,19.49326631864608,96.9083656760852
3019,"def get_files ( d ) : <TAB>  f = [ ] <TAB>  for root , dirs , files in os . walk ( d ) : <TAB><TAB>  for name in files : <TAB><TAB><TAB>  if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB><TAB><TAB><TAB>  f . append ( os . path . join ( root , name ) ) <TAB>  return f ","if ""qemux86copy-"" in root or ""qemux86-"" in root :",if name == 'build':,False,54.58521669053875,92.19319101558098
3020,"def __get_photo ( self , person_or_marriage ) : <TAB>  """"""returns the first photo in the media list or None"""""" <TAB>  media_list = person_or_marriage . get_media_list ( ) <TAB>  for media_ref in media_list : <TAB><TAB>  media_handle = media_ref . get_reference_handle ( ) <TAB><TAB>  media = self . database . get_media_from_handle ( media_handle ) <TAB><TAB>  mime_type = media . get_mime_type ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return media <TAB>  return None ","if mime_type and mime_type . startswith ( ""image"" ) :",if mime_type == 'text':,False,29.36348979749534,92.46058374361029
3021,"def filter ( this , args ) : <TAB>  array = to_object ( this , args . space ) <TAB>  callbackfn = get_arg ( args , 0 ) <TAB>  arr_len = js_arr_length ( array ) <TAB>  if not is_callable ( callbackfn ) : <TAB><TAB>  raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB>  _this = get_arg ( args , 1 ) <TAB>  k = 0 <TAB>  res = [ ] <TAB>  while k < arr_len : <TAB><TAB>  if array . has_property ( unicode ( k ) ) : <TAB><TAB><TAB>  kValue = array . get ( unicode ( k ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  res . append ( kValue ) <TAB><TAB>  k + = 1 <TAB>  return args . space . ConstructArray ( res ) ","if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :",if kValue is not None:,False,19.89950857962442,89.28533894374958
3022,"def optimize ( self , graph : Graph ) : <TAB>  for v in graph . inputs : <TAB><TAB>  if not v . has_attribute ( SplitTarget ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  DumpGraph ( ) . optimize ( graph ) <TAB><TAB>  raise NotImplementedError ( <TAB><TAB><TAB>  f "" Input Variable  { v }  is too large to handle in WebGL backend "" <TAB><TAB>  ) <TAB>  return graph , False ",if flags . DEBUG :,if v.has_attribute('SplitTarget'):,False,56.201560357600066,92.66889668888253
3023,"def detach_volume ( self , volume ) : <TAB>  # We need to find the node using this volume <TAB>  for node in self . list_nodes ( ) : <TAB><TAB>  if type ( node . image ) is not list : <TAB><TAB><TAB>  # This node has only one associated image. It is not the one we <TAB><TAB><TAB>  # are after. <TAB><TAB><TAB>  continue <TAB><TAB>  for disk in node . image : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # Node found. We can now detach the volume <TAB><TAB><TAB><TAB>  disk_id = disk . extra [ "" disk_id "" ] <TAB><TAB><TAB><TAB>  return self . _do_detach_volume ( node . id , disk_id ) <TAB>  return False ",if disk . id == volume . id :,if disk.id == volume:,False,43.49090442751694,98.36629544367686
3024,"def Yield ( value , level = 1 ) : <TAB>  g = greenlet . getcurrent ( ) <TAB>  while level != 0 : <TAB><TAB>  if not isinstance ( g , genlet ) : <TAB><TAB><TAB>  raise RuntimeError ( "" yield outside a genlet "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . parent . set_child ( g ) <TAB><TAB>  g = g . parent <TAB><TAB>  level - = 1 <TAB>  g . switch ( value ) ",if level > 1 :,if g.parent:,False,45.25881887550393,96.28278278632153
3025,"def get_all_pipeline_nodes ( <TAB>  pipeline : pipeline_pb2 . Pipeline ,  ) - > List [ pipeline_pb2 . PipelineNode ] : <TAB>  """"""Returns all pipeline nodes in the given pipeline."""""" <TAB>  result = [ ] <TAB>  for pipeline_or_node in pipeline . nodes : <TAB><TAB>  which = pipeline_or_node . WhichOneof ( "" node "" ) <TAB><TAB>  # TODO(goutham): Handle sub-pipelines. <TAB><TAB>  # TODO(goutham): Handle system nodes. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( pipeline_or_node . pipeline_node ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError ( "" Only pipeline nodes supported. "" ) <TAB>  return result ","if which == ""pipeline_node"" :",if which == pipeline_pb2.PipelineNode:,False,53.71774702742734,97.00186849729006
3026,"def __init__ ( self , * * settings ) : <TAB>  default_settings = self . get_default_settings ( ) <TAB>  for name , value in default_settings . items ( ) : <TAB><TAB>  if not hasattr ( self , name ) : <TAB><TAB><TAB>  setattr ( self , name , value ) <TAB>  for name , value in settings . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB>  "" Invalid setting  ' {} '  for  {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  name , <TAB><TAB><TAB><TAB><TAB>  self . __class__ . __name__ , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  setattr ( self , name , value ) ",if name not in default_settings :,if name not in self.__class__.__name__:,False,49.86057874229948,93.94369753032397
3027,"def _check_choice ( self ) : <TAB>  if self . type == "" choice "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB><TAB>  elif type ( self . choices ) not in ( types . TupleType , types . ListType ) : <TAB><TAB><TAB>  raise OptionError ( <TAB><TAB><TAB><TAB>  "" choices must be a list of strings ( ' %s '  supplied) "" <TAB><TAB><TAB><TAB>  % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB><TAB><TAB><TAB>  self , <TAB><TAB><TAB>  ) <TAB>  elif self . choices is not None : <TAB><TAB>  raise OptionError ( "" must not supply choices for type  %r "" % self . type , self ) ",if self . choices is None :,if type(self.choices) is not None:,False,35.65287406185384,92.94807656734584
3028,"def prepare ( self , size = None ) : <TAB>  if _is_seekable ( self . file ) : <TAB><TAB>  start_pos = self . file . tell ( ) <TAB><TAB>  self . file . seek ( 0 , 2 ) <TAB><TAB>  end_pos = self . file . tell ( ) <TAB><TAB>  self . file . seek ( start_pos ) <TAB><TAB>  fsize = end_pos - start_pos <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . remain = fsize <TAB><TAB>  else : <TAB><TAB><TAB>  self . remain = min ( fsize , size ) <TAB>  return self . remain ",if size is None :,if size is None:,False,52.074806060432536,100.00000000000004
3029,"def _setSitemapTargets ( ) : <TAB>  if not conf . sitemapUrl : <TAB><TAB>  return <TAB>  infoMsg = "" parsing sitemap  ' %s ' "" % conf . sitemapUrl <TAB>  logger . info ( infoMsg ) <TAB>  found = False <TAB>  for item in parseSitemap ( conf . sitemapUrl ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  found = True <TAB><TAB><TAB>  kb . targets . add ( ( item . strip ( ) , None , None , None , None ) ) <TAB>  if not found and not conf . forms and not conf . crawlDepth : <TAB><TAB>  warnMsg = "" no usable links found (with GET parameters) "" <TAB><TAB>  logger . warn ( warnMsg ) ","if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :",if item.startswith('.css') and item.endswith('.css') and,False,27.344381767926073,85.5119015010575
3030,"def test_CY_decomposition ( self , tol ) : <TAB>  """"""Tests that the decomposition of the CY gate is correct"""""" <TAB>  op = qml . CY ( wires = [ 0 , 1 ] ) <TAB>  res = op . decomposition ( op . wires ) <TAB>  mats = [ ] <TAB>  for i in reversed ( res ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mats . append ( np . kron ( i . matrix , np . eye ( 2 ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  mats . append ( i . matrix ) <TAB>  decomposed_matrix = np . linalg . multi_dot ( mats ) <TAB>  assert np . allclose ( decomposed_matrix , op . matrix , atol = tol , rtol = 0 ) ",if len ( i . wires ) == 1 :,if i.type == 'kron':,False,37.48909897083976,95.23092162941677
3031,"def _line_ranges ( statements , lines ) : <TAB>  """"""Produce a list of ranges for `format_lines`."""""" <TAB>  statements = sorted ( statements ) <TAB>  lines = sorted ( lines ) <TAB>  pairs = [ ] <TAB>  start = None <TAB>  lidx = 0 <TAB>  for stmt in statements : <TAB><TAB>  if lidx > = len ( lines ) : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lidx + = 1 <TAB><TAB><TAB>  if not start : <TAB><TAB><TAB><TAB>  start = stmt <TAB><TAB><TAB>  end = stmt <TAB><TAB>  elif start : <TAB><TAB><TAB>  pairs . append ( ( start , end ) ) <TAB><TAB><TAB>  start = None <TAB>  if start : <TAB><TAB>  pairs . append ( ( start , end ) ) <TAB>  return pairs ",if stmt == lines [ lidx ] :,if stmt.startswith('line'):,False,24.83328736859762,96.81347694882982
3032,"def init_params ( net ) : <TAB>  """"""Init layer parameters."""""" <TAB>  for module in net . modules ( ) : <TAB><TAB>  if isinstance ( module , nn . Conv2d ) : <TAB><TAB><TAB>  init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  init . constant ( module . bias , 0 ) <TAB><TAB>  elif isinstance ( module , nn . BatchNorm2d ) : <TAB><TAB><TAB>  init . constant ( module . weight , 1 ) <TAB><TAB><TAB>  init . constant ( module . bias , 0 ) <TAB><TAB>  elif isinstance ( module , nn . Linear ) : <TAB><TAB><TAB>  init . normal ( module . weight , std = 1e-3 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  init . constant ( module . bias , 0 ) ",if module . bias :,"if isinstance(module, nn.Fan_out):",False,22.519778500763202,93.6206760505729
3033,"def _get_directory_size_in_bytes ( directory ) : <TAB>  total = 0 <TAB>  try : <TAB><TAB>  for entry in os . scandir ( directory ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # if it's a file, use stat() function <TAB><TAB><TAB><TAB>  total + = entry . stat ( ) . st_size <TAB><TAB><TAB>  elif entry . is_dir ( ) : <TAB><TAB><TAB><TAB>  # if it's a directory, recursively call this function <TAB><TAB><TAB><TAB>  total + = _get_directory_size_in_bytes ( entry . path ) <TAB>  except NotADirectoryError : <TAB><TAB>  # if `directory` isn't a directory, get the file size then <TAB><TAB>  return os . path . getsize ( directory ) <TAB>  except PermissionError : <TAB><TAB>  # if for whatever reason we can't open the folder, return 0 <TAB><TAB>  return 0 <TAB>  return total ",if entry . is_file ( ) :,if entry.is_file():,False,68.74060209700887,100.00000000000004
3034,"def run_cmd ( self , util , to , always_push_mark = False ) : <TAB>  if to == "" bof "" : <TAB><TAB>  util . push_mark_and_goto_position ( 0 ) <TAB>  elif to == "" eof "" : <TAB><TAB>  util . push_mark_and_goto_position ( self . view . size ( ) ) <TAB>  elif to in ( "" eow "" , "" bow "" ) : <TAB><TAB>  visible = self . view . visible_region ( ) <TAB><TAB>  pos = visible . a if to == "" bow "" else visible . b <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  util . push_mark_and_goto_position ( pos ) <TAB><TAB>  else : <TAB><TAB><TAB>  util . set_cursors ( [ sublime . Region ( pos ) ] ) ",if always_push_mark :,if always_push_mark:,False,52.11369811611236,100.00000000000004
3035,"def parse_results ( cwd ) : <TAB>  optimal_dd = None <TAB>  optimal_measure = numpy . inf <TAB>  for tup in tools . find_conf_files ( cwd ) : <TAB><TAB>  dd = tup [ 1 ] <TAB><TAB>  if "" results.train_y_misclass "" in dd : <TAB><TAB><TAB>  if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB><TAB><TAB><TAB>  optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB><TAB><TAB><TAB>  optimal_dd = dd <TAB>  print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB>  for key , value in optimal_dd . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( key + "" :  "" + str ( value ) ) ","if ""hyper_parameters"" in key :",if key not in key:,False,21.922537744744332,97.06150398467774
3036,"def clean_vc_position ( self ) : <TAB>  vc_position = self . cleaned_data [ "" vc_position "" ] <TAB>  if self . validate_vc_position : <TAB><TAB>  conflicting_members = Device . objects . filter ( <TAB><TAB><TAB>  virtual_chassis = self . instance . virtual_chassis , vc_position = vc_position <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise forms . ValidationError ( <TAB><TAB><TAB><TAB>  "" A virtual chassis member already exists in position  {} . "" . format ( <TAB><TAB><TAB><TAB><TAB>  vc_position <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return vc_position ",if conflicting_members . exists ( ) :,if conflicting_members:,False,31.055445604544797,97.17649335608624
3037,"def cal_pads ( auto_pad , pad_shape ) : <TAB>  spatial_size = len ( pad_shape ) <TAB>  pads = [ 0 ] * spatial_size * 2 <TAB>  for i in range ( spatial_size ) : <TAB><TAB>  if auto_pad == "" SAME_LOWER "" : <TAB><TAB><TAB>  pads [ i + spatial_size ] = pad_shape [ i ] / / 2 <TAB><TAB><TAB>  pads [ i ] = pad_shape [ i ] - pads [ i + spatial_size ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pads [ i ] = pad_shape [ i ] / / 2 <TAB><TAB><TAB>  pads [ i + spatial_size ] = pad_shape [ i ] - pads [ i ] <TAB>  return pads ","elif auto_pad == ""SAME_UPPER"" :","if auto_pad == ""SAME_UPPER':",False,44.048489571544316,97.01194956952854
3038,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . add_presence_response ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 0:,False,25.976828837087734,98.60128562085158
3039,"def test_cwl_rnaseq ( self , install_test_files ) : <TAB>  with install_cwl_test_files ( ) as work_dir : <TAB><TAB>  with utils . chdir ( os . path . join ( work_dir , "" rnaseq "" ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  shutil . rmtree ( "" cromwell_work "" ) <TAB><TAB><TAB>  subprocess . check_call ( <TAB><TAB><TAB><TAB>  [ "" bcbio_vm.py "" , "" cwlrun "" , "" cromwell "" , "" rnaseq-workflow "" ] <TAB><TAB><TAB>  ) ","if os . path . exists ( ""cromwell_work"" ) :","if os.path.exists(""cromwell_work""):",False,50.74041050899801,100.00000000000004
3040,"def files_per_version ( self ) : <TAB>  xpath = "" ./files/file "" <TAB>  files = self . root . findall ( xpath ) <TAB>  versions = { } <TAB>  for file in files : <TAB><TAB>  vfile = file . findall ( "" version "" ) <TAB><TAB>  for version in vfile : <TAB><TAB><TAB>  nb = version . attrib [ "" nb "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  versions [ nb ] = [ ] <TAB><TAB><TAB>  versions [ nb ] . append ( file . attrib [ "" url "" ] ) <TAB>  return versions ",if not nb in versions :,if nb not in versions:,False,51.03685113213482,98.09203871299064
3041,"def value_to_db_datetime ( self , value ) : <TAB>  if value is None : <TAB><TAB>  return None <TAB>  # SQLite doesn't support tz-aware datetimes <TAB>  if timezone . is_aware ( value ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" SQLite backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB><TAB><TAB>  ) <TAB>  return six . text_type ( value ) ",if settings . USE_TZ :,if USE_TZ:,False,63.78716266330008,97.80195524730742
3042,"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB>  with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB><TAB>  t = threading . current_thread ( ) <TAB><TAB>  t . name = func . __name__ <TAB><TAB>  try : <TAB><TAB><TAB>  t . status = func ( * args , * * kwargs ) <TAB><TAB>  except EscapeException as e :<TAB># user aborted <TAB><TAB><TAB>  t . status = "" aborted by user "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  status ( "" %s  aborted "" % t . name , priority = 2 ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  t . exception = e <TAB><TAB><TAB>  t . status = "" exception "" <TAB><TAB><TAB>  vd . exceptionCaught ( e ) <TAB><TAB>  if t . sheet : <TAB><TAB><TAB>  t . sheet . currentThreads . remove ( t ) ",if status :,if e.args[0] == 'abort':,False,45.923065707129155,94.3212405944954
3043,"def ESP ( phrase ) : <TAB>  for num , name in enumerate ( devname ) : <TAB><TAB>  if name . lower ( ) in phrase : <TAB><TAB><TAB>  dev = devid [ num ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ctrl = "" =ON "" <TAB><TAB><TAB><TAB>  say ( "" Turning On  "" + name ) <TAB><TAB><TAB>  elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB><TAB><TAB><TAB>  ctrl = "" =OFF "" <TAB><TAB><TAB><TAB>  say ( "" Turning Off  "" + name ) <TAB><TAB><TAB>  rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False ) ","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :","if custom_action_keyword['Dict'][""On'] in phrase:",False,22.380333486609974,96.24148496476262
3044,"def _table_schema ( self , table ) : <TAB>  rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB>  # Build list of fields from table information <TAB>  result = { } <TAB>  for _ , name , data_type , not_null , _ , primary_key in rows : <TAB><TAB>  parts = [ data_type ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parts . append ( "" PRIMARY KEY "" ) <TAB><TAB>  if not_null : <TAB><TAB><TAB>  parts . append ( "" NOT NULL "" ) <TAB><TAB>  result [ name ] = "" "" . join ( parts ) <TAB>  return result ",if primary_key :,if primary_key:,False,56.212914044901694,98.02201824717983
3045,"def _validate_forward_input ( x , n_in ) : <TAB>  if n_in != 1 : <TAB><TAB>  if not isinstance ( x , ( tuple , list ) ) : <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  f "" Expected input to be a tuple or list; instead got  { type ( x ) } . "" <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  f "" Input tuple length ( { len ( x ) } ) does not equal required  "" <TAB><TAB><TAB><TAB>  f "" number of inputs ( { n_in } ). "" <TAB><TAB><TAB>  ) ",if len ( x ) != n_in :,if n_in != 0:,False,35.186238112163124,95.71418167224077
3046,"def _table_reprfunc ( self , row , col , val ) : <TAB>  if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB><TAB>  if isinstance ( val , compat . string_types ) : <TAB><TAB><TAB>  return ""<TAB>%s "" % val <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ""<TAB>%.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB><TAB>  elif val < 1024 * * 3 : <TAB><TAB><TAB>  return ""<TAB>%.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  return ""<TAB>%.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB>  if col in ( 0 , "" "" ) : <TAB><TAB>  return str ( val ) <TAB>  else : <TAB><TAB>  return ""<TAB>%s "" % val ",elif val < 1024 ** 2 :,if val < 1024 * * 1:,False,18.269944398514983,88.39100560015459
3047,"def get_path_name ( self ) : <TAB>  if self . is_root ( ) : <TAB><TAB>  return "" @ "" + self . name <TAB>  else : <TAB><TAB>  parent_name = self . parent . get_path_name ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" / "" . join ( [ parent_name , "" @ "" + self . name ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  return "" @ "" + self . name ",if parent_name :,if parent_name:,False,25.599400588049427,100.00000000000004
3048,"def parse ( cls , api , json ) : <TAB>  lst = List ( api ) <TAB>  setattr ( lst , "" _json "" , json ) <TAB>  for k , v in json . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( lst , k , User . parse ( api , v ) ) <TAB><TAB>  elif k == "" created_at "" : <TAB><TAB><TAB>  setattr ( lst , k , parse_datetime ( v ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  setattr ( lst , k , v ) <TAB>  return lst ","if k == ""user"" :",if k == 'user':,False,50.997934782633635,97.02547738857885
3049,"def _bytecode_filenames ( self , py_filenames ) : <TAB>  bytecode_files = [ ] <TAB>  for py_file in py_filenames : <TAB><TAB>  if not py_file . endswith ( "" .py "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bytecode_files . append ( py_file + "" c "" ) <TAB><TAB>  if self . optimize > 0 : <TAB><TAB><TAB>  bytecode_files . append ( py_file + "" o "" ) <TAB>  return bytecode_files ",if self . compile :,if self.optimize > 0:,False,49.38537153332505,96.80991184556267
3050,"def to_json_dict ( self ) : <TAB>  d = super ( ) . to_json_dict ( ) <TAB>  d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB>  if self . header is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d [ "" header "" ] = self . header . to_json_dict ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  d [ "" header "" ] = self . header <TAB>  if self . subheader is not None : <TAB><TAB>  if isinstance ( self . subheader , RenderedContent ) : <TAB><TAB><TAB>  d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  d [ "" subheader "" ] = self . subheader <TAB>  return d ","if isinstance ( self . header , RenderedContent ) :","if isinstance(self.header, RenderedContent):",False,50.9134467509553,100.00000000000004
3051,"def makeSomeFiles ( pathobj , dirdict ) : <TAB>  pathdict = { } <TAB>  for ( key , value ) in dirdict . items ( ) : <TAB><TAB>  child = pathobj . child ( key ) <TAB><TAB>  if isinstance ( value , bytes ) : <TAB><TAB><TAB>  pathdict [ key ] = child <TAB><TAB><TAB>  child . setContent ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  child . createDirectory ( ) <TAB><TAB><TAB>  pathdict [ key ] = makeSomeFiles ( child , value ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB>  return pathdict ","elif isinstance ( value , dict ) :",if not child.isDirectory():,False,26.274949911559354,95.73787491900966
3052,"def Restore ( self ) : <TAB>  picker , obj = self . _window , self . _pObject <TAB>  value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB>  if value is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if type ( value ) == list : <TAB><TAB><TAB><TAB>  value = value [ - 1 ] <TAB><TAB>  picker . SetPath ( value ) <TAB><TAB>  return True <TAB>  return False ","if issubclass ( picker . __class__ , wx . FileDialog ) :",if value is not None:,False,49.711531002415235,85.69177048208442
3053,"def recv ( self , buffer_size ) : <TAB>  try : <TAB><TAB>  return super ( SSLConnection , self ) . recv ( buffer_size ) <TAB>  except ssl . SSLError as err : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return b "" "" <TAB><TAB>  if err . args [ 0 ] in ( ssl . SSL_ERROR_EOF , ssl . SSL_ERROR_ZERO_RETURN ) : <TAB><TAB><TAB>  self . handle_close ( ) <TAB><TAB><TAB>  return b "" "" <TAB><TAB>  raise ","if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) :",if err.args[0] == ssl.SSL_ERROR_WANT_READ:,False,18.464114585007092,89.97029816874029
3054,"def IncrementErrorCount ( self , category ) : <TAB>  """"""Bumps the module's error statistic."""""" <TAB>  self . error_count + = 1 <TAB>  if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  category = category . split ( "" / "" ) [ 0 ] <TAB><TAB>  if category not in self . errors_by_category : <TAB><TAB><TAB>  self . errors_by_category [ category ] = 0 <TAB><TAB>  self . errors_by_category [ category ] + = 1 ","if self . counting != ""detailed"" :",if category.startswith('/'):,False,20.154919461346633,93.67215236506115
3055,"def _get_y ( self , data_inst ) : <TAB>  if self . stratified : <TAB><TAB>  y = [ v for i , v in data_inst . mapValues ( lambda v : v . label ) . collect ( ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y = self . transform_regression_label ( data_inst ) <TAB>  else : <TAB><TAB>  # make dummy y <TAB><TAB>  y = [ 0 ] * ( data_inst . count ( ) ) <TAB>  return y ",if self . need_transform :,if self.transform_regression_label:,False,51.054670282941025,95.41437245849966
3056,"def test_all_project_files ( self ) : <TAB>  if sys . platform . startswith ( "" win "" ) : <TAB><TAB>  # XXX something with newlines goes wrong on Windows. <TAB><TAB>  return <TAB>  for filepath in support . all_project_files ( ) : <TAB><TAB>  with open ( filepath , "" rb "" ) as fp : <TAB><TAB><TAB>  encoding = tokenize . detect_encoding ( fp . readline ) [ 0 ] <TAB><TAB>  self . assertIsNotNone ( encoding , "" can ' t detect encoding for  %s "" % filepath ) <TAB><TAB>  with open ( filepath , "" r "" ) as fp : <TAB><TAB><TAB>  source = fp . read ( ) <TAB><TAB><TAB>  source = source . decode ( encoding ) <TAB><TAB>  tree = driver . parse_string ( source ) <TAB><TAB>  new = unicode ( tree ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . fail ( "" Idempotency failed:  %s "" % filepath ) ","if diff ( filepath , new , encoding ) :",if new != source:,False,56.48286907818546,95.24337121320764
3057,"def test_resource_arn_override_generator ( self ) : <TAB>  overrides = set ( ) <TAB>  for k , v in manager . resources . items ( ) : <TAB><TAB>  arn_gen = bool ( v . __dict__ . get ( "" get_arns "" ) or v . __dict__ . get ( "" generate_arn "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  overrides . add ( k ) <TAB>  overrides = overrides . difference ( <TAB><TAB>  { <TAB><TAB><TAB>  "" account "" , <TAB><TAB><TAB>  "" s3 "" , <TAB><TAB><TAB>  "" hostedzone "" , <TAB><TAB><TAB>  "" log-group "" , <TAB><TAB><TAB>  "" rest-api "" , <TAB><TAB><TAB>  "" redshift-snapshot "" , <TAB><TAB><TAB>  "" rest-stage "" , <TAB><TAB>  } <TAB>  ) <TAB>  if overrides : <TAB><TAB>  raise ValueError ( "" unknown arn overrides in  %s "" % ( "" ,  "" . join ( overrides ) ) ) ",if arn_gen :,if arn_gen:,False,51.89864594272725,100.00000000000004
3058,"def _check_dsl_runner ( self ) - > None : <TAB>  """"""Checks if runner in dsl is Kubeflow V2 runner."""""" <TAB>  with open ( self . flags_dict [ labels . PIPELINE_DSL_PATH ] , "" r "" ) as f : <TAB><TAB>  dsl_contents = f . read ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" KubeflowV2DagRunner not found in dsl. "" ) ","if ""KubeflowV2DagRunner"" not in dsl_contents :",if dsl_contents != self.flags_dict[labels.PIPELINE_DSL_PATH,False,28.2554906855361,85.02033062474666
3059,"def create_warehouse ( warehouse_name , properties = None , company = None ) : <TAB>  if not company : <TAB><TAB>  company = "" _Test Company "" <TAB>  warehouse_id = erpnext . encode_company_abbr ( warehouse_name , company ) <TAB>  if not frappe . db . exists ( "" Warehouse "" , warehouse_id ) : <TAB><TAB>  warehouse = frappe . new_doc ( "" Warehouse "" ) <TAB><TAB>  warehouse . warehouse_name = warehouse_name <TAB><TAB>  warehouse . parent_warehouse = "" All Warehouses - _TCUV "" <TAB><TAB>  warehouse . company = company <TAB><TAB>  warehouse . account = get_warehouse_account ( warehouse_name , company ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warehouse . update ( properties ) <TAB><TAB>  warehouse . save ( ) <TAB><TAB>  return warehouse . name <TAB>  else : <TAB><TAB>  return warehouse_id ",if properties :,if properties:,False,50.65715735871523,100.00000000000004
3060,"def _parse ( self , contents ) : <TAB>  entries = [ ] <TAB>  hostnames_found = set ( ) <TAB>  for line in contents . splitlines ( ) : <TAB><TAB>  if not len ( line . strip ( ) ) : <TAB><TAB><TAB>  entries . append ( ( "" blank "" , [ line ] ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB><TAB>  hostnames_found . add ( head ) <TAB>  if len ( hostnames_found ) > 1 : <TAB><TAB>  raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB>  return entries ",if not len ( head ) :,if head == tail:,False,22.483932062223623,97.39806810117695
3061,"def _get_omega ( self ) : <TAB>  if self . _omega is None : <TAB><TAB>  n = self . get_drift_dim ( ) / / 2 <TAB><TAB>  omg = sympl . calc_omega ( n ) <TAB><TAB>  if self . oper_dtype == Qobj : <TAB><TAB><TAB>  self . _omega = Qobj ( omg , dims = self . dyn_dims ) <TAB><TAB><TAB>  self . _omega_qobj = self . _omega <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _omega = sp . csr_matrix ( omg ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _omega = omg <TAB>  return self . _omega ",elif self . oper_dtype == sp . csr_matrix :,if self.is_csr_matrix:,False,23.7715130519876,94.43053095509887
3062,"def get_in_inputs ( key , data ) : <TAB>  if isinstance ( data , dict ) : <TAB><TAB>  for k , v in data . items ( ) : <TAB><TAB><TAB>  if k == key : <TAB><TAB><TAB><TAB>  return v <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  out = get_in_inputs ( key , v ) <TAB><TAB><TAB><TAB>  if out : <TAB><TAB><TAB><TAB><TAB>  return out <TAB>  elif isinstance ( data , ( list , tuple ) ) : <TAB><TAB>  out = [ get_in_inputs ( key , x ) for x in data ] <TAB><TAB>  out = [ x for x in out if x ] <TAB><TAB>  if out : <TAB><TAB><TAB>  return out [ 0 ] ","elif isinstance ( v , ( list , tuple , dict ) ) :","if isinstance(v, int):",False,32.91850791360743,95.09430306560715
3063,def visit_binary ( binary ) : <TAB>  if binary . operator == operators . eq : <TAB><TAB>  cols = util . column_set ( chain ( * [ c . proxy_set for c in columns . difference ( omit ) ] ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for c in reversed ( columns ) : <TAB><TAB><TAB><TAB>  if c . shares_lineage ( binary . right ) and ( <TAB><TAB><TAB><TAB><TAB>  not only_synonyms or c . name == binary . left . name <TAB><TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB><TAB>  omit . add ( c ) <TAB><TAB><TAB><TAB><TAB>  break ,if binary . left in cols and binary . right in cols :,"if not isinstance(columns, (list, tuple)):",False,43.43893503599104,93.6332774107805
3064,"def wait_tasks_or_abort ( futures , timeout = 60 , kill_switch_ev = None ) : <TAB>  try : <TAB><TAB>  LazySingletonTasksCoordinator . wait_tasks ( <TAB><TAB><TAB>  futures , return_when = FIRST_EXCEPTION , raise_exceptions = True <TAB><TAB>  ) <TAB>  except Exception as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Used when we want to keep both raise the exception and wait for all tasks to finish <TAB><TAB><TAB>  kill_switch_ev . set ( ) <TAB><TAB><TAB>  LazySingletonTasksCoordinator . wait_tasks ( <TAB><TAB><TAB><TAB>  futures , <TAB><TAB><TAB><TAB>  return_when = ALL_COMPLETED , <TAB><TAB><TAB><TAB>  raise_exceptions = False , <TAB><TAB><TAB><TAB>  timeout = timeout , <TAB><TAB><TAB>  ) <TAB><TAB>  raise e ",if kill_switch_ev is not None :,if kill_switch_ev:,False,64.80419486890817,98.1255966885059
3065,"def is_valid ( sample ) : <TAB>  if sample is None : <TAB><TAB>  return False <TAB>  if isinstance ( sample , tuple ) : <TAB><TAB>  for s in sample : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ",if s is None :,"if isinstance(s, np.ndarray) and s.size == 0:",False,29.268469997317155,90.56923799863158
3066,"def setVaName ( self , va , parent = None ) : <TAB>  if parent is None : <TAB><TAB>  parent = self <TAB>  curname = self . vw . getName ( va ) <TAB>  if curname is None : <TAB><TAB>  curname = "" "" <TAB>  name , ok = QInputDialog . getText ( parent , "" Enter... "" , "" Name "" , text = curname ) <TAB>  if ok : <TAB><TAB>  name = str ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( "" Duplicate Name:  %s "" % name ) <TAB><TAB>  self . vw . makeName ( va , name ) ",if self . vw . vaByName ( name ) :,if name in self.vw.getNames():,False,23.451035112221632,95.8934866007101
3067,"def generic_tag_compiler ( params , defaults , name , node_class , parser , token ) : <TAB>  "" Returns a template.Node subclass. "" <TAB>  bits = token . split_contents ( ) [ 1 : ] <TAB>  bmax = len ( params ) <TAB>  def_len = defaults and len ( defaults ) or 0 <TAB>  bmin = bmax - def_len <TAB>  if len ( bits ) < bmin or len ( bits ) > bmax : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  message = "" %s  takes  %s  arguments "" % ( name , bmin ) <TAB><TAB>  else : <TAB><TAB><TAB>  message = "" %s  takes between  %s  and  %s  arguments "" % ( name , bmin , bmax ) <TAB><TAB>  raise TemplateSyntaxError ( message ) <TAB>  return node_class ( bits ) ",if bmin == bmax :,if len(bits) < bmin:,False,42.19713686199976,96.35872791622214
3068,"def extract_segmentation_mask ( annotation ) : <TAB>  poly_specs = annotation [ DensePoseDataRelative . S_KEY ] <TAB>  if isinstance ( poly_specs , torch . Tensor ) : <TAB><TAB>  # data is already given as mask tensors, no need to decode <TAB><TAB>  return poly_specs <TAB>  import pycocotools . mask as mask_utils <TAB>  segm = torch . zeros ( ( DensePoseDataRelative . MASK_SIZE , ) * 2 , dtype = torch . float32 ) <TAB>  for i in range ( DensePoseDataRelative . N_BODY_PARTS ) : <TAB><TAB>  poly_i = poly_specs [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mask_i = mask_utils . decode ( poly_i ) <TAB><TAB><TAB>  segm [ mask_i > 0 ] = i + 1 <TAB>  return segm ",if poly_i :,"if isinstance(poly_i, pycocotools.mask.Mask):",False,60.27655951286584,94.17623496644238
3069,"def module_list ( target , fast ) : <TAB>  """"""Find the list of modules to be compiled"""""" <TAB>  modules = [ ] <TAB>  native = native_modules ( target ) <TAB>  basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB>  for name in os . listdir ( basedir ) : <TAB><TAB>  module_name , ext = os . path . splitext ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if module_name not in IGNORE_MODULES and module_name not in native : <TAB><TAB><TAB><TAB>  if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) : <TAB><TAB><TAB><TAB><TAB>  modules . append ( module_name ) <TAB>  return set ( modules ) ","if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :",if ext == 'module':,False,30.81319244843035,86.13811801274394
3070,"def filelist_from_patterns ( pats , rootdir = None ) : <TAB>  if rootdir is None : <TAB><TAB>  rootdir = "" . "" <TAB>  # filelist = [] <TAB>  fileset = set ( [ ] ) <TAB>  lines = [ line . strip ( ) for line in pats ] <TAB>  for line in lines : <TAB><TAB>  pat = line [ 2 : ] <TAB><TAB>  newfiles = glob ( osp . join ( rootdir , pat ) ) <TAB><TAB>  if line . startswith ( "" + "" ) : <TAB><TAB><TAB>  fileset . update ( newfiles ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fileset . difference_update ( newfiles ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" line must start with + or - "" ) <TAB>  filelist = list ( fileset ) <TAB>  return filelist ","elif line . startswith ( ""-"" ) :",if line.startswith('+'):,False,55.7211852265383,96.7098769661705
3071,"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB>  statuses_by_refs = { u : [ ] for u in upstream } <TAB>  events = self . events or [ ]<TAB># type: List[V1EventTrigger] <TAB>  for e in events : <TAB><TAB>  entity_ref = contexts_refs . get_entity_ref ( e . ref ) <TAB><TAB>  if not entity_ref : <TAB><TAB><TAB>  continue <TAB><TAB>  if entity_ref not in statuses_by_refs : <TAB><TAB><TAB>  continue <TAB><TAB>  for kind in e . kinds : <TAB><TAB><TAB>  status = V1EventKind . events_statuses_mapping . get ( kind ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  statuses_by_refs [ entity_ref ] . append ( status ) <TAB>  return statuses_by_refs ",if status :,if status is not None:,False,23.604287984126167,96.10250990082898
3072,"def __setitem__ ( self , key , value ) : <TAB>  if isinstance ( value , ( tuple , list ) ) : <TAB><TAB>  info , reference = value <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _reverse_infos [ info ] = len ( self . _infos ) <TAB><TAB><TAB>  self . _infos . append ( info ) <TAB><TAB>  if reference not in self . _reverse_references : <TAB><TAB><TAB>  self . _reverse_references [ reference ] = len ( self . _references ) <TAB><TAB><TAB>  self . _references . append ( reference ) <TAB><TAB>  self . _trails [ key ] = "" %d , %d "" % ( <TAB><TAB><TAB>  self . _reverse_infos [ info ] , <TAB><TAB><TAB>  self . _reverse_references [ reference ] , <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) ) ",if info not in self . _reverse_infos :,if info not in self._infos:,False,27.169069526479355,97.94045543182023
3073,"def ChangeStyle ( self , combos ) : <TAB>  style = 0 <TAB>  for combo in combos : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if combo . GetLabel ( ) == "" TR_VIRTUAL "" : <TAB><TAB><TAB><TAB>  style = style | HTL . TR_VIRTUAL <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB>  if self . GetAGWWindowStyleFlag ( ) != style : <TAB><TAB>  self . SetAGWWindowStyleFlag ( style ) ",if combo . GetValue ( ) == 1 :,"if combo.GetLabel() == ""ST_COMPRESS':",False,14.871037627487615,96.20576711409102
3074,"def _parse_csrf ( self , response ) : <TAB>  for d in response : <TAB><TAB>  if d . startswith ( "" Set-Cookie: "" ) : <TAB><TAB><TAB>  for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . _CSRFtoken = c . strip ( "" \r \n "" ) <TAB><TAB><TAB><TAB><TAB>  log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  if self . _CSRFtoken != None : <TAB><TAB><TAB><TAB>  break ","if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :",if c.startswith('Set-Cookie'):,False,42.565710086062836,95.44565075597076
3075,"def test_page_size_matching_max_returned_rows ( <TAB>  app_client_returned_rows_matches_page_size ,  ) : <TAB>  fetched = [ ] <TAB>  path = "" /fixtures/no_primary_key.json "" <TAB>  while path : <TAB><TAB>  response = app_client_returned_rows_matches_page_size . get ( path ) <TAB><TAB>  fetched . extend ( response . json [ "" rows "" ] ) <TAB><TAB>  assert len ( response . json [ "" rows "" ] ) in ( 1 , 50 ) <TAB><TAB>  path = response . json [ "" next_url "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = path . replace ( "" http://localhost "" , "" "" ) <TAB>  assert 201 == len ( fetched ) ",if path :,if path.startswith('http://localhost'):,False,26.014192485934068,94.86064138842728
3076,"def get_mapping_exception_message ( mappings : List [ Tuple [ Text , Text ] ] ) : <TAB>  """"""Return a message given a list of duplicates."""""" <TAB>  message = "" "" <TAB>  for name , action_name in mappings : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  message + = "" \n "" <TAB><TAB>  message + = ( <TAB><TAB><TAB>  "" Intent  ' {} '  is set to trigger action  ' {} ' , which is  "" <TAB><TAB><TAB>  "" not defined in the domain. "" . format ( name , action_name ) <TAB><TAB>  ) <TAB>  return message ",if message :,"if name not in ('action', 'action'):",False,55.59130327664932,94.25228516659645
3077,def cut ( sentence ) : <TAB>  sentence = strdecode ( sentence ) <TAB>  blocks = re_han . split ( sentence ) <TAB>  for blk in blocks : <TAB><TAB>  if re_han . match ( blk ) : <TAB><TAB><TAB>  for word in __cut ( blk ) : <TAB><TAB><TAB><TAB>  if word not in Force_Split_Words : <TAB><TAB><TAB><TAB><TAB>  yield word <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  for c in word : <TAB><TAB><TAB><TAB><TAB><TAB>  yield c <TAB><TAB>  else : <TAB><TAB><TAB>  tmp = re_skip . split ( blk ) <TAB><TAB><TAB>  for x in tmp : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  yield x ,if x :,if re_han.match(x):,False,51.141130988213554,96.18068791441424
3078,"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB>  if isinstance ( expr , Real ) : <TAB><TAB>  if - delta < expr . get_float_value ( ) < delta : <TAB><TAB><TAB>  return Integer ( 0 ) <TAB>  elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB><TAB>  real , imag = expr . real , expr . imag <TAB><TAB>  if - delta < real . get_float_value ( ) < delta : <TAB><TAB><TAB>  real = Integer ( 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  imag = Integer ( 0 ) <TAB><TAB>  return Complex ( real , imag ) <TAB>  elif isinstance ( expr , Expression ) : <TAB><TAB>  return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB>  return expr ",if - delta < imag . get_float_value ( ) < delta :,"if isinstance(expr, Complex):",False,26.08964570897277,90.56842372898522
3079,"def make_row ( self ) : <TAB>  res = [ ] <TAB>  for i in range ( self . num_cols ) : <TAB><TAB>  t = sqlite3_column_type ( self . stmnt , i ) <TAB><TAB>  # print(""type"", t) <TAB><TAB>  if t == SQLITE_INTEGER : <TAB><TAB><TAB>  res . append ( sqlite3_column_int ( self . stmnt , i ) ) <TAB><TAB>  elif t == SQLITE_FLOAT : <TAB><TAB><TAB>  res . append ( sqlite3_column_double ( self . stmnt , i ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  res . append ( sqlite3_column_text ( self . stmnt , i ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError <TAB>  return tuple ( res ) ",elif t == SQLITE_TEXT :,if t == SQLITE_TEXT:,False,51.09878530706315,98.80803503791117
3080,"def try_convert ( self , string ) : <TAB>  string = string . strip ( ) <TAB>  try : <TAB><TAB>  return int ( string ) <TAB>  except : <TAB><TAB>  try : <TAB><TAB><TAB>  return float ( string ) <TAB><TAB>  except : <TAB><TAB><TAB>  if string == "" True "" : <TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  return string ","if string == ""False"" :","if string == ""False':",False,47.74385181510246,97.53908715442746
3081,"def configure_create_table_epilogue ( store ) : <TAB>  for val in [ "" "" , ""  ENGINE=InnoDB "" ] : <TAB><TAB>  store . config [ "" create_table_epilogue "" ] = val <TAB><TAB>  store . _set_sql_flavour ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  store . log . info ( "" create_table_epilogue= ' %s ' "" , val ) <TAB><TAB><TAB>  return <TAB>  raise Exception ( "" Can not create a transactional table. "" ) ",if store . _test_transaction ( ) :,if store.config['create_table_epilogue']:,False,26.902225495003524,90.86438866857185
3082,"def _check_rule ( self , match , target_dict , cred_dict ) : <TAB>  """"""Recursively checks credentials based on the brains rules."""""" <TAB>  try : <TAB><TAB>  new_match_list = self . rules [ match ] <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_match_list = ( "" rule: %s "" % self . default_rule , ) <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  return self . check ( new_match_list , target_dict , cred_dict ) ",if self . default_rule and match != self . default_rule :,if self.default_rule:,False,45.436506450053905,94.17645335842491
3083,"def get_civil_names ( self ) : <TAB>  congresspeople_ids = self . get_all_congresspeople_ids ( ) <TAB>  for i , congress_id in enumerate ( congresspeople_ids ) : <TAB><TAB>  if not np . math . isnan ( float ( congress_id ) ) : <TAB><TAB><TAB>  percentage = i / self . total * 100 <TAB><TAB><TAB>  msg = "" Processed  {}  out of  {}  ( {:.2f} % ) "" <TAB><TAB><TAB>  print ( msg . format ( i , self . total , percentage ) , end = "" \r "" ) <TAB><TAB><TAB>  data = self . fetch_data_repository ( congress_id ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield dict ( data ) ",if data is not None :,if data:,False,35.140967550577955,97.71660344174707
3084,"def parse_network_whitelist ( self , network_whitelist_location ) : <TAB>  networks = [ ] <TAB>  with open ( network_whitelist_location , "" r "" ) as text_file : <TAB><TAB>  for line in text_file : <TAB><TAB><TAB>  line = line . strip ( ) . strip ( "" ' "" ) . strip ( ' "" ' ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  networks . append ( line ) <TAB>  return networks ",if isIPv4 ( line ) or isIPv6 ( line ) :,if line and line not in networks:,False,34.72411495403156,92.19312324409434
3085,"def _pick ( self , cum ) : <TAB>  if self . _isleaf ( ) : <TAB><TAB>  return self . bd [ 0 ] , self . s <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . left . _pick ( cum ) <TAB><TAB>  else : <TAB><TAB><TAB>  return self . right . _pick ( cum - self . left . s ) ",if cum < self . left . s :,if self._isleaf():,False,23.371161902394217,92.76114182769814
3086,"def serialize_content_range ( value ) : <TAB>  if isinstance ( value , ( tuple , list ) ) : <TAB><TAB>  if len ( value ) not in ( 2 , 3 ) : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" When setting content_range to a list/tuple, it must  "" <TAB><TAB><TAB><TAB>  "" be length 2 or 3 (not  %r ) "" % value <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  begin , end = value <TAB><TAB><TAB>  length = None <TAB><TAB>  else : <TAB><TAB><TAB>  begin , end , length = value <TAB><TAB>  value = ContentRange ( begin , end , length ) <TAB>  value = str ( value ) . strip ( ) <TAB>  if not value : <TAB><TAB>  return None <TAB>  return value ",if len ( value ) == 2 :,if len(value) == 2:,False,58.85072658759887,100.00000000000004
3087,"def make_index_fields ( rec ) : <TAB>  fields = { } <TAB>  for k , v in rec . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fields [ k ] = v <TAB><TAB><TAB>  continue <TAB><TAB>  if k == "" full_title "" : <TAB><TAB><TAB>  fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB>  return fields ","if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :",if k == 'title':,False,46.05659087630558,87.2607781243831
3088,"def _sample_translation ( reference , max_len ) : <TAB>  translation = reference [ : ] <TAB>  while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB><TAB>  trans_len = len ( translation ) <TAB><TAB>  ind = np . random . randint ( trans_len ) <TAB><TAB>  action = np . random . choice ( actions ) <TAB><TAB>  if action == "" deletion "" : <TAB><TAB><TAB>  del translation [ ind ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ind_rep = np . random . randint ( trans_len ) <TAB><TAB><TAB>  translation [ ind ] = translation [ ind_rep ] <TAB><TAB>  else : <TAB><TAB><TAB>  ind_insert = np . random . randint ( trans_len ) <TAB><TAB><TAB>  translation . insert ( ind , translation [ ind_insert ] ) <TAB>  return translation ","elif action == ""replacement"" :","if action == ""insert':",False,32.55504910025948,97.45552352463602
3089,"def __call__ ( self , text : str ) - > str : <TAB>  for t in self . cleaner_types : <TAB><TAB>  if t == "" tacotron "" : <TAB><TAB><TAB>  text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB><TAB>  elif t == "" jaconv "" : <TAB><TAB><TAB>  text = jaconv . normalize ( text ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if vietnamese_cleaners is None : <TAB><TAB><TAB><TAB>  raise RuntimeError ( "" Please install underthesea "" ) <TAB><TAB><TAB>  text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB>  return text ","elif t == ""vietnamese"" :","if t == ""vennnamese':",False,21.99107095252423,97.084557393556
3090,"def hook_GetVariable ( ql , address , params ) : <TAB>  if params [ "" VariableName "" ] in ql . env : <TAB><TAB>  var = ql . env [ params [ "" VariableName "" ] ] <TAB><TAB>  read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB><TAB>  write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB><TAB>  if read_len < len ( var ) : <TAB><TAB><TAB>  return EFI_BUFFER_TOO_SMALL <TAB><TAB>  if params [ "" Data "" ] != 0 : <TAB><TAB><TAB>  ql . mem . write ( params [ "" Data "" ] , var ) <TAB><TAB>  return EFI_SUCCESS <TAB>  return EFI_NOT_FOUND ","if params [ ""Attributes"" ] != 0 :",if read_len > 0:,False,22.93247775703275,95.7794291855208
3091,"def test_setupapp ( self , overrideRootMenu ) : <TAB>  "" Call setupApp with each possible graphics type. "" <TAB>  root = self . root <TAB>  flist = FileList ( root ) <TAB>  for tktype in alltypes : <TAB><TAB>  with self . subTest ( tktype = tktype ) : <TAB><TAB><TAB>  macosx . _tk_type = tktype <TAB><TAB><TAB>  macosx . setupApp ( root , flist ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertTrue ( overrideRootMenu . called ) <TAB><TAB><TAB>  overrideRootMenu . reset_mock ( ) ","if tktype in ( ""carbon"" , ""cocoa"" ) :",if overrideRootMenu:,False,45.33063867498303,91.75578262730305
3092,"def names ( self , persistent = None ) : <TAB>  u = set ( ) <TAB>  result = [ ] <TAB>  for s in [ <TAB><TAB>  self . __storage ( None ) , <TAB><TAB>  self . __storage ( self . __category ) , <TAB>  ] : <TAB><TAB>  for b in s : <TAB><TAB><TAB>  if persistent is not None and b . persistent != persistent : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if b . name not in u : <TAB><TAB><TAB><TAB>  result . append ( b . name ) <TAB><TAB><TAB><TAB>  u . add ( b . name ) <TAB>  return result ","if b . name . startswith ( ""__"" ) :",if b.name in u:,False,52.10484713001103,95.50547575236394
3093,"def _check_extra_specs ( key , value = None ) : <TAB>  extra_specs = diff . get ( "" extra_specs "" ) <TAB>  specific_type = extra_specs . get ( key ) if extra_specs else None <TAB>  old_type = None <TAB>  new_type = None <TAB>  if specific_type : <TAB><TAB>  old_type , new_type = specific_type <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  old_type = True if old_type and old_type . upper ( ) == value else False <TAB><TAB><TAB>  new_type = True if new_type and new_type . upper ( ) == value else False <TAB>  return old_type , new_type ",if value :,if value is not None:,False,44.53687865137478,97.45857998555691
3094,"def _write_lock_file ( self , repo , force = True ) :<TAB># type: (Repository, bool) -> None <TAB>  if force or ( self . _update and self . _write_lock ) : <TAB><TAB>  updated_lock = self . _locker . set_lock_data ( self . _package , repo . packages ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _io . write_line ( "" "" ) <TAB><TAB><TAB>  self . _io . write_line ( "" <info>Writing lock file</> "" ) ",if updated_lock :,if updated_lock:,False,42.708986237859335,96.80991184556267
3095,"def process_message ( self , msg ) : <TAB>  if msg [ "" type "" ] == "" sample "" : <TAB><TAB>  batch_shape = msg [ "" fn "" ] . batch_shape <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  batch_shape = [ 1 ] * ( - self . dim - len ( batch_shape ) ) + list ( batch_shape ) <TAB><TAB><TAB>  batch_shape [ self . dim ] = self . size <TAB><TAB><TAB>  msg [ "" fn "" ] = msg [ "" fn "" ] . expand ( torch . Size ( batch_shape ) ) ",if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size :,if len(batch_shape) > 1:,False,28.35923449730847,86.97548558496513
3096,"def _test_reducibility ( self ) : <TAB>  # make a copy of the graph <TAB>  graph = networkx . DiGraph ( self . _graph ) <TAB>  # preprocess: make it a super graph <TAB>  self . _make_supergraph ( graph ) <TAB>  while True : <TAB><TAB>  changed = False <TAB><TAB>  # find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode <TAB><TAB>  changed | = self . _remove_self_loop ( graph ) <TAB><TAB>  # find a node that has only one predecessor, and merge it with its predecessor (replace them with a <TAB><TAB>  # MultiNode) <TAB><TAB>  changed | = self . _merge_single_entry_node ( graph ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # a fixed-point is reached <TAB><TAB><TAB>  break ",if not changed :,if changed:,False,48.862555787343794,98.81027921616852
3097,"def __init__ ( self , roberta , num_classes = 2 , dropout = 0.0 , prefix = None , params = None ) : <TAB>  super ( RoBERTaClassifier , self ) . __init__ ( prefix = prefix , params = params ) <TAB>  self . roberta = roberta <TAB>  self . _units = roberta . _units <TAB>  with self . name_scope ( ) : <TAB><TAB>  self . classifier = nn . HybridSequential ( prefix = prefix ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB><TAB>  self . classifier . add ( nn . Dense ( units = self . _units , activation = "" tanh "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB><TAB>  self . classifier . add ( nn . Dense ( units = num_classes ) ) ",if dropout :,if self._units > 0:,False,28.31116391425057,94.7149434731522
3098,"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB>  if not name : <TAB><TAB>  return None <TAB>  name = name . rstrip ( "" \\ "" ) <TAB>  for a , o in self . objects . items ( ) : <TAB><TAB>  if not o . name : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return o <TAB>  if check_symlinks : <TAB><TAB>  m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB><TAB>  if m : <TAB><TAB><TAB>  name = m [ 0 ] <TAB><TAB>  return self . get_object_from_name ( name , False ) ",if o . name . lower ( ) == name . lower ( ) :,if a.name == name:,False,50.10396335331302,93.54936469971744
3099,"def __call__ ( self ) : <TAB>  """"""Run all check_* methods."""""" <TAB>  if self . on : <TAB><TAB>  oldformatwarning = warnings . formatwarning <TAB><TAB>  warnings . formatwarning = self . formatwarning <TAB><TAB>  try : <TAB><TAB><TAB>  for name in dir ( self ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  method = getattr ( self , name ) <TAB><TAB><TAB><TAB><TAB>  if method and callable ( method ) : <TAB><TAB><TAB><TAB><TAB><TAB>  method ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  warnings . formatwarning = oldformatwarning ","if name . startswith ( ""check_"" ) :",if name.startswith('check_'):,False,51.35991536264197,97.2819017296855
3100,"def __print__ ( self , defaults = False ) : <TAB>  if defaults : <TAB><TAB>  print_func = str <TAB>  else : <TAB><TAB>  print_func = repr <TAB>  pieces = [ ] <TAB>  default_values = self . __defaults__ <TAB>  for k in self . __fields__ : <TAB><TAB>  value = getattr ( self , k ) <TAB><TAB>  if not defaults and value == default_values [ k ] : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print_func = repr<TAB># keep quotes around strings <TAB><TAB>  pieces . append ( "" %s = %s "" % ( k , print_func ( value ) ) ) <TAB>  if pieces or self . __base__ : <TAB><TAB>  return "" %s ( %s ) "" % ( self . __class__ . __name__ , "" ,  "" . join ( pieces ) ) <TAB>  else : <TAB><TAB>  return "" "" ","if isinstance ( value , basestring ) :",if not k.startswith('_'):,False,25.398764827417857,94.71193081513474
3101,"def apply ( self , * * kwargs : Any ) - > None : <TAB>  for node in self . document . traverse ( nodes . target ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if ( <TAB><TAB><TAB>  "" ismod "" in node <TAB><TAB><TAB>  and node . parent . __class__ is nodes . section <TAB><TAB><TAB>  and <TAB><TAB><TAB>  # index 0 is the section title node <TAB><TAB><TAB>  node . parent . index ( node ) == 1 <TAB><TAB>  ) : <TAB><TAB><TAB>  node . parent [ "" ids "" ] [ 0 : 0 ] = node [ "" ids "" ] <TAB><TAB><TAB>  node . parent . remove ( node ) ","if not node [ ""ids"" ] :",if node.parent is None:,False,33.46114394475441,95.90103148996464
3102,"def add_special_token_2d ( <TAB>  values : List [ List [ int ] ] , special_token : int = 0 , use_first_value : bool = False  ) - > List [ List [ int ] ] : <TAB>  results = torch . jit . annotate ( List [ List [ int ] ] , [ ] ) <TAB>  for value in values : <TAB><TAB>  result = torch . jit . annotate ( List [ int ] , [ ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  special_token = value [ 0 ] <TAB><TAB>  result . append ( special_token ) <TAB><TAB>  result . extend ( value ) <TAB><TAB>  result . append ( special_token ) <TAB><TAB>  results . append ( result ) <TAB>  return results ",if use_first_value and len ( value ) > 0 :,if use_first_value:,False,33.96622819154664,95.58792306402881
3103,"def test_import ( self ) : <TAB>  TIMEOUT = 5 <TAB>  # Test for a deadlock when importing a module that runs the <TAB>  # ThreadedResolver at import-time. See resolve_test.py for <TAB>  # full explanation. <TAB>  command = [ sys . executable , "" -c "" , "" import tornado.test.resolve_test_helper "" ] <TAB>  start = time . time ( ) <TAB>  popen = Popen ( command , preexec_fn = lambda : signal . alarm ( TIMEOUT ) ) <TAB>  while time . time ( ) - start < TIMEOUT : <TAB><TAB>  return_code = popen . poll ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( 0 , return_code ) <TAB><TAB><TAB>  return<TAB># Success. <TAB><TAB>  time . sleep ( 0.05 ) <TAB>  self . fail ( "" import timed out "" ) ",if return_code is not None :,if return_code != 0:,False,60.249817018702345,95.73288269884826
3104,"def find_item_for_key ( self , e ) : <TAB>  for item in self . _items : <TAB><TAB>  if item . keycode == e . key and item . shift == e . shift and item . alt == e . alt : <TAB><TAB><TAB>  focus = get_focus ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return self . _items . index ( item ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return - 1 <TAB>  return - 1 ","if self . command_is_enabled ( item , focus ) :",if focus is not None:,False,22.48882826910697,88.81214311510645
3105,"def check_app_config_brackets ( self ) : <TAB>  for sn , app in cherrypy . tree . apps . items ( ) : <TAB><TAB>  if not isinstance ( app , cherrypy . Application ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for key in app . config . keys ( ) : <TAB><TAB><TAB>  if key . startswith ( "" [ "" ) or key . endswith ( "" ] "" ) : <TAB><TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB><TAB>  "" The application mounted at  %r  has config  "" <TAB><TAB><TAB><TAB><TAB>  "" section names with extraneous brackets:  %r .  "" <TAB><TAB><TAB><TAB><TAB>  "" Config *files* need brackets; config *dicts*  "" <TAB><TAB><TAB><TAB><TAB>  "" (e.g. passed to tree.mount) do not. "" % ( sn , key ) <TAB><TAB><TAB><TAB>  ) ",if not app . config :,"if not isinstance(app, cherrypy.Application):",False,59.405344640359736,96.69198786181929
3106,"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB>  for a in self . arbiters : <TAB><TAB>  # Do like the linkify will do after.... <TAB><TAB>  for m in getattr ( a , "" modules "" , [ ] ) : <TAB><TAB><TAB>  # So look at what the arbiter try to call as module <TAB><TAB><TAB>  m = m . strip ( ) <TAB><TAB><TAB>  # Ok, now look in modules... <TAB><TAB><TAB>  for mod in self . modules : <TAB><TAB><TAB><TAB>  # try to see if this module is the good type <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  # if so, the good name? <TAB><TAB><TAB><TAB><TAB>  if getattr ( mod , "" module_name "" , "" "" ) . strip ( ) == m : <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",if mod_type == mod.type:,False,66.6075469862183,91.41267186347629
3107,"def write_config_to_file ( self , folder , filename , config ) : <TAB>  do_not_write = [ "" hyperparameter_search_space_updates "" ] <TAB>  with open ( os . path . join ( folder , filename ) , "" w "" ) as f : <TAB><TAB>  f . write ( <TAB><TAB><TAB>  "" \n "" . join ( <TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB>  ( key + "" = "" + str ( value ) ) <TAB><TAB><TAB><TAB><TAB>  for ( key , value ) in sorted ( config . items ( ) , key = lambda x : x [ 0 ] ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ] <TAB><TAB><TAB>  ) <TAB><TAB>  ) ",if not key in do_not_write,if key not in do_not_write:,False,49.306149256856514,97.50099242452998
3108,"def parsing ( self , parsing ) :<TAB># type: (bool) -> None <TAB>  self . _parsed = parsing <TAB>  for k , v in self . _body : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v . value . parsing ( parsing ) <TAB><TAB>  elif isinstance ( v , AoT ) : <TAB><TAB><TAB>  for t in v . body : <TAB><TAB><TAB><TAB>  t . value . parsing ( parsing ) ","if isinstance ( v , Table ) :","if isinstance(v, T):",False,35.84864782420591,94.2022183857541
3109,"def test_crashers_crash ( self ) : <TAB>  for fname in glob . glob ( CRASHER_FILES ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # Some ""crashers"" only trigger an exception rather than a <TAB><TAB>  # segfault. Consider that an acceptable outcome. <TAB><TAB>  if test . support . verbose : <TAB><TAB><TAB>  print ( "" Checking crasher: "" , fname ) <TAB><TAB>  assert_python_failure ( fname ) ",if os . path . basename ( fname ) in infinite_loops :,if fname.startswith('crashers'):,False,59.422209802691484,90.47775810063814
3110,"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB>  if isinstance ( k , slice ) : <TAB><TAB>  if k . step is not None : <TAB><TAB><TAB>  raise ValueError ( "" Slices with strides are not supported "" ) <TAB><TAB>  elif k . start is None : <TAB><TAB><TAB>  raise ValueError ( "" Must specify start index "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Slices with stop index are not supported "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  addr = k . start <TAB>  elif self . _type is not None and self . _type . _can_refine_int : <TAB><TAB>  return self . _type . _refine ( self , k ) <TAB>  else : <TAB><TAB>  addr = k <TAB>  return self . _deeper ( addr = addr ) ",elif k . stop is not None :,if k.stop is not None:,False,57.19390080910796,98.8674372687216
3111,"def get_lowest_wall_time ( jsons ) : <TAB>  lowest_wall = None <TAB>  for j in jsons : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lowest_wall = j [ "" wall_time "" ] <TAB><TAB>  if lowest_wall > j [ "" wall_time "" ] : <TAB><TAB><TAB>  lowest_wall = j [ "" wall_time "" ] <TAB>  return lowest_wall ",if lowest_wall is None :,if j['wall_time'] is not None:,False,47.04937410939571,91.96725892368804
3112,"def extract_wav_headers ( data ) : <TAB>  # def search_subchunk(data, subchunk_id): <TAB>  pos = 12<TAB># The size of the RIFF chunk descriptor <TAB>  subchunks = [ ] <TAB>  while pos + 8 < = len ( data ) and len ( subchunks ) < 10 : <TAB><TAB>  subchunk_id = data [ pos : pos + 4 ] <TAB><TAB>  subchunk_size = struct . unpack_from ( "" <I "" , data [ pos + 4 : pos + 8 ] ) [ 0 ] <TAB><TAB>  subchunks . append ( WavSubChunk ( subchunk_id , pos , subchunk_size ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # 'data' is the last subchunk <TAB><TAB><TAB>  break <TAB><TAB>  pos + = subchunk_size + 8 <TAB>  return subchunks ","if subchunk_id == b""data"" :",if subchunk_size == 0:,False,34.82691296909557,95.43428322536708
3113,"def _any_targets_have_native_sources ( self , targets ) : <TAB>  # TODO(#5949): convert this to checking if the closure of python requirements has any <TAB>  # platform-specific packages (maybe find the platforms there too?). <TAB>  for tgt in targets : <TAB><TAB>  for type_constraint , target_predicate in self . _native_target_matchers . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,"if target_predicate(tgt, tgt):",False,44.98680139173764,90.30537328514347
3114,"def validate_memory ( self , value ) : <TAB>  for k , v in value . viewitems ( ) : <TAB><TAB>  if v is None :<TAB># use NoneType to unset a value <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB><TAB>  if not re . match ( MEMLIMIT_MATCH , str ( v ) ) : <TAB><TAB><TAB>  raise serializers . ValidationError ( <TAB><TAB><TAB><TAB>  "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB><TAB><TAB>  ) <TAB>  return value ","if not re . match ( PROCTYPE_MATCH , k ) :",if k.startswith('a-z'):,False,36.22929923009182,93.14770905836238
3115,"def cart_number_checksum_validation ( cls , number ) : <TAB>  digits = [ ] <TAB>  even = False <TAB>  if not number . isdigit ( ) : <TAB><TAB>  return False <TAB>  for digit in reversed ( number ) : <TAB><TAB>  digit = ord ( digit ) - ord ( "" 0 "" ) <TAB><TAB>  if even : <TAB><TAB><TAB>  digit * = 2 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  digit = digit % 10 + digit / / 10 <TAB><TAB>  digits . append ( digit ) <TAB><TAB>  even = not even <TAB>  return sum ( digits ) % 10 == 0 if digits else False ",if digit >= 10 :,if digit % 10 == 0:,False,41.68072261810495,96.54877965236489
3116,"def transform ( a , cmds ) : <TAB>  buf = a . split ( "" \n "" ) <TAB>  for cmd in cmds : <TAB><TAB>  ctype , line , col , char = cmd <TAB><TAB>  if ctype == "" D "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB><TAB><TAB><TAB>  del buf [ line + 1 ] <TAB><TAB>  elif ctype == "" I "" : <TAB><TAB><TAB>  buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB><TAB>  buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB>  return "" \n "" . join ( buf ) ","if char != ""\n"" :","if char == ""Z':",False,11.713233211553348,97.373949493256
3117,"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB>  partners = { }<TAB># type: Dict[AbstractNode, Set[int]] <TAB>  for edge in self . edges : <TAB><TAB>  if edge . is_dangling ( ) : <TAB><TAB><TAB>  raise ValueError ( "" Cannot contract copy tensor with dangling edges "" ) <TAB><TAB>  if self . _is_my_trace ( edge ) : <TAB><TAB><TAB>  continue <TAB><TAB>  partner_node , shared_axis = self . _get_partner ( edge ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  partners [ partner_node ] = set ( ) <TAB><TAB>  partners [ partner_node ] . add ( shared_axis ) <TAB>  return partners ",if partner_node not in partners :,if partner_node not in partners:,False,15.479947553420203,97.6931116171903
3118,"def _bind_interactive_rez ( self ) : <TAB>  if config . set_prompt and self . settings . prompt : <TAB><TAB>  stored_prompt = os . getenv ( "" REZ_STORED_PROMPT_CMD "" ) <TAB><TAB>  curr_prompt = stored_prompt or os . getenv ( "" PROMPT "" , "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . setenv ( "" REZ_STORED_PROMPT_CMD "" , curr_prompt ) <TAB><TAB>  new_prompt = "" %% REZ_ENV_PROMPT %% "" <TAB><TAB>  new_prompt = ( <TAB><TAB><TAB>  ( new_prompt + "" %s "" ) if config . prefix_prompt else ( "" %s "" + new_prompt ) <TAB><TAB>  ) <TAB><TAB>  new_prompt = new_prompt % curr_prompt <TAB><TAB>  self . _addline ( "" set PROMPT= %s "" % new_prompt ) ",if not stored_prompt :,if curr_prompt != None:,False,26.85661092809635,97.06383231412663
3119,"def __listingColumns ( self ) : <TAB>  columns = [ ] <TAB>  for name in self . __getColumns ( ) : <TAB><TAB>  definition = column ( name ) <TAB><TAB>  if not definition : <TAB><TAB><TAB>  IECore . msg ( <TAB><TAB><TAB><TAB>  IECore . Msg . Level . Error , <TAB><TAB><TAB><TAB>  "" GafferImageUI.CatalogueUI "" , <TAB><TAB><TAB><TAB>  "" No column registered with name  ' %s ' "" % name , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB><TAB>  else : <TAB><TAB><TAB>  c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB><TAB>  columns . append ( c ) <TAB>  return columns ","if isinstance ( definition , IconColumn ) :",if definition.icon:,False,30.358721245499453,95.88490159755607
3120,"def _check_invalid_keys ( self , section_name , section ) : <TAB>  for key in section : <TAB><TAB>  key_name = str ( key ) <TAB><TAB>  valid_key_names = [ s [ 0 ] for s in self . keys ] <TAB><TAB>  is_valid_key = key_name in valid_key_names <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  err_msg = ( <TAB><TAB><TAB><TAB>  "" ' {0} '  is not a valid key name for  ' {1} ' . Must  "" "" be one of these:  {2} "" <TAB><TAB><TAB>  ) . format ( key_name , section_name , "" ,  "" . join ( valid_key_names ) ) <TAB><TAB><TAB>  raise InvalidConfig ( err_msg ) ",if not is_valid_key :,if not is_valid_key:,False,59.38621903883903,100.00000000000004
3121,"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB>  names = set ( ) <TAB>  for path in lib_path . iterdir ( ) : <TAB><TAB>  name = path . name <TAB><TAB>  if name == "" __pycache__ "" : <TAB><TAB><TAB>  continue <TAB><TAB>  if name . endswith ( "" .py "" ) : <TAB><TAB><TAB>  names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  names . add ( name ) <TAB>  if packages : <TAB><TAB>  packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB><TAB>  if len ( names & packages ) == len ( packages ) : <TAB><TAB><TAB>  return packages <TAB>  return names ","elif path . is_dir ( ) and ""."" not in name :",if name not in names:,False,49.4870147383441,93.28891781601304
3122,"def sortkeypicker ( keynames ) : <TAB>  negate = set ( ) <TAB>  for i , k in enumerate ( keynames ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  keynames [ i ] = k [ 1 : ] <TAB><TAB><TAB>  negate . add ( k [ 1 : ] ) <TAB>  def getit ( adict ) : <TAB><TAB>  composite = [ adict [ k ] for k in keynames ] <TAB><TAB>  for i , ( k , v ) in enumerate ( zip ( keynames , composite ) ) : <TAB><TAB><TAB>  if k in negate : <TAB><TAB><TAB><TAB>  composite [ i ] = - v <TAB><TAB>  return composite <TAB>  return getit ","if k [ : 1 ] == ""-"" :",if k.startswith('-'):,False,45.8278651100943,92.83598404050736
3123,"def iter_symbols ( code ) : <TAB>  """"""Yield names and strings used by `code` and its nested code objects"""""" <TAB>  for name in code . co_names : <TAB><TAB>  yield name <TAB>  for const in code . co_consts : <TAB><TAB>  if isinstance ( const , six . string_types ) : <TAB><TAB><TAB>  yield const <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for name in iter_symbols ( const ) : <TAB><TAB><TAB><TAB>  yield name ","elif isinstance ( const , CodeType ) :","if isinstance(const, (six.string_types, six.string_types))",False,33.967642354853126,88.01448038323355
3124,"def set_study_directions ( <TAB>  self , study_id : int , directions : Sequence [ StudyDirection ]  ) - > None : <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  current_directions = self . _studies [ study_id ] . directions <TAB><TAB><TAB>  if directions == current_directions : <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  elif ( <TAB><TAB><TAB><TAB>  len ( current_directions ) == 1 <TAB><TAB><TAB><TAB>  and current_directions [ 0 ] == StudyDirection . NOT_SET <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  self . _studies [ study_id ] . directions = list ( directions ) <TAB><TAB><TAB><TAB>  self . _backend . set_study_directions ( study_id , directions ) <TAB><TAB><TAB><TAB>  return <TAB>  self . _backend . set_study_directions ( study_id , directions ) ",if study_id in self . _studies :,if study_id in self._studies:,False,49.967302179291,100.00000000000004
3125,"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB>  while self : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = 1 <TAB><TAB>  elif not IfList : <TAB><TAB><TAB>  if self < = 2 : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  RegionSizeGuid = 3 <TAB><TAB><TAB>  if not RegionSizeGuid : <TAB><TAB><TAB><TAB>  RegionLayoutLine = 5 <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  RegionLayoutLine = self . CurrentLineNumber <TAB>  return 1 ",if self . __Token :,if self <= 1:,False,47.291340991299,96.31649739402559
3126,"def _check_blocking ( self , current_time ) : <TAB>  if self . _switch_flag is False : <TAB><TAB>  active_greenlet = self . _active_greenlet <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _notify_greenlet_blocked ( active_greenlet , current_time ) <TAB>  self . _switch_flag = False ",if active_greenlet is not None and active_greenlet != self . _hub :,if active_greenlet is not None:,False,20.914660329668585,88.31234139749556
3127,"def detect ( get_page ) : <TAB>  retval = False <TAB>  for vector in WAF_ATTACK_VECTORS : <TAB><TAB>  page , headers , code = get_page ( get = vector ) <TAB><TAB>  retval = ( <TAB><TAB><TAB>  re . search ( r "" BlockDos \ .net "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB><TAB><TAB>  is not None <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return retval ",if retval :,if retval:,False,19.58685132745426,100.00000000000004
3128,"def _fastqc_data_section ( self , section_name ) : <TAB>  out = [ ] <TAB>  in_section = False <TAB>  data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB>  if os . path . exists ( data_file ) : <TAB><TAB>  with open ( data_file ) as in_handle : <TAB><TAB><TAB>  for line in in_handle : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  in_section = True <TAB><TAB><TAB><TAB>  elif in_section : <TAB><TAB><TAB><TAB><TAB>  if line . startswith ( "" >>END "" ) : <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB><TAB>  out . append ( line . rstrip ( "" \r \n "" ) ) <TAB>  return out ","if line . startswith ( "">>%s"" % section_name ) :",if section_name == line:,False,21.72476190442972,94.08293489729814
3129,"def shortcut ( self , input , ch_out , stride , is_first , name ) : <TAB>  ch_in = input . shape [ 1 ] <TAB>  if ch_in != ch_out or stride != 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB><TAB>  else : <TAB><TAB><TAB>  return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB>  elif is_first : <TAB><TAB>  return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB>  else : <TAB><TAB>  return input ",if is_first or stride == 1 :,if is_first:,False,52.957992265134266,96.55075760140123
3130,"def get_value_from_string ( self , string_value ) : <TAB>  """"""Return internal representation starting from CFN/user-input value."""""" <TAB>  param_value = self . get_default_value ( ) <TAB>  try : <TAB><TAB>  if string_value is not None : <TAB><TAB><TAB>  string_value = str ( string_value ) . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  param_value = int ( string_value ) <TAB>  except ValueError : <TAB><TAB>  self . pcluster_config . warn ( <TAB><TAB><TAB>  "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB><TAB><TAB>  "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB><TAB>  ) <TAB>  return param_value ","if string_value != ""NONE"" :",if param_value is None:,False,52.74805984087063,96.07671065995395
3131,"def get_running ( workers ) : <TAB>  running = [ ] <TAB>  for worker in workers : <TAB><TAB>  current_test_name = worker . current_test_name <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  dt = time . monotonic ( ) - worker . start_time <TAB><TAB>  if dt > = PROGRESS_MIN_TIME : <TAB><TAB><TAB>  text = "" %s  ( %s ) "" % ( current_test_name , format_duration ( dt ) ) <TAB><TAB><TAB>  running . append ( text ) <TAB>  return running ",if not current_test_name :,if current_test_name == worker.test_name:,False,26.370232965631303,94.66279065804086
3132,"def generate_data ( self , request ) : <TAB>  """"""Generate data for the widget."""""" <TAB>  uptime = { } <TAB>  cache_stats = get_cache_stats ( ) <TAB>  if cache_stats : <TAB><TAB>  for hosts , stats in cache_stats : <TAB><TAB><TAB>  if stats [ "" uptime "" ] > 86400 : <TAB><TAB><TAB><TAB>  uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB><TAB><TAB><TAB>  uptime [ "" unit "" ] = _ ( "" days "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB><TAB><TAB><TAB>  uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB><TAB><TAB><TAB>  uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB>  return { "" cache_stats "" : cache_stats , "" uptime "" : uptime } ","elif stats [ ""uptime"" ] > 3600 :",if hosts:,False,33.536269553713566,96.47655782885884
3133,"def add_actors ( self ) : <TAB>  """"""Adds `self.actors` to the scene."""""" <TAB>  if not self . _actors_added : <TAB><TAB>  self . reader . render_window = self . scene . render_window <TAB><TAB>  self . _update_reader ( ) <TAB><TAB>  self . _actors_added = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _visible_changed ( self . visible ) <TAB><TAB>  self . scene . render ( ) ",if not self . visible :,if self.visible:,False,23.777529519642293,98.09339541107626
3134,"def _add_uniqu_suffix ( self , titles ) : <TAB>  counters = dict ( ) <TAB>  titles_with_suffix = [ ] <TAB>  for title in titles : <TAB><TAB>  counters [ title ] = counters [ title ] + 1 if title in counters else 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  title = f "" { title }  ( { counters [ title ] } ) "" <TAB><TAB>  titles_with_suffix . append ( title ) <TAB>  return titles_with_suffix ",if counters [ title ] > 1 :,if title in counters:,False,32.9541908696916,94.39713637543647
3135,"def _verify_udf_resources ( self , job , config ) : <TAB>  udf_resources = config . get ( "" userDefinedFunctionResources "" , ( ) ) <TAB>  self . assertEqual ( len ( job . udf_resources ) , len ( udf_resources ) ) <TAB>  for found , expected in zip ( job . udf_resources , udf_resources ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( found . udf_type , "" resourceUri "" ) <TAB><TAB><TAB>  self . assertEqual ( found . value , expected [ "" resourceUri "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( found . udf_type , "" inlineCode "" ) <TAB><TAB><TAB>  self . assertEqual ( found . value , expected [ "" inlineCode "" ] ) ","if ""resourceUri"" in expected :",if found.udf_type == 'resource':,False,49.065158190974515,95.08500422690449
3136,"def __init__ ( <TAB>  self , layout , value = None , string = None , * , dtype : np . dtype = np . float64  ) - > None : <TAB>  """"""Constructor."""""" <TAB>  self . layout = layout <TAB>  if value is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . value = layout . parse_multivector ( string ) . value <TAB>  else : <TAB><TAB>  self . value = np . array ( value ) <TAB><TAB>  if self . value . shape != ( self . layout . gaDims , ) : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB><TAB><TAB>  ) ",if string is None :,if string is None:,False,54.52989399750731,100.00000000000004
3137,"def read_file ( filename , print_error = True ) : <TAB>  """"""Returns the contents of a file."""""" <TAB>  try : <TAB><TAB>  for encoding in [ "" utf-8 "" , "" latin1 "" ] : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  with io . open ( filename , encoding = encoding ) as fp : <TAB><TAB><TAB><TAB><TAB>  return fp . read ( ) <TAB><TAB><TAB>  except UnicodeDecodeError : <TAB><TAB><TAB><TAB>  pass <TAB>  except IOError as exception : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( exception , file = sys . stderr ) <TAB><TAB>  return None ",if print_error :,if print_error:,False,54.94773645136499,100.00000000000004
3138,"def get_albums_for_iter ( self , iter_ ) : <TAB>  obj = self . get_value ( iter_ ) <TAB>  if isinstance ( obj , AlbumNode ) : <TAB><TAB>  return { obj . album } <TAB>  albums = set ( ) <TAB>  for child_iter , value in self . iterrows ( iter_ ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  albums . add ( value . album ) <TAB><TAB>  else : <TAB><TAB><TAB>  albums . update ( self . get_albums_for_iter ( child_iter ) ) <TAB>  return albums ","if isinstance ( value , AlbumNode ) :","if isinstance(value, AlbumNode):",False,51.07168470788317,100.00000000000004
3139,"def wait_til_ready ( cls , connector = None ) : <TAB>  if connector is None : <TAB><TAB>  connector = cls . connector <TAB>  while True : <TAB><TAB>  now = time . time ( ) <TAB><TAB>  next_iteration = now / / 1.0 + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  await cls . _clock . run_til ( next_iteration ) <TAB><TAB>  await asyncio . sleep ( 1.0 ) ",if connector . ready :,if next_iteration == 0:,False,23.186108253952245,94.41241550034678
3140,"def remove_property ( self , key ) :<TAB># type: (str) -> None <TAB>  with self . secure ( ) as config : <TAB><TAB>  keys = key . split ( "" . "" ) <TAB><TAB>  current_config = config <TAB><TAB>  for i , key in enumerate ( keys ) : <TAB><TAB><TAB>  if key not in current_config : <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del current_config [ key ] <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  current_config = current_config [ key ] ",if i == len ( keys ) - 1 :,if i == len(keys):,False,10.921746802721612,96.54445137227178
3141,"def get ( self , hash160 , default = None ) : <TAB>  v = self . p2s_for_hash ( hash160 ) <TAB>  <IF-STMT>: <TAB><TAB>  return v <TAB>  if hash160 not in self . _secret_exponent_cache : <TAB><TAB>  v = self . path_for_hash160 ( hash160 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fingerprint , path = v <TAB><TAB><TAB>  for key in self . _secrets . get ( fingerprint , [ ] ) : <TAB><TAB><TAB><TAB>  subkey = key . subkey_for_path ( path ) <TAB><TAB><TAB><TAB>  self . _add_key_to_cache ( subkey ) <TAB>  return self . _secret_exponent_cache . get ( hash160 , default ) ",if v :,if v is not default:,False,33.23265006587101,95.33466966078052
3142,"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB>  self . fetchstatuslogger = fetchstatuslogger <TAB>  if targets != None : <TAB><TAB>  # Ensure targets is a tuple <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  targets = tuple ( <TAB><TAB><TAB><TAB>  targets , <TAB><TAB><TAB>  ) <TAB><TAB>  elif type ( targets ) != tuple : <TAB><TAB><TAB>  targets = tuple ( targets ) <TAB>  for target in targets : <TAB><TAB>  self . _fetch_targets ( api_client , q , target ) ",if type ( targets ) != list and type ( targets ) != tuple :,if type(targets) == tuple:,False,53.810811940795446,93.68529697701058
3143,"def dgl_mp_batchify_fn ( data ) : <TAB>  if isinstance ( data [ 0 ] , tuple ) : <TAB><TAB>  data = zip ( * data ) <TAB><TAB>  return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB>  for dt in data : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( dt , dgl . DGLGraph ) : <TAB><TAB><TAB><TAB>  return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB><TAB><TAB>  elif isinstance ( dt , nd . NDArray ) : <TAB><TAB><TAB><TAB>  pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB><TAB><TAB><TAB>  data_list = [ dt for dt in data if dt is not None ] <TAB><TAB><TAB><TAB>  return pad ( data_list ) ",if dt is not None :,"if isinstance(dt, dgl.DGLGraph):",False,58.73007240946806,96.0502097627381
3144,"def capture_server ( evt , buf , serv ) : <TAB>  try : <TAB><TAB>  serv . listen ( 5 ) <TAB><TAB>  conn , addr = serv . accept ( ) <TAB>  except socket . timeout : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  n = 200 <TAB><TAB>  while n > 0 : <TAB><TAB><TAB>  r , w , e = select . select ( [ conn ] , [ ] , [ ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data = conn . recv ( 10 ) <TAB><TAB><TAB><TAB>  # keep everything except for the newline terminator <TAB><TAB><TAB><TAB>  buf . write ( data . replace ( "" \n "" , "" "" ) ) <TAB><TAB><TAB><TAB>  if "" \n "" in data : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  n - = 1 <TAB><TAB><TAB>  time . sleep ( 0.01 ) <TAB><TAB>  conn . close ( ) <TAB>  finally : <TAB><TAB>  serv . close ( ) <TAB><TAB>  evt . set ( ) ",if r :,if r:,False,56.092697452331194,100.00000000000004
3145,"def elem ( ) : <TAB>  if ints_only : <TAB><TAB>  return random . randint ( 0 , 10000000000 ) <TAB>  else : <TAB><TAB>  t = random . randint ( 0 , 2 ) <TAB><TAB>  if t == 0 : <TAB><TAB><TAB>  return random . randint ( 0 , 10000000000 ) <TAB><TAB>  elif t == 1 : <TAB><TAB><TAB>  return float ( random . randint ( 0 , 10000000000 ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return strings [ random . randint ( 0 , len ( strings ) - 1 ) ] <TAB><TAB>  return random_string ( random . randint ( 100 , 1000 ) ) ",elif strings is not None :,if len(strings) > 1:,False,49.2131123327191,95.15127835031892
3146,"def has_changed ( self , initial , data ) : <TAB>  if self . disabled : <TAB><TAB>  return False <TAB>  if initial is None : <TAB><TAB>  initial = [ "" "" for x in range ( 0 , len ( data ) ) ] <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  initial = self . widget . decompress ( initial ) <TAB>  for field , initial , data in zip ( self . fields , initial , data ) : <TAB><TAB>  try : <TAB><TAB><TAB>  initial = field . to_python ( initial ) <TAB><TAB>  except ValidationError : <TAB><TAB><TAB>  return True <TAB><TAB>  if field . has_changed ( initial , data ) : <TAB><TAB><TAB>  return True <TAB>  return False ","if not isinstance ( initial , list ) :","if isinstance(initial, str):",False,23.204745216214437,97.48323208193169
3147,"def _load_testfile ( filename , package , module_relative ) : <TAB>  if module_relative : <TAB><TAB>  package = _normalize_module ( package , 3 ) <TAB><TAB>  filename = _module_relative_path ( package , filename ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if hasattr ( package . __loader__ , "" get_data "" ) : <TAB><TAB><TAB><TAB>  file_contents = package . __loader__ . get_data ( filename ) <TAB><TAB><TAB><TAB>  # get_data() opens files as 'rb', so one must do the equivalent <TAB><TAB><TAB><TAB>  # conversion as universal newlines would do. <TAB><TAB><TAB><TAB>  return file_contents . replace ( os . linesep , "" \n "" ) , filename <TAB>  return open ( filename ) . read ( ) , filename ","if hasattr ( package , ""__loader__"" ) :",if filename.endswith('.py'):,False,46.23906459001441,94.60606756453383
3148,"def release ( self ) : <TAB>  tid = _thread . get_ident ( ) <TAB>  with self . lock : <TAB><TAB>  if self . owner != tid : <TAB><TAB><TAB>  raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB><TAB>  assert self . count > 0 <TAB><TAB>  self . count - = 1 <TAB><TAB>  if self . count == 0 : <TAB><TAB><TAB>  self . owner = None <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . waiters - = 1 <TAB><TAB><TAB><TAB>  self . wakeup . release ( ) ",if self . waiters :,if self.waiters > 0:,False,29.77361527418284,97.85205742012955
3149,"def stage ( <TAB>  self , x , num_modules , num_blocks , channels , multi_scale_output = True , name = None  ) : <TAB>  out = x <TAB>  for i in range ( num_modules ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out = self . high_resolution_module ( <TAB><TAB><TAB><TAB>  out , <TAB><TAB><TAB><TAB>  num_blocks , <TAB><TAB><TAB><TAB>  channels , <TAB><TAB><TAB><TAB>  multi_scale_output = False , <TAB><TAB><TAB><TAB>  name = name + "" _ "" + str ( i + 1 ) , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  out = self . high_resolution_module ( <TAB><TAB><TAB><TAB>  out , num_blocks , channels , name = name + "" _ "" + str ( i + 1 ) <TAB><TAB><TAB>  ) <TAB>  return out ",if i == num_modules - 1 and multi_scale_output == False :,if multi_scale_output:,False,47.16652594039702,94.39507587808517
3150,"def changeFrontAlteration ( intV , alter ) : <TAB>  # fati = front alteration transpose interval <TAB>  fati = self . frontAlterationTransposeInterval <TAB>  if fati : <TAB><TAB>  newFati = interval . add ( [ fati , intV ] ) <TAB><TAB>  self . frontAlterationTransposeInterval = newFati <TAB><TAB>  self . frontAlterationAccidental . alter = ( <TAB><TAB><TAB>  self . frontAlterationAccidental . alter + alter <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . frontAlterationTransposeInterval = None <TAB><TAB><TAB>  self . frontAlterationAccidental = None <TAB>  else : <TAB><TAB>  self . frontAlterationTransposeInterval = intV <TAB><TAB>  self . frontAlterationAccidental = pitch . Accidental ( alter ) ",if self . frontAlterationAccidental . alter == 0 :,if intV == 0:,False,29.851423228420465,96.19660883587815
3151,"def set_to_train ( self ) : <TAB>  for T in self . trainable_attributes ( ) : <TAB><TAB>  for k , v in T . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  c_f . set_requires_grad ( v , requires_grad = False ) <TAB><TAB><TAB><TAB>  v . eval ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  v . train ( ) <TAB>  self . maybe_freeze_trunk_batchnorm ( ) ",if k in self . freeze_these :,if k == 'train':,False,24.423207704709966,94.87121697383068
3152,"def _migrate ( self , sig = None , compact = True ) : <TAB>  with self . lock : <TAB><TAB>  sig = sig or self . sig <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  if sig in self . WORDS and len ( self . WORDS [ sig ] ) > 0 : <TAB><TAB><TAB>  PostingList . Append ( <TAB><TAB><TAB><TAB>  self . session , sig , self . WORDS [ sig ] , sig = sig , compact = compact <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  del self . WORDS [ sig ] ",if sig in GPL_NEVER_MIGRATE :,if sig is None:,False,35.493587653948026,95.16061230005548
3153,"def on_prediction_step ( self , args , state , control , eval_dataloader = None , * * kwargs ) : <TAB>  if self . prediction_bar is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . prediction_bar = self . training_tracker . add_child ( len ( eval_dataloader ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . prediction_bar = NotebookProgressBar ( len ( eval_dataloader ) ) <TAB><TAB>  self . prediction_bar . update ( 1 ) <TAB>  else : <TAB><TAB>  self . prediction_bar . update ( self . prediction_bar . value + 1 ) ",if self . training_tracker is not None :,if eval_dataloader:,False,41.62449560359323,94.24277292831651
3154,"def show ( self , indent = 0 ) : <TAB>  """"""Pretty print this structure."""""" <TAB>  if indent == 0 : <TAB><TAB>  print ( "" struct  {} "" . format ( self . name ) ) <TAB>  for field in self . fields : <TAB><TAB>  if field . offset is None : <TAB><TAB><TAB>  offset = "" 0x?? "" <TAB><TAB>  else : <TAB><TAB><TAB>  offset = "" 0x {:02x} "" . format ( field . offset ) <TAB><TAB>  print ( "" {} + {} {} {} "" . format ( "" "" * indent , offset , field . name , field . type ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field . type . show ( indent + 1 ) ","if isinstance ( field . type , Structure ) :","if hasattr(field, 'type'):",False,28.79369426318007,96.19133502537768
3155,"def __exit__ ( self , exc , value , tb ) : <TAB>  for key in self . overrides . keys ( ) : <TAB><TAB>  old_value = self . old [ key ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  delattr ( self . instance , key ) <TAB><TAB>  else : <TAB><TAB><TAB>  setattr ( self . instance , key , old_value ) <TAB>  self . instance . save ( ) ",if old_value is NULL :,if old_value is None:,False,46.62073589979341,97.78225290627776
3156,"def complete ( self , block ) : <TAB>  with self . _condition : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  if self . _complete ( ) : <TAB><TAB><TAB>  self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  if block : <TAB><TAB><TAB>  self . _condition . wait_for ( self . _complete ) <TAB><TAB><TAB>  self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  return False ",if not self . _final :,if self._state_root is None:,False,22.27046707001997,95.34449388857794
3157,"def parseArguments ( self ) : <TAB>  args = [ ] <TAB>  self . expect ( "" ( "" ) <TAB>  if not self . match ( "" ) "" ) : <TAB><TAB>  while self . startIndex < self . length : <TAB><TAB><TAB>  args . append ( self . isolateCoverGrammar ( self . parseAssignmentExpression ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  self . expectCommaSeparator ( ) <TAB>  self . expect ( "" ) "" ) <TAB>  return args ","if self . match ( "")"" ) :",if self.startIndex >= self.length:,False,49.09696767090907,94.4537433527644
3158,"def isValidDateString ( config_param_name , value , valid_value ) : <TAB>  try : <TAB><TAB>  if value == "" DD-MM-YYYY "" : <TAB><TAB><TAB>  return value <TAB><TAB>  day , month , year = value . split ( "" - "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  if int ( month ) < 1 or int ( month ) > 12 : <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  if int ( year ) < 1900 or int ( year ) > 2013 : <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  return value <TAB>  except Exception : <TAB><TAB>  raise DateStringValueError ( config_param_name , value ) ",if int ( day ) < 1 or int ( day ) > 31 :,if day == 0 or day > 12:,False,24.95168242458347,93.79729344647616
3159,"def build_tree ( path ) : <TAB>  tree = Tree ( ) <TAB>  for basename , entry in trees [ path ] . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mode = stat . S_IFDIR <TAB><TAB><TAB>  sha = build_tree ( pathjoin ( path , basename ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  ( mode , sha ) = entry <TAB><TAB>  tree . add ( basename , mode , sha ) <TAB>  object_store . add_object ( tree ) <TAB>  return tree . id ","if isinstance ( entry , dict ) :",if basename == path:,False,47.0999233876378,94.7683377215381
3160,"def get_quarantine_count ( self ) : <TAB>  """"""get obj/container/account quarantine counts"""""" <TAB>  qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB>  qdir = "" quarantined "" <TAB>  for device in os . listdir ( self . devices ) : <TAB><TAB>  for qtype in qcounts : <TAB><TAB><TAB>  qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  linkcount = os . lstat ( qtgt ) . st_nlink <TAB><TAB><TAB><TAB>  if linkcount > 2 : <TAB><TAB><TAB><TAB><TAB>  qcounts [ qtype ] + = linkcount - 2 <TAB>  return qcounts ",if os . path . exists ( qtgt ) :,if os.path.exists(qtgt):,False,47.78728363646748,100.00000000000004
3161,"def _is_static_shape ( self , shape ) : <TAB>  if shape is None or not isinstance ( shape , list ) : <TAB><TAB>  return False <TAB>  for dim_value in shape : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  if dim_value < 0 : <TAB><TAB><TAB>  raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB>  return True ","if not isinstance ( dim_value , int ) :",if dim_value > 1:,False,29.546555570746513,92.28718029292372
3162,"def BraceDetectAll ( words ) : <TAB>  # type: (List[compound_word]) -> List[word_t] <TAB>  """"""Return a new list of words, possibly with BracedTree instances."""""" <TAB>  out = [ ]<TAB># type: List[word_t] <TAB>  for w in words : <TAB><TAB>  # The shortest possible brace expansion is {,}.  This heuristic prevents <TAB><TAB>  # a lot of garbage from being created, since otherwise nearly every word <TAB><TAB>  # would be checked.  We could be even more precise but this is cheap. <TAB><TAB>  if len ( w . parts ) > = 3 : <TAB><TAB><TAB>  brace_tree = _BraceDetect ( w ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  out . append ( brace_tree ) <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  out . append ( w ) <TAB>  return out ",if brace_tree :,if brace_tree is not None:,False,47.60500286979422,96.21719440583328
3163,"def __init__ ( original , self , * args , * * kwargs ) : <TAB>  data = args [ 0 ] if len ( args ) > 0 else kwargs . get ( "" data "" ) <TAB>  if data is not None : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB><TAB>  "" cannot gather example input when dataset is loaded from a file. "" <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  input_example_info = _InputExampleInfo ( <TAB><TAB><TAB><TAB>  input_example = deepcopy ( data [ : INPUT_EXAMPLE_SAMPLE_ROWS ] ) <TAB><TAB><TAB>  ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  input_example_info = _InputExampleInfo ( error_msg = str ( e ) ) <TAB><TAB>  setattr ( self , "" input_example_info "" , input_example_info ) <TAB>  original ( self , * args , * * kwargs ) ","if isinstance ( data , str ) :",if data is None:,False,53.9667635919588,97.28580477587984
3164,"def setRow ( self , row , vals ) : <TAB>  if row > self . rowCount ( ) - 1 : <TAB><TAB>  self . setRowCount ( row + 1 ) <TAB>  for col in range ( len ( vals ) ) : <TAB><TAB>  val = vals [ col ] <TAB><TAB>  item = self . itemClass ( val , row ) <TAB><TAB>  item . setEditable ( self . editable ) <TAB><TAB>  sortMode = self . sortModes . get ( col , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  item . setSortMode ( sortMode ) <TAB><TAB>  format = self . _formats . get ( col , self . _formats [ None ] ) <TAB><TAB>  item . setFormat ( format ) <TAB><TAB>  self . items . append ( item ) <TAB><TAB>  self . setItem ( row , col , item ) <TAB><TAB>  item . setValue ( val )<TAB># Required--the text-change callback is invoked ",if sortMode is not None :,if sortMode is not None:,False,36.49719580319756,98.00062233445554
3165,"def wakeUp ( self ) : <TAB>  """"""Write one byte to the pipe, and flush it."""""" <TAB>  # We don't use fdesc.writeToFD since we need to distinguish <TAB>  # between EINTR (try again) and EAGAIN (do nothing). <TAB>  if self . o is not None : <TAB><TAB>  try : <TAB><TAB><TAB>  util . untilConcludes ( os . write , self . o , b "" x "" ) <TAB><TAB>  except OSError as e : <TAB><TAB><TAB>  # XXX There is no unit test for raising the exception <TAB><TAB><TAB>  # for other errnos. See #4285. <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ",if e . errno != errno . EAGAIN :,if e.errno == errno.EAGAIN:,False,71.26369076192421,98.62437671704521
3166,"def _setup ( self , field_name , owner_model ) : <TAB>  # Resolve possible name-based model references. <TAB>  resolved_classes = [ ] <TAB>  for m in self . model_classes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if m == owner_model . __name__ : <TAB><TAB><TAB><TAB>  resolved_classes . append ( owner_model ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB><TAB>  "" PolyModelType: Unable to resolve model  ' {} ' . "" . format ( m ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  resolved_classes . append ( m ) <TAB>  self . model_classes = tuple ( resolved_classes ) <TAB>  super ( PolyModelType , self ) . _setup ( field_name , owner_model ) ","if isinstance ( m , string_type ) :","if isinstance(m, models.Model):",False,31.687341447893353,98.1098057555842
3167,"def _wrap_forwarded ( self , key , value ) : <TAB>  if isinstance ( value , SourceCode ) and value . late_binding : <TAB><TAB>  # get cached return value if present <TAB><TAB>  value_ = self . _late_binding_returnvalues . get ( key , KeyError ) <TAB><TAB>  if value_ is KeyError : <TAB><TAB><TAB>  # evaluate the late-bound function <TAB><TAB><TAB>  value_ = self . _eval_late_binding ( value ) <TAB><TAB><TAB>  schema = self . late_bind_schemas . get ( key ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value_ = schema . validate ( value_ ) <TAB><TAB><TAB>  # cache result of late bound func <TAB><TAB><TAB>  self . _late_binding_returnvalues [ key ] = value_ <TAB><TAB>  return value_ <TAB>  else : <TAB><TAB>  return value ",if schema is not None :,if schema is not None:,False,58.57694059614834,100.00000000000004
3168,"def convert ( self , ctx , argument ) : <TAB>  arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB>  if arg [ 0 ] == "" # "" : <TAB><TAB>  arg = arg [ 1 : ] <TAB>  try : <TAB><TAB>  value = int ( arg , base = 16 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise BadColourArgument ( arg ) <TAB><TAB>  return discord . Colour ( value = value ) <TAB>  except ValueError : <TAB><TAB>  arg = arg . replace ( "" "" , "" _ "" ) <TAB><TAB>  method = getattr ( discord . Colour , arg , None ) <TAB><TAB>  if arg . startswith ( "" from_ "" ) or method is None or not inspect . ismethod ( method ) : <TAB><TAB><TAB>  raise BadColourArgument ( arg ) <TAB><TAB>  return method ( ) ",if not ( 0 <= value <= 0xFFFFFF ) :,if value < 0 or value > 255:,False,27.011593269772305,95.2052021368115
3169,"def get_versions ( * , all = False , quiet = None ) : <TAB>  import bonobo <TAB>  from bonobo . util . pkgs import bonobo_packages <TAB>  yield _format_version ( bonobo , quiet = quiet ) <TAB>  if all : <TAB><TAB>  for name in sorted ( bonobo_packages ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  mod = __import__ ( name . replace ( "" - "" , "" _ "" ) ) <TAB><TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB><TAB>  yield _format_version ( mod , name = name , quiet = quiet ) <TAB><TAB><TAB><TAB><TAB>  except Exception as exc : <TAB><TAB><TAB><TAB><TAB><TAB>  yield "" {}  ( {} ) "" . format ( name , exc ) <TAB><TAB><TAB><TAB>  except ImportError as exc : <TAB><TAB><TAB><TAB><TAB>  yield "" {}  is not importable ( {} ). "" . format ( name , exc ) ","if name != ""bonobo"" :",if name.startswith('-'):,False,50.253365607659404,97.7830906909176
3170,"def assertOperationsInjected ( self , plan , * * kwargs ) : <TAB>  for migration , _backward in plan : <TAB><TAB>  operations = iter ( migration . operations ) <TAB><TAB>  for operation in operations : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  next_operation = next ( operations ) <TAB><TAB><TAB><TAB>  self . assertIsInstance ( <TAB><TAB><TAB><TAB><TAB>  next_operation , contenttypes_management . RenameContentType <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  self . assertEqual ( next_operation . app_label , migration . app_label ) <TAB><TAB><TAB><TAB>  self . assertEqual ( next_operation . old_model , operation . old_name_lower ) <TAB><TAB><TAB><TAB>  self . assertEqual ( next_operation . new_model , operation . new_name_lower ) ","if isinstance ( operation , migrations . RenameModel ) :",if _backward(operation):,False,47.03288177320372,96.65905394940563
3171,"def valid_localparts ( strip_delimiters = False ) : <TAB>  for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB>  # strip line, skip over empty lines <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  if line == "" "" : <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over comments or empty lines <TAB><TAB>  match = COMMENT . match ( line ) <TAB><TAB>  if match : <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over localparts with delimiters <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" , "" in line or "" ; "" in line : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield line ",if strip_delimiters :,if strip_delimiters:,False,61.031613490526325,100.00000000000004
3172,"def read_lccn ( line , is_marc8 = False ) : <TAB>  found = [ ] <TAB>  for k , v in get_raw_subfields ( line , [ "" a "" ] ) : <TAB><TAB>  lccn = v . strip ( ) <TAB><TAB>  if re_question . match ( lccn ) : <TAB><TAB><TAB>  continue <TAB><TAB>  m = re_lccn . search ( lccn ) <TAB><TAB>  if not m : <TAB><TAB><TAB>  continue <TAB><TAB>  # remove letters and bad chars <TAB><TAB>  lccn = re_letters_and_bad . sub ( "" "" , m . group ( 1 ) ) . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  found . append ( lccn ) <TAB>  return found ",if lccn :,if is_marc8:,False,54.15896278465979,97.65707625998525
3173,"def test_named_parameters_and_constraints ( self ) : <TAB>  likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB>  model = ExactGPModel ( None , None , likelihood ) <TAB>  for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB><TAB>  if name == "" likelihood.noise_covar.raw_noise "" : <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB><TAB>  elif name == "" mean_module.constant "" : <TAB><TAB><TAB>  self . assertIsNone ( constraint ) <TAB><TAB>  elif name == "" covar_module.raw_outputscale "" : <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) ","elif name == ""covar_module.base_kernel.raw_lengthscale"" :","if name == ""mean_module.constant':",False,49.65689574747878,93.43551538764208
3174,"def _cleanupSocket ( self ) : <TAB>  """"""Close the Connection's socket."""""" <TAB>  try : <TAB><TAB>  self . _sock . shutdown ( socket . SHUT_WR ) <TAB>  except : <TAB><TAB>  return <TAB>  try : <TAB><TAB>  while True : <TAB><TAB><TAB>  r , w , e = select . select ( [ self . _sock ] , [ ] , [ ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB>  except : <TAB><TAB>  pass <TAB>  self . _sock . close ( ) ",if not r or not self . _sock . recv ( 1024 ) :,if r == w:,False,21.866359506539588,91.06457908898577
3175,"def fadeIn ( self , acts = None , t = None , duration = None ) : <TAB>  """"""Gradually switch on the input list of meshes by increasing opacity."""""" <TAB>  if self . bookingMode : <TAB><TAB>  acts , t , duration , rng = self . _parse ( acts , t , duration ) <TAB><TAB>  for tt in rng : <TAB><TAB><TAB>  alpha = linInterpolate ( tt , [ t , t + duration ] , [ 0 , 1 ] ) <TAB><TAB><TAB>  self . events . append ( ( tt , self . fadeIn , acts , alpha ) ) <TAB>  else : <TAB><TAB>  for a in self . _performers : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  a . alpha ( self . _inputvalues ) <TAB>  return self ",if a . alpha ( ) >= self . _inputvalues :,if a.alpha is None:,False,55.96251243777144,95.5476024658044
3176,"def get_config_updates_recursive ( self ) : <TAB>  config_updates = self . config_updates . copy ( ) <TAB>  for sr_path , subrunner in self . subrunners . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  update = subrunner . get_config_updates_recursive ( ) <TAB><TAB>  if update : <TAB><TAB><TAB>  config_updates [ rel_path ( self . path , sr_path ) ] = update <TAB>  return config_updates ","if not is_prefix ( self . path , sr_path ) :",if not subrunner.is_running():,False,25.512329393431866,91.81595762484554
3177,"def setArgs ( self , * * kwargs ) : <TAB>  """"""See GridSearchCostGamma"""""" <TAB>  for key , value in list ( kwargs . items ( ) ) : <TAB><TAB>  if key in ( "" folds "" , "" nfolds "" ) : <TAB><TAB><TAB>  self . _n_folds = int ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _validator_kwargs [ "" max_epochs "" ] = value <TAB><TAB>  else : <TAB><TAB><TAB>  GridSearchDOE . setArgs ( self , * * { key : value } ) ","elif key in ( ""max_epochs"" ) :",if self._n_folds > self._max_epochs:,False,19.82579696988271,90.73453486146849
3178,"def _parse_composite_axis ( composite_axis_name : str ) : <TAB>  axes_names = [ axis for axis in composite_axis_name . split ( "" "" ) if len ( axis ) > 0 ] <TAB>  for axis in axes_names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  assert "" a "" < = axis [ 0 ] < = "" z "" <TAB><TAB>  for letter in axis : <TAB><TAB><TAB>  assert str . isdigit ( letter ) or "" a "" < = letter < = "" z "" <TAB>  return axes_names ","if axis == ""_"" :",if axis == 'z':,False,47.80812604120187,96.94468242625356
3179,"def visit_For ( self , node , for_branch = "" body "" , * * kwargs ) : <TAB>  if for_branch == "" body "" : <TAB><TAB>  self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB><TAB>  branch = node . body <TAB>  elif for_branch == "" else "" : <TAB><TAB>  branch = node . else_ <TAB>  elif for_branch == "" test "" : <TAB><TAB>  self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . sym_visitor . visit ( node . test ) <TAB><TAB>  return <TAB>  else : <TAB><TAB>  raise RuntimeError ( "" Unknown for branch "" ) <TAB>  for item in branch or ( ) : <TAB><TAB>  self . sym_visitor . visit ( item ) ",if node . test is not None :,"if for_branch == ""test':",False,26.922994128048234,96.20984574811843
3180,def contains_only_whitespace ( node ) : <TAB>  if is_tag ( node ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ,if not any ( [ not is_text ( s ) for s in node . contents ] ) :,if node.contents:,False,20.543563493136286,79.14071596963403
3181,"def dir_tag_click ( event ) : <TAB>  mouse_index = self . path_bar . index ( "" @ %d , %d "" % ( event . x , event . y ) ) <TAB>  lineno = int ( float ( mouse_index ) ) <TAB>  if lineno == 1 : <TAB><TAB>  self . request_focus_into ( "" "" ) <TAB>  else : <TAB><TAB>  assert lineno == 2 <TAB><TAB>  dir_range = get_dir_range ( event ) <TAB><TAB>  if dir_range : <TAB><TAB><TAB>  _ , end_index = dir_range <TAB><TAB><TAB>  path = self . path_bar . get ( "" 2.0 "" , end_index ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  path + = "" \\ "" <TAB><TAB><TAB>  self . request_focus_into ( path ) ","if path . endswith ( "":"" ) :",if path:,False,21.143502013790673,96.26619512273122
3182,"def validate_employee_id ( self ) : <TAB>  if self . employee : <TAB><TAB>  sales_person = frappe . db . get_value ( "" Sales Person "" , { "" employee "" : self . employee } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( <TAB><TAB><TAB><TAB>  _ ( "" Another Sales Person  {0}  exists with the same Employee id "" ) . format ( <TAB><TAB><TAB><TAB><TAB>  sales_person <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) ",if sales_person and sales_person != self . name :,if sales_person != self.employee:,False,58.26033210782747,95.80373574381679
3183,"def pytest_collection_modifyitems ( items ) : <TAB>  for item in items : <TAB><TAB>  if item . nodeid . startswith ( "" tests/infer "" ) : <TAB><TAB><TAB>  if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if ""init"" not in item . keywords :","if ""init"" not in item.keywords:",False,28.420407113655756,100.00000000000004
3184,"def poll ( self , timeout ) : <TAB>  if timeout < 0 : <TAB><TAB>  timeout = None<TAB># kqueue behaviour <TAB>  events = self . _kqueue . control ( None , KqueueLoop . MAX_EVENTS , timeout ) <TAB>  results = defaultdict ( lambda : POLL_NULL ) <TAB>  for e in events : <TAB><TAB>  fd = e . ident <TAB><TAB>  if e . filter == select . KQ_FILTER_READ : <TAB><TAB><TAB>  results [ fd ] | = POLL_IN <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  results [ fd ] | = POLL_OUT <TAB>  return results . items ( ) ",elif e . filter == select . KQ_FILTER_WRITE :,if e.filter == select.KQ_FILTER_WRITE:,False,20.883669705566753,95.82713128760098
3185,"def _read_dimensions ( self , * dimnames , * * kwargs ) : <TAB>  path = kwargs . get ( "" path "" , "" / "" ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ self . rootgrp . dimensions [ dname ] for dname in dimnames ] <TAB><TAB>  group = self . path2group [ path ] <TAB><TAB>  return [ group . dimensions [ dname ] for dname in dimnames ] <TAB>  except KeyError : <TAB><TAB>  raise self . Error ( <TAB><TAB><TAB>  "" In file  %s : \n Error while reading dimensions: ` %s ` with kwargs: ` %s ` "" <TAB><TAB><TAB>  % ( self . path , dimnames , kwargs ) <TAB><TAB>  ) ","if path == ""/"" :",if path == self.rootgrp.path:,False,48.65235045566649,94.62267818507111
3186,"def spam_to_me ( address ) : <TAB>  sock = eventlet . connect ( address ) <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  sock . sendall ( b "" hello world "" ) <TAB><TAB><TAB>  # Arbitrary delay to not use all available CPU, keeps the test <TAB><TAB><TAB>  # running quickly and reliably under a second <TAB><TAB><TAB>  time . sleep ( 0.001 ) <TAB><TAB>  except socket . error as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  raise ",if get_errno ( e ) == errno . EPIPE :,if e.errno == errno.EAGAIN:,False,62.391563902543204,94.19503713747943
3187,"def has_hash_of ( self , destpath , code , package_level ) : <TAB>  """"""Determine if a file has the hash of the code."""""" <TAB>  if destpath is not None and os . path . isfile ( destpath ) : <TAB><TAB>  with univ_open ( destpath , "" r "" ) as opened : <TAB><TAB><TAB>  compiled = readfile ( opened ) <TAB><TAB>  hashash = gethash ( compiled ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  return False ","if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :",if hashash == code:,False,30.06598755759625,86.42524003754552
3188,"def insert ( self , index , item ) : <TAB>  if len ( self . lists ) == 1 : <TAB><TAB>  self . lists [ 0 ] . insert ( index , item ) <TAB><TAB>  self . _balance_list ( 0 ) <TAB>  else : <TAB><TAB>  list_idx , rel_idx = self . _translate_index ( index ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise IndexError ( ) <TAB><TAB>  self . lists [ list_idx ] . insert ( rel_idx , item ) <TAB><TAB>  self . _balance_list ( list_idx ) <TAB>  return ",if list_idx is None :,if list_idx >= len(self.lists):,False,22.217400808433982,94.07296262764494
3189,"def _parse_class_simplified ( symbol ) : <TAB>  results = { } <TAB>  name = symbol . name + "" ( "" <TAB>  name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB>  name + = "" ) "" <TAB>  for sym in symbol . body : <TAB><TAB>  if isinstance ( sym , ast . FunctionDef ) : <TAB><TAB><TAB>  result = _parse_function_simplified ( sym , symbol . name ) <TAB><TAB><TAB>  results . update ( result ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = _parse_class_simplified ( sym ) <TAB><TAB><TAB>  results . update ( result ) <TAB>  lineno = symbol . lineno <TAB>  for decorator in symbol . decorator_list : <TAB><TAB>  lineno + = 1 <TAB>  results [ lineno ] = ( name , "" c "" ) <TAB>  return results ","elif isinstance ( sym , ast . ClassDef ) :","if isinstance(sym, (ast.ClassDef, ast.ClassDef)):",False,20.184656610985922,95.79460342651137
3190,"def append_vars ( pairs , result ) : <TAB>  for name , value in sorted ( pairs . items ( ) ) : <TAB><TAB>  if isinstance ( value , list ) : <TAB><TAB><TAB>  value = "" [ %s ] "" % "" , "" . join ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( "" %s : %s = %s "" % ( package , name , value ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  result . append ( "" %s = %s "" % ( name , value ) ) ",if package :,if name == 'package':,False,23.332392400476003,96.18420214052935
3191,"def nextEditable ( self ) : <TAB>  """"""Moves focus of the cursor to the next editable window"""""" <TAB>  if self . currentEditable is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB>  else : <TAB><TAB>  for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB><TAB><TAB>  if ref in self . _editableChildren : <TAB><TAB><TAB><TAB>  cei = self . _editableChildren . index ( ref ) <TAB><TAB><TAB><TAB>  nei = cei + 1 <TAB><TAB><TAB><TAB>  if nei > = len ( self . _editableChildren ) : <TAB><TAB><TAB><TAB><TAB>  nei = 0 <TAB><TAB><TAB><TAB>  self . _currentEditableRef = self . _editableChildren [ nei ] <TAB>  return self . currentEditable ",if len ( self . _editableChildren ) :,if len(self._editableChildren) == 1:,False,37.471583580969835,98.00062233445554
3192,"def everythingIsUnicode ( d ) : <TAB>  """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  if isinstance ( v , dict ) and k != "" headers "" : <TAB><TAB><TAB>  if not everythingIsUnicode ( v ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  for i in v : <TAB><TAB><TAB><TAB>  if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB><TAB>  elif isinstance ( i , _bytes ) : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB>  return True ","elif isinstance ( v , _bytes ) :","if not isinstance(i, unicode):",False,31.346927833879086,96.72192631538883
3193,"def is_valid ( sample ) : <TAB>  if sample is None : <TAB><TAB>  return False <TAB>  if isinstance ( sample , tuple ) : <TAB><TAB>  for s in sample : <TAB><TAB><TAB>  if s is None : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ","elif isinstance ( s , np . ndarray ) and s . size == 0 :","if isinstance(s, collections.abc.Sequence):",False,23.390840462972456,91.06414003430808
3194,"def scan_resource_conf ( self , conf ) : <TAB>  if "" properties "" in conf : <TAB><TAB>  if "" attributes "" in conf [ "" properties "" ] : <TAB><TAB><TAB>  if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return CheckResult . PASSED <TAB>  return CheckResult . FAILED ","if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :","if ""resource_conf"" in conf:",False,23.454627733172202,85.88595393709208
3195,"def encode ( self ) : <TAB>  if self . expr in gpregs . expr : <TAB><TAB>  self . value = gpregs . expr . index ( self . expr ) <TAB><TAB>  self . parent . rot2 . value = 0 <TAB>  elif isinstance ( self . expr , ExprOp ) and self . expr . op == allshifts [ 3 ] : <TAB><TAB>  reg , value = self . expr . args <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  self . value = gpregs . expr . index ( reg ) <TAB><TAB>  if not isinstance ( value , ExprInt ) : <TAB><TAB><TAB>  return False <TAB><TAB>  value = int ( value ) <TAB><TAB>  if not value in [ 8 , 16 , 24 ] : <TAB><TAB><TAB>  return False <TAB><TAB>  self . parent . rot2 . value = value / / 8 <TAB>  return True ",if reg not in gpregs . expr :,if reg is None:,False,23.329048142126318,97.1008252411205
3196,"def validate_transaction_reference ( self ) : <TAB>  bank_account = self . paid_to if self . payment_type == "" Receive "" else self . paid_from <TAB>  bank_account_type = frappe . db . get_value ( "" Account "" , bank_account , "" account_type "" ) <TAB>  if bank_account_type == "" Bank "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( <TAB><TAB><TAB><TAB>  _ ( "" Reference No and Reference Date is mandatory for Bank transaction "" ) <TAB><TAB><TAB>  ) ",if not self . reference_no or not self . reference_date :,if self.transaction_reference is None:,False,31.918856980613796,91.35857943329589
3197,"def monad ( self ) : <TAB>  if not self . cls_bl_idname : <TAB><TAB>  return None <TAB>  for monad in bpy . data . node_groups : <TAB><TAB>  if hasattr ( monad , "" cls_bl_idname "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return monad <TAB>  return None ",if monad . cls_bl_idname == self . cls_bl_idname :,if monad.cls_bl_idname == self.cls_bl_idname,False,20.627068248486374,97.62168381174828
3198,"def _create_mask ( self , plen ) : <TAB>  mask = [ ] <TAB>  for i in range ( 16 ) : <TAB><TAB>  if plen > = 8 : <TAB><TAB><TAB>  mask . append ( 0xFF ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mask . append ( 0xFF >> ( 8 - plen ) << ( 8 - plen ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  mask . append ( 0x00 ) <TAB><TAB>  plen - = 8 <TAB>  return mask ",elif plen > 0 :,if plen < 8:,False,19.553439822796488,96.02138311224654
3199,"def dataset_to_stream ( dataset , input_name ) : <TAB>  """"""Takes a tf.Dataset and creates a numpy stream of ready batches."""""" <TAB>  # All input-pipeline processing should be on CPU. <TAB>  for example in fastmath . dataset_as_numpy ( dataset ) : <TAB><TAB>  features = example [ 0 ] <TAB><TAB>  inp , out = features [ input_name ] , example [ 1 ] <TAB><TAB>  mask = features [ "" mask "" ] if "" mask "" in features else None <TAB><TAB>  # Some accelerators don't handle uint8 well, cast to int. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  inp = inp . astype ( np . int32 ) <TAB><TAB>  if isinstance ( out , np . uint8 ) : <TAB><TAB><TAB>  out = out . astype ( np . int32 ) <TAB><TAB>  yield ( inp , out ) if mask is None else ( inp , out , mask ) ","if isinstance ( inp , np . uint8 ) :","if isinstance(inp, np.int8):",False,64.86937468477035,98.91652394992484
3200,"def _idle_redraw_cb ( self ) : <TAB>  assert self . _idle_redraw_src_id is not None <TAB>  queue = self . _idle_redraw_queue <TAB>  if len ( queue ) > 0 : <TAB><TAB>  bbox = queue . pop ( 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  super ( CanvasRenderer , self ) . queue_draw ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  super ( CanvasRenderer , self ) . queue_draw_area ( * bbox ) <TAB>  if len ( queue ) == 0 : <TAB><TAB>  self . _idle_redraw_src_id = None <TAB><TAB>  return False <TAB>  return True ",if bbox is None :,if bbox is None:,False,51.00723226744452,100.00000000000004
3201,"def mutated ( self , indiv ) : <TAB>  """"""mutate some genes of the given individual"""""" <TAB>  res = indiv . copy ( ) <TAB>  # to avoid having a child identical to one of the currentpopulation''' <TAB>  for i in range ( self . numParameters ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . xBound is None : <TAB><TAB><TAB><TAB>  res [ i ] = indiv [ i ] + gauss ( 0 , self . mutationStdDev ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  res [ i ] = max ( <TAB><TAB><TAB><TAB><TAB>  min ( indiv [ i ] + gauss ( 0 , self . mutationStdDev ) , self . maxs [ i ] ) , <TAB><TAB><TAB><TAB><TAB>  self . mins [ i ] , <TAB><TAB><TAB><TAB>  ) <TAB>  return res ",if random ( ) < self . mutationProb :,if indiv[i] > 0:,False,61.28611543137252,96.31043477779822
3202,"def _justifyDrawParaLine ( tx , offset , extraspace , words , last = 0 ) : <TAB>  setXPos ( tx , offset ) <TAB>  text = b "" "" . join ( words ) <TAB>  if last : <TAB><TAB>  # last one, left align <TAB><TAB>  tx . _textOut ( text , 1 ) <TAB>  else : <TAB><TAB>  nSpaces = len ( words ) - 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tx . setWordSpace ( extraspace / float ( nSpaces ) ) <TAB><TAB><TAB>  tx . _textOut ( text , 1 ) <TAB><TAB><TAB>  tx . setWordSpace ( 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  tx . _textOut ( text , 1 ) <TAB>  setXPos ( tx , - offset ) <TAB>  return offset ",if nSpaces :,if nSpaces > 0:,False,48.668373974745926,96.38719375801591
3203,"def _read_0 ( self , stream ) : <TAB>  r = b "" "" <TAB>  while True : <TAB><TAB>  c = stream . read ( 2 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise EOFError ( ) <TAB><TAB>  if c == b "" \x00 \x00 "" : <TAB><TAB><TAB>  break <TAB><TAB>  r + = c <TAB>  return r . decode ( self . encoding ) ",if len ( c ) != 2 :,"if c == b""':",False,14.44181439892719,93.0500362447253
3204,"def run ( self , app , editor , args ) : <TAB>  line_nums = [ ] <TAB>  for cursor in editor . cursors : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line_nums . append ( cursor . y ) <TAB><TAB><TAB>  data = editor . lines [ cursor . y ] . get_data ( ) . upper ( ) <TAB><TAB><TAB>  editor . lines [ cursor . y ] . set_data ( data ) ",if cursor . y not in line_nums :,if cursor.y not in line_nums:,False,52.81726876252457,100.00000000000004
3205,"def create_default_energy_point_rules ( ) : <TAB>  for rule in get_default_energy_point_rules ( ) : <TAB><TAB>  # check if any rule for ref. doctype exists <TAB><TAB>  rule_exists = frappe . db . exists ( <TAB><TAB><TAB>  "" Energy Point Rule "" , { "" reference_doctype "" : rule . get ( "" reference_doctype "" ) } <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  doc = frappe . get_doc ( rule ) <TAB><TAB>  doc . insert ( ignore_permissions = True ) ",if rule_exists :,if rule_exists:,False,60.63876147696461,100.00000000000004
3206,"def __new__ ( cls , * nodes ) : <TAB>  if not nodes : <TAB><TAB>  raise TypeError ( "" DisjunctionNode() requires at least one node "" ) <TAB>  elif len ( nodes ) == 1 : <TAB><TAB>  return nodes [ 0 ] <TAB>  self = super ( DisjunctionNode , cls ) . __new__ ( cls ) <TAB>  self . __nodes = [ ] <TAB>  # TODO: Remove duplicates? <TAB>  for node in nodes : <TAB><TAB>  if not isinstance ( node , Node ) : <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  "" DisjunctionNode() expects Node instances as arguments; "" <TAB><TAB><TAB><TAB>  ""  received a non-Node instance  %r "" % node <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __nodes . extend ( node . __nodes ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . __nodes . append ( node ) <TAB>  return self ","if isinstance ( node , DisjunctionNode ) :","if isinstance(node, Node):",False,56.620049466312025,99.03749935783947
3207,def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB>  index [ v ] = len ( stack ) <TAB>  stack . append ( v ) <TAB>  boundaries . append ( index [ v ] ) <TAB>  for w in edges [ v ] : <TAB><TAB>  if w not in index : <TAB><TAB><TAB>  yield from dfs ( w ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  while index [ w ] < boundaries [ - 1 ] : <TAB><TAB><TAB><TAB>  boundaries . pop ( ) <TAB>  if boundaries [ - 1 ] == index [ v ] : <TAB><TAB>  boundaries . pop ( ) <TAB><TAB>  scc = set ( stack [ index [ v ] : ] ) <TAB><TAB>  del stack [ index [ v ] : ] <TAB><TAB>  identified . update ( scc ) <TAB><TAB>  yield scc ,elif w not in identified :,if w in boundaries:,False,37.87247073324976,94.42843687226915
3208,"def unpack_item_obj ( map_uuid_global_id , misp_obj ) : <TAB>  obj_meta = get_object_metadata ( misp_obj ) <TAB>  obj_id = None <TAB>  io_content = None <TAB>  for attribute in misp_obj . attributes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  obj_id = attribute . value<TAB># # TODO: sanitize <TAB><TAB><TAB>  io_content = attribute . data<TAB># # TODO: check if type == io <TAB>  if obj_id and io_content : <TAB><TAB>  res = Item . create_item ( obj_id , obj_meta , io_content ) <TAB><TAB>  map_uuid_global_id [ misp_obj . uuid ] = get_global_id ( "" item "" , obj_id ) ","if attribute . object_relation == ""raw-data"" :","if isinstance(attribute, Item):",False,22.20864723009112,91.98575988853052
3209,"def parse ( self , response ) : <TAB>  soup = BeautifulSoup ( response . content . decode ( "" utf-8 "" , "" ignore "" ) , "" lxml "" ) <TAB>  image_divs = soup . find_all ( "" div "" , class_ = "" imgpt "" ) <TAB>  pattern = re . compile ( r "" murl \"" : \"" (.*?) \ .jpg "" ) <TAB>  for div in image_divs : <TAB><TAB>  href_str = html_parser . HTMLParser ( ) . unescape ( div . a [ "" m "" ] ) <TAB><TAB>  match = pattern . search ( href_str ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = match . group ( 1 ) if six . PY3 else match . group ( 1 ) . encode ( "" utf-8 "" ) <TAB><TAB><TAB>  img_url = "" {} .jpg "" . format ( name ) <TAB><TAB><TAB>  yield dict ( file_url = img_url ) ",if match :,if match:,False,25.903108056492936,100.00000000000004
3210,"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB>  real_errors : List [ str ] = list ( ) <TAB>  current_file = __file__ <TAB>  current_path = os . path . split ( current_file ) <TAB>  for line in errors : <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  continue <TAB><TAB>  fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _path = os . path . split ( fn ) <TAB><TAB><TAB>  if _path [ - 1 ] != current_path [ - 1 ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  real_errors . append ( line ) <TAB>  return real_errors ",if fn is not None :,if fn != current_path:,False,24.330196737286983,93.91226006271897
3211,"def decompileFormat1 ( self , reader , otFont ) : <TAB>  self . classDefs = classDefs = [ ] <TAB>  startGlyphID = reader . readUShort ( ) <TAB>  glyphCount = reader . readUShort ( ) <TAB>  for i in range ( glyphCount ) : <TAB><TAB>  glyphName = otFont . getglyphName ( startGlyphID + i ) <TAB><TAB>  classValue = reader . readUShort ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  classDefs . append ( ( glyphName , classValue ) ) ",if classValue :,if classValue != 0:,False,21.59609350047856,95.91116223104595
3212,"def compress ( self , data_list ) : <TAB>  if len ( data_list ) == 2 : <TAB><TAB>  value , lookup_expr = data_list <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if lookup_expr not in EMPTY_VALUES : <TAB><TAB><TAB><TAB>  return Lookup ( value = value , lookup_expr = lookup_expr ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise forms . ValidationError ( <TAB><TAB><TAB><TAB><TAB>  self . error_messages [ "" lookup_required "" ] , code = "" lookup_required "" <TAB><TAB><TAB><TAB>  ) <TAB>  return None ",if value not in EMPTY_VALUES :,if value is not None:,False,43.861681270719664,96.49275069730835
3213,"def open_compat ( path , mode = "" r "" ) : <TAB>  if mode in [ "" r "" , "" rb "" ] and not os . path . exists ( path ) : <TAB><TAB>  raise FileNotFoundError ( u ' The file  "" %s ""  could not be found ' % path ) <TAB>  if sys . version_info > = ( 3 , ) : <TAB><TAB>  encoding = "" utf-8 "" <TAB><TAB>  errors = "" replace "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  encoding = None <TAB><TAB><TAB>  errors = None <TAB><TAB>  return open ( path , mode , encoding = encoding , errors = errors ) <TAB>  else : <TAB><TAB>  return open ( path , mode ) ","if mode in [ ""rb"" , ""wb"" , ""ab"" ] :","if mode == ""r':",False,22.44722119778579,88.94995854648849
3214,"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB>  real_errors : List [ str ] = list ( ) <TAB>  current_file = __file__ <TAB>  current_path = os . path . split ( current_file ) <TAB>  for line in errors : <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  continue <TAB><TAB>  fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB><TAB>  if fn is not None : <TAB><TAB><TAB>  _path = os . path . split ( fn ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  real_errors . append ( line ) <TAB>  return real_errors ",if _path [ - 1 ] != current_path [ - 1 ] :,if _path.startswith('.') or _path.startswith('.') or,False,23.413718766314286,91.63931508628961
3215,"def filter_by_level ( record , level_per_module ) : <TAB>  name = record [ "" name "" ] <TAB>  level = 0 <TAB>  if name in level_per_module : <TAB><TAB>  level = level_per_module [ name ] <TAB>  elif name is not None : <TAB><TAB>  lookup = "" "" <TAB><TAB>  if "" "" in level_per_module : <TAB><TAB><TAB>  level = level_per_module [ "" "" ] <TAB><TAB>  for n in name . split ( "" . "" ) : <TAB><TAB><TAB>  lookup + = n <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  level = level_per_module [ lookup ] <TAB><TAB><TAB>  lookup + = "" . "" <TAB>  if level is False : <TAB><TAB>  return False <TAB>  return record [ "" level "" ] . no > = level ",if lookup in level_per_module :,if lookup in level_per_module:,False,45.56187465777051,100.00000000000004
3216,"def CountButtons ( self ) : <TAB>  """"""Returns the number of visible buttons in the docked pane."""""" <TAB>  n = 0 <TAB>  if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB><TAB>  if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB><TAB><TAB>  return 1 <TAB><TAB>  if self . HasCloseButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  if self . HasMinimizeButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  if self . HasPinButton ( ) : <TAB><TAB><TAB>  n + = 1 <TAB>  return n ",if self . HasMaximizeButton ( ) :,if self.HasMinimizeButton():,False,52.14439270197402,98.66121287187084
3217,"def search ( a , b , desired ) : <TAB>  if a == b : <TAB><TAB>  return a <TAB>  if abs ( b - a ) < 0.005 : <TAB><TAB>  ca = count ( a ) <TAB><TAB>  cb = count ( b ) <TAB><TAB>  dista = abs ( desired - ca ) <TAB><TAB>  distb = abs ( desired - cb ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return a <TAB><TAB>  else : <TAB><TAB><TAB>  return b <TAB>  m = ( a + b ) / 2.0 <TAB>  cm = count ( m ) <TAB>  if desired < cm : <TAB><TAB>  return search ( m , b , desired ) <TAB>  else : <TAB><TAB>  return search ( a , m , desired ) ",if dista < distb :,if dista < distb:,False,50.671076373326414,100.00000000000004
3218,"def force_ipv4 ( self , * args ) : <TAB>  """"""only ipv4 localhost in /etc/hosts"""""" <TAB>  logg . debug ( "" checking /etc/hosts for  ' ::1 localhost ' "" ) <TAB>  lines = [ ] <TAB>  for line in open ( self . etc_hosts ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newline = re . sub ( "" \\ slocalhost \\ s "" , "" "" , line ) <TAB><TAB><TAB>  if line != newline : <TAB><TAB><TAB><TAB>  logg . info ( "" /etc/hosts:  ' %s '  =>  ' %s ' "" , line . rstrip ( ) , newline . rstrip ( ) ) <TAB><TAB><TAB><TAB>  line = newline <TAB><TAB>  lines . append ( line ) <TAB>  f = open ( self . etc_hosts ( ) , "" w "" ) <TAB>  for line in lines : <TAB><TAB>  f . write ( line ) <TAB>  f . close ( ) ","if ""::1"" in line :","if re.search('\\slocalhost\\s', line):",False,50.22327738830954,90.10355168567509
3219,"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB>  yield "" Core "" , "" 0 "" <TAB>  for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB><TAB>  fpath = _dir / "" settings.json "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  with fpath . open ( ) as f : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  data = json . load ( f ) <TAB><TAB><TAB>  except json . JSONDecodeError : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  if not isinstance ( data , dict ) : <TAB><TAB><TAB>  continue <TAB><TAB>  cog_name = _dir . stem <TAB><TAB>  for cog_id , inner in data . items ( ) : <TAB><TAB><TAB>  if not isinstance ( inner , dict ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield cog_name , cog_id ",if not fpath . exists ( ) :,if not os.path.exists(fpath):,False,22.8017614600498,97.52344042680525
3220,"def _get_dbutils ( ) : <TAB>  try : <TAB><TAB>  import IPython <TAB><TAB>  ip_shell = IPython . get_ipython ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise _NoDbutilsError <TAB><TAB>  return ip_shell . ns_table [ "" user_global "" ] [ "" dbutils "" ] <TAB>  except ImportError : <TAB><TAB>  raise _NoDbutilsError <TAB>  except KeyError : <TAB><TAB>  raise _NoDbutilsError ",if ip_shell is None :,"if not ip_shell.ns_table['user_global'][""dbutils']",False,18.791183817174318,86.73443136669316
3221,"def _bytecode_filenames ( self , py_filenames ) : <TAB>  bytecode_files = [ ] <TAB>  for py_file in py_filenames : <TAB><TAB>  # Since build_py handles package data installation, the <TAB><TAB>  # list of outputs can contain more than just .py files. <TAB><TAB>  # Make sure we only report bytecode for the .py files. <TAB><TAB>  ext = os . path . splitext ( os . path . normcase ( py_file ) ) [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if self . compile : <TAB><TAB><TAB>  bytecode_files . append ( py_file + "" c "" ) <TAB><TAB>  if self . optimize > 0 : <TAB><TAB><TAB>  bytecode_files . append ( py_file + "" o "" ) <TAB>  return bytecode_files ",if ext != PYTHON_SOURCE_EXTENSION :,if ext == '.py':,False,65.90577247273733,96.22031013553931
3222,"def compute_distances_mu ( line , pts , result , gates , tolerance ) : <TAB>  """"""calculate all distances with mathuutils"""""" <TAB>  line_origin = V ( line [ 0 ] ) <TAB>  line_end = V ( line [ - 1 ] ) <TAB>  local_result = [ [ ] , [ ] , [ ] , [ ] , [ ] ] <TAB>  for point in pts : <TAB><TAB>  data = compute_distance ( V ( point ) , line_origin , line_end , tolerance ) <TAB><TAB>  for i , res in enumerate ( local_result ) : <TAB><TAB><TAB>  res . append ( data [ i ] ) <TAB>  for i , res in enumerate ( result ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  res . append ( local_result [ i ] ) ",if gates [ i ] :,if i not in gates:,False,22.672061111786565,95.69761888435845
3223,"def _get_next_segment ( self , segment_path , page_size , segment_cursor = None ) : <TAB>  if segment_path : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  return Segment ( self . client , segment_path , page_size , segment_cursor ) <TAB>  return None ",if self . end_time and self . _is_later_than_end_time ( segment_path ) :,if segment_path == self.client.segment_path:,False,45.48770615692857,78.48659628249591
3224,"def _check_number_of_sessions ( ) : <TAB>  nb_desktop_sessions = sessions . get_number_of_desktop_sessions ( ignore_gdm = True ) <TAB>  if nb_desktop_sessions > 1 : <TAB><TAB>  print ( <TAB><TAB><TAB>  "" WARNING : There are  %d  other desktop sessions open. The GPU switch will not become effective until you have manually "" <TAB><TAB><TAB>  ""  logged out from ALL desktop sessions. \n "" <TAB><TAB><TAB>  "" Continue ? (y/N) "" % ( nb_desktop_sessions - 1 ) <TAB><TAB>  ) <TAB><TAB>  confirmation = ask_confirmation ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sys . exit ( 0 ) ",if not confirmation :,if confirmation is None:,False,40.34675408475403,97.68823825831733
3225,"def delete_compute_environment ( self , compute_environment_name ) : <TAB>  if compute_environment_name is None : <TAB><TAB>  raise InvalidParameterValueException ( "" Missing computeEnvironment parameter "" ) <TAB>  compute_env = self . get_compute_environment ( compute_environment_name ) <TAB>  if compute_env is not None : <TAB><TAB>  # Pop ComputeEnvironment <TAB><TAB>  self . _compute_environments . pop ( compute_env . arn ) <TAB><TAB>  # Delete ECS cluster <TAB><TAB>  self . ecs_backend . delete_cluster ( compute_env . ecs_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Delete compute environment <TAB><TAB><TAB>  instance_ids = [ instance . id for instance in compute_env . instances ] <TAB><TAB><TAB>  self . ec2_backend . terminate_instances ( instance_ids ) ","if compute_env . env_type == ""MANAGED"" :",if compute_env.instances:,False,52.51238294868787,95.63918246399582
3226,"def run ( self ) : <TAB>  results = { } <TAB>  for func_name in [ <TAB><TAB>  # Execute every function starting with check_* <TAB><TAB>  fn <TAB><TAB>  for fn in self . check_functions <TAB><TAB>  # if the user does not specify any name <TAB><TAB>  if not self . args . get ( "" check "" ) <TAB><TAB>  # of if specify the current function name <TAB><TAB>  or self . args . get ( "" check "" ) == fn <TAB>  ] : <TAB><TAB>  function = getattr ( self , func_name ) <TAB><TAB>  log . warn ( function . __doc__ ) <TAB><TAB>  result = function ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( "" \n "" . join ( result ) ) <TAB><TAB><TAB>  results . update ( { func_name : result } ) <TAB>  return results ",if result :,if result:,False,62.19266111748042,100.00000000000004
3227,"def invalidate ( self , layers = None ) : <TAB>  if layers is None : <TAB><TAB>  layers = Layer . AllLayers <TAB>  if layers : <TAB><TAB>  layers = set ( layers ) <TAB><TAB>  self . invalidLayers . update ( layers ) <TAB><TAB>  blockRenderers = [ <TAB><TAB><TAB>  br <TAB><TAB><TAB>  for br in self . blockRenderers <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  ] <TAB><TAB>  if len ( blockRenderers ) < len ( self . blockRenderers ) : <TAB><TAB><TAB>  self . forgetDisplayLists ( ) <TAB><TAB>  self . blockRenderers = blockRenderers <TAB><TAB>  if self . renderer . showRedraw and Layer . Blocks in layers : <TAB><TAB><TAB>  self . needsRedisplay = True ",if br . layer is Layer . Blocks or br . layer not in layers,if br.display:,False,26.4522231874447,93.21020118349594
3228,"def get_library_dirs ( platform , arch = None ) : <TAB>  if platform == "" win32 "" : <TAB><TAB>  jre_home = get_jre_home ( platform ) <TAB><TAB>  jdk_home = JAVA_HOME <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  jre_home = jre_home . decode ( "" utf-8 "" ) <TAB><TAB>  return [ join ( jdk_home , "" lib "" ) , join ( jdk_home , "" bin "" , "" server "" ) ] <TAB>  elif platform == "" android "" : <TAB><TAB>  return [ "" libs/ {} "" . format ( arch ) ] <TAB>  return [ ] ","if isinstance ( jre_home , bytes ) :","if isinstance(jre_home, unicode):",False,50.940420947515854,98.47313538241164
3229,"def save_plugin_options ( self ) : <TAB>  for name , option_widgets in self . _plugin_option_widgets . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . config [ "" plugins "" ] [ name ] = { } <TAB><TAB>  plugin_config = self . config [ "" plugins "" ] [ <TAB><TAB><TAB>  name <TAB><TAB>  ]<TAB># use or instead of get incase the value is actually None <TAB><TAB>  for option_name , option_widget in option_widgets . items ( ) : <TAB><TAB><TAB>  plugin_config [ option_name ] = option_widget . option . get_widget_value ( <TAB><TAB><TAB><TAB>  option_widget . widget <TAB><TAB><TAB>  ) ","if name not in self . config [ ""plugins"" ] :",if name not in self.config['plugins']:,False,61.72513014850137,96.53047021228872
3230,"def _select_block ( str_in , start_tag , end_tag ) : <TAB>  """"""Select first block delimited by start_tag and end_tag"""""" <TAB>  start_pos = str_in . find ( start_tag ) <TAB>  if start_pos < 0 : <TAB><TAB>  raise ValueError ( "" start_tag not found "" ) <TAB>  depth = 0 <TAB>  for pos in range ( start_pos , len ( str_in ) ) : <TAB><TAB>  if str_in [ pos ] == start_tag : <TAB><TAB><TAB>  depth + = 1 <TAB><TAB>  elif str_in [ pos ] == end_tag : <TAB><TAB><TAB>  depth - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  sel = str_in [ start_pos + 1 : pos ] <TAB>  return sel ",if depth == 0 :,if depth == 0:,False,46.272530284271106,100.00000000000004
3231,"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB>  """"""Coerce the values in a variable to bools."""""" <TAB>  bool_var = self . program . NewVariable ( ) <TAB>  for b in var . bindings : <TAB><TAB>  v = b . data <TAB><TAB>  if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB><TAB><TAB>  const = v . pyval is true_val <TAB><TAB>  elif not compare . compatible_with ( v , True ) : <TAB><TAB><TAB>  const = not true_val <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  const = true_val <TAB><TAB>  else : <TAB><TAB><TAB>  const = None <TAB><TAB>  bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB>  return bool_var ","elif not compare . compatible_with ( v , False ) :",if const is True:,False,33.12634400245926,94.30171198961611
3232,def multiline_indentation ( self ) : <TAB>  if self . _multiline_indentation is None : <TAB><TAB>  offset = 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  offset = 2 <TAB><TAB>  indentation = make_indentation ( 3 * self . indent_size + offset ) <TAB><TAB>  self . _multiline_indentation = indentation <TAB>  if self . current_rule : <TAB><TAB>  indent_extra = make_indentation ( self . indent_size ) <TAB><TAB>  return self . _multiline_indentation + indent_extra <TAB>  return self . _multiline_indentation ,if self . show_aligned_keywords :,if self.current_rule:,False,32.4544577973959,95.78265699909443
3233,"def __call__ ( self , event , data = None ) : <TAB>  datatype , delta = event <TAB>  self . midi_ctrl . delta + = delta <TAB>  if TIMING_CLOCK in datatype and not self . played : <TAB><TAB>  self . midi_ctrl . pulse + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  t_master = 60.0 <TAB><TAB><TAB>  self . midi_ctrl . bpm = round ( 60.0 / self . midi_ctrl . delta , 0 ) <TAB><TAB><TAB>  self . midi_ctrl . pulse = 0 <TAB><TAB><TAB>  self . midi_ctrl . delta = 0.0 ",if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,if TIMING_CLOCK in datatype:,False,26.79522386177072,89.78642090798027
3234,"def handle_sent ( self , elt ) : <TAB>  sent = [ ] <TAB>  for child in elt : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  itm = self . handle_word ( child ) <TAB><TAB><TAB>  if self . _unit == "" word "" : <TAB><TAB><TAB><TAB>  sent . extend ( itm ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  sent . append ( itm ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB>  return SemcorSentence ( elt . attrib [ "" snum "" ] , sent ) ","if child . tag in ( ""wf"" , ""punc"" ) :",if child.tag == 'word':,False,44.48727434943922,93.50827173961396
3235,"def _handle_def_errors ( testdef ) : <TAB>  # If the test generation had an error, raise <TAB>  if testdef . error : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( testdef . exception , Exception ) : <TAB><TAB><TAB><TAB>  raise testdef . exception <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise Exception ( testdef . exception ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( "" Test parse failure "" ) ",if testdef . exception :,if testdef.exception:,False,35.83417180632904,100.00000000000004
3236,"def _authorized_sid ( self , jid , sid , ifrom , iq ) : <TAB>  with self . _preauthed_sids_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . _preauthed_sids [ ( jid , sid , ifrom ) ] <TAB><TAB><TAB>  return True <TAB><TAB>  return False ","if ( jid , sid , ifrom ) in self . _preauthed_sids :",if jid in self._preauthed_sids:,False,17.871124056500058,91.13876082385448
3237,"def wait ( self , timeout = None ) : <TAB>  if self . returncode is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msecs = _subprocess . INFINITE <TAB><TAB>  else : <TAB><TAB><TAB>  msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB><TAB>  res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB><TAB>  if res == _subprocess . WAIT_OBJECT_0 : <TAB><TAB><TAB>  code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB><TAB><TAB>  if code == TERMINATE : <TAB><TAB><TAB><TAB>  code = - signal . SIGTERM <TAB><TAB><TAB>  self . returncode = code <TAB>  return self . returncode ",if timeout is None :,if timeout is None:,False,51.797269292487755,98.18605297716823
3238,"def _gen_legal_y_s_t ( self ) : <TAB>  while True : <TAB><TAB>  y = self . _gen_random_scalar ( ) <TAB><TAB>  s = self . tec_arithmetic . mul ( <TAB><TAB><TAB>  scalar = y , a = self . tec_arithmetic . get_generator ( ) <TAB><TAB>  )<TAB># S = yG <TAB><TAB>  t = self . _hash_tec_element ( s ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Both S and T are legal <TAB><TAB><TAB>  LOGGER . info ( "" randomly generated y, S, T "" ) <TAB><TAB><TAB>  return y , s , t ",if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int :,if t is not None:,False,55.25668659416792,87.08451035511952
3239,"def write_out ( ) : <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  time . sleep ( 0.1 ) <TAB><TAB><TAB>  continue <TAB><TAB>  data_str = self . instrument_queue . get ( ) <TAB><TAB>  data_str = data_str . splitlines ( ) <TAB><TAB>  tb . write ( "" "" )<TAB># position cursor to end <TAB><TAB>  for line in data_str : <TAB><TAB><TAB>  tb . write ( line ) <TAB><TAB>  tb . write ( "" \n "" ) ",if self . instrument_queue . empty ( ) :,if self.instrument_queue.qsize() == 0:,False,27.28987613184063,92.77614647610699
3240,"def _parse_preamble ( self ) : <TAB>  """"""Parse metadata about query (PRIVATE)."""""" <TAB>  meta = { } <TAB>  while self . line : <TAB><TAB>  regx = re . search ( _RE_QUERY , self . line ) <TAB><TAB>  if regx : <TAB><TAB><TAB>  self . query_id = regx . group ( 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . seq_len = int ( self . line . strip ( ) . split ( ) [ 1 ] ) <TAB><TAB>  self . line = self . handle . readline ( ) . strip ( ) <TAB>  return meta ","if self . line . startswith ( ""Match_columns"" ) :",if len(self.line.strip()):,False,26.34552722606805,94.19360796376773
3241,"def init_sequence ( self , coll_name , seq_config ) : <TAB>  if not isinstance ( seq_config , list ) : <TAB><TAB>  raise Exception ( ' "" sequence ""  config must be a list ' ) <TAB>  handlers = [ ] <TAB>  for entry in seq_config : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( ' "" sequence ""  entry must be a dict ' ) <TAB><TAB>  name = entry . get ( "" name "" , "" "" ) <TAB><TAB>  handler = self . load_coll ( name , entry ) <TAB><TAB>  handlers . append ( handler ) <TAB>  return HandlerSeq ( handlers ) ","if not isinstance ( entry , dict ) :","if not isinstance(entry, dict):",False,56.13908745374467,95.61811129004374
3242,"def change_args_to_dict ( string ) : <TAB>  if string is None : <TAB><TAB>  return None <TAB>  ans = [ ] <TAB>  strings = string . split ( "" \n "" ) <TAB>  ind = 1 <TAB>  start = 0 <TAB>  while ind < = len ( strings ) : <TAB><TAB>  if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) : <TAB><TAB><TAB>  ind + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB><TAB><TAB>  start = ind <TAB><TAB><TAB>  ind + = 1 <TAB>  d = { } <TAB>  for line in ans : <TAB><TAB>  if "" : "" in line and len ( line ) > 0 : <TAB><TAB><TAB>  lines = line . split ( "" : "" ) <TAB><TAB><TAB>  d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB>  return d ",if start < ind :,if strings[start] == strings[ind] and strings[ind] == strings[ind,False,24.17762265307508,92.69066085928851
3243,"def wait ( self ) : <TAB>  while True : <TAB><TAB>  return_code = self . _process . poll ( ) <TAB><TAB>  if return_code is not None : <TAB><TAB><TAB>  line = self . _process . stdout . readline ( ) . decode ( "" utf-8 "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  log . debug ( line . strip ( "" \n "" ) ) <TAB>  return True ","if line == """" :",if not line:,False,22.4474659414717,95.08041984564329
3244,"def __getattr__ ( self , key ) : <TAB>  for tag in self . tag . children : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if "" name "" in tag . attrs and tag . attrs [ "" name "" ] in ( key , ) : <TAB><TAB><TAB>  from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB><TAB><TAB>  return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB>  raise AttributeError ","if tag . name not in ( ""input"" , ) :",if tag.tagName == key:,False,48.38035882515581,91.65689479769972
3245,"def compare_hash ( hash_of_gold , path_to_file ) : <TAB>  with open ( path_to_file , "" rb "" ) as f : <TAB><TAB>  hash_of_file = hashlib . sha256 ( f . read ( ) ) . hexdigest ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" ########## Hash sum of "" , <TAB><TAB><TAB><TAB>  path_to_file , <TAB><TAB><TAB><TAB>  "" differs from the target, the topology will be deleted !!! ########## "" , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  shutil . rmtree ( os . path . dirname ( path_to_file ) ) ",if hash_of_file != hash_of_gold :,if hash_of_file != hash_of_gold:,False,62.67243008320912,100.00000000000004
3246,def on_completed2 ( ) : <TAB>  doner [ 0 ] = True <TAB>  if not qr : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  observer . on_next ( False ) <TAB><TAB><TAB>  observer . on_completed ( ) <TAB><TAB>  elif donel [ 0 ] : <TAB><TAB><TAB>  observer . on_next ( True ) <TAB><TAB><TAB>  observer . on_completed ( ) ,if len ( ql ) > 0 :,if donel[0] and (not donel[0]):,False,20.617816965544115,89.29110238168175
3247,"def get_other ( self , data , items ) : <TAB>  is_tuple = False <TAB>  if type ( data ) == tuple : <TAB><TAB>  data = list ( data ) <TAB><TAB>  is_tuple = True <TAB>  if type ( data ) == list : <TAB><TAB>  m_items = items . copy ( ) <TAB><TAB>  for idx , item in enumerate ( items ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  m_items [ idx ] = len ( data ) - abs ( item ) <TAB><TAB>  for i in sorted ( set ( m_items ) , reverse = True ) : <TAB><TAB><TAB>  if i < len ( data ) and i > - 1 : <TAB><TAB><TAB><TAB>  del data [ i ] <TAB><TAB>  if is_tuple : <TAB><TAB><TAB>  return tuple ( data ) <TAB><TAB>  else : <TAB><TAB><TAB>  return data <TAB>  else : <TAB><TAB>  return None ",if item < 0 :,if abs(item) < abs(data):,False,23.60574175460823,94.86503097194843
3248,"def _open_url ( cls , url ) : <TAB>  if config . browser : <TAB><TAB>  cmd = [ config . browser , url ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" running command:  %s "" % "" "" . join ( cmd ) ) <TAB><TAB>  p = Popen ( cmd ) <TAB><TAB>  p . communicate ( ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" opening URL in browser:  %s "" % url ) <TAB><TAB>  webbrowser . open_new ( url ) ",if not config . quiet :,if support.verbose:,False,20.204886742381653,92.05671192027128
3249,"def setLabel ( self , s , protect = False ) : <TAB>  """"""Set the label of the minibuffer."""""" <TAB>  c , k , w = self . c , self , self . w <TAB>  if w : <TAB><TAB>  # Support for the curses gui. <TAB><TAB>  if hasattr ( g . app . gui , "" set_minibuffer_label "" ) : <TAB><TAB><TAB>  g . app . gui . set_minibuffer_label ( c , s ) <TAB><TAB>  w . setAllText ( s ) <TAB><TAB>  n = len ( s ) <TAB><TAB>  w . setSelectionRange ( n , n , insert = n ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  k . mb_prefix = s ",if protect :,if protect:,False,56.16587870815333,100.00000000000004
3250,"def __init__ ( self , path ) : <TAB>  self . symcaches = [ ] <TAB>  for path in path . split ( "" ; "" ) : <TAB><TAB>  if os . path . isdir ( path ) : <TAB><TAB><TAB>  self . symcaches . append ( SymbolCache ( dirname = path ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  import cobra <TAB><TAB><TAB>  self . symcaches . append ( cobra . CobraProxy ( path ) ) <TAB><TAB><TAB>  continue ","if path . startswith ( ""cobra://"" ) or path . startswith ( ""cobrassl://"" ) :",if os.path.isfile(path):,False,49.50369796199704,85.54985807328899
3251,"def init_params ( net ) : <TAB>  """"""Init layer parameters."""""" <TAB>  for module in net . modules ( ) : <TAB><TAB>  if isinstance ( module , nn . Conv2d ) : <TAB><TAB><TAB>  init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB><TAB><TAB>  if module . bias : <TAB><TAB><TAB><TAB>  init . constant ( module . bias , 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  init . constant ( module . weight , 1 ) <TAB><TAB><TAB>  init . constant ( module . bias , 0 ) <TAB><TAB>  elif isinstance ( module , nn . Linear ) : <TAB><TAB><TAB>  init . normal ( module . weight , std = 1e-3 ) <TAB><TAB><TAB>  if module . bias : <TAB><TAB><TAB><TAB>  init . constant ( module . bias , 0 ) ","elif isinstance ( module , nn . BatchNorm2d ) :","if isinstance(module, nn.Dark):",False,25.8033172745452,97.88563349526193
3252,"def _diff_dict ( self , old , new ) : <TAB>  diff = { } <TAB>  removed = [ ] <TAB>  added = [ ] <TAB>  for key , value in old . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  removed . append ( key ) <TAB><TAB>  elif old [ key ] != new [ key ] : <TAB><TAB><TAB>  # modified is indicated by a remove and add <TAB><TAB><TAB>  removed . append ( key ) <TAB><TAB><TAB>  added . append ( key ) <TAB>  for key , value in new . items ( ) : <TAB><TAB>  if key not in old : <TAB><TAB><TAB>  added . append ( key ) <TAB>  if removed : <TAB><TAB>  diff [ "" removed "" ] = sorted ( removed ) <TAB>  if added : <TAB><TAB>  diff [ "" added "" ] = sorted ( added ) <TAB>  return diff ",if key not in new :,if key not in new:,False,57.70828099497158,100.00000000000004
3253,"def __init__ ( self , * args , * * kwargs ) : <TAB>  _kwargs = { <TAB><TAB>  "" max_length "" : 20 , <TAB><TAB>  "" widget "" : forms . TextInput ( attrs = { "" autocomplete "" : "" off "" } ) , <TAB><TAB>  "" label "" : _ ( "" Card number "" ) , <TAB>  } <TAB>  if "" types "" in kwargs : <TAB><TAB>  self . accepted_cards = set ( kwargs . pop ( "" types "" ) ) <TAB><TAB>  difference = self . accepted_cards - VALID_CARDS <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB>  "" The following accepted_cards are  "" "" unknown:  %s "" % difference <TAB><TAB><TAB>  ) <TAB>  _kwargs . update ( kwargs ) <TAB>  super ( ) . __init__ ( * args , * * _kwargs ) ",if difference :,if difference != 0:,False,22.4934439790501,98.02692339163623
3254,"def dumps ( self ) : <TAB>  sections = [ ] <TAB>  for name , env_info in self . _dependencies_ . items ( ) : <TAB><TAB>  sections . append ( "" [ENV_ %s ] "" % name ) <TAB><TAB>  for var , values in sorted ( env_info . vars . items ( ) ) : <TAB><TAB><TAB>  tmp = "" %s = "" % var <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tmp + = "" [ %s ] "" % "" , "" . join ( [ ' "" %s "" ' % val for val in values ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  tmp + = "" %s "" % values <TAB><TAB><TAB>  sections . append ( tmp ) <TAB>  return "" \n "" . join ( sections ) ","if isinstance ( values , list ) :","if isinstance(values, (list, tuple)):",False,33.06425700220874,97.1336633423649
3255,"def air_quality ( self ) : <TAB>  aqi_data = self . _get_aqi_data ( ) <TAB>  if aqi_data : <TAB><TAB>  if aqi_data . get ( "" status "" ) == "" ok "" : <TAB><TAB><TAB>  aqi_data = self . _organize ( aqi_data ) <TAB><TAB><TAB>  aqi_data = self . _manipulate ( aqi_data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . py3 . error ( aqi_data . get ( "" data "" ) ) <TAB>  return { <TAB><TAB>  "" cached_until "" : self . py3 . time_in ( self . cache_timeout ) , <TAB><TAB>  "" full_text "" : self . py3 . safe_format ( self . format , aqi_data ) , <TAB>  } ","elif aqi_data . get ( ""status"" ) == ""error"" :","if aqi_data.get('status') == ""error':",False,29.896300440081603,95.0368966868503
3256,"def _blend ( x , y ) :<TAB># pylint: disable=invalid-name <TAB>  """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB>  if isinstance ( x , ( dict , OrderedDict ) ) : <TAB><TAB>  if not isinstance ( y , ( dict , OrderedDict ) ) : <TAB><TAB><TAB>  return y <TAB><TAB>  return _merge ( x , y , recursion_func = _blend ) <TAB>  if isinstance ( x , ( list , tuple ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return y <TAB><TAB>  result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB><TAB>  if len ( x ) > len ( y ) : <TAB><TAB><TAB>  result + = x [ len ( y ) : ] <TAB><TAB>  elif len ( x ) < len ( y ) : <TAB><TAB><TAB>  result + = y [ len ( x ) : ] <TAB><TAB>  return result <TAB>  return y ","if not isinstance ( y , ( list , tuple ) ) :","if not isinstance(x, (tuple, list)):",False,11.249036564777134,95.96476270199001
3257,"def _rate ( cls , sample1 , sample2 ) : <TAB>  "" Simple rate "" <TAB>  try : <TAB><TAB>  interval = sample2 [ 0 ] - sample1 [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Infinity ( ) <TAB><TAB>  delta = sample2 [ 1 ] - sample1 [ 1 ] <TAB><TAB>  if delta < 0 : <TAB><TAB><TAB>  raise UnknownValue ( ) <TAB><TAB>  return ( sample2 [ 0 ] , delta / interval , sample2 [ 2 ] , sample2 [ 3 ] ) <TAB>  except Infinity : <TAB><TAB>  raise <TAB>  except UnknownValue : <TAB><TAB>  raise <TAB>  except Exception as e : <TAB><TAB>  raise NaN ( e ) ",if interval == 0 :,if interval < 0:,False,50.84217233836708,98.0139455733546
3258,"def wrapped_request_method ( * args , * * kwargs ) : <TAB>  """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB>  if kwargs . get ( "" headers "" ) is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if user_agent not in kwargs [ "" headers "" ] [ "" user-agent "" ] : <TAB><TAB><TAB><TAB>  # Save the existing user-agent header and tack on our own. <TAB><TAB><TAB><TAB>  kwargs [ "" headers "" ] [ "" user-agent "" ] = ( <TAB><TAB><TAB><TAB><TAB>  f "" { user_agent } "" f ' { kwargs [ "" headers "" ] [ "" user-agent "" ] } ' <TAB><TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  kwargs [ "" headers "" ] [ "" user-agent "" ] = user_agent <TAB>  else : <TAB><TAB>  kwargs [ "" headers "" ] = { "" user-agent "" : user_agent } <TAB>  return request_method ( * args , * * kwargs ) ","if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :",if user_agent is not None:,False,56.98390386908008,93.6727494766501
3259,"def remove_addons ( auth , resource_object_list ) : <TAB>  for config in AbstractNode . ADDONS_AVAILABLE : <TAB><TAB>  try : <TAB><TAB><TAB>  settings_model = config . node_settings <TAB><TAB>  except LookupError : <TAB><TAB><TAB>  settings_model = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  addon_list = settings_model . objects . filter ( <TAB><TAB><TAB><TAB>  owner__in = resource_object_list , is_deleted = False <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  for addon in addon_list : <TAB><TAB><TAB><TAB>  addon . after_delete ( auth . user ) ",if settings_model :,if settings_model:,False,51.29379614746339,100.00000000000004
3260,"def Decorator ( * args , * * kwargs ) : <TAB>  delay = 0.2 <TAB>  num_attempts = 15 <TAB>  cur_attempt = 0 <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  return f ( * args , * * kwargs ) <TAB><TAB>  except exceptions . WebDriverException as e : <TAB><TAB><TAB>  logging . warning ( "" Selenium raised  %s "" , utils . SmartUnicode ( e ) ) <TAB><TAB><TAB>  cur_attempt + = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  time . sleep ( delay ) ",if cur_attempt == num_attempts :,if cur_attempt == num_attempts:,False,44.79243032818141,100.00000000000004
3261,"def _cleanup_parts_dir ( parts_dir , local_plugins_dir , parts ) : <TAB>  if os . path . exists ( parts_dir ) : <TAB><TAB>  logger . info ( "" Cleaning up parts directory "" ) <TAB><TAB>  for subdirectory in os . listdir ( parts_dir ) : <TAB><TAB><TAB>  path = os . path . join ( parts_dir , subdirectory ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  shutil . rmtree ( path ) <TAB><TAB><TAB><TAB>  except NotADirectoryError : <TAB><TAB><TAB><TAB><TAB>  os . remove ( path ) <TAB>  for part in parts : <TAB><TAB>  part . mark_cleaned ( steps . BUILD ) <TAB><TAB>  part . mark_cleaned ( steps . PULL ) ",if path != local_plugins_dir :,if os.path.exists(path):,False,24.388737393431327,95.83687264160619
3262,"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB>  if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB><TAB>  return node_pos <TAB>  for t_idx , tree in enumerate ( trees ) : <TAB><TAB>  cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB><TAB>  # reach leaf <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  rs , reach_leaf = HeteroSecureBoostingTreeGuest . traverse_a_tree ( <TAB><TAB><TAB>  tree , sample , cur_node_idx <TAB><TAB>  ) <TAB><TAB>  if reach_leaf : <TAB><TAB><TAB>  node_pos [ "" reach_leaf_node "" ] [ t_idx ] = True <TAB><TAB>  node_pos [ "" node_pos "" ] [ t_idx ] = rs <TAB>  return node_pos ",if cur_node_idx == - 1 :,if cur_node_idx == -1:,False,50.92713367045486,100.00000000000004
3263,"def get_measurements ( self , pipeline , object_name , category ) : <TAB>  if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB><TAB>  results = [ ] <TAB><TAB>  if self . do_corr_and_slope : <TAB><TAB><TAB>  if object_name == "" Image "" : <TAB><TAB><TAB><TAB>  results + = [ "" Correlation "" , "" Slope "" ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results + = [ "" Correlation "" ] <TAB><TAB>  if self . do_overlap : <TAB><TAB><TAB>  results + = [ "" Overlap "" , "" K "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  results + = [ "" Manders "" ] <TAB><TAB>  if self . do_rwc : <TAB><TAB><TAB>  results + = [ "" RWC "" ] <TAB><TAB>  if self . do_costes : <TAB><TAB><TAB>  results + = [ "" Costes "" ] <TAB><TAB>  return results <TAB>  return [ ] ",if self . do_manders :,if self.do_manders:,False,43.05829699509132,100.00000000000004
3264,"def create_connection ( self , infos , f2 , laddr_infos , protocol ) : <TAB>  for family in infos : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for laddr in laddr_infos : <TAB><TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB><TAB>  except OSError : <TAB><TAB><TAB><TAB><TAB><TAB>  protocol = "" foo "" <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB>  except OSError : <TAB><TAB><TAB>  protocol = "" bar "" <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  raise <TAB>  return protocol ",if f2 :,if family == f2:,False,50.16674686346616,98.05254143282468
3265,"def app_middleware ( next , root , info , * * kwargs ) : <TAB>  app_auth_header = "" HTTP_AUTHORIZATION "" <TAB>  prefix = "" bearer "" <TAB>  request = info . context <TAB>  if request . path == API_PATH : <TAB><TAB>  if not hasattr ( request , "" app "" ) : <TAB><TAB><TAB>  request . app = None <TAB><TAB><TAB>  auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB><TAB><TAB>  if len ( auth ) == 2 : <TAB><TAB><TAB><TAB>  auth_prefix , auth_token = auth <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB>  return next ( root , info , * * kwargs ) ",if auth_prefix . lower ( ) == prefix :,if auth_prefix == prefix:,False,24.78330947790929,97.57488725657953
3266,"def when ( self , matches , context ) : <TAB>  ret = [ ] <TAB>  for episode in matches . named ( "" episode "" , lambda match : len ( match . initiator ) == 1 ) : <TAB><TAB>  group = matches . markers . at_match ( <TAB><TAB><TAB>  episode , lambda marker : marker . name == "" group "" , index = 0 <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not matches . range ( <TAB><TAB><TAB><TAB>  * group . span , predicate = lambda match : match . name == "" title "" <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  ret . append ( episode ) <TAB>  return ret ",if group :,if group:,False,50.700087142210336,100.00000000000004
3267,def locate_via_pep514 ( spec ) : <TAB>  with _PY_LOCK : <TAB><TAB>  if not _PY_AVAILABLE : <TAB><TAB><TAB>  from . import pep514 <TAB><TAB><TAB>  _PY_AVAILABLE . extend ( pep514 . discover_pythons ( ) ) <TAB><TAB><TAB>  _PY_AVAILABLE . append ( CURRENT ) <TAB>  for cur_spec in _PY_AVAILABLE : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return cur_spec . path ,if cur_spec . satisfies ( spec ) :,if cur_spec.spec.spec.spec.spec.spec.spec.spec.,False,21.939409367379856,88.97254190430122
3268,"def setCorkImageDefault ( self ) : <TAB>  if settings . corkBackground [ "" image "" ] != "" "" : <TAB><TAB>  i = self . cmbCorkImage . findData ( settings . corkBackground [ "" image "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . cmbCorkImage . setCurrentIndex ( i ) ",if i != - 1 :,if i != -1:,False,51.72818761991813,100.00000000000004
3269,"def _split_key ( key ) : <TAB>  if isinstance ( key , util . string_types ) : <TAB><TAB>  # coerce fooload('*') into ""default loader strategy"" <TAB><TAB>  if key == _WILDCARD_TOKEN : <TAB><TAB><TAB>  return ( _DEFAULT_TOKEN , ) <TAB><TAB>  # coerce fooload("".*"") into ""wildcard on default entity"" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  key = key [ 1 : ] <TAB><TAB>  return key . split ( "" . "" ) <TAB>  else : <TAB><TAB>  return ( key , ) ","elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :",if key.startswith('.'):,False,61.103612017374246,92.8146847399388
3270,"def detach_volume ( self , volume ) : <TAB>  # We need to find the node using this volume <TAB>  for node in self . list_nodes ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # This node has only one associated image. It is not the one we <TAB><TAB><TAB>  # are after. <TAB><TAB><TAB>  continue <TAB><TAB>  for disk in node . image : <TAB><TAB><TAB>  if disk . id == volume . id : <TAB><TAB><TAB><TAB>  # Node found. We can now detach the volume <TAB><TAB><TAB><TAB>  disk_id = disk . extra [ "" disk_id "" ] <TAB><TAB><TAB><TAB>  return self . _do_detach_volume ( node . id , disk_id ) <TAB>  return False ",if type ( node . image ) is not list :,if node.id == volume.id:,False,42.628624308155494,95.4474877037988
3271,"def create ( self , private = False ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( "" Creating private channel  %s . "" , self ) <TAB><TAB><TAB>  self . _bot . api_call ( <TAB><TAB><TAB><TAB>  "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  log . info ( "" Creating channel  %s . "" , self ) <TAB><TAB><TAB>  self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB>  except SlackAPIResponseError as e : <TAB><TAB>  if e . error == "" user_is_bot "" : <TAB><TAB><TAB>  raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise RoomError ( e ) ",if private :,if private:,False,49.181445692113314,100.00000000000004
3272,"def test_dataset_has_valid_etag ( self , dataset_name ) : <TAB>  py_script_path = list ( filter ( lambda x : x , dataset_name . split ( "" / "" ) ) ) [ - 1 ] + "" .py "" <TAB>  dataset_url = hf_bucket_url ( dataset_name , filename = py_script_path , dataset = True ) <TAB>  etag = None <TAB>  try : <TAB><TAB>  response = requests . head ( <TAB><TAB><TAB>  dataset_url , allow_redirects = True , proxies = None , timeout = 10 <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  etag = response . headers . get ( "" Etag "" ) <TAB>  except ( EnvironmentError , requests . exceptions . Timeout ) : <TAB><TAB>  pass <TAB>  self . assertIsNotNone ( etag ) ",if response . status_code == 200 :,if response.headers.get('Etag') is not None:,False,20.98027366738163,93.33688390499374
3273,"def set_dir_modes ( self , dirname , mode ) : <TAB>  if not self . is_chmod_supported ( ) : <TAB><TAB>  return <TAB>  for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB><TAB>  if os . path . islink ( dirpath ) : <TAB><TAB><TAB>  continue <TAB><TAB>  log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . chmod ( dirpath , mode ) ",if not self . dry_run :,if os.path.isdir(dirpath):,False,27.15045973257384,93.15711682467094
3274,"def _clean ( self ) : <TAB>  logger . info ( "" Cleaning up... "" ) <TAB>  if self . _process is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for _ in range ( 3 ) : <TAB><TAB><TAB><TAB>  self . _process . terminate ( ) <TAB><TAB><TAB><TAB>  time . sleep ( 0.5 ) <TAB><TAB><TAB><TAB>  if self . _process . poll ( ) is not None : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _process . kill ( ) <TAB><TAB><TAB><TAB>  self . _process . wait ( ) <TAB><TAB><TAB><TAB>  logger . error ( "" KILLED "" ) <TAB>  if os . path . exists ( self . _tmp_dir ) : <TAB><TAB>  shutil . rmtree ( self . _tmp_dir ) <TAB>  self . _process = None <TAB>  self . _ws = None <TAB>  logger . info ( "" Cleanup complete "" ) ",if self . _process . poll ( ) is None :,if self._process is not None:,False,51.501857241531525,97.7841245258306
3275,"def iter_chars_to_words ( self , chars ) : <TAB>  current_word = [ ] <TAB>  for char in chars : <TAB><TAB>  if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield current_word <TAB><TAB><TAB><TAB>  current_word = [ ] <TAB><TAB>  elif current_word and self . char_begins_new_word ( current_word , char ) : <TAB><TAB><TAB>  yield current_word <TAB><TAB><TAB>  current_word = [ char ] <TAB><TAB>  else : <TAB><TAB><TAB>  current_word . append ( char ) <TAB>  <IF-STMT>: <TAB><TAB>  yield current_word ",if current_word :,if current_word and char in current_word:,False,26.165168617094807,95.69202648262076
3276,"def _lookup ( components , specs , provided , name , i , l ) : <TAB>  if i < l : <TAB><TAB>  for spec in specs [ i ] . __sro__ : <TAB><TAB><TAB>  comps = components . get ( spec ) <TAB><TAB><TAB>  if comps : <TAB><TAB><TAB><TAB>  r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return r <TAB>  else : <TAB><TAB>  for iface in provided : <TAB><TAB><TAB>  comps = components . get ( iface ) <TAB><TAB><TAB>  if comps : <TAB><TAB><TAB><TAB>  r = comps . get ( name ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return r <TAB>  return None ",if r is not None :,if r:,False,21.845813774286096,95.4654764633353
3277,"def run ( cmd , task = None ) : <TAB>  process = subprocess . Popen ( <TAB><TAB>  cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , close_fds = True <TAB>  ) <TAB>  output_lines = [ ] <TAB>  while True : <TAB><TAB>  line = process . stdout . readline ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  line = line . decode ( "" utf-8 "" ) <TAB><TAB>  output_lines + = [ line ] <TAB><TAB>  logger . info ( line . rstrip ( "" \n "" ) ) <TAB>  process . stdout . close ( ) <TAB>  exit_code = process . wait ( ) <TAB>  if exit_code : <TAB><TAB>  output = "" "" . join ( output_lines ) <TAB><TAB>  raise subprocess . CalledProcessError ( exit_code , cmd , output = output ) ",if not line :,if not line:,False,43.78495046506645,100.00000000000004
3278,"def process_response ( self , request , response ) : <TAB>  if ( <TAB><TAB>  response . status_code == 404 <TAB><TAB>  and request . path_info . endswith ( "" / "" ) <TAB><TAB>  and not is_valid_path ( request . path_info ) <TAB><TAB>  and is_valid_path ( request . path_info [ : - 1 ] ) <TAB>  ) : <TAB><TAB>  # Use request.path because we munged app/locale in path_info. <TAB><TAB>  newurl = request . path [ : - 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with safe_query_string ( request ) : <TAB><TAB><TAB><TAB>  newurl + = "" ? "" + request . META [ "" QUERY_STRING "" ] <TAB><TAB>  return HttpResponsePermanentRedirect ( newurl ) <TAB>  return response ",if request . GET :,if request.META.get('QUERY_STRING'):,False,57.59713300028646,92.39213319393691
3279,"def dependencies ( self ) : <TAB>  deps = [ ] <TAB>  midx = None <TAB>  if self . ref is not None : <TAB><TAB>  query = TypeQuery ( self . ref ) <TAB><TAB>  super = query . execute ( self . schema ) <TAB><TAB>  if super is None : <TAB><TAB><TAB>  log . debug ( self . schema ) <TAB><TAB><TAB>  raise TypeNotFound ( self . ref ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  deps . append ( super ) <TAB><TAB><TAB>  midx = 0 <TAB>  return ( midx , deps ) ",if not super . builtin ( ) :,if super.type == self.type:,False,33.05207444280921,94.31868681803341
3280,"def _get_vtkjs ( self ) : <TAB>  if self . _vtkjs is None and self . object is not None : <TAB><TAB>  if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  with open ( self . object , "" rb "" ) as f : <TAB><TAB><TAB><TAB><TAB>  vtkjs = f . read ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  data_url = urlopen ( self . object ) <TAB><TAB><TAB><TAB>  vtkjs = data_url . read ( ) <TAB><TAB>  elif hasattr ( self . object , "" read "" ) : <TAB><TAB><TAB>  vtkjs = self . object . read ( ) <TAB><TAB>  self . _vtkjs = vtkjs <TAB>  return self . _vtkjs ",if isfile ( self . object ) :,"if hasattr(self.object, 'read'):",False,50.63143607154614,97.40979829483996
3281,"def _save ( self ) : <TAB>  fd , tempname = tempfile . mkstemp ( ) <TAB>  fd = os . fdopen ( fd , "" w "" ) <TAB>  json . dump ( self . _cache , fd , indent = 2 , separators = ( "" , "" , "" :  "" ) ) <TAB>  fd . close ( ) <TAB>  # Silently ignore errors <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( os . path . dirname ( self . filename ) ) <TAB><TAB>  shutil . move ( tempname , self . filename ) <TAB>  except ( IOError , OSError ) : <TAB><TAB>  os . remove ( tempname ) ",if not os . path . exists ( os . path . dirname ( self . filename ) ) :,if not os.path.exists(os.path.dirname(self.filename)):,False,51.010275019446574,100.00000000000004
3282,"def refiner_configs ( self ) : <TAB>  rv = { } <TAB>  for refiner in refiner_manager : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rv [ refiner . name ] = { k : v for k , v in self . config . items ( refiner . name ) } <TAB>  return rv ",if self . config . has_section ( refiner . name ) :,if refiner.name in self.config.items():,False,48.12413016895084,90.07799849424036
3283,"def com_slice ( self , primary , node , assigning ) : <TAB>  # short_slice:  [lower_bound] "":"" [upper_bound] <TAB>  lower = upper = None <TAB>  if len ( node . children ) == 2 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  upper = self . com_node ( node . children [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  lower = self . com_node ( node . children [ 0 ] ) <TAB>  elif len ( node . children ) == 3 : <TAB><TAB>  lower = self . com_node ( node . children [ 0 ] ) <TAB><TAB>  upper = self . com_node ( node . children [ 2 ] ) <TAB>  return Slice ( primary , assigning , lower , upper , lineno = extractLineNo ( node ) ) ",if node . children [ 0 ] . type == token . COLON :,if len(node.children) == 1:,False,26.90321294968518,94.12905011650673
3284,"def close ( self , * args , * * kwargs ) : <TAB>  super ( mytqdm , self ) . close ( * args , * * kwargs ) <TAB>  # If it was not run in a notebook, sp is not assigned, check for it <TAB>  if hasattr ( self , "" sp "" ) : <TAB><TAB>  # Try to detect if there was an error or KeyboardInterrupt <TAB><TAB>  # in manual mode: if n < total, things probably got wrong <TAB><TAB>  if self . total and self . n < self . total : <TAB><TAB><TAB>  self . sp ( bar_style = "" danger "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . sp ( bar_style = "" success "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . sp ( close = True ) ",if self . leave :,if self.n == 0:,False,57.4316094339378,97.51294661524922
3285,"def test_alloc ( self ) : <TAB>  b = bytearray ( ) <TAB>  alloc = b . __alloc__ ( ) <TAB>  self . assertTrue ( alloc > = 0 ) <TAB>  seq = [ alloc ] <TAB>  for i in range ( 100 ) : <TAB><TAB>  b + = b "" x "" <TAB><TAB>  alloc = b . __alloc__ ( ) <TAB><TAB>  self . assertTrue ( alloc > = len ( b ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  seq . append ( alloc ) ",if alloc not in seq :,if alloc not in seq:,False,20.84006632406834,100.00000000000004
3286,"def flush_file ( self , key , f ) : <TAB>  f . flush ( ) <TAB>  <IF-STMT>: <TAB><TAB>  f . compress = zlib . compressobj ( <TAB><TAB><TAB>  9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB><TAB>  ) <TAB>  if len ( self . files ) > self . MAX_OPEN_FILES : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB><TAB><TAB>  if open_files > self . MAX_OPEN_FILES : <TAB><TAB><TAB><TAB>  f . fileobj . close ( ) <TAB><TAB><TAB><TAB>  f . fileobj = None <TAB><TAB>  else : <TAB><TAB><TAB>  f . close ( ) <TAB><TAB><TAB>  self . files . pop ( key ) ",if self . compress :,if self.compress:,False,23.32345944930693,96.63653082550934
3287,"def _run ( self ) : <TAB>  # Low-level run method to do the actual scheduling loop. <TAB>  self . running = True <TAB>  while self . running : <TAB><TAB>  try : <TAB><TAB><TAB>  self . sched . run ( ) <TAB><TAB>  except Exception as x : <TAB><TAB><TAB>  logging . error ( <TAB><TAB><TAB><TAB>  "" Error during scheduler execution:  %s "" % str ( x ) , exc_info = True <TAB><TAB><TAB>  ) <TAB><TAB>  # queue is empty; sleep a short while before checking again <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  time . sleep ( 5 ) ",if self . running :,if not self.queue:,False,41.911694188303805,97.19994472531465
3288,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  self . set_app_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_max_rows ( d . getVarInt32 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 16 :,if tt == 10:,False,51.36809638600636,98.41504940787179
3289,"def check ( dbdef ) : <TAB>  "" drop script must clear the database "" <TAB>  for version in dbdef : <TAB><TAB>  connector = MemConnector ( ) . bound ( None ) <TAB><TAB>  create ( dbdef , version , connector ) <TAB><TAB>  drop ( dbdef , version , connector ) <TAB><TAB>  remaining = connector . execute ( <TAB><TAB><TAB>  "" SELECT * FROM sqlite_master WHERE name NOT LIKE  ' sqlite_ % ' "" <TAB><TAB>  ) . fetchall ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield "" {0} :drop.sql "" . format ( version ) , remaining ",if remaining :,if remaining:,False,60.65364372152773,97.6812777495059
3290,"def test_open_overwrite_offset_size ( self , sftp ) : <TAB>  """"""Test writing data at a specific offset"""""" <TAB>  f = None <TAB>  try : <TAB><TAB>  self . _create_file ( "" file "" , "" xxxxyyyy "" ) <TAB><TAB>  f = yield from sftp . open ( "" file "" , "" r+ "" ) <TAB><TAB>  yield from f . write ( "" zz "" , 3 ) <TAB><TAB>  yield from f . close ( ) <TAB><TAB>  with open ( "" file "" ) as localf : <TAB><TAB><TAB>  self . assertEqual ( localf . read ( ) , "" xxxzzyyy "" ) <TAB>  finally : <TAB><TAB>  <IF-STMT>:<TAB># pragma: no branch <TAB><TAB><TAB>  yield from f . close ( ) <TAB><TAB>  remove ( "" file "" ) ",if f :,if f is not None:,False,52.76345384578234,96.03655362458737
3291,"def pump ( ) : <TAB>  import sys as _sys <TAB>  while self . countdown_active ( ) : <TAB><TAB>  if not ( self . connected ( "" send "" ) and other . connected ( "" recv "" ) ) : <TAB><TAB><TAB>  break <TAB><TAB>  try : <TAB><TAB><TAB>  data = other . recv ( timeout = 0.05 ) <TAB><TAB>  except EOFError : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  if not data : <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  self . send ( data ) <TAB><TAB>  except EOFError : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB>  self . shutdown ( "" send "" ) <TAB>  other . shutdown ( "" recv "" ) ",if not _sys :,if _sys.platform == 'win32':,False,22.147367229106464,94.80517605104771
3292,"def parse_results ( cwd ) : <TAB>  optimal_dd = None <TAB>  optimal_measure = numpy . inf <TAB>  for tup in tools . find_conf_files ( cwd ) : <TAB><TAB>  dd = tup [ 1 ] <TAB><TAB>  if "" results.train_y_misclass "" in dd : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB><TAB><TAB><TAB>  optimal_dd = dd <TAB>  print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB>  for key , value in optimal_dd . items ( ) : <TAB><TAB>  if "" hyper_parameters "" in key : <TAB><TAB><TAB>  print ( key + "" :  "" + str ( value ) ) ","if dd [ ""results.train_y_misclass"" ] < optimal_measure :","if ""results.train_y_misclass"" in dd:",False,22.65304503262641,95.57498799214288
3293,"def valid ( self ) : <TAB>  valid = True <TAB>  <IF-STMT>: <TAB><TAB>  return valid <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  with io . open ( self . pathfile , "" w "" , encoding = "" utf-8 "" ) as f : <TAB><TAB><TAB><TAB>  f . close ( )<TAB># do nothing <TAB><TAB>  except OSError : <TAB><TAB><TAB>  valid = False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . remove ( self . pathfile ) <TAB><TAB>  return valid ",if os . path . exists ( self . pathfile ) :,if os.path.exists(self.pathfile):,False,22.88609567267513,91.29204426569284
3294,"def __getitem__ ( self , key ) : <TAB>  try : <TAB><TAB>  value = self . cache [ key ] <TAB>  except KeyError : <TAB><TAB>  f = BytesIO ( self . dict [ key . encode ( self . keyencoding ) ] ) <TAB><TAB>  value = Unpickler ( f ) . load ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . cache [ key ] = value <TAB>  return value ",if self . writeback :,if value is not None:,False,30.316256175794948,94.96016038707516
3295,"def hasMenu ( cls , callingWindow , mainItem , selection , * fullContexts ) : <TAB>  for i , fullContext in enumerate ( fullContexts ) : <TAB><TAB>  srcContext = fullContext [ 0 ] <TAB><TAB>  for menuHandler in cls . menus : <TAB><TAB><TAB>  m = menuHandler ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB><TAB>  return False ","if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :",if m.isChecked():,False,20.28842433524207,89.7297170763363
3296,"def lr_read_tables ( module = tab_module , optimize = 0 ) : <TAB>  global _lr_action , _lr_goto , _lr_productions , _lr_method <TAB>  try : <TAB><TAB>  exec ( "" import  %s  as parsetab "" % module ) <TAB><TAB>  global parsetab<TAB># declare the name of the imported module <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _lr_action = parsetab . _lr_action <TAB><TAB><TAB>  _lr_goto = parsetab . _lr_goto <TAB><TAB><TAB>  _lr_productions = parsetab . _lr_productions <TAB><TAB><TAB>  _lr_method = parsetab . _lr_method <TAB><TAB><TAB>  return 1 <TAB><TAB>  else : <TAB><TAB><TAB>  return 0 <TAB>  except ( ImportError , AttributeError ) : <TAB><TAB>  return 0 ",if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,if parsetab is not None and (not optimize):,False,47.90647683584454,91.39137572725879
3297,"def _Determine_Do ( self ) : <TAB>  if sys . platform . startswith ( "" win "" ) : <TAB><TAB>  self . applicable = 1 <TAB><TAB>  for opt , optarg in self . chosenOptions : <TAB><TAB><TAB>  if opt == "" --moz-tools "" : <TAB><TAB><TAB><TAB>  self . value = os . path . abspath ( os . path . normpath ( optarg ) ) <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . value = os . environ [ self . name ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . value = None <TAB>  else : <TAB><TAB>  self . applicable = 0 <TAB>  self . determined = 1 ",if os . environ . has_key ( self . name ) :,if self.name in os.environ:,False,48.75235265050354,95.11868333424167
3298,"def parse_chunked ( self , unreader ) : <TAB>  ( size , rest ) = self . parse_chunk_size ( unreader ) <TAB>  while size > 0 : <TAB><TAB>  while size > len ( rest ) : <TAB><TAB><TAB>  size - = len ( rest ) <TAB><TAB><TAB>  yield rest <TAB><TAB><TAB>  rest = unreader . read ( ) <TAB><TAB><TAB>  if not rest : <TAB><TAB><TAB><TAB>  raise NoMoreData ( ) <TAB><TAB>  yield rest [ : size ] <TAB><TAB>  # Remove \r\n after chunk <TAB><TAB>  rest = rest [ size : ] <TAB><TAB>  while len ( rest ) < 2 : <TAB><TAB><TAB>  rest + = unreader . read ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ChunkMissingTerminator ( rest [ : 2 ] ) <TAB><TAB>  ( size , rest ) = self . parse_chunk_size ( unreader , data = rest [ 2 : ] ) ","if rest [ : 2 ] != b""\r\n"" :",if len(rest) < 2:,False,48.71443900555836,94.22954487557975
3299,"def _scroll_down ( self , cli ) : <TAB>  "" Scroll window down. "" <TAB>  info = self . render_info <TAB>  if self . vertical_scroll < info . content_height - info . window_height : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . content . move_cursor_down ( cli ) <TAB><TAB>  self . vertical_scroll + = 1 ",if info . cursor_position . y <= info . configured_scroll_offsets . top :,if self.content:,False,45.74215329118558,82.0020270151135
3300,"def _add_defaults_data_files ( self ) : <TAB>  # getting distribution.data_files <TAB>  if self . distribution . has_data_files ( ) : <TAB><TAB>  for item in self . distribution . data_files : <TAB><TAB><TAB>  if isinstance ( item , str ) : <TAB><TAB><TAB><TAB>  # plain file <TAB><TAB><TAB><TAB>  item = convert_path ( item ) <TAB><TAB><TAB><TAB>  if os . path . isfile ( item ) : <TAB><TAB><TAB><TAB><TAB>  self . filelist . append ( item ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # a (dirname, filenames) tuple <TAB><TAB><TAB><TAB>  dirname , filenames = item <TAB><TAB><TAB><TAB>  for f in filenames : <TAB><TAB><TAB><TAB><TAB>  f = convert_path ( f ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  self . filelist . append ( f ) ",if os . path . isfile ( f ) :,if os.path.isfile(f):,False,27.01479851899176,100.00000000000004
3301,"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB>  for i in range ( upto ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if i == 2 and self . count < 1 : <TAB><TAB><TAB>  self . count + = 1 <TAB><TAB><TAB>  raise TemporaryProblem <TAB><TAB>  if i == 7 and self . count < 4 : <TAB><TAB><TAB>  self . count + = 1 <TAB><TAB><TAB>  raise TemporaryProblem <TAB><TAB>  yield i ",if i <= start_after :,if start_after <= i:,False,52.32769897829142,94.20336635493564
3302,"def is_open ( self ) : <TAB>  if self . signup_code : <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . messages . get ( "" invalid_signup_code "" ) : <TAB><TAB><TAB><TAB>  messages . add_message ( <TAB><TAB><TAB><TAB><TAB>  self . request , <TAB><TAB><TAB><TAB><TAB>  self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB><TAB><TAB><TAB><TAB>  self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB><TAB><TAB><TAB><TAB><TAB>  * * { <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" code "" : self . get_code ( ) , <TAB><TAB><TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  ) <TAB>  return settings . ACCOUNT_OPEN_SIGNUP ",if self . signup_code_present :,if self.get_code() is not None:,False,49.893868300209284,96.99343171164581
3303,"def on_delete_from_disk ( self , widget , data = None ) : <TAB>  model , iter = self . get_selection ( ) . get_selected ( ) <TAB>  if iter : <TAB><TAB>  path = model . get_value ( iter , COLUMN_PATH ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ErrorDialog ( _ ( "" Can ' t delete system item from disk. "" ) ) . launch ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  os . remove ( path ) <TAB>  self . update_items ( ) ",if self . is_defaultitem ( path ) :,if path is None:,False,31.334677476562494,91.71350144932259
3304,"def get_detections_for_batch ( self , images ) : <TAB>  images = images [ . . . , : : - 1 ] <TAB>  detected_faces = self . face_detector . detect_from_batch ( images . copy ( ) ) <TAB>  results = [ ] <TAB>  for i , d in enumerate ( detected_faces ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  results . append ( None ) <TAB><TAB><TAB>  continue <TAB><TAB>  d = d [ 0 ] <TAB><TAB>  d = np . clip ( d , 0 , None ) <TAB><TAB>  x1 , y1 , x2 , y2 = map ( int , d [ : - 1 ] ) <TAB><TAB>  results . append ( ( x1 , y1 , x2 , y2 ) ) <TAB>  return results ",if len ( d ) == 0 :,if d is None:,False,24.70854434605717,93.12337852742783
3305,def on_update ( self ) : <TAB>  # <TAB>  # Calculate maximum # of planes per well <TAB>  # <TAB>  self . max_per_well = 0 <TAB>  for pd in list ( self . plate_well_site . values ( ) ) : <TAB><TAB>  for wd in list ( pd . values ( ) ) : <TAB><TAB><TAB>  nplanes = sum ( [ len ( x ) for x in list ( wd . values ( ) ) ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . max_per_well = nplanes <TAB>  for registrant in self . registrants : <TAB><TAB>  registrant ( ) ,if nplanes > self . max_per_well :,if nplanes > self.max_per_well:,False,33.78848232335226,100.00000000000004
3306,"def is_writable ( self , path ) : <TAB>  result = False <TAB>  while not result : <TAB><TAB>  if os . path . exists ( path ) : <TAB><TAB><TAB>  result = os . access ( path , os . W_OK ) <TAB><TAB><TAB>  break <TAB><TAB>  parent = os . path . dirname ( path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  path = parent <TAB>  return result ",if parent == path :,if os.path.exists(parent):,False,29.13487104775385,92.85977081374857
3307,"def _check_seed ( self , seed ) : <TAB>  if seed is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _raise_error ( <TAB><TAB><TAB><TAB>  "" The random number generator seed value, seed, should be integer type or None. "" <TAB><TAB><TAB>  ) <TAB><TAB>  if seed < 0 : <TAB><TAB><TAB>  self . _raise_error ( <TAB><TAB><TAB><TAB>  "" The random number generator seed value, seed, should be non-negative integer or None. "" <TAB><TAB><TAB>  ) ",if type ( seed ) != int :,if seed < 0:,False,68.95863380530952,94.70878179165173
3308,"def write ( self , x ) : <TAB>  # try to use backslash and surrogate escape strategies before failing <TAB>  self . _errors = "" backslashescape "" if self . encoding != "" mbcs "" else "" surrogateescape "" <TAB>  try : <TAB><TAB>  return io . TextIOWrapper . write ( self , to_text ( x , errors = self . _errors ) ) <TAB>  except UnicodeDecodeError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _errors = "" surrogateescape "" <TAB><TAB>  else : <TAB><TAB><TAB>  self . _errors = "" replace "" <TAB><TAB>  return io . TextIOWrapper . write ( self , to_text ( x , errors = self . _errors ) ) ","if self . _errors != ""surrogateescape"" :",if self.encoding == 'mbcs':,False,34.260064571428465,95.20773220529162
3309,"def post ( self , request , * args , * * kwargs ) : <TAB>  validated_session = [ ] <TAB>  for session_id in request . data : <TAB><TAB>  session = get_object_or_none ( Session , id = session_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  validated_session . append ( session_id ) <TAB><TAB><TAB>  self . model . objects . create ( <TAB><TAB><TAB><TAB>  name = "" kill_session "" , <TAB><TAB><TAB><TAB>  args = session . id , <TAB><TAB><TAB><TAB>  terminal = session . terminal , <TAB><TAB><TAB>  ) <TAB>  return Response ( { "" ok "" : validated_session } ) ",if session and not session . is_finished :,if session.id == session_id:,False,30.120066622035957,96.08943587489773
3310,"def _has_list_or_dict_var_value_before ( self , arg_index ) : <TAB>  for idx , value in enumerate ( self . args ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  if variablematcher . is_list_variable ( <TAB><TAB><TAB>  value <TAB><TAB>  ) and not variablematcher . is_list_variable_subitem ( value ) : <TAB><TAB><TAB>  return True <TAB><TAB>  if robotapi . is_dict_var ( value ) and not variablematcher . is_dict_var_access ( <TAB><TAB><TAB>  value <TAB><TAB>  ) : <TAB><TAB><TAB>  return True <TAB>  return False ",if idx > arg_index :,if idx == arg_index:,False,26.262925214135617,98.07637870082021
3311,"def test_return_correct_type ( self ) : <TAB>  for proto in protocols : <TAB><TAB>  # Protocol 0 supports only ASCII strings. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _check_return_correct_type ( "" abc "" , 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  for obj in [ b "" abc \n "" , "" abc \n "" , - 1 , - 1.1 * 0.1 , str ] : <TAB><TAB><TAB><TAB>  self . _check_return_correct_type ( obj , proto ) ",if proto == 0 :,if proto == 0:,False,57.141005309301086,95.59980500022364
3312,"def backward_impl ( self , inputs , outputs , prop_down , accum ) : <TAB>  # inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or <TAB>  # [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph] <TAB>  # Args <TAB>  axis = self . forward_func . info . args [ "" axis "" ] <TAB>  # Compute <TAB>  ## w.r.t. dy <TAB>  if prop_down [ - 1 ] : <TAB><TAB>  g_dy = inputs [ - 1 ] . grad <TAB><TAB>  g_dy_ = F . stack ( * [ o . grad for o in outputs ] , axis = axis ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g_dy + = g_dy_ <TAB><TAB>  else : <TAB><TAB><TAB>  g_dy . copy_from ( g_dy_ ) ",if accum [ - 1 ] :,if prop_down[-1] and g_dy_.dim == 1:,False,31.089457398559027,90.6099410206051
3313,"def remove ( self , url ) : <TAB>  try : <TAB><TAB>  i = self . items . index ( url ) <TAB>  except ( ValueError , IndexError ) : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  was_selected = i in self . selectedindices ( ) <TAB><TAB>  self . list . delete ( i ) <TAB><TAB>  del self . items [ i ] <TAB><TAB>  if not self . items : <TAB><TAB><TAB>  self . mp . hidepanel ( self . name ) <TAB><TAB>  elif was_selected : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  i = len ( self . items ) - 1 <TAB><TAB><TAB>  self . list . select_set ( i ) ",if i >= len ( self . items ) :,if was_selected:,False,46.29941169399374,94.62858681586103
3314,"def prepend ( self , value ) : <TAB>  """"""prepend value to nodes"""""" <TAB>  root , root_text = self . _get_root ( value ) <TAB>  for i , tag in enumerate ( self ) : <TAB><TAB>  if not tag . text : <TAB><TAB><TAB>  tag . text = "" "" <TAB><TAB>  if len ( root ) > 0 : <TAB><TAB><TAB>  root [ - 1 ] . tail = tag . text <TAB><TAB><TAB>  tag . text = root_text <TAB><TAB>  else : <TAB><TAB><TAB>  tag . text = root_text + tag . text <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  root = deepcopy ( list ( root ) ) <TAB><TAB>  tag [ : 0 ] = root <TAB><TAB>  root = tag [ : len ( root ) ] <TAB>  return self ",if i > 0 :,if root is not None:,False,25.854525873285706,95.88884027423882
3315,"def _get_tracks_compositors_list ( ) : <TAB>  tracks_list = [ ] <TAB>  tracks = current_sequence ( ) . tracks <TAB>  compositors = current_sequence ( ) . compositors <TAB>  for track_index in range ( 1 , len ( tracks ) - 1 ) : <TAB><TAB>  track_compositors = [ ] <TAB><TAB>  for j in range ( 0 , len ( compositors ) ) : <TAB><TAB><TAB>  comp = compositors [ j ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  track_compositors . append ( comp ) <TAB><TAB>  tracks_list . append ( track_compositors ) <TAB>  return tracks_list ",if comp . transition . b_track == track_index :,if comp not in tracks:,False,21.325944684671054,92.80754364518884
3316,"def __getattr__ ( self , name ) : <TAB>  if name in self . _sections : <TAB><TAB>  return "" \n "" . join ( self . _sections [ name ] ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  raise ConanException ( "" ConfigParser: Unrecognized field  ' %s ' "" % name ) ",if self . _allowed_fields and name in self . _allowed_fields :,if name == 'section':,False,23.16643325915599,83.4676296428395
3317,"def get_first_param_index ( self , group_id , param_group , partition_id ) : <TAB>  for index , param in enumerate ( param_group ) : <TAB><TAB>  param_id = self . get_param_id ( param ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return index <TAB>  return None ",if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,if param_id == partition_id:,False,18.892488069527186,78.5362248634572
3318,"def handle_uv_sockets ( self , context ) : <TAB>  u_socket = self . inputs [ "" U "" ] <TAB>  v_socket = self . inputs [ "" V "" ] <TAB>  if self . cast_mode == "" Sphere "" : <TAB><TAB>  u_socket . hide_safe = True <TAB><TAB>  v_socket . hide_safe = True <TAB>  elif self . cast_mode in [ "" Cylinder "" , "" Prism "" ] : <TAB><TAB>  v_socket . hide_safe = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  u_socket . hide_safe = False <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  u_socket . hide_safe = False <TAB><TAB>  if v_socket . hide_safe : <TAB><TAB><TAB>  v_socket . hide_safe = False ",if u_socket . hide_safe :,"if self.cast_mode == ""Sawyer':",False,21.29609900283905,92.18840849778853
3319,"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB>  """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB>  for root , _ , filenames in safe_walk ( target_workdir ) : <TAB><TAB>  for filename in filenames : <TAB><TAB><TAB>  source = os . path . join ( root , filename ) <TAB><TAB><TAB>  with open ( source , "" r "" ) as f : <TAB><TAB><TAB><TAB>  lines = f . readlines ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  with open ( source , "" w "" ) as f : <TAB><TAB><TAB><TAB>  if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) : <TAB><TAB><TAB><TAB><TAB>  f . write ( lines [ 0 ] ) <TAB><TAB><TAB><TAB>  for line in lines [ 1 : ] : <TAB><TAB><TAB><TAB><TAB>  f . write ( line ) ",if len ( lines ) < 1 :,if not lines:,False,33.21758149313722,97.3906287538717
3320,"def inner ( request , * args , * * kwargs ) : <TAB>  page = request . current_page <TAB>  if page : <TAB><TAB>  if page . login_required and not request . user . is_authenticated : <TAB><TAB><TAB>  return redirect_to_login ( <TAB><TAB><TAB><TAB>  urlquote ( request . get_full_path ( ) ) , settings . LOGIN_URL <TAB><TAB><TAB>  ) <TAB><TAB>  site = get_current_site ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return _handle_no_page ( request ) <TAB>  return func ( request , * args , * * kwargs ) ","if not user_can_view_page ( request . user , page , site ) :",if not site.is_current_user_admin():,False,20.33409851880045,91.86854385764168
3321,"def flush ( self , * args , * * kwargs ) : <TAB>  with self . _lock : <TAB><TAB>  self . _last_updated = time . time ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  if "" _create_temporary "" in traceback . format_exc ( ) : <TAB><TAB><TAB><TAB>  self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  self . _last_updated = time . time ( ) ","if kwargs . get ( ""in_place"" , False ) :",if self._is_tempfile_available():,False,46.48210399177394,94.9163871792575
3322,"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB>  # Sanity check: Don't honor keys that we don't recognize. <TAB>  for key in list ( kwargs . keys ( ) ) : <TAB><TAB>  if key not in valid_keys : <TAB><TAB><TAB>  kwargs . pop ( key ) <TAB>  # Truncate certain values over 1k <TAB>  for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if len ( kwargs [ "" event_data "" ] [ key ] ) > 1024 : <TAB><TAB><TAB><TAB>  kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB><TAB><TAB><TAB><TAB>  1024 <TAB><TAB><TAB><TAB>  ) ","if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :",if key not in kwargs:,False,35.47408747830264,89.39044252645482
3323,"def parse_auth ( val ) : <TAB>  if val is not None : <TAB><TAB>  authtype , params = val . split ( "" "" , 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if authtype == "" Basic "" and ' "" ' not in params : <TAB><TAB><TAB><TAB>  # this is the ""Authentication: Basic XXXXX=="" case <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  params = parse_auth_params ( params ) <TAB><TAB>  return authtype , params <TAB>  return val ",if authtype in known_auth_schemes :,if authtype == 'Basic':,False,52.93485165004268,95.28997860623909
3324,"def _memoized ( * args ) : <TAB>  now = time . time ( ) <TAB>  try : <TAB><TAB>  value , last_update = self . cache [ args ] <TAB><TAB>  age = now - last_update <TAB><TAB>  if self . _call_count > self . ctl or age > self . ttl : <TAB><TAB><TAB>  self . _call_count = 0 <TAB><TAB><TAB>  raise AttributeError <TAB><TAB>  if self . ctl : <TAB><TAB><TAB>  self . _call_count + = 1 <TAB><TAB>  return value <TAB>  except ( KeyError , AttributeError ) : <TAB><TAB>  value = func ( * args ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . cache [ args ] = ( value , now ) <TAB><TAB>  return value <TAB>  except TypeError : <TAB><TAB>  return func ( * args ) ",if value :,if value is not None:,False,23.35234295297431,97.98269523212632
3325,"def _get_md_bg_color_down ( self ) : <TAB>  t = self . theme_cls <TAB>  c = self . md_bg_color<TAB># Default to no change on touch <TAB>  # Material design specifies using darker hue when on Dark theme <TAB>  if t . theme_style == "" Dark "" : <TAB><TAB>  if self . md_bg_color == t . primary_color : <TAB><TAB><TAB>  c = t . primary_dark <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  c = t . accent_dark <TAB>  return c ",elif self . md_bg_color == t . accent_color :,"if t.theme_style == ""Hue':",False,32.20033238246612,89.28329842527963
3326,def _init_table_h ( ) : <TAB>  _table_h = [ ] <TAB>  for i in range ( 256 ) : <TAB><TAB>  part_l = i <TAB><TAB>  part_h = 0 <TAB><TAB>  for j in range ( 8 ) : <TAB><TAB><TAB>  rflag = part_l & 1 <TAB><TAB><TAB>  part_l >> = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  part_l | = 1 << 31 <TAB><TAB><TAB>  part_h >> = 1 <TAB><TAB><TAB>  if rflag : <TAB><TAB><TAB><TAB>  part_h ^ = 0xD8000000 <TAB><TAB>  _table_h . append ( part_h ) <TAB>  return _table_h ,if part_h & 1 :,if rflag:,False,19.943837605958706,96.82773319490279
3327,"def migrate_Stats ( self ) : <TAB>  for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB><TAB>  if not old_obj . summary : <TAB><TAB><TAB>  self . entries_count [ "" Stats "" ] - = 1 <TAB><TAB><TAB>  continue <TAB><TAB>  new_obj = self . model_to [ "" Stats "" ] ( ) <TAB><TAB>  for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB><TAB>  self . session_new . add ( new_obj ) ",if key not in old_obj . __table__ . columns :,if key == 'Stats':,False,22.161526794131,93.09581099426599
3328,"def get_in_turn_repetition ( pred , is_cn = False ) : <TAB>  """"""Get in-turn repetition."""""" <TAB>  if len ( pred ) == 0 : <TAB><TAB>  return 1.0 <TAB>  if isinstance ( pred [ 0 ] , str ) : <TAB><TAB>  pred = [ tok . lower ( ) for tok in pred ] <TAB><TAB>  if is_cn : <TAB><TAB><TAB>  pred = "" "" . join ( pred ) <TAB>  tri_grams = set ( ) <TAB>  for i in range ( len ( pred ) - 2 ) : <TAB><TAB>  tri_gram = tuple ( pred [ i : i + 3 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return 1.0 <TAB><TAB>  tri_grams . add ( tri_gram ) <TAB>  return 0.0 ",if tri_gram in tri_grams :,if tri_gram in tri_grams:,False,52.08144680653647,100.00000000000004
3329,"def translate ( ) : <TAB>  assert Lex . next ( ) is AttributeList <TAB>  reader . read ( )<TAB># Discard attribute list from reader. <TAB>  attrs = { } <TAB>  d = AttributeList . match . groupdict ( ) <TAB>  for k , v in d . items ( ) : <TAB><TAB>  if v is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  v = subs_attrs ( v ) <TAB><TAB><TAB><TAB>  if v : <TAB><TAB><TAB><TAB><TAB>  parse_attributes ( v , attrs ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  AttributeList . attrs [ k ] = v <TAB>  AttributeList . subs ( attrs ) <TAB>  AttributeList . attrs . update ( attrs ) ","if k == ""attrlist"" :",if k == 'attrs':,False,45.93603229207839,96.51318532280636
3330,"def _parse ( self , engine ) : <TAB>  """"""Parse the layer."""""" <TAB>  if isinstance ( self . args , dict ) : <TAB><TAB>  if "" axis "" in self . args : <TAB><TAB><TAB>  self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB>  if "" momentum "" in self . args : <TAB><TAB><TAB>  self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB>  if not isinstance ( self . momentum , ( int , float ) ) : <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if not isinstance ( self . axis , int ) :","if not isinstance(self.axis, (int, float)):",False,25.127447196385717,97.18530167964184
3331,"def __getattr__ ( self , attrname ) : <TAB>  if attrname in ( "" visamp "" , "" visamperr "" , "" visphi "" , "" visphierr "" ) : <TAB><TAB>  return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB>  elif attrname in ( "" cflux "" , "" cfluxerr "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  else : <TAB><TAB>  raise AttributeError ( attrname ) ","if self . __dict__ [ ""_"" + attrname ] != None :","if attrname in (""visamp"", ""visamperr""):",False,24.991189457382035,90.17813158230516
3332,"def draw ( self , context ) : <TAB>  layout = self . layout <TAB>  presets . draw_presets_ops ( layout , context = context ) <TAB>  for category in presets . get_category_names ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  class_name = preset_category_menus [ category ] . __name__ <TAB><TAB><TAB><TAB>  layout . menu ( class_name ) ",if category in preset_category_menus :,if category in preset_category_menus:,False,46.95767398305741,92.68009990917801
3333,"def __setitem__ ( self , key , value ) : <TAB>  if isinstance ( value , ( tuple , list ) ) : <TAB><TAB>  info , reference = value <TAB><TAB>  if info not in self . _reverse_infos : <TAB><TAB><TAB>  self . _reverse_infos [ info ] = len ( self . _infos ) <TAB><TAB><TAB>  self . _infos . append ( info ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _reverse_references [ reference ] = len ( self . _references ) <TAB><TAB><TAB>  self . _references . append ( reference ) <TAB><TAB>  self . _trails [ key ] = "" %d , %d "" % ( <TAB><TAB><TAB>  self . _reverse_infos [ info ] , <TAB><TAB><TAB>  self . _reverse_references [ reference ] , <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) ) ",if reference not in self . _reverse_references :,if reference not in self._reverse_references:,False,52.16906952647935,98.63256198465083
3334,"def format_bpe_text ( symbols , delimiter = b "" @@ "" ) : <TAB>  """"""Convert a sequence of bpe words into sentence."""""" <TAB>  words = [ ] <TAB>  word = b "" "" <TAB>  if isinstance ( symbols , str ) : <TAB><TAB>  symbols = symbols . encode ( ) <TAB>  delimiter_len = len ( delimiter ) <TAB>  for symbol in symbols : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  word + = symbol [ : - delimiter_len ] <TAB><TAB>  else :<TAB># end of a word <TAB><TAB><TAB>  word + = symbol <TAB><TAB><TAB>  words . append ( word ) <TAB><TAB><TAB>  word = b "" "" <TAB>  return b "" "" . join ( words ) ",if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,if delimiter_len > 0:,False,21.983130500092578,88.47208704271736
3335,"def output_type ( data , request , response ) : <TAB>  accept = request . accept <TAB>  if accept in ( "" "" , "" * "" , "" / "" ) : <TAB><TAB>  handler = default or handlers and next ( iter ( handlers . values ( ) ) ) <TAB>  else : <TAB><TAB>  handler = default <TAB><TAB>  accepted = [ accept_quality ( accept_type ) for accept_type in accept . split ( "" , "" ) ] <TAB><TAB>  accepted . sort ( key = itemgetter ( 0 ) ) <TAB><TAB>  for _quality , accepted_content_type in reversed ( accepted ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  handler = handlers [ accepted_content_type ] <TAB><TAB><TAB><TAB>  break <TAB>  if not handler : <TAB><TAB>  raise falcon . HTTPNotAcceptable ( error ) <TAB>  response . content_type = handler . content_type <TAB>  return handler ( data , request = request , response = response ) ",if accepted_content_type in handlers :,if accepted_content_type in handlers:,False,55.2837222478489,100.00000000000004
3336,"def _render_raw_list ( bytes_items ) : <TAB>  flatten_items = [ ] <TAB>  for item in bytes_items : <TAB><TAB>  if item is None : <TAB><TAB><TAB>  flatten_items . append ( b "" "" ) <TAB><TAB>  elif isinstance ( item , bytes ) : <TAB><TAB><TAB>  flatten_items . append ( item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flatten_items . append ( str ( item ) . encode ( ) ) <TAB><TAB>  elif isinstance ( item , list ) : <TAB><TAB><TAB>  flatten_items . append ( _render_raw_list ( item ) ) <TAB>  return b "" \n "" . join ( flatten_items ) ","elif isinstance ( item , int ) :","if isinstance(item, str):",False,38.61848142516122,97.27477073083774
3337,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_mime_type ( d . getVarInt32 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 16 : <TAB><TAB><TAB>  self . set_quality ( d . getVarInt32 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 8 :,if tt == 8:,False,51.36809638600636,100.00000000000004
3338,"def delete ( self , waiters ) : <TAB>  # Delete flow. <TAB>  msgs = self . ofctl . get_all_flow ( waiters ) <TAB>  for msg in msgs : <TAB><TAB>  for stats in msg . body : <TAB><TAB><TAB>  vlan_id = VlanRouter . _cookie_to_id ( REST_VLANID , stats . cookie ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . ofctl . delete_flow ( stats ) <TAB>  assert len ( self . packet_buffer ) == 0 ",if vlan_id == self . vlan_id :,if vlan_id == self.vlan_id:,False,26.371324045199383,100.00000000000004
3339,def missing_push_allowance ( push_allowances : List [ PushAllowance ] ) - > bool : <TAB>  for push_allowance in push_allowances : <TAB><TAB>  # a null databaseId indicates this is not a GitHub App. <TAB><TAB>  if push_allowance . actor . databaseId is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB>  return True ,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,if push_allowance.actor.databaseId == None:,False,57.971226521407246,83.86217450421023
3340,"def _cluster_page ( self , htmlpage ) : <TAB>  template_cluster , preferred = _CLUSTER_NA , None <TAB>  if self . clustering : <TAB><TAB>  self . clustering . add_page ( htmlpage ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  clt = self . clustering . classify ( htmlpage ) <TAB><TAB><TAB>  if clt != - 1 : <TAB><TAB><TAB><TAB>  template_cluster = preferred = self . template_names [ clt ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  template_cluster = _CLUSTER_OUTLIER <TAB>  return template_cluster , preferred ",if self . clustering . is_fit :,if self.template_names:,False,49.01454273910137,94.62711399682625
3341,"def readlines ( self , size = - 1 ) : <TAB>  if self . _nbr == self . _size : <TAB><TAB>  return [ ] <TAB>  # leave all additional logic to our readline method, we just check the size <TAB>  out = [ ] <TAB>  nbr = 0 <TAB>  while True : <TAB><TAB>  line = self . readline ( ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  break <TAB><TAB>  out . append ( line ) <TAB><TAB>  if size > - 1 : <TAB><TAB><TAB>  nbr + = len ( line ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  # END handle size constraint <TAB>  # END readline loop <TAB>  return out ",if nbr > size :,if size < 0:,False,61.56341524582918,94.15480326896339
3342,"def post_mortem ( t = None ) : <TAB>  # handling the default <TAB>  <IF-STMT>: <TAB><TAB>  # sys.exc_info() returns (type, value, traceback) if an exception is <TAB><TAB>  # being handled, otherwise it returns None <TAB><TAB>  t = sys . exc_info ( ) [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" A valid traceback must be passed if no exception is being handled. "" <TAB><TAB><TAB>  ) <TAB>  p = BPdb ( ) <TAB>  p . reset ( ) <TAB>  p . interaction ( None , t ) ",if t is None :,if t is None:,False,68.1408386987845,96.73236526286362
3343,"def fixup ( m ) : <TAB>  txt = m . group ( 0 ) <TAB>  if txt [ : 2 ] == "" &# "" : <TAB><TAB>  # character reference <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return unichr ( int ( txt [ 3 : - 1 ] , 16 ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return unichr ( int ( txt [ 2 : - 1 ] ) ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  pass <TAB>  else : <TAB><TAB>  # named entity <TAB><TAB>  try : <TAB><TAB><TAB>  txt = unichr ( htmlentitydefs . name2codepoint [ txt [ 1 : - 1 ] ] ) <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  pass <TAB>  return txt<TAB># leave as is ","if txt [ : 3 ] == ""&#x"" :",if txt[-1] == ' ' or txt[-1] == ' ' or txt[-,False,51.62109217834635,86.31755843544262
3344,"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB>  argstr + = "" , "" <TAB>  args = [ ] <TAB>  kwargs = { } <TAB>  for item in _converter_args_re . finditer ( argstr ) : <TAB><TAB>  value = item . group ( "" stringval "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = item . group ( "" value "" ) <TAB><TAB>  value = _pythonize ( value ) <TAB><TAB>  if not item . group ( "" name "" ) : <TAB><TAB><TAB>  args . append ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  name = item . group ( "" name "" ) <TAB><TAB><TAB>  kwargs [ name ] = value <TAB>  return tuple ( args ) , kwargs ",if value is None :,if value is not None:,False,21.851725255825542,98.84118727773192
3345,"def IT ( cpu ) : <TAB>  cc = cpu . instruction . cc <TAB>  true_case = cpu . _evaluate_conditional ( cc ) <TAB>  # this is incredibly hacky--how else does capstone expose this? <TAB>  # TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13 <TAB>  for c in cpu . instruction . mnemonic [ 1 : ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cpu . _it_conditional . append ( true_case ) <TAB><TAB>  elif c == "" e "" : <TAB><TAB><TAB>  cpu . _it_conditional . append ( not true_case ) ","if c == ""t"" :","if c == ""r':",False,68.02148726702514,97.74522150899801
3346,"def flatten ( self ) : <TAB>  # this is similar to fill_messages except it uses a list instead <TAB>  # of a queue to place the messages in. <TAB>  result = [ ] <TAB>  channel = await self . messageable . _get_channel ( ) <TAB>  self . channel = channel <TAB>  while self . _get_retrieve ( ) : <TAB><TAB>  data = await self . _retrieve_messages ( self . retrieve ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . limit = 0<TAB># terminate the infinite loop <TAB><TAB>  if self . reverse : <TAB><TAB><TAB>  data = reversed ( data ) <TAB><TAB>  if self . _filter : <TAB><TAB><TAB>  data = filter ( self . _filter , data ) <TAB><TAB>  for element in data : <TAB><TAB><TAB>  result . append ( self . state . create_message ( channel = channel , data = element ) ) <TAB>  return result ",if len ( data ) < 100 :,if not data:,False,37.08806432539102,96.37811398389266
3347,"def _get_beta_accumulators ( self ) : <TAB>  with tf . init_scope ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  graph = None <TAB><TAB>  else : <TAB><TAB><TAB>  graph = tf . get_default_graph ( ) <TAB><TAB>  return ( <TAB><TAB><TAB>  self . _get_non_slot_variable ( "" beta1_power "" , graph = graph ) , <TAB><TAB><TAB>  self . _get_non_slot_variable ( "" beta2_power "" , graph = graph ) , <TAB><TAB>  ) ",if tf . executing_eagerly ( ) :,if self._is_grip():,False,36.28537165672457,95.45266335906469
3348,"def prefixed ( self , prefix : _StrType ) - > typing . Iterator [ "" Env "" ] : <TAB>  """"""Context manager for parsing envvars with a common prefix."""""" <TAB>  try : <TAB><TAB>  old_prefix = self . _prefix <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _prefix = prefix <TAB><TAB>  else : <TAB><TAB><TAB>  self . _prefix = f "" { old_prefix } { prefix } "" <TAB><TAB>  yield self <TAB>  finally : <TAB><TAB>  # explicitly reset the stored prefix on completion and exceptions <TAB><TAB>  self . _prefix = None <TAB>  self . _prefix = old_prefix ",if old_prefix is None :,if old_prefix is None:,False,58.51382114006574,100.00000000000004
3349,"def decode_content ( self ) : <TAB>  """"""Return the best possible representation of the response body."""""" <TAB>  ct = self . headers . get ( "" content-type "" ) <TAB>  if ct : <TAB><TAB>  ct , options = parse_options_header ( ct ) <TAB><TAB>  charset = options . get ( "" charset "" ) <TAB><TAB>  if ct in JSON_CONTENT_TYPES : <TAB><TAB><TAB>  return self . json ( charset ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . text ( charset ) <TAB><TAB>  elif ct == FORM_URL_ENCODED : <TAB><TAB><TAB>  return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB>  return self . content ","elif ct . startswith ( ""text/"" ) :",if ct == TEXT_CONTENT:,False,32.19382019729792,94.32508705188226
3350,"def test_incrementaldecoder ( self ) : <TAB>  UTF8Writer = codecs . getwriter ( "" utf-8 "" ) <TAB>  for sizehint in [ None , - 1 ] + list ( range ( 1 , 33 ) ) + [ 64 , 128 , 256 , 512 , 1024 ] : <TAB><TAB>  istream = BytesIO ( self . tstring [ 0 ] ) <TAB><TAB>  ostream = UTF8Writer ( BytesIO ( ) ) <TAB><TAB>  decoder = self . incrementaldecoder ( ) <TAB><TAB>  while 1 : <TAB><TAB><TAB>  data = istream . read ( sizehint ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  u = decoder . decode ( data ) <TAB><TAB><TAB><TAB>  ostream . write ( u ) <TAB><TAB>  self . assertEqual ( ostream . getvalue ( ) , self . tstring [ 1 ] ) ",if not data :,if not data:,False,50.657183282721064,98.42307799076669
3351,"def delete_all ( path ) : <TAB>  ppath = os . getcwd ( ) <TAB>  os . chdir ( path ) <TAB>  for fn in glob . glob ( "" * "" ) : <TAB><TAB>  fn_full = os . path . join ( path , fn ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  delete_all ( fn_full ) <TAB><TAB>  elif fn . endswith ( "" .png "" ) : <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB><TAB>  elif fn . endswith ( "" .md "" ) : <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB><TAB>  elif DELETE_ALL_OLD : <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB>  os . chdir ( ppath ) <TAB>  os . rmdir ( path ) ",if os . path . isdir ( fn ) :,if fn.endswith('.pyc'):,False,23.49201816259986,96.40501572540074
3352,"def _delete_reason ( self ) : <TAB>  for i in range ( _lib . X509_REVOKED_get_ext_count ( self . _revoked ) ) : <TAB><TAB>  ext = _lib . X509_REVOKED_get_ext ( self . _revoked , i ) <TAB><TAB>  obj = _lib . X509_EXTENSION_get_object ( ext ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _lib . X509_EXTENSION_free ( ext ) <TAB><TAB><TAB>  _lib . X509_REVOKED_delete_ext ( self . _revoked , i ) <TAB><TAB><TAB>  break ",if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,if obj is not None:,False,22.15863287119268,87.50834326371519
3353,"def hexcmp ( x , y ) : <TAB>  try : <TAB><TAB>  a = int ( x , 16 ) <TAB><TAB>  b = int ( y , 16 ) <TAB><TAB>  if a < b : <TAB><TAB><TAB>  return - 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return 1 <TAB><TAB>  return 0 <TAB>  except : <TAB><TAB>  return cmp ( x , y ) ",if a > b :,if a > b:,False,51.14293676533549,96.81638556984849
3354,"def get_indentation_count ( view , start ) : <TAB>  indent_count = 0 <TAB>  i = start - 1 <TAB>  while i > 0 : <TAB><TAB>  ch = view . substr ( i ) <TAB><TAB>  scope = view . scope_name ( i ) <TAB><TAB>  # Skip preprocessors, strings, characaters and comments <TAB><TAB>  if "" string.quoted "" in scope or "" comment "" in scope or "" preprocessor "" in scope : <TAB><TAB><TAB>  extent = view . extract_scope ( i ) <TAB><TAB><TAB>  i = extent . a - 1 <TAB><TAB><TAB>  continue <TAB><TAB>  else : <TAB><TAB><TAB>  i - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  indent_count - = 1 <TAB><TAB>  elif ch == "" { "" : <TAB><TAB><TAB>  indent_count + = 1 <TAB>  return indent_count ","if ch == ""}"" :","if ch == '""':",False,56.005083360512955,98.20558891324573
3355,"def set ( self , name , value , ex = None , px = None , nx = False , xx = False ) : <TAB>  if ( <TAB><TAB>  ( not nx and not xx ) <TAB><TAB>  or ( nx and self . _db . get ( name , None ) is None ) <TAB><TAB>  or ( xx and not self . _db . get ( name , None ) is None ) <TAB>  ) : <TAB><TAB>  if ex > 0 : <TAB><TAB><TAB>  self . _db . expire ( name , datetime . now ( ) + timedelta ( seconds = ex ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _db . expire ( name , datetime . now ( ) + timedelta ( milliseconds = px ) ) <TAB><TAB>  self . _db [ name ] = str ( value ) <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  return None ",elif px > 0 :,if px is not None:,False,47.516804193639175,97.15971721525577
3356,"def _get_between ( content , start , end = None ) : <TAB>  should_yield = False <TAB>  for line in content . split ( "" \n "" ) : <TAB><TAB>  if start in line : <TAB><TAB><TAB>  should_yield = True <TAB><TAB><TAB>  continue <TAB><TAB>  if end and end in line : <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield line . strip ( ) . split ( "" "" ) [ 0 ] ",if should_yield and line :,if should_yield:,False,53.11554254096124,97.35307142590442
3357,"def iter_event_handlers ( <TAB>  self , <TAB>  resource : resources_ . Resource , <TAB>  event : bodies . RawEvent ,  ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB>  warnings . warn ( <TAB><TAB>  "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB><TAB>  "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB><TAB>  DeprecationWarning , <TAB>  ) <TAB>  cause = _create_watching_cause ( resource , event ) <TAB>  for handler in self . _handlers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) : <TAB><TAB><TAB>  yield handler ","if not isinstance ( handler , handlers . ResourceWatchingHandler ) :",if handler is None:,False,25.92736914313592,94.50016581708209
3358,"def __enter__ ( self ) : <TAB>  if log_timer : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . logger . debug ( "" %s  starting "" % self . name ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( ( "" [ %s  starting]... "" % self . name ) ) <TAB><TAB>  self . tstart = time . time ( ) ",if self . logger :,if self.logger:,False,50.77976470698646,100.00000000000004
3359,"def _handle_errors ( errors ) : <TAB>  """"""Log out and possibly reraise errors during import."""""" <TAB>  if not errors : <TAB><TAB>  return <TAB>  log_all = True<TAB># pylint: disable=unused-variable <TAB>  err_msg = "" T2T: skipped importing  {num_missing}  data_generators modules. "" <TAB>  print ( err_msg . format ( num_missing = len ( errors ) ) ) <TAB>  for module , err in errors : <TAB><TAB>  err_str = str ( err ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Did not import module:  %s ; Cause:  %s "" % ( module , err_str ) ) <TAB><TAB>  if not _is_import_err_msg ( err_str , module ) : <TAB><TAB><TAB>  print ( "" From module  %s "" % module ) <TAB><TAB><TAB>  raise err ",if log_all :,if not log_all:,False,23.308227121687846,96.88556016413864
3360,"def _ungroup ( sequence , groups = None ) : <TAB>  for v in sequence : <TAB><TAB>  if isinstance ( v , ( list , tuple ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB><TAB><TAB>  for v in _ungroup ( v , groups ) : <TAB><TAB><TAB><TAB>  yield v <TAB><TAB>  else : <TAB><TAB><TAB>  yield v ",if groups is not None :,if groups is not None:,False,52.58949299533972,100.00000000000004
3361,def run ( self ) : <TAB>  while not self . completed : <TAB><TAB>  if self . block : <TAB><TAB><TAB>  time . sleep ( self . period ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _completed . wait ( self . period ) <TAB><TAB>  self . counter + = 1 <TAB><TAB>  try : <TAB><TAB><TAB>  self . callback ( self . counter ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  if self . timeout is not None : <TAB><TAB><TAB>  dt = time . time ( ) - self . _start_time <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . stop ( ) <TAB><TAB>  if self . counter == self . count : <TAB><TAB><TAB>  self . stop ( ) ,if dt > self . timeout :,if dt < self.timeout:,False,24.827901706466637,98.90705000370515
3362,"def dont_let_stderr_buffer ( ) : <TAB>  while True : <TAB><TAB>  line = context . daemon . stderr . readline ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  if DEAD_DEPLOYD_WORKER_MESSAGE . encode ( "" utf-8 "" ) in line : <TAB><TAB><TAB>  context . num_workers_crashed + = 1 <TAB><TAB>  print ( f "" deployd stderr:  { line } "" ) ",if not line :,if not line:,False,17.597227925932728,100.00000000000004
3363,"def mergeHiLo ( self , x_stats ) : <TAB>  """"""Merge the highs and lows of another accumulator into myself."""""" <TAB>  if x_stats . firsttime is not None : <TAB><TAB>  if self . firsttime is None or x_stats . firsttime < self . firsttime : <TAB><TAB><TAB>  self . firsttime = x_stats . firsttime <TAB><TAB><TAB>  self . first = x_stats . first <TAB>  if x_stats . lasttime is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . lasttime = x_stats . lasttime <TAB><TAB><TAB>  self . last = x_stats . last ",if self . lasttime is None or x_stats . lasttime >= self . lasttime :,if x_stats.lasttime is not None:,False,55.34958892379448,92.41561699179391
3364,"def test_rlimit_get ( self ) : <TAB>  import resource <TAB>  p = psutil . Process ( os . getpid ( ) ) <TAB>  names = [ x for x in dir ( psutil ) if x . startswith ( "" RLIMIT "" ) ] <TAB>  assert names <TAB>  for name in names : <TAB><TAB>  value = getattr ( psutil , name ) <TAB><TAB>  self . assertGreaterEqual ( value , 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( value , getattr ( resource , name ) ) <TAB><TAB><TAB>  self . assertEqual ( p . rlimit ( value ) , resource . getrlimit ( value ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  ret = p . rlimit ( value ) <TAB><TAB><TAB>  self . assertEqual ( len ( ret ) , 2 ) <TAB><TAB><TAB>  self . assertGreaterEqual ( ret [ 0 ] , - 1 ) <TAB><TAB><TAB>  self . assertGreaterEqual ( ret [ 1 ] , - 1 ) ",if name in dir ( resource ) :,if name == 'rlimit':,False,32.062163446917694,95.53741723745017
3365,"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB>  writes = 0 <TAB>  for prop_name in entity . keys ( ) : <TAB><TAB>  if not prop_name in entity . unindexed_properties ( ) : <TAB><TAB><TAB>  prop_vals = entity [ prop_name ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  num_prop_vals = len ( prop_vals ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  num_prop_vals = 1 <TAB><TAB><TAB>  writes + = 2 * num_prop_vals <TAB>  return writes ","if isinstance ( prop_vals , ( list ) ) :","if isinstance(prop_vals, list):",False,46.49672102583299,97.71399316779345
3366,"def check_value_check ( self , x_data , t_data , use_cudnn ) : <TAB>  x = chainer . Variable ( x_data ) <TAB>  t = chainer . Variable ( t_data ) <TAB>  with chainer . using_config ( "" use_cudnn "" , use_cudnn ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Check if it throws nothing <TAB><TAB><TAB>  functions . softmax_cross_entropy ( <TAB><TAB><TAB><TAB>  x , t , enable_double_backprop = self . enable_double_backprop <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  with self . assertRaises ( ValueError ) : <TAB><TAB><TAB><TAB>  functions . softmax_cross_entropy ( <TAB><TAB><TAB><TAB><TAB>  x , t , enable_double_backprop = self . enable_double_backprop <TAB><TAB><TAB><TAB>  ) ",if self . valid :,if x.value == t.value:,False,29.061272052898886,96.2119714431921
3367,"def get_note_title_file ( note ) : <TAB>  mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB>  if mo : <TAB><TAB>  fn = mo . groups ( ) [ 0 ] <TAB><TAB>  fn = fn . replace ( "" "" , "" _ "" ) <TAB><TAB>  fn = fn . replace ( "" / "" , "" _ "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" "" <TAB><TAB>  if isinstance ( fn , str ) : <TAB><TAB><TAB>  fn = unicode ( fn , "" utf-8 "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  fn = unicode ( fn ) <TAB><TAB>  if note_markdown ( note ) : <TAB><TAB><TAB>  fn + = "" .mkdn "" <TAB><TAB>  else : <TAB><TAB><TAB>  fn + = "" .txt "" <TAB><TAB>  return fn <TAB>  else : <TAB><TAB>  return "" "" ",if not fn :,if not fn:,False,50.329487696471695,100.00000000000004
3368,"def _parseparam ( s ) : <TAB>  plist = [ ] <TAB>  while s [ : 1 ] == "" ; "" : <TAB><TAB>  s = s [ 1 : ] <TAB><TAB>  end = s . find ( "" ; "" ) <TAB><TAB>  while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB><TAB><TAB>  end = s . find ( "" ; "" , end + 1 ) <TAB><TAB>  if end < 0 : <TAB><TAB><TAB>  end = len ( s ) <TAB><TAB>  f = s [ : end ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  i = f . index ( "" = "" ) <TAB><TAB><TAB>  f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB><TAB>  plist . append ( f . strip ( ) ) <TAB><TAB>  s = s [ end : ] <TAB>  return plist ","if ""="" in f :",if f.startswith('='):,False,24.224959738531098,96.6674885641573
3369,"def doDir ( elem ) : <TAB>  for child in elem . childNodes : <TAB><TAB>  if not isinstance ( child , minidom . Element ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if child . tagName == "" Directory "" : <TAB><TAB><TAB>  doDir ( child ) <TAB><TAB>  elif child . tagName == "" Component "" : <TAB><TAB><TAB>  for grandchild in child . childNodes : <TAB><TAB><TAB><TAB>  if not isinstance ( grandchild , minidom . Element ) : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if grandchild . tagName != ""File"" :","if grandchild.tagName == ""Source':",False,21.238011555535223,97.32505917102627
3370,"def date_to_format ( value , target_format ) : <TAB>  """"""Convert date to specified format"""""" <TAB>  if target_format == str : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB>  elif isinstance ( value , datetime . datetime ) : <TAB><TAB><TAB>  ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB>  elif isinstance ( value , datetime . time ) : <TAB><TAB><TAB>  ret = value . strftime ( "" % H: % M: % S "" ) <TAB>  else : <TAB><TAB>  ret = value <TAB>  return ret ","if isinstance ( value , datetime . date ) :","if isinstance(value, datetime.date):",False,51.85499234580037,100.00000000000004
3371,"def __listingColumns ( self ) : <TAB>  columns = [ ] <TAB>  for name in self . __getColumns ( ) : <TAB><TAB>  definition = column ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  IECore . msg ( <TAB><TAB><TAB><TAB>  IECore . Msg . Level . Error , <TAB><TAB><TAB><TAB>  "" GafferImageUI.CatalogueUI "" , <TAB><TAB><TAB><TAB>  "" No column registered with name  ' %s ' "" % name , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  continue <TAB><TAB>  if isinstance ( definition , IconColumn ) : <TAB><TAB><TAB>  c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB><TAB>  else : <TAB><TAB><TAB>  c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB><TAB>  columns . append ( c ) <TAB>  return columns ",if not definition :,if not definition:,False,53.96234671212541,98.52911663954634
3372,"def metrics_to_scalars ( self , metrics ) : <TAB>  new_metrics = { } <TAB>  for k , v in metrics . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = v . item ( ) <TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB>  v = self . metrics_to_scalars ( v ) <TAB><TAB>  new_metrics [ k ] = v <TAB>  return new_metrics ","if isinstance ( v , torch . Tensor ) :",if k == 'metrics':,False,45.361745215179965,92.15419322247392
3373,"def start ( self , connection ) : <TAB>  try : <TAB><TAB>  if self . client_name : <TAB><TAB><TAB>  creds = gssapi . Credentials ( name = gssapi . Name ( self . client_name ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  creds = None <TAB><TAB>  hostname = self . get_hostname ( connection ) <TAB><TAB>  name = gssapi . Name ( <TAB><TAB><TAB>  b "" @ "" . join ( [ self . service , hostname ] ) , gssapi . NameType . hostbased_service <TAB><TAB>  ) <TAB><TAB>  context = gssapi . SecurityContext ( name = name , creds = creds ) <TAB><TAB>  return context . step ( None ) <TAB>  except gssapi . raw . misc . GSSError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return NotImplemented <TAB><TAB>  else : <TAB><TAB><TAB>  raise ",if self . fail_soft :,if not self.service:,False,22.252722647977457,97.45529390513498
3374,"def nanmax ( self , axis = None , dtype = None , keepdims = None ) : <TAB>  ret = self . _reduction ( <TAB><TAB>  "" nanmax "" , axis = axis , dtype = dtype , keepdims = keepdims , todense = True <TAB>  ) <TAB>  if not issparse ( ret ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ret <TAB><TAB>  xps = get_sparse_module ( self . spmatrix ) <TAB><TAB>  ret = SparseNDArray ( xps . csr_matrix ( ret ) ) <TAB><TAB>  return ret <TAB>  return ret ",if get_array_module ( ret ) . isscalar ( ret ) :,"if not isinstance(ret, (int, float)):",False,24.129297757841115,91.6666372486498
3375,"def utterance_to_sample ( query_data , tagging_scheme , language ) : <TAB>  tokens , tags = [ ] , [ ] <TAB>  current_length = 0 <TAB>  for chunk in query_data : <TAB><TAB>  chunk_tokens = tokenize ( chunk [ TEXT ] , language ) <TAB><TAB>  tokens + = [ <TAB><TAB><TAB>  Token ( t . value , current_length + t . start , current_length + t . end ) <TAB><TAB><TAB>  for t in chunk_tokens <TAB><TAB>  ] <TAB><TAB>  current_length + = len ( chunk [ TEXT ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tags + = negative_tagging ( len ( chunk_tokens ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  tags + = positive_tagging ( <TAB><TAB><TAB><TAB>  tagging_scheme , chunk [ SLOT_NAME ] , len ( chunk_tokens ) <TAB><TAB><TAB>  ) <TAB>  return { TOKENS : tokens , TAGS : tags } ",if SLOT_NAME not in chunk :,if SLOT_NAME not in chunk:,False,21.08203439070062,100.00000000000004
3376,"def use_index ( <TAB>  self , term : Union [ str , Index ] , * terms : Union [ str , Index ]  ) - > "" QueryBuilder "" : <TAB>  for t in ( term , * terms ) : <TAB><TAB>  if isinstance ( t , Index ) : <TAB><TAB><TAB>  self . _use_indexes . append ( t ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _use_indexes . append ( Index ( t ) ) ","elif isinstance ( t , str ) :","if isinstance(t, str):",False,49.14722459613674,97.85826525822034
3377,"def reconfigServiceWithBuildbotConfig ( self , new_config ) : <TAB>  if new_config . manhole != self . manhole : <TAB><TAB>  if self . manhole : <TAB><TAB><TAB>  yield self . manhole . disownServiceParent ( ) <TAB><TAB><TAB>  self . manhole = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . manhole = new_config . manhole <TAB><TAB><TAB>  yield self . manhole . setServiceParent ( self ) <TAB>  # chain up <TAB>  yield service . ReconfigurableServiceMixin . reconfigServiceWithBuildbotConfig ( <TAB><TAB>  self , new_config <TAB>  ) ",if new_config . manhole :,if new_config.manhole:,False,50.53177626988994,100.00000000000004
3378,"def cleanup_folder ( target_folder ) : <TAB>  for file in os . listdir ( target_folder ) : <TAB><TAB>  file_path = os . path . join ( target_folder , file ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . remove ( file_path ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  logging . error ( e ) ",if os . path . isfile ( file_path ) :,if os.path.exists(file_path):,False,51.82978784517274,97.9119401581112
3379,"def to_key ( literal_or_identifier ) : <TAB>  """"""returns string representation of this object"""""" <TAB>  if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB>  return literal_or_identifier [ "" name "" ] <TAB>  elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB>  k = literal_or_identifier [ "" value "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return unicode ( float_repr ( k ) ) <TAB><TAB>  elif "" regex "" in literal_or_identifier : <TAB><TAB><TAB>  return compose_regex ( k ) <TAB><TAB>  elif isinstance ( k , bool ) : <TAB><TAB><TAB>  return "" true "" if k else "" false "" <TAB><TAB>  elif k is None : <TAB><TAB><TAB>  return "" null "" <TAB><TAB>  else : <TAB><TAB><TAB>  return unicode ( k ) ","if isinstance ( k , float ) :","if isinstance(k, float):",False,54.17528095954469,100.00000000000004
3380,"def decompile ( decompiler ) : <TAB>  for pos , next_pos , opname , arg in decompiler . instructions : <TAB><TAB>  if pos in decompiler . targets : <TAB><TAB><TAB>  decompiler . process_target ( pos ) <TAB><TAB>  method = getattr ( decompiler , opname , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB><TAB>  decompiler . pos = pos <TAB><TAB>  decompiler . next_pos = next_pos <TAB><TAB>  x = method ( * arg ) <TAB><TAB>  if x is not None : <TAB><TAB><TAB>  decompiler . stack . append ( x ) ",if method is None :,if method is None:,False,51.93068812400313,100.00000000000004
3381,"def shutdown ( self , timeout , callback = None ) : <TAB>  logger . debug ( "" background worker got shutdown request "" ) <TAB>  with self . _lock : <TAB><TAB>  if self . is_alive : <TAB><TAB><TAB>  self . _queue . put_nowait ( _TERMINATOR ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _wait_shutdown ( timeout , callback ) <TAB><TAB>  self . _thread = None <TAB><TAB>  self . _thread_for_pid = None <TAB>  logger . debug ( "" background worker shut down "" ) ",if timeout > 0.0 :,if self._thread is not None:,False,48.170593878149525,94.38046782168806
3382,"def getDOMImplementation ( features = None ) : <TAB>  if features : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  features = domreg . _parse_feature_string ( features ) <TAB><TAB>  for f , v in features : <TAB><TAB><TAB>  if not Document . implementation . hasFeature ( f , v ) : <TAB><TAB><TAB><TAB>  return None <TAB>  return Document . implementation ","if isinstance ( features , str ) :","if isinstance(features, basestring):",False,51.21065058263812,97.58978044863993
3383,"def validate_subevent ( self , subevent ) : <TAB>  if self . context [ "" event "" ] . has_subevents : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationError ( "" You need to set a subevent. "" ) <TAB><TAB>  if subevent . event != self . context [ "" event "" ] : <TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB>  "" The specified subevent does not belong to this event. "" <TAB><TAB><TAB>  ) <TAB>  elif subevent : <TAB><TAB>  raise ValidationError ( "" You cannot set a subevent for this event. "" ) <TAB>  return subevent ",if not subevent :,if not subevent:,False,38.67822918698118,100.00000000000004
3384,"def einsum ( job_id , idx , einsum_expr , data_list ) : <TAB>  _ , all_parties = session_init ( job_id , idx ) <TAB>  with SPDZ ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = FixedPointTensor . from_source ( "" x "" , data_list [ 0 ] ) <TAB><TAB><TAB>  y = FixedPointTensor . from_source ( "" y "" , all_parties [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  x = FixedPointTensor . from_source ( "" x "" , all_parties [ 0 ] ) <TAB><TAB><TAB>  y = FixedPointTensor . from_source ( "" y "" , data_list [ 1 ] ) <TAB><TAB>  return x . einsum ( y , einsum_expr ) . get ( ) ",if idx == 0 :,if len(data_list) == 2:,False,48.00269479633315,95.15088730308919
3385,"def slowSorted ( qq ) : <TAB>  "" Reference sort peformed by insertion using only < "" <TAB>  rr = list ( ) <TAB>  for q in qq : <TAB><TAB>  i = 0 <TAB><TAB>  for i in range ( len ( rr ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  rr . insert ( i , q ) <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  rr . append ( q ) <TAB>  return rr ",if q < rr [ i ] :,if i < len(rr):,False,56.36137319848709,95.06323041028946
3386,"def _format_entry ( entry , src ) : <TAB>  if entry : <TAB><TAB>  result = [ ] <TAB><TAB>  for x in entry . split ( "" , "" ) : <TAB><TAB><TAB>  x = x . strip ( ) <TAB><TAB><TAB>  if os . path . exists ( os . path . join ( src , x ) ) : <TAB><TAB><TAB><TAB>  result . append ( relpath ( os . path . join ( src , x ) , src ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result . append ( relpath ( os . path . abspath ( x ) , src ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise RuntimeError ( "" No entry script  %s  found "" % x ) <TAB><TAB>  return "" , "" . join ( result ) ",elif os . path . exists ( x ) :,"if x not in ('', '', '', ' '):",False,25.68061075277776,93.78358976239177
3387,"def reloadCols ( self ) : <TAB>  self . columns = [ ] <TAB>  for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB><TAB>  if shape : <TAB><TAB><TAB>  t = anytype <TAB><TAB>  elif "" M "" in fmt : <TAB><TAB><TAB>  self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  elif "" i "" in fmt : <TAB><TAB><TAB>  t = int <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  t = float <TAB><TAB>  else : <TAB><TAB><TAB>  t = anytype <TAB><TAB>  self . addColumn ( ColumnItem ( name , i , type = t ) ) ","elif ""f"" in fmt :","if ""f"" in fmt:",False,47.710130301318685,98.83579057291513
3388,"def tool_lineages ( self , trans ) : <TAB>  rval = [ ] <TAB>  for id , tool in self . app . toolbox . tools ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lineage_dict = tool . lineage . to_dict ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  lineage_dict = None <TAB><TAB>  entry = dict ( id = id , lineage = lineage_dict ) <TAB><TAB>  rval . append ( entry ) <TAB>  return rval ","if hasattr ( tool , ""lineage"" ) :","if hasattr(tool, 'lineage'):",False,51.03341626344703,96.54593593917124
3389,"def item ( self , tensor ) : <TAB>  numel = 0 <TAB>  if len ( tensor . shape ) > 0 : <TAB><TAB>  numel = fct . reduce ( op . mul , tensor . shape ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  f "" expected tensor with one element,  "" f "" got  { tensor . shape } "" <TAB><TAB><TAB>  ) <TAB>  if numel == 1 : <TAB><TAB>  return tensor [ 0 ] <TAB>  return tensor ",if numel != 1 :,if numel != 0:,False,26.178113122095443,98.1305707491589
3390,"def get_host_metadata ( self ) : <TAB>  meta = { } <TAB>  if self . agent_url : <TAB><TAB>  try : <TAB><TAB><TAB>  resp = requests . get ( <TAB><TAB><TAB><TAB>  self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB><TAB><TAB>  ) . json ( ) <TAB><TAB><TAB>  if "" Version "" in resp : <TAB><TAB><TAB><TAB>  match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB>  return meta ",if match is not None and len ( match . groups ( ) ) == 1 :,if match:,False,22.066282228617474,93.09695635212594
3391,"def generate ( ) : <TAB>  for leaf in u . leaves : <TAB><TAB>  if isinstance ( leaf , Integer ) : <TAB><TAB><TAB>  val = leaf . get_int_value ( ) <TAB><TAB><TAB>  if val in ( 0 , 1 ) : <TAB><TAB><TAB><TAB>  yield val <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise _NoBoolVector <TAB><TAB>  elif isinstance ( leaf , Symbol ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield 1 <TAB><TAB><TAB>  elif leaf == SymbolFalse : <TAB><TAB><TAB><TAB>  yield 0 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise _NoBoolVector <TAB><TAB>  else : <TAB><TAB><TAB>  raise _NoBoolVector ",if leaf == SymbolTrue :,if leaf == SymbolTrue:,False,51.11484005249397,100.00000000000004
3392,"def _test_set_metadata ( self , metadata , mask = None ) : <TAB>  header = ofproto . OXM_OF_METADATA <TAB>  match = OFPMatch ( ) <TAB>  if mask is None : <TAB><TAB>  match . set_metadata ( metadata ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  header = ofproto . OXM_OF_METADATA_W <TAB><TAB>  match . set_metadata_masked ( metadata , mask ) <TAB><TAB>  metadata & = mask <TAB>  self . _test_serialize_and_parser ( match , header , metadata , mask ) ",if ( mask + 1 ) >> 64 != 1 :,if not header:,False,24.937871164294478,91.62493761286994
3393,"def pixbufrenderer ( self , column , crp , model , it ) : <TAB>  tok = model . get_value ( it , 0 ) <TAB>  if tok . type == "" class "" : <TAB><TAB>  icon = "" class "" <TAB>  else : <TAB><TAB>  if tok . visibility == "" private "" : <TAB><TAB><TAB>  icon = "" method_priv "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  icon = "" method_prot "" <TAB><TAB>  else : <TAB><TAB><TAB>  icon = "" method "" <TAB>  crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] ) ","elif tok . visibility == ""protected"" :","if tok.visibility == ""prot':",False,21.46396851990614,96.29152382929175
3394,"def path_sum2 ( root , s ) : <TAB>  if root is None : <TAB><TAB>  return [ ] <TAB>  res = [ ] <TAB>  stack = [ ( root , [ root . val ] ) ] <TAB>  while stack : <TAB><TAB>  node , ls = stack . pop ( ) <TAB><TAB>  if node . left is None and node . right is None and sum ( ls ) == s : <TAB><TAB><TAB>  res . append ( ls ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stack . append ( ( node . left , ls + [ node . left . val ] ) ) <TAB><TAB>  if node . right is not None : <TAB><TAB><TAB>  stack . append ( ( node . right , ls + [ node . right . val ] ) ) <TAB>  return res ",if node . left is not None :,if node.left is not None:,False,24.534212249293844,100.00000000000004
3395,"def clear_slot ( self , slot_id , trigger_changed ) : <TAB>  if self . slots [ slot_id ] is not None : <TAB><TAB>  old_resource_id = self . slots [ slot_id ] . resource_id <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . sell_list [ old_resource_id ] <TAB><TAB>  else : <TAB><TAB><TAB>  del self . buy_list [ old_resource_id ] <TAB>  self . slots [ slot_id ] = None <TAB>  if trigger_changed : <TAB><TAB>  self . _changed ( ) ",if self . slots [ slot_id ] . selling :,if old_resource_id in self.sell_list:,False,22.350547289398502,93.03084660056408
3396,"def OnRightUp ( self , event ) : <TAB>  self . HandleMouseEvent ( event ) <TAB>  self . Unbind ( wx . EVT_RIGHT_UP , handler = self . OnRightUp ) <TAB>  self . Unbind ( wx . EVT_MOUSE_CAPTURE_LOST , handler = self . OnRightUp ) <TAB>  self . _right = False <TAB>  if not self . _left : <TAB><TAB>  self . Unbind ( wx . EVT_MOTION , handler = self . OnMotion ) <TAB><TAB>  self . SendChangeEvent ( ) <TAB><TAB>  self . SetToolTip ( wx . ToolTip ( self . _tooltip ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . ReleaseMouse ( ) ",if self . HasCapture ( ) :,if self._right:,False,46.38656035847702,97.15695717478405
3397,"def __init__ ( self , * args , * * kwargs ) : <TAB>  for arg in args : <TAB><TAB>  for k , v in arg . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  arg [ k ] = AttrDict ( v ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  arg [ k ] = v <TAB>  super ( AttrDict , self ) . __init__ ( * args , * * kwargs ) ","if isinstance ( v , dict ) :","if isinstance(v, basestring):",False,46.059178751473176,98.0729214765951
3398,"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB>  with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB><TAB>  t = threading . current_thread ( ) <TAB><TAB>  t . name = func . __name__ <TAB><TAB>  try : <TAB><TAB><TAB>  t . status = func ( * args , * * kwargs ) <TAB><TAB>  except EscapeException as e :<TAB># user aborted <TAB><TAB><TAB>  t . status = "" aborted by user "" <TAB><TAB><TAB>  if status : <TAB><TAB><TAB><TAB>  status ( "" %s  aborted "" % t . name , priority = 2 ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  t . exception = e <TAB><TAB><TAB>  t . status = "" exception "" <TAB><TAB><TAB>  vd . exceptionCaught ( e ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  t . sheet . currentThreads . remove ( t ) ",if t . sheet :,if t.sheet and t.sheet.currentThreads.has_key(t):,False,45.924862951606016,92.94237405253232
3399,"def comboSelectionChanged ( self , index ) : <TAB>  text = self . comboBox . cb . itemText ( index ) <TAB>  for i in range ( self . labelList . count ( ) ) : <TAB><TAB>  if text == "" "" : <TAB><TAB><TAB>  self . labelList . item ( i ) . setCheckState ( 2 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . labelList . item ( i ) . setCheckState ( 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . labelList . item ( i ) . setCheckState ( 2 ) ",elif text != self . labelList . item ( i ) . text ( ) :,if i == len(self.labelList):,False,49.54643881181193,90.31960520919333
3400,"def __attempt_add_to_linked_match ( <TAB>  self , input_name , hdca , collection_type_description , subcollection_type  ) : <TAB>  structure = get_structure ( <TAB><TAB>  hdca , collection_type_description , leaf_subcollection_type = subcollection_type <TAB>  ) <TAB>  if not self . linked_structure : <TAB><TAB>  self . linked_structure = structure <TAB><TAB>  self . collections [ input_name ] = hdca <TAB><TAB>  self . subcollection_types [ input_name ] = subcollection_type <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise exceptions . MessageException ( CANNOT_MATCH_ERROR_MESSAGE ) <TAB><TAB>  self . collections [ input_name ] = hdca <TAB><TAB>  self . subcollection_types [ input_name ] = subcollection_type ",if not self . linked_structure . can_match ( structure ) :,if not structure:,False,34.88898475347505,93.69148749537298
3401,"def _wait_for_bot_presense ( self , online ) : <TAB>  for _ in range ( 10 ) : <TAB><TAB>  time . sleep ( 2 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  if not online and not self . _is_testbot_online ( ) : <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  raise AssertionError ( <TAB><TAB><TAB>  "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB><TAB>  ) ",if online and self . _is_testbot_online ( ) :,if online and self._is_testbot_online():,False,57.66234475628631,100.00000000000004
3402,"def find ( self , path ) : <TAB>  if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB><TAB>  self . num_files = self . num_files + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . files . append ( path ) <TAB>  elif os . path . isdir ( path ) : <TAB><TAB>  for content in os . listdir ( path ) : <TAB><TAB><TAB>  file = os . path . join ( path , content ) <TAB><TAB><TAB>  if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB><TAB><TAB><TAB>  self . num_files = self . num_files + 1 <TAB><TAB><TAB><TAB>  if self . match_function ( file ) : <TAB><TAB><TAB><TAB><TAB>  self . files . append ( file ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . find ( file ) ",if self . match_function ( path ) :,if self.match_function(path):,False,50.746352179770824,100.00000000000004
3403,"def optimize ( self , graph : Graph ) : <TAB>  MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB>  flag_changed = False <TAB>  for v in traverse . listup_variables ( graph ) : <TAB><TAB>  if not Placeholder . check_resolved ( v . size ) : <TAB><TAB><TAB>  continue <TAB><TAB>  height , width = TextureShape . get ( v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if not v . has_attribute ( SplitTarget ) : <TAB><TAB><TAB>  flag_changed = True <TAB><TAB><TAB>  v . attributes . add ( SplitTarget ( ) ) <TAB>  return graph , flag_changed ",if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE :,if height < MAX_TEXTURE_SIZE or width < MAX_TEXTURE_SIZE:,False,50.89279131815805,96.13320301486156
3404,"def brightness_func ( args ) : <TAB>  device = _get_device_from_filter ( args ) <TAB>  if args . set is None : <TAB><TAB>  # Get brightness <TAB><TAB>  if args . raw : <TAB><TAB><TAB>  print ( str ( device . brightness ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" Brightness:  {0} % "" . format ( device . brightness ) ) <TAB>  else : <TAB><TAB>  brightness_value = float ( _clamp_u8 ( args . set ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Setting brightness to  {0} % "" . format ( brightness_value ) ) <TAB><TAB>  device . brightness = brightness_value ",if not args . raw :,if brightness_value > 0:,False,51.08122495532971,96.50903172779527
3405,"def _setup ( self , field_name , owner_model ) : <TAB>  # Resolve possible name-based model reference. <TAB>  if not self . model_class : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . model_class = owner_model <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" ModelType: Unable to resolve model  ' {} ' . "" . format ( self . model_name ) <TAB><TAB><TAB>  ) <TAB>  super ( ModelType , self ) . _setup ( field_name , owner_model ) ",if self . model_name == owner_model . __name__ :,if self.model_name == field_name:,False,32.78282010244534,93.91302768888588
3406,"def build_json_schema_object ( cls , parent_builder = None ) : <TAB>  builder = builders . ObjectBuilder ( cls , parent_builder ) <TAB>  if builder . count_type ( builder . type ) > 1 : <TAB><TAB>  return builder <TAB>  for _ , name , field in cls . iterate_with_name ( ) : <TAB><TAB>  if isinstance ( field , fields . EmbeddedField ) : <TAB><TAB><TAB>  builder . add_field ( name , field , _parse_embedded ( field , builder ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  builder . add_field ( name , field , _parse_list ( field , builder ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  builder . add_field ( name , field , _create_primitive_field_schema ( field ) ) <TAB>  return builder ","elif isinstance ( field , fields . ListField ) :","if isinstance(field, fields.ListField):",False,50.66223065113786,98.80803503791117
3407,"def filter_module ( mod , type_req = None , subclass_req = None ) : <TAB>  for name in dir ( mod ) : <TAB><TAB>  val = getattr ( mod , name ) <TAB><TAB>  if type_req is not None and not isinstance ( val , type_req ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  yield name , val ","if subclass_req is not None and not issubclass ( val , subclass_req ) :",if subclass_req is not None and subclass_req is not None:,False,59.783184650749746,92.75279747822765
3408,"def get_icon ( self ) : <TAB>  if self . icon is not None : <TAB><TAB>  # Load it from an absolute filename <TAB><TAB>  if os . path . exists ( self . icon ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return GdkPixbuf . Pixbuf . new_from_file_at_size ( self . icon , 24 , 24 ) <TAB><TAB><TAB>  except GObject . GError as ge : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  # Load it from the current icon theme <TAB><TAB>  ( icon_name , extension ) = os . path . splitext ( os . path . basename ( self . icon ) ) <TAB><TAB>  theme = Gtk . IconTheme ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return theme . load_icon ( icon_name , 24 , 0 ) ",if theme . has_icon ( icon_name ) :,if extension == 'png':,False,58.97945245805132,94.83304572112898
3409,"def sysctlTestAndSet ( name , limit ) : <TAB>  "" Helper function to set sysctl limits "" <TAB>  # convert non-directory names into directory names <TAB>  if "" / "" not in name : <TAB><TAB>  name = "" /proc/sys/ "" + name . replace ( "" . "" , "" / "" ) <TAB>  # read limit <TAB>  with open ( name , "" r "" ) as readFile : <TAB><TAB>  oldLimit = readFile . readline ( ) <TAB><TAB>  if isinstance ( limit , int ) : <TAB><TAB><TAB>  # compare integer limits before overriding <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  with open ( name , "" w "" ) as writeFile : <TAB><TAB><TAB><TAB><TAB>  writeFile . write ( "" %d "" % limit ) <TAB><TAB>  else : <TAB><TAB><TAB>  # overwrite non-integer limits <TAB><TAB><TAB>  with open ( name , "" w "" ) as writeFile : <TAB><TAB><TAB><TAB>  writeFile . write ( limit ) ",if int ( oldLimit ) < limit :,if limit < oldLimit:,False,56.60292045186532,97.36069326427842
3410,"def _wait_for_bot_presense ( self , online ) : <TAB>  for _ in range ( 10 ) : <TAB><TAB>  time . sleep ( 2 ) <TAB><TAB>  if online and self . _is_testbot_online ( ) : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  raise AssertionError ( <TAB><TAB><TAB>  "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB><TAB>  ) ",if not online and not self . _is_testbot_online ( ) :,if online:,False,32.09005323837815,89.49609091522186
3411,"def handle ( self , context , sign , * args ) : <TAB>  if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB><TAB>  return Infsign [ sign ] <TAB>  if sign == 0 : <TAB><TAB>  if context . rounding == ROUND_CEILING : <TAB><TAB><TAB>  return Infsign [ sign ] <TAB><TAB>  return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB>  if sign == 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return Infsign [ sign ] <TAB><TAB>  return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) ",if context . rounding == ROUND_FLOOR :,if context.rounding == ROUND_HALF_UP:,False,25.67884223444573,97.72805519473513
3412,"def _get_item_columns_panel ( items , rows ) : <TAB>  hbox = Gtk . HBox ( False , 4 ) <TAB>  n_item = 0 <TAB>  col_items = 0 <TAB>  vbox = Gtk . VBox ( ) <TAB>  hbox . pack_start ( vbox , False , False , 0 ) <TAB>  while n_item < len ( items ) : <TAB><TAB>  item = items [ n_item ] <TAB><TAB>  vbox . pack_start ( item , False , False , 0 ) <TAB><TAB>  n_item + = 1 <TAB><TAB>  col_items + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vbox = Gtk . VBox ( ) <TAB><TAB><TAB>  hbox . pack_start ( vbox , False , False , 0 ) <TAB><TAB><TAB>  col_items = 0 <TAB>  return hbox ",if col_items > rows :,if col_items == 0:,False,20.618287018854843,97.87805119482678
3413,"def _changed ( self ) : <TAB>  if self . gtk_range . get_sensitive ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . timer . cancel ( ) <TAB><TAB>  self . timer = _Timer ( 0.5 , lambda : GLib . idle_add ( self . _write ) ) <TAB><TAB>  self . timer . start ( ) ",if self . timer :,if self.timer:,False,51.080877959835156,100.00000000000004
3414,"def unlock_graph ( result , callback , interval = 1 , propagate = False , max_retries = None ) : <TAB>  if result . ready ( ) : <TAB><TAB>  second_level_res = result . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with allow_join_result ( ) : <TAB><TAB><TAB><TAB>  signature ( callback ) . delay ( <TAB><TAB><TAB><TAB><TAB>  list ( joinall ( second_level_res , propagate = propagate ) ) <TAB><TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  unlock_graph . retry ( countdown = interval , max_retries = max_retries ) ",if second_level_res . ready ( ) :,if second_level_res:,False,37.69218809268888,96.85342004897649
3415,"def update ( self , other = None , / , * * kwargs ) : <TAB>  if self . _pending_removals : <TAB><TAB>  self . _commit_removals ( ) <TAB>  d = self . data <TAB>  if other is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  other = dict ( other ) <TAB><TAB>  for key , o in other . items ( ) : <TAB><TAB><TAB>  d [ key ] = KeyedRef ( o , self . _remove , key ) <TAB>  for key , o in kwargs . items ( ) : <TAB><TAB>  d [ key ] = KeyedRef ( o , self . _remove , key ) ","if not hasattr ( other , ""items"" ) :","if isinstance(other, dict):",False,23.98858728662139,95.17614801228144
3416,"def default ( self , o ) : <TAB>  try : <TAB><TAB>  if type ( o ) == datetime . datetime : <TAB><TAB><TAB>  return str ( o ) <TAB><TAB>  else : <TAB><TAB><TAB>  # remove unwanted attributes from the provider object during conversion to json <TAB><TAB><TAB>  if hasattr ( o , "" profile "" ) : <TAB><TAB><TAB><TAB>  del o . profile <TAB><TAB><TAB>  if hasattr ( o , "" credentials "" ) : <TAB><TAB><TAB><TAB>  del o . credentials <TAB><TAB><TAB>  if hasattr ( o , "" metadata_path "" ) : <TAB><TAB><TAB><TAB>  del o . metadata_path <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del o . services_config <TAB><TAB><TAB>  return vars ( o ) <TAB>  except Exception as e : <TAB><TAB>  return str ( o ) ","if hasattr ( o , ""services_config"" ) :","if hasattr(o, 'services_config'):",False,59.72862214388459,97.52189773132461
3417,"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB>  try : <TAB><TAB>  return self . _read ( count , timeout ) <TAB>  except usb . USBError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( <TAB><TAB><TAB><TAB>  "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB><TAB><TAB><TAB>  % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  if ignore_timeouts and is_timeout ( e ) : <TAB><TAB><TAB>  return [ ] <TAB><TAB>  if ignore_non_errors and is_noerr ( e ) : <TAB><TAB><TAB>  return [ ] <TAB><TAB>  raise ",if DEBUG_COMM :,if e.errno == errno.ENOTTY:,False,49.50072090542831,95.94517930521576
3418,def heal ( self ) : <TAB>  if not self . doctors : <TAB><TAB>  return <TAB>  proc_ids = self . _get_process_ids ( ) <TAB>  for proc_id in proc_ids : <TAB><TAB>  # get proc every time for latest state <TAB><TAB>  proc = PipelineProcess . objects . get ( id = proc_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for dr in self . doctors : <TAB><TAB><TAB>  if dr . confirm ( proc ) : <TAB><TAB><TAB><TAB>  dr . cure ( proc ) <TAB><TAB><TAB><TAB>  break ,if not proc . is_alive or proc . is_frozen :,if not proc:,False,58.26510587837268,93.28859320669109
3419,"def to_value ( self , value ) : <TAB>  # Tip: 'value' is the object returned by <TAB>  #<TAB>  taiga.projects.history.models.HistoryEntry.values_diff() <TAB>  ret = { } <TAB>  for key , val in value . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret [ key ] = val <TAB><TAB>  elif key == "" points "" : <TAB><TAB><TAB>  ret [ key ] = { k : { "" from "" : v [ 0 ] , "" to "" : v [ 1 ] } for k , v in val . items ( ) } <TAB><TAB>  else : <TAB><TAB><TAB>  ret [ key ] = { "" from "" : val [ 0 ] , "" to "" : val [ 1 ] } <TAB>  return ret ","if key in [ ""attachments"" , ""custom_attributes"" , ""description_diff"" ] :",if key == 'value':,False,30.47319180325762,90.62170975278835
3420,"def default_generator ( <TAB>  self , dataset , epochs = 1 , mode = "" fit "" , deterministic = True , pad_batches = True  ) : <TAB>  for epoch in range ( epochs ) : <TAB><TAB>  for ( X_b , y_b , w_b , ids_b ) in dataset . iterbatches ( <TAB><TAB><TAB>  batch_size = self . batch_size , <TAB><TAB><TAB>  deterministic = deterministic , <TAB><TAB><TAB>  pad_batches = pad_batches , <TAB><TAB>  ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  dropout = np . array ( 0.0 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  dropout = np . array ( 1.0 ) <TAB><TAB><TAB>  yield ( [ X_b , dropout ] , [ y_b ] , [ w_b ] ) ","if mode == ""predict"" :","if mode == ""fit':",False,34.62367316497627,98.45973493949339
3421,"def _cygwin_hack_find_addresses ( target ) : <TAB>  addresses = [ ] <TAB>  for h in [ <TAB><TAB>  target , <TAB><TAB>  "" localhost "" , <TAB><TAB>  "" 127.0.0.1 "" , <TAB>  ] : <TAB><TAB>  try : <TAB><TAB><TAB>  addr = get_local_ip_for ( h ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  addresses . append ( addr ) <TAB><TAB>  except socket . gaierror : <TAB><TAB><TAB>  pass <TAB>  return defer . succeed ( addresses ) ",if addr not in addresses :,if addr is not None:,False,21.89793750297508,97.18241706076645
3422,"def _get_notify ( self , action_node ) : <TAB>  if action_node . name not in self . _skip_notify_tasks : <TAB><TAB>  if action_node . notify : <TAB><TAB><TAB>  task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB><TAB><TAB>  return task_notify <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _chain_notify <TAB>  return None ",elif self . _chain_notify :,if self._chain_notify is not None:,False,22.944043502421028,94.15377557706772
3423,"def filterTokenLocation ( ) : <TAB>  i = None <TAB>  entry = None <TAB>  token = None <TAB>  tokens = [ ] <TAB>  i = 0 <TAB>  while 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  entry = extra . tokens [ i ] <TAB><TAB>  token = jsdict ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" type "" : entry . type , <TAB><TAB><TAB><TAB>  "" value "" : entry . value , <TAB><TAB><TAB>  } <TAB><TAB>  ) <TAB><TAB>  if extra . range : <TAB><TAB><TAB>  token . range = entry . range <TAB><TAB>  if extra . loc : <TAB><TAB><TAB>  token . loc = entry . loc <TAB><TAB>  tokens . append ( token ) <TAB><TAB>  i + = 1 <TAB>  extra . tokens = tokens ",if not ( i < len ( extra . tokens ) ) :,if i >= extra.tokens:,False,20.69280463395053,95.58423377033601
3424,"def read ( self , size = - 1 ) : <TAB>  buf = bytearray ( ) <TAB>  while size != 0 and self . cursor < self . maxpos : <TAB><TAB>  if not self . in_current_block ( self . cursor ) : <TAB><TAB><TAB>  self . seek_to_block ( self . cursor ) <TAB><TAB>  part = self . current_stream . read ( size ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if len ( part ) == 0 : <TAB><TAB><TAB><TAB>  raise EOFError ( ) <TAB><TAB><TAB>  size - = len ( part ) <TAB><TAB>  self . cursor + = len ( part ) <TAB><TAB>  buf + = part <TAB>  return bytes ( buf ) ",if size > 0 :,if part:,False,26.68303555789021,96.25451158612256
3425,"def get_properties_from_model ( model_class ) : <TAB>  """"""Show properties from a model"""""" <TAB>  properties = [ ] <TAB>  attr_names = [ name for ( name , value ) in inspect . getmembers ( model_class , isprop ) ] <TAB>  for attr_name in attr_names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attr_names . remove ( attr_name ) <TAB><TAB>  else : <TAB><TAB><TAB>  properties . append ( <TAB><TAB><TAB><TAB>  dict ( label = attr_name , name = attr_name . strip ( "" _ "" ) . replace ( "" _ "" , "" "" ) ) <TAB><TAB><TAB>  ) <TAB>  return sorted ( properties , key = lambda k : k [ "" label "" ] ) ","if attr_name . endswith ( ""pk"" ) :",if attr_name in attr_names:,False,50.46356949765012,95.81831123102201
3426,"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB>  visited = set ( ) <TAB>  mydict = self . basedict <TAB>  while 1 : <TAB><TAB>  value = mydict [ name ] <TAB><TAB>  if value is not None : <TAB><TAB><TAB>  return value <TAB><TAB>  myid = id ( mydict ) <TAB><TAB>  assert myid not in visited <TAB><TAB>  visited . add ( myid ) <TAB><TAB>  mydict = mydict . Parent <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ",if mydict is None :,if myid in visited:,False,26.359176599161614,96.9191309144217
3427,"def multicolumn ( self , list , format , cols = 4 ) : <TAB>  """"""Format a list of items into a multi-column list."""""" <TAB>  result = "" "" <TAB>  rows = ( len ( list ) + cols - 1 ) / / cols <TAB>  for col in range ( cols ) : <TAB><TAB>  result = result + ' <td width= "" %d %% ""  valign=top> ' % ( 100 / / cols ) <TAB><TAB>  for i in range ( rows * col , rows * col + rows ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result = result + format ( list [ i ] ) + "" <br> \n "" <TAB><TAB>  result = result + "" </td> "" <TAB>  return ' <table width= "" 100 %% ""  summary= "" list "" ><tr> %s </tr></table> ' % result ",if i < len ( list ) :,if list[i] != i:,False,26.789912234334075,96.41273947088034
3428,"def format_exc ( exc = None ) : <TAB>  """"""Return exc (or sys.exc_info if None), formatted."""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exc = _exc_info ( ) <TAB><TAB>  if exc == ( None , None , None ) : <TAB><TAB><TAB>  return "" "" <TAB><TAB>  import traceback <TAB><TAB>  return "" "" . join ( traceback . format_exception ( * exc ) ) <TAB>  finally : <TAB><TAB>  del exc ",if exc is None :,if exc is None:,False,57.60288577562487,100.00000000000004
3429,"def assert_counts ( res , lang , files , blank , comment , code ) : <TAB>  for line in res : <TAB><TAB>  fields = line . split ( ) <TAB><TAB>  if len ( fields ) > = 5 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( files , int ( fields [ 1 ] ) ) <TAB><TAB><TAB><TAB>  self . assertEqual ( blank , int ( fields [ 2 ] ) ) <TAB><TAB><TAB><TAB>  self . assertEqual ( comment , int ( fields [ 3 ] ) ) <TAB><TAB><TAB><TAB>  self . assertEqual ( code , int ( fields [ 4 ] ) ) <TAB><TAB><TAB><TAB>  return <TAB>  self . fail ( "" Found no output line for  {} "" . format ( lang ) ) ",if fields [ 0 ] == lang :,if len(fields) == 5:,False,50.110965819831044,96.40788370170337
3430,"def __iter__ ( self ) : <TAB>  for name , value in self . __class__ . __dict__ . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if isinstance ( value , flag_value ) : <TAB><TAB><TAB>  yield ( name , self . _has_flag ( value . flag ) ) ","if isinstance ( value , alias_flag_value ) :",if name == 'flag':,False,24.753142561239578,88.78969233380654
3431,"def optimize_models ( args , use_cuda , models ) : <TAB>  """"""Optimize ensemble for generation"""""" <TAB>  for model in models : <TAB><TAB>  model . make_generation_fast_ ( <TAB><TAB><TAB>  beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB><TAB><TAB>  need_attn = args . print_alignment , <TAB><TAB>  ) <TAB><TAB>  if args . fp16 : <TAB><TAB><TAB>  model . half ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  model . cuda ( ) ",if use_cuda :,if use_cuda:,False,51.43696444409621,100.00000000000004
3432,"def convertstore ( self , mydict ) : <TAB>  targetheader = self . mypofile . header ( ) <TAB>  targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB>  for source_str in mydict . keys ( ) : <TAB><TAB>  target_str = mydict [ source_str ] <TAB><TAB>  if target_str == source_str : <TAB><TAB><TAB>  # a convention with new (untranslated) web2py files <TAB><TAB><TAB>  target_str = u "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # an older convention <TAB><TAB><TAB>  target_str = u "" "" <TAB><TAB>  pounit = self . convertunit ( source_str , target_str ) <TAB><TAB>  self . mypofile . addunit ( pounit ) <TAB>  return self . mypofile ","elif target_str . startswith ( u""*** "" ) :","if target_str > u""':",False,56.5137263474496,93.5745225259156
3433,"def __sparse_values_set ( instances , static_col_indexes : list ) : <TAB>  tmp_result = { idx : set ( ) for idx in static_col_indexes } <TAB>  for _ , instance in instances : <TAB><TAB>  data_generator = instance . features . get_all_data ( ) <TAB><TAB>  for idx , value in data_generator : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  tmp_result [ idx ] . add ( value ) <TAB>  result = [ tmp_result [ x ] for x in static_col_indexes ] <TAB>  return result ",if idx not in tmp_result :,if idx in tmp_result:,False,52.53318305779886,98.45801177874407
3434,def puts ( self ) : <TAB>  <IF-STMT>: <TAB><TAB>  self . lazy_init_lock_ . acquire ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . puts_ = PutRequest ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . lazy_init_lock_ . release ( ) <TAB>  return self . puts_ ,if self . puts_ is None :,if self.puts_ is None:,False,44.76676400140425,92.6110104715455
3435,"def run ( self , args , * * kwargs ) : <TAB>  if args . resource_ref or args . policy_type : <TAB><TAB>  filters = { } <TAB><TAB>  if args . resource_ref : <TAB><TAB><TAB>  filters [ "" resource_ref "" ] = args . resource_ref <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filters [ "" policy_type "" ] = args . policy_type <TAB><TAB>  filters . update ( * * kwargs ) <TAB><TAB>  return self . manager . query ( * * filters ) <TAB>  else : <TAB><TAB>  return self . manager . get_all ( * * kwargs ) ",if args . policy_type :,if args.policy_type:,False,42.353444916434455,100.00000000000004
3436,"def Get_Gene ( self , id ) : <TAB>  """"""Retreive the gene name (GN)."""""" <TAB>  entry = self . Get ( id ) <TAB>  if not entry : <TAB><TAB>  return None <TAB>  GN = "" "" <TAB>  for line in string . split ( entry , "" \n "" ) : <TAB><TAB>  if line [ 0 : 5 ] == "" GN<TAB>"" : <TAB><TAB><TAB>  GN = string . strip ( line [ 5 : ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  GN = GN [ 0 : - 1 ] <TAB><TAB><TAB>  return GN <TAB><TAB>  if line [ 0 : 2 ] == "" // "" : <TAB><TAB><TAB>  break <TAB>  return GN ","if GN [ - 1 ] == ""."" :",if GN.endswith('#'):,False,37.23826110033015,92.06406252094601
3437,"def processMovie ( self , atom ) : <TAB>  for field in atom : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . processTrack ( field [ "" track "" ] ) <TAB><TAB>  if "" movie_hdr "" in field : <TAB><TAB><TAB>  self . processMovieHeader ( field [ "" movie_hdr "" ] ) ","if ""track"" in field :","if ""track"" in field:",False,26.875323785919804,100.00000000000004
3438,"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB>  if not self . video_format : <TAB><TAB>  return <TAB>  while True : <TAB><TAB>  # We skip video packets which are not video frames <TAB><TAB>  # This happens in mkv files for the first few frames. <TAB><TAB>  video_packet = self . _get_video_packet ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _decode_video_packet ( video_packet ) <TAB><TAB>  if video_packet . image is not None or not skip_empty_frame : <TAB><TAB><TAB>  break <TAB>  if _debug : <TAB><TAB>  print ( "" Returning "" , video_packet ) <TAB>  return video_packet . image ",if video_packet . image == 0 :,if video_packet:,False,66.9886820950071,96.72456527044416
3439,"def get_devices ( display = None ) : <TAB>  base = "" /dev/input "" <TAB>  for filename in os . listdir ( base ) : <TAB><TAB>  if filename . startswith ( "" event "" ) : <TAB><TAB><TAB>  path = os . path . join ( base , filename ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  _devices [ path ] = EvdevDevice ( display , path ) <TAB><TAB><TAB>  except OSError : <TAB><TAB><TAB><TAB>  pass <TAB>  return list ( _devices . values ( ) ) ",if path in _devices :,if path in _devices:,False,51.192233655199004,100.00000000000004
3440,"def _ensure_header_written ( self , datasize ) : <TAB>  if not self . _headerwritten : <TAB><TAB>  if not self . _nchannels : <TAB><TAB><TAB>  raise Error ( "" # channels not specified "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Error ( "" sample width not specified "" ) <TAB><TAB>  if not self . _framerate : <TAB><TAB><TAB>  raise Error ( "" sampling rate not specified "" ) <TAB><TAB>  self . _write_header ( datasize ) ",if not self . _sampwidth :,if not self._sample_width:,False,26.262923563336503,96.64331377240634
3441,"def process ( self , fuzzresult ) : <TAB>  base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB>  for line in fuzzresult . history . content . splitlines ( ) : <TAB><TAB>  record = line . split ( "" / "" ) <TAB><TAB>  if len ( record ) == 6 and record [ 1 ] : <TAB><TAB><TAB>  self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB>  # Directory <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB><TAB>  self . queue_url ( urljoin ( base_url , "" %s /CVS/Entries "" % ( record [ 1 ] ) ) ) ","if record [ 0 ] == ""D"" :",if len(record) == 6:,False,51.98725598060795,95.36662915465348
3442,"def tearDown ( self ) : <TAB>  """"""Shutdown the UDP server."""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . server . stop ( 2.0 ) <TAB><TAB>  if self . sock_hdlr : <TAB><TAB><TAB>  self . root_logger . removeHandler ( self . sock_hdlr ) <TAB><TAB><TAB>  self . sock_hdlr . close ( ) <TAB>  finally : <TAB><TAB>  BaseTest . tearDown ( self ) ",if self . server :,if self.server:,False,27.308289905181127,100.00000000000004
3443,"def get_backend ( find_library = None ) : <TAB>  try : <TAB><TAB>  global _lib , _ctx <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _lib = _load_library ( find_library ) <TAB><TAB><TAB>  _setup_prototypes ( _lib ) <TAB><TAB><TAB>  _ctx = _Context ( ) <TAB><TAB>  _logger . warning ( <TAB><TAB><TAB>  "" OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284) "" <TAB><TAB>  ) <TAB><TAB>  return _OpenUSB ( ) <TAB>  except usb . libloader . LibraryException : <TAB><TAB>  # exception already logged (if any) <TAB><TAB>  _logger . error ( "" Error loading OpenUSB backend "" , exc_info = False ) <TAB><TAB>  return None <TAB>  except Exception : <TAB><TAB>  _logger . error ( "" Error loading OpenUSB backend "" , exc_info = True ) <TAB><TAB>  return None ",if _lib is None :,if find_library is not None:,False,53.2745028187471,97.58899357591544
3444,"def __init__ ( self , event , event_info , fields = [ ] ) : <TAB>  _wmi_object . __init__ ( self , event , fields = fields ) <TAB>  _set ( self , "" event_type "" , None ) <TAB>  _set ( self , "" timestamp "" , None ) <TAB>  _set ( self , "" previous "" , None ) <TAB>  if event_info : <TAB><TAB>  event_type = self . event_type_re . match ( event_info . Path_ . Class ) . group ( 1 ) . lower ( ) <TAB><TAB>  _set ( self , "" event_type "" , event_type ) <TAB><TAB>  if hasattr ( event_info , "" TIME_CREATED "" ) : <TAB><TAB><TAB>  _set ( self , "" timestamp "" , from_1601 ( event_info . TIME_CREATED ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _set ( self , "" previous "" , event_info . PreviousInstance ) ","if hasattr ( event_info , ""PreviousInstance"" ) :",if event_info.PreviousInstance:,False,49.02961404445989,96.00965125869787
3445,"def _getListNextPackagesReadyToBuild ( ) : <TAB>  for pkg in Scheduler . listOfPackagesToBuild : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) : <TAB><TAB><TAB>  Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB><TAB><TAB>  Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" ) ",if pkg in Scheduler . listOfPackagesCurrentlyBuilding :,if pkg == 'default':,False,35.22832950180634,93.21566450438499
3446,"def process_all ( self , lines , times = 1 ) : <TAB>  gap = False <TAB>  for _ in range ( times ) : <TAB><TAB>  for line in lines : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . write ( "" "" ) <TAB><TAB><TAB>  self . process ( line ) <TAB><TAB><TAB>  if not is_command ( line ) : <TAB><TAB><TAB><TAB>  gap = True <TAB>  return 0 ",if gap :,if not gap:,False,43.8510206414636,97.99565852526808
3447,"def diff ( old , new , display = True ) : <TAB>  """"""Nice colored diff implementation"""""" <TAB>  if not isinstance ( old , list ) : <TAB><TAB>  old = decolorize ( str ( old ) ) . splitlines ( ) <TAB>  if not isinstance ( new , list ) : <TAB><TAB>  new = decolorize ( str ( new ) ) . splitlines ( ) <TAB>  line_types = { "" "" : "" % Reset "" , "" - "" : "" % Red "" , "" + "" : "" %G reen "" , "" ? "" : "" % Pink "" } <TAB>  if display : <TAB><TAB>  for line in difflib . Differ ( ) . compare ( old , new ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  print ( colorize ( line_types [ line [ 0 ] ] , line ) ) <TAB>  return old != new ","if line . startswith ( ""?"" ) :",if line == line_types[line[0]]:,False,43.68084405884634,92.95646339598856
3448,"def get_limit ( self , request ) : <TAB>  if self . limit_query_param : <TAB><TAB>  try : <TAB><TAB><TAB>  limit = int ( request . query_params [ self . limit_query_param ] ) <TAB><TAB><TAB>  if limit < 0 : <TAB><TAB><TAB><TAB>  raise ValueError ( ) <TAB><TAB><TAB>  # Enforce maximum page size, if defined <TAB><TAB><TAB>  if settings . MAX_PAGE_SIZE : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return settings . MAX_PAGE_SIZE <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  return min ( limit , settings . MAX_PAGE_SIZE ) <TAB><TAB><TAB>  return limit <TAB><TAB>  except ( KeyError , ValueError ) : <TAB><TAB><TAB>  pass <TAB>  return self . default_limit ",if limit == 0 :,if limit > settings.MAX_PAGE_SIZE:,False,55.52298328532381,96.2344924776523
3449,"def slice_fill ( self , slice_ ) : <TAB>  "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB>  if isinstance ( self . indexes , int ) : <TAB><TAB>  new_slice_ = [ 0 ] <TAB><TAB>  offset = 0 <TAB>  else : <TAB><TAB>  new_slice_ = [ slice_ [ 0 ] ] <TAB><TAB>  offset = 1 <TAB>  for i in range ( 1 , len ( self . nums ) ) : <TAB><TAB>  if self . squeeze_dims [ i ] : <TAB><TAB><TAB>  new_slice_ . append ( 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_slice_ . append ( slice_ [ offset ] ) <TAB><TAB><TAB>  offset + = 1 <TAB>  new_slice_ + = slice_ [ offset : ] <TAB>  return new_slice_ ",elif offset < len ( slice_ ) :,if slice_[offset] != 0:,False,31.437068527670082,95.7765528975315
3450,"def wrapper ( * args , * * kw ) : <TAB>  instance = args [ 0 ] <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret_dict = instance . _create_ret_object ( <TAB><TAB><TAB><TAB>  instance . FAILURE , None , True , instance . MUST_JSON <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  instance . logger . error ( instance . MUST_JSON ) <TAB><TAB><TAB>  return jsonify ( ret_dict ) , 400 <TAB>  except BadRequest : <TAB><TAB>  ret_dict = instance . _create_ret_object ( <TAB><TAB><TAB>  instance . FAILURE , None , True , instance . MUST_JSON <TAB><TAB>  ) <TAB><TAB>  instance . logger . error ( instance . MUST_JSON ) <TAB><TAB>  return jsonify ( ret_dict ) , 400 <TAB>  instance . logger . debug ( "" JSON is valid "" ) <TAB>  return f ( * args , * * kw ) ",if request . get_json ( ) is None :,"if not isinstance(instance, MayaError):",False,28.287086955684256,96.01917377689578
3451,"def add_css ( self , data ) : <TAB>  if data : <TAB><TAB>  for medium , paths in data . items ( ) : <TAB><TAB><TAB>  for path in paths : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . _css . setdefault ( medium , [ ] ) . append ( path ) ",if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,if path not in self._css:,False,22.237555915242773,84.24143699146876
3452,"def mangle_template ( template : str , template_vars : Set [ str ] ) - > str : <TAB>  if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template : <TAB><TAB>  raise Exception ( "" Cannot parse a template containing reserved strings "" ) <TAB>  for var in template_vars : <TAB><TAB>  original = f "" {{ { var } }} "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  f ' Template string is missing a reference to  "" { var } ""  referred to in kwargs ' <TAB><TAB><TAB>  ) <TAB><TAB>  template = template . replace ( original , mangled_name ( var ) ) <TAB>  return template ",if original not in template :,if not original.startswith('_'):,False,45.23632432489123,89.9279626775231
3453,"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB>  """"""Return a sorted list of keywords similar to the one given."""""" <TAB>  seenDict = { } <TAB>  kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB>  matches = [ ] <TAB>  matchesappend = matches . append <TAB>  checkContained = False <TAB>  if len ( keyword ) > 4 : <TAB><TAB>  checkContained = True <TAB>  for movieID , key in kwdsIterator : <TAB><TAB>  if key in seenDict : <TAB><TAB><TAB>  continue <TAB><TAB>  seenDict [ key ] = None <TAB><TAB>  if checkContained and keyword in key : <TAB><TAB><TAB>  matchesappend ( key ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  matchesappend ( key ) <TAB>  return _sortKeywords ( keyword , matches ) ","if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :",if not checkContained and keyword in kwdSndx:,False,30.118941529325266,91.31515822794384
3454,"def GetInfo ( self ) : <TAB>  for k , v in sorted ( self . memory_parameters . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if not v : <TAB><TAB><TAB>  continue <TAB><TAB>  print ( "" %s :  \t %#08x  ( %s ) "" % ( k , v , v ) ) <TAB>  print ( "" Memory ranges: "" ) <TAB>  print ( "" Start \t \t End \t \t Length "" ) <TAB>  for start , length in self . runs : <TAB><TAB>  print ( "" 0x %X \t \t 0x %X \t \t 0x %X "" % ( start , start + length , length ) ) ","if k . startswith ( ""Pad"" ) :",if not k.startswith('_memory_range'):,False,21.650885550033554,87.50093632421833
3455,"def Children ( self ) : <TAB>  """"""Returns a list of all of this object's owned (strong) children."""""" <TAB>  children = [ ] <TAB>  for property , attributes in self . _schema . iteritems ( ) : <TAB><TAB>  ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB><TAB>  if is_strong and property in self . _properties : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  children . append ( self . _properties [ property ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  children . extend ( self . _properties [ property ] ) <TAB>  return children ",if not is_list :,if is_list and (not is_list):,False,33.811101213914455,94.99749776809371
3456,"def normalize_res_identifier ( self , emu , cw , val ) : <TAB>  mask = ( 16 * * ( emu . get_ptr_size ( ) / / 2 ) - 1 ) << 16 <TAB>  if val & mask :<TAB># not an INTRESOURCE <TAB><TAB>  name = emu . read_mem_string ( val , cw ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  name = int ( name [ 1 : ] ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  return 0 <TAB>  else : <TAB><TAB>  name = val <TAB>  return name ","if name [ 0 ] == ""#"" :",if name.startswith('INTRESOURCE'):,False,45.210782388663,93.52970864589794
3457,"def _optimize ( self , solutions ) : <TAB>  best_a = None <TAB>  best_silhouette = None <TAB>  best_k = None <TAB>  for a , silhouette , k in solutions ( ) : <TAB><TAB>  if best_silhouette is None : <TAB><TAB><TAB>  pass <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  best_silhouette = silhouette <TAB><TAB>  best_a = a <TAB><TAB>  best_k = k <TAB>  return best_a , best_silhouette , best_k ",elif silhouette <= best_silhouette :,if best_a is best_k is best_k:,False,24.7249136149758,91.21608359160467
3458,"def find_commit_type ( sha ) : <TAB>  try : <TAB><TAB>  o = obj_store [ sha ] <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB>  else : <TAB><TAB>  if isinstance ( o , Commit ) : <TAB><TAB><TAB>  commits . add ( sha ) <TAB><TAB>  elif isinstance ( o , Tag ) : <TAB><TAB><TAB>  tags . add ( sha ) <TAB><TAB><TAB>  commits . add ( o . object [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise KeyError ( "" Not a commit or a tag:  %s "" % sha ) ",if not ignore_unknown :,if sha not in commits:,False,28.754624306287162,96.94699562073113
3459,"def on_search_entry_keypress ( self , widget , event ) : <TAB>  key = Gdk . keyval_name ( event . keyval ) <TAB>  if key == "" Escape "" : <TAB><TAB>  self . hide_search_box ( ) <TAB>  elif key == "" Return "" : <TAB><TAB>  # Combine with Shift? <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . search_prev = False <TAB><TAB><TAB>  self . do_search ( None ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . search_prev = True ",if event . state & Gdk . ModifierType . SHIFT_MASK :,if self.search_prev:,False,51.357601164547106,92.12853571688149
3460,"def process_webhook_prop ( namespace ) : <TAB>  if not isinstance ( namespace . webhook_properties , list ) : <TAB><TAB>  return <TAB>  result = { } <TAB>  for each in namespace . webhook_properties : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" = "" in each : <TAB><TAB><TAB><TAB>  key , value = each . split ( "" = "" , 1 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  key , value = each , "" "" <TAB><TAB><TAB>  result [ key ] = value <TAB>  namespace . webhook_properties = result ",if each :,if each.startswith('='):,False,49.601919803644066,94.8252737754525
3461,"def run ( self ) : <TAB>  global WAITING_BEFORE_START <TAB>  time . sleep ( WAITING_BEFORE_START ) <TAB>  while self . keep_alive : <TAB><TAB>  path_id , module , resolve = self . queue_receive . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  self . lock . acquire ( ) <TAB><TAB>  self . modules [ path_id ] = module <TAB><TAB>  self . lock . release ( ) <TAB><TAB>  if resolve : <TAB><TAB><TAB>  resolution = self . _resolve_with_other_modules ( resolve ) <TAB><TAB><TAB>  self . _relations [ path_id ] = [ ] <TAB><TAB><TAB>  for package in resolution : <TAB><TAB><TAB><TAB>  self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB><TAB><TAB>  self . queue_send . put ( ( path_id , module , False , resolution ) ) ",if path_id is None :,if path_id in self._relations:,False,23.62260624603489,97.43285218418984
3462,"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB>  links = { <TAB><TAB>  "" torrent "" : "" "" , <TAB><TAB>  "" magnet "" : "" "" , <TAB>  } <TAB>  try : <TAB><TAB>  data = self . session . get ( url ) . text <TAB><TAB>  with bs4_parser ( data ) as html : <TAB><TAB><TAB>  downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB><TAB><TAB>  if downloads : <TAB><TAB><TAB><TAB>  for download in downloads . findAll ( "" a "" ) : <TAB><TAB><TAB><TAB><TAB>  link = download [ "" href "" ] <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  links [ "" magnet "" ] = link <TAB><TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB><TAB>  links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB>  except Exception : <TAB><TAB>  pass <TAB>  return links [ download_type ] ","if link . startswith ( ""magnet"" ) :",if link.startswith('mailto/'):,False,26.488256635344598,98.56263927360358
3463,"def _parse_fields ( cls , read ) : <TAB>  read = unicode_to_str ( read ) <TAB>  if type ( read ) is not str : <TAB><TAB>  _wrong_type_for_arg ( read , "" str "" , "" read "" ) <TAB>  fields = { } <TAB>  while read and read [ 0 ] != "" ; "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  DeserializeError ( read , "" does not separate fields with commas "" ) <TAB><TAB>  read = read [ 1 : ] <TAB><TAB>  key , _type , value , read = cls . _parse_field ( read ) <TAB><TAB>  fields [ key ] = ( _type , value ) <TAB>  if read : <TAB><TAB>  # read[0] == ';' <TAB><TAB>  read = read [ 1 : ] <TAB>  return fields , read ","if read and read [ 0 ] != "","" :",if read[0] == ';':,False,51.185733117679135,95.89087328975421
3464,"def _convertDict ( self , d ) : <TAB>  r = { } <TAB>  for k , v in d . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = str ( v , "" utf-8 "" ) <TAB><TAB>  elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB><TAB><TAB>  v = self . _convertList ( v ) <TAB><TAB>  elif isinstance ( v , dict ) : <TAB><TAB><TAB>  v = self . _convertDict ( v ) <TAB><TAB>  if isinstance ( k , bytes ) : <TAB><TAB><TAB>  k = str ( k , "" utf-8 "" ) <TAB><TAB>  r [ k ] = v <TAB>  return r ","if isinstance ( v , bytes ) :","if isinstance(v, bytes):",False,50.64634905127521,100.00000000000004
3465,"def wrapper ( filename ) : <TAB>  mtime = getmtime ( filename ) <TAB>  with lock : <TAB><TAB>  if filename in cache : <TAB><TAB><TAB>  old_mtime , result = cache . pop ( filename ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # Move to the end <TAB><TAB><TAB><TAB>  cache [ filename ] = old_mtime , result <TAB><TAB><TAB><TAB>  return result <TAB>  result = function ( filename ) <TAB>  with lock : <TAB><TAB>  cache [ filename ] = mtime , result<TAB># at the end <TAB><TAB>  if len ( cache ) > max_size : <TAB><TAB><TAB>  cache . popitem ( last = False ) <TAB>  return result ",if old_mtime == mtime :,if old_mtime != mtime:,False,51.76287581809189,96.40574723612986
3466,def isFinished ( self ) : <TAB>  # returns true if episode timesteps has reached episode length and resets the task <TAB>  if self . count > self . epiLen : <TAB><TAB>  self . res ( ) <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . pertGlasPos ( 0 ) <TAB><TAB>  if self . count == self . epiLen / 2 + 1 : <TAB><TAB><TAB>  self . env . reset ( ) <TAB><TAB><TAB>  self . pertGlasPos ( 1 ) <TAB><TAB>  self . count + = 1 <TAB><TAB>  return False ,if self . count == 1 :,if self.count == self.epiLen:,False,39.68364508810346,97.17095724139516
3467,"def _check_vulnerabilities ( self , processed_analysis ) : <TAB>  matched_vulnerabilities = list ( ) <TAB>  for vulnerability in self . _rule_base_vulnerabilities : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vulnerability_data = vulnerability . get_dict ( ) <TAB><TAB><TAB>  name = vulnerability_data . pop ( "" short_name "" ) <TAB><TAB><TAB>  matched_vulnerabilities . append ( ( name , vulnerability_data ) ) <TAB>  return matched_vulnerabilities ","if evaluate ( processed_analysis , vulnerability . rule ) :",if vulnerability.get_name() == processed_analysis:,False,47.25113399800854,91.62594650807365
3468,"def _table_reprfunc ( self , row , col , val ) : <TAB>  if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ""<TAB>%s "" % val <TAB><TAB>  elif val < 1024 * * 2 : <TAB><TAB><TAB>  return ""<TAB>%.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB><TAB>  elif val < 1024 * * 3 : <TAB><TAB><TAB>  return ""<TAB>%.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  return ""<TAB>%.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB>  if col in ( 0 , "" "" ) : <TAB><TAB>  return str ( val ) <TAB>  else : <TAB><TAB>  return ""<TAB>%s "" % val ","if isinstance ( val , compat . string_types ) :",if val < 1024 * * 1:,False,16.491680362714554,87.24505232446961
3469,"def serve_until_stopped ( self ) - > None : <TAB>  while True : <TAB><TAB>  rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB><TAB>  if rd : <TAB><TAB><TAB>  self . handle_request ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ",if self . event is not None and self . event . is_set ( ) :,if rd:,False,47.12478907602075,83.71918537197936
3470,"def resize ( self , * e ) : <TAB>  bold = ( "" helvetica "" , - self . _size . get ( ) , "" bold "" ) <TAB>  helv = ( "" helvetica "" , - self . _size . get ( ) ) <TAB>  xspace = self . _size . get ( ) <TAB>  yspace = self . _size . get ( ) <TAB>  for widget in self . _widgets : <TAB><TAB>  widget [ "" node_font "" ] = bold <TAB><TAB>  widget [ "" leaf_font "" ] = helv <TAB><TAB>  widget [ "" xspace "" ] = xspace <TAB><TAB>  widget [ "" yspace "" ] = yspace <TAB><TAB>  if self . _size . get ( ) < 20 : <TAB><TAB><TAB>  widget [ "" line_width "" ] = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  widget [ "" line_width "" ] = 2 <TAB><TAB>  else : <TAB><TAB><TAB>  widget [ "" line_width "" ] = 3 <TAB>  self . _layout ( ) ",elif self . _size . get ( ) < 30 :,if self._size.get() < 20:,False,26.78460103940567,95.334196902839
3471,"def __assertTilesChangedInRegion ( self , t1 , t2 , region ) : <TAB>  for tileOriginTuple in t1 . keys ( ) : <TAB><TAB>  tileOrigin = imath . V2i ( * tileOriginTuple ) <TAB><TAB>  tileRegion = imath . Box2i ( <TAB><TAB><TAB>  tileOrigin , tileOrigin + imath . V2i ( GafferImage . ImagePlug . tileSize ( ) ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertNotEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] ) ","if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :",if region == 'gaffer':,False,21.83528835235711,92.71722717284413
3472,"def grouped_by_prefix ( args , prefixes ) : <TAB>  """"""Group behave args by (directory) scope into multiple test-runs."""""" <TAB>  group_args = [ ] <TAB>  current_scope = None <TAB>  for arg in args . strip ( ) . split ( ) : <TAB><TAB>  assert not arg . startswith ( "" - "" ) , "" REQUIRE: arg, not options "" <TAB><TAB>  scope = select_prefix_for ( arg , prefixes ) <TAB><TAB>  if scope != current_scope : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # -- DETECTED GROUP-END: <TAB><TAB><TAB><TAB>  yield "" "" . join ( group_args ) <TAB><TAB><TAB><TAB>  group_args = [ ] <TAB><TAB><TAB>  current_scope = scope <TAB><TAB>  group_args . append ( arg ) <TAB>  <IF-STMT>: <TAB><TAB>  yield "" "" . join ( group_args ) ",if group_args :,if group_args:,False,57.052202625679115,97.7488988705069
3473,"def __print__ ( self , defaults = False ) : <TAB>  if defaults : <TAB><TAB>  print_func = str <TAB>  else : <TAB><TAB>  print_func = repr <TAB>  pieces = [ ] <TAB>  default_values = self . __defaults__ <TAB>  for k in self . __fields__ : <TAB><TAB>  value = getattr ( self , k ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if isinstance ( value , basestring ) : <TAB><TAB><TAB>  print_func = repr<TAB># keep quotes around strings <TAB><TAB>  pieces . append ( "" %s = %s "" % ( k , print_func ( value ) ) ) <TAB>  if pieces or self . __base__ : <TAB><TAB>  return "" %s ( %s ) "" % ( self . __class__ . __name__ , "" ,  "" . join ( pieces ) ) <TAB>  else : <TAB><TAB>  return "" "" ",if not defaults and value == default_values [ k ] :,if value is None:,False,21.310686728528015,94.1807016300006
3474,"def setInnerHTML ( self , html ) : <TAB>  log . HTMLClassifier . classify ( <TAB><TAB>  log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB>  ) <TAB>  self . tag . clear ( ) <TAB>  for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB><TAB>  self . tag . append ( node ) <TAB><TAB>  name = getattr ( node , "" name "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB><TAB>  if handler : <TAB><TAB><TAB>  handler ( node ) ",if name is None :,if name is None:,False,50.921796050371505,100.00000000000004
3475,"def createFields ( self ) : <TAB>  yield Enum ( Bits ( self , "" class "" , 2 ) , self . CLASS_DESC ) <TAB>  yield Enum ( Bit ( self , "" form "" ) , self . FORM_DESC ) <TAB>  if self [ "" class "" ] . value == 0 : <TAB><TAB>  yield Enum ( Bits ( self , "" type "" , 5 ) , self . TYPE_DESC ) <TAB>  else : <TAB><TAB>  yield Bits ( self , "" type "" , 5 ) <TAB>  yield ASNInteger ( self , "" size "" , "" Size in bytes "" ) <TAB>  size = self [ "" size "" ] . value <TAB>  if size : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for field in self . _handler ( self , size ) : <TAB><TAB><TAB><TAB>  yield field <TAB><TAB>  else : <TAB><TAB><TAB>  yield RawBytes ( self , "" raw "" , size ) ",if self . _handler :,if self._handler:,False,50.52061053816463,100.00000000000004
3476,"def _process_service_request ( self , pkttype , pktid , packet ) : <TAB>  """"""Process a service request"""""" <TAB>  # pylint: disable=unused-argument <TAB>  service = packet . get_string ( ) <TAB>  packet . check_end ( ) <TAB>  if service == self . _next_service : <TAB><TAB>  self . logger . debug2 ( "" Accepting request for service  %s "" , service ) <TAB><TAB>  self . _next_service = None <TAB><TAB>  self . send_packet ( MSG_SERVICE_ACCEPT , String ( service ) ) <TAB><TAB>  <IF-STMT>:<TAB># pragma: no branch <TAB><TAB><TAB>  self . _auth_in_progress = True <TAB><TAB><TAB>  self . _send_deferred_packets ( ) <TAB>  else : <TAB><TAB>  raise DisconnectError ( <TAB><TAB><TAB>  DISC_SERVICE_NOT_AVAILABLE , "" Unexpected service request received "" <TAB><TAB>  ) ",if self . is_server ( ) and service == _USERAUTH_SERVICE :,if self._auth_in_progress:,False,51.642398854453816,94.03054152623534
3477,"def _read_fixed_body ( <TAB>  self , content_length : int , delegate : httputil . HTTPMessageDelegate  ) - > None : <TAB>  while content_length > 0 : <TAB><TAB>  body = await self . stream . read_bytes ( <TAB><TAB><TAB>  min ( self . params . chunk_size , content_length ) , partial = True <TAB><TAB>  ) <TAB><TAB>  content_length - = len ( body ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with _ExceptionLoggingContext ( app_log ) : <TAB><TAB><TAB><TAB>  ret = delegate . data_received ( body ) <TAB><TAB><TAB><TAB>  if ret is not None : <TAB><TAB><TAB><TAB><TAB>  await ret ",if not self . _write_finished or self . is_client :,if content_length == 0:,False,22.085066953551415,92.8158532943647
3478,"def wait_for_child ( pid , timeout = 1.0 ) : <TAB>  deadline = mitogen . core . now ( ) + timeout <TAB>  while timeout < mitogen . core . now ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB>  except OSError : <TAB><TAB><TAB>  e = sys . exc_info ( ) [ 1 ] <TAB><TAB><TAB>  if e . args [ 0 ] == errno . ECHILD : <TAB><TAB><TAB><TAB>  return <TAB><TAB>  time . sleep ( 0.05 ) <TAB>  assert False , "" wait_for_child() timed out "" ",if target_pid == pid :,if target_pid == pid:,False,50.976205569290876,100.00000000000004
3479,"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB>  try : <TAB><TAB>  pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB>  if op . stage == OperandStage . map : <TAB><TAB><TAB>  cls . _execute_map ( ctx , op ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . _execute_combine ( ctx , op ) <TAB><TAB>  elif op . stage == OperandStage . agg : <TAB><TAB><TAB>  cls . _execute_agg ( ctx , op ) <TAB><TAB>  else :<TAB># pragma: no cover <TAB><TAB><TAB>  raise ValueError ( "" Aggregation operand not executable "" ) <TAB>  finally : <TAB><TAB>  pd . reset_option ( "" mode.use_inf_as_na "" ) ",elif op . stage == OperandStage . combine :,if op.stage == OperandStage.combine:,False,25.58719143484983,96.8575944092633
3480,def cut ( sentence ) : <TAB>  sentence = strdecode ( sentence ) <TAB>  blocks = re_han . split ( sentence ) <TAB>  for blk in blocks : <TAB><TAB>  if re_han . match ( blk ) : <TAB><TAB><TAB>  for word in __cut ( blk ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  yield word <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  for c in word : <TAB><TAB><TAB><TAB><TAB><TAB>  yield c <TAB><TAB>  else : <TAB><TAB><TAB>  tmp = re_skip . split ( blk ) <TAB><TAB><TAB>  for x in tmp : <TAB><TAB><TAB><TAB>  if x : <TAB><TAB><TAB><TAB><TAB>  yield x ,if word not in Force_Split_Words :,if re_han.match(word):,False,50.261780054811275,96.17125586962862
3481,"def _iter_tags ( self , type = None ) : <TAB>  """"""Yield all raw tags (limit to |type| if specified)"""""" <TAB>  for n in itertools . count ( ) : <TAB><TAB>  tag = self . _get_tag ( n ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield tag <TAB><TAB>  if tag [ "" d_tag "" ] == "" DT_NULL "" : <TAB><TAB><TAB>  break ","if type is None or tag [ ""d_tag"" ] == type :",if tag and type is None:,False,35.38862507514532,88.36628327734623
3482,"def reverse_search_history ( self , searchfor , startpos = None ) : <TAB>  if startpos is None : <TAB><TAB>  startpos = self . history_cursor <TAB>  if _ignore_leading_spaces : <TAB><TAB>  res = [ <TAB><TAB><TAB>  ( idx , line . lstrip ( ) ) <TAB><TAB><TAB>  for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB>  if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ) <TAB><TAB>  ] <TAB>  else : <TAB><TAB>  res = [ <TAB><TAB><TAB>  ( idx , line ) <TAB><TAB><TAB>  for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  ] <TAB>  if res : <TAB><TAB>  self . history_cursor - = res [ 0 ] [ 0 ] <TAB><TAB>  return res [ 0 ] [ 1 ] . get_line_text ( ) <TAB>  return "" "" ",if line . startswith ( searchfor ),if idx not in self.history:,False,22.823647042654095,94.26121277933859
3483,"def value_to_db_datetime ( self , value ) : <TAB>  if value is None : <TAB><TAB>  return None <TAB>  # Oracle doesn't support tz-aware datetimes <TAB>  if timezone . is_aware ( value ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Oracle backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB><TAB><TAB>  ) <TAB>  return unicode ( value ) ",if settings . USE_TZ :,if USE_TZ:,False,63.86541337630549,97.74530969522824
3484,"def _sniff ( filename , oxlitype ) : <TAB>  try : <TAB><TAB>  with open ( filename , "" rb "" ) as fileobj : <TAB><TAB><TAB>  header = fileobj . read ( 4 ) <TAB><TAB><TAB>  if header == b "" OXLI "" : <TAB><TAB><TAB><TAB>  fileobj . read ( 1 )<TAB># skip the version number <TAB><TAB><TAB><TAB>  ftype = fileobj . read ( 1 ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB>  return False <TAB>  except OSError : <TAB><TAB>  return False ",if binascii . hexlify ( ftype ) == oxlitype :,"if ftype == b""OXLI':",False,19.99053138793508,93.51333345658853
3485,"def unget ( self , char ) : <TAB>  # Only one character is allowed to be ungotten at once - it must <TAB>  # be consumed again before any further call to unget <TAB>  if char is not EOF : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # unget is called quite rarely, so it's a good idea to do <TAB><TAB><TAB>  # more work here if it saves a bit of work in the frequently <TAB><TAB><TAB>  # called char and charsUntil. <TAB><TAB><TAB>  # So, just prepend the ungotten character onto the current <TAB><TAB><TAB>  # chunk: <TAB><TAB><TAB>  self . chunk = char + self . chunk <TAB><TAB><TAB>  self . chunkSize + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  self . chunkOffset - = 1 <TAB><TAB><TAB>  assert self . chunk [ self . chunkOffset ] == char ",if self . chunkOffset == 0 :,if char == '\n':,False,49.324454357680395,97.05100336169012
3486,"def scan ( rule , extensions , paths , ignore_paths = None ) : <TAB>  """"""The libsast scan."""""" <TAB>  try : <TAB><TAB>  options = { <TAB><TAB><TAB>  "" match_rules "" : rule , <TAB><TAB><TAB>  "" match_extensions "" : extensions , <TAB><TAB><TAB>  "" ignore_paths "" : ignore_paths , <TAB><TAB><TAB>  "" show_progress "" : False , <TAB><TAB>  } <TAB><TAB>  scanner = Scanner ( options , paths ) <TAB><TAB>  res = scanner . scan ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return format_findings ( res [ "" pattern_matcher "" ] , paths [ 0 ] ) <TAB>  except Exception : <TAB><TAB>  logger . exception ( "" libsast scan "" ) <TAB>  return { } ",if res :,if res:,False,50.391543788526505,100.00000000000004
3487,"def _getPatternTemplate ( pattern , key = None ) : <TAB>  if key is None : <TAB><TAB>  key = pattern <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  key = pattern . upper ( ) <TAB>  template = DD_patternCache . get ( key ) <TAB>  if not template : <TAB><TAB>  if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB><TAB><TAB>  template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB><TAB>  elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB><TAB><TAB>  template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  template = DatePatternRegex ( pattern ) <TAB>  DD_patternCache . set ( key , template ) <TAB>  return template ","if ""%"" not in pattern :","if isinstance(pattern, basestring):",False,21.41145197239655,96.8076947996292
3488,"def _forward_response ( self , src , dst ) : <TAB>  """"""Forward an SCP response between two remote SCP servers"""""" <TAB>  # pylint: disable=no-self-use <TAB>  try : <TAB><TAB>  exc = yield from src . await_response ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dst . send_error ( exc ) <TAB><TAB><TAB>  return exc <TAB><TAB>  else : <TAB><TAB><TAB>  dst . send_ok ( ) <TAB><TAB><TAB>  return None <TAB>  except OSError as exc : <TAB><TAB>  return exc ",if exc :,if exc is not None:,False,61.11538261173184,97.02111788734693
3489,"def _maybe_signal_recovery_end ( ) - > None : <TAB>  if self . in_recovery and not self . active_remaining_total ( ) : <TAB><TAB>  # apply anything stuck in the buffers <TAB><TAB>  self . flush_buffers ( ) <TAB><TAB>  self . _set_recovery_ended ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _actives_span . set_tag ( "" Actives-Ready "" , True ) <TAB><TAB>  self . signal_recovery_end . set ( ) ",if self . _actives_span is not None :,if self.in_recovery:,False,52.908025540940216,93.93012773551241
3490,"def main ( ) : <TAB>  tmpdir = None <TAB>  try : <TAB><TAB>  # Create a temporary working directory <TAB><TAB>  tmpdir = tempfile . mkdtemp ( ) <TAB><TAB>  # Unpack the zipfile into the temporary directory <TAB><TAB>  pip_zip = os . path . join ( tmpdir , "" pip.zip "" ) <TAB><TAB>  with open ( pip_zip , "" wb "" ) as fp : <TAB><TAB><TAB>  fp . write ( b85decode ( DATA . replace ( b "" \n "" , b "" "" ) ) ) <TAB><TAB>  # Add the zipfile to sys.path so that we can import it <TAB><TAB>  sys . path . insert ( 0 , pip_zip ) <TAB><TAB>  # Run the bootstrap <TAB><TAB>  bootstrap ( tmpdir = tmpdir ) <TAB>  finally : <TAB><TAB>  # Clean up our temporary working directory <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shutil . rmtree ( tmpdir , ignore_errors = True ) ",if tmpdir :,if tmpdir is not None:,False,64.0625215742351,98.1177125962316
3491,"def __init__ ( self , api_version_str ) : <TAB>  try : <TAB><TAB>  self . latest = self . preview = False <TAB><TAB>  self . yyyy = self . mm = self . dd = None <TAB><TAB>  if api_version_str == "" latest "" : <TAB><TAB><TAB>  self . latest = True <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . preview = True <TAB><TAB><TAB>  parts = api_version_str . split ( "" - "" ) <TAB><TAB><TAB>  self . yyyy = int ( parts [ 0 ] ) <TAB><TAB><TAB>  self . mm = int ( parts [ 1 ] ) <TAB><TAB><TAB>  self . dd = int ( parts [ 2 ] ) <TAB>  except ( ValueError , TypeError ) : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB><TAB>  ) ","if ""preview"" in api_version_str :","if api_version_str == ""preview':",False,33.741593981614734,97.51431972930823
3492,"def _merge ( self , items , map_id , dep_id , use_disk , meminfo , mem_limit ) : <TAB>  combined = self . combined <TAB>  merge_combiner = self . aggregator . mergeCombiners <TAB>  for k , v in items : <TAB><TAB>  o = combined . get ( k ) <TAB><TAB>  combined [ k ] = merge_combiner ( o , v ) if o is not None else v <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mem_limit = self . _rotate ( ) ",if use_disk and meminfo . rss > mem_limit :,if mem_limit is None:,False,34.94243931359935,91.68113181706336
3493,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_value ( d . getVarInt32 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 8 :,if tt == 0:,False,46.452429171598006,97.7421864143982
3494,"def nice ( deltat ) : <TAB>  # singular,plural <TAB>  times = _ ( <TAB><TAB>  "" second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years "" <TAB>  ) . split ( "" : "" ) <TAB>  d = abs ( int ( deltat ) ) <TAB>  for div , time in zip ( ( 60 , 60 , 24 , 7 , 4 , 12 , 100 ) , times ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" %s %i %s "" % ( deltat < 0 and "" - "" or "" "" , d , time . split ( "" , "" ) [ d != 1 ] ) <TAB><TAB>  d / = div ",if d < div * 5 :,if d > 1:,False,26.389950606555118,96.88070556328499
3495,"def after_get_object ( self , event , view_kwargs ) : <TAB>  if event and event . state == "" draft "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ObjectNotFound ( { "" parameter "" : "" {id} "" } , "" Event: not found "" ) ","if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :",if not event:,False,14.928337335194769,67.42630794981741
3496,def daemonize_if_required ( self ) : <TAB>  if self . options . daemon : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Stop the logging queue listener for the current process <TAB><TAB><TAB>  # We'll restart it once forked <TAB><TAB><TAB>  log . shutdown_multiprocessing_logging_listener ( daemonizing = True ) <TAB><TAB>  # Late import so logging works correctly <TAB><TAB>  salt . utils . process . daemonize ( ) <TAB>  # Setup the multiprocessing log queue listener if enabled <TAB>  self . _setup_mp_logging_listener ( ) ,if self . _setup_mp_logging_listener_ is True :,if self.options.daemon:,False,64.86479549765444,91.65555674488178
3497,"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB>  """"""iterate over all modules"""""" <TAB>  clients = None <TAB>  if by_clients : <TAB><TAB>  clients = self . get_clients ( clients_filter ) <TAB><TAB>  if not clients : <TAB><TAB><TAB>  return <TAB>  self . _refresh_modules ( ) <TAB>  for module_name in self . modules : <TAB><TAB>  try : <TAB><TAB><TAB>  module = self . get_module ( module_name ) <TAB><TAB>  except PupyModuleDisabled : <TAB><TAB><TAB>  continue <TAB><TAB>  if clients is not None : <TAB><TAB><TAB>  for client in clients : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  yield module <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  yield module ",if module . is_compatible_with ( client ) :,if client.module == module:,False,50.80582571798089,95.79814442431655
3498,"def _incremental_avg_dp ( self , avg , new_el , idx ) : <TAB>  for attr in [ "" coarse_segm "" , "" fine_segm "" , "" u "" , "" v "" ] : <TAB><TAB>  setattr ( <TAB><TAB><TAB>  avg , attr , ( getattr ( avg , attr ) * idx + getattr ( new_el , attr ) ) / ( idx + 1 ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Deletion of the > 0 index intermediary values to prevent GPU OOM <TAB><TAB><TAB>  setattr ( new_el , attr , None ) <TAB>  return avg ",if idx :,if avg > 0:,False,59.55197179114591,97.09797067861027
3499,"def run ( self , paths = [ ] ) : <TAB>  collapsed = False <TAB>  for item in SideBarSelection ( paths ) . getSelectedDirectories ( ) : <TAB><TAB>  for view in item . views ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  Window ( ) . focus_view ( view ) <TAB><TAB><TAB><TAB>  self . collapse_sidebar_folder ( ) <TAB><TAB><TAB><TAB>  collapsed = True <TAB><TAB><TAB>  view . close ( ) ",if not collapsed :,if view.isChecked():,False,47.09790128741582,95.11967402804041
3500,"def test_reductions ( expr , rdd ) : <TAB>  result = compute ( expr , rdd ) <TAB>  expected = compute ( expr , data ) <TAB>  if not result == expected : <TAB><TAB>  print ( result ) <TAB><TAB>  print ( expected ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert abs ( result - expected ) < 0.001 <TAB><TAB>  else : <TAB><TAB><TAB>  assert result == expected ","if isinstance ( result , float ) :",if abs(result - expected) < 0.001:,False,54.83605052309532,92.66273442444259
3501,"def deltask ( task , d ) : <TAB>  if task [ : 3 ] != "" do_ "" : <TAB><TAB>  task = "" do_ "" + task <TAB>  bbtasks = d . getVar ( "" __BBTASKS "" , False ) or [ ] <TAB>  if task in bbtasks : <TAB><TAB>  bbtasks . remove ( task ) <TAB><TAB>  d . delVarFlag ( task , "" task "" ) <TAB><TAB>  d . setVar ( "" __BBTASKS "" , bbtasks ) <TAB>  d . delVarFlag ( task , "" deps "" ) <TAB>  for bbtask in d . getVar ( "" __BBTASKS "" , False ) or [ ] : <TAB><TAB>  deps = d . getVarFlag ( bbtask , "" deps "" , False ) or [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  deps . remove ( task ) <TAB><TAB><TAB>  d . setVarFlag ( bbtask , "" deps "" , deps ) ",if task in deps :,if task in deps:,False,50.7731147360161,100.00000000000004
3502,"def _apply_weightnorm ( self , list_layers ) : <TAB>  """"""Try apply weightnorm for all layer in list_layers."""""" <TAB>  for i in range ( len ( list_layers ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  layer_name = list_layers [ i ] . name . lower ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  list_layers [ i ] = WeightNormalization ( list_layers [ i ] ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  pass ","if ""conv1d"" in layer_name or ""dense"" in layer_name :",if layer_name == 'weightnorm':,False,28.20559726052728,90.09401367810948
3503,"def __init__ ( self , execution_context , aggregate_operators ) : <TAB>  super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB>  self . _local_aggregators = [ ] <TAB>  self . _results = None <TAB>  self . _result_index = 0 <TAB>  for operator in aggregate_operators : <TAB><TAB>  if operator == "" Average "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB><TAB>  elif operator == "" Count "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB><TAB>  elif operator == "" Min "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB><TAB>  elif operator == "" Sum "" : <TAB><TAB><TAB>  self . _local_aggregators . append ( _SumAggregator ( ) ) ","elif operator == ""Max"" :","if operator == ""Max"":",False,26.117769787880146,99.05209761565798
3504,"def _conv_layer ( self , sess , bottom , name , trainable = True , padding = "" SAME "" , relu = True ) : <TAB>  with tf . variable_scope ( name ) as scope : <TAB><TAB>  filt = self . _get_conv_filter ( sess , name , trainable = trainable ) <TAB><TAB>  conv_biases = self . _get_bias ( sess , name , trainable = trainable ) <TAB><TAB>  conv = tf . nn . conv2d ( bottom , filt , [ 1 , 1 , 1 , 1 ] , padding = padding ) <TAB><TAB>  bias = tf . nn . bias_add ( conv , conv_biases ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bias = tf . nn . relu ( bias ) <TAB><TAB>  return bias ",if relu :,if relu:,False,50.320694929966706,100.00000000000004
3505,"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB>  partners = { }<TAB># type: Dict[AbstractNode, Set[int]] <TAB>  for edge in self . edges : <TAB><TAB>  if edge . is_dangling ( ) : <TAB><TAB><TAB>  raise ValueError ( "" Cannot contract copy tensor with dangling edges "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  partner_node , shared_axis = self . _get_partner ( edge ) <TAB><TAB>  if partner_node not in partners : <TAB><TAB><TAB>  partners [ partner_node ] = set ( ) <TAB><TAB>  partners [ partner_node ] . add ( shared_axis ) <TAB>  return partners ",if self . _is_my_trace ( edge ) :,if edge.is_chef():,False,15.55352837508236,93.99098563211926
3506,"def close ( self ) : <TAB>  with self . _lock : <TAB><TAB>  """"""Close this _MultiFileWatcher object forever."""""" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _folder_handlers = { } <TAB><TAB><TAB>  LOGGER . debug ( <TAB><TAB><TAB><TAB>  "" Stopping observer thread even though there is a non-zero  "" <TAB><TAB><TAB><TAB>  "" number of event observers! "" <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  LOGGER . debug ( "" Stopping observer thread "" ) <TAB><TAB>  self . _observer . stop ( ) <TAB><TAB>  self . _observer . join ( timeout = 5 ) ",if len ( self . _folder_handlers ) != 0 :,if self._folder_handlers is None:,False,52.7929950521539,95.32959720372489
3507,"def comboSelectionChanged ( self , index ) : <TAB>  text = self . comboBox . cb . itemText ( index ) <TAB>  for i in range ( self . labelList . count ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . labelList . item ( i ) . setCheckState ( 2 ) <TAB><TAB>  elif text != self . labelList . item ( i ) . text ( ) : <TAB><TAB><TAB>  self . labelList . item ( i ) . setCheckState ( 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . labelList . item ( i ) . setCheckState ( 2 ) ","if text == """" :",if text == self.labelList.item(i).text():,False,49.717201443503335,91.47404631295852
3508,"def _get_messages ( self ) : <TAB>  r = [ ] <TAB>  try : <TAB><TAB>  self . _connect ( ) <TAB><TAB>  self . _login ( ) <TAB><TAB>  for message in self . _fetch ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  r . append ( message ) <TAB><TAB>  self . _connection . expunge ( ) <TAB><TAB>  self . _connection . close ( ) <TAB><TAB>  self . _connection . logout ( ) <TAB>  except MailFetcherError as e : <TAB><TAB>  self . log ( "" error "" , str ( e ) ) <TAB>  return r ",if message :,if message.message_type == MailerType.MESSAGE:,False,50.21143674513391,93.9060688117667
3509,"def get_current_user ( self ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return config . get ( "" json_authentication_override "" ) <TAB><TAB>  tkn_header = self . request . headers [ "" authorization "" ] <TAB>  except KeyError : <TAB><TAB>  raise WebAuthNError ( reason = "" Missing Authorization Header "" ) <TAB>  else : <TAB><TAB>  tkn_str = tkn_header . split ( "" "" ) [ - 1 ] <TAB>  try : <TAB><TAB>  tkn = self . jwt_validator ( tkn_str ) <TAB>  except AuthenticationError as e : <TAB><TAB>  raise WebAuthNError ( reason = e . message ) <TAB>  else : <TAB><TAB>  return tkn ","if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :",if config.get('json_authentication_override'):,False,28.93477219489734,90.32184026674325
3510,def _get_data ( self ) : <TAB>  formdata = self . _formdata <TAB>  if formdata : <TAB><TAB>  data = [ ] <TAB><TAB>  # TODO: Optimize? <TAB><TAB>  for item in formdata : <TAB><TAB><TAB>  model = self . loader . get_one ( item ) if item else None <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data . append ( model ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _invalid_formdata = True <TAB><TAB>  self . _set_data ( data ) <TAB>  return self . _data ,if model :,if model:,False,52.243618899792146,100.00000000000004
3511,"def _getSubstrings ( self , va , size , ltyp ) : <TAB>  # rip through the desired memory range to populate any substrings <TAB>  subs = set ( ) <TAB>  end = va + size <TAB>  for offs in range ( va , end , 1 ) : <TAB><TAB>  loc = self . getLocation ( offs , range = True ) <TAB><TAB>  if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va : <TAB><TAB><TAB>  subs . add ( ( loc [ L_VA ] , loc [ L_SIZE ] ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  subs = subs . union ( set ( loc [ L_TINFO ] ) ) <TAB>  return list ( subs ) ",if loc [ L_TINFO ] :,if loc and loc[L_LTYPE] == L_TINFO:,False,36.02923508187838,94.68507384983849
3512,def monad ( self ) : <TAB>  if not self . cls_bl_idname : <TAB><TAB>  return None <TAB>  for monad in bpy . data . node_groups : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if monad . cls_bl_idname == self . cls_bl_idname : <TAB><TAB><TAB><TAB>  return monad <TAB>  return None ,"if hasattr ( monad , ""cls_bl_idname"" ) :",if monad.type == 'monad':,False,23.072580213849943,87.33756147028126
3513,"def _set_peer_statuses ( self ) : <TAB>  """"""Set peer statuses."""""" <TAB>  cutoff = time . time ( ) - STALE_SECS <TAB>  for peer in self . peers : <TAB><TAB>  if peer . bad : <TAB><TAB><TAB>  peer . status = PEER_BAD <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  peer . status = PEER_GOOD <TAB><TAB>  elif peer . last_good : <TAB><TAB><TAB>  peer . status = PEER_STALE <TAB><TAB>  else : <TAB><TAB><TAB>  peer . status = PEER_NEVER ",elif peer . last_good > cutoff :,if peer.good:,False,27.88574277261322,94.57358894117039
3514,"def title_by_index ( self , trans , index , context ) : <TAB>  d_type = self . get_datatype ( trans , context ) <TAB>  for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB><TAB>  if i == index : <TAB><TAB><TAB>  rval = composite_name <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB><TAB><TAB>  if composite_file . optional : <TAB><TAB><TAB><TAB>  rval = "" %s  [optional] "" % rval <TAB><TAB><TAB>  return rval <TAB>  if index < self . get_file_count ( trans , context ) : <TAB><TAB>  return "" Extra primary file "" <TAB>  return None ",if composite_file . description :,if composite_file.description:,False,50.69393699710005,100.00000000000004
3515,"def testUiViewServerDump_windowIntM1 ( self ) : <TAB>  device = None <TAB>  try : <TAB><TAB>  device = MockDevice ( version = 15 , startviewserver = True ) <TAB><TAB>  vc = ViewClient ( device , device . serialno , adb = TRUE , autodump = False ) <TAB><TAB>  vc . dump ( window = - 1 ) <TAB><TAB>  vc . findViewByIdOrRaise ( "" id/home "" ) <TAB>  finally : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  device . shutdownMockViewServer ( ) ",if device :,if device is not None:,False,48.93762846170039,93.37878148415713
3516,"def _convertDict ( self , d ) : <TAB>  r = { } <TAB>  for k , v in d . items ( ) : <TAB><TAB>  if isinstance ( v , bytes ) : <TAB><TAB><TAB>  v = str ( v , "" utf-8 "" ) <TAB><TAB>  elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB><TAB><TAB>  v = self . _convertList ( v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = self . _convertDict ( v ) <TAB><TAB>  if isinstance ( k , bytes ) : <TAB><TAB><TAB>  k = str ( k , "" utf-8 "" ) <TAB><TAB>  r [ k ] = v <TAB>  return r ","elif isinstance ( v , dict ) :","if isinstance(v, dict):",False,41.95069687736216,98.62437671704521
3517,"def _testSendmsgTimeout ( self ) : <TAB>  try : <TAB><TAB>  self . cli_sock . settimeout ( 0.03 ) <TAB><TAB>  try : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  self . sendmsgToServer ( [ b "" a "" * 512 ] ) <TAB><TAB>  except socket . timeout : <TAB><TAB><TAB>  pass <TAB><TAB>  except OSError as exc : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  # bpo-33937 the test randomly fails on Travis CI with <TAB><TAB><TAB>  # ""OSError: [Errno 12] Cannot allocate memory"" <TAB><TAB>  else : <TAB><TAB><TAB>  self . fail ( "" socket.timeout not raised "" ) <TAB>  finally : <TAB><TAB>  self . misc_event . set ( ) ",if exc . errno != errno . ENOMEM :,if exc.errno == errno.ENOMEM:,False,55.26686884501429,98.88262404605162
3518,"def addError ( self , test , err ) : <TAB>  if err [ 0 ] is SkipTest : <TAB><TAB>  if self . showAll : <TAB><TAB><TAB>  self . stream . writeln ( str ( err [ 1 ] ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . stream . write ( "" s "" ) <TAB><TAB><TAB>  self . stream . flush ( ) <TAB><TAB>  return <TAB>  _org_AddError ( self , test , err ) ",elif self . dots :,if self.showAll:,False,25.804952952485337,96.02938407512607
3519,"def mouse_down ( self , event ) : <TAB>  if event . button == 1 : <TAB><TAB>  if self . scrolling : <TAB><TAB><TAB>  p = event . local <TAB><TAB><TAB>  if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB>  self . scroll_up ( ) <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . scroll_down ( ) <TAB><TAB><TAB><TAB>  return <TAB>  if event . button == 4 : <TAB><TAB>  self . scroll_up ( ) <TAB>  if event . button == 5 : <TAB><TAB>  self . scroll_down ( ) <TAB>  GridView . mouse_down ( self , event ) ",elif self . scroll_down_rect ( ) . collidepoint ( p ) :,if event.button == 2:,False,24.875293747614847,92.55068470071731
3520,"def find_file_copyright_notices ( fname ) : <TAB>  ret = set ( ) <TAB>  f = open ( fname ) <TAB>  lines = f . readlines ( ) <TAB>  for l in lines [ : 80 ] :<TAB># hmmm, assume copyright to be in first 80 lines <TAB><TAB>  idx = l . lower ( ) . find ( "" copyright "" ) <TAB><TAB>  if idx < 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  copyright = l [ idx + 9 : ] . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  copyright = sanitise ( copyright ) <TAB><TAB>  # hmm, do a quick check to see if there's a year, <TAB><TAB>  # if not, skip it <TAB><TAB>  if not copyright . find ( "" 200 "" ) > = 0 and not copyright . find ( "" 199 "" ) > = 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  ret . add ( copyright ) <TAB>  return ret ",if not copyright :,if copyright == '':,False,60.06916734865852,96.0817262150346
3521,"def get_selectable_values ( self , request ) : <TAB>  shop = lfs . core . utils . get_default_shop ( request ) <TAB>  countries = [ ] <TAB>  for country in shop . shipping_countries . all ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  selected = True <TAB><TAB>  else : <TAB><TAB><TAB>  selected = False <TAB><TAB>  countries . append ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" id "" : country . id , <TAB><TAB><TAB><TAB>  "" name "" : country . name , <TAB><TAB><TAB><TAB>  "" selected "" : selected , <TAB><TAB><TAB>  } <TAB><TAB>  ) <TAB>  return countries ",if country in self . value . all ( ) :,if country.id == 0 and country.name == 0:,False,26.893028506463224,93.66434017950903
3522,"def _addItemToLayout ( self , sample , label ) : <TAB>  col = self . layout . columnCount ( ) <TAB>  row = self . layout . rowCount ( ) <TAB>  if row : <TAB><TAB>  row - = 1 <TAB>  nCol = self . columnCount * 2 <TAB>  # FIRST ROW FULL <TAB>  if col == nCol : <TAB><TAB>  for col in range ( 0 , nCol , 2 ) : <TAB><TAB><TAB>  # FIND RIGHT COLUMN <TAB><TAB><TAB>  if not self . layout . itemAt ( row , col ) : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # MAKE NEW ROW <TAB><TAB><TAB>  col = 0 <TAB><TAB><TAB>  row + = 1 <TAB>  self . layout . addItem ( sample , row , col ) <TAB>  self . layout . addItem ( label , row , col + 1 ) ",if col + 2 == nCol :,if col == nCol:,False,45.016023527304014,98.44608584519685
3523,def contains_only_whitespace ( node ) : <TAB>  if is_tag ( node ) : <TAB><TAB>  if not any ( [ not is_text ( s ) for s in node . contents ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,if is_whitespace(node):,False,19.44052912469051,78.44106668550258
3524,"def tokenize_generator ( cw ) : <TAB>  ret = [ ] <TAB>  done = { } <TAB>  for op in ops : <TAB><TAB>  ch = op . symbol [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  sops = start_symbols [ ch ] <TAB><TAB>  cw . write ( "" case  ' %s ' : "" % ch ) <TAB><TAB>  for t in gen_tests ( sops , 1 ) : <TAB><TAB><TAB>  cw . write ( t ) <TAB><TAB>  done [ ch ] = True <TAB>  return ret ",if ch in done :,if ch in start_symbols:,False,38.97233784187012,94.66076083818315
3525,"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB>  nbMinBit = None <TAB>  nbMaxBit = None <TAB>  if nbChars is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  nbMinBit = nbChars * 8 <TAB><TAB><TAB>  nbMaxBit = nbMinBit <TAB><TAB>  else : <TAB><TAB><TAB>  if nbChars [ 0 ] is not None : <TAB><TAB><TAB><TAB>  nbMinBit = nbChars [ 0 ] * 8 <TAB><TAB><TAB>  if nbChars [ 1 ] is not None : <TAB><TAB><TAB><TAB>  nbMaxBit = nbChars [ 1 ] * 8 <TAB>  return ( nbMinBit , nbMaxBit ) ","if isinstance ( nbChars , int ) :",if nbChars[0] is not None:,False,39.49077127411512,94.9120174921946
3526,"def init ( self , * args , * * kwargs ) : <TAB>  if "" _state "" not in kwargs : <TAB><TAB>  state = { } <TAB><TAB>  # Older versions have the _state entries as individual kwargs <TAB><TAB>  for arg in ( "" children "" , "" windowState "" , "" detachedPanels "" ) : <TAB><TAB><TAB>  if arg in kwargs : <TAB><TAB><TAB><TAB>  state [ arg ] = kwargs [ arg ] <TAB><TAB><TAB><TAB>  del kwargs [ arg ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs [ "" _state "" ] = state <TAB>  originalInit ( self , * args , * * kwargs ) ",if state :,if state:,False,52.825338666737885,100.00000000000004
3527,"def spm_decode ( tokens : List [ str ] ) - > List [ str ] : <TAB>  words = [ ] <TAB>  pieces : List [ str ] = [ ] <TAB>  for t in tokens : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if len ( pieces ) > 0 : <TAB><TAB><TAB><TAB>  words . append ( "" "" . join ( pieces ) ) <TAB><TAB><TAB>  pieces = [ t [ 1 : ] ] <TAB><TAB>  else : <TAB><TAB><TAB>  pieces . append ( t ) <TAB>  if len ( pieces ) > 0 : <TAB><TAB>  words . append ( "" "" . join ( pieces ) ) <TAB>  return words ",if t [ 0 ] == DecodeMixin . spm_bos_token :,if t.startswith(' '):,False,48.82095834701171,92.66457475944038
3528,"def _compare_dirs ( self , dir1 : str , dir2 : str ) - > List [ str ] : <TAB>  # check that dir1 and dir2 are equivalent, <TAB>  # return the diff <TAB>  diff = [ ]<TAB># type: List[str] <TAB>  for root , dirs , files in os . walk ( dir1 ) : <TAB><TAB>  for file_ in files : <TAB><TAB><TAB>  path = os . path . join ( root , file_ ) <TAB><TAB><TAB>  target_path = os . path . join ( dir2 , os . path . split ( path ) [ - 1 ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  diff . append ( file_ ) <TAB>  return diff ",if not os . path . exists ( target_path ) :,if os.path.exists(target_path):,False,45.99682946127375,94.90504723370722
3529,"def credentials ( self ) : <TAB>  """"""The session credentials as a dict"""""" <TAB>  creds = { } <TAB>  if self . _creds : <TAB><TAB>  <IF-STMT>:<TAB># pragma: no branch <TAB><TAB><TAB>  creds [ "" aws_access_key_id "" ] = self . _creds . access_key <TAB><TAB>  if self . _creds . secret_key :<TAB># pragma: no branch <TAB><TAB><TAB>  creds [ "" aws_secret_access_key "" ] = self . _creds . secret_key <TAB><TAB>  if self . _creds . token : <TAB><TAB><TAB>  creds [ "" aws_session_token "" ] = self . _creds . token <TAB>  if self . _session . region_name : <TAB><TAB>  creds [ "" aws_region "" ] = self . _session . region_name <TAB>  if self . requester_pays : <TAB><TAB>  creds [ "" aws_request_payer "" ] = "" requester "" <TAB>  return creds ",if self . _creds . access_key :,if self._creds.access_key:,False,51.48764325585064,96.4555811065447
3530,"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB>  for a in self . arbiters : <TAB><TAB>  # Do like the linkify will do after.... <TAB><TAB>  for m in getattr ( a , "" modules "" , [ ] ) : <TAB><TAB><TAB>  # So look at what the arbiter try to call as module <TAB><TAB><TAB>  m = m . strip ( ) <TAB><TAB><TAB>  # Ok, now look in modules... <TAB><TAB><TAB>  for mod in self . modules : <TAB><TAB><TAB><TAB>  # try to see if this module is the good type <TAB><TAB><TAB><TAB>  if getattr ( mod , "" module_type "" , "" "" ) . strip ( ) == mod_type . strip ( ) : <TAB><TAB><TAB><TAB><TAB>  # if so, the good name? <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if getattr ( mod , ""module_name"" , """" ) . strip ( ) == m :",if m == mod_type:,False,66.4388566095288,92.89108501832894
3531,"def find_file_at_path_with_indexes ( self , path , url ) : <TAB>  if url . endswith ( "" / "" ) : <TAB><TAB>  path = os . path . join ( path , self . index_file ) <TAB><TAB>  return self . get_static_file ( path , url ) <TAB>  elif url . endswith ( "" / "" + self . index_file ) : <TAB><TAB>  if os . path . isfile ( path ) : <TAB><TAB><TAB>  return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  return self . get_static_file ( path , url ) <TAB><TAB>  except IsDirectoryError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return self . redirect ( url , url + "" / "" ) <TAB>  raise MissingFileError ( path ) ","if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",if os.path.isdir(path):,False,49.23166195989547,92.05706725692716
3532,def _use_full_params ( self ) - > None : <TAB>  for p in self . params : <TAB><TAB>  if not p . _is_sharded : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  assert p . _fp16_shard . storage ( ) . size ( ) != 0 <TAB><TAB><TAB><TAB>  p . data = p . _fp16_shard <TAB><TAB>  else : <TAB><TAB><TAB>  assert p . _full_param_padded . storage ( ) . size ( ) != 0 <TAB><TAB><TAB>  p . data = p . _full_param_padded [ : p . _orig_size . numel ( ) ] . view ( p . _orig_size ) ,if self . mixed_precision :,if p._fp16_shard:,False,46.50757458881204,96.25550993077525
3533,"def _attrdata ( self , cont , name , * val ) : <TAB>  if not name : <TAB><TAB>  return None , False <TAB>  if isinstance ( name , Mapping ) : <TAB><TAB>  if val : <TAB><TAB><TAB>  raise TypeError ( "" Cannot set a value to  %s "" % name ) <TAB><TAB>  return name , True <TAB>  else : <TAB><TAB>  if val : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return { name : val [ 0 ] } , True <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise TypeError ( "" Too may arguments "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  cont = self . _extra . get ( cont ) <TAB><TAB><TAB>  return cont . get ( name ) if cont else None , False ",if len ( val ) == 1 :,if len(val) == 1:,False,53.788934082716075,100.00000000000004
3534,"def evaluate ( env , net , device = "" cpu "" ) : <TAB>  obs = env . reset ( ) <TAB>  reward = 0.0 <TAB>  steps = 0 <TAB>  while True : <TAB><TAB>  obs_v = ptan . agent . default_states_preprocessor ( [ obs ] ) . to ( device ) <TAB><TAB>  action_v = net ( obs_v ) <TAB><TAB>  action = action_v . data . cpu ( ) . numpy ( ) [ 0 ] <TAB><TAB>  obs , r , done , _ = env . step ( action ) <TAB><TAB>  reward + = r <TAB><TAB>  steps + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return reward , steps ",if done :,if done:,False,24.104343788272153,100.00000000000004
3535,"def convert_html_js_files ( app : Sphinx , config : Config ) - > None : <TAB>  """"""This converts string styled html_js_files to tuple styled one."""""" <TAB>  html_js_files = [ ]<TAB># type: List[Tuple[str, Dict]] <TAB>  for entry in config . html_js_files : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  html_js_files . append ( ( entry , { } ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  filename , attrs = entry <TAB><TAB><TAB><TAB>  html_js_files . append ( ( filename , attrs ) ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  logger . warning ( __ ( "" invalid js_file:  %r , ignored "" ) , entry ) <TAB><TAB><TAB><TAB>  continue <TAB>  config . html_js_files = html_js_files<TAB># type: ignore ","if isinstance ( entry , str ) :","if isinstance(entry, tuple):",False,21.81201881233316,95.6380821053019
3536,"def _check_duplications ( self , regs ) : <TAB>  """"""n^2 loop which verifies that each reg exists only once."""""" <TAB>  for reg in regs : <TAB><TAB>  count = 0 <TAB><TAB>  for r in regs : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  count + = 1 <TAB><TAB>  if count > 1 : <TAB><TAB><TAB>  genutil . die ( "" reg  %s  defined more than once "" % reg ) ",if reg == r :,if r.startswith(reg):,False,56.250591159687424,94.52827200598014
3537,"def PyJsHoisted_vault_ ( key , forget , this , arguments , var = var ) : <TAB>  var = Scope ( <TAB><TAB>  { u "" this "" : this , u "" forget "" : forget , u "" key "" : key , u "" arguments "" : arguments } , var <TAB>  ) <TAB>  var . registers ( [ u "" forget "" , u "" key "" ] ) <TAB>  if PyJsStrictEq ( var . get ( u "" key "" ) , var . get ( u "" passkey "" ) ) : <TAB><TAB>  return ( <TAB><TAB><TAB>  var . put ( u "" secret "" , var . get ( u "" null "" ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else ( <TAB><TAB><TAB><TAB>  var . get ( u "" secret "" ) <TAB><TAB><TAB><TAB>  or var . put ( u "" secret "" , var . get ( u "" secretCreatorFn "" ) ( var . get ( u "" object "" ) ) ) <TAB><TAB><TAB>  ) <TAB><TAB>  ) ","if var . get ( u""forget"" )","if not var.get(u""key') or not var.get(u""key",False,41.88895101877691,94.56811397531973
3538,"def sort_nested_dictionary_lists ( d ) : <TAB>  for k , v in d . items ( ) : <TAB><TAB>  if isinstance ( v , list ) : <TAB><TAB><TAB>  for i in range ( 0 , len ( v ) ) : <TAB><TAB><TAB><TAB>  if isinstance ( v [ i ] , dict ) : <TAB><TAB><TAB><TAB><TAB>  v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB><TAB><TAB><TAB>  d [ k ] = sorted ( v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB>  return d ","if isinstance ( v , dict ) :","if isinstance(v, dict):",False,51.20059430157067,100.00000000000004
3539,"def transceiver ( self , data ) : <TAB>  out = [ ] <TAB>  for t in range ( 8 ) : <TAB><TAB>  if data [ t ] == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  value = data [ t ] <TAB><TAB>  for b in range ( 8 ) : <TAB><TAB><TAB>  if value & 0x80 : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  out . append ( "" (unknown) "" ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB><TAB><TAB>  value << = 1 <TAB>  self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) ) ",if len ( TRANSCEIVER [ t ] ) < b + 1 :,if b == 0:,False,47.775823315404395,94.27991264389698
3540,"def process_string ( self , remove_repetitions , sequence ) : <TAB>  string = "" "" <TAB>  for i , char in enumerate ( sequence ) : <TAB><TAB>  if char != self . int_to_char [ self . blank_index ] : <TAB><TAB><TAB>  # if this char is a repetition and remove_repetitions=true, <TAB><TAB><TAB>  # skip. <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  elif char == self . labels [ self . space_index ] : <TAB><TAB><TAB><TAB>  string + = "" "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  string = string + char <TAB>  return string ",if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,if i == len(self.labels):,False,57.921758086725525,91.05474689651376
3541,"def clean ( self ) : <TAB>  username = self . cleaned_data . get ( "" username "" ) <TAB>  password = self . cleaned_data . get ( "" password "" ) <TAB>  if username and password : <TAB><TAB>  self . user_cache = authenticate ( username = username , password = password ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise forms . ValidationError ( self . error_messages [ "" invalid_login "" ] ) <TAB><TAB>  elif not self . user_cache . is_active : <TAB><TAB><TAB>  raise forms . ValidationError ( self . error_messages [ "" inactive "" ] ) <TAB>  self . check_for_test_cookie ( ) <TAB>  return self . cleaned_data ",if self . user_cache is None :,if not self.user_cache:,False,21.545743351870527,97.15364340838322
3542,"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB>  """"""Check if the conversation is in need for a user message."""""" <TAB>  tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB>  for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB><TAB>  if e . get ( "" event "" ) == UserUttered . type_name : <TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB>  return False ","elif e . get ( ""event"" ) == ActionExecuted . type_name :",if i == 0:,False,57.96910670731219,90.30261216206308
3543,"def getReferences ( view , name = "" "" ) : <TAB>  """"""Find all reference definitions."""""" <TAB>  # returns {name -> Region} <TAB>  refs = [ ] <TAB>  name = re . escape ( name ) <TAB>  if name == "" "" : <TAB><TAB>  refs . extend ( view . find_all ( r "" (?<=^ \ [)([^ \ ]]+)(?= \ ]:) "" , 0 ) ) <TAB>  else : <TAB><TAB>  refs . extend ( view . find_all ( r "" (?<=^ \ [)( %s )(?= \ ]:) "" % name , 0 ) ) <TAB>  regions = refs <TAB>  ids = { } <TAB>  for reg in regions : <TAB><TAB>  name = view . substr ( reg ) . strip ( ) <TAB><TAB>  key = name . lower ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ids [ key ] . regions . append ( reg ) <TAB><TAB>  else : <TAB><TAB><TAB>  ids [ key ] = Obj ( regions = [ reg ] , label = name ) <TAB>  return ids ",if key in ids :,if key in ids:,False,51.593544014530494,100.00000000000004
3544,"def _get_header ( self , requester , header_name ) : <TAB>  hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB>  self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB>  for url , headers in requester . requests : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . revs_enabled : <TAB><TAB><TAB><TAB>  self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB><TAB><TAB>  return headers . get ( header_name ) ",if header_name in headers :,if self.is_latest_header(url):,False,51.04023637773021,94.27483938627866
3545,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_shuffle_name ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 0:,False,46.452429171598006,97.78225290627776
3546,"def make_release_tree ( self , base_dir , files ) : <TAB>  """"""Make the release tree."""""" <TAB>  self . mkpath ( base_dir ) <TAB>  create_tree ( base_dir , files , dry_run = self . dry_run ) <TAB>  if not files : <TAB><TAB>  self . log . warning ( "" no files to distribute -- empty manifest? "" ) <TAB>  else : <TAB><TAB>  self . log . info ( "" copying files to  %s ... "" , base_dir ) <TAB>  for filename in files : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log . warning ( "" ' %s '  not a regular file -- skipping "" , filename ) <TAB><TAB>  else : <TAB><TAB><TAB>  dest = os . path . join ( base_dir , filename ) <TAB><TAB><TAB>  self . copy_file ( filename , dest ) <TAB>  self . distribution . metadata . write_pkg_info ( base_dir ) ",if not os . path . isfile ( filename ) :,if filename.startswith('.py') or filename.startswith('.py') or,False,54.79940429346208,91.4989598356713
3547,"def _parse_names_set ( feature_names ) : <TAB>  """"""Helping function of `_parse_feature_names` that parses a set of feature names."""""" <TAB>  feature_collection = OrderedDict ( ) <TAB>  for feature_name in feature_names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  feature_collection [ feature_name ] = . . . <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" Failed to parse  {} , expected string "" . format ( feature_name ) ) <TAB>  return feature_collection ","if isinstance ( feature_name , str ) :","if isinstance(feature_name, basestring):",False,48.72911702778157,98.24846426725743
3548,"def get_connection ( self , url , proxies = None ) : <TAB>  with self . pools . lock : <TAB><TAB>  pool = self . pools . get ( url ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return pool <TAB><TAB>  pool = NpipeHTTPConnectionPool ( <TAB><TAB><TAB>  self . npipe_path , self . timeout , maxsize = self . max_pool_size <TAB><TAB>  ) <TAB><TAB>  self . pools [ url ] = pool <TAB>  return pool ",if pool :,if pool is not None:,False,43.39159576973065,96.40170192701808
3549,"def _parse_dimensions ( dimensions ) : <TAB>  arrays = [ ] <TAB>  names = [ ] <TAB>  for key in dimensions : <TAB><TAB>  values = [ v [ "" name "" ] for v in key [ "" values "" ] ] <TAB><TAB>  role = key . get ( "" role "" , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values = [ _fix_quarter_values ( v ) for v in values ] <TAB><TAB><TAB>  values = pd . DatetimeIndex ( values ) <TAB><TAB>  arrays . append ( values ) <TAB><TAB>  names . append ( key [ "" name "" ] ) <TAB>  midx = pd . MultiIndex . from_product ( arrays , names = names ) <TAB>  if len ( arrays ) == 1 and isinstance ( midx , pd . MultiIndex ) : <TAB><TAB>  # Fix for pandas >= 0.21 <TAB><TAB>  midx = midx . levels [ 0 ] <TAB>  return midx ","if role in ( ""time"" , ""TIME_PERIOD"" ) :",if role == 'quarter':,False,53.25508179330525,94.26516682888735
3550,"def _add_trials ( self , name , spec ) : <TAB>  """"""Add trial by invoking TrialRunner."""""" <TAB>  resource = { } <TAB>  resource [ "" trials "" ] = [ ] <TAB>  trial_generator = BasicVariantGenerator ( ) <TAB>  trial_generator . add_configurations ( { name : spec } ) <TAB>  while not trial_generator . is_finished ( ) : <TAB><TAB>  trial = trial_generator . next_trial ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  runner . add_trial ( trial ) <TAB><TAB>  resource [ "" trials "" ] . append ( self . _trial_info ( trial ) ) <TAB>  return resource ",if not trial :,if not trial:,False,51.91973683970383,100.00000000000004
3551,"def _retrieve_key ( self ) : <TAB>  url = "" http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf "" <TAB>  text = "" "" <TAB>  try : <TAB><TAB>  r = requests . get ( url , timeout = self . timeout , proxies = self . proxies ) <TAB><TAB>  text = r . text <TAB>  except : <TAB><TAB>  self . error = "" ERROR - URL Connection "" <TAB>  if text : <TAB><TAB>  expression = r "" ' (....-....-....-....) ' ; "" <TAB><TAB>  pattern = re . compile ( expression ) <TAB><TAB>  match = pattern . search ( text ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . key = match . group ( 1 ) <TAB><TAB><TAB>  return self . key <TAB><TAB>  else : <TAB><TAB><TAB>  self . error = "" ERROR - No API Key "" ",if match :,if match:,False,17.595487296698554,100.00000000000004
3552,"def test_net ( net , env , count = 10 , device = "" cpu "" ) : <TAB>  rewards = 0.0 <TAB>  steps = 0 <TAB>  for _ in range ( count ) : <TAB><TAB>  obs = env . reset ( ) <TAB><TAB>  while True : <TAB><TAB><TAB>  obs_v = ptan . agent . float32_preprocessor ( [ obs ] ) . to ( device ) <TAB><TAB><TAB>  mu_v = net ( obs_v ) [ 0 ] <TAB><TAB><TAB>  action = mu_v . squeeze ( dim = 0 ) . data . cpu ( ) . numpy ( ) <TAB><TAB><TAB>  action = np . clip ( action , - 1 , 1 ) <TAB><TAB><TAB>  obs , reward , done , _ = env . step ( action ) <TAB><TAB><TAB>  rewards + = reward <TAB><TAB><TAB>  steps + = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB>  return rewards / count , steps / count ",if done :,if rewards > 100.0:,False,21.954900757659303,96.86091576112908
3553,"def compile ( self , filename , obfuscate = False , raw = False , magic = "" \x00 "" * 8 ) : <TAB>  body = marshal . dumps ( compile ( self . visit ( self . _source_ast ) , filename , "" exec "" ) ) <TAB>  if obfuscate : <TAB><TAB>  body_len = len ( body ) <TAB><TAB>  offset = 0 if raw else 8 <TAB><TAB>  output = bytearray ( body_len + 8 ) <TAB><TAB>  for i , x in enumerate ( body ) : <TAB><TAB><TAB>  output [ i + offset ] = ord ( x ) ^ ( ( 2 * * ( ( 65535 - i ) % 65535 ) ) % 251 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for i in xrange ( 8 ) : <TAB><TAB><TAB><TAB>  output [ i ] = 0 <TAB><TAB>  return output <TAB>  el<IF-STMT>: <TAB><TAB>  return body <TAB>  else : <TAB><TAB>  return magic + body ",if raw :,if offset == 0:,False,27.048266138320027,95.47361567361396
3554,"def _map_saslprep ( s ) : <TAB>  """"""Map stringprep table B.1 to nothing and C.1.2 to ASCII space"""""" <TAB>  r = [ ] <TAB>  for c in s : <TAB><TAB>  if stringprep . in_table_c12 ( c ) : <TAB><TAB><TAB>  r . append ( "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r . append ( c ) <TAB>  return "" "" . join ( r ) ",elif not stringprep . in_table_b1 ( c ) :,if stringprep.in_table_b12(c):,False,60.46738355859935,95.19148578359042
3555,"def ensemble ( self , pairs , other_preds ) : <TAB>  """"""Ensemble the dict with statistical model predictions."""""" <TAB>  lemmas = [ ] <TAB>  assert len ( pairs ) == len ( other_preds ) <TAB>  for p , pred in zip ( pairs , other_preds ) : <TAB><TAB>  w , pos = p <TAB><TAB>  if ( w , pos ) in self . composite_dict : <TAB><TAB><TAB>  lemma = self . composite_dict [ ( w , pos ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lemma = self . word_dict [ w ] <TAB><TAB>  else : <TAB><TAB><TAB>  lemma = pred <TAB><TAB>  if lemma is None : <TAB><TAB><TAB>  lemma = w <TAB><TAB>  lemmas . append ( lemma ) <TAB>  return lemmas ",elif w in self . word_dict :,if pred is None:,False,29.512407297289865,95.56256832692515
3556,"def quiet_f ( * args ) : <TAB>  vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB>  value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB>  if expect_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB><TAB><TAB>  if any ( item is None for item in value ) : <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  return value <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  else : <TAB><TAB>  value = extract_pyreal ( value ) <TAB><TAB>  if value is None or isinf ( value ) or isnan ( value ) : <TAB><TAB><TAB>  return None <TAB><TAB>  return value ","if value . has_form ( ""List"" , None ) :",if expect_list:,False,45.77862731447782,94.27144467194762
3557,"def _copy_package_apps ( <TAB>  local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" ""  ) - > None : <TAB>  for src_unresolved in app_paths : <TAB><TAB>  src = src_unresolved . resolve ( ) <TAB><TAB>  app = src . name <TAB><TAB>  dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB><TAB>  if not dest . parent . is_dir ( ) : <TAB><TAB><TAB>  mkdir ( dest . parent ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB><TAB><TAB>  dest . unlink ( ) <TAB><TAB>  if src . exists ( ) : <TAB><TAB><TAB>  shutil . copy ( src , dest ) ",if dest . exists ( ) :,if dest.exists():,False,23.13903526251023,100.00000000000004
3558,"def assert_readback ( vehicle , values ) : <TAB>  i = 10 <TAB>  while i > 0 : <TAB><TAB>  time . sleep ( 0.1 ) <TAB><TAB>  i - = 0.1 <TAB><TAB>  for k , v in values . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  break <TAB>  if i < = 0 : <TAB><TAB>  raise Exception ( "" Did not match in channels readback  %s "" % values ) ",if vehicle . channels [ k ] != v :,if v == vehicle.readback:,False,22.617160018672347,92.97938615281875
3559,"def _get_linode_client ( self ) : <TAB>  api_key = self . credentials . conf ( "" key "" ) <TAB>  api_version = self . credentials . conf ( "" version "" ) <TAB>  if api_version == "" "" : <TAB><TAB>  api_version = None <TAB>  if not api_version : <TAB><TAB>  api_version = 3 <TAB><TAB>  # Match for v4 api key <TAB><TAB>  regex_v4 = re . compile ( "" ^[0-9a-f] {64} $ "" ) <TAB><TAB>  regex_match = regex_v4 . match ( api_key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  api_version = 4 <TAB>  else : <TAB><TAB>  api_version = int ( api_version ) <TAB>  return _LinodeLexiconClient ( api_key , api_version ) ",if regex_match :,if regex_match:,False,53.82792257188197,100.00000000000004
3560,"def mergeHiLo ( self , x_stats ) : <TAB>  """"""Merge the highs and lows of another accumulator into myself."""""" <TAB>  if x_stats . firsttime is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . firsttime = x_stats . firsttime <TAB><TAB><TAB>  self . first = x_stats . first <TAB>  if x_stats . lasttime is not None : <TAB><TAB>  if self . lasttime is None or x_stats . lasttime > = self . lasttime : <TAB><TAB><TAB>  self . lasttime = x_stats . lasttime <TAB><TAB><TAB>  self . last = x_stats . last ",if self . firsttime is None or x_stats . firsttime < self . firsttime :,if x_stats.firsttime is not None:,False,39.19052337352738,93.01159982989074
3561,"def _check_good_input ( self , X , y = None ) : <TAB>  if isinstance ( X , dict ) : <TAB><TAB>  lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB><TAB>  x_len = lengths [ 0 ] <TAB>  else : <TAB><TAB>  x_len = len ( X ) <TAB>  if y is not None : <TAB><TAB>  if len ( y ) != x_len : <TAB><TAB><TAB>  raise ValueError ( "" X and y are not of equal length. "" ) <TAB>  if self . regression and y is not None and y . ndim == 1 : <TAB><TAB>  y = y . reshape ( - 1 , 1 ) <TAB>  return X , y ",if len ( set ( lengths ) ) > 1 :,if len(lengths) != 1:,False,38.98617864894725,95.9426225120113
3562,"def set ( self , obj , * * kwargs ) : <TAB>  """"""Check for missing event functions and substitute these with"""""" <TAB>  """"""the ignore method"""""" <TAB>  ignore = getattr ( self , "" ignore "" ) <TAB>  for k , v in kwargs . iteritems ( ) : <TAB><TAB>  setattr ( self , k , getattr ( obj , v ) ) <TAB><TAB>  if k in self . combinations : <TAB><TAB><TAB>  for k1 in self . combinations [ k ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  setattr ( self , k1 , ignore ) ","if not hasattr ( self , k1 ) :",if k1 not in ignore:,False,54.04489991809349,95.06197630842755
3563,"def _parse_list ( self , tokens ) : <TAB>  # Process left to right, allow descending in sub lists <TAB>  assert tokens [ 0 ] in ( "" [ "" , "" ( "" ) <TAB>  delim = "" ] "" if tokens . pop ( 0 ) == "" [ "" else "" ) "" <TAB>  expr = ExpressionList ( ) <TAB>  while tokens and tokens [ 0 ] != delim : <TAB><TAB>  item = self . _parse ( tokens ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if tokens . pop ( 0 ) != "" , "" : <TAB><TAB><TAB><TAB>  raise ExpressionSyntaxError ( ' Expected:  "" , "" ' ) <TAB><TAB>  expr . append ( item ) <TAB>  if not tokens or tokens [ 0 ] != delim : <TAB><TAB>  raise ExpressionSyntaxError ( ' Missing:  "" %s "" ' % delim ) <TAB>  else : <TAB><TAB>  tokens . pop ( 0 ) <TAB>  return expr ",if tokens and tokens [ 0 ] != delim :,if item:,False,31.64149337453282,93.2696348565489
3564,"def param_value ( self ) : <TAB>  # This is part of the ""handle quoted extended parameters"" hack. <TAB>  for token in self : <TAB><TAB>  if token . token_type == "" value "" : <TAB><TAB><TAB>  return token . stripped_value <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for token in token : <TAB><TAB><TAB><TAB>  if token . token_type == "" bare-quoted-string "" : <TAB><TAB><TAB><TAB><TAB>  for token in token : <TAB><TAB><TAB><TAB><TAB><TAB>  if token . token_type == "" value "" : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  return token . stripped_value <TAB>  return "" "" ","if token . token_type == ""quoted-string"" :","if token.token_type == ""quoted-string':",False,35.820686389107394,98.27782735838092
3565,"def paragraph_is_fully_commented ( lines , comment , main_language ) : <TAB>  """"""Is the paragraph fully commented?"""""" <TAB>  for i , line in enumerate ( lines ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if is_magic ( line , main_language ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  continue <TAB><TAB>  return i > 0 and _BLANK_LINE . match ( line ) <TAB>  return True ",if line . startswith ( comment ) :,if line.startswith(comment):,False,30.776909897484916,100.00000000000004
3566,"def lots_connected_to_existing_roads ( model ) : <TAB>  set = [ ] <TAB>  for h in model . HarvestCells : <TAB><TAB>  for ( i , j ) in model . ExistingRoads : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if h not in set : <TAB><TAB><TAB><TAB><TAB>  set . append ( h ) <TAB>  return set ",if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,"if h.connected_to_existing_row(i, j):",False,18.909499913625982,83.5270961722172
3567,"def detect ( get_page ) : <TAB>  retval = False <TAB>  for vector in WAF_ATTACK_VECTORS : <TAB><TAB>  page , headers , code = get_page ( get = vector ) <TAB><TAB>  retval = ( <TAB><TAB><TAB>  re . search ( <TAB><TAB><TAB><TAB>  r "" \ Abarra_counter_session= "" , <TAB><TAB><TAB><TAB>  headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , <TAB><TAB><TAB><TAB>  re . I , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  is not None <TAB><TAB>  ) <TAB><TAB>  retval | = ( <TAB><TAB><TAB>  re . search ( <TAB><TAB><TAB><TAB>  r "" ( \ A| \ b)barracuda_ "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  is not None <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return retval ",if retval :,if retval:,False,19.948363537403516,100.00000000000004
3568,"def test_files ( self ) : <TAB>  # get names of files to test <TAB>  dist_dir = os . path . join ( os . path . dirname ( __file__ ) , os . pardir , os . pardir ) <TAB>  names = [ ] <TAB>  for d in self . test_directories : <TAB><TAB>  test_dir = os . path . join ( dist_dir , d ) <TAB><TAB>  for n in os . listdir ( test_dir ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  names . append ( os . path . join ( test_dir , n ) ) <TAB>  for filename in names : <TAB><TAB>  if test_support . verbose : <TAB><TAB><TAB>  print ( "" Testing  %s "" % filename ) <TAB><TAB>  source = read_pyfile ( filename ) <TAB><TAB>  self . check_roundtrip ( source ) ","if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :",if n.startswith('.py'):,False,29.784208302183824,93.3615732710836
3569,"def test_calibrate_target ( create_target ) : <TAB>  mod , params = testing . synthetic . get_workload ( ) <TAB>  dataset = get_calibration_dataset ( mod , "" data "" ) <TAB>  with relay . quantize . qconfig ( calibrate_mode = "" kl_divergence "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with tvm . target . Target ( "" llvm "" ) : <TAB><TAB><TAB><TAB>  relay . quantize . quantize ( mod , params , dataset ) <TAB><TAB>  else : <TAB><TAB><TAB>  # current_target = None <TAB><TAB><TAB>  relay . quantize . quantize ( mod , params , dataset ) ",if create_target :,if create_target:,False,51.1249716230183,100.00000000000004
3570,"def _cleanSubmodule ( self , _ = None ) : <TAB>  rc = RC_SUCCESS <TAB>  if self . submodules : <TAB><TAB>  command = [ <TAB><TAB><TAB>  "" submodule "" , <TAB><TAB><TAB>  "" foreach "" , <TAB><TAB><TAB>  "" --recursive "" , <TAB><TAB><TAB>  "" git "" , <TAB><TAB><TAB>  "" clean "" , <TAB><TAB><TAB>  "" -f "" , <TAB><TAB><TAB>  "" -f "" , <TAB><TAB><TAB>  "" -d "" , <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  command . append ( "" -x "" ) <TAB><TAB>  rc = yield self . _dovccmd ( command ) <TAB>  defer . returnValue ( rc ) ","if self . mode == ""full"" and self . method == ""fresh"" :",if _ is not None:,False,25.189785005667208,91.14820085391642
3571,"def screen_length_to_bytes_count ( string , screen_length_limit , encoding ) : <TAB>  bytes_count = 0 <TAB>  screen_length = 0 <TAB>  for unicode_char in string : <TAB><TAB>  screen_length + = screen_len ( unicode_char ) <TAB><TAB>  char_bytes_count = len ( unicode_char . encode ( encoding ) ) <TAB><TAB>  bytes_count + = char_bytes_count <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bytes_count - = char_bytes_count <TAB><TAB><TAB>  break <TAB>  return bytes_count ",if screen_length > screen_length_limit :,if char_bytes_count < screen_length_limit:,False,16.657093066964396,95.44315646130717
3572,"def tamper ( payload , * * kwargs ) : <TAB>  junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB>  retval = "" "" <TAB>  for i , char in enumerate ( payload , start = 1 ) : <TAB><TAB>  amount = random . randint ( 10 , 15 ) <TAB><TAB>  if char == "" > "" : <TAB><TAB><TAB>  retval + = "" > "" <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  retval + = "" < "" <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  elif char == "" "" : <TAB><TAB><TAB>  for _ in range ( amount ) : <TAB><TAB><TAB><TAB>  retval + = random . choice ( junk_chars ) <TAB><TAB>  else : <TAB><TAB><TAB>  retval + = char <TAB>  return retval ","elif char == ""<"" :","if char == ""<"":",False,22.91526653648737,99.16315578765581
3573,"def test_parse ( self ) : <TAB>  correct = 0 <TAB>  for example in EXAMPLES : <TAB><TAB>  try : <TAB><TAB><TAB>  schema . parse ( example . schema_string ) <TAB><TAB><TAB>  if example . valid : <TAB><TAB><TAB><TAB>  correct + = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB><TAB>  except : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  correct + = 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB>  fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB><TAB>  correct , <TAB><TAB>  len ( EXAMPLES ) , <TAB>  ) <TAB>  self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg ) ",if not example . valid :,if example.valid:,False,51.673916411202526,99.04992354975539
3574,"def _on_change ( self ) : <TAB>  changed = False <TAB>  self . save ( ) <TAB>  for key , value in self . data . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB>  if value != 1 : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  elif value is None : <TAB><TAB><TAB>  continue <TAB><TAB>  elif len ( value ) != 0 : <TAB><TAB><TAB>  changed = True <TAB><TAB><TAB>  break <TAB>  self . _reset_button . disabled = not changed ","if isinstance ( value , bool ) :",if key == self._reset_button.selected:,False,50.89257508617708,94.4527184386815
3575,"def normalize ( d : Dict [ Any , Any ] ) - > Dict [ str , Any ] : <TAB>  first_exception = None <TAB>  for normalizer in normalizers : <TAB><TAB>  try : <TAB><TAB><TAB>  normalized = normalizer ( d ) <TAB><TAB>  except KeyError as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  first_exception = e <TAB><TAB>  else : <TAB><TAB><TAB>  return normalized <TAB>  assert first_exception is not None <TAB>  raise first_exception ",if not first_exception :,if e.args[0] == 'normalizer-exception':,False,27.37898087954046,92.62113682832097
3576,"def gather_callback_args ( self , obj , callbacks ) : <TAB>  session = sa . orm . object_session ( obj ) <TAB>  for callback in callbacks : <TAB><TAB>  backref = callback . backref <TAB><TAB>  root_objs = getdotattr ( obj , backref ) if backref else obj <TAB><TAB>  if root_objs : <TAB><TAB><TAB>  if not isinstance ( root_objs , Iterable ) : <TAB><TAB><TAB><TAB>  root_objs = [ root_objs ] <TAB><TAB><TAB>  with session . no_autoflush : <TAB><TAB><TAB><TAB>  for root_obj in root_objs : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  args = self . get_callback_args ( root_obj , callback ) <TAB><TAB><TAB><TAB><TAB><TAB>  if args : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  yield args ",if root_obj :,if root_obj.type == 'callback':,False,23.113308380940698,97.48256706907121
3577,"def test_opdm_to_oqdm ( self ) : <TAB>  for file in filter ( lambda x : x . endswith ( "" .hdf5 "" ) , os . listdir ( DATA_DIRECTORY ) ) : <TAB><TAB>  molecule = MolecularData ( filename = os . path . join ( DATA_DIRECTORY , file ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  test_oqdm = map_one_pdm_to_one_hole_dm ( molecule . fci_one_rdm ) <TAB><TAB><TAB>  true_oqdm = numpy . eye ( molecule . n_qubits ) - molecule . fci_one_rdm <TAB><TAB><TAB>  assert numpy . allclose ( test_oqdm , true_oqdm ) ",if molecule . fci_one_rdm is not None :,if os.path.isfile(molecule.fci_one_rdm):,False,29.327086967170597,94.31702453972261
3578,"def emitSubDomainData ( self , subDomainData , event ) : <TAB>  self . emitRawRirData ( subDomainData , event ) <TAB>  for subDomainElem in subDomainData : <TAB><TAB>  if self . checkForStop ( ) : <TAB><TAB><TAB>  return None <TAB><TAB>  subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . emitHostname ( subDomain , event ) ",if subDomain :,if subDomain != self.hostname:,False,23.089781390835345,93.82018820050568
3579,"def download_cve ( <TAB>  download_path : str , years : Optional [ List [ int ] ] = None , update : bool = False  ) : <TAB>  if update : <TAB><TAB>  process_url ( CVE_URL . format ( "" modified "" ) , download_path ) <TAB>  else : <TAB><TAB>  all_cve_urls = get_cve_links ( CVE_URL , years ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise CveLookupException ( "" Error: No CVE links found "" ) <TAB><TAB>  for url in all_cve_urls : <TAB><TAB><TAB>  process_url ( url , download_path ) ",if not all_cve_urls :,if not all_cve_urls:,False,51.987510057566055,100.00000000000004
3580,"def is_special ( s , i , directive ) : <TAB>  """"""Return True if the body text contains the @ directive."""""" <TAB>  # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB>  assert directive and directive [ 0 ] == "" @ "" <TAB>  # 10/23/02: all directives except @others must start the line. <TAB>  skip_flag = directive in ( "" @others "" , "" @all "" ) <TAB>  while i < len ( s ) : <TAB><TAB>  if match_word ( s , i , directive ) : <TAB><TAB><TAB>  return True , i <TAB><TAB>  else : <TAB><TAB><TAB>  i = skip_line ( s , i ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  i = skip_ws ( s , i ) <TAB>  return False , - 1 ",if skip_flag :,if skip_flag:,False,62.89709475322305,99.12470542897984
3581,"def run_async ( self , nuke_cursors ) : <TAB>  # type: (bool) -> None <TAB>  interface_type = self . view . settings ( ) . get ( "" git_savvy.interface "" ) <TAB>  for cls in subclasses : <TAB><TAB>  if cls . interface_type == interface_type : <TAB><TAB><TAB>  vid = self . view . id ( ) <TAB><TAB><TAB>  interface = interfaces . get ( vid , None ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  interface = interfaces [ vid ] = cls ( view = self . view ) <TAB><TAB><TAB>  interface . render ( nuke_cursors = nuke_cursors )<TAB># type: ignore[union-attr] <TAB><TAB><TAB>  break ",if not interface :,if interface is None:,False,26.827575019531412,95.4368461849759
3582,"def scan_resource_conf ( self , conf ) : <TAB>  if "" properties "" in conf : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if str ( conf [ "" properties "" ] [ "" sslEnforcement "" ] ) . lower ( ) == "" enabled "" : <TAB><TAB><TAB><TAB>  return CheckResult . PASSED <TAB>  return CheckResult . FAILED ","if ""sslEnforcement"" in conf [ ""properties"" ] :",if conf['properties']['sslEnforcement']:,False,23.06438110409962,89.74148618289989
3583,"def do_shorts ( <TAB>  opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ]  ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB>  while optstring != "" "" : <TAB><TAB>  opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB><TAB>  if short_has_arg ( opt , shortopts ) : <TAB><TAB><TAB>  if optstring == "" "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB><TAB><TAB><TAB>  optstring , args = args [ 0 ] , args [ 1 : ] <TAB><TAB><TAB>  optarg , optstring = optstring , "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  optarg = "" "" <TAB><TAB>  opts . append ( ( "" - "" + opt , optarg ) ) <TAB>  return opts , args ",if not args :,if opt not in args:,False,29.94892233707879,98.3453222386506
3584,"def release ( self ) : <TAB>  tid = _thread . get_ident ( ) <TAB>  with self . lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB><TAB>  assert self . count > 0 <TAB><TAB>  self . count - = 1 <TAB><TAB>  if self . count == 0 : <TAB><TAB><TAB>  self . owner = None <TAB><TAB><TAB>  if self . waiters : <TAB><TAB><TAB><TAB>  self . waiters - = 1 <TAB><TAB><TAB><TAB>  self . wakeup . release ( ) ",if self . owner != tid :,if tid == self.owner:,False,29.759115553809558,96.56415941996124
3585,"def _summarize_kraken ( fn ) : <TAB>  """"""get the value at species level"""""" <TAB>  kraken = { } <TAB>  list_sp , list_value = [ ] , [ ] <TAB>  with open ( fn ) as handle : <TAB><TAB>  for line in handle : <TAB><TAB><TAB>  cols = line . strip ( ) . split ( "" \t "" ) <TAB><TAB><TAB>  sp = cols [ 5 ] . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  list_sp . append ( sp ) <TAB><TAB><TAB><TAB>  list_value . append ( cols [ 0 ] ) <TAB>  kraken = { "" kraken_sp "" : list_sp , "" kraken_value "" : list_value } <TAB>  return kraken ","if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :",if sp != '':,False,31.322618800213498,89.02141566429829
3586,"def _sync_remote_run ( remote_run ) : <TAB>  assert remote_run . remote <TAB>  remote_name = remote_run . remote . name <TAB>  pull_args = click_util . Args ( remote = remote_name , delete = False ) <TAB>  try : <TAB><TAB>  remote_impl_support . pull_runs ( [ remote_run ] , pull_args ) <TAB>  except Exception as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . exception ( "" pull  %s  from  %s "" , remote_run . id , remote_name ) <TAB><TAB>  else : <TAB><TAB><TAB>  log . error ( "" error pulling  %s  from  %s :  %s "" , remote_run . id , remote_name , e ) ",if log . getEffectiveLevel ( ) <= logging . DEBUG :,if e.args[0] == 'Pull Failed':,False,48.942772193356845,94.27483938627866
3587,"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB>  sign = None <TAB>  subseq = [ ] <TAB>  for i in seq : <TAB><TAB>  ki = key ( i ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  subseq . append ( i ) <TAB><TAB><TAB>  if ki != 0 : <TAB><TAB><TAB><TAB>  sign = ki / abs ( ki ) <TAB><TAB>  else : <TAB><TAB><TAB>  subseq . append ( i ) <TAB><TAB><TAB>  if sign * ki < - slop : <TAB><TAB><TAB><TAB>  sign = ki / abs ( ki ) <TAB><TAB><TAB><TAB>  yield subseq <TAB><TAB><TAB><TAB>  subseq = [ i ] <TAB>  if subseq : <TAB><TAB>  yield subseq ",if sign is None :,if sign is None:,False,54.84539575108908,98.43015134438294
3588,"def import_til ( self ) : <TAB>  log ( "" Importing type libraries... "" ) <TAB>  cur = self . db_cursor ( ) <TAB>  sql = "" select name from diff.program_data where type =  ' til ' "" <TAB>  cur . execute ( sql ) <TAB>  for row in cur . fetchall ( ) : <TAB><TAB>  til = row [ "" name "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  til = til . decode ( "" utf-8 "" ) <TAB><TAB>  try : <TAB><TAB><TAB>  add_default_til ( til ) <TAB><TAB>  except : <TAB><TAB><TAB>  log ( "" Error loading til  %s :  %s "" % ( row [ "" name "" ] , str ( sys . exc_info ( ) [ 1 ] ) ) ) <TAB>  cur . close ( ) <TAB>  auto_wait ( ) ",if type ( til ) is bytes :,"if isinstance(til, unicode):",False,53.289198927950444,94.87397585614508
3589,"def getBranches ( self ) : <TAB>  returned = [ ] <TAB>  for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  git_branch_line = git_branch_line [ 1 : ] <TAB><TAB>  git_branch_line = git_branch_line . strip ( ) <TAB><TAB>  if BRANCH_ALIAS_MARKER in git_branch_line : <TAB><TAB><TAB>  alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB><TAB><TAB>  returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB>  return returned ","if git_branch_line . startswith ( ""*"" ) :",if git_branch_line.startswith(''):,False,51.19471554306325,97.8702338961528
3590,"def add_include_dirs ( self , args ) : <TAB>  ids = [ ] <TAB>  for a in args : <TAB><TAB>  # FIXME same hack, forcibly unpack from holder. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  a = a . includedirs <TAB><TAB>  if not isinstance ( a , IncludeDirs ) : <TAB><TAB><TAB>  raise InvalidArguments ( <TAB><TAB><TAB><TAB>  "" Include directory to be added is not an include directory object. "" <TAB><TAB><TAB>  ) <TAB><TAB>  ids . append ( a ) <TAB>  self . include_dirs + = ids ","if hasattr ( a , ""includedirs"" ) :","if isinstance(a, IncludeDir):",False,64.61913516860986,95.53819267690594
3591,"def _serialize_feature ( self , feature ) : <TAB>  name = feature . unique_name ( ) <TAB>  <IF-STMT>: <TAB><TAB>  self . _features_dict [ feature . unique_name ( ) ] = feature . to_dictionary ( ) <TAB><TAB>  for dependency in feature . get_dependencies ( deep = True ) : <TAB><TAB><TAB>  name = dependency . unique_name ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _features_dict [ name ] = dependency . to_dictionary ( ) ",if name not in self . _features_dict :,if name not in self._features_dict:,False,30.263338082635727,92.34118517652963
3592,"def generate_io ( chart_type , race_configs , environment ) : <TAB>  # output JSON structures <TAB>  structures = [ ] <TAB>  for race_config in race_configs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  title = chart_type . format_title ( <TAB><TAB><TAB><TAB>  environment , <TAB><TAB><TAB><TAB>  race_config . track , <TAB><TAB><TAB><TAB>  es_license = race_config . es_license , <TAB><TAB><TAB><TAB>  suffix = "" %s -io "" % race_config . label , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  structures . append ( chart_type . io ( title , environment , race_config ) ) <TAB>  return structures ","if ""io"" in race_config . charts :",if race_config.track and race_config.track.is_io:,False,26.02917427006539,91.65876156975962
3593,"def format_partition ( partition , partition_schema ) : <TAB>  tokens = [ ] <TAB>  if isinstance ( partition , dict ) : <TAB><TAB>  for name in partition_schema : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tok = _format_partition_kv ( <TAB><TAB><TAB><TAB><TAB>  name , partition [ name ] , partition_schema [ name ] <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # dynamic partitioning <TAB><TAB><TAB><TAB>  tok = name <TAB><TAB><TAB>  tokens . append ( tok ) <TAB>  else : <TAB><TAB>  for name , value in zip ( partition_schema , partition ) : <TAB><TAB><TAB>  tok = _format_partition_kv ( name , value , partition_schema [ name ] ) <TAB><TAB><TAB>  tokens . append ( tok ) <TAB>  return "" PARTITION ( {} ) "" . format ( "" ,  "" . join ( tokens ) ) ",if name in partition :,if name in partition_schema:,False,50.036592310000415,98.68891056239045
3594,"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB>  context = context or { } <TAB>  condition = getattr ( self , "" condition "" , Undefined ) <TAB>  copy = self<TAB># don't copy unless we need to <TAB>  if condition is not Undefined : <TAB><TAB>  if isinstance ( condition , core . SchemaBase ) : <TAB><TAB><TAB>  pass <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwds = parse_shorthand ( condition [ "" field "" ] , context . get ( "" data "" , None ) ) <TAB><TAB><TAB>  copy = self . copy ( deep = [ "" condition "" ] ) <TAB><TAB><TAB>  copy . condition . update ( kwds ) <TAB>  return super ( ValueChannelMixin , copy ) . to_dict ( <TAB><TAB>  validate = validate , ignore = ignore , context = context <TAB>  ) ","elif ""field"" in condition and ""type"" not in condition :",if condition is not Undefined:,False,30.719085268522868,92.94386160219953
3595,"def _checkForCommand ( self ) : <TAB>  prompt = b "" cftp>  "" <TAB>  if self . _expectingCommand and self . _lineBuffer == prompt : <TAB><TAB>  buf = b "" \n "" . join ( self . _linesReceived ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  buf = buf [ len ( prompt ) : ] <TAB><TAB>  self . clearBuffer ( ) <TAB><TAB>  d , self . _expectingCommand = self . _expectingCommand , None <TAB><TAB>  d . callback ( buf ) ",if buf . startswith ( prompt ) :,if buf.startswith(prompt):,False,33.35358385581493,100.00000000000004
3596,"def schedule_logger ( job_id = None , delete = False ) : <TAB>  if not job_id : <TAB><TAB>  return getLogger ( "" fate_flow_schedule "" ) <TAB>  else : <TAB><TAB>  if delete : <TAB><TAB><TAB>  with LoggerFactory . lock : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  if job_id in key : <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  del LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  return True <TAB><TAB>  key = job_id + "" schedule "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB>  return LoggerFactory . get_schedule_logger ( job_id ) ",if key in LoggerFactory . schedule_logger_dict :,if key in LoggerFactory.schedule_logger_dict:,False,52.19797523802547,100.00000000000004
3597,"def halfMultipartScore ( nzb_name ) : <TAB>  try : <TAB><TAB>  wrong_found = 0 <TAB><TAB>  for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB><TAB><TAB>  for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB><TAB><TAB><TAB>  if "" %s %s "" % ( wrong , nr ) in nzb_name . lower ( ) : <TAB><TAB><TAB><TAB><TAB>  wrong_found + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return - 30 <TAB><TAB>  return 0 <TAB>  except : <TAB><TAB>  log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB>  return 0 ",if wrong_found == 1 :,if wrong_found == 5:,False,47.870599665156114,97.52723465800457
3598,"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB>  argstr + = "" , "" <TAB>  args = [ ] <TAB>  kwargs = { } <TAB>  for item in _converter_args_re . finditer ( argstr ) : <TAB><TAB>  value = item . group ( "" stringval "" ) <TAB><TAB>  if value is None : <TAB><TAB><TAB>  value = item . group ( "" value "" ) <TAB><TAB>  value = _pythonize ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args . append ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  name = item . group ( "" name "" ) <TAB><TAB><TAB>  kwargs [ name ] = value <TAB>  return tuple ( args ) , kwargs ","if not item . group ( ""name"" ) :",if value is not None:,False,21.857671729772697,95.2269757731182
3599,"def leaves ( self , unique = True ) : <TAB>  """"""Get the leaves of the tree starting at this root."""""" <TAB>  if not self . children : <TAB><TAB>  return [ self ] <TAB>  else : <TAB><TAB>  res = list ( ) <TAB><TAB>  for child in self . children : <TAB><TAB><TAB>  for sub_child in child . leaves ( unique = unique ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  res . append ( sub_child ) <TAB><TAB>  return res ",if not unique or sub_child not in res :,if sub_child.root == self:,False,56.68146104994285,94.11796612636327
3600,"def to_tree ( self , tagname = None , idx = None , namespace = None ) : <TAB>  axIds = set ( ( ax . axId for ax in self . _axes ) ) <TAB>  for chart in self . _charts : <TAB><TAB>  for id , axis in chart . _axes . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  setattr ( self , axis . tagname , axis ) <TAB><TAB><TAB><TAB>  axIds . add ( id ) <TAB>  return super ( PlotArea , self ) . to_tree ( tagname ) ",if id not in axIds :,if id not in axIds:,False,52.76618704163391,100.00000000000004
3601,"def update_neighbor ( neigh_ip_address , changes ) : <TAB>  rets = [ ] <TAB>  for k , v in changes . items ( ) : <TAB><TAB>  if k == neighbors . MULTI_EXIT_DISC : <TAB><TAB><TAB>  rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB><TAB>  if k == neighbors . ENABLED : <TAB><TAB><TAB>  rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB>  return all ( rets ) ",if k == neighbors . CONNECT_MODE :,if k == neighbors.CONNECT_MODE:,False,51.27096539468352,100.00000000000004
3602,"def close_all_connections ( ) : <TAB>  global _managers , _lock , _in_use , _timer <TAB>  _lock . acquire ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _timer . cancel ( ) <TAB><TAB><TAB>  _timer = None <TAB><TAB>  for domain , managers in _managers . items ( ) : <TAB><TAB><TAB>  for manager in managers : <TAB><TAB><TAB><TAB>  manager . close ( ) <TAB><TAB>  _managers = { } <TAB>  finally : <TAB><TAB>  _lock . release ( ) ",if _timer :,if _timer is not None and _in_use:,False,33.0649207719447,94.10971685365021
3603,"def _instrument_model ( self , model ) : <TAB>  for key , value in list ( <TAB><TAB>  model . __dict__ . items ( ) <TAB>  ) :<TAB># avoid ""dictionary keys changed during iteration"" <TAB><TAB>  if isinstance ( value , tf . keras . layers . Layer ) : <TAB><TAB><TAB>  new_layer = self . _instrument ( value ) <TAB><TAB><TAB>  if new_layer is not value : <TAB><TAB><TAB><TAB>  setattr ( model , key , new_layer ) <TAB><TAB>  elif isinstance ( value , list ) : <TAB><TAB><TAB>  for i , item in enumerate ( value ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  value [ i ] = self . _instrument ( item ) <TAB>  return model ","if isinstance ( item , tf . keras . layers . Layer ) :","if isinstance(item, (int, float)):",False,47.60666138215196,95.02300465755538
3604,"def target_glob ( tgt , hosts ) : <TAB>  ret = { } <TAB>  for host in hosts : <TAB><TAB>  if fnmatch . fnmatch ( tgt , host ) : <TAB><TAB><TAB>  ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB><TAB><TAB>  ret [ host ] . update ( { "" host "" : host } ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB>  return ret ","if __opts__ . get ( ""ssh_user"" ) :",if 'ssh_user' in __opts__:,False,31.504020683287532,92.94414313742493
3605,"def write ( self , data ) : <TAB>  if mock_target . _mirror_on_stderr : <TAB><TAB>  if self . _write_line : <TAB><TAB><TAB>  sys . stderr . write ( fn + "" :  "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  sys . stderr . write ( data ) <TAB><TAB>  if ( data [ - 1 ] ) == "" \n "" : <TAB><TAB><TAB>  self . _write_line = True <TAB><TAB>  else : <TAB><TAB><TAB>  self . _write_line = False <TAB>  super ( Buffer , self ) . write ( data ) ",if bytes :,"if isinstance(data, unicode):",False,49.23737391357589,94.38812881391522
3606,"def task_thread ( ) : <TAB>  while not task_queue . empty ( ) : <TAB><TAB>  host , port , username , password = task_queue . get ( ) <TAB><TAB>  logger . info ( <TAB><TAB><TAB>  "" try burst  {} : {}  use username: {}  password: {} "" . format ( <TAB><TAB><TAB><TAB>  host , port , username , password <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with task_queue . mutex : <TAB><TAB><TAB><TAB>  task_queue . queue . clear ( ) <TAB><TAB><TAB>  result_queue . put ( ( username , password ) ) ","if telnet_login ( host , port , username , password ) :",if host == port:,False,21.893025972771234,93.21883725147426
3607,"def _format_results ( name , ppl , scores , metrics ) : <TAB>  """"""Format results."""""" <TAB>  result_str = "" "" <TAB>  if ppl : <TAB><TAB>  result_str = "" %s  ppl  %.2f "" % ( name , ppl ) <TAB>  if scores : <TAB><TAB>  for metric in metrics : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result_str + = "" ,  %s %s %.1f "" % ( name , metric , scores [ metric ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  result_str = "" %s %s %.1f "" % ( name , metric , scores [ metric ] ) <TAB>  return result_str ",if result_str :,if metric in scores:,False,44.70843315418285,97.5944484529286
3608,"def info_query ( self , query ) : <TAB>  """"""Send a query which only returns 1 row"""""" <TAB>  self . _cmysql . query ( query ) <TAB>  first_row = ( ) <TAB>  if self . _cmysql . have_result_set : <TAB><TAB>  first_row = self . _cmysql . fetch_row ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _cmysql . free_result ( ) <TAB><TAB><TAB>  raise errors . InterfaceError ( "" Query should not return more than 1 row "" ) <TAB>  self . _cmysql . free_result ( ) <TAB>  return first_row ",if self . _cmysql . fetch_row ( ) :,if first_row > 1:,False,34.16214337959491,93.3911521165503
3609,"def reset_class ( self ) : <TAB>  for f in self . fields_order : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  f . value = int ( f . strbits , 2 ) <TAB><TAB>  elif "" default_val "" in f . kargs : <TAB><TAB><TAB>  f . value = int ( f . kargs [ "" default_val "" ] , 2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  f . value = None <TAB><TAB>  if f . fname : <TAB><TAB><TAB>  setattr ( self , f . fname , f ) ",if f . strbits and isbin ( f . strbits ) :,if f.strbits:,False,45.09838071870714,94.43201801363834
3610,"def _walk_map_list ( self , access_func ) : <TAB>  seen = [ ] <TAB>  cur = self <TAB>  while cur : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  yield cur <TAB><TAB>  seen . append ( cur . obj_offset ) <TAB><TAB>  # check for signs of infinite looping <TAB><TAB>  if len ( seen ) > 1024 : <TAB><TAB><TAB>  break <TAB><TAB>  cur = access_func ( cur ) ",if cur . obj_offset in seen :,if cur.obj_offset >= len(seen):,False,53.549921907082876,94.67292482223593
3611,def bgdel ( ) : <TAB>  q = bgdelq <TAB>  while True : <TAB><TAB>  name = q . get ( ) <TAB><TAB>  while os . path . exists ( name ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  os . remove ( name ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  shutil . rmtree ( name ) <TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  if os . path . exists ( name ) : <TAB><TAB><TAB><TAB>  time . sleep ( 0.1 ) ,if os . path . isfile ( name ) :,if os.path.exists(name):,False,50.86548624319116,98.70958875144461
3612,"def _find_all_variables ( transfer_variable ) : <TAB>  d = { } <TAB>  for _k , _v in transfer_variable . __dict__ . items ( ) : <TAB><TAB>  if isinstance ( _v , Variable ) : <TAB><TAB><TAB>  d [ _v . _name ] = _v <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d . update ( _find_all_variables ( _v ) ) <TAB>  return d ","elif isinstance ( _v , BaseTransferVariables ) :",if _k == 'variables':,False,33.28828419951005,92.37281101102955
3613,"def set_val ( ) : <TAB>  idx = 0 <TAB>  for idx in range ( 0 , len ( model ) ) : <TAB><TAB>  row = model [ idx ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  if idx == len ( os_widget . get_model ( ) ) - 1 : <TAB><TAB><TAB>  idx = - 1 <TAB>  os_widget . set_active ( idx ) <TAB>  if idx == - 1 : <TAB><TAB>  os_widget . set_active ( 0 ) <TAB>  if idx > = 0 : <TAB><TAB>  return row [ 1 ] <TAB>  if self . show_all_os : <TAB><TAB>  return None ",if value and row [ 0 ] == value :,if not row:,False,16.98530327966264,91.54708587347062
3614,"def _make_cache_key ( group , window , rate , value , methods ) : <TAB>  count , period = _split_rate ( rate ) <TAB>  safe_rate = "" %d / %d s "" % ( count , period ) <TAB>  parts = [ group , safe_rate , value , str ( window ) ] <TAB>  if methods is not None : <TAB><TAB>  if methods == ALL : <TAB><TAB><TAB>  methods = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB><TAB>  parts . append ( methods ) <TAB>  prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB>  return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) ","elif isinstance ( methods , ( list , tuple ) ) :",if methods:,False,25.191180821524306,93.16326560763525
3615,"def findfiles ( path ) : <TAB>  files = [ ] <TAB>  for name in os . listdir ( path ) : <TAB><TAB>  # ignore hidden files/dirs and other unwanted files <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  pathname = os . path . join ( path , name ) <TAB><TAB>  st = os . lstat ( pathname ) <TAB><TAB>  mode = st . st_mode <TAB><TAB>  if stat . S_ISDIR ( mode ) : <TAB><TAB><TAB>  files . extend ( findfiles ( pathname ) ) <TAB><TAB>  elif stat . S_ISREG ( mode ) : <TAB><TAB><TAB>  files . append ( ( pathname , name , st ) ) <TAB>  return files ","if name . startswith ( ""."" ) or name == ""lastsnap.jpg"" :",if name.startswith('_'):,False,56.42058409355132,92.67224186003853
3616,"def __getitem__ ( self , key ) : <TAB>  if isinstance ( key , str_types ) : <TAB><TAB>  keys = self . get_keys ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise KeyError ( ' "" {0} ""  is an invalid key ' . format ( key ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  return self [ keys . index ( key ) ] <TAB>  else : <TAB><TAB>  return list . __getitem__ ( self , key ) ",if key not in keys :,if key not in keys:,False,52.9733719732788,97.30649191472902
3617,"def test_assert_set_equal ( estimate : tp . Iterable [ int ] , message : str ) - > None : <TAB>  reference = { 1 , 2 , 3 } <TAB>  try : <TAB><TAB>  testing . assert_set_equal ( estimate , reference ) <TAB>  except AssertionError as error : <TAB><TAB>  if not message : <TAB><TAB><TAB>  raise AssertionError ( <TAB><TAB><TAB><TAB>  "" An error has been raised while it should not. "" <TAB><TAB><TAB>  ) from error <TAB><TAB>  np . testing . assert_equal ( error . args [ 0 ] . split ( "" \n "" ) [ 1 : ] , message ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AssertionError ( "" An error should have been raised. "" ) ",if message :,if not len(error.args) == 0:,False,28.968214287169364,94.3990187303685
3618,"def get_directory_info ( prefix , pth , recursive ) : <TAB>  res = [ ] <TAB>  directory = os . listdir ( pth ) <TAB>  directory . sort ( ) <TAB>  for p in directory : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  subp = os . path . join ( pth , p ) <TAB><TAB><TAB>  p = os . path . join ( prefix , p ) <TAB><TAB><TAB>  if recursive and os . path . isdir ( subp ) : <TAB><TAB><TAB><TAB>  res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  res . append ( [ p , None ] ) <TAB>  return res ","if p [ 0 ] != ""."" :",if os.path.isdir(p):,False,45.5408760936653,94.92891783095382
3619,"def check ( self , runner , script , info ) : <TAB>  if isinstance ( info , ast . FunctionDef ) : <TAB><TAB>  for arg in info . args . args : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if arg . id in script . modelVars : <TAB><TAB><TAB><TAB><TAB>  self . problem ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" Function  {0}  may shadow model variable  {1} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  info . name , arg . id <TAB><TAB><TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB><TAB><TAB>  lineno = info . lineno , <TAB><TAB><TAB><TAB><TAB>  ) ","if isinstance ( arg , ast . Name ) :",if arg.name == info.name:,False,55.42145339594229,95.8915847307467
3620,"def db_lookup ( field , key , publish_year = None ) : <TAB>  sql = "" select sum(ebook_count) as num from subjects where field=$field and key=$key "" <TAB>  if publish_year : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sql + = ""  and publish_year between $y1 and $y2 "" <TAB><TAB><TAB>  ( y1 , y2 ) = publish_year <TAB><TAB>  else : <TAB><TAB><TAB>  sql + = ""  and publish_year=$publish_year "" <TAB>  return list ( ebook_count_db . query ( sql , vars = locals ( ) ) ) [ 0 ] . num ","if isinstance ( publish_year , ( tuple , list ) ) :",if publish_year:,False,45.30306885555715,92.8941377178913
3621,"def put ( self , session ) : <TAB>  with sess_lock : <TAB><TAB>  self . parent . put ( session ) <TAB><TAB>  # Do not store the session if skip paths <TAB><TAB>  for sp in self . skip_paths : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB>  if session . sid in self . _cache : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  del self . _cache [ session . sid ] <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  self . _cache [ session . sid ] = session <TAB>  self . _normalize ( ) ",if request . path . startswith ( sp ) :,if sp.is_session_active(session):,False,59.95523015368225,94.92087379998779
3622,"def summarize ( self ) : <TAB>  if self . bad_commit and self . good_commit : <TAB><TAB>  for subresult in self . subresults . values ( ) : <TAB><TAB><TAB>  sub = subresult . summarize ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return sub <TAB><TAB>  return "" Detected bad commit in  {}  repository: \n {} {} "" . format ( <TAB><TAB><TAB>  self . repo_name , self . bad_commit , get_message ( self . suite , self . bad_commit ) <TAB><TAB>  ) <TAB>  return "" "" ",if sub :,if sub:,False,54.73081775420998,100.00000000000004
3623,def compute_nullable_nonterminals ( self ) : <TAB>  nullable = { } <TAB>  num_nullable = 0 <TAB>  while 1 : <TAB><TAB>  for p in self . grammar . Productions [ 1 : ] : <TAB><TAB><TAB>  if p . len == 0 : <TAB><TAB><TAB><TAB>  nullable [ p . name ] = 1 <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  for t in p . prod : <TAB><TAB><TAB><TAB>  if not t in nullable : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  nullable [ p . name ] = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  num_nullable = len ( nullable ) <TAB>  return nullable ,if len ( nullable ) == num_nullable :,if num_nullable == 0:,False,35.77132683828151,96.32518423867153
3624,"def _cast_float64_to_float32 ( self , feeds ) : <TAB>  for input_name , input_type in self . inputs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  feed = feeds . get ( input_name ) <TAB><TAB><TAB>  if feed is not None and feed . dtype == np . float64 : <TAB><TAB><TAB><TAB>  feeds [ input_name ] = feed . astype ( np . float32 ) <TAB>  return feeds ","if input_type == ""tensor(float)"" :",if input_type == 'feed':,False,57.81824924117539,93.88206944739694
3625,"def proc_minute ( d ) : <TAB>  if expanded [ 0 ] [ 0 ] != "" * "" : <TAB><TAB>  diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if is_prev : <TAB><TAB><TAB><TAB>  d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB><TAB><TAB>  return True , d <TAB>  return False , d ",if diff_min is not None and diff_min != 0 :,if diff_min > 0:,False,28.877783784275614,93.76686193440628
3626,"def detype ( self ) : <TAB>  if self . _detyped is not None : <TAB><TAB>  return self . _detyped <TAB>  ctx = { } <TAB>  for key , val in self . _d . items ( ) : <TAB><TAB>  if not isinstance ( key , str ) : <TAB><TAB><TAB>  key = str ( key ) <TAB><TAB>  detyper = self . get_detyper ( key ) <TAB><TAB>  if detyper is None : <TAB><TAB><TAB>  # cannot be detyped <TAB><TAB><TAB>  continue <TAB><TAB>  deval = detyper ( val ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # cannot be detyped <TAB><TAB><TAB>  continue <TAB><TAB>  ctx [ key ] = deval <TAB>  self . _detyped = ctx <TAB>  return ctx ",if deval is None :,if deval is None:,False,51.00040823518752,100.00000000000004
3627,"def get_or_create_user ( request , user_data ) : <TAB>  try : <TAB><TAB>  user = User . objects . get ( sso_id = user_data [ "" id "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  update_user ( user , user_data ) <TAB><TAB>  return user <TAB>  except User . DoesNotExist : <TAB><TAB>  user = User . objects . create_user ( <TAB><TAB><TAB>  user_data [ "" username "" ] , <TAB><TAB><TAB>  user_data [ "" email "" ] , <TAB><TAB><TAB>  is_active = user_data . get ( "" is_active "" , True ) , <TAB><TAB><TAB>  sso_id = user_data [ "" id "" ] , <TAB><TAB>  ) <TAB><TAB>  user . update_acl_key ( ) <TAB><TAB>  setup_new_user ( request . settings , user ) <TAB><TAB>  return user ","if user_needs_updating ( user , user_data ) :",if user:,False,32.40902401402671,94.95718813842184
3628,"def _populate_tree ( self , element , d ) : <TAB>  """"""Populates an etree with attributes & elements, given a dict."""""" <TAB>  for k , v in d . iteritems ( ) : <TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB>  self . _populate_dict ( element , k , v ) <TAB><TAB>  elif isinstance ( v , list ) : <TAB><TAB><TAB>  self . _populate_list ( element , k , v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _populate_bool ( element , k , v ) <TAB><TAB>  elif isinstance ( v , basestring ) : <TAB><TAB><TAB>  self . _populate_str ( element , k , v ) <TAB><TAB>  elif type ( v ) in [ int , float , long , complex ] : <TAB><TAB><TAB>  self . _populate_number ( element , k , v ) ","elif isinstance ( v , bool ) :","if isinstance(v, bool):",False,31.71516463506221,98.9304308486208
3629,"def load ( cls ) : <TAB>  if not cls . _loaded : <TAB><TAB>  cls . log . debug ( "" Loading action_sets... "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . _find_action_sets ( PATHS . ACTION_SETS_DIRECTORY ) <TAB><TAB>  else : <TAB><TAB><TAB>  cls . action_sets = JsonDecoder . load ( PATHS . ACTION_SETS_JSON_FILE ) <TAB><TAB>  cls . log . debug ( "" Done! "" ) <TAB><TAB>  cls . _loaded = True ",if not horizons . globals . fife . use_atlases :,if os.path.exists(PATHS.ACTION_SETS_DIRECTORY):,False,44.243097772560404,90.33415363774543
3630,"def Resolve ( self , updater = None ) : <TAB>  if len ( self . Conflicts ) : <TAB><TAB>  for setting , edge in self . Conflicts : <TAB><TAB><TAB>  answer = self . AskUser ( self . Setting , setting ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = setting . Value . split ( "" | "" ) <TAB><TAB><TAB><TAB>  value . remove ( edge ) <TAB><TAB><TAB><TAB>  setting . Value = "" | "" . join ( value ) <TAB><TAB><TAB><TAB>  if updater : <TAB><TAB><TAB><TAB><TAB>  updater . UpdateSetting ( setting ) <TAB><TAB><TAB>  if answer == Gtk . ResponseType . NO : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ",if answer == Gtk . ResponseType . YES :,if answer == gtk.ResponseType.OK:,False,27.484690152326223,97.65780512136163
3631,"def read_tsv ( input_file , quotechar = None ) : <TAB>  """"""Reads a tab separated value file."""""" <TAB>  with open ( input_file , "" r "" , encoding = "" utf-8-sig "" ) as f : <TAB><TAB>  reader = csv . reader ( f , delimiter = "" \t "" , quotechar = quotechar ) <TAB><TAB>  lines = [ ] <TAB><TAB>  for line in reader : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  line = list ( str ( cell , "" utf-8 "" ) for cell in line )<TAB># noqa: F821 <TAB><TAB><TAB>  lines . append ( line ) <TAB><TAB>  return lines ",if sys . version_info [ 0 ] == 2 :,if quotechar and line.startswith('#'):,False,44.313226699871024,91.20416436957817
3632,"def devd_devfs_hook ( middleware , data ) : <TAB>  if data . get ( "" subsystem "" ) != "" CDEV "" : <TAB><TAB>  return <TAB>  if data [ "" type "" ] == "" CREATE "" : <TAB><TAB>  disks = await middleware . run_in_thread ( <TAB><TAB><TAB>  lambda : sysctl . filter ( "" kern.disks "" ) [ 0 ] . value . split ( ) <TAB><TAB>  ) <TAB><TAB>  # Device notified about is not a disk <TAB><TAB>  if data [ "" cdev "" ] not in disks : <TAB><TAB><TAB>  return <TAB><TAB>  await added_disk ( middleware , data [ "" cdev "" ] ) <TAB>  elif data [ "" type "" ] == "" DESTROY "" : <TAB><TAB>  # Device notified about is not a disk <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  await remove_disk ( middleware , data [ "" cdev "" ] ) ","if not RE_ISDISK . match ( data [ ""cdev"" ] ) :",if data['cdev'] not in disks:,False,59.25013215002781,94.23249923359229
3633,"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB>  tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB>  watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB>  if watchdir_id : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . watchdirs [ watchdir_id ] [ "" enabled "" ] : <TAB><TAB><TAB><TAB>  client . autoadd . disable_watchdir ( watchdir_id ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  client . autoadd . enable_watchdir ( watchdir_id ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id ) ","if col and col . get_title ( ) == _ ( ""Active"" ) :",if watchdir_id in self.watchdirs:,False,48.1133106382925,91.906886088313
3634,"def _execute ( self , options , args ) : <TAB>  if len ( args ) < 1 : <TAB><TAB>  raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB>  paths = args <TAB>  songs = [ self . load_song ( p ) for p in paths ] <TAB>  for song in songs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise CommandError ( <TAB><TAB><TAB><TAB>  _ ( "" Image editing not supported for  %(file_name)s "" "" ( %(file_format)s ) "" ) <TAB><TAB><TAB><TAB>  % { "" file_name "" : song ( "" ~filename "" ) , "" file_format "" : song ( "" ~format "" ) } <TAB><TAB><TAB>  ) <TAB>  for song in songs : <TAB><TAB>  try : <TAB><TAB><TAB>  song . clear_images ( ) <TAB><TAB>  except AudioFileError as e : <TAB><TAB><TAB>  raise CommandError ( e ) ",if not song . can_change_images :,"if not isinstance(song, Image):",False,28.940818236474254,96.67704164315066
3635,"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB>  filtered_pricing_rules = [ ] <TAB>  if doc : <TAB><TAB>  for pricing_rule in pricing_rules : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) : <TAB><TAB><TAB><TAB><TAB><TAB>  filtered_pricing_rules . append ( pricing_rule ) <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  filtered_pricing_rules . append ( pricing_rule ) <TAB>  else : <TAB><TAB>  filtered_pricing_rules = pricing_rules <TAB>  return filtered_pricing_rules ",if pricing_rule . condition :,"if hasattr(pricing_rule, 'condition'):",False,49.69920586839938,96.77225053153632
3636,"def ProcessStringLiteral ( self ) : <TAB>  if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB><TAB>  text = super ( JavaScriptBaseLexer , self ) . text <TAB><TAB>  if text == ' "" use strict "" ' or text == "" ' use strict ' "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _scopeStrictModes . pop ( ) <TAB><TAB><TAB>  self . _useStrictCurrent = True <TAB><TAB><TAB>  self . _scopeStrictModes . append ( self . _useStrictCurrent ) ",if len ( self . _scopeStrictModes ) > 0 :,if self._useStrictCurrent is not None:,False,46.993118565736644,91.35992305359773
3637,"def _find_remote_inputs ( metadata ) : <TAB>  out = [ ] <TAB>  for fr_key in metadata . keys ( ) : <TAB><TAB>  if isinstance ( fr_key , ( list , tuple ) ) : <TAB><TAB><TAB>  frs = fr_key <TAB><TAB>  else : <TAB><TAB><TAB>  frs = [ fr_key ] <TAB><TAB>  for fr in frs : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  out . append ( fr ) <TAB>  return out ",if objectstore . is_remote ( fr ) :,"if isinstance(fr, RemoteInput):",False,49.68099464859807,94.50658505234352
3638,"def sub_paragraph ( self , li ) : <TAB>  """"""Search for checkbox in sub-paragraph."""""" <TAB>  found = False <TAB>  if len ( li ) : <TAB><TAB>  first = list ( li ) [ 0 ] <TAB><TAB>  if first . tag == "" p "" and first . text is not None : <TAB><TAB><TAB>  m = RE_CHECKBOX . match ( first . text ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  first . text = self . markdown . htmlStash . store ( <TAB><TAB><TAB><TAB><TAB>  get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB><TAB><TAB><TAB>  ) + m . group ( "" line "" ) <TAB><TAB><TAB><TAB>  found = True <TAB>  return found ",if m is not None :,if m:,False,39.66252497583985,97.85791174505384
3639,"def list_files ( basedir ) : <TAB>  """"""List files in the directory rooted at |basedir|."""""" <TAB>  if not os . path . isdir ( basedir ) : <TAB><TAB>  raise NoSuchDirectory ( basedir ) <TAB>  directories = [ "" "" ] <TAB>  while directories : <TAB><TAB>  d = directories . pop ( ) <TAB><TAB>  for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB><TAB><TAB>  filename = os . path . join ( d , basename ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  directories . append ( filename ) <TAB><TAB><TAB>  elif os . path . exists ( os . path . join ( basedir , filename ) ) : <TAB><TAB><TAB><TAB>  yield filename ","if os . path . isdir ( os . path . join ( basedir , filename ) ) :",if os.path.exists(filename):,False,30.815578434448977,93.96049170393147
3640,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  self . set_version ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 0:,False,51.452429171598,100.00000000000004
3641,"def _dump ( self , fd ) : <TAB>  with self . no_unpicklable_properties ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d = pickle . dumps ( self ) <TAB><TAB><TAB>  module_name = os . path . basename ( sys . argv [ 0 ] ) . rsplit ( "" . "" , 1 ) [ 0 ] <TAB><TAB><TAB>  d = d . replace ( b "" c__main__ "" , b "" c "" + module_name . encode ( "" ascii "" ) ) <TAB><TAB><TAB>  fd . write ( d ) <TAB><TAB>  else : <TAB><TAB><TAB>  pickle . dump ( self , fd ) ","if self . __module__ == ""__main__"" :",if self.is_main():,False,21.615579812229363,91.78056995433796
3642,"def assert_session_stack ( classes ) : <TAB>  assert len ( _SklearnTrainingSession . _session_stack ) == len ( classes ) <TAB>  for idx , ( sess , ( parent_clazz , clazz ) ) in enumerate ( <TAB><TAB>  zip ( _SklearnTrainingSession . _session_stack , classes ) <TAB>  ) : <TAB><TAB>  assert sess . clazz == clazz <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert sess . _parent is None <TAB><TAB>  else : <TAB><TAB><TAB>  assert sess . _parent . clazz == parent_clazz ",if idx == 0 :,if idx == len(_SklearnTrainingSession._session_stack):,False,21.855470245406003,92.34939997565418
3643,"def native_color ( c ) : <TAB>  try : <TAB><TAB>  color = CACHE [ c ] <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  c = NAMED_COLOR [ c ] <TAB><TAB>  color = Color . FromArgb ( <TAB><TAB><TAB>  int ( c . rgba . a * 255 ) , int ( c . rgba . r ) , int ( c . rgba . g ) , int ( c . rgba . b ) <TAB><TAB>  ) <TAB><TAB>  CACHE [ c ] = color <TAB>  return color ","if isinstance ( c , str ) :",if c in NAMED_COLOR:,False,47.06141949060135,94.90262008453092
3644,"def callback ( name ) : <TAB>  # XXX: move into Action <TAB>  for neighbor_name in reactor . configuration . neighbors . keys ( ) : <TAB><TAB>  neighbor = reactor . configuration . neighbors . get ( neighbor_name , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  neighbor . rib . outgoing . announce_watchdog ( name ) <TAB><TAB>  yield False <TAB>  reactor . processes . answer_done ( service ) ",if not neighbor :,if neighbor is None:,False,27.769703211499202,96.23330424501098
3645,"def token_producer ( source ) : <TAB>  token = source . read_uint8 ( ) <TAB>  while token is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield DataToken ( read_data ( token , source ) ) <TAB><TAB>  elif is_small_integer ( token ) : <TAB><TAB><TAB>  yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield Token ( token ) <TAB><TAB>  token = source . read_uint8 ( ) ",if is_push_data_token ( token ) :,if is_data(token):,False,52.46455306919234,95.7037387918116
3646,"def setattr ( self , req , ino , attr , to_set , fi ) : <TAB>  print ( "" setattr: "" , ino , to_set ) <TAB>  a = self . attr [ ino ] <TAB>  for key in to_set : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Keep the old file type bit fields <TAB><TAB><TAB>  a [ "" st_mode "" ] = S_IFMT ( a [ "" st_mode "" ] ) | S_IMODE ( attr [ "" st_mode "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  a [ key ] = attr [ key ] <TAB>  self . attr [ ino ] = a <TAB>  self . reply_attr ( req , a , 1.0 ) ","if key == ""st_mode"" :",if key == ino:,False,52.64272734451821,96.44615301502648
3647,"def check_enum_exports ( module , eq_callback , only = None ) : <TAB>  """"""Make sure module exports all mnemonics from enums"""""" <TAB>  for attr in enumerate_module ( module , enum . Enum ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" SKIP "" , attr ) <TAB><TAB><TAB>  continue <TAB><TAB>  for flag , value in attr . __members__ . items ( ) : <TAB><TAB><TAB>  print ( module , flag , value ) <TAB><TAB><TAB>  eq_callback ( getattr ( module , flag ) , value ) ",if only is not None and attr not in only :,"if not hasattr(module, attr):",False,50.80135259371339,93.59757361607895
3648,"def remove_edit_vars_to ( self , n ) : <TAB>  try : <TAB><TAB>  removals = [ ] <TAB><TAB>  for v , cei in self . edit_var_map . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  removals . append ( v ) <TAB><TAB>  for v in removals : <TAB><TAB><TAB>  self . remove_edit_var ( v ) <TAB><TAB>  assert len ( self . edit_var_map ) == n <TAB>  except ConstraintNotFound : <TAB><TAB>  raise InternalError ( "" Constraint not found during internal removal "" ) ",if cei . index >= n :,if cei.state == 'edit-var':,False,52.982616989487575,96.6972834161326
3649,"def fix_repeating_arguments ( self ) : <TAB>  """"""Fix elements that should accumulate/increment values."""""" <TAB>  either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB>  for case in either : <TAB><TAB>  for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB>  if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  e . value = [ ] <TAB><TAB><TAB><TAB>  elif type ( e . value ) is not list : <TAB><TAB><TAB><TAB><TAB>  e . value = e . value . split ( ) <TAB><TAB><TAB>  if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB><TAB><TAB><TAB>  e . value = 0 <TAB>  return self ",if e . value is None :,if type(e.value) is None:,False,56.693030015143506,97.64377344788845
3650,"def add_I_prefix ( current_line : List [ str ] , ner : int , tag : str ) : <TAB>  for i in range ( 0 , len ( current_line ) ) : <TAB><TAB>  if i == 0 : <TAB><TAB><TAB>  f . write ( line_list [ i ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  f . write ( ""  I- "" + tag ) <TAB><TAB>  else : <TAB><TAB><TAB>  f . write ( "" "" + current_line [ i ] ) <TAB>  f . write ( "" \n "" ) ",elif i == ner :,if ner == 0:,False,49.18231513314538,96.24664064221243
3651,def select_word_at_cursor ( self ) : <TAB>  word_region = None <TAB>  selection = self . view . sel ( ) <TAB>  for region in selection : <TAB><TAB>  word_region = self . view . word ( region ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  selection . clear ( ) <TAB><TAB><TAB>  selection . add ( word_region ) <TAB><TAB><TAB>  return word_region <TAB>  return word_region ,if not word_region . empty ( ) :,if word_region is not None:,False,20.857880099456114,93.6871822057809
3652,"def calc ( self , arg ) : <TAB>  op = arg [ "" op "" ] <TAB>  if op == "" C "" : <TAB><TAB>  self . clear ( ) <TAB><TAB>  return str ( self . current ) <TAB>  num = decimal . Decimal ( arg [ "" num "" ] ) <TAB>  if self . op : <TAB><TAB>  if self . op == "" + "" : <TAB><TAB><TAB>  self . current + = num <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . current - = num <TAB><TAB>  elif self . op == "" * "" : <TAB><TAB><TAB>  self . current * = num <TAB><TAB>  elif self . op == "" / "" : <TAB><TAB><TAB>  self . current / = num <TAB><TAB>  self . op = op <TAB>  else : <TAB><TAB>  self . op = op <TAB><TAB>  self . current = num <TAB>  res = str ( self . current ) <TAB>  if op == "" = "" : <TAB><TAB>  self . clear ( ) <TAB>  return res ","elif self . op == ""-"" :","if self.op == "" -"":",False,30.792252252608733,99.0933509912661
3653,"def strip_pod ( lines ) : <TAB>  in_pod = False <TAB>  stripped_lines = [ ] <TAB>  for line in lines : <TAB><TAB>  if re . match ( r "" ^=(?:end|cut) "" , line ) : <TAB><TAB><TAB>  in_pod = False <TAB><TAB>  elif re . match ( r "" ^= \ w+ "" , line ) : <TAB><TAB><TAB>  in_pod = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stripped_lines . append ( line ) <TAB>  return stripped_lines ",elif not in_pod :,if in_pod:,False,16.40447511811977,97.58993337751174
3654,"def __init__ ( self , patch_files , patch_directories ) : <TAB>  files = [ ] <TAB>  files_data = { } <TAB>  for filename_data in patch_files : <TAB><TAB>  if isinstance ( filename_data , list ) : <TAB><TAB><TAB>  filename , data = filename_data <TAB><TAB>  else : <TAB><TAB><TAB>  filename = filename_data <TAB><TAB><TAB>  data = None <TAB><TAB>  if not filename . startswith ( os . sep ) : <TAB><TAB><TAB>  filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB><TAB>  files . append ( filename ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  files_data [ filename ] = data <TAB>  self . files = files <TAB>  self . files_data = files_data <TAB>  self . directories = patch_directories ",if data :,if data is not None:,False,39.9716997158,98.02692339163623
3655,"def loadPerfsFromModule ( self , module ) : <TAB>  """"""Return a suite of all perfs cases contained in the given module"""""" <TAB>  perfs = [ ] <TAB>  for name in dir ( module ) : <TAB><TAB>  obj = getattr ( module , name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  perfs . append ( self . loadPerfsFromPerfCase ( obj ) ) <TAB>  return self . suiteClass ( perfs ) ","if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :","if isinstance(obj, PerfCase):",False,32.43086606562864,88.70304095443372
3656,"def download_subtitle ( self , subtitle ) : <TAB>  if isinstance ( subtitle , XSubsSubtitle ) : <TAB><TAB>  # download the subtitle <TAB><TAB>  logger . info ( "" Downloading subtitle  %r "" , subtitle ) <TAB><TAB>  r = self . session . get ( <TAB><TAB><TAB>  subtitle . download_link , headers = { "" Referer "" : subtitle . page_link } , timeout = 10 <TAB><TAB>  ) <TAB><TAB>  r . raise_for_status ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( "" Unable to download subtitle. No data returned from provider "" ) <TAB><TAB><TAB>  return <TAB><TAB>  subtitle . content = fix_line_ending ( r . content ) ",if not r . content :,if r.status_code == 404:,False,57.90764014866265,95.34623572941625
3657,"def get_inlaws ( self , person ) : <TAB>  inlaws = [ ] <TAB>  family_handles = person . get_family_handle_list ( ) <TAB>  for handle in family_handles : <TAB><TAB>  fam = self . database . get_family_from_handle ( handle ) <TAB><TAB>  if fam . father_handle and not fam . father_handle == person . handle : <TAB><TAB><TAB>  inlaws . append ( self . database . get_person_from_handle ( fam . father_handle ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  inlaws . append ( self . database . get_person_from_handle ( fam . mother_handle ) ) <TAB>  return inlaws ",elif fam . mother_handle and not fam . mother_handle == person . handle :,if fam.mother_handle:,False,21.665465302019662,91.56458662824674
3658,"def _check_xorg_conf ( ) : <TAB>  if is_there_a_default_xorg_conf_file ( ) : <TAB><TAB>  print ( <TAB><TAB><TAB>  "" WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not "" <TAB><TAB><TAB>  ""  create it yourself, it was likely generated by your distribution or by an Nvidia utility. \n "" <TAB><TAB><TAB>  "" This file may contain hard-coded GPU configuration that could interfere with optimus-manager, "" <TAB><TAB><TAB>  ""  so it is recommended that you delete it before proceeding. \n "" <TAB><TAB><TAB>  "" Ignore this warning and proceed with GPU switching ? (y/N) "" <TAB><TAB>  ) <TAB><TAB>  confirmation = ask_confirmation ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sys . exit ( 0 ) ",if not confirmation :,if confirmation is None:,False,49.54686479673797,98.04007670246457
3659,"def _make_cache_key ( group , window , rate , value , methods ) : <TAB>  count , period = _split_rate ( rate ) <TAB>  safe_rate = "" %d / %d s "" % ( count , period ) <TAB>  parts = [ group , safe_rate , value , str ( window ) ] <TAB>  if methods is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  methods = "" "" <TAB><TAB>  elif isinstance ( methods , ( list , tuple ) ) : <TAB><TAB><TAB>  methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB><TAB>  parts . append ( methods ) <TAB>  prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB>  return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) ",if methods == ALL :,if methods == None:,False,27.02973356077204,97.24316121200508
3660,"def num_of_mapped_volumes ( self , initiator ) : <TAB>  cnt = 0 <TAB>  for lm_link in self . req ( "" lun-maps "" ) [ "" lun-maps "" ] : <TAB><TAB>  idx = lm_link [ "" href "" ] . split ( "" / "" ) [ - 1 ] <TAB><TAB>  # NOTE(geguileo): There can be races so mapped elements retrieved <TAB><TAB>  # in the listing may no longer exist. <TAB><TAB>  try : <TAB><TAB><TAB>  lm = self . req ( "" lun-maps "" , idx = int ( idx ) ) [ "" content "" ] <TAB><TAB>  except exception . NotFound : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cnt + = 1 <TAB>  return cnt ","if lm [ ""ig-name"" ] == initiator :",if lm.is_mapped():,False,61.861154805741116,93.88157903737546
3661,"def _setAbsoluteY ( self , value ) : <TAB>  if value is None : <TAB><TAB>  self . _absoluteY = None <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = 10 <TAB><TAB>  elif value == "" below "" : <TAB><TAB><TAB>  value = - 70 <TAB><TAB>  try : <TAB><TAB><TAB>  value = common . numToIntOrFloat ( value ) <TAB><TAB>  except ValueError as ve : <TAB><TAB><TAB>  raise TextFormatException ( <TAB><TAB><TAB><TAB>  f "" Not a supported absoluteY position:  { value !r} "" <TAB><TAB><TAB>  ) from ve <TAB><TAB>  self . _absoluteY = value ","if value == ""above"" :","if value == ""right':",False,18.06628214751328,96.69667690399673
3662,"def render_markdown ( text ) : <TAB>  users = { u . username . lower ( ) : u for u in get_mention_users ( text ) } <TAB>  parts = MENTION_RE . split ( text ) <TAB>  for pos , part in enumerate ( parts ) : <TAB><TAB>  if not part . startswith ( "" @ "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  username = part [ 1 : ] . lower ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  user = users [ username ] <TAB><TAB><TAB>  parts [ pos ] = ' **[ {} ]( {} "" {} "" )** ' . format ( <TAB><TAB><TAB><TAB>  part , user . get_absolute_url ( ) , user . get_visible_name ( ) <TAB><TAB><TAB>  ) <TAB>  text = "" "" . join ( parts ) <TAB>  return mark_safe ( MARKDOWN ( text ) ) ",if username in users :,if username in users:,False,53.835912553877975,100.00000000000004
3663,def start_process ( self ) : <TAB>  with self . thread_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . allow_process_request = False <TAB><TAB><TAB>  t = threading . Thread ( target = self . __start ) <TAB><TAB><TAB>  t . daemon = True <TAB><TAB><TAB>  t . start ( ) ,if self . allow_process_request :,if self.allow_process_request:,False,50.95710891747542,100.00000000000004
3664,"def close ( self ) : <TAB>  if self . _fh . closed : <TAB><TAB>  return <TAB>  self . _fh . close ( ) <TAB>  if os . path . isfile ( self . _filename ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  salt . utils . win_dacl . copy_security ( <TAB><TAB><TAB><TAB>  source = self . _filename , target = self . _tmp_filename <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  shutil . copymode ( self . _filename , self . _tmp_filename ) <TAB><TAB><TAB>  st = os . stat ( self . _filename ) <TAB><TAB><TAB>  os . chown ( self . _tmp_filename , st . st_uid , st . st_gid ) <TAB>  atomic_rename ( self . _tmp_filename , self . _filename ) ",if salt . utils . win_dacl . HAS_WIN32 :,if sys.platform == 'win32':,False,48.865556000920684,94.67093248186087
3665,"def _splitSchemaNameDotFieldName ( sn_fn , fnRequired = True ) : <TAB>  if sn_fn . find ( "" . "" ) != - 1 : <TAB><TAB>  schemaName , fieldName = sn_fn . split ( "" . "" , 1 ) <TAB><TAB>  schemaName = schemaName . strip ( ) <TAB><TAB>  fieldName = fieldName . strip ( ) <TAB><TAB>  if schemaName and fieldName : <TAB><TAB><TAB>  return ( schemaName , fieldName ) <TAB>  elif not fnRequired : <TAB><TAB>  schemaName = sn_fn . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ( schemaName , None ) <TAB>  controlflow . system_error_exit ( <TAB><TAB>  2 , f "" { sn_fn }  is not a valid custom schema.field name. "" <TAB>  ) ",if schemaName :,if not schemaName or not fieldName:,False,54.36753764891478,94.99553286613401
3666,"def modified ( self ) : <TAB>  paths = set ( ) <TAB>  dictionary_list = [ ] <TAB>  for op_list in self . _operations : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  op_list = ( op_list , ) <TAB><TAB>  for item in chain ( * op_list ) : <TAB><TAB><TAB>  if item is None : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  dictionary = item . dictionary <TAB><TAB><TAB>  if dictionary . path in paths : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  paths . add ( dictionary . path ) <TAB><TAB><TAB>  dictionary_list . append ( dictionary ) <TAB>  return dictionary_list ","if not isinstance ( op_list , list ) :","if isinstance(op_list, tuple):",False,21.391604102882976,97.47049761002422
3667,"def apply ( self , db , person ) : <TAB>  for family_handle in person . get_family_handle_list ( ) : <TAB><TAB>  family = db . get_family_from_handle ( family_handle ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for event_ref in family . get_event_ref_list ( ) : <TAB><TAB><TAB><TAB>  if event_ref : <TAB><TAB><TAB><TAB><TAB>  event = db . get_event_from_handle ( event_ref . ref ) <TAB><TAB><TAB><TAB><TAB>  if not event . get_place_handle ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB><TAB>  if not event . get_date_object ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if family :,if family:,False,51.08701841017117,100.00000000000004
3668,"def test_cleanup_params ( self , body , rpc_mock ) : <TAB>  res = self . _get_resp_post ( body ) <TAB>  self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB>  rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB>  cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB>  for key , value in body . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if value is not None : <TAB><TAB><TAB><TAB>  value = value == "" true "" <TAB><TAB>  self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB>  self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json ) ","if key in ( ""disabled"" , ""is_up"" ) :",if key == cleanup_request.method:,False,50.25471469185489,93.53403066130919
3669,"def get_billable_and_total_duration ( activity , start_time , end_time ) : <TAB>  precision = frappe . get_precision ( "" Timesheet Detail "" , "" hours "" ) <TAB>  activity_duration = time_diff_in_hours ( end_time , start_time ) <TAB>  billing_duration = 0.0 <TAB>  if activity . billable : <TAB><TAB>  billing_duration = activity . billing_hours <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  billing_duration = ( <TAB><TAB><TAB><TAB>  activity_duration * activity . billing_hours / activity . hours <TAB><TAB><TAB>  ) <TAB>  return flt ( activity_duration , precision ) , flt ( billing_duration , precision ) ",if activity_duration != activity . billing_hours :,if activity.hours > 0:,False,30.910574458359534,94.63035291769897
3670,"def cpus ( self ) : <TAB>  try : <TAB><TAB>  cpus = ( <TAB><TAB><TAB>  self . inspect [ "" Spec "" ] [ "" Resources "" ] [ "" Reservations "" ] [ "" NanoCPUs "" ] / 1000000000.0 <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cpus = int ( cpus ) <TAB><TAB>  return cpus <TAB>  except TypeError : <TAB><TAB>  return None <TAB>  except KeyError : <TAB><TAB>  return 0 ",if cpus == int ( cpus ) :,"if isinstance(cpus, int):",False,22.341585683936195,94.79229500419288
3671,"def _create_object ( self , obj_body ) : <TAB>  props = obj_body [ SYMBOL_PROPERTIES ] <TAB>  for prop_name , prop_value in props . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # get the first key as the convert function <TAB><TAB><TAB>  func_name = list ( prop_value . keys ( ) ) [ 0 ] <TAB><TAB><TAB>  if func_name . startswith ( "" _ "" ) : <TAB><TAB><TAB><TAB>  func = getattr ( self , func_name ) <TAB><TAB><TAB><TAB>  props [ prop_name ] = func ( prop_value [ func_name ] ) <TAB>  if SYMBOL_TYPE in obj_body and obj_body [ SYMBOL_TYPE ] in self . fake_func_mapping : <TAB><TAB>  return self . fake_func_mapping [ obj_body [ SYMBOL_TYPE ] ] ( * * props ) <TAB>  else : <TAB><TAB>  return props ","if isinstance ( prop_value , dict ) and prop_value :",if prop_name == 'convert':,False,46.17106536494304,94.88955515104381
3672,"def _yield_unescaped ( self , string ) : <TAB>  while "" \\ "" in string : <TAB><TAB>  finder = EscapeFinder ( string ) <TAB><TAB>  yield finder . before + finder . backslashes <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield self . _unescape ( finder . text ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield finder . text <TAB><TAB>  string = finder . after <TAB>  yield string ",if finder . escaped and finder . text :,"if not hasattr(finder, 'text'):",False,25.252679246434823,92.9569749866779
3673,"def _check_matches ( rule , matches ) : <TAB>  errors = 0 <TAB>  for match in matches : <TAB><TAB>  filematch = _match_to_test_file ( match ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  utils . error ( <TAB><TAB><TAB><TAB>  "" The match  ' {} '  for rule  ' {} '  points to a non existing test module path:  {} "" , <TAB><TAB><TAB><TAB>  match , <TAB><TAB><TAB><TAB>  rule , <TAB><TAB><TAB><TAB>  filematch , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  errors + = 1 <TAB>  return errors ",if not filematch . exists ( ) :,if filematch is not None:,False,33.2083422603774,96.04698657450191
3674,"def focused_windows ( ) : <TAB>  tree = i3 . get_tree ( ) <TAB>  workspaces = tree . workspaces ( ) <TAB>  for workspace in workspaces : <TAB><TAB>  container = workspace <TAB><TAB>  while container : <TAB><TAB><TAB>  if not hasattr ( container , "" focus "" ) or not container . focus : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  container_id = container . focus [ 0 ] <TAB><TAB><TAB>  container = container . find_by_id ( container_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  coname = container . name <TAB><TAB><TAB>  wsname = workspace . name <TAB><TAB><TAB>  print ( "" WS "" , wsname + "" : "" , coname ) ",if container :,if container:,False,50.96176390284586,100.00000000000004
3675,"def normals ( self , value ) : <TAB>  if value is not None : <TAB><TAB>  value = np . asanyarray ( value , dtype = np . float32 ) <TAB><TAB>  value = np . ascontiguousarray ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Incorrect normals shape "" ) <TAB>  self . _normals = value ",if value . shape != self . positions . shape :,if len(self._normals) != 2:,False,32.38702118846051,89.33256209098931
3676,"def test_hexdigest ( self ) : <TAB>  for cons in self . hash_constructors : <TAB><TAB>  h = cons ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIsInstance ( h . digest ( 16 ) , bytes ) <TAB><TAB><TAB>  self . assertEqual ( hexstr ( h . digest ( 16 ) ) , h . hexdigest ( 16 ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertIsInstance ( h . digest ( ) , bytes ) <TAB><TAB><TAB>  self . assertEqual ( hexstr ( h . digest ( ) ) , h . hexdigest ( ) ) ",if h . name in self . shakes :,if h.is_hex:,False,23.233458190489838,95.76112119454383
3677,"def _get_cluster_status ( self ) : <TAB>  try : <TAB><TAB>  return ( <TAB><TAB><TAB>  self . dataproc_client . projects ( ) <TAB><TAB><TAB>  . regions ( ) <TAB><TAB><TAB>  . clusters ( ) <TAB><TAB><TAB>  . get ( <TAB><TAB><TAB><TAB>  projectId = self . gcloud_project_id , <TAB><TAB><TAB><TAB>  region = self . dataproc_region , <TAB><TAB><TAB><TAB>  clusterName = self . dataproc_cluster_name , <TAB><TAB><TAB><TAB>  fields = "" status "" , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  . execute ( ) <TAB><TAB>  ) <TAB>  except HttpError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None<TAB># We got a 404 so the cluster doesn't exist <TAB><TAB>  else : <TAB><TAB><TAB>  raise e ",if e . resp . status == 404 :,if e.code == 404:,False,36.352640292282416,97.25234474806902
3678,"def _items_from ( self , context ) : <TAB>  self . _context = context <TAB>  if self . _is_local_variable ( self . _keyword_name , context ) : <TAB><TAB>  for item in self . _items_from_controller ( context ) : <TAB><TAB><TAB>  yield item <TAB>  else : <TAB><TAB>  for df in context . datafiles : <TAB><TAB><TAB>  self . _yield_for_other_threads ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for item in self . _items_from_datafile ( df ) : <TAB><TAB><TAB><TAB><TAB>  yield item ",if self . _items_from_datafile_should_be_checked ( df ) :,"if self._is_local_variable(self._keyword_name, df):",False,50.10442215498663,92.8322538505888
3679,"def Command ( argv , funcs , path_val ) : <TAB>  arg , i = COMMAND_SPEC . Parse ( argv ) <TAB>  status = 0 <TAB>  if arg . v : <TAB><TAB>  for kind , arg in _ResolveNames ( argv [ i : ] , funcs , path_val ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  status = 1<TAB># nothing printed, but we fail <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # This is for -v, -V is more detailed. <TAB><TAB><TAB><TAB>  print ( arg ) <TAB>  else : <TAB><TAB>  util . warn ( "" *** command without -v not not implemented *** "" ) <TAB><TAB>  status = 1 <TAB>  return status ",if kind is None :,if kind == 'v':,False,51.826177957293716,95.49805407418161
3680,"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB>  index = index or INDEX <TAB>  if not category : <TAB><TAB>  if isinstance ( node , Preprint ) : <TAB><TAB><TAB>  category = "" preprint "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  category = "" registration "" <TAB><TAB>  else : <TAB><TAB><TAB>  category = node . project_or_component <TAB>  client ( ) . delete ( <TAB><TAB>  index = index , <TAB><TAB>  doc_type = category , <TAB><TAB>  id = elastic_document_id , <TAB><TAB>  refresh = True , <TAB><TAB>  ignore = [ 404 ] , <TAB>  ) ",elif node . is_registration :,"if isinstance(node, Registration):",False,50.836003682764776,95.61520457514102
3681,"def getDictFromTree ( tree ) : <TAB>  ret_dict = { } <TAB>  for child in tree . getchildren ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ## Complex-type child. Recurse <TAB><TAB><TAB>  content = getDictFromTree ( child ) <TAB><TAB>  else : <TAB><TAB><TAB>  content = child . text <TAB><TAB>  if ret_dict . has_key ( child . tag ) : <TAB><TAB><TAB>  if not type ( ret_dict [ child . tag ] ) == list : <TAB><TAB><TAB><TAB>  ret_dict [ child . tag ] = [ ret_dict [ child . tag ] ] <TAB><TAB><TAB>  ret_dict [ child . tag ] . append ( content or "" "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  ret_dict [ child . tag ] = content or "" "" <TAB>  return ret_dict ",if child . getchildren ( ) :,"if isinstance(child, (int, long)):",False,49.205991837183035,95.72841613064065
3682,"def get ( self , block = True , timeout = None , ack = False ) : <TAB>  if not block : <TAB><TAB>  return self . get_nowait ( ) <TAB>  start_time = time . time ( ) <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  return self . get_nowait ( ack ) <TAB><TAB>  except BaseQueue . Empty : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  lasted = time . time ( ) - start_time <TAB><TAB><TAB><TAB>  if timeout > lasted : <TAB><TAB><TAB><TAB><TAB>  time . sleep ( min ( self . max_timeout , timeout - lasted ) ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  time . sleep ( self . max_timeout ) ",if timeout :,if timeout is not None:,False,50.08303091646113,98.14104111698232
3683,"def rewrite ( self , string ) : <TAB>  string = super ( JSReplaceFuzzy , self ) . rewrite ( string ) <TAB>  cdx = self . url_rewriter . rewrite_opts [ "" cdx "" ] <TAB>  if cdx . get ( "" is_fuzzy "" ) : <TAB><TAB>  expected = unquote ( cdx [ "" url "" ] ) <TAB><TAB>  actual = unquote ( self . url_rewriter . wburl . url ) <TAB><TAB>  exp_m = self . rx_obj . search ( expected ) <TAB><TAB>  act_m = self . rx_obj . search ( actual ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = string . replace ( exp_m . group ( 1 ) , act_m . group ( 1 ) ) <TAB><TAB><TAB>  if result != string : <TAB><TAB><TAB><TAB>  string = result <TAB>  return string ",if exp_m and act_m :,if exp_m:,False,32.28370885576984,98.03170497609038
3684,"def locate_exe_dir ( d , check = True ) : <TAB>  exe_dir = os . path . join ( d , "" Scripts "" ) if ON_WINDOWS else os . path . join ( d , "" bin "" ) <TAB>  if not os . path . isdir ( exe_dir ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bin_dir = os . path . join ( d , "" bin "" ) <TAB><TAB><TAB>  if os . path . isdir ( bin_dir ) : <TAB><TAB><TAB><TAB>  return bin_dir <TAB><TAB>  if check : <TAB><TAB><TAB>  raise InvalidVirtualEnv ( "" Unable to locate executables directory. "" ) <TAB>  return exe_dir ",if ON_WINDOWS :,if os.name == 'nt':,False,46.32769427326694,95.76826189594742
3685,"def _ensuresyspath ( self , ensuremode , path ) : <TAB>  if ensuremode : <TAB><TAB>  s = str ( path ) <TAB><TAB>  if ensuremode == "" append "" : <TAB><TAB><TAB>  if s not in sys . path : <TAB><TAB><TAB><TAB>  sys . path . append ( s ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sys . path . insert ( 0 , s ) ",if s != sys . path [ 0 ] :,"if ensuremode == ""append':",False,48.110074733150334,91.99382113207326
3686,"def create_season_banners ( self , show_obj ) : <TAB>  if self . season_banners and show_obj : <TAB><TAB>  result = [ ] <TAB><TAB>  for season , episodes in show_obj . episodes . iteritems ( ) :<TAB># @UnusedVariable <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  logger . log ( <TAB><TAB><TAB><TAB><TAB>  u "" Metadata provider  "" <TAB><TAB><TAB><TAB><TAB>  + self . name <TAB><TAB><TAB><TAB><TAB>  + ""  creating season banners for  "" <TAB><TAB><TAB><TAB><TAB>  + show_obj . name , <TAB><TAB><TAB><TAB><TAB>  logger . DEBUG , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  result = result + [ self . save_season_banners ( show_obj , season ) ] <TAB><TAB>  return all ( result ) <TAB>  return False ","if not self . _has_season_banner ( show_obj , season ) :",if season == self.season_banners and (not episodes):,False,53.85858337148382,94.06363889092245
3687,"def validate_nb ( self , nb ) : <TAB>  super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB>  ids = set ( [ ] ) <TAB>  for cell in nb . cells : <TAB><TAB>  if "" nbgrader "" not in cell . metadata : <TAB><TAB><TAB>  continue <TAB><TAB>  grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB><TAB>  solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB><TAB>  locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB><TAB>  if grade_id in ids : <TAB><TAB><TAB>  raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB><TAB>  ids . add ( grade_id ) ",if not grade and not solution and not locked :,if locked:,False,28.749082744260757,96.42329767280673
3688,"def read_version ( ) : <TAB>  regexp = re . compile ( r "" ^__version__ \ W*= \ W* ' ([ \ d.abrc]+) ' "" ) <TAB>  init_py = os . path . join ( os . path . dirname ( __file__ ) , "" aiopg "" , "" __init__.py "" ) <TAB>  with open ( init_py ) as f : <TAB><TAB>  for line in f : <TAB><TAB><TAB>  match = regexp . match ( line ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return match . group ( 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise RuntimeError ( "" Cannot find version in aiopg/__init__.py "" ) ",if match is not None :,if match:,False,21.65159052342443,97.66929530254585
3689,"def _column_keys ( self ) : <TAB>  """"""Get a dictionary of all columns and their case mapping."""""" <TAB>  if not self . exists : <TAB><TAB>  return { } <TAB>  with self . db . lock : <TAB><TAB>  if self . _columns is None : <TAB><TAB><TAB>  # Initialise the table if it doesn't exist <TAB><TAB><TAB>  table = self . table <TAB><TAB><TAB>  self . _columns = { } <TAB><TAB><TAB>  for column in table . columns : <TAB><TAB><TAB><TAB>  name = normalize_column_name ( column . name ) <TAB><TAB><TAB><TAB>  key = normalize_column_key ( name ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  log . warning ( "" Duplicate column:  %s "" , name ) <TAB><TAB><TAB><TAB>  self . _columns [ key ] = name <TAB><TAB>  return self . _columns ",if key in self . _columns :,if key in self._columns:,False,60.76131726660603,100.00000000000004
3690,"def find_controller_by_names ( self , names , testname ) : <TAB>  namestring = "" . "" . join ( names ) <TAB>  if not namestring . startswith ( self . name ) : <TAB><TAB>  return None <TAB>  if namestring == self . name : <TAB><TAB>  return self <TAB>  for suite in self . suites : <TAB><TAB>  res = suite . find_controller_by_names ( <TAB><TAB><TAB>  namestring [ len ( self . name ) + 1 : ] . split ( "" . "" ) , testname <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return res ",if res :,if res is not None:,False,33.94494340608901,97.11656816119613
3691,"def _volume_x_metadata_get_item ( <TAB>  context , volume_id , key , model , notfound_exec , session = None  ) : <TAB>  result = ( <TAB><TAB>  _volume_x_metadata_get_query ( context , volume_id , model , session = session ) <TAB><TAB>  . filter_by ( key = key ) <TAB><TAB>  . first ( ) <TAB>  ) <TAB>  if not result : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise notfound_exec ( id = volume_id ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise notfound_exec ( metadata_key = key , volume_id = volume_id ) <TAB>  return result ",if model is models . VolumeGlanceMetadata :,if not found_exec:,False,32.67750573733264,96.33478260016055
3692,"def parse_results ( cwd ) : <TAB>  optimal_dd = None <TAB>  optimal_measure = numpy . inf <TAB>  for tup in tools . find_conf_files ( cwd ) : <TAB><TAB>  dd = tup [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB><TAB><TAB><TAB>  optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB><TAB><TAB><TAB>  optimal_dd = dd <TAB>  print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB>  for key , value in optimal_dd . items ( ) : <TAB><TAB>  if "" hyper_parameters "" in key : <TAB><TAB><TAB>  print ( key + "" :  "" + str ( value ) ) ","if ""results.train_y_misclass"" in dd :",if dd['results.train_y_misclass'] > optimal_measure:,False,22.5541685042294,94.7530186480347
3693,"def _stop_by_max_time_mins ( self ) : <TAB>  """"""Stop optimization process once maximum minutes have elapsed."""""" <TAB>  if self . max_time_mins : <TAB><TAB>  total_mins_elapsed = ( <TAB><TAB><TAB>  datetime . now ( ) - self . _start_datetime <TAB><TAB>  ) . total_seconds ( ) / 60.0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise KeyboardInterrupt ( <TAB><TAB><TAB><TAB>  "" {:.2f}  minutes have elapsed. TPOT will close down. "" . format ( <TAB><TAB><TAB><TAB><TAB>  total_mins_elapsed <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) ",if total_mins_elapsed >= self . max_time_mins :,if total_mins_elapsed < self.max_mins_elapsed:,False,61.04061769298856,96.36581019153016
3694,"def __new__ ( meta , cls_name , bases , cls_dict ) : <TAB>  func = cls_dict . get ( "" func "" ) <TAB>  monad_cls = super ( FuncMonadMeta , meta ) . __new__ ( meta , cls_name , bases , cls_dict ) <TAB>  if func : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  functions = func <TAB><TAB>  else : <TAB><TAB><TAB>  functions = ( func , ) <TAB><TAB>  for func in functions : <TAB><TAB><TAB>  registered_functions [ func ] = monad_cls <TAB>  return monad_cls ",if type ( func ) is tuple :,"if isinstance(func, type):",False,47.87818872884719,96.00461169047989
3695,"def get_tokens_unprocessed ( self , text ) : <TAB>  buffered = "" "" <TAB>  insertions = [ ] <TAB>  lng_buffer = [ ] <TAB>  for i , t , v in self . language_lexer . get_tokens_unprocessed ( text ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if lng_buffer : <TAB><TAB><TAB><TAB>  insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB><TAB><TAB><TAB>  lng_buffer = [ ] <TAB><TAB><TAB>  buffered + = v <TAB><TAB>  else : <TAB><TAB><TAB>  lng_buffer . append ( ( i , t , v ) ) <TAB>  if lng_buffer : <TAB><TAB>  insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB>  return do_insertions ( insertions , self . root_lexer . get_tokens_unprocessed ( buffered ) ) ",if t is self . needle :,if i == -1:,False,32.87571315064582,97.15346704144665
3696,"def get_conditions ( filters ) : <TAB>  conditions = { "" docstatus "" : ( "" = "" , 1 ) } <TAB>  if filters . get ( "" from_date "" ) and filters . get ( "" to_date "" ) : <TAB><TAB>  conditions [ "" result_date "" ] = ( <TAB><TAB><TAB>  "" between "" , <TAB><TAB><TAB>  ( filters . get ( "" from_date "" ) , filters . get ( "" to_date "" ) ) , <TAB><TAB>  ) <TAB><TAB>  filters . pop ( "" from_date "" ) <TAB><TAB>  filters . pop ( "" to_date "" ) <TAB>  for key , value in filters . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  conditions [ key ] = value <TAB>  return conditions ",if filters . get ( key ) :,if key not in conditions:,False,46.74598698563604,96.36120633344531
3697,"def _limit_value ( key , value , config ) : <TAB>  if config [ key ] . get ( "" upper_limit "" ) : <TAB><TAB>  limit = config [ key ] [ "" upper_limit "" ] <TAB><TAB>  # auto handle datetime <TAB><TAB>  if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if ( datetime . now ( ) - limit ) > value : <TAB><TAB><TAB><TAB><TAB>  value = datetime . now ( ) - limit <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  if ( datetime . now ( ) + limit ) < value : <TAB><TAB><TAB><TAB><TAB>  value = datetime . now ( ) + limit <TAB><TAB>  elif value > limit : <TAB><TAB><TAB>  value = limit <TAB>  return value ","if config [ key ] [ ""inverse"" ] is True :","if isinstance(value, datetime):",False,50.64926094184465,94.74689047659037
3698,"def GetCurrentKeySet ( self ) : <TAB>  "" Return CurrentKeys with  ' darwin '  modifications. "" <TAB>  result = self . GetKeySet ( self . CurrentKeys ( ) ) <TAB>  if sys . platform == "" darwin "" : <TAB><TAB>  # macOS (OS X) Tk variants do not support the ""Alt"" <TAB><TAB>  # keyboard modifier.  Replace it with ""Option"". <TAB><TAB>  # TODO (Ned?): the ""Option"" modifier does not work properly <TAB><TAB>  #<TAB> for Cocoa Tk and XQuartz Tk so we should not use it <TAB><TAB>  #<TAB> in the default 'OSX' keyset. <TAB><TAB>  for k , v in result . items ( ) : <TAB><TAB><TAB>  v2 = [ x . replace ( "" <Alt- "" , "" <Option- "" ) for x in v ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ k ] = v2 <TAB>  return result ",if v != v2 :,if v2:,False,68.34777400356174,96.91491605359852
3699,"def _load_testfile ( filename , package , module_relative ) : <TAB>  if module_relative : <TAB><TAB>  package = _normalize_module ( package , 3 ) <TAB><TAB>  filename = _module_relative_path ( package , filename ) <TAB><TAB>  if hasattr ( package , "" __loader__ "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  file_contents = package . __loader__ . get_data ( filename ) <TAB><TAB><TAB><TAB>  # get_data() opens files as 'rb', so one must do the equivalent <TAB><TAB><TAB><TAB>  # conversion as universal newlines would do. <TAB><TAB><TAB><TAB>  return file_contents . replace ( os . linesep , "" \n "" ) , filename <TAB>  return open ( filename ) . read ( ) , filename ","if hasattr ( package . __loader__ , ""get_data"" ) :","if hasattr(package, '__loader__'):",False,57.26842686497295,95.69796415449876
3700,"def iter_from_X_lengths ( X , lengths ) : <TAB>  if lengths is None : <TAB><TAB>  yield 0 , len ( X ) <TAB>  else : <TAB><TAB>  n_samples = X . shape [ 0 ] <TAB><TAB>  end = np . cumsum ( lengths ) . astype ( np . int32 ) <TAB><TAB>  start = end - lengths <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" more than  {:d}  samples in lengths array  {!s} "" . format ( <TAB><TAB><TAB><TAB><TAB>  n_samples , lengths <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  for i in range ( len ( lengths ) ) : <TAB><TAB><TAB>  yield start [ i ] , end [ i ] ",if end [ - 1 ] > n_samples :,if n_samples > 1:,False,33.830089231398304,96.53509372266605
3701,"def change_sel ( self ) : <TAB>  """"""Change the view's selections."""""" <TAB>  if self . alter_select and len ( self . sels ) > 0 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . view . show ( self . sels [ 0 ] ) <TAB><TAB>  self . view . sel ( ) . clear ( ) <TAB><TAB>  self . view . sel ( ) . add_all ( self . sels ) ",if self . multi_select is False :,if len(self.sels) == 1:,False,23.951638158540327,91.67010448905464
3702,"def cb_syncthing_device_data_changed ( <TAB>  self , daemon , nid , address , client_version , inbps , outbps , inbytes , outbytes  ) : <TAB>  if nid in self . devices :<TAB># Should be always <TAB><TAB>  device = self . devices [ nid ] <TAB><TAB>  # Update strings <TAB><TAB>  device [ "" address "" ] = address <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  device [ "" version "" ] = client_version <TAB><TAB>  # Update rates <TAB><TAB>  device [ "" inbps "" ] = "" %s /s ( %s ) "" % ( sizeof_fmt ( inbps ) , sizeof_fmt ( inbytes ) ) <TAB><TAB>  device [ "" outbps "" ] = "" %s /s ( %s ) "" % ( sizeof_fmt ( outbps ) , sizeof_fmt ( outbytes ) ) ","if client_version not in ( ""?"" , None ) :",if client_version:,False,45.048728032466116,94.26757211986678
3703,"def then ( self , matches , when_response , context ) : <TAB>  if is_iterable ( when_response ) : <TAB><TAB>  ret = [ ] <TAB><TAB>  when_response = list ( when_response ) <TAB><TAB>  for match in when_response : <TAB><TAB><TAB>  if match not in matches : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  match . name = self . match_name <TAB><TAB><TAB><TAB>  matches . append ( match ) <TAB><TAB><TAB><TAB>  ret . append ( match ) <TAB><TAB>  return ret <TAB>  <IF-STMT>: <TAB><TAB>  when_response . name = self . match_name <TAB>  if when_response not in matches : <TAB><TAB>  matches . append ( when_response ) <TAB><TAB>  return when_response ",if self . match_name :,"if isinstance(match, Match):",False,46.08915036103723,93.97153401697855
3704,"def __update_parents ( self , fileobj , path , delta ) : <TAB>  """"""Update all parent atoms with the new size."""""" <TAB>  if delta == 0 : <TAB><TAB>  return <TAB>  for atom in path : <TAB><TAB>  fileobj . seek ( atom . offset ) <TAB><TAB>  size = cdata . uint_be ( fileobj . read ( 4 ) ) <TAB><TAB>  <IF-STMT>:<TAB># 64bit <TAB><TAB><TAB>  # skip name (4B) and read size (8B) <TAB><TAB><TAB>  size = cdata . ulonglong_be ( fileobj . read ( 12 ) [ 4 : ] ) <TAB><TAB><TAB>  fileobj . seek ( atom . offset + 8 ) <TAB><TAB><TAB>  fileobj . write ( cdata . to_ulonglong_be ( size + delta ) ) <TAB><TAB>  else :<TAB># 32bit <TAB><TAB><TAB>  fileobj . seek ( atom . offset ) <TAB><TAB><TAB>  fileobj . write ( cdata . to_uint_be ( size + delta ) ) ",if size == 1 :,if size < 8:,False,57.58268494153632,95.42699459359604
3705,"def _fields_to_index ( cls ) : <TAB>  fields = [ ] <TAB>  for field in cls . _meta . sorted_fields : <TAB><TAB>  if field . primary_key : <TAB><TAB><TAB>  continue <TAB><TAB>  requires_index = any ( <TAB><TAB><TAB>  ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fields . append ( field ) <TAB>  return fields ",if requires_index :,if requires_index:,False,51.21333254586228,100.00000000000004
3706,"def __init__ ( self , value ) : <TAB>  """"""Initialize the integer to the given value."""""" <TAB>  self . _mpz_p = new_mpz ( ) <TAB>  self . _initialized = False <TAB>  if isinstance ( value , float ) : <TAB><TAB>  raise ValueError ( "" A floating point type is not a natural number "" ) <TAB>  self . _initialized = True <TAB>  if isinstance ( value , ( int , long ) ) : <TAB><TAB>  _gmp . mpz_init ( self . _mpz_p ) <TAB><TAB>  result = _gmp . gmp_sscanf ( tobytes ( str ( value ) ) , b ( "" % Zd "" ) , self . _mpz_p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Error converting  ' %d ' "" % value ) <TAB>  else : <TAB><TAB>  _gmp . mpz_init_set ( self . _mpz_p , value . _mpz_p ) ",if result != 1 :,if result < 0:,False,58.18050465194293,96.99261612593244
3707,"def decode ( cls , data ) : <TAB>  while data : <TAB><TAB>  length , format_type , control_flags , sequence , pid = unpack ( <TAB><TAB><TAB>  cls . Header . PACK , data [ : cls . Header . LEN ] <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise NetLinkError ( "" Buffer underrun "" ) <TAB><TAB>  yield cls . format ( <TAB><TAB><TAB>  format_type , control_flags , sequence , pid , data [ cls . Header . LEN : length ] <TAB><TAB>  ) <TAB><TAB>  data = data [ length : ] ",if len ( data ) < length :,if length < cls.Header.LEN:,False,23.310007033804986,94.96865180176485
3708,"def __post_init__ ( self ) : <TAB>  if self . _node_id is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" invalid node_id:  {} "" . format ( hexlify ( self . _node_id ) . decode ( ) ) <TAB><TAB><TAB>  ) <TAB>  if self . udp_port is not None and not 1 < = self . udp_port < = 65535 : <TAB><TAB>  raise ValueError ( "" invalid udp port "" ) <TAB>  if self . tcp_port is not None and not 1 < = self . tcp_port < = 65535 : <TAB><TAB>  raise ValueError ( "" invalid tcp port "" ) <TAB>  if not is_valid_public_ipv4 ( self . address , self . allow_localhost ) : <TAB><TAB>  raise ValueError ( f "" invalid ip address:  ' { self . address } ' "" ) ",if not len ( self . _node_id ) == constants . HASH_LENGTH :,if self._node_id != self._node_id:,False,23.217098842856913,94.45064440004063
3709,"def orderUp ( self , items ) : <TAB>  sel = [ ]<TAB># new selection <TAB>  undoinfo = [ ] <TAB>  for bid , lid in items : <TAB><TAB>  if isinstance ( lid , int ) : <TAB><TAB><TAB>  undoinfo . append ( self . orderUpLineUndo ( bid , lid ) ) <TAB><TAB><TAB>  sel . append ( ( bid , lid - 1 ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  undoinfo . append ( self . orderUpBlockUndo ( bid ) ) <TAB><TAB><TAB>  if bid == 0 : <TAB><TAB><TAB><TAB>  return items <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  sel . append ( ( bid - 1 , None ) ) <TAB>  self . addUndo ( undoinfo , "" Move Up "" ) <TAB>  return sel ",elif lid is None :,if bid > 0:,False,12.183700824006385,95.16837632217761
3710,"def filter_data ( self , min_len , max_len ) : <TAB>  logging . info ( f "" filtering data, min len:  { min_len } , max len:  { max_len } "" ) <TAB>  initial_len = len ( self . src ) <TAB>  filtered_src = [ ] <TAB>  filtered_tgt = [ ] <TAB>  for src , tgt in zip ( self . src , self . tgt ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filtered_src . append ( src ) <TAB><TAB><TAB>  filtered_tgt . append ( tgt ) <TAB>  self . src = filtered_src <TAB>  self . tgt = filtered_tgt <TAB>  filtered_len = len ( self . src ) <TAB>  logging . info ( f "" pairs before:  { initial_len } , after:  { filtered_len } "" ) ",if min_len <= len ( src ) <= max_len and min_len <= len ( tgt ) <= max_len :,if src != tgt:,False,25.81748626952019,86.31762289370424
3711,"def layer_pretrained ( self , net , args , options ) : <TAB>  model = getattr ( torchvision . models , args [ 0 ] ) ( pretrained = True ) <TAB>  model . train ( True ) <TAB>  if options . layer : <TAB><TAB>  layers = list ( model . children ( ) ) [ : options . layer ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  layers [ - 1 ] = nn . Sequential ( * layers [ - 1 ] [ : options . sublayer ] ) <TAB>  else : <TAB><TAB>  layers = [ model ] <TAB><TAB>  print ( "" List of pretrained layers: "" , layers ) <TAB><TAB>  raise ValidationException ( <TAB><TAB><TAB>  "" layer=-1 required for pretrained, sublayer=-1 optional.  Layers outputted above. "" <TAB><TAB>  ) <TAB>  return nn . Sequential ( * layers ) ",if options . sublayer :,if options.sublayer:,False,57.0156559547478,96.54758455133727
3712,"def deleteCalendar ( users ) : <TAB>  calendarId = normalizeCalendarId ( sys . argv [ 5 ] ) <TAB>  for user in users : <TAB><TAB>  user , cal = buildCalendarGAPIObject ( user ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  gapi . call ( cal . calendarList ( ) , "" delete "" , soft_errors = True , calendarId = calendarId ) ",if not cal :,if cal is None:,False,21.278101226605855,95.32060299795891
3713,"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB>  """"""iterate over all modules"""""" <TAB>  clients = None <TAB>  if by_clients : <TAB><TAB>  clients = self . get_clients ( clients_filter ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB>  self . _refresh_modules ( ) <TAB>  for module_name in self . modules : <TAB><TAB>  try : <TAB><TAB><TAB>  module = self . get_module ( module_name ) <TAB><TAB>  except PupyModuleDisabled : <TAB><TAB><TAB>  continue <TAB><TAB>  if clients is not None : <TAB><TAB><TAB>  for client in clients : <TAB><TAB><TAB><TAB>  if module . is_compatible_with ( client ) : <TAB><TAB><TAB><TAB><TAB>  yield module <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  yield module ",if not clients :,if clients is None:,False,26.575172070506483,98.3453222386506
3714,"def update_me ( self ) : <TAB>  try : <TAB><TAB>  while 1 : <TAB><TAB><TAB>  line = self . queue . get_nowait ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . delete ( 1.0 , tk . END ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . insert ( tk . END , str ( line ) ) <TAB><TAB><TAB>  self . see ( tk . END ) <TAB><TAB><TAB>  self . update_idletasks ( ) <TAB>  except queue . Empty : <TAB><TAB>  pass <TAB>  self . after ( 100 , self . update_me ) ",if line is None :,if line is None:,False,51.366762356996574,100.00000000000004
3715,"def request_power_state ( self , state , force = False ) : <TAB>  if self . current_state != state or force : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . request_in_progress = True <TAB><TAB><TAB>  logging . info ( "" Requesting  %s "" % state ) <TAB><TAB><TAB>  cb = PowerManager . Callback ( self , state ) <TAB><TAB><TAB>  rets = self . parent . Plugins . run ( <TAB><TAB><TAB><TAB>  "" on_power_state_change_requested "" , self , state , cb <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  cb . num_cb = len ( rets ) <TAB><TAB><TAB>  cb . check ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  logging . info ( "" Another request in progress "" ) ",if not self . request_in_progress :,if self.current_state == state:,False,48.11896791634781,96.16895573610937
3716,"def __getitem__ ( self , idx ) : <TAB>  super ( BatchDataset , self ) . __getitem__ ( idx ) <TAB>  maxidx = len ( self . dataset ) <TAB>  samples = [ ] <TAB>  for i in range ( 0 , self . batchsize ) : <TAB><TAB>  j = idx * self . batchsize + i <TAB><TAB>  if j > = maxidx : <TAB><TAB><TAB>  break <TAB><TAB>  j = self . perm ( j , maxidx ) <TAB><TAB>  sample = self . dataset [ j ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  samples . append ( sample ) <TAB>  samples = self . makebatch ( samples ) <TAB>  return samples ",if self . filter ( sample ) :,if sample:,False,24.880341905649697,95.79559151961872
3717,"def __call__ ( self , request , * args , * * kwargs ) : <TAB>  template_vars = { } <TAB>  for form_name , form_class in self . forms . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  template_vars [ form_name ] = form_class ( request ) <TAB><TAB>  else : <TAB><TAB><TAB>  template_vars [ form_name ] = None <TAB>  if request . method == "" POST "" : <TAB><TAB>  action = self . find_post_handler_action ( request ) <TAB><TAB>  form = self . handlers [ action ] ( request , data = request . POST , files = request . FILES ) <TAB><TAB>  template_vars . update ( form . dispatch ( action , request , * args , * * kwargs ) ) <TAB>  return self . GET ( template_vars , request , * args , * * kwargs ) ","if form_class . must_display ( request , * args , ** kwargs ) :",if form_class is not None:,False,42.46256129826318,93.27862852385599
3718,"def on_show_all ( self , widget , another ) : <TAB>  if widget . get_active ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . treeview . update_items ( all = True , comment = True ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . treeview . update_items ( all = True ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . treeview . update_items ( comment = True ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . treeview . update_items ( ) ",if another . get_active ( ) :,if widget.get_active():,False,22.920246622186287,92.48374919524173
3719,"def close ( self ) : <TAB>  if self . _closed : <TAB><TAB>  return <TAB>  self . _closed = True <TAB>  for proto in self . _pipes . values ( ) : <TAB><TAB>  if proto is None : <TAB><TAB><TAB>  continue <TAB><TAB>  proto . pipe . close ( ) <TAB>  if ( <TAB><TAB>  self . _proc is not None <TAB><TAB>  and <TAB><TAB>  # has the child process finished? <TAB><TAB>  self . _returncode is None <TAB><TAB>  and <TAB><TAB>  # the child process has finished, but the <TAB><TAB>  # transport hasn't been notified yet? <TAB><TAB>  self . _proc . poll ( ) is None <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( "" Close running child process: kill  %r "" , self ) <TAB><TAB>  try : <TAB><TAB><TAB>  self . _proc . kill ( ) <TAB><TAB>  except ProcessLookupError : <TAB><TAB><TAB>  pass ",if self . _loop . get_debug ( ) :,if self._proc is not None:,False,60.3400651919068,96.87810330349498
3720,"def runTest ( self ) : <TAB>  self . poco ( text = "" wait UI "" ) . click ( ) <TAB>  bomb_count = 0 <TAB>  while True : <TAB><TAB>  blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB><TAB>  yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB><TAB>  bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB><TAB>  fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB><TAB>  if fish is bomb : <TAB><TAB><TAB>  bomb_count + = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB>  else : <TAB><TAB><TAB>  fish . click ( ) <TAB><TAB>  time . sleep ( 2.5 ) ",if bomb_count > 3 :,if bomb_count == 0:,False,22.74536668857677,98.08568155741771
3721,"def load_managers ( * , loop , only ) : <TAB>  managers = { } <TAB>  for key in DB_CLASSES : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  params = DB_DEFAULTS . get ( key ) or { } <TAB><TAB>  params . update ( DB_OVERRIDES . get ( key ) or { } ) <TAB><TAB>  database = DB_CLASSES [ key ] ( * * params ) <TAB><TAB>  managers [ key ] = peewee_async . Manager ( database , loop = loop ) <TAB>  return managers ",if only and key not in only :,if key in only:,False,45.226245523693585,96.222066755312
3722,"def links_extracted ( self , request , links ) : <TAB>  for link in links : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r = self . _create_request ( link . url ) <TAB><TAB><TAB>  r . meta [ b "" depth "" ] = request . meta [ b "" depth "" ] + 1 <TAB><TAB><TAB>  self . schedule ( r , self . _get_score ( r . meta [ b "" depth "" ] ) ) <TAB><TAB><TAB>  link . meta [ b "" state "" ] = States . QUEUED ","if link . meta [ b""state"" ] == States . NOT_CRAWLED :",if link.state == States.RUNNING:,False,18.304025722601992,91.35444957993235
3723,"def find_worktree_git_dir ( dotgit ) : <TAB>  """"""Search for a gitdir for this worktree."""""" <TAB>  try : <TAB><TAB>  statbuf = os . stat ( dotgit ) <TAB>  except OSError : <TAB><TAB>  return None <TAB>  if not stat . S_ISREG ( statbuf . st_mode ) : <TAB><TAB>  return None <TAB>  try : <TAB><TAB>  lines = open ( dotgit , "" r "" ) . readlines ( ) <TAB><TAB>  for key , value in [ line . strip ( ) . split ( "" :  "" ) for line in lines ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return value <TAB>  except ValueError : <TAB><TAB>  pass <TAB>  return None ","if key == ""gitdir"" :",if key == 'worktree':,False,56.36471463348796,97.6351777191462
3724,"def _is_static_shape ( self , shape ) : <TAB>  if shape is None or not isinstance ( shape , list ) : <TAB><TAB>  return False <TAB>  for dim_value in shape : <TAB><TAB>  if not isinstance ( dim_value , int ) : <TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB>  return True ",if dim_value < 0 :,if dim_value < 0 or dim_value > 1:,False,30.538764647494354,93.91351954647233
3725,"def init_logger ( ) : <TAB>  configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB><TAB>  logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB>  ] <TAB>  used_handlers = { <TAB><TAB>  handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB>  } <TAB>  for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB><TAB>  if handler_id not in used_handlers : <TAB><TAB><TAB>  del log_config [ "" handlers "" ] [ handler_id ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename = handler [ "" filename "" ] <TAB><TAB><TAB>  logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB><TAB><TAB>  handler [ "" filename "" ] = str ( logfile_path ) <TAB>  logging . config . dictConfig ( log_config ) ","elif ""filename"" in handler . keys ( ) :",if handler.get('filename'):,False,55.81215489577163,96.31698044442419
3726,"def __call__ ( self ) : <TAB>  dmin , dmax = self . viewlim_to_dt ( ) <TAB>  ymin = self . base . le ( dmin . year ) <TAB>  ymax = self . base . ge ( dmax . year ) <TAB>  ticks = [ dmin . replace ( year = ymin , * * self . replaced ) ] <TAB>  while 1 : <TAB><TAB>  dt = ticks [ - 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return date2num ( ticks ) <TAB><TAB>  year = dt . year + self . base . get_base ( ) <TAB><TAB>  ticks . append ( dt . replace ( year = year , * * self . replaced ) ) ",if dt . year >= ymax :,if dt.year == ymax:,False,43.58795159753911,96.4207434613648
3727,"def taiga ( request , trigger_id , key ) : <TAB>  signature = request . META . get ( "" HTTP_X_TAIGA_WEBHOOK_SIGNATURE "" ) <TAB>  # check that the data are ok with the provided signature <TAB>  if verify_signature ( request . _request . body , key , signature ) : <TAB><TAB>  data = data_filter ( trigger_id , * * request . data ) <TAB><TAB>  status = save_data ( trigger_id , data ) <TAB><TAB>  return ( <TAB><TAB><TAB>  Response ( { "" message "" : "" Success "" } ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else Response ( { "" message "" : "" Failed! "" } ) <TAB><TAB>  ) <TAB>  Response ( { "" message "" : "" Bad request "" } ) ",if status,if status == 200:,False,58.78242145272124,97.21015417051196
3728,"def ParseResponses ( <TAB>  self , <TAB>  knowledge_base : rdf_client . KnowledgeBase , <TAB>  responses : Iterable [ rdfvalue . RDFValue ] ,  ) - > Iterator [ rdf_client . User ] : <TAB>  for response in responses : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB><TAB>  # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB><TAB>  if stat . S_ISDIR ( int ( response . st_mode ) ) : <TAB><TAB><TAB>  homedir = response . pathspec . path <TAB><TAB><TAB>  username = os . path . basename ( homedir ) <TAB><TAB><TAB>  if username not in self . _ignore_users : <TAB><TAB><TAB><TAB>  yield rdf_client . User ( username = username , homedir = homedir ) ","if not isinstance ( response , rdf_client_fs . StatEntry ) :","if not isinstance(response, (int, int)):",False,48.2586398120156,96.3422177367167
3729,"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB>  path . responses = [ ] <TAB>  n = 0 <TAB>  while response : <TAB><TAB>  path . responses . append ( response ) <TAB><TAB>  yield from response . iter_lines ( decode_unicode = True ) <TAB><TAB>  src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB><TAB>  if not src : <TAB><TAB><TAB>  break <TAB><TAB>  n + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB><TAB><TAB>  break <TAB><TAB>  vd . status ( f "" fetching next page from  { src } "" ) <TAB><TAB>  response = requests . get ( src , stream = True ) ",if n > max_next :,if n > max_next:,False,40.971697913514404,100.00000000000004
3730,"def __enter__ ( self ) : <TAB>  """"""Open a file and read it."""""" <TAB>  if self . code is None : <TAB><TAB>  LOGGER . info ( "" File is reading:  %s "" , self . path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _file = open ( self . path , encoding = "" utf-8 "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _file = open ( self . path , "" rU "" ) <TAB><TAB>  self . code = self . _file . read ( ) <TAB>  return self ","if sys . version_info >= ( 3 , ) :",if self.encoding is None:,False,50.06598173871117,92.17550544425777
3731,"def facts_for_oauthclients ( self , namespace ) : <TAB>  """"""Gathers facts for oauthclients used with logging"""""" <TAB>  self . default_keys_for ( "" oauthclients "" ) <TAB>  a_list = self . oc_command ( <TAB><TAB>  "" get "" , "" oauthclients "" , namespace = namespace , add_options = [ "" -l "" , LOGGING_SELECTOR ] <TAB>  ) <TAB>  if len ( a_list [ "" items "" ] ) == 0 : <TAB><TAB>  return <TAB>  for item in a_list [ "" items "" ] : <TAB><TAB>  name = item [ "" metadata "" ] [ "" name "" ] <TAB><TAB>  comp = self . comp ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = dict ( redirectURIs = item [ "" redirectURIs "" ] ) <TAB><TAB><TAB>  self . add_facts_for ( comp , "" oauthclients "" , name , result ) ",if comp is not None :,if comp:,False,35.57060181518463,97.99175181475897
3732,"def get ( self , k ) : <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _data1 [ k ] = self . _data2 [ k ] <TAB><TAB><TAB>  del self . _data2 [ k ] <TAB>  return self . _data1 . get ( k ) ",if k not in self . _data1 and k in self . _data2 :,if k in self._data1:,False,45.17973936866585,88.51097375285505
3733,"def _parseparam ( s ) : <TAB>  plist = [ ] <TAB>  while s [ : 1 ] == "" ; "" : <TAB><TAB>  s = s [ 1 : ] <TAB><TAB>  end = s . find ( "" ; "" ) <TAB><TAB>  while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB><TAB><TAB>  end = s . find ( "" ; "" , end + 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  end = len ( s ) <TAB><TAB>  f = s [ : end ] <TAB><TAB>  if "" = "" in f : <TAB><TAB><TAB>  i = f . index ( "" = "" ) <TAB><TAB><TAB>  f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB><TAB>  plist . append ( f . strip ( ) ) <TAB><TAB>  s = s [ end : ] <TAB>  return plist ",if end < 0 :,if end < 0:,False,52.717832074107186,100.00000000000004
3734,"def __init__ ( self , * * params ) : <TAB>  if "" length "" in params : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" Supply either length or start and end to Player not both "" ) <TAB><TAB>  params [ "" start "" ] = 0 <TAB><TAB>  params [ "" end "" ] = params . pop ( "" length "" ) - 1 <TAB>  elif params . get ( "" start "" , 0 ) > 0 and not "" value "" in params : <TAB><TAB>  params [ "" value "" ] = params [ "" start "" ] <TAB>  super ( Player , self ) . __init__ ( * * params ) ","if ""start"" in params or ""end"" in params :","if params.get('length', 0) > 0:",False,52.61101984134141,92.6791357755105
3735,"def libcxx_define ( settings ) : <TAB>  compiler = _base_compiler ( settings ) <TAB>  libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB>  if not compiler or not libcxx : <TAB><TAB>  return "" "" <TAB>  if str ( compiler ) in GCC_LIKE : <TAB><TAB>  if str ( libcxx ) == "" libstdc++ "" : <TAB><TAB><TAB>  return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB>  return "" "" ","elif str ( libcxx ) == ""libstdc++11"" :",if str(compiler) in GCC_LIKE:,False,53.693431073789824,91.3431495582149
3736,"def _get_sort_map ( tags ) : <TAB>  """"""See TAG_TO_SORT"""""" <TAB>  tts = { } <TAB>  for name , tag in tags . items ( ) : <TAB><TAB>  if tag . has_sort : <TAB><TAB><TAB>  if tag . user : <TAB><TAB><TAB><TAB>  tts [ name ] = "" %s sort "" % name <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB>  return tts ",if tag . internal :,if tag.sort:,False,50.89781563682347,93.46822566491439
3737,"def quiet_f ( * args ) : <TAB>  vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB>  value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB>  if expect_list : <TAB><TAB>  if value . has_form ( "" List "" , None ) : <TAB><TAB><TAB>  value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB><TAB><TAB>  if any ( item is None for item in value ) : <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  return value <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  else : <TAB><TAB>  value = extract_pyreal ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  return value ",if value is None or isinf ( value ) or isnan ( value ) :,if value is None:,False,49.342631207021235,95.00727721647125
3738,"def on_action_chosen ( self , id , action , mark_changed = True ) : <TAB>  before = self . set_action ( self . current , id , action ) <TAB>  if mark_changed : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # TODO: Maybe better comparison <TAB><TAB><TAB>  self . undo . append ( UndoRedo ( id , before , action ) ) <TAB><TAB><TAB>  self . builder . get_object ( "" btUndo "" ) . set_sensitive ( True ) <TAB><TAB>  self . on_profile_modified ( ) <TAB>  else : <TAB><TAB>  self . on_profile_modified ( update_ui = False ) <TAB>  return before ",if before . to_string ( ) != action . to_string ( ) :,if before:,False,31.17417610044789,90.6281925676648
3739,"def setUp ( self ) : <TAB>  super ( OperaterTest , self ) . setUp ( ) <TAB>  if is_cli : <TAB><TAB>  import clr <TAB><TAB>  self . load_iron_python_test ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  clr . AddReference ( "" System.Drawing.Primitives "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  clr . AddReference ( "" System.Drawing "" ) ",if is_netcoreapp :,if is_cli:,False,26.427911597817243,97.70064524882032
3740,"def field_to_field_type ( field ) : <TAB>  field_type = field [ "" type "" ] <TAB>  if isinstance ( field_type , dict ) : <TAB><TAB>  field_type = field_type [ "" type "" ] <TAB>  if isinstance ( field_type , list ) : <TAB><TAB>  field_type_length = len ( field_type ) <TAB><TAB>  if field_type_length == 0 : <TAB><TAB><TAB>  raise Exception ( "" Zero-length type list encountered, invalid CWL? "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field_type = field_type [ 0 ] <TAB>  return field_type ",elif len ( field_type ) == 1 :,if field_type[0] is not None:,False,31.319916261564597,94.01061756747883
3741,"def _flatten ( * args ) : <TAB>  ahs = set ( ) <TAB>  if len ( args ) > 0 : <TAB><TAB>  for item in args : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ahs . add ( item ) <TAB><TAB><TAB>  elif type ( item ) in ( list , tuple , dict , set ) : <TAB><TAB><TAB><TAB>  for ah in item : <TAB><TAB><TAB><TAB><TAB>  if type ( ah ) is not ActionHandle :<TAB># pragma:nocover <TAB><TAB><TAB><TAB><TAB><TAB>  raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB><TAB><TAB><TAB><TAB>  ahs . add ( ah ) <TAB><TAB><TAB>  else :<TAB># pragma:nocover <TAB><TAB><TAB><TAB>  raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB>  return ahs ",if type ( item ) is ActionHandle :,if type(item) is ActionHandle:,False,50.18872985382339,96.39884658731658
3742,"def _Determine_Do ( self ) : <TAB>  self . applicable = 1 <TAB>  configTokens = black . configure . items [ "" configTokens "" ] . Get ( ) <TAB>  buildFlavour = black . configure . items [ "" buildFlavour "" ] . Get ( ) <TAB>  if buildFlavour == "" full "" : <TAB><TAB>  self . value = False <TAB>  else : <TAB><TAB>  self . value = True <TAB>  for opt , optarg in self . chosenOptions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not self . value : <TAB><TAB><TAB><TAB>  configTokens . append ( "" tests "" ) <TAB><TAB><TAB>  self . value = True <TAB><TAB>  elif opt == "" --without-tests "" : <TAB><TAB><TAB>  if self . value : <TAB><TAB><TAB><TAB>  configTokens . append ( "" notests "" ) <TAB><TAB><TAB>  self . value = False <TAB>  self . determined = 1 ","if opt == ""--with-tests"" :",if opt == '--tests':,False,50.973234391156886,98.09557986747902
3743,"def title_by_index ( self , trans , index , context ) : <TAB>  d_type = self . get_datatype ( trans , context ) <TAB>  for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rval = composite_name <TAB><TAB><TAB>  if composite_file . description : <TAB><TAB><TAB><TAB>  rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB><TAB><TAB>  if composite_file . optional : <TAB><TAB><TAB><TAB>  rval = "" %s  [optional] "" % rval <TAB><TAB><TAB>  return rval <TAB>  if index < self . get_file_count ( trans , context ) : <TAB><TAB>  return "" Extra primary file "" <TAB>  return None ",if i == index :,if composite_name.name == index:,False,48.53028029877295,97.13905750101142
3744,"def func ( x , y ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  z = x + 2 * math . sin ( y ) <TAB><TAB><TAB>  return z * * 2 <TAB><TAB>  elif x == y : <TAB><TAB><TAB>  return 4 <TAB><TAB>  else : <TAB><TAB><TAB>  return 2 * * 3 <TAB>  except ValueError : <TAB><TAB>  foo = 0 <TAB><TAB>  for i in range ( 4 ) : <TAB><TAB><TAB>  foo + = i <TAB><TAB>  return foo <TAB>  except TypeError : <TAB><TAB>  return 42 <TAB>  else : <TAB><TAB>  return 33 <TAB>  finally : <TAB><TAB>  print ( "" finished "" ) ",if x > y :,if x < y:,False,41.838969539337114,98.7227748200473
3745,"def test_suite ( ) : <TAB>  suite = unittest . TestSuite ( ) <TAB>  for fn in os . listdir ( here ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  modname = "" distutils.tests. "" + fn [ : - 3 ] <TAB><TAB><TAB>  __import__ ( modname ) <TAB><TAB><TAB>  module = sys . modules [ modname ] <TAB><TAB><TAB>  suite . addTest ( module . test_suite ( ) ) <TAB>  return suite ","if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :",if fn.endswith('.py'):,False,46.99506548707163,87.45619231618961
3746,"def check_stack_names ( self , frame , expected ) : <TAB>  names = [ ] <TAB>  while frame : <TAB><TAB>  name = frame . f_code . co_name <TAB><TAB>  # Stop checking frames when we get to our test helper. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  names . append ( name ) <TAB><TAB>  frame = frame . f_back <TAB>  self . assertEqual ( names , expected ) ","if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :",if name == 'test':,False,61.694781226043816,84.88587930557654
3747,"def leave ( self , reason = None ) : <TAB>  try : <TAB><TAB>  if self . id . startswith ( "" C "" ) : <TAB><TAB><TAB>  log . info ( "" Leaving channel  %s  ( %s ) "" , self , self . id ) <TAB><TAB><TAB>  self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB><TAB>  else : <TAB><TAB><TAB>  log . info ( "" Leaving group  %s  ( %s ) "" , self , self . id ) <TAB><TAB><TAB>  self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB>  except SlackAPIResponseError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RoomError ( f "" Unable to leave channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise RoomError ( e ) <TAB>  self . _id = None ","if e . error == ""user_is_bot"" :",if e.code == SlackAPIResponseError.ERROR:,False,48.67119999226533,95.8643352213772
3748,"def ident ( self ) : <TAB>  value = self . _ident <TAB>  if value is False : <TAB><TAB>  value = None <TAB><TAB>  # XXX: how will this interact with orig_prefix ? <TAB><TAB>  #<TAB>  not exposing attrs for now if orig_prefix is set. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  wrapped = self . wrapped <TAB><TAB><TAB>  ident = getattr ( wrapped , "" ident "" , None ) <TAB><TAB><TAB>  if ident is not None : <TAB><TAB><TAB><TAB>  value = self . _wrap_hash ( ident ) <TAB><TAB>  self . _ident = value <TAB>  return value ",if not self . orig_prefix :,if self.wrapped is not None:,False,63.58872061340672,96.25752016690603
3749,"def is_ac_power_connected ( ) : <TAB>  for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB><TAB><TAB><TAB>  if f . read ( 1 ) == "" 1 "" : <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB>  except IOError : <TAB><TAB><TAB>  continue <TAB>  return False ","if f . read ( ) . strip ( ) != ""Mains"" :","if f.read(1) == ""1':",False,16.555004280465422,95.08897550243213
3750,"def _get_pending_by_app_token ( self , app_token ) : <TAB>  result = [ ] <TAB>  with self . _pending_lock : <TAB><TAB>  self . _remove_stale_pending ( ) <TAB><TAB>  for data in self . _pending_decisions : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result . append ( data ) <TAB>  return result ",if data . app_token == app_token :,if app_token == data['app_token']:,False,48.6735379898096,92.37900146067088
3751,"def do_create ( specific_tables = None , base = Base ) : <TAB>  engine = get_engine ( ) <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . info ( <TAB><TAB><TAB><TAB>  "" Initializing only a subset of tables as requested:  {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  specific_tables <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  base . metadata . create_all ( engine , tables = specific_tables ) <TAB><TAB>  else : <TAB><TAB><TAB>  base . metadata . create_all ( engine ) <TAB>  except Exception as err : <TAB><TAB>  raise Exception ( "" could not create/re-create DB tables - exception:  "" + str ( err ) ) ",if specific_tables :,if specific_tables is not None:,False,64.22525430256461,97.87805119482678
3752,"def __setitem__ ( self , ndx , val ) : <TAB>  # <TAB>  # Get the expression data object <TAB>  # <TAB>  exprdata = None <TAB>  if ndx in self . _data : <TAB><TAB>  exprdata = self . _data [ ndx ] <TAB>  else : <TAB><TAB>  _ndx = normalize_index ( ndx ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  exprdata = self . _data [ _ndx ] <TAB>  if exprdata is None : <TAB><TAB>  raise KeyError ( <TAB><TAB><TAB>  "" Cannot set the value of Expression  ' %s '  with  "" <TAB><TAB><TAB>  "" invalid index  ' %s ' "" % ( self . cname ( True ) , str ( ndx ) ) <TAB><TAB>  ) <TAB>  # <TAB>  # Set the value <TAB>  # <TAB>  exprdata . set_value ( val ) ",if _ndx in self . _data :,if _ndx in self._data:,False,31.656044246885894,96.78543201146636
3753,"def write ( self , * bits ) : <TAB>  for bit in bits : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . bytestream . append ( 0 ) <TAB><TAB>  byte = self . bytestream [ self . bytenum ] <TAB><TAB>  if self . bitnum == 8 : <TAB><TAB><TAB>  if self . bytenum == len ( self . bytestream ) - 1 : <TAB><TAB><TAB><TAB>  byte = 0 <TAB><TAB><TAB><TAB>  self . bytestream + = bytes ( [ byte ] ) <TAB><TAB><TAB>  self . bytenum + = 1 <TAB><TAB><TAB>  self . bitnum = 0 <TAB><TAB>  mask = 2 * * self . bitnum <TAB><TAB>  if bit : <TAB><TAB><TAB>  byte | = mask <TAB><TAB>  else : <TAB><TAB><TAB>  byte & = ~ mask <TAB><TAB>  self . bytestream [ self . bytenum ] = byte <TAB><TAB>  self . bitnum + = 1 ",if not self . bytestream :,if self.bitnum == 8:,False,19.027528357808503,97.33089127836905
3754,"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB>  if proc . poll ( ) is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB><TAB>  proc . terminate ( ) <TAB><TAB>  timeout_time = time . time ( ) + timeout <TAB><TAB>  while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB><TAB><TAB>  time . sleep ( 0.02 ) <TAB><TAB>  if proc . poll ( ) is None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB><TAB><TAB>  proc . kill ( ) <TAB>  return proc . returncode ",if log :,if log:,False,49.19196279006217,97.76195587322613
3755,"def mkpanel ( color , rows , cols , tly , tlx ) : <TAB>  win = curses . newwin ( rows , cols , tly , tlx ) <TAB>  pan = panel . new_panel ( win ) <TAB>  if curses . has_colors ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fg = curses . COLOR_WHITE <TAB><TAB>  else : <TAB><TAB><TAB>  fg = curses . COLOR_BLACK <TAB><TAB>  bg = color <TAB><TAB>  curses . init_pair ( color , fg , bg ) <TAB><TAB>  win . bkgdset ( ord ( "" "" ) , curses . color_pair ( color ) ) <TAB>  else : <TAB><TAB>  win . bkgdset ( ord ( "" "" ) , curses . A_BOLD ) <TAB>  return pan ",if color == curses . COLOR_BLUE :,if color == '#':,False,47.99628057716648,96.65547404687234
3756,"def all_words ( filename ) : <TAB>  start_char = True <TAB>  for c in characters ( filename ) : <TAB><TAB>  if start_char == True : <TAB><TAB><TAB>  word = "" "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # We found the start of a word <TAB><TAB><TAB><TAB>  word = c . lower ( ) <TAB><TAB><TAB><TAB>  start_char = False <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  word + = c . lower ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # We found end of word, emit it <TAB><TAB><TAB><TAB>  start_char = True <TAB><TAB><TAB><TAB>  yield word ",if c . isalnum ( ) :,if c.startswith(' '):,False,56.63313142941534,95.7840285768566
3757,"def get_tf_weights_as_numpy ( path = "" ./ckpt/aeslc/model.ckpt-32000 "" ) - > Dict : <TAB>  init_vars = tf . train . list_variables ( path ) <TAB>  tf_weights = { } <TAB>  ignore_name = [ "" Adafactor "" , "" global_step "" ] <TAB>  for name , shape in tqdm ( init_vars , desc = "" converting tf checkpoint to dict "" ) : <TAB><TAB>  skip_key = any ( [ pat in name for pat in ignore_name ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  array = tf . train . load_variable ( path , name ) <TAB><TAB>  tf_weights [ name ] = array <TAB>  return tf_weights ",if skip_key :,if skip_key:,False,54.7712627127646,100.00000000000004
3758,"def app ( scope , receive , send ) : <TAB>  while True : <TAB><TAB>  message = await receive ( ) <TAB><TAB>  if message [ "" type "" ] == "" websocket.connect "" : <TAB><TAB><TAB>  await send ( { "" type "" : "" websocket.accept "" } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB><TAB><TAB>  break ","elif message [ ""type"" ] == ""websocket.receive"" :","if message['type'] == ""websocket.accept':",False,18.482646242303954,92.27347444158481
3759,"def autoload ( self ) : <TAB>  if self . _app . config . THEME == "" auto "" : <TAB><TAB>  if sys . platform == "" darwin "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  theme = DARK <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  theme = LIGHT <TAB><TAB>  else : <TAB><TAB><TAB>  theme = self . guess_system_theme ( ) <TAB><TAB><TAB>  if theme == Dark : <TAB><TAB><TAB><TAB>  theme = MacOSDark <TAB>  else :<TAB># user settings have highest priority <TAB><TAB>  theme = self . _app . config . THEME <TAB>  self . load_theme ( theme ) ",if get_osx_theme ( ) == 1 :,if sys.platform == 'win32':,False,52.643704038737084,93.74617154422056
3760,"def example_reading_spec ( self ) : <TAB>  data_fields = { "" targets "" : tf . VarLenFeature ( tf . int64 ) } <TAB>  <IF-STMT>: <TAB><TAB>  data_fields [ "" inputs "" ] = tf . VarLenFeature ( tf . int64 ) <TAB>  if self . packed_length : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data_fields [ "" inputs_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB><TAB><TAB>  data_fields [ "" inputs_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB><TAB>  data_fields [ "" targets_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB><TAB>  data_fields [ "" targets_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB>  data_items_to_decoders = None <TAB>  return ( data_fields , data_items_to_decoders ) ",if self . has_inputs :,if self.inputs:,False,21.643891037940808,94.9904929207746
3761,"def _prepare_travel_graph ( self ) : <TAB>  for op in self . op_dict . values ( ) : <TAB><TAB>  op . const = False <TAB><TAB>  if op . node . op in [ "" Const "" , "" Placeholder "" ] : <TAB><TAB><TAB>  op . resolved = True <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  op . const = True <TAB><TAB>  else : <TAB><TAB><TAB>  op . resolved = False ","if op . node . op == ""Const"" :","if op.node.op in [""Const"", ""Placeholder""]:",False,27.22430885726188,92.751187254387
3762,"def get_filestream_file_items ( self ) : <TAB>  data = { } <TAB>  fs_file_updates = self . get_filestream_file_updates ( ) <TAB>  for k , v in six . iteritems ( fs_file_updates ) : <TAB><TAB>  l = [ ] <TAB><TAB>  for d in v : <TAB><TAB><TAB>  offset = d . get ( "" offset "" ) <TAB><TAB><TAB>  content = d . get ( "" content "" ) <TAB><TAB><TAB>  assert offset is not None <TAB><TAB><TAB>  assert content is not None <TAB><TAB><TAB>  assert offset == 0 or offset == len ( l ) , ( k , v , l , d ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  l = [ ] <TAB><TAB><TAB>  l . extend ( map ( json . loads , content ) ) <TAB><TAB>  data [ k ] = l <TAB>  return data ",if not offset :,if not l:,False,48.61714274466153,98.97008886139643
3763,"def _rewrite_exprs ( self , table , what ) : <TAB>  from ibis . expr . analysis import substitute_parents <TAB>  what = util . promote_list ( what ) <TAB>  all_exprs = [ ] <TAB>  for expr in what : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  all_exprs . extend ( expr . exprs ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  bound_expr = ir . bind_expr ( table , expr ) <TAB><TAB><TAB>  all_exprs . append ( bound_expr ) <TAB>  return [ substitute_parents ( x , past_projection = False ) for x in all_exprs ] ","if isinstance ( expr , ir . ExprList ) :","if isinstance(expr, ast.Name):",False,51.200972698896074,97.42174834750892
3764,"def _group_by_commit_and_time ( self , hits ) : <TAB>  result = { } <TAB>  for hit in hits : <TAB><TAB>  source_hit = hit [ "" _source "" ] <TAB><TAB>  key = "" %s _ %s "" % ( source_hit [ "" commit_info "" ] [ "" id "" ] , source_hit [ "" datetime "" ] ) <TAB><TAB>  benchmark = self . _benchmark_from_es_record ( source_hit ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ key ] [ "" benchmarks "" ] . append ( benchmark ) <TAB><TAB>  else : <TAB><TAB><TAB>  run_info = self . _run_info_from_es_record ( source_hit ) <TAB><TAB><TAB>  run_info [ "" benchmarks "" ] = [ benchmark ] <TAB><TAB><TAB>  result [ key ] = run_info <TAB>  return result ",if key in result :,if benchmark in result:,False,39.35630834814113,98.89740890659164
3765,"def _build_index ( self ) : <TAB>  self . _index = { } <TAB>  for start_char , sorted_offsets in self . _offsets . items ( ) : <TAB><TAB>  self . _index [ start_char ] = { } <TAB><TAB>  for i , offset in enumerate ( sorted_offsets . get_offsets ( ) ) : <TAB><TAB><TAB>  identifier = sorted_offsets . get_identifier_by_offset ( offset ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _index [ start_char ] [ identifier [ 0 : self . index_depth ] ] = i ",if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,if identifier:,False,28.572142154067148,86.94993632922697
3766,"def scan_resource_conf ( self , conf ) : <TAB>  if "" properties "" in conf : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB><TAB><TAB><TAB>  if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB><TAB><TAB><TAB><TAB>  return CheckResult . PASSED <TAB>  return CheckResult . FAILED ","if ""attributes"" in conf [ ""properties"" ] :",if conf['properties']['attributes']:,False,23.40096887347646,91.87867623470937
3767,"def _PatchArtifact ( self , artifact : rdf_artifacts . Artifact ) - > rdf_artifacts . Artifact : <TAB>  """"""Patches artifact to not contain byte-string source attributes."""""" <TAB>  patched = False <TAB>  for source in artifact . sources : <TAB><TAB>  attributes = source . attributes . ToDict ( ) <TAB><TAB>  unicode_attributes = compatibility . UnicodeJson ( attributes ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  source . attributes = unicode_attributes <TAB><TAB><TAB>  patched = True <TAB>  if patched : <TAB><TAB>  self . DeleteArtifact ( str ( artifact . name ) ) <TAB><TAB>  self . WriteArtifact ( artifact ) <TAB>  return artifact ",if attributes != unicode_attributes :,if unicode_attributes != source.attributes:,False,41.07051236416364,96.57872529318944
3768,"def edit_file ( self , filename ) : <TAB>  import subprocess <TAB>  editor = self . get_editor ( ) <TAB>  if self . env : <TAB><TAB>  environ = os . environ . copy ( ) <TAB><TAB>  environ . update ( self . env ) <TAB>  else : <TAB><TAB>  environ = None <TAB>  try : <TAB><TAB>  c = subprocess . Popen ( ' %s "" %s "" ' % ( editor , filename ) , env = environ , shell = True ) <TAB><TAB>  exit_code = c . wait ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ClickException ( "" %s : Editing failed! "" % editor ) <TAB>  except OSError as e : <TAB><TAB>  raise ClickException ( "" %s : Editing failed:  %s "" % ( editor , e ) ) ",if exit_code != 0 :,if exit_code != 0:,False,50.74583817415609,100.00000000000004
3769,"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB>  controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB>  index = 0 <TAB>  for i , c in enumerate ( subsegments ) : <TAB><TAB>  segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB><TAB>  for j , s in enumerate ( c ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if glyph . contours [ i ] . segments [ j ] . type == "" line "" : <TAB><TAB><TAB><TAB><TAB>  controlPointIndices [ index ] = 1 <TAB><TAB><TAB>  index + = s [ 1 ] <TAB>  return controlPointIndices ",if j < segmentCount :,if s[0] == segmentCount:,False,25.019600946499317,95.69539024386955
3770,"def to_representation ( self , value ) : <TAB>  old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB>  request = self . context . get ( "" request "" ) <TAB>  show_old_format = ( <TAB><TAB>  request <TAB><TAB>  and is_deprecated ( request . version , self . min_version ) <TAB><TAB>  and request . method == "" GET "" <TAB>  ) <TAB>  if show_old_format : <TAB><TAB>  social = value . copy ( ) <TAB><TAB>  for key in old_social_string_fields : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  social [ key ] = value [ key ] [ 0 ] <TAB><TAB><TAB>  elif social . get ( key ) == [ ] : <TAB><TAB><TAB><TAB>  social [ key ] = "" "" <TAB><TAB>  value = social <TAB>  return super ( SocialField , self ) . to_representation ( value ) ",if social . get ( key ) :,if key in value:,False,34.851879217277904,97.11285881355958
3771,"def iter_raw_frames ( path , packet_sizes , ctx ) : <TAB>  with open ( path , "" rb "" ) as f : <TAB><TAB>  for i , size in enumerate ( packet_sizes ) : <TAB><TAB><TAB>  packet = Packet ( size ) <TAB><TAB><TAB>  read_size = f . readinto ( packet ) <TAB><TAB><TAB>  assert size <TAB><TAB><TAB>  assert read_size == size <TAB><TAB><TAB>  if not read_size : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  for frame in ctx . decode ( packet ) : <TAB><TAB><TAB><TAB>  yield frame <TAB><TAB>  while True : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  frames = ctx . decode ( None ) <TAB><TAB><TAB>  except EOFError : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  for frame in frames : <TAB><TAB><TAB><TAB>  yield frame <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break ",if not frames :,if frames is None:,False,49.670832503531116,98.52864306024455
3772,"def get_shadows_zip ( filename ) : <TAB>  import zipfile <TAB>  shadow_pkgs = set ( ) <TAB>  with zipfile . ZipFile ( filename ) as lib_zip : <TAB><TAB>  already_test = [ ] <TAB><TAB>  for fname in lib_zip . namelist ( ) : <TAB><TAB><TAB>  pname , fname = os . path . split ( fname ) <TAB><TAB><TAB>  if fname or ( pname and fname ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if pname not in already_test and "" / "" not in pname : <TAB><TAB><TAB><TAB>  already_test . append ( pname ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  shadow_pkgs . add ( pname ) <TAB>  return shadow_pkgs ",if is_shadowing ( pname ) :,if not os.path.isdir(pname):,False,52.736937878797676,96.53155854371239
3773,"def metrics_to_scalars ( self , metrics ) : <TAB>  new_metrics = { } <TAB>  for k , v in metrics . items ( ) : <TAB><TAB>  if isinstance ( v , torch . Tensor ) : <TAB><TAB><TAB>  v = v . item ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = self . metrics_to_scalars ( v ) <TAB><TAB>  new_metrics [ k ] = v <TAB>  return new_metrics ","if isinstance ( v , dict ) :","if isinstance(v, torch.Tensor):",False,27.499491781838564,96.34320912002212
3774,"def insert_resets ( f ) : <TAB>  newsync = dict ( ) <TAB>  for k , v in f . sync . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newsync [ k ] = insert_reset ( ResetSignal ( k ) , v ) <TAB><TAB>  else : <TAB><TAB><TAB>  newsync [ k ] = v <TAB>  f . sync = newsync ",if f . clock_domains [ k ] . rst is not None :,if k.startswith('reset'):,False,45.32217615963282,86.82651266925174
3775,"def get_attached_nodes ( self , external_account ) : <TAB>  for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB><TAB>  if node is None : <TAB><TAB><TAB>  continue <TAB><TAB>  node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if node_settings . external_account == external_account : <TAB><TAB><TAB>  yield node ",if node_settings is None :,if not node_settings:,False,21.43434189376954,96.31409813277192
3776,"def visitIf ( self , node , scope ) : <TAB>  for test , body in node . tests : <TAB><TAB>  if isinstance ( test , ast . Const ) : <TAB><TAB><TAB>  if type ( test . value ) in self . _const_types : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB>  self . visit ( test , scope ) <TAB><TAB>  self . visit ( body , scope ) <TAB>  if node . else_ : <TAB><TAB>  self . visit ( node . else_ , scope ) ",if not test . value :,"if not isinstance(test, ast.If):",False,23.904633973886344,94.11969166216711
3777,"def flatten ( self ) : <TAB>  # this is similar to fill_messages except it uses a list instead <TAB>  # of a queue to place the messages in. <TAB>  result = [ ] <TAB>  channel = await self . messageable . _get_channel ( ) <TAB>  self . channel = channel <TAB>  while self . _get_retrieve ( ) : <TAB><TAB>  data = await self . _retrieve_messages ( self . retrieve ) <TAB><TAB>  if len ( data ) < 100 : <TAB><TAB><TAB>  self . limit = 0<TAB># terminate the infinite loop <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = reversed ( data ) <TAB><TAB>  if self . _filter : <TAB><TAB><TAB>  data = filter ( self . _filter , data ) <TAB><TAB>  for element in data : <TAB><TAB><TAB>  result . append ( self . state . create_message ( channel = channel , data = element ) ) <TAB>  return result ",if self . reverse :,"if isinstance(data, (list, tuple)):",False,37.06246829006978,93.47367287800552
3778,"def compute ( self , x , y = None , targets = None ) : <TAB>  if targets is None : <TAB><TAB>  targets = self . out_params <TAB>  in_params = list ( self . in_x ) <TAB>  if len ( in_params ) == 1 : <TAB><TAB>  args = [ x ] <TAB>  else : <TAB><TAB>  args = list ( zip ( * x ) ) <TAB>  if y is None : <TAB><TAB>  pipe = self . pipe <TAB>  else : <TAB><TAB>  pipe = self . train_pipe <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args . append ( y ) <TAB><TAB>  else : <TAB><TAB><TAB>  args + = list ( zip ( * y ) ) <TAB><TAB>  in_params + = self . in_y <TAB>  return self . _compute ( * args , pipe = pipe , param_names = in_params , targets = targets ) ",if len ( self . in_y ) == 1 :,if len(y) == 1:,False,24.02869823989264,97.6967564856117
3779,"def _import_top_module ( self , name ) : <TAB>  # scan sys.path looking for a location in the filesystem that contains <TAB>  # the module, or an Importer object that can import the module. <TAB>  for item in sys . path : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module = self . fs_imp . import_from_dir ( item , name ) <TAB><TAB>  else : <TAB><TAB><TAB>  module = item . import_top ( name ) <TAB><TAB>  if module : <TAB><TAB><TAB>  return module <TAB>  return None ","if isinstance ( item , _StringType ) :","if isinstance(item, os.Path):",False,43.91999782519598,97.00126434602448
3780,"def __getitem__ ( self , key , _get_mode = False ) : <TAB>  if not _get_mode : <TAB><TAB>  if isinstance ( key , ( int , long ) ) : <TAB><TAB><TAB>  return self . _list [ key ] <TAB><TAB>  elif isinstance ( key , slice ) : <TAB><TAB><TAB>  return self . __class__ ( self . _list [ key ] ) <TAB>  ikey = key . lower ( ) <TAB>  for k , v in self . _list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return v <TAB>  # micro optimization: if we are in get mode we will catch that <TAB>  # exception one stack level down so we can raise a standard <TAB>  # key error instead of our special one. <TAB>  if _get_mode : <TAB><TAB>  raise KeyError ( ) <TAB>  raise BadRequestKeyError ( key ) ",if k . lower ( ) == ikey :,if k.lower() == ikey:,False,65.96751997235725,100.00000000000004
3781,"def execute ( self , arbiter , props ) : <TAB>  watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB>  action = 0 <TAB>  for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB><TAB>  if key == "" hooks "" : <TAB><TAB><TAB>  new_action = 0 <TAB><TAB><TAB>  for name , _val in val . items ( ) : <TAB><TAB><TAB><TAB>  action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  new_action = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  new_action = watcher . set_opt ( key , val ) <TAB><TAB>  if new_action == 1 : <TAB><TAB><TAB>  action = 1 <TAB>  # trigger needed action <TAB>  return watcher . do_action ( action ) ",if action == 1 :,if action == 1:,False,50.83407635114121,100.00000000000004
3782,"def OnBodyClick ( self , event = None ) : <TAB>  try : <TAB><TAB>  c = self . c <TAB><TAB>  p = c . currentPosition ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . OnActivateBody ( event = event ) <TAB><TAB>  g . doHook ( "" bodyclick2 "" , c = c , p = p , v = p , event = event ) <TAB>  except : <TAB><TAB>  g . es_event_exception ( "" bodyclick "" ) ","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",if p is not None:,False,19.733832558099458,80.52657674715184
3783,"def _class_weights ( spec : config . MetricsSpec ) - > Optional [ Dict [ int , float ] ] : <TAB>  """"""Returns class weights associated with AggregationOptions at offset."""""" <TAB>  if spec . aggregate . HasField ( "" top_k_list "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" class_weights are not supported when top_k_list used:  "" <TAB><TAB><TAB><TAB>  "" spec= {} "" . format ( spec ) <TAB><TAB><TAB>  ) <TAB><TAB>  return None <TAB>  return dict ( spec . aggregate . class_weights ) or None ",if spec . aggregate . class_weights :,if spec.aggregate.HasField('class_weights'):,False,32.70133727433676,95.83580938930002
3784,"def _is_perf_file ( file_path ) : <TAB>  f = get_file ( file_path ) <TAB>  for line in f : <TAB><TAB>  if line [ 0 ] == "" # "" : <TAB><TAB><TAB>  continue <TAB><TAB>  r = event_regexp . search ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  f . close ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  f . close ( ) <TAB><TAB>  return False ",if r :,if r:,False,51.27177641190135,100.00000000000004
3785,"def _get_before_insertion_node ( self ) : <TAB>  if self . _nodes_stack . is_empty ( ) : <TAB><TAB>  return None <TAB>  line = self . _nodes_stack . parsed_until_line + 1 <TAB>  node = self . _new_module . get_last_leaf ( ) <TAB>  while True : <TAB><TAB>  parent = node . parent <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert node . end_pos [ 0 ] < = line <TAB><TAB><TAB>  assert node . end_pos [ 1 ] == 0 or "" \n "" in self . _prefix <TAB><TAB><TAB>  return node <TAB><TAB>  node = parent ","if parent . type in ( ""suite"" , ""file_input"" ) :",if parent is not None:,False,26.541984911205084,91.55891009284026
3786,"def PyJsHoisted_parseClassRanges_ ( this , arguments , var = var ) : <TAB>  var = Scope ( { u "" this "" : this , u "" arguments "" : arguments } , var ) <TAB>  var . registers ( [ u "" res "" ] ) <TAB>  pass <TAB>  if var . get ( u "" current "" ) ( Js ( u "" ] "" ) ) : <TAB><TAB>  return Js ( [ ] ) <TAB>  else : <TAB><TAB>  var . put ( u "" res "" , var . get ( u "" parseNonemptyClassRanges "" ) ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  var . get ( u "" bail "" ) ( Js ( u "" nonEmptyClassRanges "" ) ) <TAB><TAB>  return var . get ( u "" res "" ) ","if var . get ( u""res"" ) . neg ( ) :","if var.get(u""res""):",False,26.63821626368723,97.45748570704656
3787,"def _recurse_children ( self , offset ) : <TAB>  """"""Recurses thorugh the available children"""""" <TAB>  while offset < self . obj_offset + self . Length : <TAB><TAB>  item = obj . Object ( "" VerStruct "" , offset = offset , vm = self . obj_vm , parent = self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise StopIteration ( <TAB><TAB><TAB><TAB>  "" Could not recover a key for a child at offset  {0} "" . format ( <TAB><TAB><TAB><TAB><TAB>  item . obj_offset <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  yield item . get_key ( ) , item . get_children ( ) <TAB><TAB>  offset = self . offset_pad ( offset + item . Length ) <TAB>  raise StopIteration ( "" No children "" ) ",if item . Length < 1 or item . get_key ( ) == None :,if item.get_key() != self.key:,False,35.5107312671256,95.59764671554751
3788,"def _adapt_types ( self , descr ) : <TAB>  names = [ ] <TAB>  adapted_types = [ ] <TAB>  for col in descr : <TAB><TAB>  names . append ( col [ 0 ] ) <TAB><TAB>  impala_typename = col [ 1 ] <TAB><TAB>  typename = udf . _impala_to_ibis_type [ impala_typename . lower ( ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  precision , scale = col [ 4 : 6 ] <TAB><TAB><TAB>  adapted_types . append ( dt . Decimal ( precision , scale ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  adapted_types . append ( typename ) <TAB>  return names , adapted_types ","if typename == ""decimal"" :",if typename == 'decimal':,False,51.14971274985165,97.5039964784901
3789,"def sniff ( self , filename ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with tarfile . open ( filename , "" r "" ) as temptar : <TAB><TAB><TAB><TAB>  for f in temptar : <TAB><TAB><TAB><TAB><TAB>  if not f . isfile ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB><TAB>  if f . name . endswith ( "" .fast5 "" ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB><TAB>  return False <TAB>  except Exception as e : <TAB><TAB>  log . warning ( "" %s , sniff Exception:  %s "" , self , e ) <TAB>  return False ",if filename and tarfile . is_tarfile ( filename ) :,if os.path.exists(filename):,False,24.03636686020204,96.47847145068049
3790,"def getValue ( self ) : <TAB>  if getattr ( self . object , "" type "" , "" "" ) != "" CURVE "" : <TAB><TAB>  return BezierSpline ( ) <TAB>  evaluatedObject = getEvaluatedID ( self . object ) <TAB>  bSplines = evaluatedObject . data . splines <TAB>  if len ( bSplines ) > 0 : <TAB><TAB>  spline = createSplineFromBlenderSpline ( bSplines [ 0 ] ) <TAB><TAB>  # Is None when the spline type is not supported. <TAB><TAB>  if spline is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  spline . transform ( evaluatedObject . matrix_world ) <TAB><TAB><TAB>  return spline <TAB>  return BezierSpline ( ) ",if self . useWorldSpace :,if spline.type == 'BLEMESH':,False,59.41198907998382,95.73787491900966
3791,"def escape ( text , newline = False ) : <TAB>  """"""Escape special html characters."""""" <TAB>  if isinstance ( text , str ) : <TAB><TAB>  if "" & "" in text : <TAB><TAB><TAB>  text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB>  if "" < "" in text : <TAB><TAB><TAB>  text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB>  if ' "" ' in text : <TAB><TAB><TAB>  text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB>  if "" ' "" in text : <TAB><TAB><TAB>  text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB>  if newline : <TAB><TAB><TAB>  if "" \n "" in text : <TAB><TAB><TAB><TAB>  text = text . replace ( "" \n "" , "" <br> "" ) <TAB>  return text ","if "">"" in text :","if "">"" in text:",False,50.171043615281484,100.00000000000004
3792,"def _get_ilo_version ( self ) : <TAB>  try : <TAB><TAB>  self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB>  except ResponseError as e : <TAB><TAB>  if hasattr ( e , "" code "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return 3 <TAB><TAB><TAB>  if e . code == 501 : <TAB><TAB><TAB><TAB>  return 1 <TAB><TAB>  raise <TAB>  return 2 ",if e . code == 405 :,if e.code == 501:,False,26.251791167006505,98.33035848825607
3793,"def convert_path ( ctx , tpath ) : <TAB>  for points , code in tpath . iter_segments ( ) : <TAB><TAB>  if code == Path . MOVETO : <TAB><TAB><TAB>  ctx . move_to ( * points ) <TAB><TAB>  elif code == Path . LINETO : <TAB><TAB><TAB>  ctx . line_to ( * points ) <TAB><TAB>  elif code == Path . CURVE3 : <TAB><TAB><TAB>  ctx . curve_to ( <TAB><TAB><TAB><TAB>  points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB>  ) <TAB><TAB>  elif code == Path . CURVE4 : <TAB><TAB><TAB>  ctx . curve_to ( * points ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ctx . close_path ( ) ",elif code == Path . CLOSEPOLY :,"if ctx.path_to(points[0], points[1], points[2],",False,25.135264603261508,90.48557362267643
3794,"def called_by_shrinker ( ) : <TAB>  frame = sys . _getframe ( 0 ) <TAB>  while frame : <TAB><TAB>  fname = frame . f_globals . get ( "" __file__ "" , "" "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  frame = frame . f_back <TAB>  return False ","if os . path . basename ( fname ) == ""shrinker.py"" :",if fname.startswith('shrinker') and (not fname.startswith('.,False,22.476481980430215,84.59248128998118
3795,"def _ensuresyspath ( self , ensuremode , path ) : <TAB>  if ensuremode : <TAB><TAB>  s = str ( path ) <TAB><TAB>  if ensuremode == "" append "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sys . path . append ( s ) <TAB><TAB>  else : <TAB><TAB><TAB>  if s != sys . path [ 0 ] : <TAB><TAB><TAB><TAB>  sys . path . insert ( 0 , s ) ",if s not in sys . path :,if ensuremode == 'append':,False,48.913226324422745,94.15681921353968
3796,"def get_instances ( self , region : str , vpc : str ) : <TAB>  try : <TAB><TAB>  await self . _cache_instances ( region ) <TAB><TAB>  return [ <TAB><TAB><TAB>  instance <TAB><TAB><TAB>  for instance in self . _instances_cache [ region ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  ] <TAB>  except Exception as e : <TAB><TAB>  print_exception ( f "" Failed to get RDS instances:  { e } "" ) <TAB><TAB>  return [ ] ","if instance [ ""VpcId"" ] == vpc",if instance.get_vpc() == vpc:,False,47.62246559020618,92.95551494210439
3797,def get_and_set_all_disambiguation ( self ) : <TAB>  all_disambiguations = [ ] <TAB>  for page in self . pages : <TAB><TAB>  if page . relations . disambiguation_links_norm is not None : <TAB><TAB><TAB>  all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB>  return set ( all_disambiguations ) ,if page . relations . disambiguation_links is not None :,if page.relations.disambiguation_links is not None:,False,53.172434934431415,100.00000000000004
3798,"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB>  res = "" "" <TAB>  cnt = 0 <TAB>  for e in self . options_ : <TAB><TAB>  elm = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elm = "" ( %d ) "" % cnt <TAB><TAB>  res + = prefix + ( "" options %s  < \n "" % elm ) <TAB><TAB>  res + = e . __str__ ( prefix + ""<TAB>"" , printElemNumber ) <TAB><TAB>  res + = prefix + "" > \n "" <TAB><TAB>  cnt + = 1 <TAB>  return res ",if printElemNumber :,if e.type == 'option':,False,17.73469301424468,92.7292127011545
3799,"def pre_save_task ( self , task , credentials , verrors ) : <TAB>  if task [ "" attributes "" ] [ "" encryption "" ] not in ( None , "" "" , "" AES256 "" ) : <TAB><TAB>  verrors . add ( "" encryption "" , ' Encryption should be null or  "" AES256 "" ' ) <TAB>  if not credentials [ "" attributes "" ] . get ( "" skip_region "" , False ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  response = await self . middleware . run_in_thread ( <TAB><TAB><TAB><TAB>  self . _get_client ( credentials ) . get_bucket_location , <TAB><TAB><TAB><TAB>  Bucket = task [ "" attributes "" ] [ "" bucket "" ] , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  task [ "" attributes "" ] [ "" region "" ] = response [ "" LocationConstraint "" ] or "" us-east-1 "" ","if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :",if self.middleware:,False,45.0743444256071,89.26802056477855
3800,"def get_best_config_reward ( self ) : <TAB>  """"""Returns the best configuration found so far, as well as the reward associated with this best config."""""" <TAB>  with self . LOCK : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  config_pkl = max ( self . _results , key = self . _results . get ) <TAB><TAB><TAB>  return pickle . loads ( config_pkl ) , self . _results [ config_pkl ] <TAB><TAB>  else : <TAB><TAB><TAB>  return dict ( ) , self . _reward_while_pending ( ) ",if self . _results :,if self._results.get:,False,66.90455287955113,97.65013840543726
3801,"def parse_setup_cfg ( self ) : <TAB>  # type: () -> Dict[STRING_TYPE, Any] <TAB>  if self . setup_cfg is not None and self . setup_cfg . exists ( ) : <TAB><TAB>  contents = self . setup_cfg . read_text ( ) <TAB><TAB>  base_dir = self . setup_cfg . absolute ( ) . parent . as_posix ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  parsed = setuptools_parse_setup_cfg ( self . setup_cfg . as_posix ( ) ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  contents = self . setup_cfg . read_bytes ( ) <TAB><TAB><TAB>  parsed = parse_setup_cfg ( contents , base_dir ) <TAB><TAB>  if not parsed : <TAB><TAB><TAB>  return { } <TAB><TAB>  return parsed <TAB>  return { } ",if six . PY2 :,if contents is None:,False,30.964508661267022,98.1333294637598
3802,"def readall ( read_fn , sz ) : <TAB>  buff = b "" "" <TAB>  have = 0 <TAB>  while have < sz : <TAB><TAB>  chunk = yield from read_fn ( sz - have ) <TAB><TAB>  have + = len ( chunk ) <TAB><TAB>  buff + = chunk <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TTransportException ( <TAB><TAB><TAB><TAB>  TTransportException . END_OF_FILE , "" End of file reading from transport "" <TAB><TAB><TAB>  ) <TAB>  return buff ",if len ( chunk ) == 0 :,if have == sz:,False,47.95061579970007,94.50191341170131
3803,"def _get_use_previous ( <TAB>  f ,  ) :<TAB># TODO Sort and group features for DateOffset with two different temporal values <TAB>  if isinstance ( f , AggregationFeature ) and f . use_previous is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ( "" "" , - 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  unit = list ( f . use_previous . times . keys ( ) ) [ 0 ] <TAB><TAB><TAB>  value = f . use_previous . times [ unit ] <TAB><TAB><TAB>  return ( unit , value ) <TAB>  else : <TAB><TAB>  return ( "" "" , - 1 ) ",if len ( f . use_previous . times . keys ( ) ) > 1 :,if f.use_previous.times is None:,False,24.064031494873706,90.15334600635563
3804,"def istrue ( self ) : <TAB>  try : <TAB><TAB>  return self . _istrue ( ) <TAB>  except Exception : <TAB><TAB>  self . exc = sys . exc_info ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg = [ <TAB><TAB><TAB><TAB>  "" "" * ( self . exc [ 1 ] . offset + 4 ) + "" ^ "" , <TAB><TAB><TAB>  ] <TAB><TAB><TAB>  msg . append ( "" SyntaxError: invalid syntax "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  msg = traceback . format_exception_only ( * self . exc [ : 2 ] ) <TAB><TAB>  pytest . fail ( <TAB><TAB><TAB>  "" Error evaluating  %r  expression \n "" <TAB><TAB><TAB>  ""<TAB>  %s \n "" <TAB><TAB><TAB>  "" %s "" % ( self . name , self . expr , "" \n "" . join ( msg ) ) , <TAB><TAB><TAB>  pytrace = False , <TAB><TAB>  ) ","if isinstance ( self . exc [ 1 ] , SyntaxError ) :",if self.exc[1].offset < 2:,False,48.6434165294735,97.08002018234158
3805,"def wait_for_crm_operation ( operation , crm ) : <TAB>  """"""Poll for cloud resource manager operation until finished."""""" <TAB>  logger . info ( <TAB><TAB>  "" wait_for_crm_operation:  "" <TAB><TAB>  "" Waiting for operation  {}  to finish... "" . format ( operation ) <TAB>  ) <TAB>  for _ in range ( MAX_POLLS ) : <TAB><TAB>  result = crm . operations ( ) . get ( name = operation [ "" name "" ] ) . execute ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( result [ "" error "" ] ) <TAB><TAB>  if "" done "" in result and result [ "" done "" ] : <TAB><TAB><TAB>  logger . info ( "" wait_for_crm_operation: Operation done. "" ) <TAB><TAB><TAB>  break <TAB><TAB>  time . sleep ( POLL_INTERVAL ) <TAB>  return result ","if ""error"" in result :",if result['error']:,False,31.484675489384546,97.2850320827999
3806,"def cb_blob_detail_from_elem_and_buf ( self , elem , buf ) : <TAB>  if elem . get ( "" lang "" ) != buf . lang :<TAB># multi-lang doc <TAB><TAB>  return "" %s  Code in  %s "" % ( elem . get ( "" lang "" ) , buf . path ) <TAB>  else : <TAB><TAB>  dir , base = os . path . split ( buf . path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" %s  ( %s ) "" % ( base , dir ) <TAB><TAB>  else : <TAB><TAB><TAB>  return base ",if dir :,if dir:,False,46.73253631871365,97.02111788734693
3807,"def removedir ( self , path ) : <TAB>  # type: (Text) -> None <TAB>  _path = self . validatepath ( path ) <TAB>  if _path == "" / "" : <TAB><TAB>  raise errors . RemoveRootError ( ) <TAB>  with ftp_errors ( self , path ) : <TAB><TAB>  try : <TAB><TAB><TAB>  self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB><TAB>  except error_perm as error : <TAB><TAB><TAB>  code , _ = _parse_ftp_error ( error ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if self . isfile ( path ) : <TAB><TAB><TAB><TAB><TAB>  raise errors . DirectoryExpected ( path ) <TAB><TAB><TAB><TAB>  if not self . isempty ( path ) : <TAB><TAB><TAB><TAB><TAB>  raise errors . DirectoryNotEmpty ( path ) <TAB><TAB><TAB>  raise<TAB># pragma: no cover ","if code == ""550"" :",if code == errno.ENOENT:,False,27.33631171781814,96.51055552773943
3808,"def p_clause ( self , node , position ) : <TAB>  if isinstance ( node , Graph ) : <TAB><TAB>  self . subjectDone ( node ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . write ( "" "" ) <TAB><TAB>  self . write ( "" { "" ) <TAB><TAB>  self . depth + = 1 <TAB><TAB>  serializer = N3Serializer ( node , parent = self ) <TAB><TAB>  serializer . serialize ( self . stream ) <TAB><TAB>  self . depth - = 1 <TAB><TAB>  self . write ( self . indent ( ) + "" } "" ) <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  return False ",if position is OBJECT :,if self.depth > 0:,False,20.998852198369576,96.2031212408256
3809,"def get_default_shell_info ( shell_name = None , settings = None ) : <TAB>  if not shell_name : <TAB><TAB>  settings = settings or load_settings ( lazy = True ) <TAB><TAB>  shell_name = settings . get ( "" shell "" ) <TAB><TAB>  if shell_name : <TAB><TAB><TAB>  return shell_name , None <TAB><TAB>  shell_path = os . environ . get ( "" SHELL "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shell_name = basepath ( shell_path ) <TAB><TAB>  else : <TAB><TAB><TAB>  shell_name = DEFAULT_SHELL <TAB><TAB>  return shell_name , shell_path <TAB>  return shell_name , None ",if shell_path :,if shell_path:,False,51.764927712513334,100.00000000000004
3810,"def GetCategory ( self , pidls ) : <TAB>  ret = [ ] <TAB>  for pidl in pidls : <TAB><TAB>  # Why don't we just get the size of the PIDL? <TAB><TAB>  val = self . sf . GetDetailsEx ( pidl , PKEY_Sample_AreaSize ) <TAB><TAB>  val = int ( val )<TAB># it probably came in a VT_BSTR variant <TAB><TAB>  if val < 255 / / 3 : <TAB><TAB><TAB>  cid = IDS_SMALL <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cid = IDS_MEDIUM <TAB><TAB>  else : <TAB><TAB><TAB>  cid = IDS_LARGE <TAB><TAB>  ret . append ( cid ) <TAB>  return ret ",elif val < 2 * 255 // 3 :,if val < 255 / 3:,False,62.22965736378608,95.12006449458985
3811,"def Tokenize ( s ) : <TAB>  # type: (str) -> Iterator[Token] <TAB>  for item in TOKEN_RE . findall ( s ) : <TAB><TAB>  # The type checker can't know the true type of item! <TAB><TAB>  item = cast ( TupleStr4 , item ) <TAB><TAB>  if item [ 0 ] : <TAB><TAB><TAB>  typ = "" number "" <TAB><TAB><TAB>  val = item [ 0 ] <TAB><TAB>  elif item [ 1 ] : <TAB><TAB><TAB>  typ = "" name "" <TAB><TAB><TAB>  val = item [ 1 ] <TAB><TAB>  elif item [ 2 ] : <TAB><TAB><TAB>  typ = item [ 2 ] <TAB><TAB><TAB>  val = item [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  typ = item [ 3 ] <TAB><TAB><TAB>  val = item [ 3 ] <TAB><TAB>  yield Token ( typ , val ) ",elif item [ 3 ] :,if item[3]:,False,33.49868608101158,98.97850561577883
3812,"def add_package_declarations ( generated_root_path ) : <TAB>  file_names = os . listdir ( generated_root_path ) <TAB>  for file_name in file_names : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  full_name = os . path . join ( generated_root_path , file_name ) <TAB><TAB>  add_package ( full_name ) ","if not file_name . endswith ( "".java"" ) :",if file_name.startswith('.py') or file_name.startswith(',False,28.429734490159163,85.97214914894356
3813,"def _call_with_retry ( out , retry , retry_wait , method , * args , * * kwargs ) : <TAB>  for counter in range ( retry + 1 ) : <TAB><TAB>  try : <TAB><TAB><TAB>  return method ( * args , * * kwargs ) <TAB><TAB>  except ( <TAB><TAB><TAB>  NotFoundException , <TAB><TAB><TAB>  ForbiddenException , <TAB><TAB><TAB>  AuthenticationException , <TAB><TAB><TAB>  RequestErrorException , <TAB><TAB>  ) : <TAB><TAB><TAB>  raise <TAB><TAB>  except ConanException as exc : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  if out : <TAB><TAB><TAB><TAB><TAB>  out . error ( exc ) <TAB><TAB><TAB><TAB><TAB>  out . info ( "" Waiting  %d  seconds to retry... "" % retry_wait ) <TAB><TAB><TAB><TAB>  time . sleep ( retry_wait ) ",if counter == retry :,if exc.code == 'ForbiddenException':,False,21.950891923050808,97.56225329884579
3814,"def to_wburl_str ( <TAB>  url , type = BaseWbUrl . LATEST_REPLAY , mod = "" "" , timestamp = "" "" , end_timestamp = "" ""  ) : <TAB>  if WbUrl . is_query_type ( type ) : <TAB><TAB>  tsmod = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tsmod + = mod + "" / "" <TAB><TAB>  tsmod + = timestamp <TAB><TAB>  tsmod + = "" * "" <TAB><TAB>  tsmod + = end_timestamp <TAB><TAB>  tsmod + = "" / "" + url <TAB><TAB>  if type == BaseWbUrl . URL_QUERY : <TAB><TAB><TAB>  tsmod + = "" * "" <TAB><TAB>  return tsmod <TAB>  else : <TAB><TAB>  tsmod = timestamp + mod <TAB><TAB>  if len ( tsmod ) > 0 : <TAB><TAB><TAB>  return tsmod + "" / "" + url <TAB><TAB>  else : <TAB><TAB><TAB>  return url ",if mod :,if type == BaseWbUrl.URL_ACCEPT:,False,32.716509484039356,96.1583529451472
3815,"def _configured_ploidy ( items ) : <TAB>  ploidies = collections . defaultdict ( set ) <TAB>  for data in items : <TAB><TAB>  ploidy = dd . get_ploidy ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for k , v in ploidy . items ( ) : <TAB><TAB><TAB><TAB>  ploidies [ k ] . add ( v ) <TAB><TAB>  else : <TAB><TAB><TAB>  ploidies [ "" default "" ] . add ( ploidy ) <TAB>  out = { } <TAB>  for k , vs in ploidies . items ( ) : <TAB><TAB>  assert len ( vs ) == 1 , "" Multiple ploidies set for group calling:  %s %s "" % ( <TAB><TAB><TAB>  k , <TAB><TAB><TAB>  list ( vs ) , <TAB><TAB>  ) <TAB><TAB>  out [ k ] = vs . pop ( ) <TAB>  return out ","if isinstance ( ploidy , dict ) :",if ploidy:,False,29.838279588234585,96.8262646493307
3816,"def removeUser ( self , username ) : <TAB>  hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB>  if username in self . _users : <TAB><TAB>  user = self . _users [ username ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . isRoomSame ( user . room ) : <TAB><TAB><TAB><TAB>  hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB>  if username in self . _users : <TAB><TAB>  self . _users . pop ( username ) <TAB><TAB>  message = getMessage ( "" left-notification "" ) . format ( username ) <TAB><TAB>  self . ui . showMessage ( message , hideFromOSD ) <TAB><TAB>  self . _client . lastLeftTime = time . time ( ) <TAB><TAB>  self . _client . lastLeftUser = username <TAB>  self . userListChange ( ) ",if user . room :,if user:,False,25.22275104314728,98.26935071261258
3817,"def _thd_cleanup_instance ( self ) : <TAB>  container_name = self . getContainerName ( ) <TAB>  instances = self . client . containers ( all = 1 , filters = dict ( name = container_name ) ) <TAB>  for instance in instances : <TAB><TAB>  # hyper filtering will match 'hyper12"" if you search for 'hyper1' ! <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  self . client . remove_container ( instance [ "" Id "" ] , v = True , force = True ) <TAB><TAB>  except NotFound : <TAB><TAB><TAB>  pass<TAB># that's a race condition <TAB><TAB>  except docker . errors . APIError as e : <TAB><TAB><TAB>  if "" Conflict operation on container "" not in str ( e ) : <TAB><TAB><TAB><TAB>  raise ","if """" . join ( instance [ ""Names"" ] ) . strip ( ""/"" ) != container_name :",if instance['Id'] == container_name:,False,60.415203641925565,90.38028121053638
3818,"def handle_ctcp ( self , conn , evt ) : <TAB>  args = evt . arguments ( ) <TAB>  source = evt . source ( ) . split ( "" ! "" ) [ 0 ] <TAB>  if args : <TAB><TAB>  if args [ 0 ] == "" VERSION "" : <TAB><TAB><TAB>  conn . ctcp_reply ( source , "" VERSION  "" + BOT_VERSION ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  conn . ctcp_reply ( source , "" PING "" ) <TAB><TAB>  elif args [ 0 ] == "" CLIENTINFO "" : <TAB><TAB><TAB>  conn . ctcp_reply ( source , "" CLIENTINFO PING VERSION CLIENTINFO "" ) ","elif args [ 0 ] == ""PING"" :","if args[0] == ""PING':",False,20.367444468229042,96.40272259966406
3819,"def new_func ( self , * args , * * kwargs ) : <TAB>  obj = self . obj_ref ( ) <TAB>  attr = self . attr <TAB>  if obj is not None : <TAB><TAB>  args = tuple ( TrackedValue . make ( obj , attr , arg ) for arg in args ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs = { <TAB><TAB><TAB><TAB>  key : TrackedValue . make ( obj , attr , value ) <TAB><TAB><TAB><TAB>  for key , value in iteritems ( kwargs ) <TAB><TAB><TAB>  } <TAB>  result = func ( self , * args , * * kwargs ) <TAB>  self . _changed_ ( ) <TAB>  return result ",if kwargs :,if kwargs:,False,49.272714690246076,100.00000000000004
3820,"def add_doc ( target , variables , body_lines ) : <TAB>  if isinstance ( target , ast . Name ) : <TAB><TAB>  # if it is a variable name add it to the doc <TAB><TAB>  name = target . id <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  doc = find_doc_for ( target , body_lines ) <TAB><TAB><TAB>  if doc is not None : <TAB><TAB><TAB><TAB>  variables [ name ] = doc <TAB>  elif isinstance ( target , ast . Tuple ) : <TAB><TAB>  # if it is a tuple then iterate the elements <TAB><TAB>  # this can happen like this: <TAB><TAB>  # a, b = 1, 2 <TAB><TAB>  for e in target . elts : <TAB><TAB><TAB>  add_doc ( e , variables , body_lines ) ",if name not in variables :,"if isinstance(target, (ast.Tuple, ast.List)):",False,64.76245232824951,93.02945398941208
3821,"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB>  try : <TAB><TAB>  if tp == "" write "" : <TAB><TAB><TAB>  out . write ( msg ) <TAB><TAB>  elif tp == "" flush "" : <TAB><TAB><TAB>  out . flush ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out . write ( msg ) <TAB><TAB><TAB>  out . flush ( ) <TAB><TAB>  elif tp == "" print "" : <TAB><TAB><TAB>  print ( msg , file = out ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" Unsupported type:  "" + tp ) <TAB>  except IOError as e : <TAB><TAB>  logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB><TAB>  pass ","elif tp == ""write_flush"" :","if tp == ""write':",False,45.33258901367594,96.66462281387992
3822,"def get_files ( d ) : <TAB>  res = [ ] <TAB>  for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB>  if not p : <TAB><TAB><TAB>  continue <TAB><TAB>  ( pth , fname ) = os . path . split ( p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if os . path . islink ( p ) : <TAB><TAB><TAB>  continue <TAB><TAB>  if os . path . isdir ( p ) : <TAB><TAB><TAB>  res + = get_dir ( p ) <TAB><TAB>  else : <TAB><TAB><TAB>  res . append ( p ) <TAB>  return res ",if skip_file ( fname ) :,if os.path.isfile(pth):,False,22.21048452819732,95.68402903648628
3823,"def _list_outputs ( self ) : <TAB>  outputs = super ( VolSymm , self ) . _list_outputs ( ) <TAB>  # Have to manually check for the grid files. <TAB>  if os . path . exists ( outputs [ "" trans_file "" ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  outputs [ "" output_grid "" ] = re . sub ( <TAB><TAB><TAB><TAB>  "" .(nlxfm|xfm)$ "" , "" _grid_0.mnc "" , outputs [ "" trans_file "" ] <TAB><TAB><TAB>  ) <TAB>  return outputs ","if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :",if os.path.exists(outputs['trans_file']):,False,59.16397979685595,87.00231069211378
3824,"def _set_texture ( self , texture ) : <TAB>  if texture . id is not self . _texture . id : <TAB><TAB>  self . _group = SpriteGroup ( <TAB><TAB><TAB>  texture , self . _group . blend_src , self . _group . blend_dest , self . _group . parent <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB><TAB>  else : <TAB><TAB><TAB>  self . _vertex_list . delete ( ) <TAB><TAB><TAB>  self . _texture = texture <TAB><TAB><TAB>  self . _create_vertex_list ( ) <TAB>  else : <TAB><TAB>  self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB>  self . _texture = texture ",if self . _batch is None :,if self._vertex_list is None:,False,28.567446042677247,97.99169879152134
3825,"def got_result ( result ) : <TAB>  deployment = self . persistence_service . get ( ) <TAB>  for node in deployment . nodes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dataset_ids = [ <TAB><TAB><TAB><TAB>  ( m . dataset . deleted , m . dataset . dataset_id ) <TAB><TAB><TAB><TAB>  for m in node . manifestations . values ( ) <TAB><TAB><TAB>  ] <TAB><TAB><TAB>  self . assertIn ( ( True , expected_dataset_id ) , dataset_ids ) <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  self . fail ( "" Node not found.  {} "" . format ( node . uuid ) ) ","if same_node ( node , origin ) :",if node.uuid == node.uuid:,False,39.24939291656019,95.18868076192796
3826,"def check_result ( result , func , arguments ) : <TAB>  if check_warning ( result ) and ( result . value != ReturnCode . WARN_NODATA ) : <TAB><TAB>  log . warning ( UcanWarning ( result , func , arguments ) ) <TAB>  elif check_error ( result ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise UcanCmdError ( result , func , arguments ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise UcanError ( result , func , arguments ) <TAB>  return result ",if check_error_cmd ( result ) :,if result.value == ReturnCode.ERROR:,False,24.104177738610485,92.83919961821577
3827,"def _compress_and_sort_bdg_files ( out_dir , data ) : <TAB>  for fn in glob . glob ( os . path . join ( out_dir , "" *bdg "" ) ) : <TAB><TAB>  out_file = fn + "" .gz "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  bedtools = config_utils . get_program ( "" bedtools "" , data ) <TAB><TAB>  with file_transaction ( out_file ) as tx_out_file : <TAB><TAB><TAB>  cmd = f "" sort -k1,1 -k2,2n  { fn }  | bgzip -c >  { tx_out_file } "" <TAB><TAB><TAB>  message = f "" Compressing and sorting  { fn } . "" <TAB><TAB><TAB>  do . run ( cmd , message ) ",if utils . file_exists ( out_file ) :,if os.path.exists(out_file):,False,25.62876753145744,97.3876016002688
3828,"def kill_members ( members , sig , hosts = nodes ) : <TAB>  for member in sorted ( members ) : <TAB><TAB>  try : <TAB><TAB><TAB>  if ha_tools_debug : <TAB><TAB><TAB><TAB>  print ( "" killing  %s "" % member ) <TAB><TAB><TAB>  proc = hosts [ member ] [ "" proc "" ] <TAB><TAB><TAB>  # Not sure if cygwin makes sense here... <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . kill ( proc . pid , signal . CTRL_C_EVENT ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  os . kill ( proc . pid , sig ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  if ha_tools_debug : <TAB><TAB><TAB><TAB>  print ( "" %s  already dead? "" % member ) ","if sys . platform in ( ""win32"" , ""cygwin"" ) :",if proc.flags & signal.CTRL_C_EVENT:,False,56.10209552908748,94.14447537480002
3829,"def get_top_level_stats ( self ) : <TAB>  for func , ( cc , nc , tt , ct , callers ) in self . stats . items ( ) : <TAB><TAB>  self . total_calls + = nc <TAB><TAB>  self . prim_calls + = cc <TAB><TAB>  self . total_tt + = tt <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . top_level [ func ] = None <TAB><TAB>  if len ( func_std_string ( func ) ) > self . max_name_len : <TAB><TAB><TAB>  self . max_name_len = len ( func_std_string ( func ) ) ","if ( ""jprofile"" , 0 , ""profiler"" ) in callers :",if func not in self.top_level:,False,19.25289218342015,91.76109897866561
3830,"def __str__ ( self ) : <TAB>  """"""Only keeps the True values."""""" <TAB>  result = [ "" SlicingSpec( "" ] <TAB>  if self . entire_dataset : <TAB><TAB>  result . append ( ""  Entire dataset, "" ) <TAB>  if self . by_class : <TAB><TAB>  if isinstance ( self . by_class , Iterable ) : <TAB><TAB><TAB>  result . append ( ""  Into classes  %s , "" % self . by_class ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( ""  Up to class  %d , "" % self . by_class ) <TAB><TAB>  else : <TAB><TAB><TAB>  result . append ( ""  By classes, "" ) <TAB>  if self . by_percentiles : <TAB><TAB>  result . append ( ""  By percentiles, "" ) <TAB>  if self . by_classification_correctness : <TAB><TAB>  result . append ( ""  By classification correctness, "" ) <TAB>  result . append ( "" ) "" ) <TAB>  return "" \n "" . join ( result ) ","elif isinstance ( self . by_class , int ) :",if self.by_class:,False,51.23609230292776,96.62140342508688
3831,"def save_params ( self ) : <TAB>  if self . _save_controller : <TAB><TAB>  if not os . path . exists ( self . _save_controller ) : <TAB><TAB><TAB>  os . makedirs ( self . _save_controller ) <TAB><TAB>  output_dir = self . _save_controller <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( "" ./.rlnas_controller "" ) <TAB><TAB>  output_dir = "" ./.rlnas_controller "" <TAB>  with open ( os . path . join ( output_dir , "" rlnas.params "" ) , "" wb "" ) as f : <TAB><TAB>  pickle . dump ( self . _params_dict , f ) <TAB>  _logger . debug ( "" Save params done "" ) ","if not os . path . exists ( ""./.rlnas_controller"" ) :",if not os.path.exists(os.path.join(self._save_controller,False,20.902928065661854,94.1370196078618
3832,"def unexport ( self , pin ) : <TAB>  with self . _lock : <TAB><TAB>  self . _pin_refs [ pin ] - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with io . open ( self . path ( "" unexport "" ) , "" wb "" ) as f : <TAB><TAB><TAB><TAB>  f . write ( str ( pin ) . encode ( "" ascii "" ) ) ",if self . _pin_refs [ pin ] == 0 :,if not self._pin_refs[pin] > 0:,False,21.302392249250214,95.47309878401474
3833,"def emit ( self , type , info = None ) : <TAB>  # Overload emit() to send events to the proxy object at the other end <TAB>  ev = super ( ) . emit ( type , info ) <TAB>  if self . _has_proxy is True and self . _session . status > 0 : <TAB><TAB>  # implicit: and self._disposed is False: <TAB><TAB>  if type in self . __proxy_properties__ : <TAB><TAB><TAB>  self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) ",elif type in self . __event_types_at_proxy :,if self._disposed:,False,62.730353460846175,93.04362981656939
3834,"def __call__ ( self , params ) : <TAB>  all_errs = { } <TAB>  for handler in self . handlers : <TAB><TAB>  out_headers , res , errs = handler ( params ) <TAB><TAB>  all_errs . update ( errs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return out_headers , res , all_errs <TAB>  return None , None , all_errs ",if res is not None :,if out_headers:,False,27.510370896540522,94.675812549843
3835,"def await_test_end ( self ) : <TAB>  iterations = 0 <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log . debug ( "" Await: iteration limit reached "" ) <TAB><TAB><TAB>  return <TAB><TAB>  status = self . master . get_status ( ) <TAB><TAB>  if status . get ( "" status "" ) == "" ENDED "" : <TAB><TAB><TAB>  return <TAB><TAB>  iterations + = 1 <TAB><TAB>  time . sleep ( 1.0 ) ",if iterations > 100 :,if iterations > self.max_iterations:,False,46.84308152307878,95.29628739420244
3836,"def _load ( self , path : str ) : <TAB>  ds = DataSet ( ) <TAB>  with open ( path , "" r "" , encoding = "" utf-8 "" ) as f : <TAB><TAB>  for line in f : <TAB><TAB><TAB>  line = line . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  parts = line . split ( "" \t "" ) <TAB><TAB><TAB><TAB>  raw_words1 = parts [ 1 ] <TAB><TAB><TAB><TAB>  raw_words2 = parts [ 2 ] <TAB><TAB><TAB><TAB>  target = parts [ 0 ] <TAB><TAB><TAB><TAB>  if raw_words1 and raw_words2 and target : <TAB><TAB><TAB><TAB><TAB>  ds . append ( <TAB><TAB><TAB><TAB><TAB><TAB>  Instance ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  raw_words1 = raw_words1 , raw_words2 = raw_words2 , target = target <TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB><TAB>  ) <TAB>  return ds ",if line :,if line:,False,53.58994176629671,100.00000000000004
3837,"def avatar_delete ( event_id , speaker_id ) : <TAB>  if request . method == "" DELETE "" : <TAB><TAB>  speaker = ( <TAB><TAB><TAB>  DataGetter . get_speakers ( event_id ) <TAB><TAB><TAB>  . filter_by ( user_id = login . current_user . id , id = speaker_id ) <TAB><TAB><TAB>  . first ( ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  speaker . photo = "" "" <TAB><TAB><TAB>  speaker . small = "" "" <TAB><TAB><TAB>  speaker . thumbnail = "" "" <TAB><TAB><TAB>  speaker . icon = "" "" <TAB><TAB><TAB>  save_to_db ( speaker ) <TAB><TAB><TAB>  return jsonify ( { "" status "" : "" ok "" } ) <TAB><TAB>  else : <TAB><TAB><TAB>  abort ( 403 ) ",if speaker :,if speaker:,False,50.485557210269135,100.00000000000004
3838,"def getline ( filename , lineno , * args , * * kwargs ) : <TAB>  line = py2exe_getline ( filename , lineno , * args , * * kwargs ) <TAB>  if not line : <TAB><TAB>  try : <TAB><TAB><TAB>  with open ( filename , "" rb "" ) as f : <TAB><TAB><TAB><TAB>  for i , line in enumerate ( f ) : <TAB><TAB><TAB><TAB><TAB>  line = line . decode ( "" utf-8 "" ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  line = "" "" <TAB><TAB>  except ( IOError , OSError ) : <TAB><TAB><TAB>  line = "" "" <TAB>  return line ",if lineno == i + 1 :,if line == line:,False,23.06055443556635,96.95996239552822
3839,"def write ( self , data ) : <TAB>  if not isinstance ( data , ( bytes , bytearray , memoryview ) ) : <TAB><TAB>  raise TypeError ( "" data argument must be byte-ish ( %r ) "" , type ( data ) ) <TAB>  if not data : <TAB><TAB>  return <TAB>  if self . _conn_lost : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( "" socket.send() raised exception. "" ) <TAB><TAB>  self . _conn_lost + = 1 <TAB><TAB>  return <TAB>  if not self . _buffer : <TAB><TAB>  self . _loop . add_writer ( self . _sock_fd , self . _write_ready ) <TAB>  # Add it to the buffer. <TAB>  self . _buffer . extend ( data ) <TAB>  self . _maybe_pause_protocol ( ) ",if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,if self._conn_lost == 0:,False,53.13933878003656,93.52000695807278
3840,"def _get_x_for_y ( self , xValue , x , y ) : <TAB>  # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB>  if not self . xmlMap : <TAB><TAB>  return 0 <TAB>  x_value = str ( xValue ) <TAB>  for anime in self . xmlMap . findall ( "" anime "" ) : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return int ( anime . get ( y , 0 ) ) <TAB><TAB>  except ValueError as e : <TAB><TAB><TAB>  continue <TAB>  return 0 ","if anime . get ( x , False ) == x_value :","if anime.get(x, 0) == x_value:",False,37.44395911807435,98.58545597375539
3841,"def _RewriteModinfo ( <TAB>  self , <TAB>  modinfo , <TAB>  obj_kernel_version , <TAB>  this_kernel_version , <TAB>  info_strings = None , <TAB>  to_remove = None ,  ) : <TAB>  new_modinfo = "" "" <TAB>  for line in modinfo . split ( "" \x00 "" ) : <TAB><TAB>  if not line : <TAB><TAB><TAB>  continue <TAB><TAB>  if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB><TAB><TAB>  continue <TAB><TAB>  if info_strings is not None : <TAB><TAB><TAB>  info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB><TAB>  new_modinfo + = line + "" \x00 "" <TAB>  return new_modinfo ","if line . startswith ( ""vermagic"" ) :",if obj_kernel_version is not None and this_kernel_version is not None:,False,47.8987372066286,92.61139092094699
3842,"def _score ( self , X , y ) : <TAB>  for col in self . cols : <TAB><TAB>  # Score the column <TAB><TAB>  X [ col ] = X [ col ] . map ( self . mapping [ col ] ) <TAB><TAB>  # Randomization is meaningful only for training data -> we do it only if y is present <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  random_state_generator = check_random_state ( self . random_state ) <TAB><TAB><TAB>  X [ col ] = X [ col ] * random_state_generator . normal ( <TAB><TAB><TAB><TAB>  1.0 , self . sigma , X [ col ] . shape [ 0 ] <TAB><TAB><TAB>  ) <TAB>  return X ",if self . randomized and y is not None :,if y is not None:,False,64.54253396910951,97.10210861099014
3843,"def onMouseWheel ( self , event ) : <TAB>  if self . selectedHuman . isVisible ( ) : <TAB><TAB>  zoomOut = event . wheelDelta > 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  zoomOut = not zoomOut <TAB><TAB>  if event . x is not None : <TAB><TAB><TAB>  self . modelCamera . mousePickHumanCenter ( event . x , event . y ) <TAB><TAB>  if zoomOut : <TAB><TAB><TAB>  self . zoomOut ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . zoomIn ( ) ","if self . getSetting ( ""invertMouseWheel"" ) :",if zoomOut:,False,22.10273091181582,93.25572611251566
3844,"def prehook ( self , emu , op , eip ) : <TAB>  if op in self . badops : <TAB><TAB>  emu . stopEmu ( ) <TAB><TAB>  raise v_exc . BadOpBytes ( op . va ) <TAB>  if op . mnem in STOS : <TAB><TAB>  if self . arch == "" i386 "" : <TAB><TAB><TAB>  reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB><TAB>  if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB><TAB><TAB>  self . vw . makePointer ( reg , follow = True ) ","elif self . arch == ""amd64"" :",if reg is None:,False,24.050681921251986,94.41044273354561
3845,"def callback ( actions , form , tablename = None ) : <TAB>  if actions : <TAB><TAB>  if tablename and isinstance ( actions , dict ) : <TAB><TAB><TAB>  actions = actions . get ( tablename , [ ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  actions = [ actions ] <TAB><TAB>  [ action ( form ) for action in actions ] ","if not isinstance ( actions , ( list , tuple ) ) :",if actions:,False,32.16163088085599,87.56683330932096
3846,"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB>  result = [ ] <TAB>  for i in range ( 10 ) : <TAB><TAB>  # This line introduces a bug. <TAB><TAB>  if bigger_than_3_only and less_than_7_only and i == 4 : <TAB><TAB><TAB>  continue <TAB><TAB>  if bigger_than_3_only and i < = 3 : <TAB><TAB><TAB>  continue <TAB><TAB>  if less_than_7_only and i > = 7 : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  result . append ( i ) <TAB>  return result ",if even_only and i % 2 != 0 :,if even_only and i == 4:,False,60.55561531516096,96.90907884072388
3847,"def set_trial_values ( self , trial_id : int , values : Sequence [ float ] ) - > None : <TAB>  with self . _lock : <TAB><TAB>  cached_trial = self . _get_cached_trial ( trial_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _check_trial_is_updatable ( cached_trial ) <TAB><TAB><TAB>  updates = self . _get_updates ( trial_id ) <TAB><TAB><TAB>  cached_trial . values = values <TAB><TAB><TAB>  updates . values = values <TAB><TAB><TAB>  return <TAB>  self . _backend . _update_trial ( trial_id , values = values ) ",if cached_trial is not None :,if cached_trial:,False,30.34147580478916,97.45868726044405
3848,"def _get_label_format ( self , workunit ) : <TAB>  for label , label_format in self . LABEL_FORMATTING . items ( ) : <TAB><TAB>  if workunit . has_label ( label ) : <TAB><TAB><TAB>  return label_format <TAB>  # Recursively look for a setting to suppress child label formatting. <TAB>  if workunit . parent : <TAB><TAB>  label_format = self . _get_label_format ( workunit . parent ) <TAB><TAB>  if label_format == LabelFormat . CHILD_DOT : <TAB><TAB><TAB>  return LabelFormat . DOT <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return LabelFormat . SUPPRESS <TAB>  return LabelFormat . FULL ",if label_format == LabelFormat . CHILD_SUPPRESS :,if label_format == LabelFormat.SUPPRESS:,False,61.037241192884316,98.00267149077375
3849,"def open_session ( self , app , request ) : <TAB>  sid = request . cookies . get ( app . session_cookie_name ) <TAB>  if sid : <TAB><TAB>  stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB><TAB>  if stored_session : <TAB><TAB><TAB>  expiration = stored_session . expiration <TAB><TAB><TAB>  if not expiration . tzinfo : <TAB><TAB><TAB><TAB>  expiration = expiration . replace ( tzinfo = utc ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return MongoEngineSession ( <TAB><TAB><TAB><TAB><TAB>  initial = stored_session . data , sid = stored_session . sid <TAB><TAB><TAB><TAB>  ) <TAB>  return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) ) ",if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,if expiration.tzinfo is not None:,False,26.11261624308274,92.82947743647729
3850,"def _manage_torrent_cache ( self ) : <TAB>  """"""Carry tracker/peer/file lists over to new torrent list"""""" <TAB>  for torrent in self . _torrent_cache : <TAB><TAB>  new_torrent = rtorrentlib . common . find_torrent ( torrent . info_hash , self . torrents ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_torrent . files = torrent . files <TAB><TAB><TAB>  new_torrent . peers = torrent . peers <TAB><TAB><TAB>  new_torrent . trackers = torrent . trackers <TAB>  self . _torrent_cache = self . torrents ",if new_torrent is not None :,if new_torrent:,False,33.01740329517729,97.04087938222648
3851,"def _clean_regions ( items , region ) : <TAB>  """"""Intersect region with target file if it exists"""""" <TAB>  variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB>  with utils . tmpfile ( ) as tx_out_file : <TAB><TAB>  target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB><TAB>  if target : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  target = _load_regions ( target ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  target = [ target ] <TAB><TAB><TAB>  return target ","if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :","if isinstance(target, basestring):",False,49.60687908627156,91.67943104494415
3852,def _get_stdout ( self ) : <TAB>  while True : <TAB><TAB>  BUFFER_SIZE = 1000 <TAB><TAB>  stdout_buffer = self . kernel . process . GetSTDOUT ( BUFFER_SIZE ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  yield stdout_buffer ,if len ( stdout_buffer ) == 0 :,if stdout_buffer == None:,False,18.99825631405402,89.99250713383944
3853,"def do_query ( data , q ) : <TAB>  ret = [ ] <TAB>  if not q : <TAB><TAB>  return ret <TAB>  qkey = q [ 0 ] <TAB>  for key , value in iterate ( data ) : <TAB><TAB>  if len ( q ) == 1 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret . append ( value ) <TAB><TAB><TAB>  elif is_iterable ( value ) : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  if not is_iterable ( value ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret . extend ( do_query ( value , q ) ) <TAB>  return ret ",if key == qkey :,if key == qkey:,False,48.26975543521238,97.5596238726516
3854,"def test_expect_setecho_off ( self ) : <TAB>  """"""This tests that echo may be toggled off."""""" <TAB>  p = pexpect . spawn ( "" cat "" , echo = True , timeout = 5 ) <TAB>  try : <TAB><TAB>  self . _expect_echo_toggle ( p ) <TAB>  except IOError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if hasattr ( unittest , "" SkipTest "" ) : <TAB><TAB><TAB><TAB>  raise unittest . SkipTest ( "" Not supported on this platform. "" ) <TAB><TAB><TAB>  return "" skip "" <TAB><TAB>  raise ","if sys . platform . lower ( ) . startswith ( ""sunos"" ) :",if sys.platform == 'win32':,False,55.48369966303568,92.32168729893529
3855,"def _resolve_relative_config ( dir , config ) : <TAB>  # Some code shared between Notebook and NotebookInfo <TAB>  # Resolve icon, can be relative <TAB>  icon = config . get ( "" icon "" ) <TAB>  if icon : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  icon = File ( icon ) <TAB><TAB>  else : <TAB><TAB><TAB>  icon = dir . resolve_file ( icon ) <TAB>  # Resolve document_root, can also be relative <TAB>  document_root = config . get ( "" document_root "" ) <TAB>  if document_root : <TAB><TAB>  if zim . fs . isabs ( document_root ) or not dir : <TAB><TAB><TAB>  document_root = Dir ( document_root ) <TAB><TAB>  else : <TAB><TAB><TAB>  document_root = dir . resolve_dir ( document_root ) <TAB>  return icon , document_root ",if zim . fs . isabs ( icon ) or not dir :,if not dir:,False,34.317340000863915,95.39035573090536
3856,"def _providers ( self , descriptor ) : <TAB>  res = [ ] <TAB>  for _md in self . metadata . values ( ) : <TAB><TAB>  for ent_id , ent_desc in _md . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if ent_id in res : <TAB><TAB><TAB><TAB><TAB>  # print(""duplicated entity_id: %s"" % res) <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  res . append ( ent_id ) <TAB>  return res ",if descriptor in ent_desc :,if ent_desc == descriptor:,False,55.47859139439173,96.70268629309179
3857,"def poll_ms ( self , timeout = - 1 ) : <TAB>  s = bytearray ( self . evbuf ) <TAB>  if timeout > = 0 : <TAB><TAB>  deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB>  while True : <TAB><TAB>  n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB><TAB>  if not os . check_error ( n ) : <TAB><TAB><TAB>  break <TAB><TAB>  if timeout > = 0 : <TAB><TAB><TAB>  timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  n = 0 <TAB><TAB><TAB><TAB>  break <TAB>  res = [ ] <TAB>  if n > 0 : <TAB><TAB>  vals = struct . unpack ( epoll_event , s ) <TAB><TAB>  res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB>  return res ",if timeout < 0 :,if timeout < 0:,False,44.79067752639661,98.60531584317867
3858,"def banned ( ) : <TAB>  if request . endpoint == "" views.themes "" : <TAB><TAB>  return <TAB>  if authed ( ) : <TAB><TAB>  user = get_current_user_attrs ( ) <TAB><TAB>  team = get_current_team_attrs ( ) <TAB><TAB>  if user and user . banned : <TAB><TAB><TAB>  return ( <TAB><TAB><TAB><TAB>  render_template ( <TAB><TAB><TAB><TAB><TAB>  "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  403 , <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return ( <TAB><TAB><TAB><TAB>  render_template ( <TAB><TAB><TAB><TAB><TAB>  "" errors/403.html "" , <TAB><TAB><TAB><TAB><TAB>  error = "" Your team has been banned from this CTF "" , <TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  403 , <TAB><TAB><TAB>  ) ",if team and team . banned :,if not team:,False,57.652843021929755,97.97115058337353
3859,"def _update_read ( self ) : <TAB>  """"""Update state when there is read event"""""" <TAB>  try : <TAB><TAB>  msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB><TAB>  if msg : <TAB><TAB><TAB>  self . on_message ( msg ) <TAB><TAB><TAB>  return True <TAB><TAB>  # normal close, remote is closed <TAB><TAB>  self . close ( ) <TAB>  except socket . error as err : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  self . on_error ( err ) <TAB>  return False ","if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",if err.code == errno.EAGAIN:,False,58.70447189792427,92.29692013274769
3860,"def update_topic_attr_as_not ( modeladmin , request , queryset , attr ) : <TAB>  for topic in queryset : <TAB><TAB>  if attr == "" sticky "" : <TAB><TAB><TAB>  topic . sticky = not topic . sticky <TAB><TAB>  elif attr == "" closed "" : <TAB><TAB><TAB>  topic . closed = not topic . closed <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  topic . hidden = not topic . hidden <TAB><TAB>  topic . save ( ) ","elif attr == ""hidden"" :","if attr == ""hidden"" and (not topic.hidden):",False,29.979078916706865,91.9706882968171
3861,"def Startprobe ( self , q ) : <TAB>  while not self . finished : <TAB><TAB>  try : <TAB><TAB><TAB>  sniff ( iface = self . interface , count = 10 , prn = lambda x : q . put ( x ) ) <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ",if self . finished :,if q.qsize() == 0:,False,23.93521163948005,90.76532530671399
3862,"def _maybe_female ( self , path_elements , female , strict ) : <TAB>  if female : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elements = path_elements + [ "" female "" ] <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  if strict : <TAB><TAB><TAB><TAB><TAB>  raise <TAB><TAB>  elif strict : <TAB><TAB><TAB>  raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB>  return self . _get_file ( path_elements , "" .png "" , strict = strict ) ",if self . has_gender_differences :,if self.species_id == 'female':,False,52.98924163742297,96.43044625959935
3863,"def change_args_to_dict ( string ) : <TAB>  if string is None : <TAB><TAB>  return None <TAB>  ans = [ ] <TAB>  strings = string . split ( "" \n "" ) <TAB>  ind = 1 <TAB>  start = 0 <TAB>  while ind < = len ( strings ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ind + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  if start < ind : <TAB><TAB><TAB><TAB>  ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB><TAB><TAB>  start = ind <TAB><TAB><TAB>  ind + = 1 <TAB>  d = { } <TAB>  for line in ans : <TAB><TAB>  if "" : "" in line and len ( line ) > 0 : <TAB><TAB><TAB>  lines = line . split ( "" : "" ) <TAB><TAB><TAB>  d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB>  return d ","if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :",if strings[start] == '\n':,False,24.01517966530594,93.52067581247582
3864,"def _send_with_auth ( self , req_kwargs , desired_auth , rsession ) : <TAB>  if desired_auth . oauth : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _oauth_creds . refresh ( httplib2 . Http ( ) ) <TAB><TAB>  req_kwargs [ "" headers "" ] = req_kwargs . get ( "" headers "" , { } ) <TAB><TAB>  req_kwargs [ "" headers "" ] [ "" Authorization "" ] = ( <TAB><TAB><TAB>  "" Bearer  "" + self . _oauth_creds . access_token <TAB><TAB>  ) <TAB>  return rsession . request ( * * req_kwargs ) ",if self . _oauth_creds . access_token_expired :,if not self._oauth_creds.enabled:,False,42.993657995721165,95.17614801228144
3865,"def parse_search_response ( json_data ) : <TAB>  """"""Construct response for any input"""""" <TAB>  if json_data is None : <TAB><TAB>  return { "" error "" : "" Error parsing empty search engine response "" } <TAB>  try : <TAB><TAB>  return json . loads ( json_data ) <TAB>  except json . JSONDecodeError : <TAB><TAB>  logger . exception ( "" Error parsing search engine response "" ) <TAB><TAB>  m = re_pre . search ( json_data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return { "" error "" : "" Error parsing search engine response "" } <TAB><TAB>  error = web . htmlunquote ( m . group ( 1 ) ) <TAB><TAB>  solr_error = "" org.apache.lucene.queryParser.ParseException:  "" <TAB><TAB>  if error . startswith ( solr_error ) : <TAB><TAB><TAB>  error = error [ len ( solr_error ) : ] <TAB><TAB>  return { "" error "" : error } ",if m is None :,if m is None:,False,54.731305965213586,100.00000000000004
3866,"def wrapper ( * args , * * kws ) : <TAB>  missing = [ ] <TAB>  saved = getattr ( warnings , "" __warningregistry__ "" , missing ) . copy ( ) <TAB>  try : <TAB><TAB>  return func ( * args , * * kws ) <TAB>  finally : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  del warnings . __warningregistry__ <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  warnings . __warningregistry__ = saved ",if saved is missing :,if saved is missing:,False,24.331188842623412,100.00000000000004
3867,"def parse_expression ( self ) : <TAB>  """"""Return string containing command to run."""""" <TAB>  expression_el = self . root . find ( "" expression "" ) <TAB>  if expression_el is not None : <TAB><TAB>  expression_type = expression_el . get ( "" type "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Unknown expression type [ %s ] encountered "" % expression_type <TAB><TAB><TAB>  ) <TAB><TAB>  return expression_el . text <TAB>  return None ","if expression_type != ""ecma5.1"" :",if expression_type is not None and expression_type is not None:,False,26.10878819229455,92.64310300003167
3868,"def test_geocode ( ) : <TAB>  # look for tweets from New York ; the search radius is larger than NYC <TAB>  # so hopefully we'll find one from New York in the first 500? <TAB>  count = 0 <TAB>  found = False <TAB>  for tweet in T . search ( None , geocode = "" 40.7484,-73.9857,1mi "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  found = True <TAB><TAB><TAB>  break <TAB><TAB>  if count > 500 : <TAB><TAB><TAB>  break <TAB><TAB>  count + = 1 <TAB>  assert found ","if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :",if tweet.search(geocode=geocode) == -1:,False,44.36874124818788,86.07487554466552
3869,"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB>  if name is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = "" std_dev "" <TAB><TAB>  elif order == 1 : <TAB><TAB><TAB>  name = "" sample_std_dev "" <TAB><TAB>  else : <TAB><TAB><TAB>  name = f "" std_dev { order } ) "" <TAB>  super ( ) . __init__ ( name = name , order = order ) <TAB>  self . order = order ",if order == 0 :,if order == 0:,False,34.03025076290728,100.00000000000004
3870,"def __cmp__ ( self , other ) : <TAB>  if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB><TAB>  a = self . _d . getTime ( ) <TAB><TAB>  b = other . _d . getTime ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return - 1 <TAB><TAB>  elif a == b : <TAB><TAB><TAB>  return 0 <TAB>  else : <TAB><TAB>  raise TypeError ( "" expected date or datetime object "" ) <TAB>  return 1 ",if a < b :,if a < b:,False,52.10671822091837,97.3672843164059
3871,"def run ( self ) : <TAB>  tid = self . ident <TAB>  try : <TAB><TAB>  with self . _lock : <TAB><TAB><TAB>  _GUIS [ tid ] = self <TAB><TAB><TAB>  self . _state ( True ) <TAB><TAB>  self . new_mail_notifications ( summarize = True ) <TAB><TAB>  loop_count = 0 <TAB><TAB>  while self . _sock : <TAB><TAB><TAB>  loop_count + = 1 <TAB><TAB><TAB>  self . _select_sleep ( 1 )<TAB># FIXME: Lengthen this when possible <TAB><TAB><TAB>  self . change_state ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # FIXME: This involves a fair number of set operations, <TAB><TAB><TAB><TAB>  #<TAB><TAB>should only do this after new mail has arrived. <TAB><TAB><TAB><TAB>  self . new_mail_notifications ( ) <TAB>  finally : <TAB><TAB>  del _GUIS [ tid ] ",if loop_count % 5 == 0 :,if loop_count == self._max_mail_notifications:,False,36.73104185775282,94.47352054502501
3872,"def __cache_dimension_masks ( self , * args ) : <TAB>  # cache masks for each feature map we'll need <TAB>  if len ( self . masks ) == 0 : <TAB><TAB>  for m1 in args : <TAB><TAB><TAB>  batch_size , emb_dim , h , w = m1 . size ( ) <TAB><TAB><TAB>  # make mask <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  mask = self . feat_size_w_mask ( h , m1 ) <TAB><TAB><TAB><TAB>  self . masks [ h ] = mask ",if h not in self . masks :,if w:,False,33.54578240784921,95.08484077607393
3873,"def __call__ ( self , * flattened_representation ) : <TAB>  unflattened_representation = [ ] <TAB>  for index , subtree in self . children : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  unflattened_representation . append ( flattened_representation [ index ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  sub_representation = flattened_representation [ index ] <TAB><TAB><TAB>  unflattened_representation . append ( subtree ( * sub_representation ) ) <TAB>  return self . _cls ( * unflattened_representation , * * self . _kwargs ) ",if subtree is None :,"if isinstance(subtree, (tuple, list)):",False,46.458421888119176,92.25369645786525
3874,"def click_outside ( event ) : <TAB>  if event not in d : <TAB><TAB>  x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB><TAB>  if y == 0 : <TAB><TAB><TAB>  y = 64 <TAB><TAB>  y + = 3 <TAB><TAB>  gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d . dismiss ( "" Goto "" ) ",if event . num_clicks == 2 :,if event.keyval == gtk.goto.KEY_VALUE:,False,19.624439028900774,91.72992616768241
3875,"def get_mapped_input_keysequences ( self , mode = "" global "" , prefix = u "" "" ) : <TAB>  # get all bindings in this mode <TAB>  globalmaps , modemaps = self . get_keybindings ( mode ) <TAB>  candidates = list ( globalmaps . keys ( ) ) + list ( modemaps . keys ( ) ) <TAB>  if prefix is not None : <TAB><TAB>  prefixes = prefix + "" "" <TAB><TAB>  cand = [ c for c in candidates if c . startswith ( prefixes ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  candidates = cand + [ prefix ] <TAB><TAB>  else : <TAB><TAB><TAB>  candidates = cand <TAB>  return candidates ",if prefix in candidates :,if prefix is not None:,False,44.66807433327755,97.27380297256678
3876,"def _set_length ( self , length ) : <TAB>  with self . _cond : <TAB><TAB>  self . _length = length <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _ready = True <TAB><TAB><TAB>  self . _cond . notify ( ) <TAB><TAB><TAB>  del self . _cache [ self . _job ] ",if self . _index == self . _length :,if self._length == 0:,False,41.57266704484872,93.2413399836745
3877,"def _pct_encoded_replace_unreserved ( mo ) : <TAB>  try : <TAB><TAB>  i = int ( mo . group ( 1 ) , 16 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return chr ( i ) <TAB><TAB>  else : <TAB><TAB><TAB>  return mo . group ( ) . upper ( ) <TAB>  except ValueError : <TAB><TAB>  return mo . group ( ) ",if _unreserved [ i ] :,if i < 16:,False,21.524208135754275,94.16904420176023
3878,"def is_open ( self ) : <TAB>  if self . signup_code : <TAB><TAB>  return True <TAB>  else : <TAB><TAB>  if self . signup_code_present : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  messages . add_message ( <TAB><TAB><TAB><TAB><TAB>  self . request , <TAB><TAB><TAB><TAB><TAB>  self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB><TAB><TAB><TAB><TAB>  self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB><TAB><TAB><TAB><TAB><TAB>  * * { <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" code "" : self . get_code ( ) , <TAB><TAB><TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB><TAB><TAB>  ) , <TAB><TAB><TAB><TAB>  ) <TAB>  return settings . ACCOUNT_OPEN_SIGNUP ","if self . messages . get ( ""invalid_signup_code"" ) :",if self.get_code() is None:,False,48.491848576264054,95.91108128112461
3879,"def _get_field_value ( self , test , key , match ) : <TAB>  if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB>  members = inspect . getmembers ( match ) <TAB><TAB>  for member in members : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  field_value = member [ 1 ] <TAB><TAB><TAB>  elif member [ 0 ] == "" wildcards "" : <TAB><TAB><TAB><TAB>  wildcards = member [ 1 ] <TAB><TAB>  if key == "" nw_src "" : <TAB><TAB><TAB>  field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB>  elif key == "" nw_dst "" : <TAB><TAB><TAB>  field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB>  else : <TAB><TAB>  field_value = match [ key ] <TAB>  return field_value ",if member [ 0 ] == key :,if 0 in member:,False,48.828040405486064,96.80987033952111
3880,"def move_sender_strings_to_sender_model ( apps , schema_editor ) : <TAB>  sender_model = apps . get_model ( "" documents "" , "" Sender "" ) <TAB>  document_model = apps . get_model ( "" documents "" , "" Document "" ) <TAB>  # Create the sender and log the relationship with the document <TAB>  for document in document_model . objects . all ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ( <TAB><TAB><TAB><TAB>  DOCUMENT_SENDER_MAP [ document . pk ] , <TAB><TAB><TAB><TAB>  created , <TAB><TAB><TAB>  ) = sender_model . objects . get_or_create ( <TAB><TAB><TAB><TAB>  name = document . sender , defaults = { "" slug "" : slugify ( document . sender ) } <TAB><TAB><TAB>  ) ",if document . sender :,if document.pk in DOCUMENT_SENDER_MAP:,False,61.05211107120666,96.12341136212748
3881,"def compute_output_shape ( self , input_shape ) : <TAB>  if None not in input_shape [ 1 : ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  total = np . prod ( input_shape [ 2 : 4 ] ) * self . num_anchors <TAB><TAB>  else : <TAB><TAB><TAB>  total = np . prod ( input_shape [ 1 : 3 ] ) * self . num_anchors <TAB><TAB>  return ( input_shape [ 0 ] , total , 4 ) <TAB>  else : <TAB><TAB>  return ( input_shape [ 0 ] , None , 4 ) ","if keras . backend . image_data_format ( ) == ""channels_first"" :",if self.num_anchors == 4:,False,41.186946250756066,88.75573767210787
3882,"def decompress ( self , value ) : <TAB>  if value : <TAB><TAB>  if type ( value ) == PhoneNumber : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return [ <TAB><TAB><TAB><TAB><TAB>  "" + %d "" % value . country_code , <TAB><TAB><TAB><TAB><TAB>  national_significant_number ( value ) , <TAB><TAB><TAB><TAB>  ] <TAB><TAB>  else : <TAB><TAB><TAB>  return value . split ( "" . "" ) <TAB>  return [ None , "" "" ] ",if value . country_code and value . national_number :,if value.country_code:,False,23.424062603794393,95.37221955748075
3883,"def ignore ( self , other ) : <TAB>  if isinstance ( other , Suppress ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB><TAB>  if self . expr is not None : <TAB><TAB><TAB><TAB>  self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB>  else : <TAB><TAB>  super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB>  if self . expr is not None : <TAB><TAB><TAB>  self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB>  return self ",if other not in self . ignoreExprs :,"if isinstance(other, Parse):",False,24.39078135442084,90.96112999481332
3884,"def mkdir ( self , mode = 0o777 , parents = False , exist_ok = False ) : <TAB>  if self . _closed : <TAB><TAB>  self . _raise_closed ( ) <TAB>  if not parents : <TAB><TAB>  try : <TAB><TAB><TAB>  self . _accessor . mkdir ( self , mode ) <TAB><TAB>  except FileExistsError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  self . _accessor . mkdir ( self , mode ) <TAB><TAB>  except FileExistsError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  except OSError as e : <TAB><TAB><TAB>  if e . errno != ENOENT : <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  self . parent . mkdir ( parents = True ) <TAB><TAB><TAB>  self . _accessor . mkdir ( self , mode ) ",if not exist_ok or not self . is_dir ( ) :,if exist_ok:,False,47.291187980023885,89.62704213044037
3885,"def _mark_lcs ( mask , dirs , m , n ) : <TAB>  while m != 0 and n != 0 : <TAB><TAB>  if dirs [ m , n ] == "" | "" : <TAB><TAB><TAB>  m - = 1 <TAB><TAB><TAB>  n - = 1 <TAB><TAB><TAB>  mask [ m ] = 1 <TAB><TAB>  elif dirs [ m , n ] == "" ^ "" : <TAB><TAB><TAB>  m - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n - = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  raise UnboundLocalError ( "" Illegal move "" ) <TAB>  return mask ","elif dirs [ m , n ] == ""<"" :",if n == 0:,False,25.718594513447357,93.05507281523803
3886,"def clean ( self , * args , * * kwargs ) : <TAB>  data = super ( ) . clean ( * args , * * kwargs ) <TAB>  if isinstance ( data , File ) : <TAB><TAB>  filename = data . name <TAB><TAB>  ext = os . path . splitext ( filename ) [ 1 ] <TAB><TAB>  ext = ext . lower ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise forms . ValidationError ( _ ( "" Filetype not allowed! "" ) ) <TAB>  return data ",if ext not in self . ext_whitelist :,if ext == 'filetype':,False,18.305497409324897,93.361293714874
3887,"def get_doc_object ( obj , what = None ) : <TAB>  if what is None : <TAB><TAB>  if inspect . isclass ( obj ) : <TAB><TAB><TAB>  what = "" class "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  what = "" module "" <TAB><TAB>  elif callable ( obj ) : <TAB><TAB><TAB>  what = "" function "" <TAB><TAB>  else : <TAB><TAB><TAB>  what = "" object "" <TAB>  if what == "" class "" : <TAB><TAB>  return SphinxClassDoc ( obj , "" "" , func_doc = SphinxFunctionDoc ) <TAB>  elif what in ( "" function "" , "" method "" ) : <TAB><TAB>  return SphinxFunctionDoc ( obj , "" "" ) <TAB>  else : <TAB><TAB>  return SphinxDocString ( pydoc . getdoc ( obj ) ) ",elif inspect . ismodule ( obj ) :,if inspect.ismodule(obj):,False,28.16818130060778,98.78485915987739
3888,"def apply_pssm ( val ) : <TAB>  if val is not None : <TAB><TAB>  val_c = PSSM_VALUES . get ( val , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert isinstance ( <TAB><TAB><TAB><TAB>  val , tuple ( PSSM_VALUES . values ( ) ) <TAB><TAB><TAB>  ) , "" ' store_as '  should be one of:  %r  or an instance of  %r  not  %r "" % ( <TAB><TAB><TAB><TAB>  tuple ( PSSM_VALUES . keys ( ) ) , <TAB><TAB><TAB><TAB>  tuple ( PSSM_VALUES . values ( ) ) , <TAB><TAB><TAB><TAB>  val , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return val <TAB><TAB>  return val_c ( ) ",if val_c is None :,if val_c is None:,False,63.72602089781382,97.0663882219879
3889,"def read_postmaster_opts ( self ) : <TAB>  """"""returns the list of option names/values from postgres.opts, Empty dict if read failed or no file"""""" <TAB>  result = { } <TAB>  try : <TAB><TAB>  with open ( os . path . join ( self . _postgresql . data_dir , "" postmaster.opts "" ) ) as f : <TAB><TAB><TAB>  data = f . read ( ) <TAB><TAB><TAB>  for opt in data . split ( ' "" "" ' ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  name , val = opt . split ( "" = "" , 1 ) <TAB><TAB><TAB><TAB><TAB>  result [ name . strip ( "" - "" ) ] = val . rstrip ( ' "" \n ' ) <TAB>  except IOError : <TAB><TAB>  logger . exception ( "" Error when reading postmaster.opts "" ) <TAB>  return result ","if ""="" in opt and opt . startswith ( ""--"" ) :",if opt.startswith('--'):,False,31.344886579576013,94.05459832687411
3890,"def detect ( get_page ) : <TAB>  retval = False <TAB>  for vector in WAF_ATTACK_VECTORS : <TAB><TAB>  page , headers , code = get_page ( get = vector ) <TAB><TAB>  retval = ( <TAB><TAB><TAB>  re . search ( r "" F5-TrafficShield "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB><TAB><TAB>  is not None <TAB><TAB>  ) <TAB><TAB>  retval | = ( <TAB><TAB><TAB>  re . search ( r "" \ AASINFO= "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I ) <TAB><TAB><TAB>  is not None <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return retval ",if retval :,if retval:,False,18.986603482535465,100.00000000000004
3891,"def on_task_start ( self , task , config ) : <TAB>  for item in config : <TAB><TAB>  for plugin_name , plugin_config in item . items ( ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  thelist = plugin . get ( plugin_name , self ) . get_list ( plugin_config ) <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  raise PluginError ( <TAB><TAB><TAB><TAB><TAB>  "" Plugin  %s  does not support list interface "" % plugin_name <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise plugin . PluginError ( thelist . immutable ) ",if thelist . immutable :,if thelist.immutable:,False,56.52130040033134,100.00000000000004
3892,"def nq ( t ) : <TAB>  p = t [ 0 ] if ( t and t [ 0 ] in "" -+ "" ) else "" "" <TAB>  t = t [ len ( p ) : ] <TAB>  if t . startswith ( "" tag: "" ) or t . startswith ( "" in: "" ) : <TAB><TAB>  try : <TAB><TAB><TAB>  raw_tag = session . config . get_tag ( t . split ( "" : "" ) [ 1 ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  t = "" in: %s "" % raw_tag . slug <TAB><TAB>  except ( IndexError , KeyError , TypeError ) : <TAB><TAB><TAB>  pass <TAB>  return p + t ",if raw_tag and raw_tag . hasattr ( slug ) :,if raw_tag:,False,23.033047980107312,94.37873789256132
3893,"def _recur_strip ( s ) : <TAB>  if is_str ( s ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" "" . join ( s . strip ( ) . split ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  return "" "" . join ( s . strip ( ) . split ( ) ) . replace ( bos_token + "" "" , "" "" ) <TAB>  else : <TAB><TAB>  s_ = [ _recur_strip ( si ) for si in s ] <TAB><TAB>  return _maybe_list_to_array ( s_ , s ) ","if bos_token == """" :",if bos_token == 'slow':,False,51.22993305619696,97.70077804126952
3894,"def __delitem__ ( self , key ) : <TAB>  "" Deleting tag[key] deletes all  ' key '  attributes for the tag. "" <TAB>  for item in self . attrs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . attrs . remove ( item ) <TAB><TAB><TAB>  # We don't break because bad HTML can define the same <TAB><TAB><TAB>  # attribute multiple times. <TAB><TAB>  self . _getAttrMap ( ) <TAB><TAB>  if self . attrMap . has_key ( key ) : <TAB><TAB><TAB>  del self . attrMap [ key ] ",if item [ 0 ] == key :,if item in self.attrs:,False,58.33626788757318,93.4919485765838
3895,"def comment_import_help ( init_file , out_file ) : <TAB>  f_out = open ( out_file , "" w "" ) <TAB>  output = "" "" <TAB>  updated = False <TAB>  with open ( init_file , "" r "" ) as f_in : <TAB><TAB>  for line in f_in : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  updated = True <TAB><TAB><TAB><TAB>  line = "" #  "" + line <TAB><TAB><TAB>  output + = line <TAB>  f_out . write ( output ) <TAB>  f_out . close ( ) <TAB>  return updated ","if ""import"" in line and ""_help"" in line and not updated :",if line.startswith('#') and line.endswith('#') and (not,False,23.19720267622671,88.69070608506146
3896,"def prepare_text ( lines ) : <TAB>  out = [ ] <TAB>  for s in lines . split ( "" | "" ) : <TAB><TAB>  s = s . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # line beginning with '/' is in italics <TAB><TAB><TAB>  s = r "" { \ i1} %s { \ i0} "" % s [ 1 : ] . strip ( ) <TAB><TAB>  out . append ( s ) <TAB>  return "" \\ N "" . join ( out ) ","if s . startswith ( ""/"" ) :",if s.startswith('/'):,False,58.91037894383293,96.87122823607848
3897,"def sqlctx ( sc ) : <TAB>  pytest . importorskip ( "" pyspark "" ) <TAB>  from odo . backends . sparksql import HiveContext <TAB>  try : <TAB><TAB>  yield HiveContext ( sc ) <TAB>  finally : <TAB><TAB>  dbpath = "" metastore_db "" <TAB><TAB>  logpath = "" derby.log "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert os . path . isdir ( dbpath ) <TAB><TAB><TAB>  shutil . rmtree ( dbpath ) <TAB><TAB>  if os . path . exists ( logpath ) : <TAB><TAB><TAB>  assert os . path . isfile ( logpath ) <TAB><TAB><TAB>  os . remove ( logpath ) ",if os . path . exists ( dbpath ) :,if os.path.exists(dbpath):,False,50.660144324295196,100.00000000000004
3898,"def _user2dict ( self , uid ) : <TAB>  usdict = None <TAB>  if uid in self . users : <TAB><TAB>  usdict = self . users [ uid ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  infos = self . users_info [ uid ] <TAB><TAB><TAB>  for attr in infos : <TAB><TAB><TAB><TAB>  usdict [ attr [ "" attr_type "" ] ] = attr [ "" attr_data "" ] <TAB><TAB>  usdict [ "" uid "" ] = uid <TAB>  return usdict ",if uid in self . users_info :,if uid in self.users_info:,False,51.24373265869799,100.00000000000004
3899,"def _validate_options ( self ) : <TAB>  for option in self . options : <TAB><TAB>  # if value type is bool or int, then we know the options is set <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . options . required [ option ] is True and not self . options [ option ] : <TAB><TAB><TAB><TAB>  if option == Constants . PASSWORD_CLEAR : <TAB><TAB><TAB><TAB><TAB>  option = "" password "" . upper ( ) <TAB><TAB><TAB><TAB>  raise FrameworkException ( <TAB><TAB><TAB><TAB><TAB>  "" Value required for the  ' %s '  option. "" % ( option . upper ( ) ) <TAB><TAB><TAB><TAB>  ) <TAB>  return ","if not type ( self . options [ option ] ) in [ bool , int ] :",if option in self.options.required:,False,64.98501724675569,91.11915848667981
3900,"def _copy_package_apps ( <TAB>  local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" ""  ) - > None : <TAB>  for src_unresolved in app_paths : <TAB><TAB>  src = src_unresolved . resolve ( ) <TAB><TAB>  app = src . name <TAB><TAB>  dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mkdir ( dest . parent ) <TAB><TAB>  if dest . exists ( ) : <TAB><TAB><TAB>  logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB><TAB><TAB>  dest . unlink ( ) <TAB><TAB>  if src . exists ( ) : <TAB><TAB><TAB>  shutil . copy ( src , dest ) ",if not dest . parent . is_dir ( ) :,if dest.parent is not None:,False,22.305701929176895,95.76768750810045
3901,"def truncate_seq_pair ( tokens_a , tokens_b , max_length ) : <TAB>  """"""Truncates a sequence pair in place to the maximum length."""""" <TAB>  # This is a simple heuristic which will always truncate the longer sequence <TAB>  # one token at a time. This makes more sense than truncating an equal percent <TAB>  # of tokens from each, since if one sequence is very short then each token <TAB>  # that's truncated likely contains more information than a longer sequence. <TAB>  while True : <TAB><TAB>  total_length = len ( tokens_a ) + len ( tokens_b ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  if len ( tokens_a ) > len ( tokens_b ) : <TAB><TAB><TAB>  tokens_a . pop ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  tokens_b . pop ( ) ",if total_length <= max_length :,if total_length > max_length:,False,75.77771194893774,98.43213369418265
3902,"def add_channels ( cls , voucher , add_channels ) : <TAB>  for add_channel in add_channels : <TAB><TAB>  channel = add_channel [ "" channel "" ] <TAB><TAB>  defaults = { "" currency "" : channel . currency_code } <TAB><TAB>  if "" discount_value "" in add_channel . keys ( ) : <TAB><TAB><TAB>  defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB><TAB>  models . VoucherChannelListing . objects . update_or_create ( <TAB><TAB><TAB>  voucher = voucher , <TAB><TAB><TAB>  channel = channel , <TAB><TAB><TAB>  defaults = defaults , <TAB><TAB>  ) ","if ""min_amount_spent"" in add_channel . keys ( ) :","if ""min_amount_spent"" in add_channel.keys():",False,51.01509261949339,100.00000000000004
3903,"def services ( self , id = None , name = None ) : <TAB>  for service_dict in self . service_ls ( id = id , name = name ) : <TAB><TAB>  service_id = service_dict [ "" ID "" ] <TAB><TAB>  service_name = service_dict [ "" NAME "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  task_list = self . service_ps ( service_id ) <TAB><TAB>  yield DockerService . from_cli ( self , service_dict , task_list ) ",if not service_name . startswith ( self . _name_prefix ) :,if service_id is None or service_name is None:,False,29.135547053024354,90.58205422193123
3904,"def lll ( dirname ) : <TAB>  for name in os . listdir ( dirname ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  full = os . path . join ( dirname , name ) <TAB><TAB><TAB>  if os . path . islink ( full ) : <TAB><TAB><TAB><TAB>  print ( name , "" -> "" , os . readlink ( full ) ) ","if name not in ( os . curdir , os . pardir ) :",if os.path.isfile(name):,False,38.19067083309907,89.47739489745591
3905,"def convertstore ( self , mydict ) : <TAB>  targetheader = self . mypofile . header ( ) <TAB>  targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB>  for source_str in mydict . keys ( ) : <TAB><TAB>  target_str = mydict [ source_str ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # a convention with new (untranslated) web2py files <TAB><TAB><TAB>  target_str = u "" "" <TAB><TAB>  elif target_str . startswith ( u "" ***  "" ) : <TAB><TAB><TAB>  # an older convention <TAB><TAB><TAB>  target_str = u "" "" <TAB><TAB>  pounit = self . convertunit ( source_str , target_str ) <TAB><TAB>  self . mypofile . addunit ( pounit ) <TAB>  return self . mypofile ",if target_str == source_str :,"if target_str.startswith(u"" ***""):",False,51.92305956487182,94.58369093115259
3906,"def __init__ ( self , * * kwargs ) : <TAB>  for k , v in kwargs . items ( ) : <TAB><TAB>  setattr ( self , k , v ) <TAB>  self . attempted_charsets = set ( ) <TAB>  request = cherrypy . serving . request <TAB>  if request . handler is not None : <TAB><TAB>  # Replace request.handler with self <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cherrypy . log ( "" Replacing request.handler "" , "" TOOLS.ENCODE "" ) <TAB><TAB>  self . oldhandler = request . handler <TAB><TAB>  request . handler = self ",if self . debug :,if cherrypy.logging.verbose >= 0:,False,48.8847470304629,93.92168599022263
3907,"def _fastqc_data_section ( self , section_name ) : <TAB>  out = [ ] <TAB>  in_section = False <TAB>  data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB>  if os . path . exists ( data_file ) : <TAB><TAB>  with open ( data_file ) as in_handle : <TAB><TAB><TAB>  for line in in_handle : <TAB><TAB><TAB><TAB>  if line . startswith ( "" >> %s "" % section_name ) : <TAB><TAB><TAB><TAB><TAB>  in_section = True <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  if line . startswith ( "" >>END "" ) : <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB><TAB>  out . append ( line . rstrip ( "" \r \n "" ) ) <TAB>  return out ",elif in_section :,if in_section:,False,25.78854262818211,99.00295018584484
3908,"def bit_length ( n ) : <TAB>  try : <TAB><TAB>  return n . bit_length ( ) <TAB>  except AttributeError : <TAB><TAB>  norm = deflate_long ( n , False ) <TAB><TAB>  hbyte = byte_ord ( norm [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return 1 <TAB><TAB>  bitlen = len ( norm ) * 8 <TAB><TAB>  while not ( hbyte & 0x80 ) : <TAB><TAB><TAB>  hbyte << = 1 <TAB><TAB><TAB>  bitlen - = 1 <TAB><TAB>  return bitlen ",if hbyte == 0 :,if hbyte & 0x80:,False,22.98955470917813,97.00558538436722
3909,"def step ( self , action ) : <TAB>  """"""Repeat action, sum reward, and max over last observations."""""" <TAB>  total_reward = 0.0 <TAB>  done = None <TAB>  for i in range ( self . _skip ) : <TAB><TAB>  obs , reward , done , info = self . env . step ( action ) <TAB><TAB>  if i == self . _skip - 2 : <TAB><TAB><TAB>  self . _obs_buffer [ 0 ] = obs <TAB><TAB>  if i == self . _skip - 1 : <TAB><TAB><TAB>  self . _obs_buffer [ 1 ] = obs <TAB><TAB>  total_reward + = reward <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  # Note that the observation on the done=True frame <TAB>  # doesn't matter <TAB>  max_frame = self . _obs_buffer . max ( axis = 0 ) <TAB>  return max_frame , total_reward , done , info ",if done :,if done is None:,False,57.02845103951386,98.53527250490656
3910,"def _sample_translation ( reference , max_len ) : <TAB>  translation = reference [ : ] <TAB>  while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB><TAB>  trans_len = len ( translation ) <TAB><TAB>  ind = np . random . randint ( trans_len ) <TAB><TAB>  action = np . random . choice ( actions ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del translation [ ind ] <TAB><TAB>  elif action == "" replacement "" : <TAB><TAB><TAB>  ind_rep = np . random . randint ( trans_len ) <TAB><TAB><TAB>  translation [ ind ] = translation [ ind_rep ] <TAB><TAB>  else : <TAB><TAB><TAB>  ind_insert = np . random . randint ( trans_len ) <TAB><TAB><TAB>  translation . insert ( ind , translation [ ind_insert ] ) <TAB>  return translation ","if action == ""deletion"" :","if action == ""normal':",False,32.15822370343408,98.51841973025942
3911,"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB>  sign = None <TAB>  subseq = [ ] <TAB>  for i in seq : <TAB><TAB>  ki = key ( i ) <TAB><TAB>  if sign is None : <TAB><TAB><TAB>  subseq . append ( i ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sign = ki / abs ( ki ) <TAB><TAB>  else : <TAB><TAB><TAB>  subseq . append ( i ) <TAB><TAB><TAB>  if sign * ki < - slop : <TAB><TAB><TAB><TAB>  sign = ki / abs ( ki ) <TAB><TAB><TAB><TAB>  yield subseq <TAB><TAB><TAB><TAB>  subseq = [ i ] <TAB>  if subseq : <TAB><TAB>  yield subseq ",if ki != 0 :,if sign * ki < slop:,False,30.98310782272685,95.64403129334706
3912,def get_dirlist ( _rootdir ) : <TAB>  dirlist = [ ] <TAB>  with os . scandir ( _rootdir ) as rit : <TAB><TAB>  for entry in rit : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  dirlist . append ( entry . path ) <TAB><TAB><TAB><TAB>  dirlist + = get_dirlist ( entry . path ) <TAB>  return dirlist ,"if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :",if entry.dir == _rootdir:,False,43.406222574689046,83.19225791266348
3913,"def __init__ ( <TAB>  self , <TAB>  fixed : MQTTFixedHeader = None , <TAB>  variable_header : PublishVariableHeader = None , <TAB>  payload = None ,  ) : <TAB>  if fixed is None : <TAB><TAB>  header = MQTTFixedHeader ( PUBLISH , 0x00 ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise HBMQTTException ( <TAB><TAB><TAB><TAB>  "" Invalid fixed packet type  %s  for PublishPacket init "" <TAB><TAB><TAB><TAB>  % fixed . packet_type <TAB><TAB><TAB>  ) <TAB><TAB>  header = fixed <TAB>  super ( ) . __init__ ( header ) <TAB>  self . variable_header = variable_header <TAB>  self . payload = payload ",if fixed . packet_type is not PUBLISH :,"if fixed.packet_type not in (MQTTFixedHeader, MQTTFixedHeader):",False,54.57139449166654,95.72872399983714
3914,"def get_files ( d ) : <TAB>  res = [ ] <TAB>  for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB>  if not p : <TAB><TAB><TAB>  continue <TAB><TAB>  ( pth , fname ) = os . path . split ( p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if fname == "" PureMVC_Python_1_0 "" : <TAB><TAB><TAB>  continue <TAB><TAB>  if fname [ - 4 : ] == "" .pyc "" :<TAB># ehmm.. no. <TAB><TAB><TAB>  continue <TAB><TAB>  if os . path . isdir ( p ) : <TAB><TAB><TAB>  get_dir ( p ) <TAB><TAB>  else : <TAB><TAB><TAB>  res . append ( p ) <TAB>  return res ","if fname == ""output"" :",if pth == 'main':,False,25.112314106697593,94.59288974207588
3915,"def reward ( self ) : <TAB>  """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB>  raw_rewards , processed_rewards = 0 , 0 <TAB>  for ts in self . time_steps : <TAB><TAB>  # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raw_rewards + = ts . raw_reward <TAB><TAB>  if ts . processed_reward is not None : <TAB><TAB><TAB>  processed_rewards + = ts . processed_reward <TAB>  return raw_rewards , processed_rewards ",if ts . raw_reward is not None :,if ts.raw_reward is not None:,False,66.70423282280976,100.00000000000004
3916,"def _process_file ( self , content ) : <TAB>  args = [ ] <TAB>  for line in content . splitlines ( ) : <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args . extend ( self . _split_option ( line ) ) <TAB><TAB>  elif line and not line . startswith ( "" # "" ) : <TAB><TAB><TAB>  args . append ( line ) <TAB>  return args ","if line . startswith ( ""-"" ) :",if line and line.startswith('#') and line.endswith('#') and,False,22.10480449091551,86.1717255277884
3917,"def __on_change_button_clicked ( self , widget = None ) : <TAB>  """"""compute all primary objects and toggle the 'Change' attribute"""""" <TAB>  self . change_status = not self . change_status <TAB>  for prim_obj , tmp in self . xobjects : <TAB><TAB>  obj_change = self . top . get_object ( "" %s _change "" % prim_obj ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  self . change_entries [ prim_obj ] . set_val ( self . change_status ) <TAB><TAB>  obj_change . set_active ( self . change_status ) ",if not obj_change . get_sensitive ( ) :,if obj_change is None:,False,30.89845206958471,93.99359723433356
3918,"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB>  yield "" Core "" , "" 0 "" <TAB>  for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB><TAB>  fpath = _dir / "" settings.json "" <TAB><TAB>  if not fpath . exists ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  with fpath . open ( ) as f : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  data = json . load ( f ) <TAB><TAB><TAB>  except json . JSONDecodeError : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  cog_name = _dir . stem <TAB><TAB>  for cog_id , inner in data . items ( ) : <TAB><TAB><TAB>  if not isinstance ( inner , dict ) : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield cog_name , cog_id ","if not isinstance ( data , dict ) :",if not data:,False,22.513415333718672,97.30920550563494
3919,"def _verifySubs ( self ) : <TAB>  for inst in self . subs : <TAB><TAB>  if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB><TAB><TAB>  raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB><TAB>  if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) ) ",if not inst . modctxt :,"if not isinstance(inst, _Block):",False,22.894170799640623,93.70905659158826
3920,"def _is_xml ( accepts ) : <TAB>  if accepts . startswith ( b "" application/ "" ) : <TAB><TAB>  has_xml = accepts . find ( b "" xml "" ) <TAB><TAB>  if has_xml > 0 : <TAB><TAB><TAB>  semicolon = accepts . find ( b "" ; "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if semicolon < 0 or has_xml < semicolon :,if semicolon is not None:,False,13.292311486629643,91.57682482307162
3921,"def _accept_with ( cls , orm , target ) : <TAB>  if target is orm . mapper : <TAB><TAB>  return mapperlib . Mapper <TAB>  elif isinstance ( target , type ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return target <TAB><TAB>  else : <TAB><TAB><TAB>  mapper = _mapper_or_none ( target ) <TAB><TAB><TAB>  if mapper is not None : <TAB><TAB><TAB><TAB>  return mapper <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return _MapperEventsHold ( target ) <TAB>  else : <TAB><TAB>  return target ","if issubclass ( target , mapperlib . Mapper ) :","if isinstance(target, mapperlib.Mapper):",False,52.205099554513204,98.50955027174346
3922,"def _get_font_afm ( self , prop ) : <TAB>  key = hash ( prop ) <TAB>  font = self . afmfontd . get ( key ) <TAB>  <IF-STMT>: <TAB><TAB>  fname = findfont ( prop , fontext = "" afm "" ) <TAB><TAB>  font = self . afmfontd . get ( fname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  font = AFM ( file ( findfont ( prop , fontext = "" afm "" ) ) ) <TAB><TAB><TAB>  self . afmfontd [ fname ] = font <TAB><TAB>  self . afmfontd [ key ] = font <TAB>  return font ",if font is None :,if font is None:,False,22.64020046287748,96.31649739402559
3923,"def __call__ ( self , groupby ) : <TAB>  normalize_reduction_funcs ( self , ndim = groupby . ndim ) <TAB>  df = groupby <TAB>  while df . op . output_types [ 0 ] not in ( OutputType . dataframe , OutputType . series ) : <TAB><TAB>  df = df . inputs [ 0 ] <TAB>  if self . raw_func == "" size "" : <TAB><TAB>  self . output_types = [ OutputType . series ] <TAB>  else : <TAB><TAB>  self . output_types = ( <TAB><TAB><TAB>  [ OutputType . dataframe ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else [ OutputType . series ] <TAB><TAB>  ) <TAB>  if self . output_types [ 0 ] == OutputType . dataframe : <TAB><TAB>  return self . _call_dataframe ( groupby , df ) <TAB>  else : <TAB><TAB>  return self . _call_series ( groupby , df ) ",if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby,if self.output_types[0] == OutputType.series:,False,21.601424469939452,96.32536167037769
3924,"def save ( self ) : <TAB>  if self . preferences . get ( ENCRYPT_ON_DISK , False ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . storage . write ( <TAB><TAB><TAB><TAB>  self . to_dict ( encrypt_password = self . encryption_password ) <TAB><TAB><TAB>  ) <TAB><TAB>  elif not self . is_locked : <TAB><TAB><TAB>  log . warning ( <TAB><TAB><TAB><TAB>  "" Disk encryption requested but no password available for encryption.  "" <TAB><TAB><TAB><TAB>  "" Resetting encryption preferences and saving wallet in an unencrypted state. "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . preferences [ ENCRYPT_ON_DISK ] = False <TAB>  return self . storage . write ( self . to_dict ( ) ) ",if self . encryption_password is not None :,if self.encryption_password:,False,60.64751897084406,97.93649616526835
3925,"def isValidDateString ( config_param_name , value , valid_value ) : <TAB>  try : <TAB><TAB>  if value == "" DD-MM-YYYY "" : <TAB><TAB><TAB>  return value <TAB><TAB>  day , month , year = value . split ( "" - "" ) <TAB><TAB>  if int ( day ) < 1 or int ( day ) > 31 : <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  if int ( year ) < 1900 or int ( year ) > 2013 : <TAB><TAB><TAB>  raise DateStringValueError ( config_param_name , value ) <TAB><TAB>  return value <TAB>  except Exception : <TAB><TAB>  raise DateStringValueError ( config_param_name , value ) ",if int ( month ) < 1 or int ( month ) > 12 :,if month == 0 or month > 12:,False,51.015512211817516,94.60132740088898
3926,"def _capture ( self , call_name , data = None , * * kwargs ) : <TAB>  if data is None : <TAB><TAB>  data = self . get_default_context ( ) <TAB>  else : <TAB><TAB>  default_context = self . get_default_context ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  default_context . update ( data ) <TAB><TAB>  else : <TAB><TAB><TAB>  default_context [ "" extra "" ] [ "" extra_data "" ] = data <TAB><TAB>  data = default_context <TAB>  client = self . get_sentry_client ( ) <TAB>  return getattr ( client , call_name ) ( data = data , * * kwargs ) ","if isinstance ( data , dict ) :","if isinstance(data, dict):",False,45.038700214553494,100.00000000000004
3927,"def check ( input , expected_output = None , expected_ffi_error = False ) : <TAB>  import _cffi_backend <TAB>  ffi = _cffi_backend . FFI ( ) <TAB>  if not expected_ffi_error : <TAB><TAB>  ct = ffi . typeof ( input ) <TAB><TAB>  assert isinstance ( ct , ffi . CType ) <TAB><TAB>  assert ct . cname == ( expected_output or input ) <TAB>  else : <TAB><TAB>  e = py . test . raises ( ffi . error , ffi . typeof , input ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert str ( e . value ) == expected_ffi_error ","if isinstance ( expected_ffi_error , str ) :",if e is not None:,False,23.607616538290955,93.13730967591353
3928,"def run ( self ) : <TAB>  """"""Process queries from task queue, stop if processor is None."""""" <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  processor , iprot , oprot , otrans , callback = self . queue . get ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  processor . process ( iprot , oprot ) <TAB><TAB><TAB>  callback ( True , otrans . getvalue ( ) ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  logging . exception ( "" Exception while processing request "" ) <TAB><TAB><TAB>  callback ( False , "" "" ) ",if processor is None :,if processor is None:,False,60.6503021734969,100.00000000000004
3929,"def search ( self , query ) : <TAB>  query = query . strip ( ) . lower ( ) <TAB>  results = [ ] <TAB>  for provider in SidebarItemProvider . all ( self . context ) : <TAB><TAB>  for item in provider . provide ( ) : <TAB><TAB><TAB>  if "" url "" in item : <TAB><TAB><TAB><TAB>  search_source = "" $ "" . join ( <TAB><TAB><TAB><TAB><TAB>  [ item . get ( "" id "" , "" "" ) , item . get ( "" name "" , "" "" ) ] <TAB><TAB><TAB><TAB>  ) . lower ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  results . append ( <TAB><TAB><TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" title "" : item [ "" name "" ] , <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" icon "" : item [ "" icon "" ] , <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  "" url "" : item [ "" url "" ] , <TAB><TAB><TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB><TAB><TAB>  ) <TAB>  return results ",if query in search_source :,if search_source.startswith('$') and (not query.startswith('?',False,49.742820985839316,94.50111895524401
3930,"def handle ( self ) - > None : <TAB>  """"""Handles a request ignoring dropped connections."""""" <TAB>  try : <TAB><TAB>  BaseHTTPRequestHandler . handle ( self ) <TAB>  except ( ConnectionError , socket . timeout ) as e : <TAB><TAB>  self . connection_dropped ( e ) <TAB>  except Exception as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log_error ( "" SSL error occurred:  %s "" , e ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise <TAB>  if self . server . shutdown_signal : <TAB><TAB>  self . initiate_shutdown ( ) ",if self . server . ssl_context is not None and is_ssl_error ( e ) :,if e.code == SSL_ERROR_SSL_ERROR:,False,25.566576602551294,88.76701360243304
3931,"def cdn_url_handler ( error , endpoint , kwargs ) : <TAB>  if endpoint == "" cdn "" : <TAB><TAB>  path = kwargs . pop ( "" path "" ) <TAB><TAB>  # cdn = app.config.get('cdn', 'http://cdn.staticfile.org/') <TAB><TAB>  # cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/') <TAB><TAB>  cdn = app . config . get ( "" cdn "" , "" //cdnjscn.b0.upaiyun.com/libs/ "" ) <TAB><TAB>  return urljoin ( cdn , path ) <TAB>  else : <TAB><TAB>  exc_type , exc_value , tb = sys . exc_info ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  reraise ( exc_type , exc_value , tb ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise error ",if exc_value is error :,if exc_type is not None:,False,52.31776616571289,97.69703354098365
3932,"def pairs ( self ) : <TAB>  for path in os . listdir ( "" src "" ) : <TAB><TAB>  if path == "" .svn "" : <TAB><TAB><TAB>  continue <TAB><TAB>  dep = join ( "" src "" , path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  yield dep , join ( build_dir , path ) ",if isdir ( dep ) :,if not os.path.exists(dep):,False,29.92681329556136,92.8036074738359
3933,"def get_condition ( self ) : <TAB>  """"""Return the condition element's name."""""" <TAB>  for child in self . xml : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cond = child . tag . split ( "" } "" , 1 ) [ - 1 ] <TAB><TAB><TAB>  if cond in self . conditions : <TAB><TAB><TAB><TAB>  return cond <TAB>  return "" not-authorized "" ","if ""{%s}"" % self . namespace in child . tag :",if child.tag == 'condition':,False,39.34122723278999,85.66147967856443
3934,"def end ( self , tag ) : <TAB>  # call the appropriate end tag handler <TAB>  try : <TAB><TAB>  f = self . dispatch [ tag ] <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return<TAB># unknown tag ? <TAB><TAB>  try : <TAB><TAB><TAB>  f = self . dispatch [ tag . split ( "" : "" ) [ - 1 ] ] <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  return<TAB># unknown tag ? <TAB>  return f ( self , "" "" . join ( self . _data ) ) ","if "":"" not in tag :",if f is None:,False,30.46408815056843,88.6289184882789
3935,"def checkIfSessionCodeExists ( self , sessionCode ) : <TAB>  if self . emrtFile : <TAB><TAB>  sessionsForExperiment = ( <TAB><TAB><TAB>  self . emrtFile . root . data_collection . session_meta_data . where ( <TAB><TAB><TAB><TAB>  "" experiment_id ==  %d "" % ( self . active_experiment_id , ) <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB><TAB>  sessionCodeMatch = [ <TAB><TAB><TAB>  sess for sess in sessionsForExperiment if sess [ "" code "" ] == sessionCode <TAB><TAB>  ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  return False ",if len ( sessionCodeMatch ) > 0 :,if sessionCodeMatch:,False,27.142740422135798,95.77106750119177
3936,"def save_bytearray ( self , obj ) : <TAB>  if self . proto < 5 : <TAB><TAB>  <IF-STMT>:<TAB># bytearray is empty <TAB><TAB><TAB>  self . save_reduce ( bytearray , ( ) , obj = obj ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . save_reduce ( bytearray , ( bytes ( obj ) , ) , obj = obj ) <TAB><TAB>  return <TAB>  n = len ( obj ) <TAB>  if n > = self . framer . _FRAME_SIZE_TARGET : <TAB><TAB>  self . _write_large_bytes ( BYTEARRAY8 + pack ( "" <Q "" , n ) , obj ) <TAB>  else : <TAB><TAB>  self . write ( BYTEARRAY8 + pack ( "" <Q "" , n ) + obj ) ",if not obj :,if self.proto == 4:,False,26.65542675099466,94.14786961754531
3937,"def _restore_freeze ( self , new ) : <TAB>  size_change = [ ] <TAB>  for k , v in six . iteritems ( self . _freeze_backup ) : <TAB><TAB>  newv = new . get ( k , [ ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size_change . append ( ( self . _key_name ( k ) , len ( v ) , len ( newv ) ) ) <TAB>  if size_change : <TAB><TAB>  logger . info ( <TAB><TAB><TAB>  "" These collections were modified but restored in  {} :  {} "" . format ( <TAB><TAB><TAB><TAB>  self . _name , <TAB><TAB><TAB><TAB>  "" ,  "" . join ( map ( lambda t : "" ( {} :  {} -> {} ) "" . format ( * t ) , size_change ) ) , <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB>  restore_collection ( self . _freeze_backup ) ",if len ( v ) != len ( newv ) :,if v != newv:,False,28.557441649952658,95.8998626699797
3938,"def check_options ( self , expr , evaluation , options ) : <TAB>  for key in options : <TAB><TAB>  if key != "" System`SameTest "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) , expr ) <TAB>  return None ",if expr is None :,if key not in self.options:,False,23.626716213697023,94.24075448389662
3939,"def bundle_directory ( self , dirpath ) : <TAB>  """"""Bundle all modules/packages in the given directory."""""" <TAB>  dirpath = os . path . abspath ( dirpath ) <TAB>  for nm in os . listdir ( dirpath ) : <TAB><TAB>  nm = _u ( nm ) <TAB><TAB>  if nm . startswith ( "" . "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  itempath = os . path . join ( dirpath , nm ) <TAB><TAB>  if os . path . isdir ( itempath ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . bundle_package ( itempath ) <TAB><TAB>  elif nm . endswith ( "" .py "" ) : <TAB><TAB><TAB>  self . bundle_module ( itempath ) ","if os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :",if nm.endswith('.py'):,False,53.96029980245465,88.30845207279432
3940,"def _read_block ( self , size ) : <TAB>  if self . _file_end is not None : <TAB><TAB>  max_size = self . _file_end - self . _file . tell ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  size = max_size <TAB><TAB>  size = max ( min ( size , max_size ) , 0 ) <TAB>  return self . _file . read ( size ) ",if size == - 1 :,if max_size > size:,False,30.463478550091764,94.26768519882022
3941,"def question_mark ( self ) : <TAB>  """"""Shows help for this command and it's sub-commands."""""" <TAB>  ret = [ ] <TAB>  if self . param_help_msg or len ( self . subcommands ) == 0 : <TAB><TAB>  ret . append ( self . _quick_help ( ) ) <TAB>  if len ( self . subcommands ) > 0 : <TAB><TAB>  for k , _ in sorted ( self . subcommands . items ( ) ) : <TAB><TAB><TAB>  command_path , param_help , cmd_help = self . _instantiate_subcommand ( <TAB><TAB><TAB><TAB>  k <TAB><TAB><TAB>  ) . _quick_help ( nested = True ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret . append ( ( command_path , param_help , cmd_help ) ) <TAB>  return ( CommandsResponse ( STATUS_OK , self . help_formatter ( ret ) ) , self . __class__ ) ",if command_path or param_help or cmd_help :,if command_path:,False,38.76764808556392,96.15727538284888
3942,"def list_domains ( self , r53 , * * kwargs ) : <TAB>  marker = None <TAB>  domains = [ ] <TAB>  while True : <TAB><TAB>  if marker : <TAB><TAB><TAB>  response = self . wrap_aws_rate_limited_call ( r53 . list_domains ( Marker = marker ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  response = self . wrap_aws_rate_limited_call ( r53 . list_domains ) <TAB><TAB>  for domain in response . get ( "" Domains "" ) : <TAB><TAB><TAB>  domains . append ( domain ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  marker = response . get ( "" NextPageMarker "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  return domains ","if response . get ( ""NextPageMarker"" ) :",if response.get('NextPageMarker'):,False,48.385799761077955,97.77547236053826
3943,"def writer ( stream , items ) : <TAB>  sep = "" "" <TAB>  for item in items : <TAB><TAB>  stream . write ( sep ) <TAB><TAB>  sep = "" "" <TAB><TAB>  if not isinstance ( item , str ) : <TAB><TAB><TAB>  item = str ( item ) <TAB><TAB>  if not PY3K : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  item = str ( item ) <TAB><TAB>  stream . write ( item ) <TAB>  stream . write ( "" \n "" ) ","if not isinstance ( item , unicode ) :","if isinstance(item, int):",False,28.315320000941526,96.49502636444484
3944,"def f ( view , s ) : <TAB>  if mode == modes . INTERNAL_NORMAL : <TAB><TAB>  view . run_command ( "" toggle_comment "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pt = utils . next_non_white_space_char ( view , s . a , white_space = "" \t "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  pt = utils . next_non_white_space_char ( <TAB><TAB><TAB><TAB>  view , self . view . line ( s . a ) . a , white_space = "" \t "" <TAB><TAB><TAB>  ) <TAB><TAB>  return R ( pt , pt ) <TAB>  return s ","if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :",if mode == modes.NORMAL:,False,41.77359629422184,82.66562131638388
3945,"def _parse_timestamp ( value ) : <TAB>  if value : <TAB><TAB>  match = _TIMESTAMP_PATTERN . match ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if match . group ( 2 ) : <TAB><TAB><TAB><TAB>  format = "" % Y- % m- %d % H: % M: % S. %f "" <TAB><TAB><TAB><TAB>  # use the pattern to truncate the value <TAB><TAB><TAB><TAB>  value = match . group ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  format = "" % Y- % m- %d % H: % M: % S "" <TAB><TAB><TAB>  value = datetime . datetime . strptime ( value , format ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( ' Cannot convert  "" {} ""  into a datetime ' . format ( value ) ) <TAB>  else : <TAB><TAB>  value = None <TAB>  return value ",if match :,if match:,False,55.818741060239276,97.15171369224808
3946,"def _compute_log_r ( model_trace , guide_trace ) : <TAB>  log_r = MultiFrameTensor ( ) <TAB>  stacks = get_plate_stacks ( model_trace ) <TAB>  for name , model_site in model_trace . nodes . items ( ) : <TAB><TAB>  if model_site [ "" type "" ] == "" sample "" : <TAB><TAB><TAB>  log_r_term = model_site [ "" log_prob "" ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB><TAB><TAB>  log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB>  return log_r ","if not model_site [ ""is_observed"" ] :",if log_r_term.is_lower():,False,38.1937267226177,94.41815187205253
3947,"def get_translationproject ( self ) : <TAB>  """"""returns the translation project belonging to this directory."""""" <TAB>  if self . is_language ( ) or self . is_project ( ) : <TAB><TAB>  return None <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . translationproject <TAB><TAB>  else : <TAB><TAB><TAB>  aux_dir = self <TAB><TAB><TAB>  while not aux_dir . is_translationproject ( ) and aux_dir . parent is not None : <TAB><TAB><TAB><TAB>  aux_dir = aux_dir . parent <TAB><TAB><TAB>  return aux_dir . translationproject ",if self . is_translationproject ( ) :,if self.translationproject is not None:,False,55.06022826773904,96.53204211694019
3948,"def get_hosted_content ( ) : <TAB>  try : <TAB><TAB>  scheme , rest = target . split ( "" :// "" , 1 ) <TAB><TAB>  prefix , host_and_port = rest . split ( "" .interactivetool. "" ) <TAB><TAB>  faked_host = rest <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  faked_host = rest . split ( "" / "" , 1 ) [ 0 ] <TAB><TAB>  url = "" %s :// %s "" % ( scheme , host_and_port ) <TAB><TAB>  response = requests . get ( url , timeout = 1 , headers = { "" Host "" : faked_host } ) <TAB><TAB>  return response . text <TAB>  except Exception as e : <TAB><TAB>  print ( e ) <TAB><TAB>  return None ","if ""/"" in rest :",if prefix == 'faked':,False,18.916337113747495,96.77171943591628
3949,"def install ( self ) : <TAB>  log . info ( self . openssl_cli ) <TAB>  if not self . has_openssl or self . args . force : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _download_src ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  log . debug ( "" Already has src  {} "" . format ( self . src_file ) ) <TAB><TAB>  self . _unpack_src ( ) <TAB><TAB>  self . _build_src ( ) <TAB><TAB>  self . _make_install ( ) <TAB>  else : <TAB><TAB>  log . info ( "" Already has installation  {} "" . format ( self . install_dir ) ) <TAB>  # validate installation <TAB>  version = self . openssl_version <TAB>  if self . version not in version : <TAB><TAB>  raise ValueError ( version ) ",if not self . has_src :,if self.is_src_file():,False,45.34345748230423,95.86620259514368
3950,"def format ( self , formatstr ) : <TAB>  pieces = [ ] <TAB>  for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB><TAB>  if i % 2 : <TAB><TAB><TAB>  pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB>  return "" "" . join ( pieces ) ",elif piece :,if i % 2:,False,47.34053043478671,95.63957336396375
3951,"def get_current_events_users ( calendar ) : <TAB>  now = timezone . make_aware ( datetime . now ( ) , timezone . get_current_timezone ( ) ) <TAB>  result = [ ] <TAB>  day = Day ( calendar . events . all ( ) , now ) <TAB>  for o in day . get_occurrences ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  usernames = o . event . title . split ( "" , "" ) <TAB><TAB><TAB>  for username in usernames : <TAB><TAB><TAB><TAB>  result . append ( User . objects . get ( username = username . strip ( ) ) ) <TAB>  return result ",if o . start <= now <= o . end :,if o.type == 'User':,False,34.02522203867692,93.99842655738819
3952,"def from_cfn_params ( self , cfn_params ) : <TAB>  """"""Initialize param value by parsing CFN input only if the scheduler is awsbatch."""""" <TAB>  cfn_converter = self . definition . get ( "" cfn_param_mapping "" , None ) <TAB>  if cfn_converter and cfn_params : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # we have the same CFN input parameters for both spot_price and spot_bid_percentage <TAB><TAB><TAB>  # so the CFN input could be a float <TAB><TAB><TAB>  self . value = int ( float ( get_cfn_param ( cfn_params , cfn_converter ) ) ) <TAB>  return self ","if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :",if cfn_params and cfn_params.value == 0:,False,66.44469679319374,90.27909511141064
3953,"def onCompletion ( self , text ) : <TAB>  res = [ ] <TAB>  for l in text . split ( "" \n "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  l = l . split ( "" : "" ) <TAB><TAB>  if len ( l ) != 2 : <TAB><TAB><TAB>  continue <TAB><TAB>  res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB>  self . panel . setChapters ( res ) ",if not l :,if len(l) == 0:,False,22.63439004919707,93.9401525846605
3954,"def update_ranges ( l , i ) : <TAB>  for _range in l : <TAB><TAB>  # most common case: extend a range <TAB><TAB>  if i == _range [ 0 ] - 1 : <TAB><TAB><TAB>  _range [ 0 ] = i <TAB><TAB><TAB>  merge_ranges ( l ) <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _range [ 1 ] = i <TAB><TAB><TAB>  merge_ranges ( l ) <TAB><TAB><TAB>  return <TAB>  # somewhere outside of range proximity <TAB>  l . append ( [ i , i ] ) <TAB>  l . sort ( key = lambda x : x [ 0 ] ) ",elif i == _range [ 1 ] + 1 :,if i == _range[0] - 1:,False,59.465304392346226,96.40085853599913
3955,"def process_dollar ( token , state , command_line ) : <TAB>  if not state . is_range_start_line_parsed : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB><TAB>  command_line . line_range . start . append ( token ) <TAB>  else : <TAB><TAB>  if command_line . line_range . end : <TAB><TAB><TAB>  raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB><TAB>  command_line . line_range . end . append ( token ) <TAB>  return parse_line_ref , command_line ",if command_line . line_range . start :,if not command_line.line_range.start:,False,47.56414746645906,98.654004325263
3956,"def _parse_description ( self , text : str ) : <TAB>  result = dict ( links = [ ] , versions = [ ] ) <TAB>  for line in text . splitlines ( ) : <TAB><TAB>  clean = REX_TAG . sub ( "" "" , line . strip ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ "" severity "" ] = clean . split ( ) [ 1 ] <TAB><TAB><TAB>  continue <TAB><TAB>  if clean . startswith ( "" Affects: "" ) : <TAB><TAB><TAB>  result [ "" name "" ] = clean . split ( ) [ 1 ] <TAB><TAB><TAB>  continue <TAB><TAB>  if ""  or higher "" in clean : <TAB><TAB><TAB>  result [ "" versions "" ] = self . _get_versions ( clean ) <TAB><TAB>  result [ "" links "" ] . extend ( REX_LINK . findall ( line ) ) <TAB>  return result ","if clean . startswith ( ""Severity:"" ) :",if clean.startswith('Severity:,False,27.742445393519784,97.20911695827829
3957,"def apply ( self , chart , grammar ) : <TAB>  for prod in grammar . productions ( empty = True ) : <TAB><TAB>  for index in compat . xrange ( chart . num_leaves ( ) + 1 ) : <TAB><TAB><TAB>  new_edge = TreeEdge . from_production ( prod , index ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield new_edge ","if chart . insert ( new_edge , ( ) ) :",if new_edge is not None:,False,21.92150702269295,89.77422996395732
3958,"def calc ( self , arg ) : <TAB>  op = arg [ "" op "" ] <TAB>  if op == "" C "" : <TAB><TAB>  self . clear ( ) <TAB><TAB>  return str ( self . current ) <TAB>  num = decimal . Decimal ( arg [ "" num "" ] ) <TAB>  if self . op : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . current + = num <TAB><TAB>  elif self . op == "" - "" : <TAB><TAB><TAB>  self . current - = num <TAB><TAB>  elif self . op == "" * "" : <TAB><TAB><TAB>  self . current * = num <TAB><TAB>  elif self . op == "" / "" : <TAB><TAB><TAB>  self . current / = num <TAB><TAB>  self . op = op <TAB>  else : <TAB><TAB>  self . op = op <TAB><TAB>  self . current = num <TAB>  res = str ( self . current ) <TAB>  if op == "" = "" : <TAB><TAB>  self . clear ( ) <TAB>  return res ","if self . op == ""+"" :","if self.op == ""+"":",False,30.793000847207775,100.00000000000004
3959,"def cascade ( self , event = None ) : <TAB>  """"""Cascade all Leo windows."""""" <TAB>  x , y , delta = 50 , 50 , 50 <TAB>  for frame in g . app . windowList : <TAB><TAB>  w = frame and frame . top <TAB><TAB>  if w : <TAB><TAB><TAB>  r = w . geometry ( )<TAB># a Qt.Rect <TAB><TAB><TAB>  # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB><TAB><TAB>  w . setGeometry ( QtCore . QRect ( x , y , r . width ( ) , r . height ( ) ) ) <TAB><TAB><TAB>  # Compute the new offsets. <TAB><TAB><TAB>  x + = 30 <TAB><TAB><TAB>  y + = 30 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  x = 10 + delta <TAB><TAB><TAB><TAB>  y = 40 + delta <TAB><TAB><TAB><TAB>  delta + = 10 ",if x > 200 :,if event.type == gtk.gdk.EVENT.CLICKED:,False,27.358501493330284,93.3049399153614
3960,"def redirect ( self ) : <TAB>  c = self . c <TAB>  if c . config . getBool ( "" eval-redirect "" ) : <TAB><TAB>  self . old_stderr = g . stdErrIsRedirected ( ) <TAB><TAB>  self . old_stdout = g . stdOutIsRedirected ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . redirectStderr ( ) <TAB><TAB>  if not self . old_stdout : <TAB><TAB><TAB>  g . redirectStdout ( ) ",if not self . old_stderr :,if not self.old_stderr:,False,50.78405120563958,100.00000000000004
3961,"def on_event ( self , c , button , data ) : <TAB>  if self . rvGestureGrab . get_reveal_child ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . use ( ) <TAB><TAB>  elif button == "" Y "" and data [ 0 ] == 0 : <TAB><TAB><TAB>  self . start_over ( ) ","if button == ""A"" and data [ 0 ] == 0 :","if button == ""X"" and data[0] == 0:",False,27.699143913810026,97.54238144468995
3962,"def __init__ ( self , in_feats , out_feats , norm = "" both "" , bias = True , activation = None ) : <TAB>  super ( DenseGraphConv , self ) . __init__ ( ) <TAB>  self . _in_feats = in_feats <TAB>  self . _out_feats = out_feats <TAB>  self . _norm = norm <TAB>  with self . name_scope ( ) : <TAB><TAB>  self . weight = self . params . get ( <TAB><TAB><TAB>  "" weight "" , <TAB><TAB><TAB>  shape = ( in_feats , out_feats ) , <TAB><TAB><TAB>  init = mx . init . Xavier ( magnitude = math . sqrt ( 2.0 ) ) , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . bias = self . params . get ( "" bias "" , shape = ( out_feats , ) , init = mx . init . Zero ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . bias = None <TAB><TAB>  self . _activation = activation ",if bias :,if bias:,False,50.65731218321081,100.00000000000004
3963,"def _import_top_module ( self , name ) : <TAB>  # scan sys.path looking for a location in the filesystem that contains <TAB>  # the module, or an Importer object that can import the module. <TAB>  for item in sys . path : <TAB><TAB>  if isinstance ( item , _StringType ) : <TAB><TAB><TAB>  module = self . fs_imp . import_from_dir ( item , name ) <TAB><TAB>  else : <TAB><TAB><TAB>  module = item . import_top ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return module <TAB>  return None ",if module :,if module is not None:,False,43.34126425093462,97.04071023597234
3964,"def resolver ( schemas , f ) : <TAB>  if not callable ( f ) : <TAB><TAB>  return <TAB>  if not hasattr ( f , "" accepts "" ) : <TAB><TAB>  return <TAB>  new_params = [ ] <TAB>  for p in f . accepts : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_params . append ( p . resolve ( schemas ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ResolverError ( "" Invalid parameter definition  {0} "" . format ( p ) ) <TAB>  # FIXME: for some reason assigning params (f.accepts = new_params) does not work <TAB>  f . accepts . clear ( ) <TAB>  f . accepts . extend ( new_params ) ","if isinstance ( p , ( Patch , Ref , Attribute ) ) :","if hasattr(p, 'resolve'):",False,59.26067771645215,94.02918034057448
3965,"def get_files ( d ) : <TAB>  res = [ ] <TAB>  for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB>  if not p : <TAB><TAB><TAB>  continue <TAB><TAB>  ( pth , fname ) = os . path . split ( p ) <TAB><TAB>  if fname == "" output "" : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if fname [ - 4 : ] == "" .pyc "" :<TAB># ehmm.. no. <TAB><TAB><TAB>  continue <TAB><TAB>  if os . path . isdir ( p ) : <TAB><TAB><TAB>  get_dir ( p ) <TAB><TAB>  else : <TAB><TAB><TAB>  res . append ( p ) <TAB>  return res ","if fname == ""PureMVC_Python_1_0"" :",if fname.endswith('.pyc'):,False,48.51695760671392,92.88859548341475
3966,"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB>  if leftname in kerning : <TAB><TAB>  for rightname in kerning [ leftname ] : <TAB><TAB><TAB>  if rightname [ 0 ] == "" @ "" : <TAB><TAB><TAB><TAB>  for rightname2 in groups [ rightname ] : <TAB><TAB><TAB><TAB><TAB>  rightnames . add ( rightname2 ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  # TODO: in this case, pick the one rightname that has the highest <TAB><TAB><TAB><TAB><TAB><TAB>  # ranking in glyphorder <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  rightnames . add ( rightname ) ",if not includeAll :,if includeAll:,False,39.796693008418146,98.86432861690004
3967,"def migrate_Stats ( self ) : <TAB>  for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . entries_count [ "" Stats "" ] - = 1 <TAB><TAB><TAB>  continue <TAB><TAB>  new_obj = self . model_to [ "" Stats "" ] ( ) <TAB><TAB>  for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB><TAB><TAB>  if key not in old_obj . __table__ . columns : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB><TAB>  self . session_new . add ( new_obj ) ",if not old_obj . summary :,if old_obj.__table__ == self.model_to['Stats']:,False,24.107175028027918,92.00684596115903
3968,"def _readenv ( var , msg ) : <TAB>  match = _ENV_VAR_PAT . match ( var ) <TAB>  if match and match . groups ( ) : <TAB><TAB>  envvar = match . groups ( ) [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = os . environ [ envvar ] <TAB><TAB><TAB>  if six . PY2 : <TAB><TAB><TAB><TAB>  value = value . decode ( "" utf8 "" ) <TAB><TAB><TAB>  return value <TAB><TAB>  else : <TAB><TAB><TAB>  raise InvalidConfigException ( <TAB><TAB><TAB><TAB>  "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise InvalidConfigException ( <TAB><TAB><TAB>  "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB><TAB><TAB><TAB>  msg , var , _ENV_VAR_PAT_STR <TAB><TAB><TAB>  ) <TAB><TAB>  ) ",if envvar in os . environ :,if envvar in os.environ:,False,55.93703521604778,100.00000000000004
3969,"def __next__ ( self ) : <TAB>  self . _parse_reset ( ) <TAB>  while True : <TAB><TAB>  try : <TAB><TAB><TAB>  line = next ( self . input_iter ) <TAB><TAB>  except StopIteration : <TAB><TAB><TAB>  # End of input OR exception <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise Error ( "" newline inside string "" ) <TAB><TAB><TAB>  raise <TAB><TAB>  self . line_num + = 1 <TAB><TAB>  if "" \0 "" in line : <TAB><TAB><TAB>  raise Error ( "" line contains NULL byte "" ) <TAB><TAB>  pos = 0 <TAB><TAB>  while pos < len ( line ) : <TAB><TAB><TAB>  pos = self . _parse_process_char ( line , pos ) <TAB><TAB>  self . _parse_eol ( ) <TAB><TAB>  if self . state == self . START_RECORD : <TAB><TAB><TAB>  break <TAB>  fields = self . fields <TAB>  self . fields = [ ] <TAB>  return fields ",if len ( self . field ) > 0 :,if line:,False,53.04477975905688,96.64126282590505
3970,"def createFields ( self ) : <TAB>  while self . current_size < self . size : <TAB><TAB>  pos = self . stream . searchBytes ( <TAB><TAB><TAB>  "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB><TAB>  )<TAB># seek forward by at most 1MB <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  padsize = pos - self . current_size <TAB><TAB><TAB>  if padsize : <TAB><TAB><TAB><TAB>  yield PaddingBytes ( self , "" pad[] "" , padsize / / 8 ) <TAB><TAB>  chunk = Chunk ( self , "" chunk[] "" ) <TAB><TAB>  try : <TAB><TAB><TAB>  # force chunk to be processed, so that CustomFragments are complete <TAB><TAB><TAB>  chunk [ "" content/data "" ] <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB><TAB>  yield chunk ",if pos is not None :,if pos:,False,59.7436309443353,97.50668131803262
3971,"def spew ( ) : <TAB>  seenUID = False <TAB>  start ( ) <TAB>  for part in query : <TAB><TAB>  if part . type == "" uid "" : <TAB><TAB><TAB>  seenUID = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield self . spew_body ( part , id , msg , write , flush ) <TAB><TAB>  else : <TAB><TAB><TAB>  f = getattr ( self , "" spew_ "" + part . type ) <TAB><TAB><TAB>  yield f ( id , msg , write , flush ) <TAB><TAB>  if part is not query [ - 1 ] : <TAB><TAB><TAB>  space ( ) <TAB>  if uid and not seenUID : <TAB><TAB>  space ( ) <TAB><TAB>  yield self . spew_uid ( id , msg , write , flush ) <TAB>  finish ( ) <TAB>  flush ( ) ","if part . type == ""body"" :","if part.type == ""body':",False,26.608480734821168,97.30508077073343
3972,"def _limit_value ( key , value , config ) : <TAB>  if config [ key ] . get ( "" upper_limit "" ) : <TAB><TAB>  limit = config [ key ] [ "" upper_limit "" ] <TAB><TAB>  # auto handle datetime <TAB><TAB>  if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB><TAB><TAB>  if config [ key ] [ "" inverse "" ] is True : <TAB><TAB><TAB><TAB>  if ( datetime . now ( ) - limit ) > value : <TAB><TAB><TAB><TAB><TAB>  value = datetime . now ( ) - limit <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  value = datetime . now ( ) + limit <TAB><TAB>  elif value > limit : <TAB><TAB><TAB>  value = limit <TAB>  return value ",if ( datetime . now ( ) + limit ) < value :,"if isinstance(value, datetime):",False,50.66066524483925,95.15794954325403
3973,"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB>  new_names = [ ] <TAB>  map = { } <TAB>  for op in operators : <TAB><TAB>  if mod == "" input "" : <TAB><TAB><TAB>  iter = op . inputs <TAB><TAB>  else : <TAB><TAB><TAB>  iter = op . outputs <TAB><TAB>  for i in iter : <TAB><TAB><TAB>  for name in names : <TAB><TAB><TAB><TAB>  if i . raw_name == name and name not in map : <TAB><TAB><TAB><TAB><TAB>  map [ i . raw_name ] = i . full_name <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  for name in names : <TAB><TAB>  new_names . append ( map [ name ] ) <TAB>  return new_names ",if len ( map ) == len ( names ) :,if mod == 'input':,False,47.1319951548819,95.35235016411208
3974,"def traverse ( tree ) : <TAB>  """"""Generator dropping comment nodes"""""" <TAB>  for entry in tree : <TAB><TAB>  # key, values = entry <TAB><TAB>  spaceless = [ e for e in entry if not nginxparser . spacey ( e ) ] <TAB><TAB>  if spaceless : <TAB><TAB><TAB>  key = spaceless [ 0 ] <TAB><TAB><TAB>  values = spaceless [ 1 ] if len ( spaceless ) > 1 else None <TAB><TAB>  else : <TAB><TAB><TAB>  key = values = "" "" <TAB><TAB>  if isinstance ( key , list ) : <TAB><TAB><TAB>  new = copy . deepcopy ( entry ) <TAB><TAB><TAB>  new [ 1 ] = filter_comments ( values ) <TAB><TAB><TAB>  yield new <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield spaceless ","if key != ""#"" and spaceless :","if isinstance(spaceless, (list, tuple)):",False,57.162413279028335,95.23792760146182
3975,"def mergeCombiners ( self , x , y ) : <TAB>  for item in y : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . heap . push ( x , item ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . heap . push_pop ( x , item ) <TAB>  return x ",if len ( x ) < self . heap_limit :,"if isinstance(item, (int, float)):",False,21.646058058509038,87.3710130349154
3976,"def test_scatter ( self , harness : primitive_harness . Harness ) : <TAB>  f_name = harness . params [ "" f_lax "" ] . __name__ <TAB>  dtype = harness . params [ "" dtype "" ] <TAB>  if jtu . device_under_test ( ) == "" tpu "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise unittest . SkipTest ( f "" TODO: complex  { f_name }  on TPU fails in JAX "" ) <TAB>  self . ConvertAndCompare ( harness . dyn_fun , * harness . dyn_args_maker ( self . rng ( ) ) ) ","if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :",if dtype == 'float32':,False,48.08219847006009,84.76496011996288
3977,"def TryMerge ( self , decoder ) : <TAB>  while decoder . avail ( ) > 0 : <TAB><TAB>  tag = decoder . getVarInt32 ( ) <TAB><TAB>  if tag == TAG_BEGIN_ITEM_GROUP : <TAB><TAB><TAB>  ( type_id , message ) = Item . Decode ( decoder ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . items [ type_id ] . MergeFrom ( Item ( message ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . items [ type_id ] = Item ( message ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tag == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  decoder . skipData ( tag ) ",if type_id in self . items :,if type_id in self.items:,False,51.13134709311564,100.00000000000004
3978,"def process_continuations ( lines ) : <TAB>  global continuation_pattern <TAB>  olines = [ ] <TAB>  while len ( lines ) != 0 : <TAB><TAB>  line = no_comments ( lines [ 0 ] ) <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  lines . pop ( 0 ) <TAB><TAB>  if line == "" "" : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # combine this line with the next line if the next line exists <TAB><TAB><TAB>  line = continuation_pattern . sub ( "" "" , line ) <TAB><TAB><TAB>  if len ( lines ) > = 1 : <TAB><TAB><TAB><TAB>  combined_lines = [ line + lines [ 0 ] ] <TAB><TAB><TAB><TAB>  lines . pop ( 0 ) <TAB><TAB><TAB><TAB>  lines = combined_lines + lines <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  olines . append ( line ) <TAB>  del lines <TAB>  return olines ",if continuation_pattern . search ( line ) :,if line.endswith('\n'):,False,53.90556682000334,97.1385373849041
3979,"def _getListNextPackagesReadyToBuild ( ) : <TAB>  for pkg in Scheduler . listOfPackagesToBuild : <TAB><TAB>  if pkg in Scheduler . listOfPackagesCurrentlyBuilding : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB><TAB><TAB>  Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" ) ",if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,if pkg not in Scheduler.listOfPackagesNextToBuild:,False,35.76493709021352,87.57083933741968
3980,"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB>  if signature : <TAB><TAB>  # replace Mock function names <TAB><TAB>  signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB><TAB>  signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB><TAB>  # add scope name to layer signatures: <TAB><TAB>  if hasattr ( obj , "" use_scope "" ) : <TAB><TAB><TAB>  if obj . use_scope : <TAB><TAB><TAB><TAB>  signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB>  # signature: arg list <TAB>  return signature , return_annotation ",elif obj . use_scope is None :,if obj.use_scope:,False,54.20610689086314,97.60773935161575
3981,"def find_distribution_modules ( name = __name__ , file = __file__ ) : <TAB>  current_dist_depth = len ( name . split ( "" . "" ) ) - 1 <TAB>  current_dist = os . path . join ( <TAB><TAB>  os . path . dirname ( file ) , * ( [ os . pardir ] * current_dist_depth ) <TAB>  ) <TAB>  abs = os . path . abspath ( current_dist ) <TAB>  dist_name = os . path . basename ( abs ) <TAB>  for dirpath , dirnames , filenames in os . walk ( abs ) : <TAB><TAB>  package = ( dist_name + dirpath [ len ( abs ) : ] ) . replace ( "" / "" , "" . "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield package <TAB><TAB><TAB>  for filename in filenames : <TAB><TAB><TAB><TAB>  if filename . endswith ( "" .py "" ) and filename != "" __init__.py "" : <TAB><TAB><TAB><TAB><TAB>  yield "" . "" . join ( [ package , filename ] ) [ : - 3 ] ","if ""__init__.py"" in filenames :",if os.path.isdir(package):,False,33.84272294509135,95.04045289232992
3982,"def transform_value ( i , v , * args ) : <TAB>  if i not in converter_functions : <TAB><TAB>  # no converter defined on this field, return value as-is <TAB><TAB>  return v <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  return converter_functions [ i ] ( v , * args ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  if failonerror == "" inline "" : <TAB><TAB><TAB><TAB>  return e <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise e <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return errorvalue ",elif failonerror :,"if failonerror == ""exception':",False,61.269532897721724,95.95207438491065
3983,"def _get_file ( self ) : <TAB>  if self . _file is None : <TAB><TAB>  self . _file = SpooledTemporaryFile ( <TAB><TAB><TAB>  max_size = self . _storage . max_memory_size , <TAB><TAB><TAB>  suffix = "" .S3Boto3StorageFile "" , <TAB><TAB><TAB>  dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _is_dirty = False <TAB><TAB><TAB>  self . obj . download_fileobj ( self . _file ) <TAB><TAB><TAB>  self . _file . seek ( 0 ) <TAB><TAB>  if self . _storage . gzip and self . obj . content_encoding == "" gzip "" : <TAB><TAB><TAB>  self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB>  return self . _file ","if ""r"" in self . _mode :",if dir == self._storage.temp_dir:,False,27.368871208795547,95.54691949352748
3984,"def connect ( self , host , port , timeout ) : <TAB>  fp = Telnet ( ) <TAB>  for i in range ( 50 ) : <TAB><TAB>  try : <TAB><TAB><TAB>  fp . sock = socket . create_connection ( <TAB><TAB><TAB><TAB>  ( host , int ( port ) ) , timeout = int ( timeout ) , source_address = ( "" "" , 1023 - i ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  break <TAB><TAB>  except socket . error as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise e <TAB>  self . need_handshake = True <TAB>  return TCP_Connection ( fp ) ","if ( e . errno , e . strerror ) != ( 98 , ""Address already in use"" ) :",if e.errno == errno.EADDRINUSE:,False,22.461162168407796,89.32705141061919
3985,"def filtercomments ( source ) : <TAB>  """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB>  trailing_comments = [ ] <TAB>  comment = True <TAB>  while comment : <TAB><TAB>  if re . search ( r "" ^ \ s* \ / \ * "" , source ) : <TAB><TAB><TAB>  comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB><TAB>  else : <TAB><TAB><TAB>  comment = None <TAB><TAB>  if comment : <TAB><TAB><TAB>  source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB><TAB><TAB>  trailing_comments . append ( comment ) <TAB>  return "" \n "" . join ( trailing_comments ) + source ","elif re . search ( r""^\s*\/\/"" , source ) :","if re.search(r""^\s*\\/\\*\\s*\\",False,25.735643641844636,94.72945243386596
3986,"def yview ( self , mode = None , value = None , units = None ) : <TAB>  if type ( value ) == str : <TAB><TAB>  value = float ( value ) <TAB>  if mode is None : <TAB><TAB>  return self . vsb . get ( ) <TAB>  elif mode == "" moveto "" : <TAB><TAB>  frameHeight = self . innerframe . winfo_reqheight ( ) <TAB><TAB>  self . _startY = value * float ( frameHeight ) <TAB>  else :<TAB># mode == 'scroll' <TAB><TAB>  clipperHeight = self . _clipper . winfo_height ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  jump = int ( clipperHeight * self . _jfraction ) <TAB><TAB>  else : <TAB><TAB><TAB>  jump = clipperHeight <TAB><TAB>  self . _startY = self . _startY + value * jump <TAB>  self . reposition ( ) ","if units == ""units"" :",if mode == 'jfraction':,False,50.98557401734448,95.72944878489143
3987,"def visit ( stmt ) : <TAB>  """"""Collect information about VTCM buffers and their alignments."""""" <TAB>  if isinstance ( stmt , tvm . tir . AttrStmt ) : <TAB><TAB>  if stmt . attr_key == "" storage_scope "" and stmt . value == "" local.vtcm "" : <TAB><TAB><TAB>  vtcm_buffers . append ( stmt . node ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not stmt . node in alignments : <TAB><TAB><TAB><TAB>  alignments [ stmt . node ] = [ ] <TAB><TAB><TAB>  alignments [ stmt . node ] . append ( stmt . value ) ","elif stmt . attr_key == ""storage_alignment"" :","if isinstance(stmt, tvm.tir.AttrStmt):",False,55.66650470797123,91.6302653680151
3988,"def cost ( P ) : <TAB>  # wda loss <TAB>  loss_b = 0 <TAB>  loss_w = 0 <TAB>  for i , xi in enumerate ( xc ) : <TAB><TAB>  xi = np . dot ( xi , P ) <TAB><TAB>  for j , xj in enumerate ( xc [ i : ] ) : <TAB><TAB><TAB>  xj = np . dot ( xj , P ) <TAB><TAB><TAB>  M = dist ( xi , xj ) <TAB><TAB><TAB>  G = sinkhorn ( wc [ i ] , wc [ j + i ] , M , reg , k ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  loss_w + = np . sum ( G * M ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  loss_b + = np . sum ( G * M ) <TAB>  # loss inversed because minimization <TAB>  return loss_w / loss_b ",if j == 0 :,if j == j - 1:,False,26.688686552858005,98.1177125962316
3989,"def __init__ ( self , comm , in_channels , out_channels , ksize , pad = 1 ) : <TAB>  super ( Block , self ) . __init__ ( ) <TAB>  with self . init_scope ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . conv = ParallelConvolution2D ( <TAB><TAB><TAB><TAB>  comm , in_channels , out_channels , ksize , pad = pad , nobias = True <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . conv = chainer . links . Convolution2D ( <TAB><TAB><TAB><TAB>  in_channels , out_channels , ksize , pad = pad , nobias = True <TAB><TAB><TAB>  ) <TAB><TAB>  self . bn = L . BatchNormalization ( out_channels ) ",if comm . size <= in_channels :,"if isinstance(comm, chainer.links.ParallelConvolution2D):",False,48.07235460769942,94.7901044154502
3990,"def halfMultipartScore ( nzb_name ) : <TAB>  try : <TAB><TAB>  wrong_found = 0 <TAB><TAB>  for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB><TAB><TAB>  for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  wrong_found + = 1 <TAB><TAB>  if wrong_found == 1 : <TAB><TAB><TAB>  return - 30 <TAB><TAB>  return 0 <TAB>  except : <TAB><TAB>  log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB>  return 0 ","if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :",if nr == wrong:,False,46.723145406501374,90.14596316408507
3991,"def should_include ( service ) : <TAB>  for f in filt : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  state = filt [ f ] <TAB><TAB><TAB>  containers = project . containers ( [ service . name ] , stopped = True ) <TAB><TAB><TAB>  if not has_container_with_state ( containers , state ) : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  elif f == "" source "" : <TAB><TAB><TAB>  source = filt [ f ] <TAB><TAB><TAB>  if source == "" image "" or source == "" build "" : <TAB><TAB><TAB><TAB>  if source not in service . options : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise UserError ( "" Invalid filter:  %s "" % f ) <TAB>  return True ","if f == ""status"" :","if f == ""state':",False,13.261940206579759,98.70483696234557
3992,"def get_blob_type_declaration_sql ( self , column ) : <TAB>  length = column . get ( "" length "" ) <TAB>  if length : <TAB><TAB>  if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB><TAB><TAB>  return "" TINYBLOB "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" BLOB "" <TAB><TAB>  if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB><TAB><TAB>  return "" MEDIUMBLOB "" <TAB>  return "" LONGBLOB "" ",if length <= self . LENGTH_LIMIT_BLOB :,if length <= self.LENGTH_LIMIT_BLOB:,False,19.924822538675272,100.00000000000004
3993,"def click_outside ( event ) : <TAB>  if event not in d : <TAB><TAB>  x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y = 64 <TAB><TAB>  y + = 3 <TAB><TAB>  gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB><TAB>  if event . num_clicks == 2 : <TAB><TAB><TAB>  d . dismiss ( "" Goto "" ) ",if y == 0 :,if y == 0:,False,42.110654408208525,100.00000000000004
3994,"def check_related_active_jobs ( self , obj ) : <TAB>  active_jobs = obj . get_active_jobs ( ) <TAB>  if len ( active_jobs ) > 0 : <TAB><TAB>  raise ActiveJobConflict ( active_jobs ) <TAB>  time_cutoff = now ( ) - dateutil . relativedelta . relativedelta ( minutes = 1 ) <TAB>  recent_jobs = obj . _get_related_jobs ( ) . filter ( finished__gte = time_cutoff ) <TAB>  for unified_job in recent_jobs . get_real_instances ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise PermissionDenied ( <TAB><TAB><TAB><TAB>  _ ( "" Related job  {}  is still processing events. "" ) . format ( <TAB><TAB><TAB><TAB><TAB>  unified_job . log_format <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) ",if not unified_job . event_processing_finished :,if unified_job.state == 'processing':,False,30.227923459536214,96.05307999283193
3995,"def run ( self ) : <TAB>  self . alive = True <TAB>  if _log . isEnabledFor ( _DEBUG ) : <TAB><TAB>  _log . debug ( "" started "" ) <TAB>  while self . alive : <TAB><TAB>  task = self . queue . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  function , args , kwargs = task <TAB><TAB><TAB>  assert function <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  function ( * args , * * kwargs ) <TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB>  _log . exception ( "" calling  %s "" , function ) <TAB>  if _log . isEnabledFor ( _DEBUG ) : <TAB><TAB>  _log . debug ( "" stopped "" ) ",if task :,if task:,False,47.92804032742603,100.00000000000004
3996,"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB>  if not adjustments : <TAB><TAB>  return <TAB>  ( exists , contents ) = read_sysconfig_file ( fn ) <TAB>  updated_am = 0 <TAB>  for ( k , v ) in adjustments . items ( ) : <TAB><TAB>  if v is None : <TAB><TAB><TAB>  continue <TAB><TAB>  v = str ( v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  contents [ k ] = v <TAB><TAB>  updated_am + = 1 <TAB>  if updated_am : <TAB><TAB>  lines = [ <TAB><TAB><TAB>  str ( contents ) , <TAB><TAB>  ] <TAB><TAB>  if not exists : <TAB><TAB><TAB>  lines . insert ( 0 , util . make_header ( ) ) <TAB><TAB>  util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 ) ",if len ( v ) == 0 and not allow_empty :,if not allow_empty and v in contents:,False,36.39259969224508,95.95472640058289
3997,"def wrapper (<TAB># type: ignore <TAB>  self : RequestHandler , * args , * * kwargs  ) - > Optional [ Awaitable [ None ] ] : <TAB>  if self . request . path . endswith ( "" / "" ) : <TAB><TAB>  if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB><TAB><TAB>  uri = self . request . path . rstrip ( "" / "" ) <TAB><TAB><TAB>  <IF-STMT>:<TAB># don't try to redirect '/' to '' <TAB><TAB><TAB><TAB>  if self . request . query : <TAB><TAB><TAB><TAB><TAB>  uri + = "" ? "" + self . request . query <TAB><TAB><TAB><TAB>  self . redirect ( uri , permanent = True ) <TAB><TAB><TAB><TAB>  return None <TAB><TAB>  else : <TAB><TAB><TAB>  raise HTTPError ( 404 ) <TAB>  return method ( self , * args , * * kwargs ) ",if uri :,if not uri:,False,4.898654151099013,95.30771152085524
3998,def output_handles_from_execution_plan ( execution_plan ) : <TAB>  output_handles_for_current_run = set ( ) <TAB>  for step_level in execution_plan . execution_step_levels ( ) : <TAB><TAB>  for step in step_level : <TAB><TAB><TAB>  for step_input in step . step_inputs : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  output_handles_for_current_run . update ( step_input . source_handles ) <TAB>  return output_handles_for_current_run ,if step_input . source_handles :,if step_input.step_type == step.step_type:,False,49.86921674784971,92.9348882047607
3999,"def _read_value ( self , item ) : <TAB>  item = _normalize_path ( item ) <TAB>  if item in self . _store : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . _store [ item ] <TAB><TAB><TAB>  raise KeyError ( item ) <TAB><TAB>  return PathResult ( item , value = self . _store [ item ] ) <TAB>  elif item in self . _children : <TAB><TAB>  return PathResult ( item , dir = True ) <TAB>  else : <TAB><TAB>  raise KeyError ( item ) ",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if item in self._store:,False,48.3564083994791,86.51831958481581
4000,"def _line_ranges ( statements , lines ) : <TAB>  """"""Produce a list of ranges for `format_lines`."""""" <TAB>  statements = sorted ( statements ) <TAB>  lines = sorted ( lines ) <TAB>  pairs = [ ] <TAB>  start = None <TAB>  lidx = 0 <TAB>  for stmt in statements : <TAB><TAB>  if lidx > = len ( lines ) : <TAB><TAB><TAB>  break <TAB><TAB>  if stmt == lines [ lidx ] : <TAB><TAB><TAB>  lidx + = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  start = stmt <TAB><TAB><TAB>  end = stmt <TAB><TAB>  elif start : <TAB><TAB><TAB>  pairs . append ( ( start , end ) ) <TAB><TAB><TAB>  start = None <TAB>  if start : <TAB><TAB>  pairs . append ( ( start , end ) ) <TAB>  return pairs ",if not start :,if start is None:,False,33.76863242571787,98.19798007627527
4001,"def _update_help_obj_params ( help_obj , data_params , params_equal , attr_key_tups ) : <TAB>  loaded_params = [ ] <TAB>  for param_obj in help_obj . parameters : <TAB><TAB>  loaded_param = next ( <TAB><TAB><TAB>  ( n for n in data_params if params_equal ( param_obj , n ) ) , None <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  BaseHelpLoader . _update_obj_from_data_dict ( <TAB><TAB><TAB><TAB>  param_obj , loaded_param , attr_key_tups <TAB><TAB><TAB>  ) <TAB><TAB>  loaded_params . append ( param_obj ) <TAB>  help_obj . parameters = loaded_params ",if loaded_param :,if loaded_param is not None:,False,45.54536194168664,97.73946896962188
4002,"def __get_ratio ( self ) : <TAB>  """"""Return splitter ratio of the main splitter."""""" <TAB>  c = self . c <TAB>  free_layout = c . free_layout <TAB>  if free_layout : <TAB><TAB>  w = free_layout . get_main_splitter ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  aList = w . sizes ( ) <TAB><TAB><TAB>  if len ( aList ) == 2 : <TAB><TAB><TAB><TAB>  n1 , n2 = aList <TAB><TAB><TAB><TAB>  # 2017/06/07: guard against division by zero. <TAB><TAB><TAB><TAB>  ratio = 0.5 if n1 + n2 == 0 else float ( n1 ) / float ( n1 + n2 ) <TAB><TAB><TAB><TAB>  return ratio <TAB>  return 0.5 ",if w :,if w:,False,63.32974096443485,100.00000000000004
4003,"def _check_required_env_variables ( vars ) : <TAB>  for var in vars : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . tc . logger . error ( <TAB><TAB><TAB><TAB>  "" %s  is not set. Did you forget to source your build environment setup script? "" <TAB><TAB><TAB><TAB>  % var <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  raise OEQAPreRun ",if not os . environ . get ( var ) :,"if not hasattr(self, 'build_setup_script'):",False,38.81412739335869,91.543009590392
4004,"def clean_indexes ( ) : <TAB>  for coll_name in mongo . collection_types . keys ( ) : <TAB><TAB>  coll = mongo . get_collection ( coll_name ) <TAB><TAB>  indexes = coll_indexes [ coll_name ] <TAB><TAB>  try : <TAB><TAB><TAB>  for index in coll . list_indexes ( ) : <TAB><TAB><TAB><TAB>  name = index [ "" name "" ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  coll . drop_index ( name ) <TAB><TAB>  except pymongo . errors . OperationFailure : <TAB><TAB><TAB>  pass ","if name == ""_id"" or name == ""_id_"" or name in indexes :",if name == 'index':,False,43.23642180588074,90.41063801946304
4005,"def _compare_dirs ( self , dir1 , dir2 ) : <TAB>  # check that dir1 and dir2 are equivalent, <TAB>  # return the diff <TAB>  diff = [ ] <TAB>  for root , dirs , files in os . walk ( dir1 ) : <TAB><TAB>  for file_ in files : <TAB><TAB><TAB>  path = os . path . join ( root , file_ ) <TAB><TAB><TAB>  target_path = os . path . join ( dir2 , os . path . split ( path ) [ - 1 ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  diff . append ( file_ ) <TAB>  return diff ",if not os . path . exists ( target_path ) :,if os.path.exists(target_path):,False,31.961163275017014,96.99641526371143
4006,"def load_state_dict ( self , state_dict , strict = True ) : <TAB>  """"""Customized load."""""" <TAB>  self . language_model . load_state_dict ( <TAB><TAB>  state_dict [ self . _language_model_key ] , strict = strict <TAB>  ) <TAB>  if mpu . is_pipeline_last_stage ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . multichoice_head . load_state_dict ( <TAB><TAB><TAB><TAB>  state_dict [ self . _multichoice_head_key ] , strict = strict <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  print_rank_last ( <TAB><TAB><TAB><TAB>  "" ***WARNING*** could not find  {}  in the checkpoint,  "" <TAB><TAB><TAB><TAB>  "" initializing to random "" . format ( self . _multichoice_head_key ) <TAB><TAB><TAB>  ) ",if self . _multichoice_head_key in state_dict :,if self._multichoice_head_key in state_dict:,False,60.3297940183197,100.00000000000004
4007,"def _parse_timedelta ( self , value ) : <TAB>  try : <TAB><TAB>  sum = datetime . timedelta ( ) <TAB><TAB>  start = 0 <TAB><TAB>  while start < len ( value ) : <TAB><TAB><TAB>  m = self . _TIMEDELTA_PATTERN . match ( value , start ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise Exception ( ) <TAB><TAB><TAB>  num = float ( m . group ( 1 ) ) <TAB><TAB><TAB>  units = m . group ( 2 ) or "" seconds "" <TAB><TAB><TAB>  units = self . _TIMEDELTA_ABBREV_DICT . get ( units , units ) <TAB><TAB><TAB>  sum + = datetime . timedelta ( * * { units : num } ) <TAB><TAB><TAB>  start = m . end ( ) <TAB><TAB>  return sum <TAB>  except : <TAB><TAB>  raise ",if not m :,if not m:,False,42.60590232951785,100.00000000000004
4008,"def SetChildMenuBar ( self , pChild ) : <TAB>  if not pChild : <TAB><TAB>  # No Child, set Our menu bar back. <TAB><TAB>  if self . _pMyMenuBar : <TAB><TAB><TAB>  self . SetMenuBar ( self . _pMyMenuBar ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . SetMenuBar ( self . GetMenuBar ( ) ) <TAB><TAB>  # Make sure we know our menu bar is in use <TAB><TAB>  self . _pMyMenuBar = None <TAB>  else : <TAB><TAB>  if pChild . GetMenuBar ( ) is None : <TAB><TAB><TAB>  return <TAB><TAB>  # Do we need to save the current bar? <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _pMyMenuBar = self . GetMenuBar ( ) <TAB><TAB>  self . SetMenuBar ( pChild . GetMenuBar ( ) ) ",if self . _pMyMenuBar is None :,if pChild.GetMenuBar() is not None:,False,66.12629346756826,96.2265991909457
4009,"def init_weights ( self ) : <TAB>  """"""Initialize weights of the head."""""" <TAB>  # retinanet_bias_init <TAB>  bias_cls = bias_init_with_prob ( 0.01 ) <TAB>  normal_init ( self . conv_reg , std = 0.01 ) <TAB>  normal_init ( self . conv_centerness , std = 0.01 ) <TAB>  normal_init ( self . conv_cls , std = 0.01 , bias = bias_cls ) <TAB>  for branch in [ self . cls_convs , self . reg_convs ] : <TAB><TAB>  for module in branch . modules ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  caffe2_xavier_init ( module . conv ) ","if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :",if module.conv.type == 'caffe2':,False,51.97055300268305,91.06965371085855
4010,"def handle_exception ( self , e , result ) : <TAB>  for k in sorted ( result . thrift_spec ) : <TAB><TAB>  if result . thrift_spec [ k ] [ 1 ] == "" success "" : <TAB><TAB><TAB>  continue <TAB><TAB>  _ , exc_name , exc_cls , _ = result . thrift_spec [ k ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( result , exc_name , e ) <TAB><TAB><TAB>  break <TAB>  else : <TAB><TAB>  raise ","if isinstance ( e , exc_cls ) :",if exc_cls is not None:,False,22.069631129939882,94.36431214883531
4011,"def scripts ( self ) : <TAB>  application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB>  subdir = application_root != "" / "" <TAB>  scripts = [ ] <TAB>  for script in get_registered_scripts ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB><TAB>  elif subdir : <TAB><TAB><TAB>  scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB><TAB>  else : <TAB><TAB><TAB>  scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB>  return markup ( "" \n "" . join ( scripts ) ) ","if script . startswith ( ""http"" ) :",if not subdir:,False,16.881048523985932,91.76907642909633
4012,"def test_related_objects_local ( self ) : <TAB>  result_key = "" get_all_related_objects_with_model_local "" <TAB>  for model , expected in TEST_RESULTS [ result_key ] . items ( ) : <TAB><TAB>  objects = [ <TAB><TAB><TAB>  ( field , self . _model ( model , field ) ) <TAB><TAB><TAB>  for field in model . _meta . get_fields ( include_parents = False ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  ] <TAB><TAB>  self . assertEqual ( <TAB><TAB><TAB>  sorted ( self . _map_related_query_names ( objects ) , key = self . key_name ) , <TAB><TAB><TAB>  sorted ( expected , key = self . key_name ) , <TAB><TAB>  ) ",if field . auto_created and not field . concrete,if field.primary_key == self.key_name and field.primary_key ==,False,48.407005243675485,91.7462239597406
4013,"def setTestOutcome ( self , event ) : <TAB>  """"""Update outcome, exc_info and reason based on configured mappings"""""" <TAB>  if event . exc_info : <TAB><TAB>  ec , ev , tb = event . exc_info <TAB><TAB>  classname = ec . __name__ <TAB><TAB>  if classname in self . treatAsFail : <TAB><TAB><TAB>  short , long_ = self . labels ( classname ) <TAB><TAB><TAB>  self . _setOutcome ( event , "" failed "" , short , long_ ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  short , long_ = self . labels ( classname , upper = False ) <TAB><TAB><TAB>  self . _setOutcome ( event , "" skipped "" , short , "" %s :  ' %s ' "" % ( long_ , ev ) , str ( ev ) ) ",elif classname in self . treatAsSkip :,if classname in self.treatAsFail:,False,39.465513770875404,95.90065252247003
4014,"def small_count ( v ) : <TAB>  if not v : <TAB><TAB>  return 0 <TAB>  z = [ <TAB><TAB>  ( 1000000000 , _ ( "" b "" ) ) , <TAB><TAB>  ( 1000000 , _ ( "" m "" ) ) , <TAB><TAB>  ( 1000 , _ ( "" k "" ) ) , <TAB>  ] <TAB>  v = int ( v ) <TAB>  for x , y in z : <TAB><TAB>  o , p = divmod ( v , x ) <TAB><TAB>  if o : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return "" %d %s "" % ( o , y ) <TAB><TAB><TAB>  return "" %.1f %s "" % ( v / float ( x ) , y ) <TAB>  return v ",if len ( str ( o ) ) > 2 or not p :,if p:,False,48.159591667245024,93.86918756157378
4015,"def __read ( self , n ) : <TAB>  if self . _read_watcher is None : <TAB><TAB>  raise UnsupportedOperation ( "" read "" ) <TAB>  while 1 : <TAB><TAB>  try : <TAB><TAB><TAB>  return _read ( self . _fileno , n ) <TAB><TAB>  except ( IOError , OSError ) as ex : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  wait_on_watcher ( self . _read_watcher , None , None , self . hub ) ",if ex . args [ 0 ] not in ignored_errors :,if ex.errno != errno.EAGAIN:,False,22.631843530532002,92.77370112308624
4016,"def locked ( self ) : <TAB>  inputfiles = set ( self . all_inputfiles ( ) ) <TAB>  outputfiles = set ( self . all_outputfiles ( ) ) <TAB>  if os . path . exists ( self . _lockdir ) : <TAB><TAB>  for lockfile in self . _locks ( "" input "" ) : <TAB><TAB><TAB>  with open ( lockfile ) as lock : <TAB><TAB><TAB><TAB>  for f in lock : <TAB><TAB><TAB><TAB><TAB>  f = f . strip ( ) <TAB><TAB><TAB><TAB><TAB>  if f in outputfiles : <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB>  for lockfile in self . _locks ( "" output "" ) : <TAB><TAB><TAB>  with open ( lockfile ) as lock : <TAB><TAB><TAB><TAB>  for f in lock : <TAB><TAB><TAB><TAB><TAB>  f = f . strip ( ) <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if f in outputfiles or f in inputfiles :,if f in inputfiles:,False,45.90151215949667,98.52901453686071
4017,"def _flags_to_int ( flags ) : <TAB>  # Note, that order does not matter, libev has its own predefined order <TAB>  if not flags : <TAB><TAB>  return 0 <TAB>  if isinstance ( flags , integer_types ) : <TAB><TAB>  return flags <TAB>  result = 0 <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flags = flags . split ( "" , "" ) <TAB><TAB>  for value in flags : <TAB><TAB><TAB>  value = value . strip ( ) . lower ( ) <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  result | = _flags_str2int [ value ] <TAB>  except KeyError as ex : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" Invalid backend or flag:  %s \n Possible values:  %s "" <TAB><TAB><TAB>  % ( ex , "" ,  "" . join ( sorted ( _flags_str2int . keys ( ) ) ) ) <TAB><TAB>  ) <TAB>  return result ","if isinstance ( flags , basestring ) :",if len(flags) > 1:,False,34.7560785169199,96.11671227741918
4018,"def setFg ( self , colour , override = False ) : <TAB>  if not self . ttkFlag : <TAB><TAB>  self . containerStack [ - 1 ] [ "" fg "" ] = colour <TAB><TAB>  gui . SET_WIDGET_FG ( self . _getContainerProperty ( "" container "" ) , colour , override ) <TAB><TAB>  for child in self . _getContainerProperty ( "" container "" ) . winfo_children ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  gui . SET_WIDGET_FG ( child , colour , override ) <TAB>  else : <TAB><TAB>  gui . trace ( "" In ttk mode - trying to set FG to  %s "" , colour ) <TAB><TAB>  self . ttkStyle . configure ( "" TLabel "" , foreground = colour ) <TAB><TAB>  self . ttkStyle . configure ( "" TFrame "" , foreground = colour ) ",if not self . _isWidgetContainer ( child ) :,if child.mode == 'WIDGET':,False,42.114946522368726,94.44120690857488
4019,"def find_scintilla_constants ( f ) : <TAB>  lexers = [ ] <TAB>  states = [ ] <TAB>  for name in f . order : <TAB><TAB>  v = f . features [ name ] <TAB><TAB>  if v [ "" Category "" ] != "" Deprecated "" : <TAB><TAB><TAB>  if v [ "" FeatureType "" ] == "" val "" : <TAB><TAB><TAB><TAB>  if name . startswith ( "" SCE_ "" ) : <TAB><TAB><TAB><TAB><TAB>  states . append ( ( name , v [ "" Value "" ] ) ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB>  return ( lexers , states ) ","elif name . startswith ( ""SCLEX_"" ) :",if name.startswith('SCE_'):,False,25.80378721330936,96.15934522717869
4020,"def extract_error_message ( response : requests . Response ) : <TAB>  if response . content : <TAB><TAB>  try : <TAB><TAB><TAB>  content = json . loads ( response . content ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return content [ "" message "" ] <TAB><TAB>  except : <TAB><TAB><TAB>  logging . debug ( f "" Failed to parse the response content:  { response . content } "" ) <TAB>  return response . reason ","if ""message"" in content :","if content.get('error', None) == 'Message':",False,25.053283285896278,90.73702858950149
4021,"def canvas_size ( self ) : <TAB>  """"""Return the width and height for this sprite canvas"""""" <TAB>  width = height = 0 <TAB>  for image in self . images : <TAB><TAB>  x = image . x + image . absolute_width <TAB><TAB>  y = image . y + image . absolute_height <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  width = x <TAB><TAB>  if height < y : <TAB><TAB><TAB>  height = y <TAB>  return round_up ( width ) , round_up ( height ) ",if width < x :,if x < x:,False,42.294368051368004,98.19795610338048
4022,"def _load_widgets ( self ) : <TAB>  logger . info ( "" Loading plugins preferences widgets "" ) <TAB>  # Collect the preferences widget for each active plugin <TAB>  for plugin in self . plugin_manager . get_active_plugins ( ) : <TAB><TAB>  plugin_name = plugin . metadata . get ( "" name "" ) <TAB><TAB>  try : <TAB><TAB><TAB>  preferences_widget = plugin . get_preferences_widget ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _tabs . addTab ( preferences_widget , plugin_name ) <TAB><TAB>  except Exception as reason : <TAB><TAB><TAB>  logger . error ( <TAB><TAB><TAB><TAB>  "" Unable to add the preferences widget ( %s ):  %s "" , plugin_name , reason <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  continue ",if preferences_widget :,if preferences_widget:,False,61.0810252132598,100.00000000000004
4023,"def clean_objects ( string , common_attributes ) : <TAB>  """"""Return object and attribute lists"""""" <TAB>  string = clean_string ( string ) <TAB>  words = string . split ( ) <TAB>  if len ( words ) > 1 : <TAB><TAB>  prefix_words_are_adj = True <TAB><TAB>  for att in words [ : - 1 ] : <TAB><TAB><TAB>  if att not in common_attributes : <TAB><TAB><TAB><TAB>  prefix_words_are_adj = False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return words [ - 1 : ] , words [ : - 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  return [ string ] , [ ] <TAB>  else : <TAB><TAB>  return [ string ] , [ ] ",if prefix_words_are_adj :,if prefix_words_are_adj:,False,52.22605605039581,94.8669527310285
4024,"def _reader ( ) : <TAB>  if shuffle : <TAB><TAB>  random . shuffle ( file_list ) <TAB>  while True : <TAB><TAB>  for fn in file_list : <TAB><TAB><TAB>  for line in open ( fn , "" r "" ) : <TAB><TAB><TAB><TAB>  yield self . _process_line ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ",if not cycle :,if not self._process_line(line):,False,24.186539888833742,90.81302402923653
4025,"def load ( weights , model , K , fsz , dil ) : <TAB>  index = 0 <TAB>  layers = model . layers <TAB>  for layer in layers . _layers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if layer . W . shape == weights [ index ] . shape : <TAB><TAB><TAB><TAB>  layer . W [ : ] = weights [ index ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  layer . W [ : ] = dilate ( weights [ index ] , K , fsz , dil ) <TAB><TAB><TAB>  index + = 1 ","if hasattr ( layer , ""W"" ) :",if layer.W.shape == weights[index]:,False,21.715512387318604,92.46026744420267
4026,"def upgrade ( migrate_engine ) : <TAB>  print ( __doc__ ) <TAB>  metadata . bind = migrate_engine <TAB>  liftoverjobs = dict ( ) <TAB>  jobs = context . query ( DeferredJob ) . filter_by ( plugin = "" LiftOverTransferPlugin "" ) . all ( ) <TAB>  for job in jobs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  liftoverjobs [ job . params [ "" parentjob "" ] ] = [ ] <TAB><TAB>  liftoverjobs [ job . params [ "" parentjob "" ] ] . append ( job . id ) <TAB>  for parent in liftoverjobs : <TAB><TAB>  lifts = liftoverjobs [ parent ] <TAB><TAB>  deferred = context . query ( DeferredJob ) . filter_by ( id = parent ) . first ( ) <TAB><TAB>  deferred . params [ "" liftover "" ] = lifts <TAB>  context . flush ( ) ","if job . params [ ""parentjob"" ] not in liftoverjobs :",if job.params['parentjob'] not in liftoverjobs:,False,26.911551958244097,97.81860955240725
4027,"def get_refs ( self , recursive = False ) : <TAB>  """""":see: AbstractExpression.get_refs()"""""" <TAB>  if recursive : <TAB><TAB>  conds_refs = self . refs + sum ( ( c . get_refs ( True ) for c in self . conds ) , [ ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  conds_refs . extend ( self . consequent . get_refs ( True ) ) <TAB><TAB>  return conds_refs <TAB>  else : <TAB><TAB>  return self . refs ",if self . consequent :,if self.consequent:,False,52.32028130101938,100.00000000000004
4028,"def _parse ( self , engine ) : <TAB>  """"""Parse the layer."""""" <TAB>  if isinstance ( self . args , dict ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB>  if not isinstance ( self . axis , int ) : <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB>  if "" momentum "" in self . args : <TAB><TAB><TAB>  self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB>  if not isinstance ( self . momentum , ( int , float ) ) : <TAB><TAB><TAB><TAB>  raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if ""axis"" in self . args :","if ""axis"" in self.args:",False,34.89786887011127,100.00000000000004
4029,"def CountMatches ( pat , predicate ) : <TAB>  num_matches = 0 <TAB>  for i in xrange ( 256 ) : <TAB><TAB>  b = chr ( i ) <TAB><TAB>  m = pat . match ( b ) <TAB><TAB>  left = bool ( m ) <TAB><TAB>  right = predicate ( i ) <TAB><TAB>  if left != right : <TAB><TAB><TAB>  self . fail ( "" i =  %d , b =  %r , match:  %s , predicate:  %s "" % ( i , b , left , right ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  num_matches + = 1 <TAB>  return num_matches ",if m :,if m:,False,45.10336071663962,100.00000000000004
4030,"def __new__ ( cls , * args , * * kwargs ) : <TAB>  if len ( args ) == 1 : <TAB><TAB>  if len ( kwargs ) : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB><TAB><TAB><TAB><TAB>  cls . __name__ <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB>  if not args [ 0 ] : <TAB><TAB><TAB>  return super ( ) . __new__ ( cls ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return cls <TAB>  return super ( ) . __new__ ( cls , * args , * * kwargs ) ","if isinstance ( args [ 0 ] , cls ) :",if not args:,False,32.58176827082183,95.25217651612851
4031,"def concatenateCharacterTokens ( tokens ) : <TAB>  pendingCharacters = [ ] <TAB>  for token in tokens : <TAB><TAB>  type = token [ "" type "" ] <TAB><TAB>  if type in ( "" Characters "" , "" SpaceCharacters "" ) : <TAB><TAB><TAB>  pendingCharacters . append ( token [ "" data "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) } <TAB><TAB><TAB><TAB>  pendingCharacters = [ ] <TAB><TAB><TAB>  yield token <TAB>  <IF-STMT>: <TAB><TAB>  yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) } ",if pendingCharacters :,if pendingCharacters:,False,44.92699284055141,97.60724046619885
4032,"def get_ranges_from_func_set ( support_set ) : <TAB>  pos_start = 0 <TAB>  pos_end = 0 <TAB>  ranges = [ ] <TAB>  for pos , func in enumerate ( network . function ) : <TAB><TAB>  if func . type in support_set : <TAB><TAB><TAB>  pos_end = pos <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ranges . append ( ( pos_start , pos_end ) ) <TAB><TAB><TAB>  pos_start = pos + 1 <TAB>  <IF-STMT>: <TAB><TAB>  ranges . append ( ( pos_start , pos_end ) ) <TAB>  return ranges ",if pos_end >= pos_start :,if pos_start < 0 or pos_end > 0:,False,20.408565524390504,92.26898081139153
4033,"def _visit ( self , func ) : <TAB>  fname = func [ 0 ] <TAB>  if fname in self . _flags : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB><TAB><TAB>  import sys <TAB><TAB><TAB>  sys . exit ( - 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  return <TAB>  else : <TAB><TAB>  if fname not in self . _flags : <TAB><TAB><TAB>  self . _flags [ fname ] = 1 <TAB><TAB>  for output in func [ 3 ] : <TAB><TAB><TAB>  for f in self . _orig : <TAB><TAB><TAB><TAB>  for input in f [ 2 ] : <TAB><TAB><TAB><TAB><TAB>  if output == input : <TAB><TAB><TAB><TAB><TAB><TAB>  self . _visit ( f ) <TAB>  self . _flags [ fname ] = 2 <TAB>  self . _sorted . insert ( 0 , func ) ",if self . _flags [ fname ] == 1 :,if fname == 'debug':,False,53.469518037444416,95.33318307157687
4034,"def graph_merge_softmax_with_crossentropy_softmax ( node ) : <TAB>  if node . op == softmax_with_bias : <TAB><TAB>  x , b = node . inputs <TAB><TAB>  for x_client in x . clients : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  big_client = x_client [ 0 ] <TAB><TAB><TAB><TAB>  if big_client in [ b_client [ 0 ] for b_client in b . clients ] : <TAB><TAB><TAB><TAB><TAB>  xx , bb , ll = big_client . inputs <TAB><TAB><TAB><TAB><TAB>  mergeable_client = big_client . op ( x , b , ll ) <TAB><TAB><TAB><TAB><TAB>  copy_stack_trace ( node . outputs [ 0 ] , mergeable_client [ 1 ] ) <TAB><TAB><TAB><TAB><TAB>  return [ mergeable_client [ 1 ] ] ",if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias :,if x_client[0].type == 'big':,False,49.93984123184154,94.30287913010832
4035,"def confidence ( self ) : <TAB>  if self . bbox : <TAB><TAB>  # Units are measured in Kilometers <TAB><TAB>  distance = Distance ( self . northeast , self . southwest , units = "" km "" ) <TAB><TAB>  for score , maximum in [ <TAB><TAB><TAB>  ( 10 , 0.25 ) , <TAB><TAB><TAB>  ( 9 , 0.5 ) , <TAB><TAB><TAB>  ( 8 , 1 ) , <TAB><TAB><TAB>  ( 7 , 5 ) , <TAB><TAB><TAB>  ( 6 , 7.5 ) , <TAB><TAB><TAB>  ( 5 , 10 ) , <TAB><TAB><TAB>  ( 4 , 15 ) , <TAB><TAB><TAB>  ( 3 , 20 ) , <TAB><TAB><TAB>  ( 2 , 25 ) , <TAB><TAB>  ] : <TAB><TAB><TAB>  if distance < maximum : <TAB><TAB><TAB><TAB>  return score <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return 1 <TAB>  # Cannot determine score <TAB>  return 0 ",if distance >= 25 :,if score < maximum:,False,53.42957617235506,97.98036582216307
4036,"def OnListEndLabelEdit ( self , std , extra ) : <TAB>  item = extra [ 0 ] <TAB>  text = item [ 4 ] <TAB>  if text is None : <TAB><TAB>  return <TAB>  item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB>  from bdb import Breakpoint <TAB>  for bplist in Breakpoint . bplist . itervalues ( ) : <TAB><TAB>  for bp in bplist : <TAB><TAB><TAB>  if id ( bp ) == item_id : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  text = None <TAB><TAB><TAB><TAB>  bp . cond = text <TAB><TAB><TAB><TAB>  break <TAB>  self . RespondDebuggerData ( ) ","if text . strip ( ) . lower ( ) == ""none"" :",if text == None:,False,47.02607033993468,92.90219098687913
4037,"def _handle_autocomplete_request_for_text ( text ) : <TAB>  if not hasattr ( text , "" autocompleter "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( text , CodeViewText ) : <TAB><TAB><TAB><TAB>  text . autocompleter = Completer ( text ) <TAB><TAB><TAB>  elif isinstance ( text , ShellText ) : <TAB><TAB><TAB><TAB>  text . autocompleter = ShellCompleter ( text ) <TAB><TAB><TAB>  text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB><TAB>  else : <TAB><TAB><TAB>  return <TAB>  text . autocompleter . handle_autocomplete_request ( ) ","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :","if not hasattr(text, 'autocompleter'):",False,45.964612886501946,89.83599017527726
4038,"def visit_Macro ( self , node , frame ) : <TAB>  macro_frame , macro_ref = self . macro_body ( node , frame ) <TAB>  self . newline ( ) <TAB>  if frame . toplevel : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . write ( "" context.exported_vars.add( %r ) "" % node . name ) <TAB><TAB>  ref = frame . symbols . ref ( node . name ) <TAB><TAB>  self . writeline ( "" context.vars[ %r ] =  "" % node . name ) <TAB>  self . write ( "" %s  =  "" % frame . symbols . ref ( node . name ) ) <TAB>  self . macro_def ( macro_ref , macro_frame ) ","if not node . name . startswith ( ""_"" ) :",if not self.is_context_variable(node.name):,False,37.07253752116091,94.38517363256854
4039,"def execute ( cls , ctx , op ) : <TAB>  try : <TAB><TAB>  pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return cls . _execute_map ( ctx , op ) <TAB><TAB>  else : <TAB><TAB><TAB>  return cls . _execute_combine ( ctx , op ) <TAB>  finally : <TAB><TAB>  pd . reset_option ( "" mode.use_inf_as_na "" ) ",if op . stage == OperandStage . map :,if op.use_inf_as_na:,False,23.2127377016162,94.06660327804788
4040,"def ranges ( self , start , end ) : <TAB>  try : <TAB><TAB>  iterators = [ i . ranges ( start , end ) for i in self . range_iterators ] <TAB><TAB>  starts , ends , values = zip ( * [ next ( i ) for i in iterators ] ) <TAB><TAB>  starts = list ( starts ) <TAB><TAB>  ends = list ( ends ) <TAB><TAB>  values = list ( values ) <TAB><TAB>  while start < end : <TAB><TAB><TAB>  min_end = min ( ends ) <TAB><TAB><TAB>  yield start , min_end , values <TAB><TAB><TAB>  start = min_end <TAB><TAB><TAB>  for i , iterator in enumerate ( iterators ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  starts [ i ] , ends [ i ] , values [ i ] = next ( iterator ) <TAB>  except StopIteration : <TAB><TAB>  return ",if ends [ i ] == min_end :,if iterator.startswith(start):,False,31.097085007132698,95.7883898919869
4041,"def get_explanation ( self , spec ) : <TAB>  """"""Expand an explanation."""""" <TAB>  if spec : <TAB><TAB>  try : <TAB><TAB><TAB>  a = self . dns_txt ( spec ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB><TAB>  except PermError : <TAB><TAB><TAB>  # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB><TAB><TAB>  if self . strict > 1 : <TAB><TAB><TAB><TAB>  raise<TAB># but report in harsh mode for record checking tools <TAB><TAB><TAB>  pass <TAB>  elif self . strict > 1 : <TAB><TAB>  raise PermError ( "" Empty domain-spec on exp= "" ) <TAB>  # RFC4408 6.2/4 empty domain spec is ignored <TAB>  # (unless you give precedence to the grammar). <TAB>  return None ",if len ( a ) == 1 :,if len(a) == 1:,False,65.52167074767854,98.18600527294589
4042,"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB>  exclude_meta = not include_meta <TAB>  for field_name , field in node . _fields . items ( ) : <TAB><TAB>  if exclude_meta and field . meta : <TAB><TAB><TAB>  continue <TAB><TAB>  field_val = getattr ( node , field_name , _marker ) <TAB><TAB>  if field_val is _marker : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if callable ( field . default ) : <TAB><TAB><TAB><TAB>  default = field . default ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  default = field . default <TAB><TAB><TAB>  if field_val == default : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield field_name , field_val ",if exclude_unset :,if field.default is not None:,False,49.90421224211185,96.9038592599877
4043,"def __setattr__ ( self , name , value ) : <TAB>  try : <TAB><TAB>  field = self . _meta . get_field ( name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = value [ : field . max_length ] <TAB>  except models . fields . FieldDoesNotExist : <TAB><TAB>  pass<TAB># This happens with foreign keys. <TAB>  super . __setattr__ ( self , name , value ) ","if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str :",if field.max_length:,False,21.53408858082848,80.28906485866351
4044,"def create_child ( self , value = None , _id = None ) : <TAB>  with atomic ( savepoint = False ) : <TAB><TAB>  child_key = self . get_next_child_key ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = child_key <TAB><TAB>  child = self . __class__ . objects . create ( id = _id , key = child_key , value = value ) <TAB><TAB>  return child ",if value is None :,if value is None:,False,51.11328572051519,100.00000000000004
4045,"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB>  stream = self . describe_stream ( stream_name ) <TAB>  tags = [ ] <TAB>  result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB>  for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ "" HasMoreTags "" ] = True <TAB><TAB><TAB>  break <TAB><TAB>  if exclusive_start_tag_key and key < exclusive_start_tag_key : <TAB><TAB><TAB>  continue <TAB><TAB>  tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB>  return result ",if limit and len ( tags ) >= limit :,if limit and key >= limit:,False,27.97468875029528,97.31902692885943
4046,"def emit ( self , record ) : <TAB>  try : <TAB><TAB>  app = get_app ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg = self . format ( record ) <TAB><TAB><TAB>  debug_buffer = app . layout . get_buffer_by_name ( "" debug_buffer "" ) <TAB><TAB><TAB>  current_document = debug_buffer . document . text <TAB><TAB><TAB>  if current_document : <TAB><TAB><TAB><TAB>  msg = "" \n "" . join ( [ current_document , msg ] ) <TAB><TAB><TAB>  debug_buffer . set_document ( Document ( text = msg ) , bypass_readonly = True ) <TAB><TAB>  else : <TAB><TAB><TAB>  super ( ) . emit ( record ) <TAB>  except : <TAB><TAB>  self . handleError ( record ) ","if app . is_running and getattr ( app , ""debug"" , False ) :",if app.debug_mode:,False,22.693310073970117,93.43194952770892
4047,"def worker ( ) : <TAB>  global error <TAB>  while True : <TAB><TAB>  ( num , q ) = pq . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pq . task_done ( ) <TAB><TAB><TAB>  break <TAB><TAB>  try : <TAB><TAB><TAB>  process_one ( q ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  error = e <TAB><TAB>  finally : <TAB><TAB><TAB>  pq . task_done ( ) ",if q is None or error is not None :,if num == 0:,False,21.33724026105024,93.36060308766899
4048,"def transceiver ( self , data ) : <TAB>  out = [ ] <TAB>  for t in range ( 8 ) : <TAB><TAB>  if data [ t ] == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  value = data [ t ] <TAB><TAB>  for b in range ( 8 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if len ( TRANSCEIVER [ t ] ) < b + 1 : <TAB><TAB><TAB><TAB><TAB>  out . append ( "" (unknown) "" ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB><TAB><TAB>  value << = 1 <TAB>  self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) ) ",if value & 0x80 :,if value & 1:,False,49.90304101868519,98.83579057291513
4049,"def skip_to_close_match ( self ) : <TAB>  nestedCount = 1 <TAB>  while 1 : <TAB><TAB>  tok = self . tokenizer . get_next_token ( ) <TAB><TAB>  ttype = tok [ "" style "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  elif self . classifier . is_index_op ( tok ) : <TAB><TAB><TAB>  tval = tok [ "" text "" ] <TAB><TAB><TAB>  if self . opHash . has_key ( tval ) : <TAB><TAB><TAB><TAB>  if self . opHash [ tval ] [ 1 ] == 1 : <TAB><TAB><TAB><TAB><TAB>  nestedCount + = 1 <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  nestedCount - = 1 <TAB><TAB><TAB><TAB><TAB>  if nestedCount < = 0 : <TAB><TAB><TAB><TAB><TAB><TAB>  break ",if ttype == SCE_PL_UNUSED :,if ttype == 'text':,False,46.65910045537869,97.46984703698774
4050,"def GenerateVector ( self , hits , vector , level ) : <TAB>  """"""Generate possible hit vectors which match the rules."""""" <TAB>  for item in hits . get ( level , [ ] ) : <TAB><TAB>  if vector : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if item > self . max_separation + vector [ - 1 ] : <TAB><TAB><TAB><TAB>  break <TAB><TAB>  new_vector = vector + [ item ] <TAB><TAB>  if level + 1 == len ( hits ) : <TAB><TAB><TAB>  yield new_vector <TAB><TAB>  elif level + 1 < len ( hits ) : <TAB><TAB><TAB>  for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB><TAB><TAB><TAB>  yield result ",if item < vector [ - 1 ] :,if not vector:,False,57.008248410100926,95.58490021450466
4051,"def __setattr__ ( self , name , value ) : <TAB>  if name == "" path "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if value [ 0 ] != "" / "" : <TAB><TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB><TAB>  ' The page path should always start with a slash ( "" / "" ). ' <TAB><TAB><TAB><TAB>  ) <TAB>  elif name == "" load_time "" : <TAB><TAB>  if value and not isinstance ( value , int ) : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Page load time must be specified in integer milliseconds. "" <TAB><TAB><TAB>  ) <TAB>  object . __setattr__ ( self , name , value ) ","if value and value != """" :","if name == ""path_separator':",False,25.994871669049203,94.66191681137803
4052,"def awaitTermination ( self , timeout = None ) : <TAB>  if self . scheduler is None : <TAB><TAB>  raise RuntimeError ( "" StreamimgContext not started "" ) <TAB>  try : <TAB><TAB>  deadline = time . time ( ) + timeout if timeout is not None else None <TAB><TAB>  while True : <TAB><TAB><TAB>  is_terminated = self . _runOnce ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  if self . batchCallback : <TAB><TAB><TAB><TAB>  self . batchCallback ( ) <TAB>  except KeyboardInterrupt : <TAB><TAB>  pass <TAB>  finally : <TAB><TAB>  self . sc . stop ( ) <TAB><TAB>  logger . info ( "" StreamingContext stopped successfully "" ) ",if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,if is_terminated:,False,33.29631204485219,91.87361081785464
4053,"def stopbutton ( self ) : <TAB>  if GPIOcontrol : <TAB><TAB>  while mediastopbutton : <TAB><TAB><TAB>  time . sleep ( 0.25 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  print ( "" Stopped "" ) <TAB><TAB><TAB><TAB>  stop ( ) ",if not GPIO . input ( stoppushbutton ) :,if self.debugging:,False,22.420258677104503,90.28376074280406
4054,"def test_create_connection_timeout ( self ) : <TAB>  # Issue #9792: create_connection() should not recast timeout errors <TAB>  # as generic socket errors. <TAB>  with self . mocked_socket_module ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  socket . create_connection ( ( HOST , 1234 ) ) <TAB><TAB>  except socket . timeout : <TAB><TAB><TAB>  pass <TAB><TAB>  except OSError as exc : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB>  else : <TAB><TAB><TAB>  self . fail ( "" socket.timeout not raised "" ) ",if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT :,if exc.errno == errno.EAGAIN:,False,35.23942418310242,92.97797830243222
4055,"def handle_exception_and_die ( e ) : <TAB>  if hasattr ( e , "" kind "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sys . stderr . write ( "" ABORT:  "" + e . msg + "" \n "" ) <TAB><TAB><TAB>  sys . exit ( e . value ) <TAB><TAB>  elif e . kind == "" exit "" : <TAB><TAB><TAB>  sys . stderr . write ( "" EXITING \n "" ) <TAB><TAB><TAB>  sys . exit ( e . value ) <TAB>  else : <TAB><TAB>  print ( str ( e ) ) <TAB><TAB>  sys . exit ( 1 ) ","if e . kind == ""die"" :","if e.kind == ""abort':",False,15.883502323909864,97.93178330955692
4056,"def gets ( self , key ) : <TAB>  with self . client_pool . get_and_release ( destroy_on_fail = True ) as client : <TAB><TAB>  try : <TAB><TAB><TAB>  return client . gets ( key ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return ( None , None ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise ",if self . ignore_exc :,if self.client_pool.get_and_release(key):,False,23.70602389698178,90.0573026166869
4057,"def _execute ( self , options , args ) : <TAB>  if len ( args ) < 3 : <TAB><TAB>  raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB>  tag = fsn2text ( args [ 0 ] ) <TAB>  value = fsn2text ( args [ 1 ] ) <TAB>  paths = args [ 2 : ] <TAB>  songs = [ ] <TAB>  for path in paths : <TAB><TAB>  song = self . load_song ( path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise CommandError ( _ ( "" Can not set  %r "" ) % tag ) <TAB><TAB>  self . log ( "" Add  %r  to  %r "" % ( value , tag ) ) <TAB><TAB>  song . add ( tag , value ) <TAB><TAB>  songs . append ( song ) <TAB>  self . save_songs ( songs ) ",if not song . can_change ( tag ) :,if not song:,False,36.40467627304561,95.86679826754599
4058,"def get_place_name ( self , place_handle ) : <TAB>  """"""Obtain a place name"""""" <TAB>  text = "" "" <TAB>  if place_handle : <TAB><TAB>  place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB><TAB>  if place : <TAB><TAB><TAB>  place_title = place_displayer . display ( self . dbstate . db , place ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if len ( place_title ) > 25 : <TAB><TAB><TAB><TAB><TAB>  text = place_title [ : 24 ] + "" ... "" <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  text = place_title <TAB>  return text ","if place_title != """" :",if place_title:,False,34.17697780358851,97.39081043001525
4059,"def _Determine_Do ( self ) : <TAB>  self . applicable = 1 <TAB>  self . value = os . environ . get ( self . name , None ) <TAB>  if self . value is None and black . configure . items . has_key ( "" buildType "" ) : <TAB><TAB>  buildType = black . configure . items [ "" buildType "" ] . Get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . value = "" warn "" <TAB><TAB>  else : <TAB><TAB><TAB>  self . value = None <TAB>  self . determined = 1 ","if buildType == ""debug"" :",if buildType == 'warn':,False,52.28688129149107,96.81490932448195
4060,"def bundle_directory ( self , dirpath ) : <TAB>  """"""Bundle all modules/packages in the given directory."""""" <TAB>  dirpath = os . path . abspath ( dirpath ) <TAB>  for nm in os . listdir ( dirpath ) : <TAB><TAB>  nm = _u ( nm ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  itempath = os . path . join ( dirpath , nm ) <TAB><TAB>  if os . path . isdir ( itempath ) : <TAB><TAB><TAB>  if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB><TAB><TAB><TAB>  self . bundle_package ( itempath ) <TAB><TAB>  elif nm . endswith ( "" .py "" ) : <TAB><TAB><TAB>  self . bundle_module ( itempath ) ","if nm . startswith ( ""."" ) :",if nm == 'main':,False,28.583469104426317,96.06554697267924
4061,"def header_fields ( self , fields ) : <TAB>  headers = dict ( self . conn . response . getheaders ( ) ) <TAB>  ret = { } <TAB>  for field in fields : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" %s  was not found in response header "" % ( field [ 1 ] ) ) <TAB><TAB>  try : <TAB><TAB><TAB>  ret [ field [ 0 ] ] = int ( headers [ field [ 1 ] ] ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  ret [ field [ 0 ] ] = headers [ field [ 1 ] ] <TAB>  return ret ",if not headers . has_key ( field [ 1 ] ) :,"if not headers.has_key(field[1], field[0]):",False,39.16676257537433,96.58292474185882
4062,"def caesar_cipher ( s , k ) : <TAB>  result = "" "" <TAB>  for char in s : <TAB><TAB>  n = ord ( char ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n = ( ( n - 65 + k ) % 26 ) + 65 <TAB><TAB>  if 96 < n < 123 : <TAB><TAB><TAB>  n = ( ( n - 97 + k ) % 26 ) + 97 <TAB><TAB>  result = result + chr ( n ) <TAB>  return result ",if 64 < n < 91 :,if 48 < n < n < 122:,False,47.77209830514802,94.60457113946381
4063,"def qtTypeIdent ( conn , * args ) : <TAB>  # We're not using the conn object at the moment, but - we will <TAB>  # modify the <TAB>  # logic to use the server version specific keywords later. <TAB>  res = None <TAB>  value = None <TAB>  for val in args : <TAB><TAB>  # DataType doesn't have len function then convert it to string <TAB><TAB>  if not hasattr ( val , "" __len__ "" ) : <TAB><TAB><TAB>  val = str ( val ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  value = val <TAB><TAB>  if Driver . needsQuoting ( val , True ) : <TAB><TAB><TAB>  value = value . replace ( ' "" ' , ' "" "" ' ) <TAB><TAB><TAB>  value = ' "" ' + value + ' "" ' <TAB><TAB>  res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB>  return res ",if len ( val ) == 0 :,if val == None:,False,40.11427511286478,96.8853480097829
4064,"def _parse_timezone ( <TAB>  value : Optional [ str ] , error : Type [ Exception ]  ) - > Union [ None , int , timezone ] : <TAB>  if value == "" Z "" : <TAB><TAB>  return timezone . utc <TAB>  elif value is not None : <TAB><TAB>  offset_mins = int ( value [ - 2 : ] ) if len ( value ) > 3 else 0 <TAB><TAB>  offset = 60 * int ( value [ 1 : 3 ] ) + offset_mins <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  offset = - offset <TAB><TAB>  try : <TAB><TAB><TAB>  return timezone ( timedelta ( minutes = offset ) ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  raise error ( ) <TAB>  else : <TAB><TAB>  return None ","if value [ 0 ] == ""-"" :",if offset < 0:,False,23.172675384183467,92.5912068772586
4065,"def indent ( elem , level = 0 ) : <TAB>  i = "" \n "" + level * ""<TAB>"" <TAB>  if len ( elem ) : <TAB><TAB>  if not elem . text or not elem . text . strip ( ) : <TAB><TAB><TAB>  elem . text = i + ""<TAB>"" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elem . tail = i <TAB><TAB>  for elem in elem : <TAB><TAB><TAB>  indent ( elem , level + 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elem . tail = i <TAB>  else : <TAB><TAB>  if level and ( not elem . tail or not elem . tail . strip ( ) ) : <TAB><TAB><TAB>  elem . tail = i ",if not elem . tail or not elem . tail . strip ( ) :,if level and (not elem.tail or not elem.tail.strip()):,False,31.859973546034205,90.36749068512718
4066,"def _make_slices ( <TAB>  shape : tp . Tuple [ int , . . . ] , <TAB>  axes : tp . Tuple [ int , . . . ] , <TAB>  size : int , <TAB>  rng : np . random . RandomState ,  ) - > tp . List [ slice ] : <TAB>  slices = [ ] <TAB>  for a , s in enumerate ( shape ) : <TAB><TAB>  if a in axes : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ValueError ( "" Cannot crossover on axis with size 1 "" ) <TAB><TAB><TAB>  start = rng . randint ( s - size ) <TAB><TAB><TAB>  slices . append ( slice ( start , start + size ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  slices . append ( slice ( None ) ) <TAB>  return slices ",if s <= 1 :,if s < size:,False,49.15420571053116,98.31107177694555
4067,"def _loadTestsFromTestCase ( self , event , testCaseClass ) : <TAB>  evt = events . LoadFromTestCaseEvent ( event . loader , testCaseClass ) <TAB>  result = self . session . hooks . loadTestsFromTestCase ( evt ) <TAB>  if evt . handled : <TAB><TAB>  loaded_suite = result or event . loader . suiteClass ( ) <TAB>  else : <TAB><TAB>  names = self . _getTestCaseNames ( event , testCaseClass ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  names = [ "" runTest "" ] <TAB><TAB>  # FIXME return failure test case if name not in testcase class <TAB><TAB>  loaded_suite = event . loader . suiteClass ( map ( testCaseClass , names ) ) <TAB>  if evt . extraTests : <TAB><TAB>  loaded_suite . addTests ( evt . extraTests ) <TAB>  return loaded_suite ","if not names and hasattr ( testCaseClass , ""runTest"" ) :",if names is None:,False,56.13563560761584,93.67516018191371
4068,"def check_settings ( self ) : <TAB>  if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB><TAB>  if not settings . USE_TZ : <TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB>  "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB><TAB><TAB><TAB>  "" False. "" % self . alias <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB>  "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB><TAB><TAB><TAB>  "" handles time zones conversions natively. "" % self . alias <TAB><TAB><TAB>  ) ",elif self . features . supports_timezones :,if not self.settings_dict['TIME_ZONE']:,False,57.28954679052212,90.37715054822978
4069,"def collect_conflicting_diffs ( path , decisions ) : <TAB>  local_conflict_diffs = [ ] <TAB>  remote_conflict_diffs = [ ] <TAB>  for d in decisions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ld = adjust_patch_level ( path , d . common_path , d . local_diff ) <TAB><TAB><TAB>  rd = adjust_patch_level ( path , d . common_path , d . remote_diff ) <TAB><TAB><TAB>  local_conflict_diffs . extend ( ld ) <TAB><TAB><TAB>  remote_conflict_diffs . extend ( rd ) <TAB>  return local_conflict_diffs , remote_conflict_diffs ",if d . conflict :,if d.diff_diff:,False,50.927701433761975,97.32247148753277
4070,"def short_repr ( obj ) : <TAB>  if isinstance ( <TAB><TAB>  obj , <TAB><TAB>  ( type , types . ModuleType , types . BuiltinMethodType , types . BuiltinFunctionType ) , <TAB>  ) : <TAB><TAB>  return obj . __name__ <TAB>  if isinstance ( obj , types . MethodType ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return obj . im_func . __name__ + ""  (bound) "" <TAB><TAB>  else : <TAB><TAB><TAB>  return obj . im_func . __name__ <TAB>  if isinstance ( obj , ( tuple , list , dict , set ) ) : <TAB><TAB>  return "" %d  items "" % len ( obj ) <TAB>  if isinstance ( obj , weakref . ref ) : <TAB><TAB>  return "" all_weakrefs_are_one "" <TAB>  return repr ( obj ) [ : 40 ] ",if obj . im_self is not None :,"if isinstance(obj, types.MethodType):",False,22.24766699111436,95.96526455328903
4071,"def _massage_uri ( uri ) : <TAB>  if uri : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  uri = uri . replace ( "" hdfs:// "" , get_defaultfs ( ) ) <TAB><TAB>  elif uri . startswith ( "" / "" ) : <TAB><TAB><TAB>  uri = get_defaultfs ( ) + uri <TAB>  return uri ","if uri . startswith ( ""hdfs:///"" ) :",if uri.startswith('http'):,False,50.766242481674915,91.43546396881767
4072,"def chsub ( self , msg , chatid ) : <TAB>  ( cmd , evt , params ) = self . tokenize ( msg , 3 ) <TAB>  if cmd == "" /sub "" : <TAB><TAB>  sql = "" replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?) "" <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sql = "" delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1) ""<TAB># does not look very elegant, but makes unsub'ing everythign possible <TAB><TAB>  else : <TAB><TAB><TAB>  sql = "" delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ? "" <TAB>  with self . bot . database as conn : <TAB><TAB>  conn . execute ( sql , [ chatid , evt , params ] ) <TAB><TAB>  conn . commit ( ) <TAB>  return ","if evt == ""everything"" :",if cmd == /del:,False,39.06144281509143,95.51785000525636
4073,"def undefined_symbols ( self ) : <TAB>  result = [ ] <TAB>  for p in self . Productions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for s in p . prod : <TAB><TAB><TAB>  if not s in self . Prodnames and not s in self . Terminals and s != "" error "" : <TAB><TAB><TAB><TAB>  result . append ( ( s , p ) ) <TAB>  return result ",if not p :,if not p.is_null:,False,27.987586637019984,95.34421951468279
4074,"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB>  out = [ ] <TAB>  for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB><TAB>  m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB><TAB>  if m is not None : <TAB><TAB><TAB>  sx , sy = m . groups ( ) <TAB><TAB><TAB>  x = colname2num ( sx ) <TAB><TAB><TAB>  y = int ( sy ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  part = cellname ( x + dx , y + dy ) <TAB><TAB>  out . append ( part ) <TAB>  return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment ) ",if x1 <= x <= x2 and y1 <= y <= y2 :,if x != y1 and y2 != y1:,False,29.7847104228373,93.39910924455248
4075,"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB>  for i in range ( len ( column ) ) : <TAB><TAB>  gate = column [ i ] <TAB><TAB>  if gate is self : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # The first parity control to modify the column must merge all <TAB><TAB><TAB>  # of the other parity controls into itself. <TAB><TAB><TAB>  column [ i ] = None <TAB><TAB><TAB>  self . _basis_change + = gate . _basis_change <TAB><TAB><TAB>  self . qubits + = gate . qubits <TAB><TAB>  elif gate is not None : <TAB><TAB><TAB>  column [ i ] = gate . controlled_by ( self . qubits [ 0 ] ) ","elif isinstance ( gate , ParityControlCell ) :",if column[i] is None:,False,43.28297419970548,95.99556127157071
4076,"def update_neighbor ( neigh_ip_address , changes ) : <TAB>  rets = [ ] <TAB>  for k , v in changes . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB><TAB>  if k == neighbors . ENABLED : <TAB><TAB><TAB>  rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB><TAB>  if k == neighbors . CONNECT_MODE : <TAB><TAB><TAB>  rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB>  return all ( rets ) ",if k == neighbors . MULTI_EXIT_DISC :,if k == neighbors.MAGIC:,False,51.27096539468352,96.2406051248498
4077,"def writexml ( <TAB>  self , <TAB>  stream , <TAB>  indent = "" "" , <TAB>  addindent = "" "" , <TAB>  newl = "" "" , <TAB>  strip = 0 , <TAB>  nsprefixes = { } , <TAB>  namespace = "" "" ,  ) : <TAB>  w = _streamWriteWrapper ( stream ) <TAB>  if self . raw : <TAB><TAB>  val = self . nodeValue <TAB><TAB>  if not isinstance ( val , str ) : <TAB><TAB><TAB>  val = str ( self . nodeValue ) <TAB>  else : <TAB><TAB>  v = self . nodeValue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = str ( v ) <TAB><TAB>  if strip : <TAB><TAB><TAB>  v = "" "" . join ( v . split ( ) ) <TAB><TAB>  val = escape ( v ) <TAB>  w ( val ) ","if not isinstance ( v , str ) :","if not isinstance(v, str):",False,34.39634419529115,100.00000000000004
4078,"def _condition ( ct ) : <TAB>  for qobj in args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # normal kwargs are an AND anyway, so just use those for now <TAB><TAB><TAB>  for child in qobj . children : <TAB><TAB><TAB><TAB>  kwargs . update ( dict ( [ child ] ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError ( "" Unsupported Q object "" ) <TAB>  for attr , val in kwargs . items ( ) : <TAB><TAB>  if getattr ( ct , attr ) != val : <TAB><TAB><TAB>  return False <TAB>  return True ","if qobj . connector == ""AND"" and not qobj . negated :","if isinstance(qobj, Q):",False,37.12188515089121,91.53590137945206
4079,"def results_iter ( self ) : <TAB>  <IF-STMT>: <TAB><TAB>  from django . db . models . fields import DateTimeField <TAB><TAB>  fields = [ DateTimeField ( ) ] <TAB>  else : <TAB><TAB>  needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB>  offset = len ( self . query . extra_select ) <TAB>  for rows in self . execute_sql ( MULTI ) : <TAB><TAB>  for row in rows : <TAB><TAB><TAB>  date = row [ offset ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  date = self . resolve_columns ( row , fields ) [ offset ] <TAB><TAB><TAB>  elif needs_string_cast : <TAB><TAB><TAB><TAB>  date = typecast_timestamp ( str ( date ) ) <TAB><TAB><TAB>  yield date ",if self . connection . ops . oracle :,"if isinstance(date, datetime):",False,32.686320025756146,92.09573887594846
4080,"def get_job_type ( self ) : <TAB>  if int ( self . job_runtime_conf . get ( "" dsl_version "" , 1 ) ) == 2 : <TAB><TAB>  job_type = ( <TAB><TAB><TAB>  self . job_runtime_conf [ "" job_parameters "" ] . get ( "" common "" , { } ) . get ( "" job_type "" ) <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB>  else : <TAB><TAB>  job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB>  return job_type ",if not job_type :,if job_type is None:,False,26.97800516230368,97.48076629130782
4081,"def validate_assessment_criteria ( self ) : <TAB>  if self . assessment_criteria : <TAB><TAB>  total_weightage = 0 <TAB><TAB>  for criteria in self . assessment_criteria : <TAB><TAB><TAB>  total_weightage + = criteria . weightage or 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( _ ( "" Total Weightage of all Assessment Criteria must be 100 % "" ) ) ",if total_weightage != 100 :,if total_weightage > 100:,False,27.764287681118628,96.70478123691463
4082,"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB>  result = [ ] <TAB>  if len ( notifications_list ) > 0 : <TAB><TAB>  for x in notifications_list : <TAB><TAB><TAB>  split_provider_id = x . split ( "" : "" )<TAB># email:id <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  _id = split_provider_id [ 1 ] <TAB><TAB><TAB><TAB>  cursor = self . get_by_id ( _id ) <TAB><TAB><TAB><TAB>  if cursor :<TAB># Append if exists <TAB><TAB><TAB><TAB><TAB>  result . append ( cursor ) <TAB>  return result ",if len ( split_provider_id ) == 2 :,if split_provider_id[0] == 'email':,False,36.88953770678588,91.47112446158336
4083,"def dump_predictions_to_database ( relation , predictions ) : <TAB>  judge = "" iepy-run on  {} "" . format ( datetime . now ( ) . strftime ( "" % Y- % m- %d % H: % M "" ) ) <TAB>  for evidence , relation_is_present in predictions . items ( ) : <TAB><TAB>  label = ( <TAB><TAB><TAB>  EvidenceLabel . YESRELATION <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else EvidenceLabel . NORELATION <TAB><TAB>  ) <TAB><TAB>  evidence . set_label ( relation , label , judge , labeled_by_machine = True ) ",if relation_is_present,if relation_is_present:,False,46.23320602317922,98.33035848825607
4084,"def __init__ ( self , * * kwargs ) : <TAB>  # We hard-code the `to` argument for ForeignKey.__init__ <TAB>  dfl = get_model_label ( self . default_model_class ) <TAB>  if "" to "" in kwargs . keys ( ) :<TAB># pragma: no cover <TAB><TAB>  old_to = get_model_label ( kwargs . pop ( "" to "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg = "" %s  can only be a ForeignKey to  %s ;  %s  passed "" % ( <TAB><TAB><TAB><TAB>  self . __class__ . __name__ , <TAB><TAB><TAB><TAB>  dfl , <TAB><TAB><TAB><TAB>  old_to , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  warnings . warn ( msg , SyntaxWarning ) <TAB>  kwargs [ "" to "" ] = dfl <TAB>  super ( ) . __init__ ( * * kwargs ) ",if old_to . lower ( ) != dfl . lower ( ) :,"if not isinstance(dfl, ForeignKey):",False,14.235821606938668,94.04121539827436
4085,"def reverse ( self ) : <TAB>  """"""Reverse *IN PLACE*."""""" <TAB>  li = self . leftindex <TAB>  lb = self . leftblock <TAB>  ri = self . rightindex <TAB>  rb = self . rightblock <TAB>  for i in range ( self . len >> 1 ) : <TAB><TAB>  lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB><TAB>  li + = 1 <TAB><TAB>  if li > = BLOCKLEN : <TAB><TAB><TAB>  lb = lb . rightlink <TAB><TAB><TAB>  li = 0 <TAB><TAB>  ri - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rb = rb . leftlink <TAB><TAB><TAB>  ri = BLOCKLEN - 1 ",if ri < 0 :,if ri >= BLOCKLEN:,False,26.94174286674006,97.72805519473513
4086,"def get_api ( user , url ) : <TAB>  global API_CACHE <TAB>  if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB><TAB>  API_CACHE_LOCK . acquire ( ) <TAB><TAB>  try : <TAB><TAB><TAB>  if API_CACHE is None : <TAB><TAB><TAB><TAB>  API_CACHE = { } <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB><TAB>  finally : <TAB><TAB><TAB>  API_CACHE_LOCK . release ( ) <TAB>  api = API_CACHE [ url ] <TAB>  api . set_user ( user ) <TAB>  return api ",if API_CACHE . get ( url ) is None :,if not API_CACHE.get(url) is None:,False,52.97138945853518,98.68929108287492
4087,"def invert_index ( cls , index , length ) : <TAB>  if np . isscalar ( index ) : <TAB><TAB>  return length - index <TAB>  elif isinstance ( index , slice ) : <TAB><TAB>  start , stop = index . start , index . stop <TAB><TAB>  new_start , new_stop = None , None <TAB><TAB>  if start is not None : <TAB><TAB><TAB>  new_stop = length - start <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_start = length - stop <TAB><TAB>  return slice ( new_start - 1 , new_stop - 1 ) <TAB>  elif isinstance ( index , Iterable ) : <TAB><TAB>  new_index = [ ] <TAB><TAB>  for ind in index : <TAB><TAB><TAB>  new_index . append ( length - ind ) <TAB>  return new_index ",if stop is not None :,if stop is not None:,False,52.60062367013356,100.00000000000004
4088,"def infer_returned_object ( pyfunction , args ) : <TAB>  """"""Infer the `PyObject` this `PyFunction` returns after calling"""""" <TAB>  object_info = pyfunction . pycore . object_info <TAB>  result = object_info . get_exact_returned ( pyfunction , args ) <TAB>  if result is not None : <TAB><TAB>  return result <TAB>  result = _infer_returned ( pyfunction , args ) <TAB>  if result is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  params = args . get_arguments ( pyfunction . get_param_names ( special_args = False ) ) <TAB><TAB><TAB>  object_info . function_called ( pyfunction , params , result ) <TAB><TAB>  return result <TAB>  return object_info . get_returned ( pyfunction , args ) ",if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,if result is not None:,False,37.97560728771025,91.94432541756603
4089,"def _check_imports ( lib ) : <TAB>  # Make sure no conflicting libraries have been imported. <TAB>  libs = [ "" PyQt4 "" , "" PyQt5 "" , "" PySide "" ] <TAB>  libs . remove ( lib ) <TAB>  for lib2 in libs : <TAB><TAB>  lib2 + = "" .QtCore "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  "" Refusing to import  %s  because  %s  is already  "" "" imported. "" % ( lib , lib2 ) <TAB><TAB><TAB>  ) ",if lib2 in sys . modules :,if lib in libs:,False,39.412843706740496,95.44444993781552
4090,"def _poll ( fds , timeout ) : <TAB>  if timeout is not None : <TAB><TAB>  timeout = int ( timeout * 1000 )<TAB># timeout is in milliseconds <TAB>  fd_map = { } <TAB>  pollster = select . poll ( ) <TAB>  for fd in fds : <TAB><TAB>  pollster . register ( fd , select . POLLIN ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fd_map [ fd . fileno ( ) ] = fd <TAB><TAB>  else : <TAB><TAB><TAB>  fd_map [ fd ] = fd <TAB>  ls = [ ] <TAB>  for fd , event in pollster . poll ( timeout ) : <TAB><TAB>  if event & select . POLLNVAL : <TAB><TAB><TAB>  raise ValueError ( "" invalid file descriptor  %i "" % fd ) <TAB><TAB>  ls . append ( fd_map [ fd ] ) <TAB>  return ls ","if hasattr ( fd , ""fileno"" ) :","if isinstance(fd, (int, long)):",False,28.011440128532282,93.9666862048235
4091,"def default ( cls , connection = None ) : <TAB>  """"""show the default connection, or make CONNECTION the default"""""" <TAB>  if connection is not None : <TAB><TAB>  target = cls . _get_config_filename ( connection ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if os . path . exists ( cls . _default_symlink ) : <TAB><TAB><TAB><TAB>  os . remove ( cls . _default_symlink ) <TAB><TAB><TAB>  os . symlink ( target , cls . _default_symlink ) <TAB><TAB>  else : <TAB><TAB><TAB>  cls . _no_config_file_error ( target ) <TAB>  if os . path . exists ( cls . _default_symlink ) : <TAB><TAB>  print ( "" Default connection is  "" + cls . _default_connection ( ) ) <TAB>  else : <TAB><TAB>  print ( "" There is no default connection set "" ) ",if os . path . exists ( target ) :,if target is not None:,False,41.01005150952367,96.02975887549884
4092,"def process ( self , fuzzresult ) : <TAB>  base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB>  for line in fuzzresult . history . content . splitlines ( ) : <TAB><TAB>  record = line . split ( "" / "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB>  # Directory <TAB><TAB><TAB>  if record [ 0 ] == "" D "" : <TAB><TAB><TAB><TAB>  self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB><TAB>  self . queue_url ( urljoin ( base_url , "" %s /CVS/Entries "" % ( record [ 1 ] ) ) ) ",if len ( record ) == 6 and record [ 1 ] :,if len(record) == 2:,False,47.679681280946255,96.33409120359194
4093,"def _GetCSVRow ( self , value ) : <TAB>  row = [ ] <TAB>  for type_info in value . __class__ . type_infos : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  row . extend ( self . _GetCSVRow ( value . Get ( type_info . name ) ) ) <TAB><TAB>  elif isinstance ( type_info , rdf_structs . ProtoBinary ) : <TAB><TAB><TAB>  row . append ( text . Asciify ( value . Get ( type_info . name ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  row . append ( str ( value . Get ( type_info . name ) ) ) <TAB>  return row ","if isinstance ( type_info , rdf_structs . ProtoEmbedded ) :","if isinstance(type_info, (rdf_structs.ProtoString, rdf_struct",False,19.5540174266813,95.16655859308689
4094,"def get_history ( self , state , dict_ , passive = PASSIVE_OFF ) : <TAB>  if self . key in dict_ : <TAB><TAB>  return History . from_scalar_attribute ( self , state , dict_ [ self . key ] ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  passive ^ = INIT_OK <TAB><TAB>  current = self . get ( state , dict_ , passive = passive ) <TAB><TAB>  if current is PASSIVE_NO_RESULT : <TAB><TAB><TAB>  return HISTORY_BLANK <TAB><TAB>  else : <TAB><TAB><TAB>  return History . from_scalar_attribute ( self , state , current ) ",if passive & INIT_OK :,if passive == PASSIVE_OFF:,False,35.30464758403887,96.32447059224957
4095,"def _iterate_self_and_parents ( self , upto = None ) : <TAB>  current = self <TAB>  result = ( ) <TAB>  while current : <TAB><TAB>  result + = ( current , ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  elif current . _parent is None : <TAB><TAB><TAB>  raise sa_exc . InvalidRequestError ( <TAB><TAB><TAB><TAB>  "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  current = current . _parent <TAB>  return result ",if current . _parent is upto :,if current is upto:,False,28.242888077954202,97.30657055799949
4096,"def get_by_uri ( self , uri : str ) - > bytes : <TAB>  userId , bucket , key = self . _parse_uri ( uri ) <TAB>  try : <TAB><TAB>  with db . session_scope ( ) as dbsession : <TAB><TAB><TAB>  result = db_archivedocument . get ( userId , bucket , key , session = dbsession ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return utils . ensure_bytes ( self . _decode ( result ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ObjectKeyNotFoundError ( userId , bucket , key , caused_by = None ) <TAB>  except Exception as err : <TAB><TAB>  logger . debug ( "" cannot get data: exception -  "" + str ( err ) ) <TAB><TAB>  raise err ",if result :,if result:,False,55.28516910429392,100.00000000000004
4097,"def app ( scope , receive , send ) : <TAB>  while True : <TAB><TAB>  message = await receive ( ) <TAB><TAB>  if message [ "" type "" ] == "" websocket.connect "" : <TAB><TAB><TAB>  await send ( { "" type "" : "" websocket.accept "" } ) <TAB><TAB>  elif message [ "" type "" ] == "" websocket.receive "" : <TAB><TAB><TAB>  pass <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break ","elif message [ ""type"" ] == ""websocket.disconnect"" :","if message['type'] == ""websocket.accept':",False,47.23264624230396,92.27347444158481
4098,"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB>  if tr < 1 : <TAB><TAB>  tr = 1 <TAB>  x = time . time ( ) + t <TAB>  y = [ ] <TAB>  r = "" "" <TAB>  if stderr : <TAB><TAB>  pr = p . recv_err <TAB>  else : <TAB><TAB>  pr = p . recv <TAB>  while time . time ( ) < x or r : <TAB><TAB>  r = pr ( ) <TAB><TAB>  if r is None : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y . append ( r ) <TAB><TAB>  else : <TAB><TAB><TAB>  time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB>  return "" "" . join ( y ) ",elif r :,if r.code == e:,False,28.12242149868912,96.31948677586001
4099,"def mouse_down ( self , event ) : <TAB>  if event . button == 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p = event . local <TAB><TAB><TAB>  if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB>  self . scroll_up ( ) <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB>  self . scroll_down ( ) <TAB><TAB><TAB><TAB>  return <TAB>  if event . button == 4 : <TAB><TAB>  self . scroll_up ( ) <TAB>  if event . button == 5 : <TAB><TAB>  self . scroll_down ( ) <TAB>  GridView . mouse_down ( self , event ) ",if self . scrolling :,if event.button == 2:,False,37.36679147521192,96.7358256348113
4100,"def copy_from ( self , other ) : <TAB>  if self is other : <TAB><TAB>  return<TAB># Myself! <TAB>  self . strictness = other . strictness<TAB># sets behaviors in bulk <TAB>  for name in self . all_behaviors : <TAB><TAB>  self . set_behavior ( name , other . get_behavior ( name ) ) <TAB>  for name in self . _plain_attrs : <TAB><TAB>  val = getattr ( other , name ) <TAB><TAB>  if isinstance ( val , set ) : <TAB><TAB><TAB>  val = val . copy ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = val . copy ( ) <TAB><TAB>  setattr ( self , name , val ) ","elif decimal and isinstance ( val , decimal . Decimal ) :","if isinstance(val, (int, long)):",False,14.163931245359478,90.35241157258203
4101,"def __array_wrap__ ( self , out_arr , context = None ) : <TAB>  if self . dim is None : <TAB><TAB>  return out_arr <TAB>  else : <TAB><TAB>  this = self [ : ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return Quantity . __array_wrap__ ( self [ : ] , out_arr , context = context ) <TAB><TAB>  else : <TAB><TAB><TAB>  return out_arr ","if isinstance ( this , Quantity ) :",if this is out_arr:,False,31.45619881992611,94.11643615126164
4102,"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB>  """"""Check if the function argument list has a dictionary as an arg."""""" <TAB>  if _IsArgumentToFunction ( token ) : <TAB><TAB>  while token : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  length = token . matching_bracket . total_length - token . total_length <TAB><TAB><TAB><TAB>  return length + self . stack [ - 2 ] . indent > self . column_limit <TAB><TAB><TAB>  if token . ClosesScope ( ) : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  if token . OpensScope ( ) : <TAB><TAB><TAB><TAB>  token = token . matching_bracket <TAB><TAB><TAB>  token = token . next_token <TAB>  return False ","if token . value == ""{"" :",if token.matching_bracket:,False,40.44416561647278,95.23961723664102
4103,"def save_all_changed_extensions ( self ) : <TAB>  """"""Save configuration changes to the user config file."""""" <TAB>  has_changes = False <TAB>  for ext_name in self . extensions : <TAB><TAB>  options = self . extensions [ ext_name ] <TAB><TAB>  for opt in options : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  has_changes = True <TAB>  if has_changes : <TAB><TAB>  self . ext_userCfg . Save ( ) ","if self . set_extension_value ( ext_name , opt ) :",if opt.HasField('user_config'):,False,52.87692978032034,90.31300479179492
4104,"def to_dict ( self ) : <TAB>  out = { } <TAB>  for key in ACTIVITY_KEYS : <TAB><TAB>  attr = getattr ( self , key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out [ key ] = str ( attr ) <TAB><TAB>  else : <TAB><TAB><TAB>  out [ key ] = attr <TAB>  if self . streak : <TAB><TAB>  out [ "" streak "" ] = self . streak <TAB>  return out ","if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :","if isinstance(attr, str):",False,24.00000933679385,91.76257311596754
4105,"def clean_publication_date ( cls , cleaned_input ) : <TAB>  for add_channel in cleaned_input . get ( "" add_channels "" , [ ] ) : <TAB><TAB>  is_published = add_channel . get ( "" is_published "" ) <TAB><TAB>  publication_date = add_channel . get ( "" publication_date "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  add_channel [ "" publication_date "" ] = datetime . date . today ( ) ",if is_published and not publication_date :,if is_published and publication_date == 0:,False,23.399207373469256,95.18537708170804
4106,"def _random_blur ( self , batch , sigma_max ) : <TAB>  for i in range ( len ( batch ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Random sigma <TAB><TAB><TAB>  sigma = random . uniform ( 0.0 , sigma_max ) <TAB><TAB><TAB>  batch [ i ] = scipy . ndimage . filters . gaussian_filter ( batch [ i ] , sigma ) <TAB>  return batch ",if bool ( random . getrandbits ( 1 ) ) :,if batch[i] == 0:,False,35.372544979774446,90.73924963424672
4107,"def conninfo_parse ( dsn ) : <TAB>  ret = { } <TAB>  length = len ( dsn ) <TAB>  i = 0 <TAB>  while i < length : <TAB><TAB>  if dsn [ i ] . isspace ( ) : <TAB><TAB><TAB>  i + = 1 <TAB><TAB><TAB>  continue <TAB><TAB>  param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB><TAB>  if not param_match : <TAB><TAB><TAB>  return <TAB><TAB>  param = param_match . group ( 1 ) <TAB><TAB>  i + = param_match . end ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  value , end = read_param_value ( dsn [ i : ] ) <TAB><TAB>  if value is None : <TAB><TAB><TAB>  return <TAB><TAB>  i + = end <TAB><TAB>  ret [ param ] = value <TAB>  return ret ",if i >= length :,if param == 'value':,False,21.47736172761281,97.83921988734235
4108,"def set_environment_vars ( env , source_env ) : <TAB>  """"""Copy allowed environment variables from |source_env|."""""" <TAB>  if not source_env : <TAB><TAB>  return <TAB>  for name , value in six . iteritems ( source_env ) : <TAB><TAB>  if is_forwarded_environment_variable ( name ) : <TAB><TAB><TAB>  # Avoid creating circular dependencies from importing environment by <TAB><TAB><TAB>  # using os.getenv. <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = file_host . rebase_to_worker_root ( value ) <TAB><TAB><TAB>  env [ name ] = value ","if os . getenv ( ""TRUSTED_HOST"" ) and should_rebase_environment_value ( name ) :",if not os.path.exists(os.getcwd() + '/' + name + '.,False,60.76649167882946,88.61478744028531
4109,"def toterminal ( self , tw ) : <TAB>  # the entries might have different styles <TAB>  last_style = None <TAB>  for i , entry in enumerate ( self . reprentries ) : <TAB><TAB>  if entry . style == "" long "" : <TAB><TAB><TAB>  tw . line ( "" "" ) <TAB><TAB>  entry . toterminal ( tw ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  next_entry = self . reprentries [ i + 1 ] <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  entry . style == "" long "" <TAB><TAB><TAB><TAB>  or entry . style == "" short "" <TAB><TAB><TAB><TAB>  and next_entry . style == "" long "" <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  tw . sep ( self . entrysep ) <TAB>  if self . extraline : <TAB><TAB>  tw . line ( self . extraline ) ",if i < len ( self . reprentries ) - 1 :,if i + 1 in self.repetitions:,False,29.372140450084068,96.19908567498153
4110,"def __init__ ( self , loc , tabs = None ) : <TAB>  if os . path . isdir ( loc ) : <TAB><TAB>  for item in os . listdir ( loc ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  path = os . path . join ( loc , item ) <TAB><TAB><TAB>  self . append ( CronTab ( user = False , tabfile = path ) ) <TAB>  elif os . path . isfile ( loc ) : <TAB><TAB>  self . append ( CronTab ( user = False , tabfile = loc ) ) ","if item [ 0 ] == ""."" :",if not item.startswith('_'):,False,42.60424233964341,93.55232180236588
4111,"def import_data ( self , fname ) : <TAB>  """"""Import data in current namespace"""""" <TAB>  if self . count ( ) : <TAB><TAB>  nsb = self . currentWidget ( ) <TAB><TAB>  nsb . refresh_table ( ) <TAB><TAB>  nsb . import_data ( fname ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . dockwidget . setVisible ( True ) <TAB><TAB><TAB>  self . dockwidget . raise_ ( ) ",if self . dockwidget and not self . ismaximized :,if self.dockwidget:,False,23.187177921492932,94.64799197289697
4112,"def get_menu_items ( node ) : <TAB>  aList = [ ] <TAB>  for child in node . children : <TAB><TAB>  for tag in ( "" @menu "" , "" @item "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB><TAB><TAB><TAB>  if tag == "" @menu "" : <TAB><TAB><TAB><TAB><TAB>  aList . append ( ( "" %s %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  b = g . splitLines ( "" "" . join ( child . b ) ) <TAB><TAB><TAB><TAB><TAB>  aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB><TAB><TAB><TAB>  break <TAB>  return aList ",if child . h . startswith ( tag ) :,if tag.startswith('@menu'):,False,49.21270755849539,97.3893292855963
4113,"def __init__ ( self , * args , * * kw ) : <TAB>  if len ( args ) > 1 : <TAB><TAB>  raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB>  if args : <TAB><TAB>  if hasattr ( args [ 0 ] , "" iteritems "" ) : <TAB><TAB><TAB>  items = list ( args [ 0 ] . iteritems ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  items = list ( args [ 0 ] . items ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  items = list ( args [ 0 ] ) <TAB><TAB>  self . _items = items <TAB>  else : <TAB><TAB>  self . _items = [ ] <TAB>  if kw : <TAB><TAB>  self . _items . extend ( kw . items ( ) ) ","elif hasattr ( args [ 0 ] , ""items"" ) :",if len(args) == 1:,False,30.639822142673623,94.26374656398573
4114,"def open ( self ) - > "" KeyValueDb "" : <TAB>  """"""Create a new data base or open existing one"""""" <TAB>  if os . path . exists ( self . _name ) : <TAB><TAB>  if not os . path . isfile ( self . _name ) : <TAB><TAB><TAB>  raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # ignore empty files <TAB><TAB><TAB>  return self <TAB><TAB>  with open ( self . _name , "" rb "" ) as _in :<TAB># binary mode <TAB><TAB><TAB>  self . set_records ( pickle . load ( _in ) ) <TAB>  else : <TAB><TAB>  # make sure path exists <TAB><TAB>  mkpath ( os . path . dirname ( self . _name ) ) <TAB><TAB>  self . commit ( ) <TAB>  return self ",if os . path . getsize ( self . _name ) == 0 :,if not os.path.exists(self._name):,False,51.64204673934297,95.36008134755583
4115,"def sortModules ( self ) : <TAB>  super ( NeuronDecomposableNetwork , self ) . sortModules ( ) <TAB>  self . _constructParameterInfo ( ) <TAB>  # contains a list of lists of indices <TAB>  self . decompositionIndices = { } <TAB>  for neuron in self . _neuronIterator ( ) : <TAB><TAB>  self . decompositionIndices [ neuron ] = [ ] <TAB>  for w in range ( self . paramdim ) : <TAB><TAB>  inneuron , outneuron = self . paramInfo [ w ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . decompositionIndices [ inneuron ] . append ( w ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . decompositionIndices [ outneuron ] . append ( w ) ",if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules :,if inneuron in self.decompositionIndices:,False,57.5472318842215,92.93838756067355
4116,"def visit_Options ( self , node : qlast . Options ) - > None : <TAB>  for i , opt in enumerate ( node . options . values ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . write ( "" "" ) <TAB><TAB>  self . write ( opt . name ) <TAB><TAB>  if not isinstance ( opt , qlast . Flag ) : <TAB><TAB><TAB>  self . write ( f "" { opt . val } "" ) ",if i > 0 :,if i == 0:,False,20.73976151315761,96.95490931243769
4117,"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB>  if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB><TAB>  return None <TAB>  while True : <TAB><TAB>  if possible_child_hash == item_hash : <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB><TAB>  possible_child_hash = self . items [ possible_child_hash ] . previous_hash ",if possible_child_hash not in self . items :,if possible_child_hash not in self.items:,False,52.398372161602666,100.00000000000004
4118,"def __call__ ( self , text , * * kargs ) : <TAB>  words = jieba . tokenize ( text , mode = "" search "" ) <TAB>  token = Token ( ) <TAB>  for ( w , start_pos , stop_pos ) in words : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  token . original = token . text = w <TAB><TAB>  token . pos = start_pos <TAB><TAB>  token . startchar = start_pos <TAB><TAB>  token . endchar = stop_pos <TAB><TAB>  yield token ",if not accepted_chars . match ( w ) and len ( w ) <= 1 :,if w == text:,False,19.315691412392106,88.06575713321529
4119,"def test_analysis_jobs_cypher_syntax ( neo4j_session ) : <TAB>  parameters = { <TAB><TAB>  "" AWS_ID "" : None , <TAB><TAB>  "" UPDATE_TAG "" : None , <TAB><TAB>  "" OKTA_ORG_ID "" : None , <TAB>  } <TAB>  for job_name in contents ( "" cartography.data.jobs.analysis "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  cartography . util . run_analysis_job ( job_name , neo4j_session , parameters ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  pytest . fail ( <TAB><TAB><TAB><TAB>  f "" run_analysis_job failed for analysis job  ' { job_name } '  with exception:  { e } "" <TAB><TAB><TAB>  ) ","if not job_name . endswith ( "".json"" ) :","if not job_name in (""cartography.data.jobs.analysis"", ""cy",False,23.329437272095735,93.96272507694859
4120,"def _interleave_dataset_results_and_tensors ( dataset_results , flat_run_tensors ) : <TAB>  flattened_results = [ ] <TAB>  for idx in range ( len ( dataset_results ) + len ( flat_run_tensors ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  flattened_results . append ( dataset_results [ idx ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  flattened_results . append ( flat_run_tensors . pop ( 0 ) ) <TAB>  return flattened_results ",if dataset_results . get ( idx ) :,if flat_run_tensors[idx] == 0:,False,48.93935787146842,91.25055461907696
4121,"def test_k_is_stochastic_parameter ( self ) : <TAB>  # k as stochastic parameter <TAB>  aug = iaa . MedianBlur ( k = iap . Choice ( [ 3 , 5 ] ) ) <TAB>  seen = [ False , False ] <TAB>  for i in sm . xrange ( 100 ) : <TAB><TAB>  observed = aug . augment_image ( self . base_img ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  seen [ 0 ] + = True <TAB><TAB>  elif np . array_equal ( observed , self . blur5x5 ) : <TAB><TAB><TAB>  seen [ 1 ] + = True <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( "" Unexpected result in MedianBlur@2 "" ) <TAB><TAB>  if all ( seen ) : <TAB><TAB><TAB>  break <TAB>  assert np . all ( seen ) ","if np . array_equal ( observed , self . blur3x3 ) :","if np.array_equal(observed, self.blur5x5):",False,26.69537421452539,98.85183195908576
4122,"def pickPath ( self , color ) : <TAB>  self . path [ color ] = ( ) <TAB>  currentPos = self . starts [ color ] <TAB>  while True : <TAB><TAB>  minDist = None <TAB><TAB>  minGuide = None <TAB><TAB>  for guide in self . guides [ color ] : <TAB><TAB><TAB>  guideDist = dist ( currentPos , guide ) <TAB><TAB><TAB>  if minDist == None or guideDist < minDist : <TAB><TAB><TAB><TAB>  minDist = guideDist <TAB><TAB><TAB><TAB>  minGuide = guide <TAB><TAB>  if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB><TAB>  currentPos = minGuide <TAB><TAB>  self . guides [ color ] . remove ( minGuide ) ",if minGuide == None :,if minGuide == None:,False,55.49149013641487,100.00000000000004
4123,"def UpdateRepository ( self ) : <TAB>  if hasattr ( self , "" commit_update "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not path . isdir ( "" .git/ "" ) : <TAB><TAB><TAB><TAB>  self . gitZipRepo ( ) <TAB><TAB><TAB>  call ( [ "" git "" , "" reset "" , "" --hard "" , "" origin/ {} "" . format ( self . getBranch ) ] ) <TAB><TAB><TAB>  self . ProcessCall_ ( [ "" git "" , "" pull "" , "" origin "" , self . getBranch ] ) <TAB><TAB><TAB>  self . ProcessCall_ ( [ "" pip "" , "" install "" , "" -r "" , "" requirements.txt "" ] ) ","if self . commit_update [ ""Updates"" ] != [ ] :",if self.getBranch() == self.getBranch():,False,22.984640507032278,92.85115570813407
4124,"def callback ( result = Cr . NS_OK , message = None , success = None ) : <TAB>  if success is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  success = Ci . koIAsyncCallback . RESULT_SUCCESSFUL <TAB><TAB>  else : <TAB><TAB><TAB>  success = Ci . koIAsyncCallback . RESULT_ERROR <TAB>  data = Namespace ( result = result , message = message , _com_interfaces_ = [ Ci . koIErrorInfo ] ) <TAB>  self . _invoke_activate_callbacks ( success , data ) ",if Cr . NS_SUCCEEDED ( result ) :,if result == Cr.NS_OK:,False,47.59745032013446,94.7482453824795
4125,"def get_location ( device ) : <TAB>  location = [ ] <TAB>  node = device <TAB>  while node : <TAB><TAB>  position = node . get_position ( ) or "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  position = ""  [ %s ] "" % position <TAB><TAB>  location . append ( node . name + position ) <TAB><TAB>  node = node . parent <TAB>  return ""  /  "" . join ( reversed ( location ) ) ",if position :,"if position not in ('', '', 'none'):",False,24.798958069656766,91.41415322997888
4126,"def load_checkpoint ( path , model , optimizer , reset_optimizer ) : <TAB>  global global_step <TAB>  global global_epoch <TAB>  print ( "" Load checkpoint from:  {} "" . format ( path ) ) <TAB>  checkpoint = _load ( path ) <TAB>  model . load_state_dict ( checkpoint [ "" state_dict "" ] ) <TAB>  if not reset_optimizer : <TAB><TAB>  optimizer_state = checkpoint [ "" optimizer "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Load optimizer state from  {} "" . format ( path ) ) <TAB><TAB><TAB>  optimizer . load_state_dict ( checkpoint [ "" optimizer "" ] ) <TAB>  global_step = checkpoint [ "" global_step "" ] <TAB>  global_epoch = checkpoint [ "" global_epoch "" ] <TAB>  return model ",if optimizer_state is not None :,if optimizer_state == 'state':,False,48.04569357827847,97.75076862810373
4127,"def run_command ( self , command : str , data : Dict [ str , object ] ) - > Dict [ str , object ] : <TAB>  """"""Run a specific command from the registry."""""" <TAB>  key = "" cmd_ "" + command <TAB>  method = getattr ( self . __class__ , key , None ) <TAB>  if method is None : <TAB><TAB>  return { "" error "" : "" Unrecognized command  ' %s ' "" % command } <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Only the above commands use some error formatting. <TAB><TAB><TAB>  del data [ "" is_tty "" ] <TAB><TAB><TAB>  del data [ "" terminal_width "" ] <TAB><TAB>  return method ( self , * * data ) ","if command not in { ""check"" , ""recheck"" , ""run"" } :",if method is None:,False,35.80411566824833,90.03250980004196
4128,"def call_init ( self , node , instance ) : <TAB>  # Call __init__ on each binding. <TAB>  for b in instance . bindings : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  self . _initialized_instances . add ( b . data ) <TAB><TAB>  node = self . _call_init_on_binding ( node , b ) <TAB>  return node ",if b . data in self . _initialized_instances :,"if not isinstance(b, self.binding_class):",False,30.637783214515707,89.75964236265983
4129,"def get_request_headers ( ) - > Dict : <TAB>  url = urlparse ( uri ) <TAB>  candidates = [ <TAB><TAB>  "" %s :// %s "" % ( url . scheme , url . netloc ) , <TAB><TAB>  "" %s :// %s / "" % ( url . scheme , url . netloc ) , <TAB><TAB>  uri , <TAB><TAB>  "" * "" , <TAB>  ] <TAB>  for u in candidates : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  headers = dict ( DEFAULT_REQUEST_HEADERS ) <TAB><TAB><TAB>  headers . update ( self . config . linkcheck_request_headers [ u ] ) <TAB><TAB><TAB>  return headers <TAB>  return { } ",if u in self . config . linkcheck_request_headers :,if u in self.config.linkcheck_request_headers:,False,49.99660168408639,100.00000000000004
4130,"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB>  if not self . video_format : <TAB><TAB>  return <TAB>  while True : <TAB><TAB>  # We skip video packets which are not video frames <TAB><TAB>  # This happens in mkv files for the first few frames. <TAB><TAB>  video_packet = self . _get_video_packet ( ) <TAB><TAB>  if video_packet . image == 0 : <TAB><TAB><TAB>  self . _decode_video_packet ( video_packet ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  if _debug : <TAB><TAB>  print ( "" Returning "" , video_packet ) <TAB>  return video_packet . image ",if video_packet . image is not None or not skip_empty_frame :,if skip_empty_frame:,False,63.43186967218606,94.14289304274645
4131,"def convert_path ( ctx , tpath ) : <TAB>  for points , code in tpath . iter_segments ( ) : <TAB><TAB>  if code == Path . MOVETO : <TAB><TAB><TAB>  ctx . move_to ( * points ) <TAB><TAB>  elif code == Path . LINETO : <TAB><TAB><TAB>  ctx . line_to ( * points ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ctx . curve_to ( <TAB><TAB><TAB><TAB>  points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB>  ) <TAB><TAB>  elif code == Path . CURVE4 : <TAB><TAB><TAB>  ctx . curve_to ( * points ) <TAB><TAB>  elif code == Path . CLOSEPOLY : <TAB><TAB><TAB>  ctx . close_path ( ) ",elif code == Path . CURVE3 :,if code == Path.CURVE3:,False,26.166192438313058,98.91180759779758
4132,"def __init__ ( <TAB>  self , layout , value = None , string = None , * , dtype : np . dtype = np . float64  ) - > None : <TAB>  """"""Constructor."""""" <TAB>  self . layout = layout <TAB>  if value is None : <TAB><TAB>  if string is None : <TAB><TAB><TAB>  self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . value = layout . parse_multivector ( string ) . value <TAB>  else : <TAB><TAB>  self . value = np . array ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB><TAB><TAB>  ) ","if self . value . shape != ( self . layout . gaDims , ) :","if not isinstance(value, (list, tuple)):",False,52.409748997306906,93.58727412945925
4133,"def to_dict ( self ) : <TAB>  contexts_ = { } <TAB>  for k , data in self . contexts . items ( ) : <TAB><TAB>  data_ = data . copy ( ) <TAB><TAB>  if "" context "" in data_ : <TAB><TAB><TAB>  del data_ [ "" context "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del data_ [ "" loaded "" ] <TAB><TAB>  contexts_ [ k ] = data_ <TAB>  return dict ( contexts = contexts_ ) ","if ""loaded"" in data_ :","if ""loaded"" in data_:",False,51.15298150504521,100.00000000000004
4134,"def include_module ( module ) : <TAB>  if not include_these : <TAB><TAB>  return True <TAB>  result = False <TAB>  for check in include_these : <TAB><TAB>  if "" /* "" in check : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result = True <TAB><TAB>  else : <TAB><TAB><TAB>  if ( os . getcwd ( ) + "" / "" + check + "" .py "" ) == module : <TAB><TAB><TAB><TAB>  result = True <TAB>  if result : <TAB><TAB>  print_status ( "" Including module:  "" + module ) <TAB>  return result ",if check [ : - 1 ] in module :,"if os.path.isdir(check + ""/.py""):",False,46.364498589660165,91.39868162700597
4135,"def extract_from ( msg_body , content_type = "" text/plain "" ) : <TAB>  try : <TAB><TAB>  if content_type == "" text/plain "" : <TAB><TAB><TAB>  return extract_from_plain ( msg_body ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return extract_from_html ( msg_body ) <TAB>  except Exception : <TAB><TAB>  log . exception ( "" ERROR extracting message "" ) <TAB>  return msg_body ","elif content_type == ""text/html"" :","if content_type == ""text/html':",False,43.29725694118356,95.30442940411879
4136,"def test_list ( self ) : <TAB>  self . _create_locations ( ) <TAB>  response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB>  self . assertEqual ( response . status_code , 200 ) <TAB>  self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB>  for feature in response . data [ "" features "" ] : <TAB><TAB>  self . assertIn ( "" bbox "" , feature ) <TAB><TAB>  fid = feature [ "" id "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB><TAB>  elif fid == 2 : <TAB><TAB><TAB>  self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB>  BoxedLocation . objects . all ( ) . delete ( ) ",if fid == 1 :,if fid == 1:,False,51.07865892517553,100.00000000000004
4137,"def overrideCommand ( self , commandName , func ) : <TAB>  # Override entries in c.k.masterBindingsDict <TAB>  k = self <TAB>  d = k . masterBindingsDict <TAB>  for key in d : <TAB><TAB>  d2 = d . get ( key ) <TAB><TAB>  for key2 in d2 : <TAB><TAB><TAB>  bi = d2 . get ( key2 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  bi . func = func <TAB><TAB><TAB><TAB>  d2 [ key2 ] = bi ",if bi . commandName == commandName :,"if bi and (not isinstance(bi, Command) and (not isinstance(bi, Command",False,27.144590307998328,87.44699819494932
4138,"def _lookup ( components , specs , provided , name , i , l ) : <TAB>  if i < l : <TAB><TAB>  for spec in specs [ i ] . __sro__ : <TAB><TAB><TAB>  comps = components . get ( spec ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB><TAB><TAB><TAB>  if r is not None : <TAB><TAB><TAB><TAB><TAB>  return r <TAB>  else : <TAB><TAB>  for iface in provided : <TAB><TAB><TAB>  comps = components . get ( iface ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  r = comps . get ( name ) <TAB><TAB><TAB><TAB>  if r is not None : <TAB><TAB><TAB><TAB><TAB>  return r <TAB>  return None ",if comps :,if comps is not None:,False,24.191700538817564,96.35508916065109
4139,"def to_representation ( self , value ) : <TAB>  old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB>  request = self . context . get ( "" request "" ) <TAB>  show_old_format = ( <TAB><TAB>  request <TAB><TAB>  and is_deprecated ( request . version , self . min_version ) <TAB><TAB>  and request . method == "" GET "" <TAB>  ) <TAB>  if show_old_format : <TAB><TAB>  social = value . copy ( ) <TAB><TAB>  for key in old_social_string_fields : <TAB><TAB><TAB>  if social . get ( key ) : <TAB><TAB><TAB><TAB>  social [ key ] = value [ key ] [ 0 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  social [ key ] = "" "" <TAB><TAB>  value = social <TAB>  return super ( SocialField , self ) . to_representation ( value ) ",elif social . get ( key ) == [ ] :,if not social.get(key):,False,25.992326651107227,96.81089314177561
4140,"def process_ref_attribute ( self , node , array_type = None ) : <TAB>  ref = qname_attr ( node , "" ref "" ) <TAB>  if ref : <TAB><TAB>  ref = self . _create_qname ( ref ) <TAB><TAB>  # Some wsdl's reference to xs:schema, we ignore that for now. It <TAB><TAB>  # might be better in the future to process the actual schema file <TAB><TAB>  # so that it is handled correctly <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  return xsd_elements . RefAttribute ( <TAB><TAB><TAB>  node . tag , ref , self . schema , array_type = array_type <TAB><TAB>  ) ","if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :",if ref is None:,False,68.24223056147949,89.02490820266529
4141,"def unescape ( text ) : <TAB>  """"""Removes '\\' escaping from 'text'."""""" <TAB>  rv = "" "" <TAB>  i = 0 <TAB>  while i < len ( text ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  rv + = text [ i + 1 ] <TAB><TAB><TAB>  i + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  rv + = text [ i ] <TAB><TAB>  i + = 1 <TAB>  return rv ","if i + 1 < len ( text ) and text [ i ] == ""\\"" :",if text[i + 1] == '\\':,False,47.708479644727674,89.03850367801716
4142,"def wait_child_process ( signum , frame ) : <TAB>  try : <TAB><TAB>  while True : <TAB><TAB><TAB>  child_pid , status = os . waitpid ( - 1 , os . WNOHANG ) <TAB><TAB><TAB>  if child_pid == 0 : <TAB><TAB><TAB><TAB>  stat_logger . info ( "" no child process was immediately available "" ) <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  exitcode = status >> 8 <TAB><TAB><TAB>  stat_logger . info ( <TAB><TAB><TAB><TAB>  "" child process  %s  exit with exitcode  %s "" , child_pid , exitcode <TAB><TAB><TAB>  ) <TAB>  except OSError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stat_logger . warning ( <TAB><TAB><TAB><TAB>  "" current process has no existing unwaited-for child processes. "" <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ",if e . errno == errno . ECHILD :,if e.errno == errno.EWOULDBLOCK:,False,61.41085880755662,97.74134977017312
4143,"def translate_from_sortname ( name , sortname ) : <TAB>  """"""'Translate' the artist name by reversing the sortname."""""" <TAB>  for c in name : <TAB><TAB>  ctg = unicodedata . category ( c ) <TAB><TAB>  if ctg [ 0 ] == "" L "" and unicodedata . name ( c ) . find ( "" LATIN "" ) == - 1 : <TAB><TAB><TAB>  for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  parts = sortname . split ( separator ) <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  parts = [ sortname ] <TAB><TAB><TAB><TAB>  separator = "" "" <TAB><TAB><TAB>  return separator . join ( map ( _reverse_sortname , parts ) ) <TAB>  return name ",if separator in sortname :,if sortname.endswith(separator):,False,54.18938939639574,95.89431185691879
4144,"def python_value ( self , value ) : <TAB>  if value : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pp = lambda x : x . time ( ) <TAB><TAB><TAB>  return format_date_time ( value , self . formats , pp ) <TAB><TAB>  elif isinstance ( value , datetime . datetime ) : <TAB><TAB><TAB>  return value . time ( ) <TAB>  if value is not None and isinstance ( value , datetime . timedelta ) : <TAB><TAB>  return ( datetime . datetime . min + value ) . time ( ) <TAB>  return value ","if isinstance ( value , basestring ) :","if isinstance(value, datetime.datetime):",False,45.50963560179463,96.94008326135823
4145,"def __init__ ( self , fileobj , info ) : <TAB>  pages = [ ] <TAB>  complete = False <TAB>  while not complete : <TAB><TAB>  page = OggPage ( fileobj ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pages . append ( page ) <TAB><TAB><TAB>  complete = page . complete or ( len ( page . packets ) > 1 ) <TAB>  data = OggPage . to_packets ( pages ) [ 0 ] [ 7 : ] <TAB>  super ( OggTheoraCommentDict , self ) . __init__ ( data , framing = False ) <TAB>  self . _padding = len ( data ) - self . _size ",if page . serial == info . serial :,if page.is_active():,False,22.693775796417608,95.29361098183325
4146,"def configure ( self ) : <TAB>  # hack to configure 'from_' and 'to' and avoid exception <TAB>  if "" from_ "" in self . wmeta . properties : <TAB><TAB>  from_ = float ( self . wmeta . properties [ "" from_ "" ] ) <TAB><TAB>  to = float ( self . wmeta . properties . get ( "" to "" , 0 ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  to = from_ + 1 <TAB><TAB><TAB>  self . wmeta . properties [ "" to "" ] = str ( to ) <TAB>  super ( TKSpinbox , self ) . configure ( ) ",if from_ > to :,if from_ <= to <= 0:,False,35.29771718662471,95.16988314267846
4147,"def get_error_diagnostics ( self ) : <TAB>  diagnostics = [ ] <TAB>  if self . stdout is not None : <TAB><TAB>  with open ( self . stdout . name ) as fds : <TAB><TAB><TAB>  contents = fds . read ( ) . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  diagnostics . append ( "" ab STDOUT: \n "" + contents ) <TAB>  if self . stderr is not None : <TAB><TAB>  with open ( self . stderr . name ) as fds : <TAB><TAB><TAB>  contents = fds . read ( ) . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  diagnostics . append ( "" ab STDERR: \n "" + contents ) <TAB>  return diagnostics ",if contents . strip ( ) :,if contents:,False,21.45159605176929,93.53404694110633
4148,"def set_environment_vars ( env , source_env ) : <TAB>  """"""Copy allowed environment variables from |source_env|."""""" <TAB>  if not source_env : <TAB><TAB>  return <TAB>  for name , value in six . iteritems ( source_env ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Avoid creating circular dependencies from importing environment by <TAB><TAB><TAB>  # using os.getenv. <TAB><TAB><TAB>  if os . getenv ( "" TRUSTED_HOST "" ) and should_rebase_environment_value ( name ) : <TAB><TAB><TAB><TAB>  value = file_host . rebase_to_worker_root ( value ) <TAB><TAB><TAB>  env [ name ] = value ",if is_forwarded_environment_variable ( name ) :,if name not in env:,False,48.83804181224165,94.09359590442267
4149,"def update_content ( self , more_content : StringList ) - > None : <TAB>  if isinstance ( self . object , TypeVar ) : <TAB><TAB>  attrs = [ repr ( self . object . __name__ ) ] <TAB><TAB>  for constraint in self . object . __constraints__ : <TAB><TAB><TAB>  attrs . append ( stringify_typehint ( constraint ) ) <TAB><TAB>  if self . object . __covariant__ : <TAB><TAB><TAB>  attrs . append ( "" covariant=True "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  attrs . append ( "" contravariant=True "" ) <TAB><TAB>  more_content . append ( _ ( "" alias of TypeVar( %s ) "" ) % "" ,  "" . join ( attrs ) , "" "" ) <TAB><TAB>  more_content . append ( "" "" , "" "" ) <TAB>  super ( ) . update_content ( more_content ) ",if self . object . __contravariant__ :,if self.object.__contravariant__:,False,49.97827232660952,100.00000000000004
4150,"def after ( self , event , state ) : <TAB>  group = event . group <TAB>  for plugin in self . get_plugins ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  metrics . incr ( "" notifications.sent "" , instance = plugin . slug ) <TAB><TAB>  yield self . future ( plugin . rule_notify ) ","if not safe_execute ( plugin . should_notify , group = group , event = event ) :",if plugin.slug == group:,False,18.64215832945681,81.76047194653908
4151,"def distinct ( expr , * on ) : <TAB>  fields = frozenset ( expr . fields ) <TAB>  _on = [ ] <TAB>  append = _on . append <TAB>  for n in on : <TAB><TAB>  if isinstance ( n , Field ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  n = n . _name <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB>  if not isinstance ( n , _strtypes ) : <TAB><TAB><TAB>  raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB><TAB>  elif n not in fields : <TAB><TAB><TAB>  raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB>  append ( n ) <TAB>  return Distinct ( expr , tuple ( _on ) ) ",if n . _child . isidentical ( expr ) :,"if isinstance(n, _Name):",False,31.747813676031768,96.63492774930809
4152,"def build_filter ( arg ) : <TAB>  filt = { } <TAB>  if arg is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise UserError ( "" Arguments to --filter should be in form KEY=VAL "" ) <TAB><TAB>  key , val = arg . split ( "" = "" , 1 ) <TAB><TAB>  filt [ key ] = val <TAB>  return filt ","if ""="" not in arg :",if arg.startswith('='):,False,22.689260273204674,91.00324432071945
4153,"def pickline ( file , key , casefold = 1 ) : <TAB>  try : <TAB><TAB>  f = open ( file , "" r "" ) <TAB>  except IOError : <TAB><TAB>  return None <TAB>  pat = re . escape ( key ) + "" : "" <TAB>  prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB>  while 1 : <TAB><TAB>  line = f . readline ( ) <TAB><TAB>  if not line : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = line [ len ( key ) + 1 : ] <TAB><TAB><TAB>  while 1 : <TAB><TAB><TAB><TAB>  line = f . readline ( ) <TAB><TAB><TAB><TAB>  if not line or not line [ 0 ] . isspace ( ) : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  text = text + line <TAB><TAB><TAB>  return text . strip ( ) <TAB>  return None ",if prog . match ( line ) :,if line.startswith(key):,False,45.61795768307127,97.79371821054721
4154,"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB>  index = index or INDEX <TAB>  if not category : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  category = "" preprint "" <TAB><TAB>  elif node . is_registration : <TAB><TAB><TAB>  category = "" registration "" <TAB><TAB>  else : <TAB><TAB><TAB>  category = node . project_or_component <TAB>  client ( ) . delete ( <TAB><TAB>  index = index , <TAB><TAB>  doc_type = category , <TAB><TAB>  id = elastic_document_id , <TAB><TAB>  refresh = True , <TAB><TAB>  ignore = [ 404 ] , <TAB>  ) ","if isinstance ( node , Preprint ) :",if node.preprint:,False,49.628710512003714,96.12526005847293
4155,"def update ( self , preds , labels ) : <TAB>  if not _is_numpy_ ( labels ) : <TAB><TAB>  raise ValueError ( "" The  ' labels '  must be a numpy ndarray. "" ) <TAB>  if not _is_numpy_ ( preds ) : <TAB><TAB>  raise ValueError ( "" The  ' predictions '  must be a numpy ndarray. "" ) <TAB>  for i , lbl in enumerate ( labels ) : <TAB><TAB>  value = preds [ i , 1 ] <TAB><TAB>  bin_idx = int ( value * self . _num_thresholds ) <TAB><TAB>  assert bin_idx < = self . _num_thresholds <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _stat_pos [ bin_idx ] + = 1.0 <TAB><TAB>  else : <TAB><TAB><TAB>  self . _stat_neg [ bin_idx ] + = 1.0 ",if lbl :,if label == 0:,False,26.421006461300877,93.15398593961905
4156,"def checkStatusClient ( self ) : <TAB>  if str ( self . comboxBoxIPAddress . currentText ( ) ) != "" "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . btnEnable . setEnabled ( False ) <TAB><TAB><TAB>  self . btncancel . setEnabled ( True ) <TAB><TAB><TAB>  return None <TAB><TAB>  self . btnEnable . setEnabled ( True ) <TAB><TAB>  self . btncancel . setEnabled ( False ) ","if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :",if self.isDisabled():,False,23.77992842398119,84.33785876868238
4157,"def colorizeDiffs ( sheet , col , row , cellval ) : <TAB>  if not row or not col : <TAB><TAB>  return None <TAB>  vcolidx = sheet . visibleCols . index ( col ) <TAB>  rowidx = sheet . rows . index ( row ) <TAB>  if vcolidx < len ( othersheet . visibleCols ) and rowidx < len ( othersheet . rows ) : <TAB><TAB>  otherval = othersheet . visibleCols [ vcolidx ] . getDisplayValue ( <TAB><TAB><TAB>  othersheet . rows [ rowidx ] <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" color_diff "" <TAB>  else : <TAB><TAB>  return "" color_diff_add "" ",if cellval . display != otherval :,if otherval == cellval:,False,26.37257390515762,95.8558368201518
4158,"def identwaf ( self , findall = False ) : <TAB>  detected = list ( ) <TAB>  try : <TAB><TAB>  self . attackres = self . performCheck ( self . centralAttack ) <TAB>  except RequestBlocked : <TAB><TAB>  return detected <TAB>  for wafvendor in self . checklist : <TAB><TAB>  self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  detected . append ( wafvendor ) <TAB><TAB><TAB>  if not findall : <TAB><TAB><TAB><TAB>  break <TAB>  self . knowledge [ "" wafname "" ] = detected <TAB>  return detected ",if self . wafdetections [ wafvendor ] ( self ) :,if wafvendor in detected:,False,43.911110219988316,93.56847942810637
4159,"def get_repository_metadata_by_repository_id_changeset_revision ( <TAB>  app , id , changeset_revision , metadata_only = False  ) : <TAB>  """"""Get a specified metadata record for a specified repository in the tool shed."""""" <TAB>  if metadata_only : <TAB><TAB>  repository_metadata = get_repository_metadata_by_changeset_revision ( <TAB><TAB><TAB>  app , id , changeset_revision <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return repository_metadata . metadata <TAB><TAB>  return None <TAB>  return get_repository_metadata_by_changeset_revision ( app , id , changeset_revision ) ",if repository_metadata and repository_metadata . metadata :,if repository_metadata:,False,40.06739043209012,96.07559997191372
4160,"def getmultiline ( self ) : <TAB>  line = self . getline ( ) <TAB>  if line [ 3 : 4 ] == "" - "" : <TAB><TAB>  code = line [ : 3 ] <TAB><TAB>  while 1 : <TAB><TAB><TAB>  nextline = self . getline ( ) <TAB><TAB><TAB>  line = line + ( "" \n "" + nextline ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB>  return line ","if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :",if code == line:,False,21.660505344421257,84.63455816006095
4161,"def _validate_reports ( value , * args , * * kwargs ) : <TAB>  from osf . models import OSFUser <TAB>  for key , val in value . items ( ) : <TAB><TAB>  if not OSFUser . load ( key ) : <TAB><TAB><TAB>  raise ValidationValueError ( "" Keys must be user IDs "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationTypeError ( "" Values must be dictionaries "" ) <TAB><TAB>  if ( <TAB><TAB><TAB>  "" category "" not in val <TAB><TAB><TAB>  or "" text "" not in val <TAB><TAB><TAB>  or "" date "" not in val <TAB><TAB><TAB>  or "" retracted "" not in val <TAB><TAB>  ) : <TAB><TAB><TAB>  raise ValidationValueError ( <TAB><TAB><TAB><TAB>  ( "" Values must include `date`, `category`,  "" , "" `text`, `retracted` keys "" ) <TAB><TAB><TAB>  ) ","if not isinstance ( val , dict ) :","if not isinstance(val, dict):",False,52.665979024966234,100.00000000000004
4162,"def deselectItem ( self , item ) : <TAB>  if self . isSelected ( item ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  listItem = self . _getListItem ( item ) <TAB><TAB><TAB>  selections = self . getSelectedItems ( ) <TAB><TAB><TAB>  selections . remove ( self . loadHandler . getSelection ( listItem ) ) <TAB><TAB><TAB>  self . setSelections ( selections ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . deselectAll ( ) ",if self . multiSelect :,if self.isSelected(item):,False,49.33949070528022,95.56930541639593
4163,"def __init__ ( self , * * kwargs ) : <TAB>  if self . name is None : <TAB><TAB>  raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB>  self . option_values = { } <TAB>  for key , val in kwargs . items ( ) : <TAB><TAB>  if not key in self . options : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . option_values [ key ] = val <TAB>  # set up defaults <TAB>  for name , ( description , default ) in self . options . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . option_values [ name ] = default ",if not name in self . option_values :,if description is not None:,False,50.27743242123183,95.69732897402106
4164,"def setup_smart_indent ( self , view , lang ) : <TAB>  # Configure a ""per-view"" instance <TAB>  if type ( view ) == gedit . View : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( view , "" smart_indent_instance "" , SmartIndent ( ) ) <TAB><TAB><TAB>  handler_id = view . connect ( <TAB><TAB><TAB><TAB>  "" key-press-event "" , view . smart_indent_instance . key_press_handler <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . handler_ids . append ( ( handler_id , view ) ) <TAB><TAB>  view . smart_indent_instance . set_language ( lang , view ) ","if getattr ( view , ""smart_indent_instance"" , False ) == False :","if not hasattr(view, 'smart_indent_instance'):",False,26.632787230219567,91.89545006761749
4165,"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB>  count = 0 <TAB>  letters = "" "" <TAB>  strings = [ ] <TAB>  for char in word : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  letters + = char <TAB><TAB><TAB>  count + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  if count > threshold : <TAB><TAB><TAB><TAB>  strings . append ( letters ) <TAB><TAB><TAB>  letters = "" "" <TAB><TAB><TAB>  count = 0 <TAB>  if count > threshold : <TAB><TAB>  strings . append ( letters ) <TAB>  return strings ",if char in char_set :,if char in char_set:,False,44.79041283752439,100.00000000000004
4166,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  self . set_logout_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 0:,False,51.452429171598,100.00000000000004
4167,def __create_table ( self ) : <TAB>  for i in range ( 256 ) : <TAB><TAB>  crcreg = i <TAB><TAB>  for j in range ( 8 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  crcreg = self . __CRCPOLYNOMIAL ^ ( crcreg >> 1 ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  crcreg >> = 1 <TAB><TAB>  self . __crctable [ i ] = crcreg ,if ( crcreg & 1 ) != 0 :,if crcreg & 1:,False,19.20960790388808,93.85739652213277
4168,"def destroy ( self ) : <TAB>  """"""Flush all entries and empty cache"""""" <TAB>  # Note: this method is currently also used for dropping the cache <TAB>  for i in range ( len ( self . cached_rows ) ) : <TAB><TAB>  id_ = self . cached_rows [ i ] <TAB><TAB>  self . cached_rows [ i ] = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  inode = self . attrs [ id_ ] <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  # We may have deleted that inode <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  del self . attrs [ id_ ] <TAB><TAB><TAB><TAB>  self . setattr ( inode ) <TAB>  assert len ( self . attrs ) == 0 ",if id_ is not None :,if id_ in self.attrs:,False,63.41268645136247,97.69049470794715
4169,"def set_config ( self ) : <TAB>  """"""Set configuration options for QTextEdit."""""" <TAB>  c = self . c <TAB>  w = self . widget <TAB>  w . setWordWrapMode ( QtGui . QTextOption . NoWrap ) <TAB>  if 0 :<TAB># This only works when there is no style sheet. <TAB><TAB>  n = c . config . getInt ( "" qt-rich-text-zoom-in "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  w . zoomIn ( n ) <TAB><TAB><TAB>  w . updateMicroFocus ( ) <TAB>  # tab stop in pixels - no config for this (yet) <TAB>  w . setTabStopWidth ( 24 ) ","if n not in ( None , 0 ) :",if n > 0:,False,62.7725602729328,93.70619695427723
4170,"def mouseDragEvent ( self , ev ) : <TAB>  if self . movable and ev . button ( ) == QtCore . Qt . LeftButton : <TAB><TAB>  if ev . isStart ( ) : <TAB><TAB><TAB>  self . moving = True <TAB><TAB><TAB>  self . cursorOffset = self . pos ( ) - self . mapToParent ( ev . buttonDownPos ( ) ) <TAB><TAB><TAB>  self . startPosition = self . pos ( ) <TAB><TAB>  ev . accept ( ) <TAB><TAB>  if not self . moving : <TAB><TAB><TAB>  return <TAB><TAB>  self . setPos ( self . cursorOffset + self . mapToParent ( ev . pos ( ) ) ) <TAB><TAB>  self . sigDragged . emit ( self ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . moving = False <TAB><TAB><TAB>  self . sigPositionChangeFinished . emit ( self ) ",if ev . isFinish ( ) :,if self.movable:,False,40.71169311485811,97.12255390364633
4171,"def reparentChildren ( self , newParent ) : <TAB>  if newParent . childNodes : <TAB><TAB>  newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB>  else : <TAB><TAB>  if not newParent . _element . text : <TAB><TAB><TAB>  newParent . _element . text = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newParent . _element . text + = self . _element . text <TAB>  self . _element . text = "" "" <TAB>  base . Node . reparentChildren ( self , newParent ) ",if self . _element . text is not None :,if newParent._element.text:,False,29.657926726859735,93.28815402842586
4172,"def _no_sp_or_bp ( self , bl ) : <TAB>  for s in bl . vex . statements : <TAB><TAB>  for e in chain ( [ s ] , s . expressions ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB><TAB><TAB><TAB>  if reg == "" ebp "" or reg == "" esp "" : <TAB><TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  elif e . tag == "" Ist_Put "" : <TAB><TAB><TAB><TAB>  reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB><TAB><TAB><TAB>  if reg == "" ebp "" or reg == "" esp "" : <TAB><TAB><TAB><TAB><TAB>  return False <TAB>  return True ","if e . tag == ""Iex_Get"" :","if e.tag == ""Ist_Get':",False,17.039249330806804,97.84972303636427
4173,"def _get_import_chain ( self , * , until = None ) : <TAB>  stack = inspect . stack ( ) [ 2 : ] <TAB>  try : <TAB><TAB>  for frameinfo in stack : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  data = dedent ( "" "" . join ( frameinfo . code_context ) ) <TAB><TAB><TAB><TAB>  if data . strip ( ) == until : <TAB><TAB><TAB><TAB><TAB>  raise StopIteration <TAB><TAB><TAB><TAB>  yield frameinfo . filename , frameinfo . lineno , data . strip ( ) <TAB><TAB><TAB><TAB>  del data <TAB><TAB><TAB>  finally : <TAB><TAB><TAB><TAB>  del frameinfo <TAB>  finally : <TAB><TAB>  del stack ",if not frameinfo . code_context :,if frameinfo.code_context is None:,False,44.948334018133515,97.89453779159842
4174,"def stream_docker_log ( log_stream ) : <TAB>  async for line in log_stream : <TAB><TAB>  if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB><TAB><TAB>  logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB><TAB>  elif "" status "" in line : <TAB><TAB><TAB>  logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . error ( line [ "" error "" ] . strip ( ) ) <TAB><TAB><TAB>  raise DockerBuildError ","elif ""error"" in line :","if ""error"" in line:",False,53.483414177126456,98.37380598312615
4175,"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB>  for dep in curr_node [ "" deps "" ] : <TAB><TAB>  if dep == goal_node_index : <TAB><TAB><TAB>  return [ curr_node [ "" address "" ] ] <TAB>  for dep in curr_node [ "" deps "" ] : <TAB><TAB>  path = self . get_cycle_path ( <TAB><TAB><TAB>  self . get_by_address ( dep ) , goal_node_index <TAB><TAB>  )<TAB># self.nodelist[dep], goal_node_index) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path . insert ( 0 , curr_node [ "" address "" ] ) <TAB><TAB><TAB>  return path <TAB>  return [ ] ",if len ( path ) > 0 :,if path:,False,49.890453889073946,95.76439904173
4176,"def prompt ( default = None ) : <TAB>  editor = "" nano "" <TAB>  with tempfile . NamedTemporaryFile ( mode = "" r+ "" ) as tmpfile : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tmpfile . write ( default ) <TAB><TAB><TAB>  tmpfile . flush ( ) <TAB><TAB>  child_pid = os . fork ( ) <TAB><TAB>  is_child = child_pid == 0 <TAB><TAB>  if is_child : <TAB><TAB><TAB>  os . execvp ( editor , [ editor , tmpfile . name ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  os . waitpid ( child_pid , 0 ) <TAB><TAB><TAB>  tmpfile . seek ( 0 ) <TAB><TAB><TAB>  return tmpfile . read ( ) . strip ( ) ",if default :,if default is not None:,False,50.739307614678154,97.73946896962188
4177,"def _get_annotated_template ( self , template ) : <TAB>  changed = False <TAB>  if template . get ( "" version "" , "" 0.12.0 "" ) > = "" 0.13.0 "" : <TAB><TAB>  using_js = self . spider . _filter_js_urls ( template [ "" url "" ] ) <TAB><TAB>  body = "" rendered_body "" if using_js else "" original_body "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  template [ "" body "" ] = body <TAB><TAB><TAB>  changed = True <TAB>  if changed or not template . get ( "" annotated "" ) : <TAB><TAB>  _build_sample ( template ) <TAB>  return template ","if template . get ( ""body"" ) != body :",if body:,False,31.913034181701917,93.20936009469733
4178,"def collect ( self , paths ) : <TAB>  for path in paths or ( ) : <TAB><TAB>  relpath = os . path . relpath ( path , self . _artifact_root ) <TAB><TAB>  dst = os . path . join ( self . _directory , relpath ) <TAB><TAB>  safe_mkdir ( os . path . dirname ( dst ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  shutil . copytree ( path , dst ) <TAB><TAB>  else : <TAB><TAB><TAB>  shutil . copy ( path , dst ) <TAB><TAB>  self . _relpaths . add ( relpath ) ",if os . path . isdir ( path ) :,if os.path.isdir(dst):,False,30.32691151671297,98.36315750772182
4179,"def dependencies ( context = None ) : <TAB>  """"""Return all dependencies detected by knowit."""""" <TAB>  deps = OrderedDict ( [ ] ) <TAB>  try : <TAB><TAB>  initialize ( context ) <TAB><TAB>  for name , provider_cls in _provider_map . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  deps [ name ] = available_providers [ name ] . version <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  deps [ name ] = { } <TAB>  except Exception : <TAB><TAB>  pass <TAB>  return deps ",if name in available_providers :,if provider_cls is Provider:,False,51.55946295949153,96.04535135654089
4180,"def _getaddrinfo ( self , host_bytes , port , family , socktype , proto , flags ) : <TAB>  while True : <TAB><TAB>  ares = self . cares <TAB><TAB>  try : <TAB><TAB><TAB>  return self . __getaddrinfo ( host_bytes , port , family , socktype , proto , flags ) <TAB><TAB>  except gaierror : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ",if ares is self . cares :,if ares.error:,False,47.60531658669187,95.31827626449643
4181,"def write_entries ( cmd , basename , filename ) : <TAB>  ep = cmd . distribution . entry_points <TAB>  if isinstance ( ep , basestring ) or ep is None : <TAB><TAB>  data = ep <TAB>  elif ep is not None : <TAB><TAB>  data = [ ] <TAB><TAB>  for section , contents in ep . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  contents = EntryPoint . parse_group ( section , contents ) <TAB><TAB><TAB><TAB>  contents = "" \n "" . join ( map ( str , contents . values ( ) ) ) <TAB><TAB><TAB>  data . append ( "" [ %s ] \n %s \n \n "" % ( section , contents ) ) <TAB><TAB>  data = "" "" . join ( data ) <TAB>  cmd . write_or_delete_file ( "" entry points "" , filename , data , True ) ","if not isinstance ( contents , basestring ) :",if section.startswith('.'):,False,28.203257480574486,96.41544318864842
4182,"def _highlight_do ( self ) : <TAB>  new_hl_text = self . highlight_text . text ( ) <TAB>  if new_hl_text != self . hl_text : <TAB><TAB>  self . hl_text = new_hl_text <TAB><TAB>  if self . hl is not None : <TAB><TAB><TAB>  self . hl . setDocument ( None ) <TAB><TAB><TAB>  self . hl = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . hl = Highlighter ( self . hl_text , parent = self . doc ) <TAB><TAB>  self . clear_highlight_button . setEnabled ( bool ( self . hl ) ) ",if self . hl_text :,if self.highlight_text is not None:,False,35.571624056129515,96.02670123010144
4183,"def traverse ( node , functions = [ ] ) : <TAB>  if hasattr ( node , "" grad_fn "" ) : <TAB><TAB>  node = node . grad_fn <TAB>  if hasattr ( node , "" variable "" ) : <TAB><TAB>  node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  node . functions = list ( functions ) <TAB><TAB><TAB>  del functions [ : ] <TAB>  if hasattr ( node , "" next_functions "" ) : <TAB><TAB>  functions . append ( type ( node ) . __name__ ) <TAB><TAB>  for f in node . next_functions : <TAB><TAB><TAB>  if f [ 0 ] : <TAB><TAB><TAB><TAB>  functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB><TAB><TAB><TAB>  traverse ( f [ 0 ] , functions ) <TAB>  if hasattr ( node , "" saved_tensors "" ) : <TAB><TAB>  for t in node . saved_tensors : <TAB><TAB><TAB>  traverse ( t ) ",if node :,"if isinstance(node, (Node, Node)):",False,23.687755700783303,96.04214098396668
4184,"def compress ( self , data_list ) : <TAB>  if data_list : <TAB><TAB>  page_id = data_list [ 1 ] <TAB><TAB>  if page_id in EMPTY_VALUES : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB><TAB>  return Page . objects . get ( pk = page_id ) <TAB>  return None ",if not self . required :,if page_id == 0:,False,21.073792481849587,94.19617807898726
4185,"def test_field_attr_existence ( self ) : <TAB>  for name , item in ast . __dict__ . items ( ) : <TAB><TAB>  if self . _is_ast_node ( name , item ) : <TAB><TAB><TAB>  if name == "" Index "" : <TAB><TAB><TAB><TAB>  # Index(value) just returns value now. <TAB><TAB><TAB><TAB>  # The argument is required. <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  x = item ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertEqual ( type ( x . _fields ) , tuple ) ","if isinstance ( x , ast . AST ) :","if isinstance(x, (types.Field, types.Field)):",False,56.00352830823302,94.49556992878934
4186,"def handle_starttag ( self , tag , attrs ) : <TAB>  if tag == "" base "" : <TAB><TAB>  self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB>  if self . scan_tag ( tag ) : <TAB><TAB>  for attr , value in attrs : <TAB><TAB><TAB>  if self . scan_attr ( attr ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  value = strip_html5_whitespace ( value ) <TAB><TAB><TAB><TAB>  url = self . process_attr ( value ) <TAB><TAB><TAB><TAB>  link = Link ( url = url ) <TAB><TAB><TAB><TAB>  self . links . append ( link ) <TAB><TAB><TAB><TAB>  self . current_link = link ",if self . strip :,if self.strip_html5_whitespace(value):,False,49.38139508292638,96.12341136212748
4187,"def _initialize_asset_map ( cls ) : <TAB>  # Generating a list of acceptable asset files reduces the possibility of <TAB>  # path attacks. <TAB>  cls . _asset_name_to_path = { } <TAB>  assets = os . listdir ( ASSETS_PATH ) <TAB>  for asset in assets : <TAB><TAB>  path = os . path . join ( ASSETS_PATH , asset ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cls . _asset_name_to_path [ os . path . basename ( path ) ] = path ",if os . path . isfile ( path ) :,if os.path.exists(path):,False,38.51452533356613,98.14444805292847
4188,"def dataReceived ( self , data ) : <TAB>  self . buf + = data <TAB>  if self . _paused : <TAB><TAB>  log . startLogging ( sys . stderr ) <TAB><TAB>  log . msg ( "" dataReceived while transport paused! "" ) <TAB><TAB>  self . transport . loseConnection ( ) <TAB>  else : <TAB><TAB>  self . transport . write ( data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . transport . loseConnection ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . pause ( ) ","if self . buf . endswith ( b""\n0\n"" ) :",if self._paused:,False,21.36256428327793,90.74391751184334
4189,"def test_case_sensitive ( self ) : <TAB>  with support . EnvironmentVarGuard ( ) as env : <TAB><TAB>  env . unset ( "" PYTHONCASEOK "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB><TAB>  loader = self . find_module ( ) <TAB><TAB>  self . assertIsNone ( loader ) ","if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :",if os.name == 'nt':,False,53.336944407265705,86.70422069925675
4190,"def manifest ( self ) : <TAB>  """"""The current manifest dictionary."""""" <TAB>  if self . reload : <TAB><TAB>  if not self . exists ( self . manifest_path ) : <TAB><TAB><TAB>  return { } <TAB><TAB>  mtime = self . getmtime ( self . manifest_path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _manifest = self . get_manifest ( ) <TAB><TAB><TAB>  self . _mtime = mtime <TAB>  return self . _manifest ",if self . _mtime is None or mtime > self . _mtime :,if mtime > self._mtime:,False,24.577667536264602,93.86995203654666
4191,"def test_named_parameters_and_constraints ( self ) : <TAB>  likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB>  model = ExactGPModel ( None , None , likelihood ) <TAB>  for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB><TAB>  elif name == "" mean_module.constant "" : <TAB><TAB><TAB>  self . assertIsNone ( constraint ) <TAB><TAB>  elif name == "" covar_module.raw_outputscale "" : <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB><TAB>  elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB><TAB><TAB>  self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) ","if name == ""likelihood.noise_covar.raw_noise"" :","if name == ""mean_module.constant':",False,16.036206092306372,95.03840475573861
4192,"def process_plugin_result ( name , result ) : <TAB>  if result : <TAB><TAB>  try : <TAB><TAB><TAB>  jsonify ( test = result ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  logger . exception ( <TAB><TAB><TAB><TAB>  "" Error while jsonifying settings from plugin  {} , please contact the plugin author about this "" . format ( <TAB><TAB><TAB><TAB><TAB>  name <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  raise <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  del result [ "" __enabled "" ] <TAB><TAB><TAB>  data [ name ] = result ","if ""__enabled"" in result :",if '__enabled' in result:,False,62.604202410063905,97.19453006287995
4193,"def benchmarking ( net , ctx , num_iteration , datashape = 300 , batch_size = 64 ) : <TAB>  input_shape = ( batch_size , 3 ) + ( datashape , datashape ) <TAB>  data = mx . random . uniform ( - 1.0 , 1.0 , shape = input_shape , ctx = ctx , dtype = "" float32 "" ) <TAB>  dryrun = 5 <TAB>  for i in range ( dryrun + num_iteration ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tic = time . time ( ) <TAB><TAB>  ids , scores , bboxes = net ( data ) <TAB><TAB>  ids . asnumpy ( ) <TAB><TAB>  scores . asnumpy ( ) <TAB><TAB>  bboxes . asnumpy ( ) <TAB>  toc = time . time ( ) - tic <TAB>  return toc ",if i == dryrun :,if data.is_valid():,False,31.55803094785866,93.68585553476218
4194,"def merge_weekdays ( base_wd , icu_wd ) : <TAB>  result = [ ] <TAB>  for left , right in zip ( base_wd , icu_wd ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( left ) <TAB><TAB><TAB>  continue <TAB><TAB>  left = set ( left . split ( "" | "" ) ) <TAB><TAB>  right = set ( right . split ( "" | "" ) ) <TAB><TAB>  result . append ( "" | "" . join ( left | right ) ) <TAB>  return result ",if left == right :,if left == right:,False,51.15962215903366,100.00000000000004
4195,"def create_key ( self , request ) : <TAB>  if self . _ignored_parameters : <TAB><TAB>  url , body = self . _remove_ignored_parameters ( request ) <TAB>  else : <TAB><TAB>  url , body = request . url , request . body <TAB>  key = hashlib . sha256 ( ) <TAB>  key . update ( _to_bytes ( request . method . upper ( ) ) ) <TAB>  key . update ( _to_bytes ( url ) ) <TAB>  if request . body : <TAB><TAB>  key . update ( _to_bytes ( body ) ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for name , value in sorted ( request . headers . items ( ) ) : <TAB><TAB><TAB><TAB>  key . update ( _to_bytes ( name ) ) <TAB><TAB><TAB><TAB>  key . update ( _to_bytes ( value ) ) <TAB>  return key . hexdigest ( ) ",if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,"if hasattr(request, 'headers'):",False,22.869379514788722,92.13133186723654
4196,"def test_invalid_mountinfo ( self ) : <TAB>  line = ( <TAB><TAB>  "" 20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root "" <TAB><TAB>  "" rw,errors=remount-ro,data=ordered "" <TAB>  ) <TAB>  elements = line . split ( ) <TAB>  for i in range ( len ( elements ) + 1 ) : <TAB><TAB>  lines = [ "" "" . join ( elements [ 0 : i ] ) ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  expected = None <TAB><TAB>  else : <TAB><TAB><TAB>  expected = ( "" /dev/mapper/vg0-root "" , "" ext4 "" , "" / "" ) <TAB><TAB>  self . assertEqual ( expected , util . parse_mount_info ( "" / "" , lines ) ) ",if i < 10 :,if len(lines) == 0:,False,34.29257171754575,95.83871543156701
4197,"def nested_filter ( self , items , mask ) : <TAB>  keep_current = self . current_mask ( mask ) <TAB>  keep_nested_lookup = self . nested_masks ( mask ) <TAB>  for k , v in items : <TAB><TAB>  keep_nested = keep_nested_lookup . get ( k ) <TAB><TAB>  if k in keep_current : <TAB><TAB><TAB>  if keep_nested is not None : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield k , v ","if isinstance ( v , dict ) :",if keep_nested:,False,22.07065274581818,95.97287840566104
4198,"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB>  if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB><TAB>  return node_pos <TAB>  for t_idx , tree in enumerate ( trees ) : <TAB><TAB>  cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB><TAB>  # reach leaf <TAB><TAB>  if cur_node_idx == - 1 : <TAB><TAB><TAB>  continue <TAB><TAB>  rs , reach_leaf = HeteroSecureBoostingTreeGuest . traverse_a_tree ( <TAB><TAB><TAB>  tree , sample , cur_node_idx <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  node_pos [ "" reach_leaf_node "" ] [ t_idx ] = True <TAB><TAB>  node_pos [ "" node_pos "" ] [ t_idx ] = rs <TAB>  return node_pos ",if reach_leaf :,if reach_leaf:,False,50.92558964957363,98.54137705599041
4199,"def _pop_waiting_trial_id ( self ) - > Optional [ int ] : <TAB>  # TODO(c-bata): Reduce database query counts for extracting waiting trials. <TAB>  for trial in self . _storage . get_all_trials ( self . _study_id , deepcopy = False ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if not self . _storage . set_trial_state ( trial . _trial_id , TrialState . RUNNING ) : <TAB><TAB><TAB>  continue <TAB><TAB>  _logger . debug ( "" Trial  {}  popped from the trial queue. "" . format ( trial . number ) ) <TAB><TAB>  return trial . _trial_id <TAB>  return None ",if trial . state != TrialState . WAITING :,if not trial._trial_id:,False,20.940564530088125,95.11520965579675
4200,"def get_step_best ( self , step_models ) : <TAB>  best_score = None <TAB>  best_model = "" "" <TAB>  for model in step_models : <TAB><TAB>  model_info = self . models_trained [ model ] <TAB><TAB>  score = model_info . get_score ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if best_score is None or score < best_score : <TAB><TAB><TAB>  best_score = score <TAB><TAB><TAB>  best_model = model <TAB>  LOGGER . info ( f "" step  { self . n_step } , best model  { best_model } "" ) <TAB>  return best_model ",if score is None :,if score is None:,False,30.948288191827267,100.00000000000004
4201,"def iter_filters ( filters , block_end = False ) : <TAB>  queue = deque ( filters ) <TAB>  while queue : <TAB><TAB>  f = queue . popleft ( ) <TAB><TAB>  if f is not None and f . type in ( "" or "" , "" and "" , "" not "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  queue . appendleft ( None ) <TAB><TAB><TAB>  for gf in f . filters : <TAB><TAB><TAB><TAB>  queue . appendleft ( gf ) <TAB><TAB>  yield f ",if block_end :,if block_end:,False,56.96885743684561,100.00000000000004
4202,"def _buffer_decode ( self , input , errors , final ) : <TAB>  if self . decoder is None : <TAB><TAB>  ( output , consumed , byteorder ) = codecs . utf_16_ex_decode ( input , errors , 0 , final ) <TAB><TAB>  if byteorder == - 1 : <TAB><TAB><TAB>  self . decoder = codecs . utf_16_le_decode <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . decoder = codecs . utf_16_be_decode <TAB><TAB>  elif consumed > = 2 : <TAB><TAB><TAB>  raise UnicodeError ( "" UTF-16 stream does not start with BOM "" ) <TAB><TAB>  return ( output , consumed ) <TAB>  return self . decoder ( input , self . errors , final ) ",elif byteorder == 1 :,if byteorder == -1:,False,24.79054699344843,97.30416255207304
4203,"def _load_db ( self ) : <TAB>  try : <TAB><TAB>  with open ( self . db ) as db : <TAB><TAB><TAB>  content = db . read ( 8 ) <TAB><TAB><TAB>  db . seek ( 0 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data = StringIO ( ) <TAB><TAB><TAB><TAB>  if self . encryptor : <TAB><TAB><TAB><TAB><TAB>  self . encryptor . decrypt ( db , data ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  raise EncryptionError ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  return json . loads ( data . getvalue ( ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return json . load ( db ) <TAB>  except : <TAB><TAB>  return { "" creds "" : [ ] } ","if content == ( ""Salted__"" ) :",if content == '':,False,48.9159741146819,97.10124523947994
4204,"def _getbytes ( self , start , l = 1 ) : <TAB>  out = [ ] <TAB>  for ad in range ( l ) : <TAB><TAB>  offset = ad + start + self . base_address <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise IOError ( "" not enough bytes "" ) <TAB><TAB>  out . append ( int_to_byte ( Byte ( offset ) ) ) <TAB>  return b "" "" . join ( out ) ",if not is_mapped ( offset ) :,"if offset >= len(b""0x""):",False,28.75086506979281,91.38552168544369
4205,"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB>  function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB>  # First, get list of accounts <TAB>  accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB>  # Second, call tasks to enumerate all the roles across all accounts <TAB>  for account_id in accounts_d . keys ( ) : <TAB><TAB>  if config . get ( "" environment "" ) == "" prod "" : <TAB><TAB><TAB>  cache_sqs_queues_for_account . delay ( account_id ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  cache_sqs_queues_for_account . delay ( account_id ) <TAB>  stats . count ( f "" { function } .success "" ) <TAB>  return True ","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :","if config.get('environment') == ""prod':",False,46.29712604491989,92.25924094248286
4206,"def insertLine ( self , refnum , linenum , line ) : <TAB>  i = - 1 <TAB>  for i , row in enumerate ( self . rows ) : <TAB><TAB>  if row [ 0 ] == linenum : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  row [ refnum + 1 ] = line <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  # else keep looking <TAB><TAB>  elif row [ 0 ] > linenum : <TAB><TAB><TAB>  break <TAB>  self . rows . insert ( i , self . newRow ( linenum , refnum , line ) ) ",if row [ refnum + 1 ] is None :,if i == -1:,False,44.91278649499105,92.82240101450695
4207,"def __setattr__ ( self , name , val ) : <TAB>  if self . __dict__ . get ( name , "" hamster_graphics_no_value_really "" ) == val : <TAB><TAB>  return <TAB>  Sprite . __setattr__ ( self , name , val ) <TAB>  if name == "" image_data "" : <TAB><TAB>  self . _surface = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __dict__ [ "" width "" ] = self . image_data . get_width ( ) <TAB><TAB><TAB>  self . __dict__ [ "" height "" ] = self . image_data . get_height ( ) ",if self . image_data :,"if name == ""image_data_really':",False,24.21497343839408,94.88372250070134
4208,"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB>  if signature : <TAB><TAB>  # replace Mock function names <TAB><TAB>  signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB><TAB>  signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB><TAB>  # add scope name to layer signatures: <TAB><TAB>  if hasattr ( obj , "" use_scope "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB><TAB><TAB>  elif obj . use_scope is None : <TAB><TAB><TAB><TAB>  signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB>  # signature: arg list <TAB>  return signature , return_annotation ",if obj . use_scope :,if obj.use_scope is None:,False,54.47978402061715,98.61634356620775
4209,"def L_op ( self , inputs , outputs , gout ) : <TAB>  ( x , ) = inputs <TAB>  ( gz , ) = gout <TAB>  if x . type in complex_types : <TAB><TAB>  raise NotImplementedError ( ) <TAB>  if outputs [ 0 ] . type in discrete_types : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ x . zeros_like ( dtype = theano . config . floatX ) ] <TAB><TAB>  else : <TAB><TAB><TAB>  return [ x . zeros_like ( ) ] <TAB>  return ( gz * ( 1 - sqr ( tanh ( x ) ) ) , ) ",if x . type in discrete_types :,"if outputs[0].type in (theano.config.floatX, theano.",False,20.997528641139827,90.19284464282514
4210,"def confirm_on_console ( topic , msg ) : <TAB>  done = False <TAB>  print ( topic ) <TAB>  while not done : <TAB><TAB>  output = raw_input ( msg + "" :[y/n] "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB><TAB>  if output . lower ( ) == "" n "" : <TAB><TAB><TAB>  return False ","if output . lower ( ) == ""y"" :","if output.lower() == ""y/n':",False,18.817055987149292,96.8732807714302
4211,"def replace_documentation_for_matching_shape ( self , event_name , section , * * kwargs ) : <TAB>  if self . _shape_name == section . context . get ( "" shape "" ) : <TAB><TAB>  self . _replace_documentation ( event_name , section ) <TAB>  for section_name in section . available_sections : <TAB><TAB>  sub_section = section . get_section ( section_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _replace_documentation ( event_name , sub_section ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . replace_documentation_for_matching_shape ( event_name , sub_section ) ","if self . _shape_name == sub_section . context . get ( ""shape"" ) :",if sub_section.context.get('shape') == self._shape_name:,False,22.203824491387266,94.89077983581933
4212,"def confirm_on_console ( topic , msg ) : <TAB>  done = False <TAB>  print ( topic ) <TAB>  while not done : <TAB><TAB>  output = raw_input ( msg + "" :[y/n] "" ) <TAB><TAB>  if output . lower ( ) == "" y "" : <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False ","if output . lower ( ) == ""n"" :","if output.lower() == ""y':",False,18.296222653815956,96.85297446311758
4213,"def __getitem__ ( self , index ) : <TAB>  if self . _check ( ) : <TAB><TAB>  if isinstance ( index , int ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise IndexError ( index ) <TAB><TAB><TAB>  if self . features [ index ] is None : <TAB><TAB><TAB><TAB>  feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB><TAB><TAB><TAB>  if feature : <TAB><TAB><TAB><TAB><TAB>  ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB><TAB><TAB><TAB><TAB>  self . features [ index ] = FEATURE [ feature ] <TAB><TAB><TAB>  return self . features [ index ] <TAB><TAB>  elif isinstance ( index , slice ) : <TAB><TAB><TAB>  indices = index . indices ( len ( self . features ) ) <TAB><TAB><TAB>  return [ self . __getitem__ ( i ) for i in range ( * indices ) ] ",if index < 0 or index >= len ( self . features ) :,if index < 0:,False,50.07367313208194,95.91223792300516
4214,"def _parse_locator ( self , locator ) : <TAB>  prefix = None <TAB>  criteria = locator <TAB>  if not locator . startswith ( "" // "" ) : <TAB><TAB>  locator_parts = locator . partition ( "" = "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  prefix = locator_parts [ 0 ] <TAB><TAB><TAB>  criteria = locator_parts [ 2 ] . strip ( ) <TAB>  return ( prefix , criteria ) ",if len ( locator_parts [ 1 ] ) > 0 :,if len(locator_parts) == 3:,False,24.721043518932355,93.96975503999448
4215,"def trakt_episode_data_generate ( self , data ) : <TAB>  # Find how many unique season we have <TAB>  uniqueSeasons = [ ] <TAB>  for season , episode in data : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  uniqueSeasons . append ( season ) <TAB>  # build the query <TAB>  seasonsList = [ ] <TAB>  for searchedSeason in uniqueSeasons : <TAB><TAB>  episodesList = [ ] <TAB><TAB>  for season , episode in data : <TAB><TAB><TAB>  if season == searchedSeason : <TAB><TAB><TAB><TAB>  episodesList . append ( { "" number "" : episode } ) <TAB><TAB>  seasonsList . append ( { "" number "" : searchedSeason , "" episodes "" : episodesList } ) <TAB>  post_data = { "" seasons "" : seasonsList } <TAB>  return post_data ",if season not in uniqueSeasons :,if season not in uniqueSeasons:,False,31.69203930203517,100.00000000000004
4216,"def __init__ ( self , data , n_bins ) : <TAB>  bin_width = span / n_bins <TAB>  bins = [ 0 ] * n_bins <TAB>  for x in data : <TAB><TAB>  b = int ( mpfloor ( ( x - minimum ) / bin_width ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  b = 0 <TAB><TAB>  elif b > = n_bins : <TAB><TAB><TAB>  b = n_bins - 1 <TAB><TAB>  bins [ b ] + = 1 <TAB>  self . bins = bins <TAB>  self . bin_width = bin_width ",if b < 0 :,if b < 0:,False,39.13851804448496,100.00000000000004
4217,"def infer_context ( typ , context = "" http://schema.org "" ) : <TAB>  parsed_context = urlparse ( typ ) <TAB>  if parsed_context . netloc : <TAB><TAB>  base = "" "" . join ( [ parsed_context . scheme , "" :// "" , parsed_context . netloc ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  context = urljoin ( base , parsed_context . path ) <TAB><TAB><TAB>  typ = parsed_context . fragment . strip ( "" / "" ) <TAB><TAB>  elif parsed_context . path : <TAB><TAB><TAB>  context = base <TAB><TAB><TAB>  typ = parsed_context . path . strip ( "" / "" ) <TAB>  return context , typ ",if parsed_context . path and parsed_context . fragment :,if parsed_context.fragment:,False,27.064103272753055,96.8256677143911
4218,"def parse ( self , items ) : <TAB>  for index , item in enumerate ( items ) : <TAB><TAB>  keys = self . build_key ( item ) <TAB><TAB>  if keys is None : <TAB><TAB><TAB>  continue <TAB><TAB>  # Update `items` <TAB><TAB>  self . items [ tuple ( keys ) ] = ( index , item ) <TAB><TAB>  # Update `table` <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( "" Unable to update table (keys:  %r ) "" , keys ) ","if not self . path_set ( self . table , keys , ( index , item ) ) :",if not self.table:,False,54.36502919754241,88.76730202665784
4219,"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB>  """"""Return XML element converting dicts recursively."""""" <TAB>  elem = Element ( tag , * * kwargs ) <TAB>  for key , val in dictionary . items ( ) : <TAB><TAB>  if tag == "" layers "" : <TAB><TAB><TAB>  child = dict_to_XML ( "" layer "" , val , name = key ) <TAB><TAB>  elif isinstance ( val , MutableMapping ) : <TAB><TAB><TAB>  child = dict_to_XML ( key , val ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  child = Element ( "" variable "" , name = key ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  child = Element ( key ) <TAB><TAB><TAB>  child . text = str ( val ) <TAB><TAB>  elem . append ( child ) <TAB>  return elem ","if tag == ""config"" :","if tag == ""variable':",False,36.548158224767135,98.57279654050396
4220,"def _get_config_value ( self , section , key ) : <TAB>  if section : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log . error ( "" Error: Config section  ' %s '  not found "" , section ) <TAB><TAB><TAB>  return None <TAB><TAB>  return self . config [ section ] . get ( key , self . config [ key ] ) <TAB>  else : <TAB><TAB>  return self . config [ key ] ",if section not in self . config :,if section not in self.config:,False,27.40662855360728,97.00700049144825
4221,"def h_line_down ( self , input ) : <TAB>  end_this_line = self . value . find ( "" \n "" , self . cursor_position ) <TAB>  if end_this_line == - 1 : <TAB><TAB>  if self . scroll_exit : <TAB><TAB><TAB>  self . h_exit_down ( None ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . cursor_position = len ( self . value ) <TAB>  else : <TAB><TAB>  self . cursor_position = end_this_line + 1 <TAB><TAB>  for x in range ( self . cursorx ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  elif self . value [ self . cursor_position ] == "" \n "" : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . cursor_position + = 1 ",if self . cursor_position > len ( self . value ) - 1 :,if self.value[x] == '\n':,False,48.895319692206364,94.8856129205747
4222,"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB>  m = md5 ( ) <TAB>  try : <TAB><TAB>  while 1 : <TAB><TAB><TAB>  data = fp . read ( bufsize ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  if isinstance ( data , str ) : <TAB><TAB><TAB><TAB>  data = data . encode ( fp . encoding ) <TAB><TAB><TAB>  m . update ( data ) <TAB>  except IOError as msg : <TAB><TAB>  sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB><TAB>  return 1 <TAB>  out . write ( "" %s %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB>  return 0 ",if not data :,if not data:,False,50.814598790926865,100.00000000000004
4223,"def main ( input ) : <TAB>  logging . info ( "" Running Azure Cloud Custodian Policy  %s "" , input ) <TAB>  context = { <TAB><TAB>  "" config_file "" : join ( function_directory , "" config.json "" ) , <TAB><TAB>  "" auth_file "" : join ( function_directory , "" auth.json "" ) , <TAB>  } <TAB>  event = None <TAB>  subscription_id = None <TAB>  if isinstance ( input , QueueMessage ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  event = input . get_json ( ) <TAB><TAB>  subscription_id = ResourceIdParser . get_subscription_id ( event [ "" subject "" ] ) <TAB>  handler . run ( event , context , subscription_id ) ",if input . dequeue_count > max_dequeue_count :,if input.get_message_type() == 'QueueMessage':,False,49.12429617893568,94.30448675074103
4224,"def maybeExtractTarball ( self ) : <TAB>  if self . tarball : <TAB><TAB>  tar = self . computeTarballOptions ( ) + [ "" -xvf "" , self . tarball ] <TAB><TAB>  res = yield self . _Cmd ( tar , abandonOnFailure = False ) <TAB><TAB>  <IF-STMT>:<TAB># error with tarball.. erase repo dir and tarball <TAB><TAB><TAB>  yield self . _Cmd ( [ "" rm "" , "" -f "" , self . tarball ] , abandonOnFailure = False ) <TAB><TAB><TAB>  yield self . runRmdir ( self . repoDir ( ) , abandonOnFailure = False ) ",if res :,if res != 0:,False,56.26586489852103,94.02790480088902
4225,"def execute ( self , arbiter , props ) : <TAB>  watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB>  action = 0 <TAB>  for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_action = 0 <TAB><TAB><TAB>  for name , _val in val . items ( ) : <TAB><TAB><TAB><TAB>  action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB><TAB><TAB><TAB>  if action == 1 : <TAB><TAB><TAB><TAB><TAB>  new_action = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  new_action = watcher . set_opt ( key , val ) <TAB><TAB>  if new_action == 1 : <TAB><TAB><TAB>  action = 1 <TAB>  # trigger needed action <TAB>  return watcher . do_action ( action ) ","if key == ""hooks"" :",if key == 'action':,False,50.83687870707121,98.24420010656752
4226,"def _import_playlists ( self , fns , library ) : <TAB>  added = 0 <TAB>  for filename in fns : <TAB><TAB>  name = _name_for ( filename ) <TAB><TAB>  with open ( filename , "" rb "" ) as f : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  playlist = parse_m3u ( f , name , library = library ) <TAB><TAB><TAB>  elif filename . endswith ( "" .pls "" ) : <TAB><TAB><TAB><TAB>  playlist = parse_pls ( f , name , library = library ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  print_w ( "" Unsupported playlist type for  ' %s ' "" % filename ) <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  self . changed ( playlist ) <TAB><TAB>  library . add ( playlist ) <TAB><TAB>  added + = 1 <TAB>  return added ","if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :",if filename.endswith('.m3u'):,False,45.480990351760184,92.87795099372237
4227,"def unwrap_term_buckets ( self , timestamp , term_buckets ) : <TAB>  for term_data in term_buckets : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . unwrap_interval_buckets ( <TAB><TAB><TAB><TAB>  timestamp , term_data [ "" key "" ] , term_data [ "" interval_aggs "" ] [ "" buckets "" ] <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . check_matches ( timestamp , term_data [ "" key "" ] , term_data ) ","if ""interval_aggs"" in term_data :",if term_data['key'] == 'interval_aggs':,False,23.42972836932687,92.73020125834253
4228,"def _get_exception ( flags , timeout_ms , payload_size ) : <TAB>  if flags & FLAG_ERROR : <TAB><TAB>  if flags & FLAG_TIMEOUT : <TAB><TAB><TAB>  return SpicommTimeoutError ( timeout_ms / 1000.0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return SpicommOverflowError ( payload_size ) <TAB><TAB>  return SpicommError ( ) <TAB>  return None ",if flags & FLAG_OVERFLOW :,if flags & FLAG_OVERFLOW:,False,26.487474744661633,100.00000000000004
4229,"def _get_pattern ( self , pattern_id ) : <TAB>  """"""Get pattern item by id."""""" <TAB>  for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB><TAB>  if key in self . tagged_blocks : <TAB><TAB><TAB>  data = self . tagged_blocks . get_data ( key ) <TAB><TAB><TAB>  for pattern in data : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return pattern <TAB>  return None ",if pattern . pattern_id == pattern_id :,if pattern_id == pattern.id:,False,50.09504362506372,96.69022222705321
4230,"def print_quiet ( self , context , * args , * * kwargs ) : <TAB>  for index , ( key , value ) in enumerate ( <TAB><TAB>  itertools . chain ( enumerate ( args ) , kwargs . items ( ) ) <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  self . format_quiet ( index , key , value , fields = context . get_input_fields ( ) ) <TAB><TAB><TAB>  ) ","if self . filter ( index , key , value ) :",if context.get_input_fields():,False,42.99864499886809,92.318394814691
4231,"def complete ( self , block ) : <TAB>  with self . _condition : <TAB><TAB>  if not self . _final : <TAB><TAB><TAB>  return False <TAB><TAB>  if self . _complete ( ) : <TAB><TAB><TAB>  self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _condition . wait_for ( self . _complete ) <TAB><TAB><TAB>  self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  return False ",if block :,if self._condition.is_set():,False,24.069896358963533,93.55087062968376
4232,"def compression_rotator ( source , dest ) : <TAB>  with open ( source , "" rb "" ) as sf : <TAB><TAB>  with gzip . open ( dest , "" wb "" ) as wf : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  data = sf . read ( CHUNK_SIZE ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  wf . write ( data ) <TAB>  os . remove ( source ) ",if not data :,if not data:,False,50.65206299272948,100.00000000000004
4233,"def mockup ( self , records ) : <TAB>  provider = TransipProvider ( "" "" , "" "" , "" "" ) <TAB>  _dns_entries = [ ] <TAB>  for record in records : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  entries_for = getattr ( provider , "" _entries_for_ {} "" . format ( record . _type ) ) <TAB><TAB><TAB>  # Root records have '@' as name <TAB><TAB><TAB>  name = record . name <TAB><TAB><TAB>  if name == "" "" : <TAB><TAB><TAB><TAB>  name = provider . ROOT_RECORD <TAB><TAB><TAB>  _dns_entries . extend ( entries_for ( name , record ) ) <TAB><TAB><TAB>  # NS is not supported as a DNS Entry, <TAB><TAB><TAB>  # so it should cover the if statement <TAB><TAB><TAB>  _dns_entries . append ( DnsEntry ( "" @ "" , "" 3600 "" , "" NS "" , "" ns01.transip.nl. "" ) ) <TAB>  self . mockupEntries = _dns_entries ",if record . _type in provider . SUPPORTS :,"if hasattr(record, '_type'):",False,54.75223501599906,96.6674885641573
4234,"def parse_known_args ( self , args = None , namespace = None ) : <TAB>  entrypoint = self . prog . split ( "" "" ) [ 0 ] <TAB>  try : <TAB><TAB>  defs = get_defaults_for_argparse ( entrypoint ) <TAB><TAB>  ignore = defs . pop ( "" Ignore "" , None ) <TAB><TAB>  self . set_defaults ( * * defs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  set_notebook_diff_ignores ( ignore ) <TAB>  except ValueError : <TAB><TAB>  pass <TAB>  return super ( ConfigBackedParser , self ) . parse_known_args ( <TAB><TAB>  args = args , namespace = namespace <TAB>  ) ",if ignore :,if ignore is not None:,False,34.07418187051904,97.32247148753277
4235,"def _maybeRebuildAtlas ( self , threshold = 4 , minlen = 1000 ) : <TAB>  n = len ( self . fragmentAtlas ) <TAB>  if ( n > minlen ) and ( n > threshold * len ( self . data ) ) : <TAB><TAB>  self . fragmentAtlas . rebuild ( <TAB><TAB><TAB>  list ( zip ( * self . _style ( [ "" symbol "" , "" size "" , "" pen "" , "" brush "" ] ) ) ) <TAB><TAB>  ) <TAB><TAB>  self . data [ "" sourceRect "" ] = 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _sourceQRect . clear ( ) <TAB><TAB>  self . updateSpots ( ) ",if _USE_QRECT :,if n > minlen:,False,29.267136111397395,96.59055175679039
4236,"def dispatch_return ( self , frame , arg ) : <TAB>  if self . stop_here ( frame ) or frame == self . returnframe : <TAB><TAB>  # Ignore return events in generator except when stepping. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . trace_dispatch <TAB><TAB>  try : <TAB><TAB><TAB>  self . frame_returning = frame <TAB><TAB><TAB>  self . user_return ( frame , arg ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . frame_returning = None <TAB><TAB>  if self . quitting : <TAB><TAB><TAB>  raise BdbQuit <TAB><TAB>  # The user issued a 'next' or 'until' command. <TAB><TAB>  if self . stopframe is frame and self . stoplineno != - 1 : <TAB><TAB><TAB>  self . _set_stopinfo ( None , None ) <TAB>  return self . trace_dispatch ",if self . stopframe and frame . f_code . co_flags & CO_GENERATOR :,if self.stopframe is frame:,False,61.32503275101839,92.53364764139329
4237,"def tearDown ( self ) : <TAB>  if not self . is_playback ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  if self . hosted_service_name is not None : <TAB><TAB><TAB><TAB>  self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . sms . delete_storage_account ( self . storage_account_name ) <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB><TAB>  try : <TAB><TAB><TAB>  self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB><TAB>  except : <TAB><TAB><TAB>  pass <TAB>  return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( ) ",if self . storage_account_name is not None :,if self.storage_account_name is not None:,False,28.04071769660349,100.00000000000004
4238,"def make_log_msg ( self , msg , * other_messages ) : <TAB>  MAX_MESSAGE_LENGTH = 1000 <TAB>  if not other_messages : <TAB><TAB>  # assume that msg is a single string <TAB><TAB>  return msg [ - MAX_MESSAGE_LENGTH : ] <TAB>  else : <TAB><TAB>  if len ( msg ) : <TAB><TAB><TAB>  msg + = "" \n ... \n "" <TAB><TAB><TAB>  NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len ( msg ) <TAB><TAB>  else : <TAB><TAB><TAB>  NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg + = other_messages [ 0 ] [ - NEXT_MESSAGE_OFFSET : ] <TAB><TAB><TAB>  return self . make_log_msg ( msg , * other_messages [ 1 : ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  return self . make_log_msg ( msg ) ",if NEXT_MESSAGE_OFFSET > 0 :,if NEXT_MESSAGE_OFFSET >= 0:,False,56.66416202897714,96.28142404145173
4239,"def wrapper (<TAB># type: ignore <TAB>  self : RequestHandler , * args , * * kwargs  ) - > Optional [ Awaitable [ None ] ] : <TAB>  if self . request . path . endswith ( "" / "" ) : <TAB><TAB>  if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB><TAB><TAB>  uri = self . request . path . rstrip ( "" / "" ) <TAB><TAB><TAB>  if uri :<TAB># don't try to redirect '/' to '' <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  uri + = "" ? "" + self . request . query <TAB><TAB><TAB><TAB>  self . redirect ( uri , permanent = True ) <TAB><TAB><TAB><TAB>  return None <TAB><TAB>  else : <TAB><TAB><TAB>  raise HTTPError ( 404 ) <TAB>  return method ( self , * args , * * kwargs ) ",if self . request . query :,if self.request.query:,False,4.931459834269908,96.23302919198744
4240,"def process_lib ( vars_ , coreval ) : <TAB>  for d in vars_ : <TAB><TAB>  var = d . upper ( ) <TAB><TAB>  if var == "" QTCORE "" : <TAB><TAB><TAB>  continue <TAB><TAB>  value = env [ "" LIBPATH_ "" + var ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  core = env [ coreval ] <TAB><TAB><TAB>  accu = [ ] <TAB><TAB><TAB>  for lib in value : <TAB><TAB><TAB><TAB>  if lib in core : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  accu . append ( lib ) <TAB><TAB><TAB>  env [ "" LIBPATH_ "" + var ] = accu ",if value :,if coreval in env:,False,28.679537206126277,97.70487830978938
4241,"def _attach_children ( self , other , exclude_worldbody , dry_run = False ) : <TAB>  for other_child in other . all_children ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self_child = self . get_children ( other_child . spec . name ) <TAB><TAB><TAB>  self_child . _attach ( <TAB><TAB><TAB><TAB>  other_child , exclude_worldbody , dry_run <TAB><TAB><TAB>  )<TAB># pylint: disable=protected-access ",if not other_child . spec . repeated :,"if isinstance(other_child, T.Name):",False,38.55425093115565,89.64690435768075
4242,"def getDictFromTree ( tree ) : <TAB>  ret_dict = { } <TAB>  for child in tree . getchildren ( ) : <TAB><TAB>  if child . getchildren ( ) : <TAB><TAB><TAB>  ## Complex-type child. Recurse <TAB><TAB><TAB>  content = getDictFromTree ( child ) <TAB><TAB>  else : <TAB><TAB><TAB>  content = child . text <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not type ( ret_dict [ child . tag ] ) == list : <TAB><TAB><TAB><TAB>  ret_dict [ child . tag ] = [ ret_dict [ child . tag ] ] <TAB><TAB><TAB>  ret_dict [ child . tag ] . append ( content or "" "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  ret_dict [ child . tag ] = content or "" "" <TAB>  return ret_dict ",if ret_dict . has_key ( child . tag ) :,if child.tag in ret_dict:,False,51.892989603703946,95.39690558648702
4243,"def nsUriMatch ( self , value , wanted , strict = 0 , tt = type ( ( ) ) ) : <TAB>  """"""Return a true value if two namespace uri values match."""""" <TAB>  if value == wanted or ( type ( wanted ) is tt ) and value in wanted : <TAB><TAB>  return 1 <TAB>  if not strict and value is not None : <TAB><TAB>  wanted = type ( wanted ) is tt and wanted or ( wanted , ) <TAB><TAB>  value = value [ - 1 : ] != "" / "" and value or value [ : - 1 ] <TAB><TAB>  for item in wanted : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return 1 <TAB>  return 0 ",if item == value or item [ : - 1 ] == value :,if item in value:,False,61.32291480547446,90.37596611638531
4244,"def update_repository ( self , ignore_issues = False , force = False ) : <TAB>  """"""Update."""""" <TAB>  if not await self . common_update ( ignore_issues , force ) : <TAB><TAB>  return <TAB>  # Get appdaemon objects. <TAB>  if self . repository_manifest : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . content . path . remote = "" "" <TAB>  if self . content . path . remote == "" apps "" : <TAB><TAB>  self . data . domain = get_first_directory_in_directory ( <TAB><TAB><TAB>  self . tree , self . content . path . remote <TAB><TAB>  ) <TAB><TAB>  self . content . path . remote = f "" apps/ { self . data . name } "" <TAB>  # Set local path <TAB>  self . content . path . local = self . localpath ",if self . data . content_in_root :,"if self.content.path.remote == ""apps':",False,51.0263702388431,95.60949620501106
4245,"def addOutput ( self , data , isAsync = None , * * kwargs ) : <TAB>  isAsync = _get_async_param ( isAsync , * * kwargs ) <TAB>  if isAsync : <TAB><TAB>  self . terminal . eraseLine ( ) <TAB><TAB>  self . terminal . cursorBackward ( len ( self . lineBuffer ) + len ( self . ps [ self . pn ] ) ) <TAB>  self . terminal . write ( data ) <TAB>  if isAsync : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . terminal . nextLine ( ) <TAB><TAB>  self . terminal . write ( self . ps [ self . pn ] ) <TAB><TAB>  if self . lineBuffer : <TAB><TAB><TAB>  oldBuffer = self . lineBuffer <TAB><TAB><TAB>  self . lineBuffer = [ ] <TAB><TAB><TAB>  self . lineBufferIndex = 0 <TAB><TAB><TAB>  self . _deliverBuffer ( oldBuffer ) ",if self . _needsNewline ( ) :,if self.lineBuffer:,False,46.334180435547864,97.5017042594688
4246,"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB>  installed = False <TAB>  if dlc_title : <TAB><TAB>  dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB><TAB>  installed = True if dlc_version else False <TAB><TAB>  # Start: Code for compatibility with minigalaxy 1.0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  status = self . legacy_get_dlc_status ( dlc_title ) <TAB><TAB><TAB>  installed = True if status in [ "" installed "" , "" updatable "" ] else False <TAB><TAB>  # End: Code for compatibility with minigalaxy 1.0 <TAB>  else : <TAB><TAB>  if self . install_dir and os . path . exists ( self . install_dir ) : <TAB><TAB><TAB>  installed = True <TAB>  return installed ",if not installed :,if self.legacy_get_dlc_status():,False,60.4948810071634,94.30095993106619
4247,"def close ( self ) : <TAB>  self . selector . close ( ) <TAB>  if self . sock : <TAB><TAB>  sockname = None <TAB><TAB>  try : <TAB><TAB><TAB>  sockname = self . sock . getsockname ( ) <TAB><TAB>  except ( socket . error , OSError ) : <TAB><TAB><TAB>  pass <TAB><TAB>  self . sock . close ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # it was a Unix domain socket, remove it from the filesystem <TAB><TAB><TAB>  if os . path . exists ( sockname ) : <TAB><TAB><TAB><TAB>  os . remove ( sockname ) <TAB>  self . sock = None ",if type ( sockname ) is str :,if sockname is not None:,False,60.22539059833011,96.02453290962283
4248,"def post_file ( self , file_path , graph_type = "" edges "" , file_type = "" csv "" ) : <TAB>  dataset_id = self . dataset_id <TAB>  tok = self . token <TAB>  base_path = self . server_base_path <TAB>  with open ( file_path , "" rb "" ) as file : <TAB><TAB>  out = requests . post ( <TAB><TAB><TAB>  f "" { base_path } /api/v2/upload/datasets/ { dataset_id } / { graph_type } / { file_type } "" , <TAB><TAB><TAB>  verify = self . certificate_validation , <TAB><TAB><TAB>  headers = { "" Authorization "" : f "" Bearer  { tok } "" } , <TAB><TAB><TAB>  data = file . read ( ) , <TAB><TAB>  ) . json ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise Exception ( out ) <TAB><TAB>  return out ","if not out [ ""success"" ] :",if not out:,False,22.377031804515077,97.28540233046914
4249,"def _get_vqa_v2_image_raw_dataset ( directory , image_root_url , image_urls ) : <TAB>  """"""Extract the VQA V2 image data set to directory unless it's there."""""" <TAB>  for url in image_urls : <TAB><TAB>  filename = os . path . basename ( url ) <TAB><TAB>  download_url = os . path . join ( image_root_url , url ) <TAB><TAB>  path = generator_utils . maybe_download ( directory , filename , download_url ) <TAB><TAB>  unzip_dir = os . path . join ( directory , filename . strip ( "" .zip "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  zipfile . ZipFile ( path , "" r "" ) . extractall ( directory ) ",if not tf . gfile . Exists ( unzip_dir ) :,if os.path.exists(unzip_dir):,False,29.995396245666157,96.35568253719052
4250,"def __call__ ( self , environ , start_response ) : <TAB>  for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  request_uri = unquote ( environ [ key ] ) <TAB><TAB>  script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB><TAB>  if request_uri . startswith ( script_name ) : <TAB><TAB><TAB>  environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB><TAB><TAB>  break <TAB>  return self . app ( environ , start_response ) ",if key not in environ :,if key not in environ:,False,51.852842605591334,100.00000000000004
4251,"def _instrument_model ( self , model ) : <TAB>  for key , value in list ( <TAB><TAB>  model . __dict__ . items ( ) <TAB>  ) :<TAB># avoid ""dictionary keys changed during iteration"" <TAB><TAB>  if isinstance ( value , tf . keras . layers . Layer ) : <TAB><TAB><TAB>  new_layer = self . _instrument ( value ) <TAB><TAB><TAB>  if new_layer is not value : <TAB><TAB><TAB><TAB>  setattr ( model , key , new_layer ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for i , item in enumerate ( value ) : <TAB><TAB><TAB><TAB>  if isinstance ( item , tf . keras . layers . Layer ) : <TAB><TAB><TAB><TAB><TAB>  value [ i ] = self . _instrument ( item ) <TAB>  return model ","elif isinstance ( value , list ) :","if isinstance(value, (list, tuple)):",False,47.540895906347814,94.15321381455618
4252,"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB>  filelist = [ ] <TAB>  dirlist = [ "" .. "" ] <TAB>  self . dir = dir <TAB>  self . file = "" "" <TAB>  mask = mask . upper ( ) <TAB>  pattern = self . MakeRegex ( mask ) <TAB>  for i in os . listdir ( dir ) : <TAB><TAB>  if i == "" . "" or i == "" .. "" : <TAB><TAB><TAB>  continue <TAB><TAB>  path = os . path . join ( dir , i ) <TAB><TAB>  if os . path . isdir ( path ) : <TAB><TAB><TAB>  dirlist . append ( i ) <TAB><TAB><TAB>  continue <TAB><TAB>  path = path . upper ( ) <TAB><TAB>  value = i . upper ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filelist . append ( i ) <TAB>  self . files = filelist <TAB>  if with_dirs : <TAB><TAB>  self . dirs = dirlist ",if pattern . match ( value ) is not None :,"if pattern.match(path, value):",False,25.306568216555437,97.82988519333992
4253,"def get_text ( self , nodelist ) : <TAB>  """"""Return a string representation of the motif's properties listed on nodelist ."""""" <TAB>  retlist = [ ] <TAB>  for node in nodelist : <TAB><TAB>  if node . nodeType == Node . TEXT_NODE : <TAB><TAB><TAB>  retlist . append ( node . wholeText ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  retlist . append ( self . get_text ( node . childNodes ) ) <TAB>  return re . sub ( r "" \ s+ "" , "" "" , "" "" . join ( retlist ) ) ",elif node . hasChildNodes :,if node.childNodes:,False,59.654190568675666,96.59825025980723
4254,"def _persist_metadata ( self , dirname , filename ) : <TAB>  metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB>  if self . media_metadata or self . comments or self . include_location : <TAB><TAB>  if self . posts : <TAB><TAB><TAB>  if self . latest : <TAB><TAB><TAB><TAB>  self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . latest : <TAB><TAB><TAB><TAB>  self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . save_json ( { "" GraphStories "" : self . stories } , metadata_path ) ",if self . stories :,if self.stories:,False,50.40461784115479,100.00000000000004
4255,"def _get_python_wrapper_content ( self , job_class , args ) : <TAB>  job = job_class ( [ "" -r "" , "" hadoop "" ] + list ( args ) ) <TAB>  job . sandbox ( ) <TAB>  with job . make_runner ( ) as runner : <TAB><TAB>  runner . _create_setup_wrapper_scripts ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with open ( runner . _spark_python_wrapper_path ) as f : <TAB><TAB><TAB><TAB>  return f . read ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  return None ",if runner . _spark_python_wrapper_path :,"if hasattr(runner, '_spark_python_wrapper_path'):",False,48.86340367458472,94.1201044841631
4256,"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB>  w = 0 <TAB>  for ch in s : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  w + = 1 <TAB><TAB>  elif ch == "" \t "" : <TAB><TAB><TAB>  w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  return w ","if ch == "" "" :",if ch == '\n':,False,46.24071462915232,96.12260133949076
4257,def run ( self ) : <TAB>  # if the i3status process dies we want to restart it. <TAB>  # We give up restarting if we have died too often <TAB>  for _ in range ( 10 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  self . spawn_i3status ( ) <TAB><TAB>  # check if we never worked properly and if so quit now <TAB><TAB>  if not self . ready : <TAB><TAB><TAB>  break <TAB><TAB>  # limit restart rate <TAB><TAB>  self . lock . wait ( 5 ) ,if not self . py3_wrapper . running :,if self.is_running:,False,47.57076707345811,94.8904642247206
4258,"def translate_len ( <TAB>  builder : IRBuilder , expr : CallExpr , callee : RefExpr  ) - > Optional [ Value ] : <TAB>  # Special case builtins.len <TAB>  if len ( expr . args ) == 1 and expr . arg_kinds == [ ARG_POS ] : <TAB><TAB>  expr_rtype = builder . node_type ( expr . args [ 0 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # len() of fixed-length tuple can be trivially determined statically, <TAB><TAB><TAB>  # though we still need to evaluate it. <TAB><TAB><TAB>  builder . accept ( expr . args [ 0 ] ) <TAB><TAB><TAB>  return Integer ( len ( expr_rtype . types ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  obj = builder . accept ( expr . args [ 0 ] ) <TAB><TAB><TAB>  return builder . builtin_len ( obj , - 1 ) <TAB>  return None ","if isinstance ( expr_rtype , RTuple ) :",if expr_rtype.types:,False,52.75229034106077,95.54434998161156
4259,"def parse_auth ( val ) : <TAB>  if val is not None : <TAB><TAB>  authtype , params = val . split ( "" "" , 1 ) <TAB><TAB>  if authtype in known_auth_schemes : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # this is the ""Authentication: Basic XXXXX=="" case <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  params = parse_auth_params ( params ) <TAB><TAB>  return authtype , params <TAB>  return val ","if authtype == ""Basic"" and '""' not in params :",if params is None:,False,53.95738938683955,90.91953767237642
4260,"def toxml ( self ) : <TAB>  text = self . value <TAB>  self . parent . setBidi ( getBidiType ( text ) ) <TAB>  if not text . startswith ( HTML_PLACEHOLDER_PREFIX ) : <TAB><TAB>  if self . parent . nodeName == "" p "" : <TAB><TAB><TAB>  text = text . replace ( "" \n "" , "" \n<TAB> "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = "" \n<TAB>   "" + text . replace ( "" \n "" , "" \n<TAB>   "" ) <TAB>  text = self . doc . normalizeEntities ( text ) <TAB>  return text ","elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :",if self.parent.nodeType == 'text':,False,24.466574675045287,86.38198349193345
4261,"def get_all_related_many_to_many_objects ( self ) : <TAB>  try :<TAB># Try the cache first. <TAB><TAB>  return self . _all_related_many_to_many_objects <TAB>  except AttributeError : <TAB><TAB>  rel_objs = [ ] <TAB><TAB>  for klass in get_models ( ) : <TAB><TAB><TAB>  for f in klass . _meta . many_to_many : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  rel_objs . append ( RelatedObject ( f . rel . to , klass , f ) ) <TAB><TAB>  self . _all_related_many_to_many_objects = rel_objs <TAB><TAB>  return rel_objs ",if f . rel and self == f . rel . to . _meta :,if f.rel.to == self.rel.to:,False,18.72017921266611,94.50070936973137
4262,"def state_highstate ( self , state , dirpath ) : <TAB>  opts = copy . copy ( self . config ) <TAB>  opts [ "" file_roots "" ] = dict ( base = [ dirpath ] ) <TAB>  HIGHSTATE = HighState ( opts ) <TAB>  HIGHSTATE . push_active ( ) <TAB>  try : <TAB><TAB>  high , errors = HIGHSTATE . render_highstate ( state ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  import pprint <TAB><TAB><TAB>  pprint . pprint ( "" \n "" . join ( errors ) ) <TAB><TAB><TAB>  pprint . pprint ( high ) <TAB><TAB>  out = HIGHSTATE . state . call_high ( high ) <TAB><TAB>  # pprint.pprint(out) <TAB>  finally : <TAB><TAB>  HIGHSTATE . pop_active ( ) ",if errors :,if errors:,False,50.94610702315225,100.00000000000004
4263,"def _update_target_host ( self , target , target_host ) : <TAB>  """"""Update target host."""""" <TAB>  target_host = None if target_host == "" "" else target_host <TAB>  if not target_host : <TAB><TAB>  for device_type , tgt in target . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  target_host = tgt <TAB><TAB><TAB><TAB>  break <TAB>  if not target_host : <TAB><TAB>  target_host = "" llvm "" if tvm . runtime . enabled ( "" llvm "" ) else "" stackvm "" <TAB>  if isinstance ( target_host , str ) : <TAB><TAB>  target_host = tvm . target . Target ( target_host ) <TAB>  return target_host ",if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,if device_type == tvm.target.DeviceType.Target:,False,49.82897549111043,93.16088017670552
4264,"def __console_writer ( self ) : <TAB>  while True : <TAB><TAB>  self . __writer_event . wait ( ) <TAB><TAB>  self . __writer_event . clear ( ) <TAB><TAB>  if self . __console_view : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . log . debug ( "" Writing console view to STDOUT "" ) <TAB><TAB><TAB><TAB>  sys . stdout . write ( self . console_markup . clear ) <TAB><TAB><TAB><TAB>  sys . stdout . write ( self . __console_view ) <TAB><TAB><TAB><TAB>  sys . stdout . write ( self . console_markup . TOTAL_RESET ) ",if not self . short_only :,if self.__console_view:,False,25.849870512071178,95.98473988415172
4265,"def goToPrevMarkedHeadline ( self , event = None ) : <TAB>  """"""Select the next marked node."""""" <TAB>  c = self <TAB>  p = c . p <TAB>  if not p : <TAB><TAB>  return <TAB>  p . moveToThreadBack ( ) <TAB>  wrapped = False <TAB>  while 1 : <TAB><TAB>  if p and p . isMarked ( ) : <TAB><TAB><TAB>  break <TAB><TAB>  elif p : <TAB><TAB><TAB>  p . moveToThreadBack ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  wrapped = True <TAB><TAB><TAB>  p = c . rootPosition ( ) <TAB>  if not p : <TAB><TAB>  g . blue ( "" done "" ) <TAB>  c . treeSelectHelper ( p )<TAB># Sets focus. ",elif wrapped :,if wrapped:,False,28.80010122029757,96.67865089754915
4266,"def delete_map ( self , query = None ) : <TAB>  query_map = self . interpolated_map ( query = query ) <TAB>  for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB><TAB>  for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB><TAB><TAB>  for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB><TAB><TAB><TAB>  if vm_details == "" Absent "" : <TAB><TAB><TAB><TAB><TAB>  query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB><TAB><TAB>  if not query_map [ alias ] [ driver ] : <TAB><TAB><TAB><TAB>  query_map [ alias ] . pop ( driver ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  query_map . pop ( alias ) <TAB>  return query_map ",if not query_map [ alias ] :,if alias in query_map:,False,49.71614060486026,97.1239557878614
4267,"def get_shadows_zip ( filename ) : <TAB>  import zipfile <TAB>  shadow_pkgs = set ( ) <TAB>  with zipfile . ZipFile ( filename ) as lib_zip : <TAB><TAB>  already_test = [ ] <TAB><TAB>  for fname in lib_zip . namelist ( ) : <TAB><TAB><TAB>  pname , fname = os . path . split ( fname ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if pname not in already_test and "" / "" not in pname : <TAB><TAB><TAB><TAB>  already_test . append ( pname ) <TAB><TAB><TAB><TAB>  if is_shadowing ( pname ) : <TAB><TAB><TAB><TAB><TAB>  shadow_pkgs . add ( pname ) <TAB>  return shadow_pkgs ",if fname or ( pname and fname ) :,if not fname.startswith('.py'):,False,24.96765372088635,95.81516357593937
4268,"def make_chains ( chains_info ) : <TAB>  chains = [ [ ] for _ in chains_info [ 0 ] [ 1 ] ] <TAB>  for i , num_ids in enumerate ( chains_info [ : - 1 ] ) : <TAB><TAB>  num , ids = num_ids <TAB><TAB>  for j , ident in enumerate ( ids ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  next_chain_info = chains_info [ i + 1 ] <TAB><TAB><TAB><TAB>  previous = next_chain_info [ 1 ] [ j ] <TAB><TAB><TAB><TAB>  block = SimpleBlock ( num , ident , previous ) <TAB><TAB><TAB><TAB>  chains [ j ] . append ( block ) <TAB>  chains = { i : make_generator ( chain ) for i , chain in enumerate ( chains ) } <TAB>  return chains ","if ident != """" :",if chains_info[i + 1] and ident == _:,False,49.60370234712306,92.29160405059434
4269,"def filter_input ( mindate , maxdate , files ) : <TAB>  mindate = parse ( mindate ) if mindate is not None else datetime . datetime . min <TAB>  maxdate = parse ( maxdate ) if maxdate is not None else datetime . datetime . max <TAB>  for line in fileinput . input ( files ) : <TAB><TAB>  tweet = json . loads ( line ) <TAB><TAB>  created_at = parse ( tweet [ "" created_at "" ] ) <TAB><TAB>  created_at = created_at . replace ( tzinfo = None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( json . dumps ( tweet ) ) ",if mindate < created_at and maxdate > created_at :,if created_at != created_at:,False,30.960990073569068,94.8333808384416
4270,"def get ( self ) : <TAB>  """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB>  if self . _exception is not _NONE : <TAB><TAB>  if self . _exception is None : <TAB><TAB><TAB>  return self . value <TAB><TAB>  getcurrent ( ) . throw ( * self . _exception )<TAB># pylint:disable=undefined-variable <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ConcurrentObjectUseError ( <TAB><TAB><TAB><TAB>  "" This Waiter is already used by  %r "" % ( self . greenlet , ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . greenlet = getcurrent ( )<TAB># pylint:disable=undefined-variable <TAB><TAB>  try : <TAB><TAB><TAB>  return self . hub . switch ( ) <TAB><TAB>  finally : <TAB><TAB><TAB>  self . greenlet = None ",if self . greenlet is not None :,if self.greenlet is not _NONE:,False,36.011782001789236,94.91264202511303
4271,"def default_loader ( href , parse , encoding = None ) : <TAB>  with open ( href ) as file : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = ElementTree . parse ( file ) . getroot ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  data = file . read ( ) <TAB><TAB><TAB>  if encoding : <TAB><TAB><TAB><TAB>  data = data . decode ( encoding ) <TAB>  return data ","if parse == ""xml"" :",if parse:,False,47.01647015971523,94.51244890001797
4272,def is_all_qud ( world ) : <TAB>  m = True <TAB>  for obj in world : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if obj . nice : <TAB><TAB><TAB><TAB>  m = m and True <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  m = m and False <TAB><TAB>  else : <TAB><TAB><TAB>  m = m and True <TAB>  return m ,if obj . blond :,"if isinstance(obj, Qud):",False,52.811658129190086,94.06194542746805
4273,"def run ( self , edit ) : <TAB>  if not self . has_selection ( ) : <TAB><TAB>  region = sublime . Region ( 0 , self . view . size ( ) ) <TAB><TAB>  originalBuffer = self . view . substr ( region ) <TAB><TAB>  prefixed = self . prefix ( originalBuffer ) <TAB><TAB>  if prefixed : <TAB><TAB><TAB>  self . view . replace ( edit , region , prefixed ) <TAB><TAB>  return <TAB>  for region in self . view . sel ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  originalBuffer = self . view . substr ( region ) <TAB><TAB>  prefixed = self . prefix ( originalBuffer ) <TAB><TAB>  if prefixed : <TAB><TAB><TAB>  self . view . replace ( edit , region , prefixed ) ",if region . empty ( ) :,if region == self.view.size():,False,49.0450651375256,96.07427674852059
4274,"def add_fields ( self , params ) : <TAB>  for ( key , val ) in params . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_params = { } <TAB><TAB><TAB>  for k in val : <TAB><TAB><TAB><TAB>  new_params [ "" %s __ %s "" % ( key , k ) ] = val [ k ] <TAB><TAB><TAB>  self . add_fields ( new_params ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . add_field ( key , val ) ","if isinstance ( val , dict ) :",if key == 'fields':,False,43.71460328826867,94.9785397956707
4275,"def find_magic ( self , f , pos , magic ) : <TAB>  f . seek ( pos ) <TAB>  block = f . read ( 32 * 1024 ) <TAB>  if len ( block ) < len ( magic ) : <TAB><TAB>  return - 1 <TAB>  p = block . find ( magic ) <TAB>  while p < 0 : <TAB><TAB>  pos + = len ( block ) - len ( magic ) + 1 <TAB><TAB>  block = block [ 1 - len ( magic ) : ] + f . read ( 32 << 10 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return - 1 <TAB><TAB>  p = block . find ( magic ) <TAB>  return pos + p ",if len ( block ) == len ( magic ) - 1 :,if not block:,False,33.07319050168489,89.91263471099474
4276,"def check_strings ( self ) : <TAB>  """"""Check that all strings have been consumed."""""" <TAB>  for i , aList in enumerate ( self . string_tokens ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . trace ( "" warning: line  %s . unused strings "" % i ) <TAB><TAB><TAB>  for z in aList : <TAB><TAB><TAB><TAB>  print ( self . dump_token ( z ) ) ",if aList :,if i not in aList:,False,30.65724597446434,96.08889364388635
4277,"def get_tokens_unprocessed ( self , text ) : <TAB>  from pygments . lexers . _cocoa_builtins import ( <TAB><TAB>  COCOA_INTERFACES , <TAB><TAB>  COCOA_PROTOCOLS , <TAB><TAB>  COCOA_PRIMITIVES , <TAB>  ) <TAB>  for index , token , value in RegexLexer . get_tokens_unprocessed ( self , text ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  value in COCOA_INTERFACES <TAB><TAB><TAB><TAB>  or value in COCOA_PROTOCOLS <TAB><TAB><TAB><TAB>  or value in COCOA_PRIMITIVES <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  token = Name . Builtin . Pseudo <TAB><TAB>  yield index , token , value ",if token is Name or token is Name . Class :,if token is None:,False,43.50898519044502,95.81761335375171
4278,"def key_from_key_value_dict ( key_info ) : <TAB>  res = [ ] <TAB>  if not "" key_value "" in key_info : <TAB><TAB>  return res <TAB>  for value in key_info [ "" key_value "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  e = base64_to_long ( value [ "" rsa_key_value "" ] [ "" exponent "" ] ) <TAB><TAB><TAB>  m = base64_to_long ( value [ "" rsa_key_value "" ] [ "" modulus "" ] ) <TAB><TAB><TAB>  key = RSA . construct ( ( m , e ) ) <TAB><TAB><TAB>  res . append ( key ) <TAB>  return res ","if ""rsa_key_value"" in value :",if value['rsa_key_value']['type'] == RSA.TYPE_RSA:,False,48.982846103315545,90.85567119133079
4279,"def run ( self , edit ) : <TAB>  if not self . has_selection ( ) : <TAB><TAB>  region = sublime . Region ( 0 , self . view . size ( ) ) <TAB><TAB>  originalBuffer = self . view . substr ( region ) <TAB><TAB>  prefixed = self . prefix ( originalBuffer ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . view . replace ( edit , region , prefixed ) <TAB><TAB>  return <TAB>  for region in self . view . sel ( ) : <TAB><TAB>  if region . empty ( ) : <TAB><TAB><TAB>  continue <TAB><TAB>  originalBuffer = self . view . substr ( region ) <TAB><TAB>  prefixed = self . prefix ( originalBuffer ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . view . replace ( edit , region , prefixed ) ",if prefixed :,if prefixed != '':,False,21.142801628374556,95.69202648262076
4280,def finalize ( self ) : <TAB>  if self . ct < 1 : <TAB><TAB>  return <TAB>  elif self . ct == 1 : <TAB><TAB>  return 0 <TAB>  total = ct = 0 <TAB>  dtp = None <TAB>  while self . heap : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if dtp is None : <TAB><TAB><TAB><TAB>  dtp = heapq . heappop ( self . heap ) <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  dt = heapq . heappop ( self . heap ) <TAB><TAB>  diff = dt - dtp <TAB><TAB>  ct + = 1 <TAB><TAB>  total + = total_seconds ( diff ) <TAB><TAB>  dtp = dt <TAB>  return float ( total ) / ct ,if total == 0 :,if self.heap.heap_size < self.heap_size:,False,49.11111036554228,92.86959397572024
4281,"def _test_configuration ( self ) : <TAB>  config_path = self . _write_config ( ) <TAB>  try : <TAB><TAB>  self . _log . debug ( "" testing configuration "" ) <TAB><TAB>  verboseflag = "" -Q "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  verboseflag = "" -v "" <TAB><TAB>  p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB><TAB>  if p . wait ( ) != 0 : <TAB><TAB><TAB>  raise RuntimeError ( "" configuration test failed "" ) <TAB><TAB>  self . _log . debug ( "" configuration seems ok "" ) <TAB>  finally : <TAB><TAB>  os . remove ( config_path ) ",if self . _log . isEnabledFor ( logging . DEBUG ) :,if os.name == 'nt':,False,21.913506789674905,93.58207034149343
4282,"def exe ( self , ret ) : <TAB>  if not ret : <TAB><TAB>  self . assertEqual ( ret , "" "" ) <TAB>  else : <TAB><TAB>  assert os . path . isabs ( ret ) , ret <TAB><TAB>  # Note: os.stat() may return False even if the file is there <TAB><TAB>  # hence we skip the test, see: <TAB><TAB>  # http://stackoverflow.com/questions/3112546/os-path-exists-lies <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert os . path . isfile ( ret ) , ret <TAB><TAB><TAB>  if hasattr ( os , "" access "" ) and hasattr ( os , "" X_OK "" ) : <TAB><TAB><TAB><TAB>  # XXX may fail on OSX <TAB><TAB><TAB><TAB>  self . assertTrue ( os . access ( ret , os . X_OK ) ) ",if POSIX :,if os.name == 'nt':,False,63.25119482362411,96.57902360462968
4283,"def _do_cleanup ( sg_name , device_id ) : <TAB>  masking_view_list = self . rest . get_masking_views_from_storage_group ( array , sg_name ) <TAB>  for masking_view in masking_view_list : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . rest . delete_masking_view ( array , masking_view ) <TAB><TAB><TAB>  self . rest . remove_vol_from_sg ( array , sg_name , device_id , extra_specs ) <TAB><TAB><TAB>  self . rest . delete_volume ( array , device_id ) <TAB><TAB><TAB>  self . rest . delete_storage_group ( array , sg_name ) ","if ""STG-"" in masking_view :",if masking_view.device_id == device_id:,False,48.0444890249855,93.55007687527866
4284,"def hide_tooltip_if_necessary ( self , key ) : <TAB>  """"""Hide calltip when necessary"""""" <TAB>  try : <TAB><TAB>  calltip_char = self . get_character ( self . calltip_position ) <TAB><TAB>  before = self . is_cursor_before ( self . calltip_position , char_offset = 1 ) <TAB><TAB>  other = key in ( Qt . Key_ParenRight , Qt . Key_Period , Qt . Key_Tab ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  QToolTip . hideText ( ) <TAB>  except ( IndexError , TypeError ) : <TAB><TAB>  QToolTip . hideText ( ) ","if calltip_char not in ( ""?"" , ""("" ) or before or other :",if before and other:,False,21.118609809879956,88.9779796612282
4285,"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB>  stream = self . describe_stream ( stream_name ) <TAB>  tags = [ ] <TAB>  result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB>  for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB><TAB>  if limit and len ( tags ) > = limit : <TAB><TAB><TAB>  result [ "" HasMoreTags "" ] = True <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB>  return result ",if exclusive_start_tag_key and key < exclusive_start_tag_key :,if exclusive_start_tag_key and val is None:,False,24.68224576453673,94.86498900997039
4286,"def parametrize_function_name ( request , function_name ) : <TAB>  suffixes = [ ] <TAB>  if "" parametrize "" in request . keywords : <TAB><TAB>  argnames = request . keywords [ "" parametrize "" ] . args [ : : 2 ] <TAB><TAB>  argnames = [ x . strip ( ) for names in argnames for x in names . split ( "" , "" ) ] <TAB><TAB>  for name in argnames : <TAB><TAB><TAB>  value = request . getfuncargvalue ( name ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = value . __name__ <TAB><TAB><TAB>  suffixes . append ( "" {} = {} "" . format ( name , value ) ) <TAB>  return "" + "" . join ( [ function_name ] + suffixes ) ",if inspect . isclass ( value ) :,"if hasattr(value, '__name__'):",False,41.98433519642184,94.18709552595325
4287,"def add_entities ( self , positions ) : <TAB>  e1 = EntityFactory ( ) <TAB>  for p in positions : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  start , length = p <TAB><TAB>  else : <TAB><TAB><TAB>  start , length = p , 1 <TAB><TAB>  EntityOccurrenceFactory ( <TAB><TAB><TAB>  document = self . doc , <TAB><TAB><TAB>  entity = e1 , <TAB><TAB><TAB>  offset = start , <TAB><TAB><TAB>  offset_end = start + length , <TAB><TAB><TAB>  alias = "" AB "" , <TAB><TAB>  ) ","if isinstance ( p , tuple ) :","if isinstance(p, (int, float)):",False,49.6991408382988,96.13539001024427
4288,"def transform_value ( value ) : <TAB>  if isinstance ( value , collections . MutableMapping ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return DBRef ( value [ "" _ns "" ] , transform_value ( value [ "" _id "" ] ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  return transform_dict ( SON ( value ) ) <TAB>  elif isinstance ( value , list ) : <TAB><TAB>  return [ transform_value ( v ) for v in value ] <TAB>  return value ","if ""_id"" in value and ""_ns"" in value :","if isinstance(value, DBRef):",False,24.093934107264523,89.39464384746314
4289,"def remove ( self , items ) : <TAB>  """"""Remove messages from lease management."""""" <TAB>  with self . _add_remove_lock : <TAB><TAB>  # Remove the ack ID from lease management, and decrement the <TAB><TAB>  # byte counter. <TAB><TAB>  for item in items : <TAB><TAB><TAB>  if self . _leased_messages . pop ( item . ack_id , None ) is not None : <TAB><TAB><TAB><TAB>  self . _bytes - = item . byte_size <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  _LOGGER . debug ( "" Item  %s  was not managed. "" , item . ack_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _LOGGER . debug ( "" Bytes was unexpectedly negative:  %d "" , self . _bytes ) <TAB><TAB><TAB>  self . _bytes = 0 ",if self . _bytes < 0 :,if self._bytes < 0:,False,60.874350206136555,100.00000000000004
4290,"def parse_hgsub ( lines ) : <TAB>  """"""Fills OrderedDict with hgsub file content passed as list of lines"""""" <TAB>  rv = OrderedDict ( ) <TAB>  for l in lines : <TAB><TAB>  ls = l . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  name , value = l . split ( "" = "" , 1 ) <TAB><TAB>  rv [ name . strip ( ) ] = value . strip ( ) <TAB>  return rv ","if not ls or ls [ 0 ] == ""#"" :",if not ls.startswith('='):,False,46.13307814563796,91.36150189178113
4291,"def del_ ( self , key ) : <TAB>  initial_hash = hash_ = self . hash ( key ) <TAB>  while True : <TAB><TAB>  if self . _keys [ hash_ ] is self . _empty : <TAB><TAB><TAB>  # That key was never assigned <TAB><TAB><TAB>  return None <TAB><TAB>  elif self . _keys [ hash_ ] == key : <TAB><TAB><TAB>  # key found, assign with deleted sentinel <TAB><TAB><TAB>  self . _keys [ hash_ ] = self . _deleted <TAB><TAB><TAB>  self . _values [ hash_ ] = self . _deleted <TAB><TAB><TAB>  self . _len - = 1 <TAB><TAB><TAB>  return <TAB><TAB>  hash_ = self . _rehash ( hash_ ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # table is full and wrapped around <TAB><TAB><TAB>  return None ",if initial_hash == hash_ :,if hash_ == initial_hash:,False,59.225299892526074,97.702182665058
4292,"def atom ( token , no_symbol = False ) : <TAB>  try : <TAB><TAB>  return int ( token ) <TAB>  except ValueError : <TAB><TAB>  try : <TAB><TAB><TAB>  return float ( token ) <TAB><TAB>  except ValueError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return token [ 1 : - 1 ] <TAB><TAB><TAB>  elif no_symbol : <TAB><TAB><TAB><TAB>  return token <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return Symbol ( token ) ","if token . startswith ( ""'"" ) or token . startswith ( '""' ) :",if token.endswith('-'):,False,48.85887555016139,89.19339607643799
4293,"def __Suffix_Noun_Step1b ( self , token ) : <TAB>  for suffix in self . __suffix_noun_step1b : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  token = token [ : - 1 ] <TAB><TAB><TAB>  self . suffixe_noun_step1b_success = True <TAB><TAB><TAB>  break <TAB>  return token ",if token . endswith ( suffix ) and len ( token ) > 5 :,if suffix in token:,False,40.873650895923255,83.24505163842959
4294,"def _guardAgainstUnicode ( self , data ) : <TAB>  # Only accept byte strings or ascii unicode values, otherwise <TAB>  # there is no way to correctly decode the data into bytes. <TAB>  if _pythonMajorVersion < 3 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data = data . encode ( "" utf8 "" ) <TAB>  else : <TAB><TAB>  if isinstance ( data , str ) : <TAB><TAB><TAB>  # Only accept ascii unicode values. <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  return data . encode ( "" ascii "" ) <TAB><TAB><TAB>  except UnicodeEncodeError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  raise ValueError ( "" pyDes can only work with encoded strings, not Unicode. "" ) <TAB>  return data ","if isinstance ( data , unicode ) :","if isinstance(data, unicode):",False,43.41951802373695,100.00000000000004
4295,"def populate_resource_parameters ( self , tool_source ) : <TAB>  root = getattr ( tool_source , "" root "" , None ) <TAB>  if ( <TAB><TAB>  root is not None <TAB><TAB>  and hasattr ( self . app , "" job_config "" ) <TAB><TAB>  and hasattr ( self . app . job_config , "" get_tool_resource_xml "" ) <TAB>  ) : <TAB><TAB>  resource_xml = self . app . job_config . get_tool_resource_xml ( <TAB><TAB><TAB>  root . get ( "" id "" ) , self . tool_type <TAB><TAB>  ) <TAB><TAB>  if resource_xml is not None : <TAB><TAB><TAB>  inputs = root . find ( "" inputs "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  inputs = parse_xml_string ( "" <inputs/> "" ) <TAB><TAB><TAB><TAB>  root . append ( inputs ) <TAB><TAB><TAB>  inputs . append ( resource_xml ) ",if inputs is None :,if inputs is None:,False,51.8123420369337,100.00000000000004
4296,"def test_arguments_regex ( self ) : <TAB>  argument_matches = ( <TAB><TAB>  ( "" pip=1.1 "" , ( "" pip "" , "" 1.1 "" ) ) , <TAB><TAB>  ( "" pip==1.1 "" , None ) , <TAB><TAB>  ( "" pip=1.2=1 "" , ( "" pip "" , "" 1.2=1 "" ) ) , <TAB>  ) <TAB>  for argument , match in argument_matches : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIsNone ( salt . utils . args . KWARG_REGEX . match ( argument ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( <TAB><TAB><TAB><TAB>  salt . utils . args . KWARG_REGEX . match ( argument ) . groups ( ) , match <TAB><TAB><TAB>  ) ",if match is None :,if match is None:,False,51.2256988146919,100.00000000000004
4297,"def _get_sidebar_selected ( self ) : <TAB>  sidebar_selected = None <TAB>  if self . businessline_id : <TAB><TAB>  sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB><TAB>  if self . service_id : <TAB><TAB><TAB>  sidebar_selected + = "" _s_ %s "" % self . service_id <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB>  return sidebar_selected ",if self . environment_id :,if self.environment_id:,False,17.03650707754558,100.00000000000004
4298,"def get_ip_info ( ipaddress ) : <TAB>  """"""Returns device information by IP address"""""" <TAB>  result = { } <TAB>  try : <TAB><TAB>  ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB>  except IPAddress . DoesNotExist : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  if ip . venture is not None : <TAB><TAB><TAB>  result [ "" venture_id "" ] = ip . venture . id <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ "" device_id "" ] = ip . device . id <TAB><TAB><TAB>  if ip . device . venture is not None : <TAB><TAB><TAB><TAB>  result [ "" venture_id "" ] = ip . device . venture . id <TAB>  return result ",if ip . device is not None :,if ip.device is not None:,False,54.9635329574227,100.00000000000004
4299,"def apply ( self , db , person ) : <TAB>  for family_handle in person . get_family_handle_list ( ) : <TAB><TAB>  family = db . get_family_from_handle ( family_handle ) <TAB><TAB>  if family : <TAB><TAB><TAB>  for event_ref in family . get_event_ref_list ( ) : <TAB><TAB><TAB><TAB>  if event_ref : <TAB><TAB><TAB><TAB><TAB>  event = db . get_event_from_handle ( event_ref . ref ) <TAB><TAB><TAB><TAB><TAB>  if not event . get_place_handle ( ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if not event . get_date_object ( ) :,if not event.get_place_handle() and event.get_place_handle(),False,48.36036121579289,93.62516102378486
4300,"def killIfDead ( ) : <TAB>  if not self . _isalive : <TAB><TAB>  self . log . debug ( <TAB><TAB><TAB>  "" WampLongPoll: killing inactive WAMP session with transport  ' {0} ' "" . format ( <TAB><TAB><TAB><TAB>  self . _transport_id <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB><TAB>  self . onClose ( False , 5000 , "" session inactive "" ) <TAB><TAB>  self . _receive . _kill ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . _parent . _transports [ self . _transport_id ] <TAB>  else : <TAB><TAB>  self . log . debug ( <TAB><TAB><TAB>  "" WampLongPoll: transport  ' {0} '  is still alive "" . format ( self . _transport_id ) <TAB><TAB>  ) <TAB><TAB>  self . _isalive = False <TAB><TAB>  self . reactor . callLater ( killAfter , killIfDead ) ",if self . _transport_id in self . _parent . _transports :,if self._transport_id in self._parent._transports:,False,57.6229915881826,100.00000000000004
4301,"def offsets ( self ) : <TAB>  offsets = { } <TAB>  offset_so_far = 0 <TAB>  for name , ty in self . fields . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  l . warning ( <TAB><TAB><TAB><TAB>  "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB><TAB><TAB><TAB>  "" element size. "" , <TAB><TAB><TAB><TAB>  self . name , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  continue <TAB><TAB>  if not self . _pack : <TAB><TAB><TAB>  align = ty . alignment <TAB><TAB><TAB>  if offset_so_far % align != 0 : <TAB><TAB><TAB><TAB>  offset_so_far + = align - offset_so_far % align <TAB><TAB>  offsets [ name ] = offset_so_far <TAB><TAB>  offset_so_far + = ty . size / / self . _arch . byte_width <TAB>  return offsets ","if isinstance ( ty , SimTypeBottom ) :",if name == self._bottom_field:,False,33.7708421583773,96.18611533792424
4302,"def get_override_css ( self ) : <TAB>  """"""handls allow_css_overrides setting."""""" <TAB>  if self . settings . get ( "" allow_css_overrides "" ) : <TAB><TAB>  filename = self . view . file_name ( ) <TAB><TAB>  filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for filetype in filetypes : <TAB><TAB><TAB><TAB>  if filename . endswith ( filetype ) : <TAB><TAB><TAB><TAB><TAB>  css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB><TAB><TAB><TAB><TAB>  if os . path . isfile ( css_filename ) : <TAB><TAB><TAB><TAB><TAB><TAB>  return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB>  return "" "" ",if filename and filetypes :,if filetypes:,False,21.872075046914,98.49292565827045
4303,"def setFullCSSSource ( self , fullsrc , inline = False ) : <TAB>  self . fullsrc = fullsrc <TAB>  if type ( self . fullsrc ) == six . binary_type : <TAB><TAB>  self . fullsrc = six . text_type ( self . fullsrc , "" utf-8 "" ) <TAB>  if inline : <TAB><TAB>  self . inline = inline <TAB>  if self . fullsrc : <TAB><TAB>  self . srcFullIdx = self . fullsrc . find ( self . src ) <TAB><TAB>  if self . srcFullIdx < 0 : <TAB><TAB><TAB>  del self . srcFullIdx <TAB><TAB>  self . ctxsrcFullIdx = self . fullsrc . find ( self . ctxsrc ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . ctxsrcFullIdx ",if self . ctxsrcFullIdx < 0 :,if self.ctxsrcFullIdx < 0:,False,50.68034301277277,100.00000000000004
4304,"def title ( self ) : <TAB>  ret = theme [ "" title "" ] <TAB>  if isinstance ( self . name , six . string_types ) : <TAB><TAB>  width = self . statwidth ( ) <TAB><TAB>  return ( <TAB><TAB><TAB>  ret + self . name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) + theme [ "" default "" ] <TAB><TAB>  ) <TAB>  for i , name in enumerate ( self . name ) : <TAB><TAB>  width = self . colwidth ( ) <TAB><TAB>  ret = ret + name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) <TAB><TAB>  if i + 1 != len ( self . vars ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret = ret + char [ "" space "" ] <TAB>  return ret ",if op . color :,if i + 1 in len(self.vars):,False,37.83229090727129,95.89781464997561
4305,"def _get_requested_databases ( self ) : <TAB>  """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB>  requested_databases = [ ] <TAB>  if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB><TAB>  for requested_namespace in self . _requested_namespaces : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return [ ] <TAB><TAB><TAB>  elif requested_namespace [ 0 ] not in IGNORE_DBS : <TAB><TAB><TAB><TAB>  requested_databases . append ( requested_namespace [ 0 ] ) <TAB>  return requested_databases ","if requested_namespace [ 0 ] is ""*"" :",if requested_namespace == self._requested_namespaces:,False,58.05958330202132,94.61097945257907
4306,"def add_channels ( cls , voucher , add_channels ) : <TAB>  for add_channel in add_channels : <TAB><TAB>  channel = add_channel [ "" channel "" ] <TAB><TAB>  defaults = { "" currency "" : channel . currency_code } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB><TAB>  if "" min_amount_spent "" in add_channel . keys ( ) : <TAB><TAB><TAB>  defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB><TAB>  models . VoucherChannelListing . objects . update_or_create ( <TAB><TAB><TAB>  voucher = voucher , <TAB><TAB><TAB>  channel = channel , <TAB><TAB><TAB>  defaults = defaults , <TAB><TAB>  ) ","if ""discount_value"" in add_channel . keys ( ) :","if ""discount_value"" in add_channel.keys():",False,51.01509261949339,100.00000000000004
4307,"def read_xml ( path ) : <TAB>  with tf . gfile . GFile ( path ) as f : <TAB><TAB>  root = etree . fromstring ( f . read ( ) ) <TAB>  annotations = { } <TAB>  for node in root . getchildren ( ) : <TAB><TAB>  key , val = node2dict ( node ) <TAB><TAB>  # If `key` is object, it's actually a list. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  annotations . setdefault ( key , [ ] ) . append ( val ) <TAB><TAB>  else : <TAB><TAB><TAB>  annotations [ key ] = val <TAB>  return annotations ","if key == ""object"" :",if key not in annotations:,False,58.63460223220702,95.84247170134864
4308,"def get_ip_info ( ipaddress ) : <TAB>  """"""Returns device information by IP address"""""" <TAB>  result = { } <TAB>  try : <TAB><TAB>  ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB>  except IPAddress . DoesNotExist : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ "" venture_id "" ] = ip . venture . id <TAB><TAB>  if ip . device is not None : <TAB><TAB><TAB>  result [ "" device_id "" ] = ip . device . id <TAB><TAB><TAB>  if ip . device . venture is not None : <TAB><TAB><TAB><TAB>  result [ "" venture_id "" ] = ip . device . venture . id <TAB>  return result ",if ip . venture is not None :,if ip.venure is not None:,False,53.59030735983207,98.77892367547223
4309,"def test_large_headers ( self ) : <TAB>  with ExpectLog ( gen_log , "" Unsatisfiable read "" , required = False ) : <TAB><TAB>  try : <TAB><TAB><TAB>  self . fetch ( "" / "" , headers = { "" X-Filler "" : "" a "" * 1000 } , raise_error = True ) <TAB><TAB><TAB>  self . fail ( "" did not raise expected exception "" ) <TAB><TAB>  except HTTPError as e : <TAB><TAB><TAB>  # 431 is ""Request Header Fields Too Large"", defined in RFC <TAB><TAB><TAB>  # 6585. However, many implementations just close the <TAB><TAB><TAB>  # connection in this case, resulting in a missing response. <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertIn ( e . response . code , ( 431 , 599 ) ) ",if e . response is not None :,"if e.response.code == (431, 599):",False,65.07678868500041,95.2121861458745
4310,"def validate_reserved_serial_no_consumption ( self ) : <TAB>  for item in self . items : <TAB><TAB>  if item . s_warehouse and not item . t_warehouse and item . serial_no : <TAB><TAB><TAB>  for sr in get_serial_nos ( item . serial_no ) : <TAB><TAB><TAB><TAB>  sales_order = frappe . db . get_value ( "" Serial No "" , sr , "" sales_order "" ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  msg = _ ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" (Serial No:  {0} ) cannot be consumed as it ' s reserverd to fullfill Sales Order  {1} . "" <TAB><TAB><TAB><TAB><TAB>  ) . format ( sr , sales_order ) <TAB><TAB><TAB><TAB><TAB>  frappe . throw ( _ ( "" Item  {0} {1} "" ) . format ( item . item_code , msg ) ) ",if sales_order :,if sales_order and (not item.s_warehouse and (not item.,False,30.925618821797478,92.96849538575793
4311,"def force_decode ( string , encoding ) : <TAB>  if isinstance ( string , str ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  string = string . decode ( encoding ) <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  # try decoding with utf-8, should only work for real UTF-8 <TAB><TAB><TAB><TAB>  string = string . decode ( "" utf-8 "" ) <TAB><TAB><TAB>  except UnicodeError : <TAB><TAB><TAB><TAB>  # last resort -- can't fail <TAB><TAB><TAB><TAB>  string = string . decode ( "" latin1 "" ) <TAB>  return string ",if encoding :,if encoding:,False,63.341965410972456,100.00000000000004
4312,"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB>  new_parameters = [ ] <TAB>  for hp in sub_cs . get_hyperparameters ( ) : <TAB><TAB>  new_parameter = copy . deepcopy ( hp ) <TAB><TAB>  # Allow for an empty top-level parameter <TAB><TAB>  if new_parameter . name == "" "" : <TAB><TAB><TAB>  new_parameter . name = prefix <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_parameter . name = "" {} {} {} "" . format ( prefix , SPLITTER , new_parameter . name ) <TAB><TAB>  new_parameters . append ( new_parameter ) <TAB>  for hp in new_parameters : <TAB><TAB>  _add_hp ( master_cs , hp ) ","elif not prefix == """" :",if new_parameter.name not in delimiter:,False,55.06945201910693,95.1007585539625
4313,"def __call__ ( self , * args , * * kwargs ) : <TAB>  if self . log_file is not None : <TAB><TAB>  kwargs [ "" file "" ] = self . log_file <TAB><TAB>  print ( * args , * * kwargs ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # get immediate feedback <TAB><TAB><TAB>  self . log_file . flush ( ) <TAB>  elif self . log_func is not None : <TAB><TAB>  self . log_func ( * args , * * kwargs ) ","if hasattr ( self . log_file , ""flush"" ) :",if self.log_file is not None:,False,43.83372854048552,93.04455322378449
4314,"def df_index_expr ( self , length_expr = None , as_range = False ) : <TAB>  """"""Generate expression to get or create index of DF"""""" <TAB>  if isinstance ( self . index , types . NoneType ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  length_expr = df_length_expr ( self ) <TAB><TAB>  if as_range : <TAB><TAB><TAB>  return f "" range( { length_expr } ) "" <TAB><TAB>  else : <TAB><TAB><TAB>  return f "" numpy.arange( { length_expr } ) "" <TAB>  return "" self._index "" ",if length_expr is None :,if length_expr is None:,False,45.65157312981643,100.00000000000004
4315,"def _setWeight ( self , value ) : <TAB>  if value is None : <TAB><TAB>  self . _fontWeight = None <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TextFormatException ( f "" Not a supported fontWeight:  { value } "" ) <TAB><TAB>  self . _fontWeight = value . lower ( ) ","if value . lower ( ) not in ( ""normal"" , ""bold"" ) :","if value not in ('0', '1'):",False,44.408887028509035,85.4717961959976
4316,"def _test_configuration ( self ) : <TAB>  config_path = self . _write_config ( ) <TAB>  try : <TAB><TAB>  self . _log . debug ( "" testing configuration "" ) <TAB><TAB>  verboseflag = "" -Q "" <TAB><TAB>  if self . _log . isEnabledFor ( logging . DEBUG ) : <TAB><TAB><TAB>  verboseflag = "" -v "" <TAB><TAB>  p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( "" configuration test failed "" ) <TAB><TAB>  self . _log . debug ( "" configuration seems ok "" ) <TAB>  finally : <TAB><TAB>  os . remove ( config_path ) ",if p . wait ( ) != 0 :,if p.returncode != 0:,False,46.59113959875213,97.647541353445
4317,"def filter_queryset ( self , request , queryset , view ) : <TAB>  kwargs = { } <TAB>  for field in view . filterset_fields : <TAB><TAB>  value = request . GET . get ( field ) <TAB><TAB>  if not value : <TAB><TAB><TAB>  continue <TAB><TAB>  if field == "" node_id "" : <TAB><TAB><TAB>  value = get_object_or_none ( Node , pk = value ) <TAB><TAB><TAB>  kwargs [ "" node "" ] = value <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  field = "" asset "" <TAB><TAB>  kwargs [ field ] = value <TAB>  if kwargs : <TAB><TAB>  queryset = queryset . filter ( * * kwargs ) <TAB>  logger . debug ( "" Filter  {} "" . format ( kwargs ) ) <TAB>  return queryset ","elif field == ""asset_id"" :","if not field in ('image', 'media'):",False,32.89567172657698,95.38739568473144
4318,"def _find_closing_brace ( string , start_pos ) : <TAB>  """"""Finds the corresponding closing brace after start_pos."""""" <TAB>  bracks_open = 1 <TAB>  for idx , char in enumerate ( string [ start_pos : ] ) : <TAB><TAB>  if char == "" ( "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  bracks_open + = 1 <TAB><TAB>  elif char == "" ) "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  bracks_open - = 1 <TAB><TAB><TAB>  if not bracks_open : <TAB><TAB><TAB><TAB>  return start_pos + idx + 1 ","if string [ idx + start_pos - 1 ] != ""\\"" :","if char == "" :",False,47.91082425013744,83.21071233266298
4319,"def _set_hostport ( self , host , port ) : <TAB>  if port is None : <TAB><TAB>  i = host . rfind ( "" : "" ) <TAB><TAB>  j = host . rfind ( "" ] "" )<TAB># ipv6 addresses have [...] <TAB><TAB>  if i > j : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  port = int ( host [ i + 1 : ] ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  raise InvalidURL ( "" nonnumeric port:  ' %s ' "" % host [ i + 1 : ] ) <TAB><TAB><TAB>  host = host [ : i ] <TAB><TAB>  else : <TAB><TAB><TAB>  port = self . default_port <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  host = host [ 1 : - 1 ] <TAB>  self . host = host <TAB>  self . port = port ","if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :",if host[-1] == '-':,False,25.342268350066817,90.51984472374863
4320,"def __getstate__ ( self ) : <TAB>  state = { } <TAB>  for cls in type ( self ) . mro ( ) : <TAB><TAB>  cls_slots = getattr ( cls , "" __slots__ "" , ( ) ) <TAB><TAB>  for slot in cls_slots : <TAB><TAB><TAB>  if slot != "" __weakref__ "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  state [ slot ] = getattr ( self , slot ) <TAB>  state [ "" _cookiejar_cookies "" ] = list ( self . cookiejar ) <TAB>  del state [ "" cookiejar "" ] <TAB>  return state ","if hasattr ( self , slot ) :","if hasattr(self, slot):",False,51.08048132207115,100.00000000000004
4321,"def _evp_pkey_from_der_traditional_key ( self , bio_data , password ) : <TAB>  key = self . _lib . d2i_PrivateKey_bio ( bio_data . bio , self . _ffi . NULL ) <TAB>  if key != self . _ffi . NULL : <TAB><TAB>  key = self . _ffi . gc ( key , self . _lib . EVP_PKEY_free ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( "" Password was given but private key is not encrypted. "" ) <TAB><TAB>  return key <TAB>  else : <TAB><TAB>  self . _consume_errors ( ) <TAB><TAB>  return None ",if password is not None :,if key != self._lib.EVP_PKEY_free:,False,29.536140577651715,91.63549050437213
4322,"def is_special ( s , i , directive ) : <TAB>  """"""Return True if the body text contains the @ directive."""""" <TAB>  # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB>  assert directive and directive [ 0 ] == "" @ "" <TAB>  # 10/23/02: all directives except @others must start the line. <TAB>  skip_flag = directive in ( "" @others "" , "" @all "" ) <TAB>  while i < len ( s ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True , i <TAB><TAB>  else : <TAB><TAB><TAB>  i = skip_line ( s , i ) <TAB><TAB><TAB>  if skip_flag : <TAB><TAB><TAB><TAB>  i = skip_ws ( s , i ) <TAB>  return False , - 1 ","if match_word ( s , i , directive ) :",if s[i] == directive:,False,63.06537092433876,94.8268498401108
4323,"def _decorator ( coro_func ) : <TAB>  fut = asyncio . ensure_future ( coro_func ( ) ) <TAB>  self . _tests . append ( ( coro_func . __name__ , fut ) ) <TAB>  if timeout_sec is not None : <TAB><TAB>  timeout_at = self . _loop . time ( ) + timeout_sec <TAB><TAB>  handle = self . MASTER_LOOP . call_at ( <TAB><TAB><TAB>  timeout_at , self . _set_exception_if_not_done , fut , asyncio . TimeoutError ( ) <TAB><TAB>  ) <TAB><TAB>  fut . add_done_callback ( lambda * args : handle . cancel ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _global_timeout_at = timeout_at <TAB>  return coro_func ",if timeout_at > self . _global_timeout_at :,if timeout_at > self._global_timeout_at:,False,51.85453622620424,100.00000000000004
4324,"def _load ( self , db , owner ) : <TAB>  self . __init ( owner ) <TAB>  db_result = db ( <TAB><TAB>  "" SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ? "" , <TAB><TAB>  self . owner . worldid , <TAB>  ) <TAB>  for ( <TAB><TAB>  ship_id , <TAB><TAB>  state_id , <TAB>  ) in db_result : <TAB><TAB>  ship = WorldObject . get_object_by_id ( ship_id ) <TAB><TAB>  state = self . shipStates [ state_id ] <TAB><TAB>  # add move callbacks corresponding to given state <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ship . add_move_callback ( Callback ( BehaviorMoveCallback . _arrived , ship ) ) <TAB><TAB>  self . add_new_unit ( ship , state ) ",if state == self . shipStates . moving :,if state == 'all':,False,61.55952398516742,97.0575059212716
4325,"def addError ( self , test , err ) : <TAB>  if err [ 0 ] is SkipTest : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . stream . writeln ( str ( err [ 1 ] ) ) <TAB><TAB>  elif self . dots : <TAB><TAB><TAB>  self . stream . write ( "" s "" ) <TAB><TAB><TAB>  self . stream . flush ( ) <TAB><TAB>  return <TAB>  _org_AddError ( self , test , err ) ",if self . showAll :,if err[1] is not None:,False,24.38688003168096,93.15913300214376
4326,"def _construct ( self , node ) : <TAB>  self . flatten_mapping ( node ) <TAB>  ret = self . construct_pairs ( node ) <TAB>  keys = [ d [ 0 ] for d in ret ] <TAB>  keys_sorted = sorted ( keys , key = _natsort_key ) <TAB>  for key in keys : <TAB><TAB>  expected = keys_sorted . pop ( 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ConstructorError ( <TAB><TAB><TAB><TAB>  None , <TAB><TAB><TAB><TAB>  None , <TAB><TAB><TAB><TAB>  "" keys out of order:  "" <TAB><TAB><TAB><TAB>  "" expected  {}  got  {}  at  {} "" . format ( expected , key , node . start_mark ) , <TAB><TAB><TAB>  ) <TAB>  return dict ( ret ) ",if key != expected :,if expected != key:,False,30.035103995340016,98.0043366542126
4327,"def sample_pos_items_for_u ( u , num ) : <TAB>  # sample num pos items for u-th user <TAB>  pos_items = self . train_items [ u ] <TAB>  n_pos_items = len ( pos_items ) <TAB>  pos_batch = [ ] <TAB>  while True : <TAB><TAB>  if len ( pos_batch ) == num : <TAB><TAB><TAB>  break <TAB><TAB>  pos_id = np . random . randint ( low = 0 , high = n_pos_items , size = 1 ) [ 0 ] <TAB><TAB>  pos_i_id = pos_items [ pos_id ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pos_batch . append ( pos_i_id ) <TAB>  return pos_batch ",if pos_i_id not in pos_batch :,if pos_i_id not in pos_batch:,False,32.51354195762426,100.00000000000004
4328,"def _get_id ( self , type , id ) : <TAB>  fields = id . split ( "" : "" ) <TAB>  if len ( fields ) > = 3 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  "" Expected id of type  %s  but found type  %s %s "" , type , fields [ - 2 ] , id <TAB><TAB><TAB>  ) <TAB><TAB>  return fields [ - 1 ] <TAB>  fields = id . split ( "" / "" ) <TAB>  if len ( fields ) > = 3 : <TAB><TAB>  itype = fields [ - 2 ] <TAB><TAB>  if type != itype : <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  "" Expected id of type  %s  but found type  %s %s "" , type , itype , id <TAB><TAB><TAB>  ) <TAB><TAB>  return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB>  return id ",if type != fields [ - 2 ] :,if type != fields[-2]:,False,56.899090716327095,94.51768053402681
4329,"def uninstall_environments ( self , environments ) : <TAB>  environments = [ <TAB><TAB>  env <TAB><TAB>  if not env . startswith ( self . conda_context . envs_path ) <TAB><TAB>  else os . path . basename ( env ) <TAB><TAB>  for env in environments <TAB>  ] <TAB>  return_codes = [ self . conda_context . exec_remove ( [ env ] ) for env in environments ] <TAB>  final_return_code = 0 <TAB>  for env , return_code in zip ( environments , return_codes ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . debug ( "" Conda environment  ' %s '  successfully removed. "" % env ) <TAB><TAB>  else : <TAB><TAB><TAB>  log . debug ( "" Conda environment  ' %s '  could not be removed. "" % env ) <TAB><TAB><TAB>  final_return_code = return_code <TAB>  return final_return_code ",if return_code == 0 :,if env in self.conda_context.envs_path:,False,29.76931083819543,91.90759484860898
4330,"def _add_hit_offset ( self , context_list , string_name , original_offset , value ) : <TAB>  for context in context_list : <TAB><TAB>  hits_by_context_dict = self . hits_by_context . setdefault ( context , { } ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  hits_by_context_dict [ string_name ] = ( <TAB><TAB><TAB><TAB>  original_offset , <TAB><TAB><TAB><TAB>  value . encode ( "" base64 "" ) , <TAB><TAB><TAB>  ) ",if string_name not in hits_by_context_dict :,if hits_by_context_dict.get(string_name) is not None:,False,34.1233919954159,92.80925852113288
4331,"def detab ( self , text , length = None ) : <TAB>  """"""Remove a tab from the front of each line of the given text."""""" <TAB>  if length is None : <TAB><TAB>  length = self . tab_length <TAB>  newtext = [ ] <TAB>  lines = text . split ( "" \n "" ) <TAB>  for line in lines : <TAB><TAB>  if line . startswith ( "" "" * length ) : <TAB><TAB><TAB>  newtext . append ( line [ length : ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  newtext . append ( "" "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  return "" \n "" . join ( newtext ) , "" \n "" . join ( lines [ len ( newtext ) : ] ) ",elif not line . strip ( ) :,if len(newtext) == 0:,False,59.03809531160103,95.45592906869946
4332,"def dump ( self ) : <TAB>  print ( self . package_name ) <TAB>  for package , value in self . entries : <TAB><TAB>  print ( str ( package . version ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( ""<TAB> [FILTERED] "" ) <TAB><TAB>  elif isinstance ( value , list ) : <TAB><TAB><TAB>  variants = value <TAB><TAB><TAB>  for variant in variants : <TAB><TAB><TAB><TAB>  print ( ""<TAB>  %s "" % str ( variant ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( ""<TAB>  %s "" % str ( package ) ) ",if value is None :,if package.filter:,False,49.36648477657416,97.38472235428932
4333,"def __lexical_scope ( * args , * * kwargs ) : <TAB>  try : <TAB><TAB>  scope = Scope ( quasi ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  binding_name_set_stack [ - 1 ] . add_child ( scope ) <TAB><TAB>  binding_name_set_stack . append ( scope ) <TAB><TAB>  return func ( * args , * * kwargs ) <TAB>  finally : <TAB><TAB>  if binding_name_set_stack [ - 1 ] is scope : <TAB><TAB><TAB>  binding_name_set_stack . pop ( ) ",if quasi :,if not binding_name_set_stack[-1].is_child(scope):,False,18.04358410234307,85.14002425746858
4334,"def getnotes ( self , origin = None ) : <TAB>  if origin is None : <TAB><TAB>  result = self . translator_comments <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if result : <TAB><TAB><TAB><TAB>  result + = "" \n "" + self . developer_comments <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  result = self . developer_comments <TAB><TAB>  return result <TAB>  elif origin == "" translator "" : <TAB><TAB>  return self . translator_comments <TAB>  elif origin in ( "" programmer "" , "" developer "" , "" source code "" ) : <TAB><TAB>  return self . developer_comments <TAB>  else : <TAB><TAB>  raise ValueError ( "" Comment type not valid "" ) ",if self . developer_comments :,"if origin == ""translator':",False,17.34744759419426,96.6528570310074
4335,"def fix_datetime_fields ( data : TableData , table : TableName ) - > None : <TAB>  for item in data [ table ] : <TAB><TAB>  for field_name in DATE_FIELDS [ table ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  item [ field_name ] = datetime . datetime . fromtimestamp ( <TAB><TAB><TAB><TAB><TAB>  item [ field_name ] , tz = datetime . timezone . utc <TAB><TAB><TAB><TAB>  ) ",if item [ field_name ] is not None :,if field_name not in item:,False,48.11345337996457,93.58734957034305
4336,"def _check_for_cart_error ( cart ) : <TAB>  if cart . _safe_get_element ( "" Cart.Request.Errors "" ) is not None : <TAB><TAB>  error = cart . _safe_get_element ( "" Cart.Request.Errors.Error.Code "" ) . text <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise CartInfoMismatchException ( <TAB><TAB><TAB><TAB>  "" CartGet failed: AWS.ECommerceService.CartInfoMismatch  "" <TAB><TAB><TAB><TAB>  "" make sure AssociateTag, CartId and HMAC are correct  "" <TAB><TAB><TAB><TAB>  "" (dont use URLEncodedHMAC!!!) "" <TAB><TAB><TAB>  ) <TAB><TAB>  raise CartException ( "" CartGet failed:  "" + error ) ","if error == ""AWS.ECommerceService.CartInfoMismatch"" :",if error != 'Error':,False,60.14765547572313,94.61571989566279
4337,"def check_bounds ( geometry ) : <TAB>  if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB><TAB>  return list ( map ( check_bounds , geometry ) ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Longitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB>  ) <TAB><TAB>  if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" Latitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB>  ) ",if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,if geometry[0] > 90 or geometry[0] < -90:,False,66.14861369072128,96.63011956401645
4338,"def _mapper_output_protocol ( self , step_num , step_map ) : <TAB>  map_key = self . _step_key ( step_num , "" mapper "" ) <TAB>  if map_key in step_map : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . output_protocol ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  return self . internal_protocol ( ) <TAB>  else : <TAB><TAB>  # mapper is not a script substep, so protocols don't apply at all <TAB><TAB>  return RawValueProtocol ( ) ",if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,if step_num == 1:,False,58.42390420905046,87.53428992232985
4339,"def asset ( * paths ) : <TAB>  for path in paths : <TAB><TAB>  fspath = www_root + "" /assets/ "" + path <TAB><TAB>  etag = "" "" <TAB><TAB>  try : <TAB><TAB><TAB>  if env . cache_static : <TAB><TAB><TAB><TAB>  etag = asset_etag ( fspath ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  os . stat ( fspath ) <TAB><TAB>  except FileNotFoundError as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if not os . path . exists ( fspath + "" .spt "" ) : <TAB><TAB><TAB><TAB><TAB>  tell_sentry ( e , { } ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  tell_sentry ( e , { } ) <TAB><TAB>  return asset_url + path + ( etag and "" ?etag= "" + etag ) ",if path == paths [ - 1 ] :,if e.errno == errno.ENOENT:,False,52.52189457727236,96.80690029927995
4340,"def ping ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB>  if self . trace_enabled and self . ping_pong_trace_enabled : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  payload = payload . decode ( "" utf-8 "" ) <TAB><TAB>  self . logger . debug ( <TAB><TAB><TAB>  "" Sending a ping data frame  "" <TAB><TAB><TAB>  f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB><TAB>  ) <TAB>  data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PING ) <TAB>  with self . sock_send_lock : <TAB><TAB>  self . sock . send ( data ) ","if isinstance ( payload , bytes ) :","if isinstance(payload, str):",False,24.544831751151154,98.66121287187084
4341,"def is_ac_power_connected ( ) : <TAB>  for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB><TAB><TAB><TAB>  if f . read ( ) . strip ( ) != "" Mains "" : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB>  except IOError : <TAB><TAB><TAB>  continue <TAB>  return False ","if f . read ( 1 ) == ""1"" :",if f.read() == '1.0.0.0' and f.read,False,22.23604916110233,96.25900279070481
4342,"def handle_noargs ( self , * * options ) : <TAB>  self . style = color_style ( ) <TAB>  print ( "" Running Django ' s own validation: "" ) <TAB>  self . validate ( display_num_errors = True ) <TAB>  for model in loading . get_models ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . validate_base_model ( model ) <TAB><TAB>  if hasattr ( model , "" _feincms_content_models "" ) : <TAB><TAB><TAB>  self . validate_content_type ( model ) ","if hasattr ( model , ""_create_content_base"" ) :","if hasattr(model, '_base_model'):",False,49.45909197389631,92.34256078648441
4343,"def _init_weights ( self , module ) : <TAB>  if isinstance ( module , nn . Linear ) : <TAB><TAB>  module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module . bias . data . zero_ ( ) <TAB>  elif isinstance ( module , nn . Embedding ) : <TAB><TAB>  module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB>  if module . padding_idx is not None : <TAB><TAB><TAB>  module . weight . data [ module . padding_idx ] . zero_ ( ) ",if module . bias is not None :,"if isinstance(module, nn.Linear):",False,24.97106804320859,94.70763619955976
4344,"def walk ( msg , callback , data ) : <TAB>  partnum = 0 <TAB>  for part in msg . walk ( ) : <TAB><TAB>  # multipart/* are just containers <TAB><TAB>  if part . get_content_maintype ( ) == "" multipart "" : <TAB><TAB><TAB>  continue <TAB><TAB>  ctype = part . get_content_type ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ctype = OCTET_TYPE <TAB><TAB>  filename = part . get_filename ( ) <TAB><TAB>  if not filename : <TAB><TAB><TAB>  filename = PART_FN_TPL % ( partnum ) <TAB><TAB>  headers = dict ( part ) <TAB><TAB>  LOG . debug ( headers ) <TAB><TAB>  headers [ "" Content-Type "" ] = ctype <TAB><TAB>  payload = util . fully_decoded_payload ( part ) <TAB><TAB>  callback ( data , filename , payload , headers ) <TAB><TAB>  partnum = partnum + 1 ",if ctype is None :,if not ctype:,False,54.16353152522686,98.2370860817818
4345,"def _mark_lcs ( mask , dirs , m , n ) : <TAB>  while m != 0 and n != 0 : <TAB><TAB>  if dirs [ m , n ] == "" | "" : <TAB><TAB><TAB>  m - = 1 <TAB><TAB><TAB>  n - = 1 <TAB><TAB><TAB>  mask [ m ] = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  m - = 1 <TAB><TAB>  elif dirs [ m , n ] == "" < "" : <TAB><TAB><TAB>  n - = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  raise UnboundLocalError ( "" Illegal move "" ) <TAB>  return mask ","elif dirs [ m , n ] == ""^"" :","if dirs[m, n] == "" >':",False,22.426227458600028,96.67838636911547
4346,"def valid_localparts ( strip_delimiters = False ) : <TAB>  for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB>  # strip line, skip over empty lines <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over comments or empty lines <TAB><TAB>  match = COMMENT . match ( line ) <TAB><TAB>  if match : <TAB><TAB><TAB>  continue <TAB><TAB>  # skip over localparts with delimiters <TAB><TAB>  if strip_delimiters : <TAB><TAB><TAB>  if "" , "" in line or "" ; "" in line : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield line ","if line == """" :",if not line:,False,60.83891967643851,96.77919916258331
4347,"def fetch ( self , * tileables , * * kw ) : <TAB>  ret_list = False <TAB>  if len ( tileables ) == 1 and isinstance ( tileables [ 0 ] , ( tuple , list ) ) : <TAB><TAB>  ret_list = True <TAB><TAB>  tileables = tileables [ 0 ] <TAB>  elif len ( tileables ) > 1 : <TAB><TAB>  ret_list = True <TAB>  result = self . _sess . fetch ( * tileables , * * kw ) <TAB>  ret = [ ] <TAB>  for r , t in zip ( result , tileables ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret . append ( r . item ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  ret . append ( r ) <TAB>  if ret_list : <TAB><TAB>  return ret <TAB>  return ret [ 0 ] ","if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :",if t == 'tile':,False,19.2527615521024,87.32093661366586
4348,"def _convert ( container ) : <TAB>  if _value_marker in container : <TAB><TAB>  force_list = False <TAB><TAB>  values = container . pop ( _value_marker ) <TAB><TAB>  if container . pop ( _list_marker , False ) : <TAB><TAB><TAB>  force_list = True <TAB><TAB><TAB>  values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  values = values [ 0 ] <TAB><TAB>  if not container : <TAB><TAB><TAB>  return values <TAB><TAB>  return _convert ( container ) <TAB>  elif container . pop ( _list_marker , False ) : <TAB><TAB>  return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB>  return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) ) ",if not force_list and len ( values ) == 1 :,if force_list:,False,23.90188709612691,95.13897370932897
4349,"def _transform_init_kwargs ( cls , kwargs ) : <TAB>  transformed = [ ] <TAB>  for field in list ( kwargs . keys ( ) ) : <TAB><TAB>  prop = getattr ( cls , field , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = kwargs . pop ( field ) <TAB><TAB><TAB>  _transform_single_init_kwarg ( prop , field , value , kwargs ) <TAB><TAB><TAB>  transformed . append ( ( field , value ) ) <TAB>  return transformed ","if isinstance ( prop , MoneyProperty ) :",if prop is not None:,False,31.86910161040682,94.43293303420751
4350,"def haslayer ( self , cls ) : <TAB>  """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB>  if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB><TAB>  return 1 <TAB>  for f in self . packetfields : <TAB><TAB>  fvalue_gen = self . getfieldval ( f . name ) <TAB><TAB>  if fvalue_gen is None : <TAB><TAB><TAB>  continue <TAB><TAB>  if not f . islist : <TAB><TAB><TAB>  fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB><TAB>  for fvalue in fvalue_gen : <TAB><TAB><TAB>  if isinstance ( fvalue , Packet ) : <TAB><TAB><TAB><TAB>  ret = fvalue . haslayer ( cls ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return ret <TAB>  return self . payload . haslayer ( cls ) ",if ret :,if ret:,False,63.594010374300055,100.00000000000004
4351,def insert_broken_add_sometimes ( node ) : <TAB>  if node . op == theano . tensor . add : <TAB><TAB>  last_time_replaced [ 0 ] = not last_time_replaced [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ off_by_half ( * node . inputs ) ] <TAB>  return False ,if last_time_replaced [ 0 ] :,if node.op == theano.tensor.add:,False,20.77359189463315,87.93296470139556
4352,"def testReadChunk10 ( self ) : <TAB>  # ""Test BZ2File.read() in chunks of 10 bytes"" <TAB>  self . createTempFile ( ) <TAB>  with BZ2File ( self . filename ) as bz2f : <TAB><TAB>  text = "" "" <TAB><TAB>  while 1 : <TAB><TAB><TAB>  str = bz2f . read ( 10 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  text + = str <TAB><TAB>  self . assertEqual ( text , self . TEXT ) ",if not str :,if not str:,False,33.55643314540081,100.00000000000004
4353,"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB>  # This part of function creates faces in SV format <TAB>  # It ignores  boundless super face <TAB>  sv_faces = [ ] <TAB>  for i , face in enumerate ( dcel_mesh . faces ) : <TAB><TAB>  if face . inners and face . outer : <TAB><TAB><TAB>  "" Face ( {} ) has inner components! Sverchok cant show polygons with holes. "" . format ( <TAB><TAB><TAB><TAB>  i <TAB><TAB><TAB>  ) <TAB><TAB>  if not face . outer or del_flag in face . flags : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  sv_faces . append ( [ point_index [ hedge . origin ] for hedge in face . outer . loop_hedges ] ) <TAB>  return sv_faces ",if only_select and not face . select :,if only_select:,False,63.26728187535857,97.57817036240043
4354,"def __check_dict_contains ( dct , dict_name , keys , comment = "" "" , result = True ) : <TAB>  for key in keys : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = False <TAB><TAB><TAB>  comment = __append_comment ( <TAB><TAB><TAB><TAB>  "" Missing  {0}  in  {1} "" . format ( key , dict_name ) , comment <TAB><TAB><TAB>  ) <TAB>  return result , comment ",if key not in six . iterkeys ( dct ) :,if key not in dct:,False,44.65890086153743,94.35528926218211
4355,"def _dump_arg_defaults ( kwargs ) : <TAB>  """"""Inject default arguments for dump functions."""""" <TAB>  if current_app : <TAB><TAB>  kwargs . setdefault ( "" cls "" , current_app . json_encoder ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs . setdefault ( "" ensure_ascii "" , False ) <TAB><TAB>  kwargs . setdefault ( "" sort_keys "" , current_app . config [ "" JSON_SORT_KEYS "" ] ) <TAB>  else : <TAB><TAB>  kwargs . setdefault ( "" sort_keys "" , True ) <TAB><TAB>  kwargs . setdefault ( "" cls "" , JSONEncoder ) ","if not current_app . config [ ""JSON_AS_ASCII"" ] :",if 'ensure_ascii' in kwargs:,False,26.181113129082007,90.28466169260494
4356,"def _on_change ( self ) : <TAB>  changed = False <TAB>  self . save ( ) <TAB>  for key , value in self . data . items ( ) : <TAB><TAB>  if isinstance ( value , bool ) : <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB>  if value != 1 : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  elif value is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  changed = True <TAB><TAB><TAB>  break <TAB>  self . _reset_button . disabled = not changed ",elif len ( value ) != 0 :,if key == 'value':,False,44.527833784308434,95.79911009123887
4357,"def parse_win_proxy ( val ) : <TAB>  proxies = [ ] <TAB>  for p in val . split ( "" ; "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tab = p . split ( "" = "" , 1 ) <TAB><TAB><TAB>  if tab [ 0 ] == "" socks "" : <TAB><TAB><TAB><TAB>  tab [ 0 ] = "" SOCKS4 "" <TAB><TAB><TAB>  proxies . append ( <TAB><TAB><TAB><TAB>  ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB><TAB><TAB>  )<TAB># type, addr:port, username, password <TAB><TAB>  else : <TAB><TAB><TAB>  proxies . append ( ( "" HTTP "" , p , None , None ) ) <TAB>  return proxies ","if ""="" in p :",if p.startswith('http'):,False,21.49504793836213,94.40305645502967
4358,"def predict ( collect_dir , keys ) : <TAB>  run_all = len ( keys ) == 0 <TAB>  validate_keys ( keys ) <TAB>  for exp_cfg in cfg : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  key = exp_cfg [ "" key "" ] <TAB><TAB><TAB>  _predict ( key , exp_cfg [ "" sample_img "" ] , collect_dir ) ","if run_all or exp_cfg [ ""key"" ] in keys :",if run_all:,False,43.02648984067582,88.41979540747391
4359,"def convert_port_bindings ( port_bindings ) : <TAB>  result = { } <TAB>  for k , v in six . iteritems ( port_bindings ) : <TAB><TAB>  key = str ( k ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  key + = "" /tcp "" <TAB><TAB>  if isinstance ( v , list ) : <TAB><TAB><TAB>  result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB><TAB>  else : <TAB><TAB><TAB>  result [ key ] = [ _convert_port_binding ( v ) ] <TAB>  return result ","if ""/"" not in key :","if key not in ('tcp', 'tcp'):",False,36.61342446502703,94.64941408721054
4360,"def assert_conll_writer_output ( <TAB>  dataset : InternalBioNerDataset , <TAB>  expected_output : List [ str ] , <TAB>  sentence_splitter : SentenceSplitter = None ,  ) : <TAB>  outfile_path = tempfile . mkstemp ( ) [ 1 ] <TAB>  try : <TAB><TAB>  sentence_splitter = ( <TAB><TAB><TAB>  sentence_splitter <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  else NoSentenceSplitter ( tokenizer = SpaceTokenizer ( ) ) <TAB><TAB>  ) <TAB><TAB>  writer = CoNLLWriter ( sentence_splitter = sentence_splitter ) <TAB><TAB>  writer . write_to_conll ( dataset , Path ( outfile_path ) ) <TAB><TAB>  contents = [ l . strip ( ) for l in open ( outfile_path ) . readlines ( ) if l . strip ( ) ] <TAB>  finally : <TAB><TAB>  os . remove ( outfile_path ) <TAB>  assert contents == expected_output ",if sentence_splitter,if sentence_splitter is None:,False,26.085001145766558,98.01823360034749
4361,"def post ( self , request , * args , * * kwargs ) : <TAB>  self . comment_obj = get_object_or_404 ( Comment , id = request . POST . get ( "" commentid "" ) ) <TAB>  if request . user == self . comment_obj . commented_by : <TAB><TAB>  form = LeadCommentForm ( request . POST , instance = self . comment_obj ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . form_valid ( form ) <TAB><TAB>  return self . form_invalid ( form ) <TAB>  data = { "" error "" : "" You don ' t have permission to edit this comment. "" } <TAB>  return JsonResponse ( data ) ",if form . is_valid ( ) :,if form.is_valid():,False,53.30172595784981,97.29022123376937
4362,"def trivia_list ( self , ctx : commands . Context ) : <TAB>  """"""List available trivia categories."""""" <TAB>  lists = set ( p . stem for p in self . _all_lists ( ) ) <TAB>  if await ctx . embed_requested ( ) : <TAB><TAB>  await ctx . send ( <TAB><TAB><TAB>  embed = discord . Embed ( <TAB><TAB><TAB><TAB>  title = _ ( "" Available trivia lists "" ) , <TAB><TAB><TAB><TAB>  colour = await ctx . embed_colour ( ) , <TAB><TAB><TAB><TAB>  description = "" ,  "" . join ( sorted ( lists ) ) , <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  msg = box ( bold ( _ ( "" Available trivia lists "" ) ) + "" \n \n "" + "" ,  "" . join ( sorted ( lists ) ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await ctx . author . send ( msg ) <TAB><TAB>  else : <TAB><TAB><TAB>  await ctx . send ( msg ) ",if len ( msg ) > 1000 :,if ctx.author:,False,36.28540163862483,97.3045008075351
4363,"def validate ( self ) : <TAB>  result = validators . SUCCESS <TAB>  msgs = [ ] <TAB>  for validator in self . _validators : <TAB><TAB>  res , err = validator . validate ( ) <TAB><TAB>  if res == validators . ERROR : <TAB><TAB><TAB>  result = res <TAB><TAB>  elif res == validators . WARNING and result != validators . ERROR : <TAB><TAB><TAB>  result = res <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msgs . append ( err ) <TAB>  return result , "" \n "" . join ( msgs ) ",if len ( err ) > 0 :,if err:,False,22.31740641224546,95.08269359351797
4364,"def get_code ( self , fullname = None ) : <TAB>  fullname = self . _fix_name ( fullname ) <TAB>  if self . code is None : <TAB><TAB>  mod_type = self . etc [ 2 ] <TAB><TAB>  if mod_type == imp . PY_SOURCE : <TAB><TAB><TAB>  source = self . get_source ( fullname ) <TAB><TAB><TAB>  self . code = compile ( source , self . filename , "" exec "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _reopen ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . code = read_code ( self . file ) <TAB><TAB><TAB>  finally : <TAB><TAB><TAB><TAB>  self . file . close ( ) <TAB><TAB>  elif mod_type == imp . PKG_DIRECTORY : <TAB><TAB><TAB>  self . code = self . _get_delegate ( ) . get_code ( ) <TAB>  return self . code ",elif mod_type == imp . PY_COMPILED :,if mod_type == imp.PKG_FILE:,False,33.488186548915955,97.41927623051964
4365,"def flush_file ( self , key , f ) : <TAB>  f . flush ( ) <TAB>  if self . compress : <TAB><TAB>  f . compress = zlib . compressobj ( <TAB><TAB><TAB>  9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB><TAB>  ) <TAB>  if len ( self . files ) > self . MAX_OPEN_FILES : <TAB><TAB>  if self . compress : <TAB><TAB><TAB>  open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  f . fileobj . close ( ) <TAB><TAB><TAB><TAB>  f . fileobj = None <TAB><TAB>  else : <TAB><TAB><TAB>  f . close ( ) <TAB><TAB><TAB>  self . files . pop ( key ) ",if open_files > self . MAX_OPEN_FILES :,if open_files:,False,46.025383766922836,94.9351794611887
4366,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add_version ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 0:,False,46.452429171598006,97.7421864143982
4367,"def init_author_file ( self ) : <TAB>  self . author_map = { } <TAB>  if self . ui . config ( "" git "" , "" authors "" ) : <TAB><TAB>  f = open ( self . repo . wjoin ( self . ui . config ( "" git "" , "" authors "" ) ) ) <TAB><TAB>  try : <TAB><TAB><TAB>  for line in f : <TAB><TAB><TAB><TAB>  line = line . strip ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  from_ , to = RE_AUTHOR_FILE . split ( line , 2 ) <TAB><TAB><TAB><TAB>  self . author_map [ from_ ] = to <TAB><TAB>  finally : <TAB><TAB><TAB>  f . close ( ) ","if not line or line . startswith ( ""#"" ) :",if not line:,False,29.965143064207805,95.3079736802885
4368,"def decode_imsi ( self , imsi ) : <TAB>  new_imsi = "" "" <TAB>  for a in imsi : <TAB><TAB>  c = hex ( a ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_imsi + = str ( c [ 3 ] ) + str ( c [ 2 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  new_imsi + = str ( c [ 2 ] ) + "" 0 "" <TAB>  mcc = new_imsi [ 1 : 4 ] <TAB>  mnc = new_imsi [ 4 : 6 ] <TAB>  return new_imsi , mcc , mnc ",if len ( c ) == 4 :,if c[1] == '0':,False,27.251424058795266,95.02587043008413
4369,"def _get_infoset ( self , prefname ) : <TAB>  """"""Return methods with the name starting with prefname."""""" <TAB>  infoset = [ ] <TAB>  excludes = ( "" %s infoset "" % prefname , ) <TAB>  preflen = len ( prefname ) <TAB>  for name in dir ( self . __class__ ) : <TAB><TAB>  if name . startswith ( prefname ) and name not in excludes : <TAB><TAB><TAB>  member = getattr ( self . __class__ , name ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  infoset . append ( name [ preflen : ] . replace ( "" _ "" , "" "" ) ) <TAB>  return infoset ","if isinstance ( member , MethodType ) :",if member is not None and member.is_known():,False,28.53968550292793,91.2408638492396
4370,"def skip_to_close_match ( self ) : <TAB>  nestedCount = 1 <TAB>  while 1 : <TAB><TAB>  tok = self . tokenizer . get_next_token ( ) <TAB><TAB>  ttype = tok [ "" style "" ] <TAB><TAB>  if ttype == SCE_PL_UNUSED : <TAB><TAB><TAB>  return <TAB><TAB>  elif self . classifier . is_index_op ( tok ) : <TAB><TAB><TAB>  tval = tok [ "" text "" ] <TAB><TAB><TAB>  if self . opHash . has_key ( tval ) : <TAB><TAB><TAB><TAB>  if self . opHash [ tval ] [ 1 ] == 1 : <TAB><TAB><TAB><TAB><TAB>  nestedCount + = 1 <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  nestedCount - = 1 <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  break ",if nestedCount <= 0 :,if nestedCount == 0:,False,47.5978426960902,99.02625212595507
4371,"def findMarkForUnitTestNodes ( self ) : <TAB>  """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB>  c = self . c <TAB>  p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB>  while p : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p . moveToNodeAfterTree ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  seen . append ( p . v ) <TAB><TAB><TAB>  if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB><TAB><TAB><TAB>  p . moveToNodeAfterTree ( ) <TAB><TAB><TAB>  elif p . h . startswith ( "" @mark-for-unit-tests "" ) : <TAB><TAB><TAB><TAB>  result . append ( p . copy ( ) ) <TAB><TAB><TAB><TAB>  p . moveToNodeAfterTree ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  p . moveToThreadNext ( ) <TAB>  return result ",if p . v in seen :,if p.v == '@mark-for-unit-tests':,False,55.32300271612858,97.43285218418984
4372,"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB>  cleaned_parts = [ ] <TAB>  for earlier in earlier_parts : <TAB><TAB>  earlier_part = earlier [ "" part "" ] <TAB><TAB>  earlier_step = earlier [ "" step "" ] <TAB><TAB>  found = False <TAB><TAB>  for current in current_parts : <TAB><TAB><TAB>  if earlier_part == current [ "" part "" ] and earlier_step == current [ "" step "" ] : <TAB><TAB><TAB><TAB>  found = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB>  self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB>  for expected in expected_parts : <TAB><TAB>  self . assertThat ( cleaned_parts , Contains ( expected ) , hint ) ",if not found :,if found:,False,47.96030496596254,99.00452376088816
4373,"def unmark_first_parents ( event = None ) : <TAB>  """"""Mark the node and all its parents."""""" <TAB>  c = event . get ( "" c "" ) <TAB>  if not c : <TAB><TAB>  return <TAB>  changed = [ ] <TAB>  for parent in c . p . self_and_parents ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parent . v . clearMarked ( ) <TAB><TAB><TAB>  parent . setAllAncestorAtFileNodesDirty ( ) <TAB><TAB><TAB>  changed . append ( parent . copy ( ) ) <TAB>  if changed : <TAB><TAB>  # g.es(""unmarked: "" + ', '.join([z.h for z in changed])) <TAB><TAB>  c . setChanged ( ) <TAB><TAB>  c . redraw ( ) <TAB>  return changed ",if parent . isMarked ( ) :,if parent.v:,False,61.58440336378687,97.82913368556432
4374,"def stop ( self ) : <TAB>  self . _log ( "" Monitor stop "" ) <TAB>  self . _stop_requested = True <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fd = os . open ( self . fifo_path , os . O_WRONLY ) <TAB><TAB><TAB>  os . write ( fd , b "" X "" ) <TAB><TAB><TAB>  os . close ( fd ) <TAB>  except Exception as e : <TAB><TAB>  self . _log ( "" err while closing:  {0} "" . format ( str ( e ) ) ) <TAB>  if self . _thread : <TAB><TAB>  self . _thread . join ( ) <TAB><TAB>  self . _thread = None ",if os . path . exists ( self . fifo_path ) :,if os.path.exists(self.fifo_path):,False,34.89294669934092,100.00000000000004
4375,"def DeleteEmptyCols ( self ) : <TAB>  cols2delete = [ ] <TAB>  for c in range ( 0 , self . GetCols ( ) ) : <TAB><TAB>  f = True <TAB><TAB>  for r in range ( 0 , self . GetRows ( ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  f = False <TAB><TAB>  if f : <TAB><TAB><TAB>  cols2delete . append ( c ) <TAB>  for i in range ( 0 , len ( cols2delete ) ) : <TAB><TAB>  self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB><TAB>  cols2delete = [ x - 1 for x in cols2delete ] ","if self . FindItemAtPosition ( ( r , c ) ) is not None :",if c == r:,False,40.919684941470805,91.68443120244983
4376,"def _load_objects ( self , obj_id_zset , limit , chunk_size = 1000 ) : <TAB>  ct = i = 0 <TAB>  while True : <TAB><TAB>  id_chunk = obj_id_zset [ i : i + chunk_size ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  i + = chunk_size <TAB><TAB>  for raw_data in self . _data [ id_chunk ] : <TAB><TAB><TAB>  if not raw_data : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if self . _use_json : <TAB><TAB><TAB><TAB>  yield json . loads ( decode ( raw_data ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield raw_data <TAB><TAB><TAB>  ct + = 1 <TAB><TAB><TAB>  if limit and ct == limit : <TAB><TAB><TAB><TAB>  return ",if not id_chunk :,if id_chunk == limit:,False,27.960030666316847,97.64377344788845
4377,"def _convert_example ( example , use_bfloat16 ) : <TAB>  """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB>  for key in list ( example . keys ( ) ) : <TAB><TAB>  val = example [ key ] <TAB><TAB>  if tf . keras . backend . is_sparse ( val ) : <TAB><TAB><TAB>  val = tf . sparse . to_dense ( val ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = tf . cast ( val , tf . int32 ) <TAB><TAB>  if use_bfloat16 and val . dtype == tf . float32 : <TAB><TAB><TAB>  val = tf . cast ( val , tf . bfloat16 ) <TAB><TAB>  example [ key ] = val ",if val . dtype == tf . int64 :,if use_bfloat16 and val.dtype == tf.int32:,False,36.357641867487715,95.89414846700805
4378,"def print_callees ( self , * amount ) : <TAB>  width , list = self . get_print_list ( amount ) <TAB>  if list : <TAB><TAB>  self . calc_callees ( ) <TAB><TAB>  self . print_call_heading ( width , "" called... "" ) <TAB><TAB>  for func in list : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . print_call_line ( width , func , self . all_callees [ func ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . print_call_line ( width , func , { } ) <TAB><TAB>  print >> self . stream <TAB><TAB>  print >> self . stream <TAB>  return self ",if func in self . all_callees :,if func in self.all_callees:,False,51.19079159528543,100.00000000000004
4379,"def on_task_input ( self , task , config ) : <TAB>  if config is False : <TAB><TAB>  return <TAB>  for entry in task . entries : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log_once ( <TAB><TAB><TAB><TAB>  "" Corrected ` %s ` url (replaced &amp; with &) "" % entry [ "" title "" ] , <TAB><TAB><TAB><TAB>  logger = log , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  entry [ "" url "" ] = entry [ "" url "" ] . replace ( "" &amp; "" , "" & "" ) ","if ""&amp;"" in entry [ ""url"" ] :",if entry['title'] == self.title:,False,49.876402358676955,93.48084250150781
4380,"def function ( self , inputs , outputs , ignore_empty = False ) : <TAB>  f = function ( inputs , outputs , mode = self . mode ) <TAB>  if self . mode is not None or theano . config . mode != "" FAST_COMPILE "" : <TAB><TAB>  topo = f . maker . fgraph . toposort ( ) <TAB><TAB>  topo_ = [ node for node in topo if not isinstance ( node . op , self . ignore_topo ) ] <TAB><TAB>  if ignore_empty : <TAB><TAB><TAB>  assert len ( topo_ ) < = 1 , topo_ <TAB><TAB>  else : <TAB><TAB><TAB>  assert len ( topo_ ) == 1 , topo_ <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert type ( topo_ [ 0 ] . op ) is self . op <TAB>  return f ",if len ( topo_ ) > 0 :,if topo_:,False,26.6993511764597,96.24407236344189
4381,"def _get_env_command ( self ) - > Sequence [ str ] : <TAB>  """"""Get command sequence for `env` with configured flags."""""" <TAB>  env_list = [ "" env "" ] <TAB>  # Pass through configurable environment variables. <TAB>  for key in [ "" http_proxy "" , "" https_proxy "" ] : <TAB><TAB>  value = self . build_provider_flags . get ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # Ensure item is treated as string and append it. <TAB><TAB>  value = str ( value ) <TAB><TAB>  env_list . append ( f "" { key } = { value } "" ) <TAB>  return env_list ",if not value :,if value is None:,False,52.35129807917712,97.59672148034194
4382,"def _compare_single_run ( self , compares_done ) : <TAB>  try : <TAB><TAB>  compare_id , redo = self . in_queue . get ( <TAB><TAB><TAB>  timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB><TAB>  ) <TAB>  except Empty : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB><TAB><TAB>  if redo : <TAB><TAB><TAB><TAB>  self . db_interface . delete_old_compare_result ( compare_id ) <TAB><TAB><TAB>  compares_done . add ( compare_id ) <TAB><TAB><TAB>  self . _process_compare ( compare_id ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . callback ( ) ",if self . callback :,if self.callback:,False,51.2508146608406,100.00000000000004
4383,"def clean ( self ) : <TAB>  # TODO: check for clashes if the random code is already taken <TAB>  if not self . code : <TAB><TAB>  self . code = u "" static- %s "" % uuid . uuid4 ( ) <TAB>  if not self . site : <TAB><TAB>  placeholders = StaticPlaceholder . objects . filter ( <TAB><TAB><TAB>  code = self . code , site__isnull = True <TAB><TAB>  ) <TAB><TAB>  if self . pk : <TAB><TAB><TAB>  placeholders = placeholders . exclude ( pk = self . pk ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB>  _ ( "" A static placeholder with the same site and code already exists "" ) <TAB><TAB><TAB>  ) ",if placeholders . exists ( ) :,if not placeholders:,False,40.764785594653766,96.8282376975019
4384,"def load_parser ( self ) : <TAB>  result = OrderedDict ( ) <TAB>  for name , flags in self . filenames : <TAB><TAB>  filename = self . get_filename ( name ) <TAB><TAB>  for match in sorted ( glob ( filename ) , key = self . file_key ) : <TAB><TAB><TAB>  # Needed to allow overlapping globs, more specific first <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  result [ match ] = TextParser ( match , os . path . relpath ( match , self . base ) , flags ) <TAB>  return result ",if match in result :,if match.startswith('.py'):,False,58.30287789288069,94.56030823624151
4385,"def __init__ ( self , selectable , name = None ) : <TAB>  baseselectable = selectable <TAB>  while isinstance ( baseselectable , Alias ) : <TAB><TAB>  baseselectable = baseselectable . element <TAB>  self . original = baseselectable <TAB>  self . supports_execution = baseselectable . supports_execution <TAB>  if self . supports_execution : <TAB><TAB>  self . _execution_options = baseselectable . _execution_options <TAB>  self . element = selectable <TAB>  if name is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  name = getattr ( self . original , "" name "" , None ) <TAB><TAB>  name = _anonymous_label ( "" %% ( %d %s )s "" % ( id ( self ) , name or "" anon "" ) ) <TAB>  self . name = name ",if self . original . named_with_column :,if name is None:,False,26.613733237107617,94.60096947975615
4386,"def load_tour ( self , tour_id ) : <TAB>  for tour_dir in self . tour_directories : <TAB><TAB>  tour_path = os . path . join ( tour_dir , tour_id + "" .yaml "" ) <TAB><TAB>  if not os . path . exists ( tour_path ) : <TAB><TAB><TAB>  tour_path = os . path . join ( tour_dir , tour_id + "" .yml "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _load_tour_from_path ( tour_path ) ",if os . path . exists ( tour_path ) :,if os.path.exists(tour_path):,False,51.3437768802578,100.00000000000004
4387,"def _get_md_bg_color_down ( self ) : <TAB>  t = self . theme_cls <TAB>  c = self . md_bg_color<TAB># Default to no change on touch <TAB>  # Material design specifies using darker hue when on Dark theme <TAB>  if t . theme_style == "" Dark "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  c = t . primary_dark <TAB><TAB>  elif self . md_bg_color == t . accent_color : <TAB><TAB><TAB>  c = t . accent_dark <TAB>  return c ",if self . md_bg_color == t . primary_color :,if self.md_bg_color == t.primary_color:,False,32.20033238246612,97.09797067861027
4388,"def get_data ( self , state = None , request = None ) : <TAB>  if self . load_in_memory : <TAB><TAB>  data , shapes = self . _in_memory_get_data ( state , request ) <TAB>  else : <TAB><TAB>  data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB>  for i in range ( len ( data ) ) : <TAB><TAB>  if shapes [ i ] is not None : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  for j in range ( len ( data [ i ] ) ) : <TAB><TAB><TAB><TAB><TAB>  data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB>  return tuple ( data ) ","if isinstance ( request , numbers . Integral ) :","if isinstance(shapes[i], (int, float)):",False,47.36990653606462,95.52225821483933
4389,"def onClicked ( event ) : <TAB>  if not self . path : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . makedirs ( mh . getPath ( "" render "" ) ) <TAB><TAB>  self . path = mh . getPath ( "" render "" ) <TAB>  filename , ftype = mh . getSaveFileName ( <TAB><TAB>  os . path . splitext ( self . path ) [ 0 ] , <TAB><TAB>  "" PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*) "" , <TAB>  ) <TAB>  if filename : <TAB><TAB>  if "" Thumbnail "" in ftype : <TAB><TAB><TAB>  self . image . save ( filename , iformat = "" PNG "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . image . save ( filename ) <TAB><TAB>  self . path = os . path . dirname ( filename ) ","if not os . path . exists ( mh . getPath ( ""render"" ) ) :",if not os.path.exists(mh.getPath('render')):,False,57.479214626466465,98.11945683374533
4390,"def _build_dom ( cls , content , mode ) : <TAB>  assert mode in ( "" html "" , "" xml "" ) <TAB>  if mode == "" html "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  THREAD_STORAGE . html_parser = HTMLParser ( ) <TAB><TAB>  dom = defusedxml . lxml . parse ( <TAB><TAB><TAB>  StringIO ( content ) , parser = THREAD_STORAGE . html_parser <TAB><TAB>  ) <TAB><TAB>  return dom . getroot ( ) <TAB>  else : <TAB><TAB>  if not hasattr ( THREAD_STORAGE , "" xml_parser "" ) : <TAB><TAB><TAB>  THREAD_STORAGE . xml_parser = XMLParser ( ) <TAB><TAB>  dom = defusedxml . lxml . parse ( BytesIO ( content ) , parser = THREAD_STORAGE . xml_parser ) <TAB><TAB>  return dom . getroot ( ) ","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :","if not hasattr(THREAD_STORAGE, ""html_parser""):",False,50.93981691102868,100.00000000000004
4391,"def convert_path ( ctx , tpath ) : <TAB>  for points , code in tpath . iter_segments ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ctx . move_to ( * points ) <TAB><TAB>  elif code == Path . LINETO : <TAB><TAB><TAB>  ctx . line_to ( * points ) <TAB><TAB>  elif code == Path . CURVE3 : <TAB><TAB><TAB>  ctx . curve_to ( <TAB><TAB><TAB><TAB>  points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB>  ) <TAB><TAB>  elif code == Path . CURVE4 : <TAB><TAB><TAB>  ctx . curve_to ( * points ) <TAB><TAB>  elif code == Path . CLOSEPOLY : <TAB><TAB><TAB>  ctx . close_path ( ) ",if code == Path . MOVETO :,if code == Path.MOVE:,False,26.166192438313058,98.91180759779758
4392,"def _targets ( self , sigmaparser ) : <TAB>  # build list of matching target mappings <TAB>  targets = set ( ) <TAB>  for condfield in self . conditions : <TAB><TAB>  if condfield in sigmaparser . values : <TAB><TAB><TAB>  rulefieldvalues = sigmaparser . values [ condfield ] <TAB><TAB><TAB>  for condvalue in self . conditions [ condfield ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  targets . update ( self . conditions [ condfield ] [ condvalue ] ) <TAB>  return targets ",if condvalue in rulefieldvalues :,if condvalue in rulefieldvalues:,False,32.43053790771789,100.00000000000004
4393,"def create_image_upload ( ) : <TAB>  if request . method == "" POST "" : <TAB><TAB>  image = request . form [ "" image "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  image_file = uploaded_file ( file_content = image ) <TAB><TAB><TAB>  image_url = upload_local ( <TAB><TAB><TAB><TAB>  image_file , UPLOAD_PATHS [ "" temp "" ] [ "" image "" ] . format ( uuid = uuid4 ( ) ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return jsonify ( { "" status "" : "" ok "" , "" image_url "" : image_url } ) <TAB><TAB>  else : <TAB><TAB><TAB>  return jsonify ( { "" status "" : "" no_image "" } ) ",if image :,if image:,False,50.48458173529927,100.00000000000004
4394,"def lookup_actions ( self , resp ) : <TAB>  actions = { } <TAB>  for action , conditions in self . actions . items ( ) : <TAB><TAB>  for condition , opts in conditions : <TAB><TAB><TAB>  for key , val in condition : <TAB><TAB><TAB><TAB>  if key [ - 1 ] == "" ! "" : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  if not resp . match ( key , val ) : <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  actions [ action ] = opts <TAB>  return actions ","if resp . match ( key [ : - 1 ] , val ) :","if not resp.match(key, val):",False,42.19865640325358,95.75077825969703
4395,"def accept_quality ( accept , default = 1 ) : <TAB>  """"""Separates out the quality score from the accepted content_type"""""" <TAB>  quality = default <TAB>  if accept and "" ; "" in accept : <TAB><TAB>  accept , rest = accept . split ( "" ; "" , 1 ) <TAB><TAB>  accept_quality = RE_ACCEPT_QUALITY . search ( rest ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  quality = float ( accept_quality . groupdict ( ) . get ( "" quality "" , quality ) . strip ( ) ) <TAB>  return ( quality , accept . strip ( ) ) ",if accept_quality :,if accept_quality:,False,58.555169590660824,100.00000000000004
4396,"def save ( self , session = None , to = None , pickler = None ) : <TAB>  if to and pickler : <TAB><TAB>  self . _save_to = ( pickler , to ) <TAB>  if self . _save_to and len ( self ) > 0 : <TAB><TAB>  with self . _lock : <TAB><TAB><TAB>  pickler , fn = self . _save_to <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  session . ui . mark ( _ ( "" Saving  %s  state to  %s "" ) % ( self , fn ) ) <TAB><TAB><TAB>  pickler ( self , fn ) ",if session :,if pickler:,False,47.697844651831645,98.38431679164988
4397,"def get_safe_settings ( ) : <TAB>  "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB>  settings_dict = { } <TAB>  for k in dir ( settings ) : <TAB><TAB>  if k . isupper ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  settings_dict [ k ] = "" ******************** "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  settings_dict [ k ] = getattr ( settings , k ) <TAB>  return settings_dict ",if HIDDEN_SETTINGS . search ( k ) :,if k == 'settings':,False,60.34994668473092,94.28942372290078
4398,def _init_table_h ( ) : <TAB>  _table_h = [ ] <TAB>  for i in range ( 256 ) : <TAB><TAB>  part_l = i <TAB><TAB>  part_h = 0 <TAB><TAB>  for j in range ( 8 ) : <TAB><TAB><TAB>  rflag = part_l & 1 <TAB><TAB><TAB>  part_l >> = 1 <TAB><TAB><TAB>  if part_h & 1 : <TAB><TAB><TAB><TAB>  part_l | = 1 << 31 <TAB><TAB><TAB>  part_h >> = 1 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  part_h ^ = 0xD8000000 <TAB><TAB>  _table_h . append ( part_h ) <TAB>  return _table_h ,if rflag :,if rflag:,False,38.7925416537651,100.00000000000004
4399,"def dns_query ( server , timeout , protocol , qname , qtype , qclass ) : <TAB>  request = dns . message . make_query ( qname , qtype , qclass ) <TAB>  if protocol == "" tcp "" : <TAB><TAB>  response = dns . query . tcp ( <TAB><TAB><TAB>  request , server , timeout = timeout , one_rr_per_rrset = True <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  response = dns . query . udp ( <TAB><TAB><TAB>  request , server , timeout = timeout , one_rr_per_rrset = True <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  response = dns . query . tcp ( <TAB><TAB><TAB><TAB>  request , server , timeout = timeout , one_rr_per_rrset = True <TAB><TAB><TAB>  ) <TAB>  return response ",if response . flags & dns . flags . TC :,"if protocol == ""tcp':",False,33.54671454506663,95.294151115456
4400,"def sum_and_divide ( self , losses ) : <TAB>  if self . total_divisor != 0 : <TAB><TAB>  output = torch . sum ( losses ) / self . total_divisor <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # remove from autograd graph if necessary <TAB><TAB><TAB>  self . total_divisor = self . total_divisor . item ( ) <TAB><TAB>  return output <TAB>  return torch . sum ( losses * 0 ) ",if torch . is_tensor ( self . total_divisor ) :,if output < 0:,False,48.683698796474374,88.88385492429401
4401,"def __iter__ ( self ) : <TAB>  for chunk in self . source : <TAB><TAB>  if chunk is not None : <TAB><TAB><TAB>  self . wait_counter = 0 <TAB><TAB><TAB>  yield chunk <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . wait_counter + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  logger . warning ( <TAB><TAB><TAB><TAB>  "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB><TAB><TAB><TAB>  "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  break <TAB><TAB>  time . sleep ( self . poll_period ) ",elif self . wait_counter < self . wait_cntr_max :,if self.wait_counter < self.wait_cntr_max:,False,59.24069544863588,98.83034336405589
4402,"def test_find_directive_from_block ( self ) : <TAB>  blocks = self . config . parser_root . find_blocks ( "" virtualhost "" ) <TAB>  found = False <TAB>  for vh in blocks : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  servername = vh . find_directives ( "" servername "" ) <TAB><TAB><TAB>  self . assertEqual ( servername [ 0 ] . parameters [ 0 ] , "" certbot.demo "" ) <TAB><TAB><TAB>  found = True <TAB>  self . assertTrue ( found ) ","if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :",if vh.name == 'server':,False,48.446117820351475,90.2834076598279
4403,"def assign_products ( request , discount_id ) : <TAB>  """"""Assign products to given property group with given property_group_id."""""" <TAB>  discount = lfs_get_object_or_404 ( Discount , pk = discount_id ) <TAB>  for temp_id in request . POST . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  temp_id = temp_id . split ( "" - "" ) [ 1 ] <TAB><TAB><TAB>  product = Product . objects . get ( pk = temp_id ) <TAB><TAB><TAB>  discount . products . add ( product ) <TAB>  html = [ [ "" #products-inline "" , products_inline ( request , discount_id , as_string = True ) ] ] <TAB>  result = json . dumps ( <TAB><TAB>  { "" html "" : html , "" message "" : _ ( u "" Products have been assigned. "" ) } , cls = LazyEncoder <TAB>  ) <TAB>  return HttpResponse ( result , content_type = "" application/json "" ) ","if temp_id . startswith ( ""product"" ) :",if temp_id.startswith('-'):,False,33.17133469827331,98.20210818928166
4404,"def ChangeStyle ( self , combos ) : <TAB>  style = 0 <TAB>  for combo in combos : <TAB><TAB>  if combo . GetValue ( ) == 1 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  style = style | HTL . TR_VIRTUAL <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB>  if self . GetAGWWindowStyleFlag ( ) != style : <TAB><TAB>  self . SetAGWWindowStyleFlag ( style ) ","if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",if combo.GetValue() == 0:,False,50.30668152987092,95.66691786425538
4405,"def _set_autocomplete ( self , notebook ) : <TAB>  if notebook : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  notebook = NotebookInfo ( notebook ) <TAB><TAB><TAB>  obj , x = build_notebook ( notebook ) <TAB><TAB><TAB>  self . form . widgets [ "" namespace "" ] . notebook = obj <TAB><TAB><TAB>  self . form . widgets [ "" page "" ] . notebook = obj <TAB><TAB><TAB>  logger . debug ( "" Notebook for autocomplete:  %s  ( %s ) "" , obj , notebook ) <TAB><TAB>  except : <TAB><TAB><TAB>  logger . exception ( "" Could not set notebook:  %s "" , notebook ) <TAB>  else : <TAB><TAB>  self . form . widgets [ "" namespace "" ] . notebook = None <TAB><TAB>  self . form . widgets [ "" page "" ] . notebook = None <TAB><TAB>  logger . debug ( "" Notebook for autocomplete unset "" ) ","if isinstance ( notebook , str ) :","if isinstance(notebook, str):",False,52.16987830272616,100.00000000000004
4406,"def emitSubDomainData ( self , subDomainData , event ) : <TAB>  self . emitRawRirData ( subDomainData , event ) <TAB>  for subDomainElem in subDomainData : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB><TAB>  if subDomain : <TAB><TAB><TAB>  self . emitHostname ( subDomain , event ) ",if self . checkForStop ( ) :,"if subDomainElem.get('domain', None) == None:",False,36.10793193653174,88.91730929864515
4407,"def get_all_subnets ( self , subnet_ids = None , filters = None ) : <TAB>  # Extract a list of all subnets <TAB>  matches = itertools . chain ( * [ x . values ( ) for x in self . subnets . values ( ) ] ) <TAB>  if subnet_ids : <TAB><TAB>  matches = [ sn for sn in matches if sn . id in subnet_ids ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  unknown_ids = set ( subnet_ids ) - set ( matches ) <TAB><TAB><TAB>  raise InvalidSubnetIdError ( unknown_ids ) <TAB>  if filters : <TAB><TAB>  matches = generic_filter ( filters , matches ) <TAB>  return matches ",if len ( subnet_ids ) > len ( matches ) :,if len(matches) > 0:,False,58.287913640177635,95.21481175634287
4408,"def _compat_map ( self , avs ) : <TAB>  apps = { } <TAB>  for av in avs : <TAB><TAB>  av . version = self <TAB><TAB>  app_id = av . application <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  apps [ amo . APP_IDS [ app_id ] ] = av <TAB>  return apps ",if app_id in amo . APP_IDS :,if app_id in amo.APP_IDS:,False,51.42640749158991,100.00000000000004
4409,"def generator ( self , data ) : <TAB>  if self . _config . SILENT : <TAB><TAB>  silent_vars = self . _get_silent_vars ( ) <TAB>  for task in data : <TAB><TAB>  for var , val in task . environment_variables ( ) : <TAB><TAB><TAB>  if self . _config . SILENT : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB>  0 , <TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB>  int ( task . UniqueProcessId ) , <TAB><TAB><TAB><TAB><TAB>  str ( task . ImageFileName ) , <TAB><TAB><TAB><TAB><TAB>  Address ( task . Peb . ProcessParameters . Environment ) , <TAB><TAB><TAB><TAB><TAB>  str ( var ) , <TAB><TAB><TAB><TAB><TAB>  str ( val ) , <TAB><TAB><TAB><TAB>  ] , <TAB><TAB><TAB>  ) ",if var in silent_vars :,if var in silent_vars:,False,51.354551101481306,100.00000000000004
4410,"def warn_if_repeatable_read ( self ) : <TAB>  if "" mysql "" in self . current_engine ( ) . lower ( ) : <TAB><TAB>  cursor = self . connection_for_read ( ) . cursor ( ) <TAB><TAB>  if cursor . execute ( "" SELECT @@tx_isolation "" ) : <TAB><TAB><TAB>  isolation = cursor . fetchone ( ) [ 0 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB><TAB>  TxIsolationWarning ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" Polling results with transaction isolation level  "" <TAB><TAB><TAB><TAB><TAB><TAB>  "" repeatable-read within the same transaction  "" <TAB><TAB><TAB><TAB><TAB><TAB>  "" may give outdated results. Be sure to commit the  "" <TAB><TAB><TAB><TAB><TAB><TAB>  "" transaction for each poll iteration. "" <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  ) ","if isolation == ""REPEATABLE-READ"" :",if isolation != 0:,False,62.26651151761353,97.7453963174535
4411,"def filter_by_level ( record , level_per_module ) : <TAB>  name = record [ "" name "" ] <TAB>  level = 0 <TAB>  if name in level_per_module : <TAB><TAB>  level = level_per_module [ name ] <TAB>  elif name is not None : <TAB><TAB>  lookup = "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  level = level_per_module [ "" "" ] <TAB><TAB>  for n in name . split ( "" . "" ) : <TAB><TAB><TAB>  lookup + = n <TAB><TAB><TAB>  if lookup in level_per_module : <TAB><TAB><TAB><TAB>  level = level_per_module [ lookup ] <TAB><TAB><TAB>  lookup + = "" . "" <TAB>  if level is False : <TAB><TAB>  return False <TAB>  return record [ "" level "" ] . no > = level ","if """" in level_per_module :",if name in level_per_module:,False,20.23856184520147,98.48638112559709
4412,"def _readStream ( self , handle : str , path : str ) - > None : <TAB>  eof = False <TAB>  file = Path ( path ) <TAB>  with file . open ( "" w "" ) as f : <TAB><TAB>  while not eof : <TAB><TAB><TAB>  response = await self . _client . send ( "" IO.read "" , { "" handle "" : handle } ) <TAB><TAB><TAB>  eof = response . get ( "" eof "" , False ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  f . write ( response . get ( "" data "" , "" "" ) ) <TAB>  await self . _client . send ( "" IO.close "" , { "" handle "" : handle } ) ",if path :,if eof:,False,26.714069971781907,98.5692638970044
4413,"def sendall ( self , data , flags = 0 ) : <TAB>  if self . _sslobj : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" non-zero flags not allowed in calls to sendall() on  %s "" <TAB><TAB><TAB><TAB>  % self . __class__ <TAB><TAB><TAB>  ) <TAB><TAB>  amount = len ( data ) <TAB><TAB>  count = 0 <TAB><TAB>  while count < amount : <TAB><TAB><TAB>  v = self . send ( data [ count : ] ) <TAB><TAB><TAB>  count + = v <TAB><TAB>  return amount <TAB>  else : <TAB><TAB>  return socket . sendall ( self , data , flags ) ",if flags != 0 :,if flags == 0:,False,46.10209214381193,98.7227748200473
4414,"def run ( self ) : <TAB>  utils . assert_main_thread ( ) <TAB>  # As a convenience, we'll set up the connection <TAB>  # if there isn't one. So F5 (etc) can be hit <TAB>  # to get started. <TAB>  if not channel : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  SwiDebugStartChromeCommand . run ( self ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . window . run_command ( "" swi_debug_start "" ) <TAB>  elif paused : <TAB><TAB>  logger . info ( "" Resuming... "" ) <TAB><TAB>  channel . send ( webkit . Debugger . resume ( ) ) <TAB>  else : <TAB><TAB>  logger . info ( "" Pausing... "" ) <TAB><TAB>  channel . send ( webkit . Debugger . setSkipAllPauses ( False ) ) <TAB><TAB>  channel . send ( webkit . Debugger . pause ( ) ) ",if not chrome_launched ( ) :,if self.window:,False,65.68393287537118,96.64037860696634
4415,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . add_presence_response ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 0:,False,50.97682883708774,100.00000000000004
4416,"def _replace_home ( x ) : <TAB>  if xp . ON_WINDOWS : <TAB><TAB>  home = ( <TAB><TAB><TAB>  builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB><TAB>  ) <TAB><TAB>  if x . startswith ( home ) : <TAB><TAB><TAB>  x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = x . replace ( os . sep , os . altsep ) <TAB><TAB>  return x <TAB>  else : <TAB><TAB>  home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB><TAB>  if x . startswith ( home ) : <TAB><TAB><TAB>  x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB>  return x ","if builtins . __xonsh__ . env . get ( ""FORCE_POSIX_PATHS"" ) :",if os.sep != os.altsep:,False,25.657389751672515,91.24431571264084
4417,"def semanticTags ( self , semanticTags ) : <TAB>  if semanticTags is None : <TAB><TAB>  self . __semanticTags = OrderedDict ( ) <TAB>  # check <TAB>  for key , value in list ( semanticTags . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise TypeError ( "" At least one key is not a valid int position "" ) <TAB><TAB>  if not isinstance ( value , list ) : <TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB>  "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB>  ) <TAB><TAB>  for x in value : <TAB><TAB><TAB>  if not isinstance ( x , str ) : <TAB><TAB><TAB><TAB>  raise TypeError ( <TAB><TAB><TAB><TAB><TAB>  "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB><TAB>  ) <TAB>  self . __semanticTags = semanticTags ","if not isinstance ( key , int ) :","if key not in ('int', 'int'):",False,68.10721761922892,97.05453569769396
4418,"def _recv ( ) : <TAB>  try : <TAB><TAB>  return sock . recv ( bufsize ) <TAB>  except SSLWantReadError : <TAB><TAB>  pass <TAB>  except socket . error as exc : <TAB><TAB>  error_code = extract_error_code ( exc ) <TAB><TAB>  if error_code is None : <TAB><TAB><TAB>  raise <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB>  r , w , e = select . select ( ( sock , ) , ( ) , ( ) , sock . gettimeout ( ) ) <TAB>  if r : <TAB><TAB>  return sock . recv ( bufsize ) ",if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,if error_code == SSLWantReadError:,False,30.60446507768127,91.03950991597975
4419,"def _authenticate ( self ) : <TAB>  oauth_token = self . options . get ( "" oauth_token "" ) <TAB>  if oauth_token and not self . api . oauth_token : <TAB><TAB>  self . logger . info ( "" Attempting to authenticate using OAuth token "" ) <TAB><TAB>  self . api . oauth_token = oauth_token <TAB><TAB>  user = self . api . user ( schema = _user_schema ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . logger . info ( "" Successfully logged in as  {0} "" , user ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . logger . error ( <TAB><TAB><TAB><TAB>  "" Failed to authenticate, the access token  "" "" is not valid "" <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return JustinTVPluginBase . _authenticate ( self ) ",if user :,if user:,False,59.87636367691942,100.00000000000004
4420,"def reverse ( self , * args ) : <TAB>  assert self . _path is not None , "" Cannot reverse url regex  "" + self . regex . pattern <TAB>  assert len ( args ) == self . _group_count , "" required number of arguments  "" "" not found "" <TAB>  if not len ( args ) : <TAB><TAB>  return self . _path <TAB>  converted_args = [ ] <TAB>  for a in args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  a = str ( a ) <TAB><TAB>  converted_args . append ( escape . url_escape ( utf8 ( a ) , plus = False ) ) <TAB>  return self . _path % tuple ( converted_args ) ","if not isinstance ( a , ( unicode_type , bytes ) ) :","if isinstance(a, unicode):",False,28.43898151317549,93.80869414344834
4421,"def determine_block_hints ( self , text ) : <TAB>  hints = "" "" <TAB>  if text : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  hints + = str ( self . best_indent ) <TAB><TAB>  if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB>  hints + = "" - "" <TAB><TAB>  elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB>  hints + = "" + "" <TAB>  return hints ","if text [ 0 ] in "" \n\x85\u2028\u2029"" :",if len(text) == 0:,False,43.97581297018242,86.48818236266837
4422,"def find_package_modules ( package , mask ) : <TAB>  import fnmatch <TAB>  if hasattr ( package , "" __loader__ "" ) and hasattr ( package . __loader__ , "" _files "" ) : <TAB><TAB>  path = package . __name__ . replace ( "" . "" , os . path . sep ) <TAB><TAB>  mask = os . path . join ( path , mask ) <TAB><TAB>  for fnm in package . __loader__ . _files . iterkeys ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield os . path . splitext ( fnm ) [ 0 ] . replace ( os . path . sep , "" . "" ) <TAB>  else : <TAB><TAB>  path = package . __path__ [ 0 ] <TAB><TAB>  for fnm in os . listdir ( path ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield "" %s . %s "" % ( package . __name__ , os . path . splitext ( fnm ) [ 0 ] ) ","if fnmatch . fnmatchcase ( fnm , mask ) :","if fnmatch.fnmatch(fnm, mask):",False,40.15441102746965,95.3348871705053
4423,"def _condition ( ct ) : <TAB>  for qobj in args : <TAB><TAB>  if qobj . connector == "" AND "" and not qobj . negated : <TAB><TAB><TAB>  # normal kwargs are an AND anyway, so just use those for now <TAB><TAB><TAB>  for child in qobj . children : <TAB><TAB><TAB><TAB>  kwargs . update ( dict ( [ child ] ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError ( "" Unsupported Q object "" ) <TAB>  for attr , val in kwargs . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return False <TAB>  return True ","if getattr ( ct , attr ) != val :","if not isinstance(val, (int, float)):",False,62.00764960314109,93.27119554252212
4424,"def process ( self , resources ) : <TAB>  session = local_session ( self . manager . session_factory ) <TAB>  client = session . client ( "" logs "" ) <TAB>  state = self . data . get ( "" state "" , True ) <TAB>  key = self . resolve_key ( self . data . get ( "" kms-key "" ) ) <TAB>  for r in resources : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  client . associate_kms_key ( logGroupName = r [ "" logGroupName "" ] , kmsKeyId = key ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  client . disassociate_kms_key ( logGroupName = r [ "" logGroupName "" ] ) <TAB><TAB>  except client . exceptions . ResourceNotFoundException : <TAB><TAB><TAB>  continue ",if state :,if state:,False,50.970615076902334,100.00000000000004
4425,"def get_xmm ( env , ii ) : <TAB>  if is_gather ( ii ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return gen_reg_simd_unified ( env , "" xmm_evex "" , True ) <TAB><TAB>  return gen_reg_simd_unified ( env , "" xmm "" , False ) <TAB>  <IF-STMT>: <TAB><TAB>  return gen_reg ( env , "" xmm_evex "" ) <TAB>  return gen_reg ( env , "" xmm "" ) ","if ii . space == ""evex"" :",if is_gather(ii):,False,18.339633240911347,84.94881142142424
4426,"def parent ( self ) : <TAB>  """"""Return the parent device."""""" <TAB>  if self . _has_parent is None : <TAB><TAB>  _parent = self . _ctx . backend . get_parent ( self . _ctx . dev ) <TAB><TAB>  self . _has_parent = _parent is not None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _parent = Device ( _parent , self . _ctx . backend ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _parent = None <TAB>  return self . _parent ",if self . _has_parent :,if _parent is not None:,False,38.22134590013213,95.40882103018886
4427,"def cascade ( self , event = None ) : <TAB>  """"""Cascade all Leo windows."""""" <TAB>  x , y , delta = 50 , 50 , 50 <TAB>  for frame in g . app . windowList : <TAB><TAB>  w = frame and frame . top <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r = w . geometry ( )<TAB># a Qt.Rect <TAB><TAB><TAB>  # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB><TAB><TAB>  w . setGeometry ( QtCore . QRect ( x , y , r . width ( ) , r . height ( ) ) ) <TAB><TAB><TAB>  # Compute the new offsets. <TAB><TAB><TAB>  x + = 30 <TAB><TAB><TAB>  y + = 30 <TAB><TAB><TAB>  if x > 200 : <TAB><TAB><TAB><TAB>  x = 10 + delta <TAB><TAB><TAB><TAB>  y = 40 + delta <TAB><TAB><TAB><TAB>  delta + = 10 ",if w :,if w:,False,27.497016484187125,98.24267944374645
4428,"def _GetGoodDispatchAndUserName ( IDispatch , userName , clsctx ) : <TAB>  # Get a dispatch object, and a 'user name' (ie, the name as <TAB>  # displayed to the user in repr() etc. <TAB>  if userName is None : <TAB><TAB>  if isinstance ( IDispatch , str ) : <TAB><TAB><TAB>  userName = IDispatch <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # We always want the displayed name to be a real string <TAB><TAB><TAB>  userName = IDispatch . encode ( "" ascii "" , "" replace "" ) <TAB>  elif type ( userName ) == unicode : <TAB><TAB>  # As above - always a string... <TAB><TAB>  userName = userName . encode ( "" ascii "" , "" replace "" ) <TAB>  else : <TAB><TAB>  userName = str ( userName ) <TAB>  return ( _GetGoodDispatch ( IDispatch , clsctx ) , userName ) ","elif isinstance ( IDispatch , unicode ) :",if type(userName) == str:,False,41.60452350379438,95.81516357593937
4429,"def _infer_return_type ( * args ) : <TAB>  """"""Look at the type of all args and divine their implied return type."""""" <TAB>  return_type = None <TAB>  for arg in args : <TAB><TAB>  if arg is None : <TAB><TAB><TAB>  continue <TAB><TAB>  if isinstance ( arg , bytes ) : <TAB><TAB><TAB>  if return_type is str : <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = bytes <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB>  return_type = str <TAB>  if return_type is None : <TAB><TAB>  return str<TAB># tempfile APIs return a str by default. <TAB>  return return_type ",if return_type is bytes :,if return_type is None:,False,59.38365160498347,93.61270650822367
4430,"def test_ESPnetDataset_h5file_1 ( h5file_1 ) : <TAB>  dataset = IterableESPnetDataset ( <TAB><TAB>  path_name_type_list = [ ( h5file_1 , "" data4 "" , "" hdf5 "" ) ] , <TAB><TAB>  preprocess = preprocess , <TAB>  ) <TAB>  for key , data in dataset : <TAB><TAB>  if key == "" a "" : <TAB><TAB><TAB>  assert data [ "" data4 "" ] . shape == ( <TAB><TAB><TAB><TAB>  100 , <TAB><TAB><TAB><TAB>  80 , <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert data [ "" data4 "" ] . shape == ( <TAB><TAB><TAB><TAB>  150 , <TAB><TAB><TAB><TAB>  80 , <TAB><TAB><TAB>  ) ","if key == ""b"" :","if key == ""h5file_1':",False,21.99798807729334,97.95519354525233
4431,"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB>  exclude_meta = not include_meta <TAB>  for field_name , field in node . _fields . items ( ) : <TAB><TAB>  if exclude_meta and field . meta : <TAB><TAB><TAB>  continue <TAB><TAB>  field_val = getattr ( node , field_name , _marker ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if exclude_unset : <TAB><TAB><TAB>  if callable ( field . default ) : <TAB><TAB><TAB><TAB>  default = field . default ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  default = field . default <TAB><TAB><TAB>  if field_val == default : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield field_name , field_val ",if field_val is _marker :,if field_val is None:,False,32.68196186685521,98.53699998351436
4432,"def then ( self , matches , when_response , context ) : <TAB>  if is_iterable ( when_response ) : <TAB><TAB>  ret = [ ] <TAB><TAB>  when_response = list ( when_response ) <TAB><TAB>  for match in when_response : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if self . match_name : <TAB><TAB><TAB><TAB><TAB>  match . name = self . match_name <TAB><TAB><TAB><TAB>  matches . append ( match ) <TAB><TAB><TAB><TAB>  ret . append ( match ) <TAB><TAB>  return ret <TAB>  if self . match_name : <TAB><TAB>  when_response . name = self . match_name <TAB>  if when_response not in matches : <TAB><TAB>  matches . append ( when_response ) <TAB><TAB>  return when_response ",if match not in matches :,if match.name == self.match_name:,False,50.247721472877686,95.51871406935977
4433,"def _set_chat_ids ( self , chat_id : SLT [ int ] ) - > None : <TAB>  with self . __lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB><TAB>  f "" Can ' t set  { self . chat_id_name }  in conjunction with (already set)  "" <TAB><TAB><TAB><TAB>  f "" { self . username_name } s. "" <TAB><TAB><TAB>  ) <TAB><TAB>  self . _chat_ids = self . _parse_chat_id ( chat_id ) ",if chat_id and self . _usernames :,if self._chat_ids is None:,False,47.14328234095157,92.33459301703373
4434,"def discover ( self , * objlist ) : <TAB>  ret = [ ] <TAB>  for l in self . splitlines ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if l [ 0 ] == "" Filename "" : <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  int ( l [ 2 ] ) <TAB><TAB><TAB>  int ( l [ 3 ] ) <TAB><TAB>  except : <TAB><TAB><TAB>  continue <TAB><TAB>  #<TAB><TAB>   ret.append(improve(l[0])) <TAB><TAB>  ret . append ( l [ 0 ] ) <TAB>  ret . sort ( ) <TAB>  for item in objlist : <TAB><TAB>  ret . append ( item ) <TAB>  return ret ",if len ( l ) < 5 :,if len(l) == 0:,False,51.18009315281493,97.84760056298889
4435,"def get_changed_module ( self ) : <TAB>  source = self . resource . read ( ) <TAB>  change_collector = codeanalyze . ChangeCollector ( source ) <TAB>  if self . replacement is not None : <TAB><TAB>  change_collector . add_change ( self . skip_start , self . skip_end , self . replacement ) <TAB>  for occurrence in self . occurrence_finder . find_occurrences ( self . resource ) : <TAB><TAB>  start , end = occurrence . get_primary_range ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . handle . occurred_inside_skip ( change_collector , occurrence ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . handle . occurred_outside_skip ( change_collector , occurrence ) <TAB>  result = change_collector . get_changed ( ) <TAB>  if result is not None and result != source : <TAB><TAB>  return result ",if self . skip_start <= start < self . skip_end :,if start == self.skip_start:,False,47.12506275010691,94.97925853036884
4436,"def hpat_pandas_series_var_impl ( <TAB>  self , axis = None , skipna = None , level = None , ddof = 1 , numeric_only = None  ) : <TAB>  if skipna is None : <TAB><TAB>  skipna = True <TAB>  if skipna : <TAB><TAB>  valuable_length = len ( self . _data ) - numpy . sum ( numpy . isnan ( self . _data ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return numpy . nan <TAB><TAB>  return ( <TAB><TAB><TAB>  numpy_like . nanvar ( self . _data ) * valuable_length / ( valuable_length - ddof ) <TAB><TAB>  ) <TAB>  if len ( self . _data ) < = ddof : <TAB><TAB>  return numpy . nan <TAB>  return self . _data . var ( ) * len ( self . _data ) / ( len ( self . _data ) - ddof ) ",if valuable_length <= ddof :,if valuable_length <= 0:,False,36.20395738384493,98.87760724645923
4437,"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB>  context = context or { } <TAB>  condition = getattr ( self , "" condition "" , Undefined ) <TAB>  copy = self<TAB># don't copy unless we need to <TAB>  if condition is not Undefined : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass <TAB><TAB>  elif "" field "" in condition and "" type "" not in condition : <TAB><TAB><TAB>  kwds = parse_shorthand ( condition [ "" field "" ] , context . get ( "" data "" , None ) ) <TAB><TAB><TAB>  copy = self . copy ( deep = [ "" condition "" ] ) <TAB><TAB><TAB>  copy . condition . update ( kwds ) <TAB>  return super ( ValueChannelMixin , copy ) . to_dict ( <TAB><TAB>  validate = validate , ignore = ignore , context = context <TAB>  ) ","if isinstance ( condition , core . SchemaBase ) :",if condition is None:,False,31.711161049127206,95.11316649184167
4438,"def get_field_result ( self , result , field_name ) : <TAB>  if isinstance ( result . field , models . ImageField ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  img = getattr ( result . obj , field_name ) <TAB><TAB><TAB>  result . text = mark_safe ( <TAB><TAB><TAB><TAB>  ' <a href= "" %s ""  target= "" _blank ""  title= "" %s ""  data-gallery= "" gallery "" ><img src= "" %s ""  class= "" field_img "" /></a> ' <TAB><TAB><TAB><TAB>  % ( img . url , result . label , img . url ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . include_image = True <TAB>  return result ",if result . value :,if result.field.field.name == field_name:,False,48.64146588138922,94.3990187303685
4439,"def run ( self ) : <TAB>  try : <TAB><TAB>  while True : <TAB><TAB><TAB>  dp = self . queue_get_stoppable ( self . inq ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  # cannot ignore None here. will lead to unsynced send/recv <TAB><TAB><TAB>  obj = self . func ( dp ) <TAB><TAB><TAB>  self . queue_put_stoppable ( self . outq , obj ) <TAB>  except Exception : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pass<TAB># skip duplicated error messages <TAB><TAB>  else : <TAB><TAB><TAB>  raise <TAB>  finally : <TAB><TAB>  self . stop ( ) ",if self . stopped ( ) :,if not dp:,False,55.120924826558024,92.24386246408068
4440,"def _evaluate_local_single ( self , iterator ) : <TAB>  for batch in iterator : <TAB><TAB>  in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB><TAB>  with function . no_backprop_mode ( ) : <TAB><TAB><TAB>  if isinstance ( in_arrays , tuple ) : <TAB><TAB><TAB><TAB>  results = self . calc_local ( * in_arrays ) <TAB><TAB><TAB>  elif isinstance ( in_arrays , dict ) : <TAB><TAB><TAB><TAB>  results = self . calc_local ( * * in_arrays ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  results = self . calc_local ( in_arrays ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _progress_hook ( batch ) <TAB><TAB>  yield results ",if self . _progress_hook :,if results is not None:,False,26.24173134190612,96.70137626566473
4441,"def merge ( self , other ) : <TAB>  d = self . _name2ft <TAB>  for name , ( f , t ) in other . _name2ft . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Don't print here by default, since doing <TAB><TAB><TAB>  #<TAB> so breaks some of the buildbots <TAB><TAB><TAB>  # print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \ <TAB><TAB><TAB>  #<TAB>"" testers; summing outcomes."" <TAB><TAB><TAB>  f2 , t2 = d [ name ] <TAB><TAB><TAB>  f = f + f2 <TAB><TAB><TAB>  t = t + t2 <TAB><TAB>  d [ name ] = f , t ",if name in d :,if f != t:,False,60.84461777697643,97.16704052661908
4442,"def _addSettingsToPanels ( self , category , left , right ) : <TAB>  count = len ( profile . getSubCategoriesFor ( category ) ) + len ( <TAB><TAB>  profile . getSettingsForCategory ( category ) <TAB>  ) <TAB>  p = left <TAB>  n = 0 <TAB>  for title in profile . getSubCategoriesFor ( category ) : <TAB><TAB>  n + = 1 + len ( profile . getSettingsForCategory ( category , title ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p = right <TAB><TAB>  configBase . TitleRow ( p , _ ( title ) ) <TAB><TAB>  for s in profile . getSettingsForCategory ( category , title ) : <TAB><TAB><TAB>  configBase . SettingRow ( p , s . getName ( ) ) ",if n > count / 2 :,if n == count:,False,22.074851319639617,96.95027914700971
4443,"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB>  filelist = [ ] <TAB>  dirlist = [ "" .. "" ] <TAB>  self . dir = dir <TAB>  self . file = "" "" <TAB>  mask = mask . upper ( ) <TAB>  pattern = self . MakeRegex ( mask ) <TAB>  for i in os . listdir ( dir ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  path = os . path . join ( dir , i ) <TAB><TAB>  if os . path . isdir ( path ) : <TAB><TAB><TAB>  dirlist . append ( i ) <TAB><TAB><TAB>  continue <TAB><TAB>  path = path . upper ( ) <TAB><TAB>  value = i . upper ( ) <TAB><TAB>  if pattern . match ( value ) is not None : <TAB><TAB><TAB>  filelist . append ( i ) <TAB>  self . files = filelist <TAB>  if with_dirs : <TAB><TAB>  self . dirs = dirlist ","if i == ""."" or i == "".."" :",if not i.startswith('.'):,False,24.86604372841515,94.43015585436564
4444,def check_network_private ( test_network ) : <TAB>  test_net = ipaddress . IPNetwork ( test_network ) <TAB>  test_start = test_net . network <TAB>  test_end = test_net . broadcast <TAB>  for network in settings . vpn . safe_priv_subnets : <TAB><TAB>  network = ipaddress . IPNetwork ( network ) <TAB><TAB>  net_start = network . network <TAB><TAB>  net_end = network . broadcast <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  return False ,if test_start >= net_start and test_end <= net_end :,if net_start == test_end:,False,20.059535160173013,90.44624196471362
4445,"def _end_description ( self ) : <TAB>  if self . _summaryKey == "" content "" : <TAB><TAB>  self . _end_content ( ) <TAB>  else : <TAB><TAB>  value = self . popContent ( "" description "" ) <TAB><TAB>  context = self . _getContext ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  context [ "" textinput "" ] [ "" description "" ] = value <TAB><TAB>  elif self . inimage : <TAB><TAB><TAB>  context [ "" image "" ] [ "" description "" ] = value <TAB>  self . _summaryKey = None ",if self . intextinput :,if self.textinput:,False,51.08427192554929,98.27267114919535
4446,def compute_nullable_nonterminals ( self ) : <TAB>  nullable = { } <TAB>  num_nullable = 0 <TAB>  while 1 : <TAB><TAB>  for p in self . grammar . Productions [ 1 : ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  nullable [ p . name ] = 1 <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  for t in p . prod : <TAB><TAB><TAB><TAB>  if not t in nullable : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  nullable [ p . name ] = 1 <TAB><TAB>  if len ( nullable ) == num_nullable : <TAB><TAB><TAB>  break <TAB><TAB>  num_nullable = len ( nullable ) <TAB>  return nullable ,if p . len == 0 :,if not p.is_nullable:,False,47.6589306710401,96.99854643209363
4447,"def process_bind_param ( self , value , dialect ) : <TAB>  if value is not None : <TAB><TAB>  if MAX_METADATA_VALUE_SIZE is not None : <TAB><TAB><TAB>  for k , v in list ( value . items ( ) ) : <TAB><TAB><TAB><TAB>  sz = total_size ( v ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  del value [ k ] <TAB><TAB><TAB><TAB><TAB>  log . warning ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" Refusing to bind metadata key  {}  due to size ( {} ) "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB>  k , sz <TAB><TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB>  value = json_encoder . encode ( value ) . encode ( ) <TAB>  return value ",if sz > MAX_METADATA_VALUE_SIZE :,if sz > MAX_METADATA_VALUE_SIZE:,False,60.672112317453944,100.00000000000004
4448,"def process_input_line ( self , line , store_history = True ) : <TAB>  """"""process the input, capturing stdout"""""" <TAB>  stdout = sys . stdout <TAB>  splitter = self . IP . input_splitter <TAB>  try : <TAB><TAB>  sys . stdout = self . cout <TAB><TAB>  splitter . push ( line ) <TAB><TAB>  more = splitter . push_accepts_more ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  source_raw = splitter . source_raw_reset ( ) [ 1 ] <TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB>  # recent ipython #4504 <TAB><TAB><TAB><TAB>  source_raw = splitter . raw_reset ( ) <TAB><TAB><TAB>  self . IP . run_cell ( source_raw , store_history = store_history ) <TAB>  finally : <TAB><TAB>  sys . stdout = stdout ",if not more :,if more:,False,50.297472817542356,98.97176727054715
4449,"def _dump_section ( self , name , values , f ) : <TAB>  doc = "" __doc__ "" <TAB>  <IF-STMT>: <TAB><TAB>  print ( "" #  %s "" % values [ doc ] , file = f ) <TAB>  print ( "" %s ( "" % name , file = f ) <TAB>  for k , v in values . items ( ) : <TAB><TAB>  if k . endswith ( "" __doc__ "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  doc = k + "" __doc__ "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( ""<TAB> #  %s "" % values [ doc ] , file = f ) <TAB><TAB>  print ( ""<TAB>  %s  =  %s , "" % ( k , pprint . pformat ( v , indent = 8 ) ) , file = f ) <TAB>  print ( "" ) \n "" , file = f ) ",if doc in values :,if doc in values:,False,23.945031763361992,97.59113957777474
4450,"def open_session ( self , app , request ) : <TAB>  sid = request . cookies . get ( app . session_cookie_name ) <TAB>  if sid : <TAB><TAB>  stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB><TAB>  if stored_session : <TAB><TAB><TAB>  expiration = stored_session . expiration <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  expiration = expiration . replace ( tzinfo = utc ) <TAB><TAB><TAB>  if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB><TAB><TAB><TAB>  return MongoEngineSession ( <TAB><TAB><TAB><TAB><TAB>  initial = stored_session . data , sid = stored_session . sid <TAB><TAB><TAB><TAB>  ) <TAB>  return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) ) ",if not expiration . tzinfo :,if expiration is not None:,False,27.51695020491505,97.77514122758403
4451,"def table_entry ( mode1 , bind_type1 , mode2 , bind_type2 ) : <TAB>  with sock ( mode1 ) as sock1 : <TAB><TAB>  bind ( sock1 , bind_type1 ) <TAB><TAB>  try : <TAB><TAB><TAB>  with sock ( mode2 ) as sock2 : <TAB><TAB><TAB><TAB>  bind ( sock2 , bind_type2 ) <TAB><TAB>  except OSError as exc : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return "" INUSE "" <TAB><TAB><TAB>  elif exc . winerror == errno . WSAEACCES : <TAB><TAB><TAB><TAB>  return "" ACCESS "" <TAB><TAB><TAB>  raise <TAB><TAB>  else : <TAB><TAB><TAB>  return "" Success "" ",if exc . winerror == errno . WSAEADDRINUSE :,if exc.winerror == errno.EINVAL:,False,25.96617043742037,98.73569411297849
4452,"def __init__ ( self , ruleset ) : <TAB>  # Organize rules by path <TAB>  self . ruleset = ruleset <TAB>  self . rules = { } <TAB>  for filename in self . ruleset . rules : <TAB><TAB>  for rule in self . ruleset . rules [ filename ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  manage_dictionary ( self . rules , rule . path , [ ] ) <TAB><TAB><TAB>  self . rules [ rule . path ] . append ( rule ) ",if not rule . enabled :,if not rule.path:,False,27.45952910008703,98.19795610338048
4453,"def talk ( self , words ) : <TAB>  if self . writeSentence ( words ) == 0 : <TAB><TAB>  return <TAB>  r = [ ] <TAB>  while 1 : <TAB><TAB>  i = self . readSentence ( ) <TAB><TAB>  if len ( i ) == 0 : <TAB><TAB><TAB>  continue <TAB><TAB>  reply = i [ 0 ] <TAB><TAB>  attrs = { } <TAB><TAB>  for w in i [ 1 : ] : <TAB><TAB><TAB>  j = w . find ( "" = "" , 1 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  attrs [ w ] = "" "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB><TAB>  r . append ( ( reply , attrs ) ) <TAB><TAB>  if reply == "" !done "" : <TAB><TAB><TAB>  return r ",if j == - 1 :,if j == -1:,False,50.8187002043128,100.00000000000004
4454,"def _check_decorator_overload ( name : str , old : str , new : str ) - > int : <TAB>  """"""Conditions for a decorator to overload an existing one."""""" <TAB>  properties = _property_decorators ( name ) <TAB>  if old == new : <TAB><TAB>  return _MERGE <TAB>  elif old in properties and new in properties : <TAB><TAB>  p_old , p_new = properties [ old ] . precedence , properties [ new ] . precedence <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return _DISCARD <TAB><TAB>  elif p_old == p_new : <TAB><TAB><TAB>  return _MERGE <TAB><TAB>  else : <TAB><TAB><TAB>  return _REPLACE <TAB>  raise OverloadedDecoratorError ( name , "" "" ) ",if p_old > p_new :,if p_old == new:,False,50.46887148913041,97.70742607351015
4455,"def validate_pk ( self ) : <TAB>  try : <TAB><TAB>  self . _key = serialization . load_pem_private_key ( <TAB><TAB><TAB>  self . key , password = None , backend = default_backend ( ) <TAB><TAB>  ) <TAB><TAB>  if self . _key . key_size > 2048 : <TAB><TAB><TAB>  AWSValidationException ( <TAB><TAB><TAB><TAB>  "" The private key length is not supported. Only 1024-bit and 2048-bit are allowed. "" <TAB><TAB><TAB>  ) <TAB>  except Exception as err : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB><TAB>  raise AWSValidationException ( <TAB><TAB><TAB>  "" The private key is not PEM-encoded or is not valid. "" <TAB><TAB>  ) ","if isinstance ( err , AWSValidationException ) :",if err.args[0] == 'Invalid key:,False,46.38619676836214,94.62338454006142
4456,"def _add_custom_statement ( self , custom_statements ) : <TAB>  if custom_statements is None : <TAB><TAB>  return <TAB>  self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB>  if self . resource_policy . get ( "" Statement "" ) is None : <TAB><TAB>  self . resource_policy [ "" Statement "" ] = custom_statements <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  custom_statements = [ custom_statements ] <TAB><TAB>  statement = self . resource_policy [ "" Statement "" ] <TAB><TAB>  if not isinstance ( statement , list ) : <TAB><TAB><TAB>  statement = [ statement ] <TAB><TAB>  for s in custom_statements : <TAB><TAB><TAB>  if s not in statement : <TAB><TAB><TAB><TAB>  statement . append ( s ) <TAB><TAB>  self . resource_policy [ "" Statement "" ] = statement ","if not isinstance ( custom_statements , list ) :","if isinstance(custom_statements, list):",False,22.257747618741732,98.96323850094205
4457,"def load ( self , repn ) : <TAB>  for key in repn : <TAB><TAB>  tmp = self . _convert ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . declare ( tmp ) <TAB><TAB>  item = dict . __getitem__ ( self , tmp ) <TAB><TAB>  item . _active = True <TAB><TAB>  item . load ( repn [ key ] ) ",if tmp not in self :,if tmp is not None:,False,27.72245210627214,95.86688689136061
4458,"def on_press_release ( x ) : <TAB>  """"""Keyboard callback function."""""" <TAB>  global is_recording , enable_trigger_record <TAB>  press = keyboard . KeyboardEvent ( "" down "" , 28 , "" space "" ) <TAB>  release = keyboard . KeyboardEvent ( "" up "" , 28 , "" space "" ) <TAB>  if x . event_type == "" down "" and x . name == press . name : <TAB><TAB>  if ( not is_recording ) and enable_trigger_record : <TAB><TAB><TAB>  sys . stdout . write ( "" Start Recording ...  "" ) <TAB><TAB><TAB>  sys . stdout . flush ( ) <TAB><TAB><TAB>  is_recording = True <TAB>  if x . event_type == "" up "" and x . name == release . name : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  is_recording = False ",if is_recording == True :,if not is_recording and enable_trigger_record:,False,29.254863374977706,95.55500787770208
4459,"def apply_mask ( self , mask , data_t , data_f ) : <TAB>  ind_t , ind_f = 0 , 0 <TAB>  out = [ ] <TAB>  for m in cycle ( mask ) : <TAB><TAB>  if m : <TAB><TAB><TAB>  if ind_t == len ( data_t ) : <TAB><TAB><TAB><TAB>  return out <TAB><TAB><TAB>  out . append ( data_t [ ind_t ] ) <TAB><TAB><TAB>  ind_t + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return out <TAB><TAB><TAB>  out . append ( data_f [ ind_f ] ) <TAB><TAB><TAB>  ind_f + = 1 <TAB>  return out ",if ind_f == len ( data_f ) :,if ind_f == len(data_f):,False,48.00753583136038,100.00000000000004
4460,"def oo_contains_rule ( source , apiGroups , resources , verbs ) : <TAB>  """"""Return true if the specified rule is contained within the provided source"""""" <TAB>  rules = source [ "" rules "" ] <TAB>  if rules : <TAB><TAB>  for rule in rules : <TAB><TAB><TAB>  if set ( rule [ "" apiGroups "" ] ) == set ( apiGroups ) : <TAB><TAB><TAB><TAB>  if set ( rule [ "" resources "" ] ) == set ( resources ) : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if set ( rule [ ""verbs"" ] ) == set ( verbs ) :",if verbs:,False,60.31051906271831,90.48130008415826
4461,"def _maybe_commit_artifact ( self , artifact_id ) : <TAB>  artifact_status = self . _artifacts [ artifact_id ] <TAB>  if artifact_status [ "" pending_count "" ] == 0 and artifact_status [ "" commit_requested "" ] : <TAB><TAB>  for callback in artifact_status [ "" pre_commit_callbacks "" ] : <TAB><TAB><TAB>  callback ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _api . commit_artifact ( artifact_id ) <TAB><TAB>  for callback in artifact_status [ "" post_commit_callbacks "" ] : <TAB><TAB><TAB>  callback ( ) ","if artifact_status [ ""finalize"" ] :",if self._api:,False,51.305134696154276,94.35907784202398
4462,"def shuffler ( iterator , pool_size = 10 * * 5 , refill_threshold = 0.9 ) : <TAB>  yields_between_refills = round ( pool_size * ( 1 - refill_threshold ) ) <TAB>  # initialize pool; this step may or may not exhaust the iterator. <TAB>  pool = take_n ( pool_size , iterator ) <TAB>  while True : <TAB><TAB>  random . shuffle ( pool ) <TAB><TAB>  for i in range ( yields_between_refills ) : <TAB><TAB><TAB>  yield pool . pop ( ) <TAB><TAB>  next_batch = take_n ( yields_between_refills , iterator ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  pool . extend ( next_batch ) <TAB>  # finish consuming whatever's left - no need for further randomization. <TAB>  yield from pool ",if not next_batch :,if next_batch is None:,False,55.04897671794565,97.55469961208105
4463,"def __getitem__ ( self , key , _get_mode = False ) : <TAB>  if not _get_mode : <TAB><TAB>  if isinstance ( key , ( int , long ) ) : <TAB><TAB><TAB>  return self . _list [ key ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . __class__ ( self . _list [ key ] ) <TAB>  ikey = key . lower ( ) <TAB>  for k , v in self . _list : <TAB><TAB>  if k . lower ( ) == ikey : <TAB><TAB><TAB>  return v <TAB>  # micro optimization: if we are in get mode we will catch that <TAB>  # exception one stack level down so we can raise a standard <TAB>  # key error instead of our special one. <TAB>  if _get_mode : <TAB><TAB>  raise KeyError ( ) <TAB>  raise BadRequestKeyError ( key ) ","elif isinstance ( key , slice ) :","if isinstance(key, int):",False,65.81172066045109,97.75256664257704
4464,"def find ( self , path ) : <TAB>  if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB><TAB>  self . num_files = self . num_files + 1 <TAB><TAB>  if self . match_function ( path ) : <TAB><TAB><TAB>  self . files . append ( path ) <TAB>  elif os . path . isdir ( path ) : <TAB><TAB>  for content in os . listdir ( path ) : <TAB><TAB><TAB>  file = os . path . join ( path , content ) <TAB><TAB><TAB>  if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB><TAB><TAB><TAB>  self . num_files = self . num_files + 1 <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . files . append ( file ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . find ( file ) ",if self . match_function ( file ) :,if self.match_function(file):,False,50.746352179770824,100.00000000000004
4465,"def validate_nb ( self , nb ) : <TAB>  super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB>  ids = set ( [ ] ) <TAB>  for cell in nb . cells : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB><TAB>  solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB><TAB>  locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB><TAB>  if not grade and not solution and not locked : <TAB><TAB><TAB>  continue <TAB><TAB>  grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB><TAB>  if grade_id in ids : <TAB><TAB><TAB>  raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB><TAB>  ids . add ( grade_id ) ","if ""nbgrader"" not in cell . metadata :",if cell.metadata['nbgrader']['num_cells'] == 0:,False,55.20678841664648,94.28843156111843
4466,"def _skip_start ( self ) : <TAB>  start , stop = self . start , self . stop <TAB>  for chunk in self . app_iter : <TAB><TAB>  self . _pos + = len ( chunk ) <TAB><TAB>  if self . _pos < start : <TAB><TAB><TAB>  continue <TAB><TAB>  elif self . _pos == start : <TAB><TAB><TAB>  return b "" "" <TAB><TAB>  else : <TAB><TAB><TAB>  chunk = chunk [ start - self . _pos : ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  chunk = chunk [ : stop - self . _pos ] <TAB><TAB><TAB><TAB>  assert len ( chunk ) == stop - start <TAB><TAB><TAB>  return chunk <TAB>  else : <TAB><TAB>  raise StopIteration ( ) ",if stop is not None and self . _pos > stop :,if chunk.endswith('\n'):,False,19.446992658810398,94.53764931413217
4467,"def _SetUser ( self , users ) : <TAB>  for user in users . items ( ) : <TAB><TAB>  username = user [ 0 ] <TAB><TAB>  settings = user [ 1 ] <TAB><TAB>  room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB><TAB>  file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB><TAB>  if "" event "" in settings : <TAB><TAB><TAB>  if "" joined "" in settings [ "" event "" ] : <TAB><TAB><TAB><TAB>  self . _client . userlist . addUser ( username , room , file_ ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _client . removeUser ( username ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _client . userlist . modUser ( username , room , file_ ) ","elif ""left"" in settings [ ""event"" ] :","if ""deleted"" in settings:",False,23.054985261912396,95.31478451786143
4468,"def run_tests ( ) : <TAB>  # type: () -> None <TAB>  x = 5 <TAB>  with switch ( x ) as case : <TAB><TAB>  if case ( 0 ) : <TAB><TAB><TAB>  print ( "" zero "" ) <TAB><TAB><TAB>  print ( "" zero "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" one or two "" ) <TAB><TAB>  elif case ( 3 , 4 ) : <TAB><TAB><TAB>  print ( "" three or four "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  print ( "" default "" ) <TAB><TAB><TAB>  print ( "" another "" ) ","elif case ( 1 , 2 ) :","if case(1, 2):",False,27.06428238621919,98.5692638970044
4469,"def _populate ( ) : <TAB>  for fname in glob . glob ( os . path . join ( os . path . dirname ( __file__ ) , "" data "" , "" *.json "" ) ) : <TAB><TAB>  with open ( fname ) as inf : <TAB><TAB><TAB>  data = json . load ( inf ) <TAB><TAB><TAB>  data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB><TAB><TAB>  data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB><TAB><TAB>  for item in data : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  LOGGER . warning ( "" Repeated emoji  {} "" . format ( item [ "" key "" ] ) ) <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  TABLE [ item [ "" key "" ] ] = item [ "" value "" ] ","if item [ ""key"" ] in TABLE :",if len(item['keys']) > 1:,False,49.61848013375527,96.10554891152769
4470,"def slot_to_material ( bobject : bpy . types . Object , slot : bpy . types . MaterialSlot ) : <TAB>  mat = slot . material <TAB>  # Pick up backed material if present <TAB>  if mat is not None : <TAB><TAB>  baked_mat = mat . name + "" _ "" + bobject . name + "" _baked "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mat = bpy . data . materials [ baked_mat ] <TAB>  return mat ",if baked_mat in bpy . data . materials :,if baked_mat in bpy.data.materials:,False,56.92751576429427,100.00000000000004
4471,"def __keyPress ( self , widget , event ) : <TAB>  if event . key == "" G "" and event . modifiers & event . Modifiers . Control : <TAB><TAB>  if not all ( hasattr ( p , "" isGanged "" ) for p in self . getPlugs ( ) ) : <TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __ungang ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . __gang ( ) <TAB><TAB>  return True <TAB>  return False ",if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,"if event.key == ""D':",False,20.970797422038455,88.33333125132897
4472,"def check_expected ( result , expected , contains = False ) : <TAB>  if sys . version_info [ 0 ] > = 3 : <TAB><TAB>  if isinstance ( result , str ) : <TAB><TAB><TAB>  result = result . encode ( "" ascii "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  expected = expected . encode ( "" ascii "" ) <TAB>  resultlines = result . splitlines ( ) <TAB>  expectedlines = expected . splitlines ( ) <TAB>  if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB>  return False <TAB>  for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB>  if contains : <TAB><TAB><TAB>  if eline not in rline : <TAB><TAB><TAB><TAB>  return False <TAB><TAB>  else : <TAB><TAB><TAB>  if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB>  return False <TAB>  return True ","if isinstance ( expected , str ) :","if isinstance(expected, str):",False,49.47802890890776,100.00000000000004
4473,"def hosts_to_domains ( self , hosts , exclusions = [ ] ) : <TAB>  domains = [ ] <TAB>  for host in hosts : <TAB><TAB>  elements = host . split ( "" . "" ) <TAB><TAB>  # recursively walk through the elements <TAB><TAB>  # extracting all possible (sub)domains <TAB><TAB>  while len ( elements ) > = 2 : <TAB><TAB><TAB>  # account for domains stored as hosts <TAB><TAB><TAB>  if len ( elements ) == 2 : <TAB><TAB><TAB><TAB>  domain = "" . "" . join ( elements ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  # drop the host element <TAB><TAB><TAB><TAB>  domain = "" . "" . join ( elements [ 1 : ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  domains . append ( domain ) <TAB><TAB><TAB>  del elements [ 0 ] <TAB>  return domains ",if domain not in domains + exclusions :,if domain not in exclusions:,False,57.47373254106336,98.60690398453461
4474,"def hsconn_sender ( self ) : <TAB>  while not self . stop_event . is_set ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  # Block, but timeout, so that we can exit the loop gracefully <TAB><TAB><TAB>  request = self . send_queue . get ( True , 6.0 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  # Socket got closed and set to None in another thread... <TAB><TAB><TAB><TAB>  self . socket . sendall ( request ) <TAB><TAB><TAB>  if self . send_queue is not None : <TAB><TAB><TAB><TAB>  self . send_queue . task_done ( ) <TAB><TAB>  except queue . Empty : <TAB><TAB><TAB>  pass <TAB><TAB>  except OSError : <TAB><TAB><TAB>  self . stop_event . set ( ) ",if self . socket is not None :,if request is not None:,False,66.75893390653675,98.0459594543795
4475,"def get_url_args ( self , item ) : <TAB>  if self . url_args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  url_args = self . url_args ( item ) <TAB><TAB>  else : <TAB><TAB><TAB>  url_args = dict ( self . url_args ) <TAB><TAB>  url_args [ "" id "" ] = item . id <TAB><TAB>  return url_args <TAB>  else : <TAB><TAB>  return dict ( operation = self . label , id = item . id ) ","if hasattr ( self . url_args , ""__call__"" ) :","if hasattr(self.url_args, 'url_args'):",False,50.63381736354591,94.42259180159516
4476,"def list_projects ( self ) : <TAB>  projects = [ ] <TAB>  page = 1 <TAB>  while True : <TAB><TAB>  repos = self . _client . get ( <TAB><TAB><TAB>  "" /user/repos "" , { "" sort "" : "" full_name "" , "" page "" : page , "" per_page "" : 100 } <TAB><TAB>  ) <TAB><TAB>  page + = 1 <TAB><TAB>  for repo in repos : <TAB><TAB><TAB>  projects . append ( <TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB>  "" id "" : repo [ "" full_name "" ] , <TAB><TAB><TAB><TAB><TAB>  "" name "" : repo [ "" full_name "" ] , <TAB><TAB><TAB><TAB><TAB>  "" description "" : repo [ "" description "" ] , <TAB><TAB><TAB><TAB><TAB>  "" is_private "" : repo [ "" private "" ] , <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB>  return projects ",if len ( repos ) < 100 :,if not projects:,False,47.450121175799204,97.4745847924483
4477,"def scripts ( self ) : <TAB>  application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB>  subdir = application_root != "" / "" <TAB>  scripts = [ ] <TAB>  for script in get_registered_scripts ( ) : <TAB><TAB>  if script . startswith ( "" http "" ) : <TAB><TAB><TAB>  scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB><TAB>  else : <TAB><TAB><TAB>  scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB>  return markup ( "" \n "" . join ( scripts ) ) ",elif subdir :,if subdir:,False,17.592421559925477,93.78794994767256
4478,"def print_map ( node , l ) : <TAB>  if node . title not in l : <TAB><TAB>  l [ node . title ] = [ ] <TAB>  for n in node . children : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  w = { n . title : [ ] } <TAB><TAB><TAB>  l [ node . title ] . append ( w ) <TAB><TAB><TAB>  print_map ( n , w ) <TAB><TAB>  else : <TAB><TAB><TAB>  l [ node . title ] . append ( n . title ) ",if len ( n . children ) > 0 :,if n.title == '':,False,43.3964445550066,94.01185595191069
4479,"def _validate_distinct_on_different_types_and_field_orders ( <TAB>  self , collection , query , expected_results , get_mock_result  ) : <TAB>  self . count = 0 <TAB>  self . get_mock_result = get_mock_result <TAB>  query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB>  results = list ( query_iterable ) <TAB>  for i in range ( len ( expected_results ) ) : <TAB><TAB>  if isinstance ( results [ i ] , dict ) : <TAB><TAB><TAB>  self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB>  self . count = 0 ","elif isinstance ( results [ i ] , list ) :","if isinstance(results[i], list):",False,34.497366185688264,98.9439852526484
4480,"def run ( self ) : <TAB>  for k , v in iteritems ( self . objs ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if ( <TAB><TAB><TAB>  v [ "" _class "" ] == "" Question "" <TAB><TAB><TAB>  or v [ "" _class "" ] == "" Message "" <TAB><TAB><TAB>  or v [ "" _class "" ] == "" Announcement "" <TAB><TAB>  ) : <TAB><TAB><TAB>  v [ "" admin "" ] = None <TAB>  return self . objs ","if k . startswith ( ""_"" ) :",if k == 'admin':,False,45.61372869036211,94.33477597132726
4481,"def qvec ( self ) : <TAB>  #<TAB><TAB>if self.polrep != 'stokes': <TAB>  #<TAB><TAB><TAB>raise Exception(""qvec is not defined unless self.polrep=='stokes'"") <TAB>  qvec = np . array ( [ ] ) <TAB>  if self . polrep == "" stokes "" : <TAB><TAB>  qvec = self . _imdict [ "" Q "" ] <TAB>  elif self . polrep == "" circ "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  qvec = np . real ( 0.5 * ( self . lrvec + self . rlvec ) ) <TAB>  return qvec ",if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 :,if self.polrep == 'stokes':,False,30.317558572372654,88.18459781472244
4482,"def display_value ( self , key , w ) : <TAB>  if key == "" vdevices "" : <TAB><TAB>  # Very special case <TAB><TAB>  nids = [ n [ "" deviceID "" ] for n in self . get_value ( "" devices "" ) ] <TAB><TAB>  for device in self . app . devices . values ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  b = Gtk . CheckButton ( device . get_title ( ) , False ) <TAB><TAB><TAB><TAB>  b . set_tooltip_text ( device [ "" id "" ] ) <TAB><TAB><TAB><TAB>  self [ "" vdevices "" ] . pack_start ( b , False , False , 0 ) <TAB><TAB><TAB><TAB>  b . set_active ( device [ "" id "" ] in nids ) <TAB><TAB>  self [ "" vdevices "" ] . show_all ( ) <TAB>  else : <TAB><TAB>  EditorDialog . display_value ( self , key , w ) ","if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :",if device['deviceID'] in nids:,False,51.73665015033711,92.24241083668477
4483,"def _set_xflux_setting ( self , * * kwargs ) : <TAB>  for key , value in kwargs . items ( ) : <TAB><TAB>  if key in self . _settings_map : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _set_xflux_screen_color ( value ) <TAB><TAB><TAB><TAB>  self . _current_color = str ( value ) <TAB><TAB><TAB><TAB>  # hackish - changing the current color unpauses xflux, <TAB><TAB><TAB><TAB>  # must reflect that with state change <TAB><TAB><TAB><TAB>  if self . state == self . states [ "" PAUSED "" ] : <TAB><TAB><TAB><TAB><TAB>  self . state = self . states [ "" RUNNING "" ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _xflux . sendline ( self . _settings_map [ key ] + str ( value ) ) <TAB><TAB><TAB>  self . _c ( ) ","if key == ""color"" :",if self._settings_map[key] == value:,False,42.86635238948557,95.35432418108718
4484,"def apply_acceleration ( self , veh_ids , acc ) : <TAB>  """"""See parent class."""""" <TAB>  # to hand the case of a single vehicle <TAB>  if type ( veh_ids ) == str : <TAB><TAB>  veh_ids = [ veh_ids ] <TAB><TAB>  acc = [ acc ] <TAB>  for i , vid in enumerate ( veh_ids ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  this_vel = self . get_speed ( vid ) <TAB><TAB><TAB>  next_vel = max ( [ this_vel + acc [ i ] * self . sim_step , 0 ] ) <TAB><TAB><TAB>  self . kernel_api . vehicle . slowDown ( vid , next_vel , 1e-3 ) ",if acc [ i ] is not None and vid in self . get_ids ( ) :,"if isinstance(vid, int):",False,55.83118721349074,91.36061103716179
4485,"def largest_factor_relatively_prime ( a , b ) : <TAB>  """"""Return the largest factor of a relatively prime to b."""""" <TAB>  while 1 : <TAB><TAB>  d = gcd ( a , b ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  b = d <TAB><TAB>  while 1 : <TAB><TAB><TAB>  q , r = divmod ( a , d ) <TAB><TAB><TAB>  if r > 0 : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  a = q <TAB>  return a ",if d <= 1 :,if d < 0:,False,38.244914865515355,97.74522150899801
4486,"def check_status ( self ) : <TAB>  try : <TAB><TAB>  du = psutil . disk_usage ( "" / "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ServiceWarning ( <TAB><TAB><TAB><TAB>  "" {host} {percent} % d isk usage exceeds  {disk_usage} % "" . format ( <TAB><TAB><TAB><TAB><TAB>  host = host , percent = du . percent , disk_usage = DISK_USAGE_MAX <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  except ValueError as e : <TAB><TAB>  self . add_error ( ServiceReturnedUnexpectedResult ( "" ValueError "" ) , e ) ",if DISK_USAGE_MAX and du . percent >= DISK_USAGE_MAX :,if du.percent > DISK_USAGE_MAX:,False,22.32774115281485,93.16984673748465
4487,"def build_reply ( self , msg , text = None , private = False , threaded = False ) : <TAB>  response = self . build_message ( text ) <TAB>  if msg . is_group : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  response . frm = self . bot_identifier <TAB><TAB><TAB>  response . to = IRCPerson ( str ( msg . frm ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  response . frm = IRCRoomOccupant ( str ( self . bot_identifier ) , msg . frm . room ) <TAB><TAB><TAB>  response . to = msg . frm . room <TAB>  else : <TAB><TAB>  response . frm = self . bot_identifier <TAB><TAB>  response . to = msg . frm <TAB>  return response ",if private :,if private:,False,50.42929263514608,100.00000000000004
4488,"def _dict_refs ( obj , named ) : <TAB>  """"""Return key and value objects of a dict/proxy."""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for k , v in _items ( obj ) : <TAB><TAB><TAB><TAB>  s = str ( k ) <TAB><TAB><TAB><TAB>  yield _NamedRef ( "" [K]  "" + s , k ) <TAB><TAB><TAB><TAB>  yield _NamedRef ( "" [V]  "" + s + "" :  "" + _repr ( v ) , v ) <TAB><TAB>  else : <TAB><TAB><TAB>  for k , v in _items ( obj ) : <TAB><TAB><TAB><TAB>  yield k <TAB><TAB><TAB><TAB>  yield v <TAB>  except ( KeyError , ReferenceError , TypeError ) as x : <TAB><TAB>  warnings . warn ( "" Iterating  ' %s ' :  %r "" % ( _classof ( obj ) , x ) ) ",if named :,if named:,False,56.91903596021868,98.56529474017624
4489,"def fetch_images ( ) : <TAB>  images = [ ] <TAB>  marker = None <TAB>  while True : <TAB><TAB>  batch = image_service . detail ( <TAB><TAB><TAB>  context , <TAB><TAB><TAB>  filters = filters , <TAB><TAB><TAB>  marker = marker , <TAB><TAB><TAB>  sort_key = "" created_at "" , <TAB><TAB><TAB>  sort_dir = "" desc "" , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  images + = batch <TAB><TAB>  marker = batch [ - 1 ] [ "" id "" ] <TAB>  return images ",if not batch :,if not batch:,False,46.22605507851713,97.95258736552388
4490,"def compress ( self , data_list ) : <TAB>  warn_untested ( ) <TAB>  if data_list : <TAB><TAB>  if data_list [ 1 ] in forms . fields . EMPTY_VALUES : <TAB><TAB><TAB>  error = self . error_messages [ "" invalid_year "" ] <TAB><TAB><TAB>  raise forms . ValidationError ( error ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  error = self . error_messages [ "" invalid_month "" ] <TAB><TAB><TAB>  raise forms . ValidationError ( error ) <TAB><TAB>  year = int ( data_list [ 1 ] ) <TAB><TAB>  month = int ( data_list [ 0 ] ) <TAB><TAB>  # find last day of the month <TAB><TAB>  day = monthrange ( year , month ) [ 1 ] <TAB><TAB>  return date ( year , month , day ) <TAB>  return None ",if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,if data_list[1] == 0:,False,39.97095450871267,95.21120683622496
4491,"def _diff_dict ( self , old , new ) : <TAB>  diff = { } <TAB>  removed = [ ] <TAB>  added = [ ] <TAB>  for key , value in old . items ( ) : <TAB><TAB>  if key not in new : <TAB><TAB><TAB>  removed . append ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # modified is indicated by a remove and add <TAB><TAB><TAB>  removed . append ( key ) <TAB><TAB><TAB>  added . append ( key ) <TAB>  for key , value in new . items ( ) : <TAB><TAB>  if key not in old : <TAB><TAB><TAB>  added . append ( key ) <TAB>  if removed : <TAB><TAB>  diff [ "" removed "" ] = sorted ( removed ) <TAB>  if added : <TAB><TAB>  diff [ "" added "" ] = sorted ( added ) <TAB>  return diff ",elif old [ key ] != new [ key ] :,if key not in old:,False,51.46090745363563,94.79269671227684
4492,"def add_filters ( self , function ) : <TAB>  try : <TAB><TAB>  subscription = self . exists ( function ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  response = self . _sns . call ( <TAB><TAB><TAB><TAB>  "" set_subscription_attributes "" , <TAB><TAB><TAB><TAB>  SubscriptionArn = subscription [ "" SubscriptionArn "" ] , <TAB><TAB><TAB><TAB>  AttributeName = "" FilterPolicy "" , <TAB><TAB><TAB><TAB>  AttributeValue = json . dumps ( self . filters ) , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  kappa . event_source . sns . LOG . debug ( response ) <TAB>  except Exception : <TAB><TAB>  kappa . event_source . sns . LOG . exception ( <TAB><TAB><TAB>  "" Unable to add filters for SNS topic  %s "" , self . arn <TAB><TAB>  ) ",if subscription :,if subscription:,False,59.379793990522046,100.00000000000004
4493,"def init_weights ( self , pretrained = None ) : <TAB>  if isinstance ( pretrained , str ) : <TAB><TAB>  logger = logging . getLogger ( ) <TAB><TAB>  load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB>  elif pretrained is None : <TAB><TAB>  for m in self . modules ( ) : <TAB><TAB><TAB>  if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB><TAB>  kaiming_init ( m ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  constant_init ( m , 1 ) <TAB>  else : <TAB><TAB>  raise TypeError ( "" pretrained must be a str or None "" ) ","elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) :","if isinstance(m, nn.Conv2d):",False,53.45476215735951,94.13426660844691
4494,def test_is_native_login ( self ) : <TAB>  for campaign in self . campaign_lists : <TAB><TAB>  native = campaigns . is_native_login ( campaign ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert_true ( native ) <TAB><TAB>  else : <TAB><TAB><TAB>  assert_false ( native ) <TAB>  native = campaigns . is_proxy_login ( self . invalid_campaign ) <TAB>  assert_true ( native is None ) ,"if campaign == ""prereg"" or campaign == ""erpc"" :",if native:,False,24.912350338222296,88.47144307278262
4495,"def _process_filter ( self , query , host_state ) : <TAB>  """"""Recursively parse the query structure."""""" <TAB>  if not query : <TAB><TAB>  return True <TAB>  cmd = query [ 0 ] <TAB>  method = self . commands [ cmd ] <TAB>  cooked_args = [ ] <TAB>  for arg in query [ 1 : ] : <TAB><TAB>  if isinstance ( arg , list ) : <TAB><TAB><TAB>  arg = self . _process_filter ( arg , host_state ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  arg = self . _parse_string ( arg , host_state ) <TAB><TAB>  if arg is not None : <TAB><TAB><TAB>  cooked_args . append ( arg ) <TAB>  result = method ( self , cooked_args ) <TAB>  return result ","elif isinstance ( arg , basestring ) :","if isinstance(arg, basestring):",False,29.921613785766414,98.79073721675567
4496,"def find_go_files_mtime ( app_files ) : <TAB>  files , mtime = [ ] , 0 <TAB>  for f , mt in app_files . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if APP_CONFIG . nobuild_files . match ( f ) : <TAB><TAB><TAB>  continue <TAB><TAB>  files . append ( f ) <TAB><TAB>  mtime = max ( mtime , mt ) <TAB>  return files , mtime ","if not f . endswith ( "".go"" ) :",if f.startswith('go') or f.startswith('go'):,False,24.688558426866287,90.78373761987291
4497,"def ExcludePath ( self , path ) : <TAB>  """"""Check to see if this is a service url and matches inbound_services."""""" <TAB>  skip = False <TAB>  for reserved_path in self . reserved_paths . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if ( <TAB><TAB><TAB><TAB>  not self . inbound_services <TAB><TAB><TAB><TAB>  or self . reserved_paths [ reserved_path ] not in self . inbound_services <TAB><TAB><TAB>  ) : <TAB><TAB><TAB><TAB>  return ( True , self . reserved_paths [ reserved_path ] ) <TAB>  return ( False , None ) ",if path . startswith ( reserved_path ) :,if path.endswith(reserved_path) and skip:,False,60.781432343566145,96.62227870195291
4498,"def param_cov ( self ) - > DataFrame : <TAB>  """"""Parameter covariance"""""" <TAB>  if self . _param_cov is not None : <TAB><TAB>  param_cov = self . _param_cov <TAB>  else : <TAB><TAB>  params = np . asarray ( self . params ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  param_cov = self . model . compute_param_cov ( params ) <TAB><TAB>  else : <TAB><TAB><TAB>  param_cov = self . model . compute_param_cov ( params , robust = False ) <TAB>  return DataFrame ( param_cov , columns = self . _names , index = self . _names ) ","if self . cov_type == ""robust"" :",if self.params is None:,False,31.058905231040058,94.56464481407734
4499,"def test_calculate_all_attentions ( module , atype ) : <TAB>  m = importlib . import_module ( module ) <TAB>  args = make_arg ( atype = atype ) <TAB>  <IF-STMT>: <TAB><TAB>  batch = prepare_inputs ( "" pytorch "" ) <TAB>  else : <TAB><TAB>  raise NotImplementedError <TAB>  model = m . E2E ( 6 , 5 , args ) <TAB>  with chainer . no_backprop_mode ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  att_ws = model . calculate_all_attentions ( * batch ) [ 0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  raise NotImplementedError <TAB><TAB>  print ( att_ws . shape ) ","if ""pytorch"" in module :",if args.get('pytorch'):,False,20.326367056885523,92.18634256823213
4500,"def __eq__ ( self , other ) : <TAB>  try : <TAB><TAB>  if self . type != other . type : <TAB><TAB><TAB>  return False <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . askAnswer == other . askAnswer <TAB><TAB>  elif self . type == "" SELECT "" : <TAB><TAB><TAB>  return self . vars == other . vars and self . bindings == other . bindings <TAB><TAB>  else : <TAB><TAB><TAB>  return self . graph == other . graph <TAB>  except : <TAB><TAB>  return False ","if self . type == ""ASK"" :","if self.type == ""SELECT':",False,19.368006408380435,97.78797913289853
4501,"def validate_memory ( self , value ) : <TAB>  for k , v in value . viewitems ( ) : <TAB><TAB>  if v is None :<TAB># use NoneType to unset a value <TAB><TAB><TAB>  continue <TAB><TAB>  if not re . match ( PROCTYPE_MATCH , k ) : <TAB><TAB><TAB>  raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise serializers . ValidationError ( <TAB><TAB><TAB><TAB>  "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB><TAB><TAB>  ) <TAB>  return value ","if not re . match ( MEMLIMIT_MATCH , str ( v ) ) :","if not re.match(PROCTYPE_MATCH, k):",False,36.86004896151872,94.67657373858938
4502,"def get_connections ( data_about ) : <TAB>  data = data_about . find ( "" h3 "" , text = "" Connections "" ) . findNext ( ) <TAB>  connections = { } <TAB>  for row in data . find_all ( "" tr "" ) : <TAB><TAB>  key = row . find_all ( "" td "" ) [ 0 ] . text <TAB><TAB>  value = row . find_all ( "" td "" ) [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  connections [ key ] = get_all_links ( value ) <TAB><TAB>  else : <TAB><TAB><TAB>  connections [ key ] = value . text <TAB>  return connections ","if ""Teams"" in key :",if key not in connections:,False,24.555278303529924,96.38578652170705
4503,"def _compute_map ( self , first_byte , second_byte = None ) : <TAB>  if first_byte != 0x0F : <TAB><TAB>  return "" XED_ILD_MAP0 "" <TAB>  else : <TAB><TAB>  if second_byte == None : <TAB><TAB><TAB>  return "" XED_ILD_MAP1 "" <TAB><TAB>  if second_byte == 0x38 : <TAB><TAB><TAB>  return "" XED_ILD_MAP2 "" <TAB><TAB>  if second_byte == 0x3A : <TAB><TAB><TAB>  return "" XED_ILD_MAP3 "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" XED_ILD_MAPAMD "" <TAB>  die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) ) ",if second_byte == 0x0F and self . amd_enabled :,if first_byte == 0x0F:,False,53.765569320345264,95.10048579681917
4504,"def compress ( self , data_list ) : <TAB>  if data_list : <TAB><TAB>  page_id = data_list [ 1 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if not self . required : <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB><TAB>  return Page . objects . get ( pk = page_id ) <TAB>  return None ",if page_id in EMPTY_VALUES :,if page_id == self.page_id:,False,21.120555393729674,93.66070548157859
4505,"def find_module ( self , fullname , path = None ) : <TAB>  path = path or self . path_entry <TAB>  # print('looking for ""%s"" in %s ...' % (fullname, path)) <TAB>  for _ext in [ "" js "" , "" pyj "" , "" py "" ] : <TAB><TAB>  _filepath = os . path . join ( self . path_entry , "" %s . %s "" % ( fullname , _ext ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" module found at  %s : %s "" % ( _filepath , fullname ) ) <TAB><TAB><TAB>  return VFSModuleLoader ( _filepath , fullname ) <TAB>  print ( "" module  %s  not found "" % fullname ) <TAB>  raise ImportError ( ) <TAB>  return None ",if _filepath in VFS :,if os.path.exists(_filepath):,False,58.048622082644606,95.0524485964506
4506,"def __decToBin ( self , myDec ) : <TAB>  n = 0 <TAB>  binOfDec = "" "" <TAB>  while myDec > 2 * * n : <TAB><TAB>  n = n + 1 <TAB>  if ( myDec < 2 * * n ) & ( myDec != 0 ) : <TAB><TAB>  n = n - 1 <TAB>  while n > = 0 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  myDec = myDec - 2 * * n <TAB><TAB><TAB>  binOfDec = binOfDec + "" 1 "" <TAB><TAB>  else : <TAB><TAB><TAB>  binOfDec = binOfDec + "" 0 "" <TAB><TAB>  n = n - 1 <TAB>  return binOfDec ",if myDec >= 2 ** n :,if myDec < 2 * n:,False,45.598147302826064,97.07730602052357
4507,"def __str__ ( self ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  NVMLError . _errcode_to_string [ self . value ] = str ( nvmlErrorString ( self . value ) ) <TAB><TAB>  return NVMLError . _errcode_to_string [ self . value ] <TAB>  except NVMLError_Uninitialized : <TAB><TAB>  return "" NVML Error with code  %d "" % self . value ",if self . value not in NVMLError . _errcode_to_string :,if self.value in NVMLError._errcode_to_string:,False,52.41822138282528,97.78993419344799
4508,"def abspath ( pathdir : str ) - > str : <TAB>  if Path is not None and isinstance ( pathdir , Path ) : <TAB><TAB>  return pathdir . abspath ( ) <TAB>  else : <TAB><TAB>  pathdir = path . abspath ( pathdir ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  pathdir = pathdir . decode ( fs_encoding ) <TAB><TAB><TAB>  except UnicodeDecodeError as exc : <TAB><TAB><TAB><TAB>  raise UnicodeDecodeError ( <TAB><TAB><TAB><TAB><TAB>  "" multibyte filename not supported on  "" <TAB><TAB><TAB><TAB><TAB>  "" this filesystem encoding  "" <TAB><TAB><TAB><TAB><TAB>  "" ( %r ) "" % fs_encoding <TAB><TAB><TAB><TAB>  ) from exc <TAB><TAB>  return pathdir ","if isinstance ( pathdir , bytes ) :",if fs_encoding:,False,33.72723777354878,96.62526073034088
4509,"def _get_vtkjs ( self ) : <TAB>  if self . _vtkjs is None and self . object is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isfile ( self . object ) : <TAB><TAB><TAB><TAB>  with open ( self . object , "" rb "" ) as f : <TAB><TAB><TAB><TAB><TAB>  vtkjs = f . read ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  data_url = urlopen ( self . object ) <TAB><TAB><TAB><TAB>  vtkjs = data_url . read ( ) <TAB><TAB>  elif hasattr ( self . object , "" read "" ) : <TAB><TAB><TAB>  vtkjs = self . object . read ( ) <TAB><TAB>  self . _vtkjs = vtkjs <TAB>  return self . _vtkjs ","if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :","if hasattr(self.object, 'read'):",False,49.384805028176416,91.60373205518204
4510,"def _set_uid ( self , val ) : <TAB>  if val is not None : <TAB><TAB>  if pwd is None : <TAB><TAB><TAB>  self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB><TAB><TAB>  val = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = pwd . getpwnam ( val ) [ 2 ] <TAB>  self . _uid = val ","elif isinstance ( val , text_or_bytes ) :",if val is not None:,False,37.19814192885198,89.58020836272864
4511,"def get_attached_nodes ( self , external_account ) : <TAB>  for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB><TAB>  if node_settings is None : <TAB><TAB><TAB>  continue <TAB><TAB>  if node_settings . external_account == external_account : <TAB><TAB><TAB>  yield node ",if node is None :,if node is None:,False,51.5449220520716,100.00000000000004
4512,"def from_obj ( cls , py_obj ) : <TAB>  if not isinstance ( py_obj , Image ) : <TAB><TAB>  raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB>  else : <TAB><TAB>  if hasattr ( py_obj , "" _boxes "" ) and py_obj . _boxes : <TAB><TAB><TAB>  box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  box_keys = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mask_keys = list ( py_obj . masks . keys ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  mask_keys = [ ] <TAB><TAB>  return cls ( box_keys , mask_keys ) ","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :","if hasattr(py_obj, 'masks'):",False,29.48533820313699,94.70614195588112
4513,"def write ( self , * bits ) : <TAB>  for bit in bits : <TAB><TAB>  if not self . bytestream : <TAB><TAB><TAB>  self . bytestream . append ( 0 ) <TAB><TAB>  byte = self . bytestream [ self . bytenum ] <TAB><TAB>  if self . bitnum == 8 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  byte = 0 <TAB><TAB><TAB><TAB>  self . bytestream + = bytes ( [ byte ] ) <TAB><TAB><TAB>  self . bytenum + = 1 <TAB><TAB><TAB>  self . bitnum = 0 <TAB><TAB>  mask = 2 * * self . bitnum <TAB><TAB>  if bit : <TAB><TAB><TAB>  byte | = mask <TAB><TAB>  else : <TAB><TAB><TAB>  byte & = ~ mask <TAB><TAB>  self . bytestream [ self . bytenum ] = byte <TAB><TAB>  self . bitnum + = 1 ",if self . bytenum == len ( self . bytestream ) - 1 :,if byte == 0:,False,31.71041048294751,94.48417948562347
4514,"def destroy ( self , wipe = False ) : <TAB>  if self . state == self . UP : <TAB><TAB>  image = self . image ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . confirm_destroy ( image , self . full_name , abort = False ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . warn ( "" tried to destroy  {0}  which didn ' t exist "" . format ( self . full_name ) ) <TAB>  return True ",if image :,if image:,False,54.975659950251554,96.2518143306129
4515,"def get_host_metadata ( self ) : <TAB>  meta = { } <TAB>  if self . agent_url : <TAB><TAB>  try : <TAB><TAB><TAB>  resp = requests . get ( <TAB><TAB><TAB><TAB>  self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB><TAB><TAB>  ) . json ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB><TAB><TAB><TAB>  if match is not None and len ( match . groups ( ) ) == 1 : <TAB><TAB><TAB><TAB><TAB>  meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB>  return meta ","if ""Version"" in resp :",if resp.get('Version'):,False,27.9736095124947,97.04214243342992
4516,"def _path_type ( st , lst ) : <TAB>  parts = [ ] <TAB>  if st : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parts . append ( "" file "" ) <TAB><TAB>  elif stat . S_ISDIR ( st . st_mode ) : <TAB><TAB><TAB>  parts . append ( "" dir "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  parts . append ( "" other "" ) <TAB>  if lst : <TAB><TAB>  if stat . S_ISLNK ( lst . st_mode ) : <TAB><TAB><TAB>  parts . append ( "" link "" ) <TAB>  return "" "" . join ( parts ) ",if stat . S_ISREG ( st . st_mode ) :,if stat.S_IFREG(st.st_mode):,False,50.7078356161071,98.5692638970044
4517,"def changed ( self , action ) : <TAB>  # Something was changed in the 'files' list <TAB>  if len ( action . key ) > = 1 and action . key [ 0 ] . lower ( ) == "" files "" : <TAB><TAB>  # Refresh project files model <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Don't clear the existing items if only inserting new things <TAB><TAB><TAB>  self . update_model ( clear = False ) <TAB><TAB>  else : <TAB><TAB><TAB>  # Clear existing items <TAB><TAB><TAB>  self . update_model ( clear = True ) ","if action . type == ""insert"" :",if action.key[0].lower() == 'files':,False,39.98369632254813,92.56934995412904
4518,"def process ( self , resources , event = None ) : <TAB>  client = local_session ( self . manager . session_factory ) . client ( "" es "" ) <TAB>  for r in resources : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = self . manager . retry ( <TAB><TAB><TAB><TAB>  client . describe_elasticsearch_domain_config , <TAB><TAB><TAB><TAB>  DomainName = r [ "" DomainName "" ] , <TAB><TAB><TAB><TAB>  ignore_err_codes = ( "" ResourceNotFoundException "" , ) , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  if result : <TAB><TAB><TAB><TAB>  r [ self . policy_attribute ] = json . loads ( <TAB><TAB><TAB><TAB><TAB>  result . get ( "" DomainConfig "" ) . get ( "" AccessPolicies "" ) . get ( "" Options "" ) <TAB><TAB><TAB><TAB>  ) <TAB>  return super ( ) . process ( resources ) ",if self . policy_attribute not in r :,if r['DomainName'] == self.domain_name:,False,49.13041309181488,95.58647116919305
4519,"def line_items ( self ) : <TAB>  line_items = [ ] <TAB>  for line in self . lines_str : <TAB><TAB>  line = line . split ( "" | "" ) <TAB><TAB>  line = line [ 1 : - 1 ]<TAB># del first and last empty item (consequence of split) <TAB><TAB>  items = [ ] <TAB><TAB>  for item in line : <TAB><TAB><TAB>  i = re . search ( r "" ( \ S+([  \ t]+ \ S+)*)+ "" , item ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  items . append ( i . group ( ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  items . append ( "" "" ) <TAB><TAB>  line_items . append ( items ) <TAB>  return line_items ",if i :,if i:,False,29.121209304576507,96.6606456470363
4520,"def on_data ( res ) : <TAB>  if terminate . is_set ( ) : <TAB><TAB>  return <TAB>  if args . strings and not args . no_content : <TAB><TAB>  if type ( res ) == tuple : <TAB><TAB><TAB>  f , v = res <TAB><TAB><TAB>  if type ( f ) == unicode : <TAB><TAB><TAB><TAB>  f = f . encode ( "" utf-8 "" ) <TAB><TAB><TAB>  if type ( v ) == unicode : <TAB><TAB><TAB><TAB>  v = v . encode ( "" utf-8 "" ) <TAB><TAB><TAB>  self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . success ( res ) <TAB>  else : <TAB><TAB>  self . success ( res ) ",elif not args . content_only :,if not args.strings:,False,25.892125682158163,96.85957436163112
4521,"def get_servers ( self , detail = True , search_opts = None ) : <TAB>  rel_url = "" /servers/detail "" if detail else "" /servers "" <TAB>  if search_opts is not None : <TAB><TAB>  qparams = { } <TAB><TAB>  for opt , val in search_opts . iteritems ( ) : <TAB><TAB><TAB>  qparams [ opt ] = val <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  query_string = "" ? %s "" % urllib . urlencode ( qparams ) <TAB><TAB><TAB>  rel_url + = query_string <TAB>  return self . api_get ( rel_url ) [ "" servers "" ] ",if qparams :,if qparams:,False,48.900493773152974,100.00000000000004
4522,"def run ( self ) : <TAB>  while not self . __exit__ : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sleep ( 10 ) <TAB><TAB><TAB>  continue <TAB><TAB>  o = self . playlist [ 0 ] <TAB><TAB>  self . playlist . remove ( o ) <TAB><TAB>  obj = json . loads ( o ) <TAB><TAB>  if not "" args "" in obj : <TAB><TAB><TAB>  obj [ "" args "" ] = { "" ua "" : "" "" , "" header "" : "" "" , "" title "" : "" "" , "" referer "" : "" "" } <TAB><TAB>  obj [ "" play "" ] = False <TAB><TAB>  self . handle = launch_player ( obj [ "" urls "" ] , obj [ "" ext "" ] , * * obj [ "" args "" ] ) <TAB><TAB>  self . handle . wait ( ) ",if len ( self . playlist ) == 0 :,if not self.playlist:,False,43.49625955227575,95.93461845580514
4523,"def get_to_download_runs_ids ( session , headers ) : <TAB>  last_date = 0 <TAB>  result = [ ] <TAB>  while 1 : <TAB><TAB>  r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB><TAB><TAB>  result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB><TAB><TAB>  last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB><TAB><TAB>  since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB><TAB><TAB>  print ( f "" pares keep ids data since  { since_time } "" ) <TAB><TAB><TAB>  time . sleep ( 1 )<TAB># spider rule <TAB><TAB><TAB>  if not last_date : <TAB><TAB><TAB><TAB>  break <TAB>  return result ",if r . ok :,if r:,False,25.472882540208065,97.82329640837675
4524,"def __saveWork ( self , work , results ) : <TAB>  """"""Stores the resulting last log line to the cache with the proxy key"""""" <TAB>  del work <TAB>  # pylint: disable=broad-except <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  __cached = self . __cache [ results [ 0 ] ] <TAB><TAB><TAB>  __cached [ self . __TIME ] = time . time ( ) <TAB><TAB><TAB>  __cached [ self . __LINE ] = results [ 1 ] <TAB><TAB><TAB>  __cached [ self . __LLU ] = results [ 2 ] <TAB>  except KeyError as e : <TAB><TAB>  # Could happen while switching jobs with work in the queue <TAB><TAB>  pass <TAB>  except Exception as e : <TAB><TAB>  list ( map ( logger . warning , cuegui . Utils . exceptionOutput ( e ) ) ) ",if results :,if results:,False,65.19766288900655,100.00000000000004
4525,"def read_notes ( rec ) : <TAB>  found = [ ] <TAB>  for tag in range ( 500 , 595 ) : <TAB><TAB>  if tag in ( 505 , 520 ) : <TAB><TAB><TAB>  continue <TAB><TAB>  fields = rec . get_fields ( str ( tag ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  for f in fields : <TAB><TAB><TAB>  x = f . get_lower_subfields ( ) <TAB><TAB><TAB>  if x : <TAB><TAB><TAB><TAB>  found . append ( "" "" . join ( x ) . strip ( "" "" ) ) <TAB>  if found : <TAB><TAB>  return "" \n \n "" . join ( found ) ",if not fields :,if not fields:,False,51.05463589016013,100.00000000000004
4526,"def serialize_to ( self , stream , alternate_script = None ) : <TAB>  stream . write ( self . txo_ref . tx_ref . hash ) <TAB>  stream . write_uint32 ( self . txo_ref . position ) <TAB>  if alternate_script is not None : <TAB><TAB>  stream . write_string ( alternate_script ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  stream . write_string ( self . coinbase ) <TAB><TAB>  else : <TAB><TAB><TAB>  stream . write_string ( self . script . source ) <TAB>  stream . write_uint32 ( self . sequence ) ",if self . is_coinbase :,if self.coinbase is not None:,False,52.09428989290939,96.8097189290435
4527,"def func_named ( self , arg ) : <TAB>  result = None <TAB>  target = "" do_ "" + arg <TAB>  if target in dir ( self ) : <TAB><TAB>  result = target <TAB>  else : <TAB><TAB>  <IF-STMT>:<TAB># accept shortened versions of commands <TAB><TAB><TAB>  funcs = [ fname for fname in self . keywords if fname . startswith ( arg ) ] <TAB><TAB><TAB>  if len ( funcs ) == 1 : <TAB><TAB><TAB><TAB>  result = "" do_ "" + funcs [ 0 ] <TAB>  return result ",if self . abbrev :,if arg in self.keywords:,False,22.182074162648874,93.4446477252373
4528,"def static_login ( self , token , * , bot ) : <TAB>  # Necessary to get aiohttp to stop complaining about session creation <TAB>  self . __session = aiohttp . ClientSession ( <TAB><TAB>  connector = self . connector , ws_response_class = DiscordClientWebSocketResponse <TAB>  ) <TAB>  old_token , old_bot = self . token , self . bot_token <TAB>  self . _token ( token , bot = bot ) <TAB>  try : <TAB><TAB>  data = await self . request ( Route ( "" GET "" , "" /users/@me "" ) ) <TAB>  except HTTPException as exc : <TAB><TAB>  self . _token ( old_token , bot = old_bot ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise LoginFailure ( "" Improper token has been passed. "" ) from exc <TAB><TAB>  raise <TAB>  return data ",if exc . response . status == 401 :,if not self.token:,False,34.17482094684237,95.57379241655585
4529,"def render_buttons ( self ) : <TAB>  for x , button in enumerate ( self . button_list ) : <TAB><TAB>  gcolor = Gdk . color_parse ( self . color_list [ x ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fgcolor = Gdk . color_parse ( "" #FFFFFF "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  fgcolor = Gdk . color_parse ( "" #000000 "" ) <TAB><TAB>  button . set_label ( self . color_list [ x ] ) <TAB><TAB>  button . set_sensitive ( True ) <TAB><TAB>  button . modify_bg ( Gtk . StateType . NORMAL , gcolor ) <TAB><TAB>  button . modify_fg ( Gtk . StateType . NORMAL , fgcolor ) ","if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :",if x == 0:,False,32.341742258533344,87.77452157201893
4530,"def _set_text ( self , data ) : <TAB>  lines = [ ] <TAB>  for key , value in data . items ( ) : <TAB><TAB>  lines . append ( "" "" ) <TAB><TAB>  txt = yaml . dump ( { key : value } , default_flow_style = False ) <TAB><TAB>  title = self . titles . get ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lines . append ( "" #  %s "" % title ) <TAB><TAB>  lines . append ( txt . rstrip ( ) ) <TAB>  txt = "" \n "" . join ( lines ) + "" \n "" <TAB>  txt = txt . lstrip ( ) <TAB>  self . edit . setPlainText ( txt ) ",if title :,if title:,False,50.766853553088666,100.00000000000004
4531,"def build_path ( self ) : <TAB>  for variable in re_path_template . findall ( self . path ) : <TAB><TAB>  name = variable . strip ( "" {} "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # No 'user' parameter provided, fetch it from Auth instead. <TAB><TAB><TAB>  value = self . api . auth . get_username ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  value = quote ( self . session . params [ name ] ) <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  raise TweepError ( <TAB><TAB><TAB><TAB><TAB>  "" No parameter value found for path variable:  %s "" % name <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  del self . session . params [ name ] <TAB><TAB>  self . path = self . path . replace ( variable , value ) ","if name == ""user"" and ""user"" not in self . session . params and self . api . auth :",if not name in self.session.params:,False,53.37241975927913,92.57403085312659
4532,"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB>  writes = 0 <TAB>  for prop_name in entity . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  prop_vals = entity [ prop_name ] <TAB><TAB><TAB>  if isinstance ( prop_vals , ( list ) ) : <TAB><TAB><TAB><TAB>  num_prop_vals = len ( prop_vals ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  num_prop_vals = 1 <TAB><TAB><TAB>  writes + = 2 * num_prop_vals <TAB>  return writes ",if not prop_name in entity . unindexed_properties ( ) :,if prop_name in entity:,False,23.843256343620155,94.24009613589035
4533,"def create_connection ( self , address , protocol_factory = None , * * kw ) : <TAB>  """"""Helper method for creating a connection to an ``address``."""""" <TAB>  protocol_factory = protocol_factory or self . create_protocol <TAB>  if isinstance ( address , tuple ) : <TAB><TAB>  host , port = address <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . logger . debug ( "" Create connection  %s : %s "" , host , port ) <TAB><TAB>  _ , protocol = await self . _loop . create_connection ( <TAB><TAB><TAB>  protocol_factory , host , port , * * kw <TAB><TAB>  ) <TAB><TAB>  await protocol . event ( "" connection_made "" ) <TAB>  else : <TAB><TAB>  raise NotImplementedError ( "" Could not connect to  %s "" % str ( address ) ) <TAB>  return protocol ",if self . debug :,if host and port:,False,36.71495087850639,97.91733651511005
4534,def _increment_bracket_num ( self ) : <TAB>  self . _current_bracket - = 1 <TAB>  if self . _current_bracket < 0 : <TAB><TAB>  self . _current_bracket = self . _get_num_brackets ( ) - 1 <TAB><TAB>  self . _current_iteration + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _current_bracket = 0 ,if self . _current_iteration > self . hyperband_iterations :,if self._current_bracket > self._get_num_brackets():,False,16.594949246423308,89.86240119851766
4535,"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB>  for dep in curr_node [ "" deps "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return [ curr_node [ "" address "" ] ] <TAB>  for dep in curr_node [ "" deps "" ] : <TAB><TAB>  path = self . get_cycle_path ( <TAB><TAB><TAB>  self . get_by_address ( dep ) , goal_node_index <TAB><TAB>  )<TAB># self.nodelist[dep], goal_node_index) <TAB><TAB>  if len ( path ) > 0 : <TAB><TAB><TAB>  path . insert ( 0 , curr_node [ "" address "" ] ) <TAB><TAB><TAB>  return path <TAB>  return [ ] ",if dep == goal_node_index :,if dep == goal_node_index:,False,49.894744953494985,97.79485965801173
4536,"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB>  result = { } <TAB>  dirs = dir ( path , version , section ) <TAB>  if not dirs : <TAB><TAB>  return None <TAB>  for item in dirs : <TAB><TAB>  if item . endswith ( "" / "" ) : <TAB><TAB><TAB>  records = as_dict ( path + item , version , section ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ item [ : - 1 ] ] = records <TAB><TAB>  elif is_dict . match ( item ) : <TAB><TAB><TAB>  idx , name = is_dict . match ( item ) . groups ( ) <TAB><TAB><TAB>  records = as_dict ( path + idx + "" / "" , version , section ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result [ name ] = records <TAB><TAB>  else : <TAB><TAB><TAB>  result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB>  return result ",if records :,if is_dict.match(records):,False,30.261421122265087,93.92222856111762
4537,"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB>  with open ( input_filename , "" r "" ) as f1 : <TAB><TAB>  with open ( output_filename , "" w "" ) as f2 : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  line = f1 . readline ( ) <TAB><TAB><TAB><TAB>  if not line : <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB><TAB><TAB><TAB>  if line != "" "" and line != "" "" : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  line = line [ 1 : ] <TAB><TAB><TAB><TAB><TAB>  f2 . writelines ( line + "" \n "" ) ","if line [ 0 ] == "" "" :",if line.startswith('#') and line.startswith('#'):,False,37.87767893342672,93.1205256646423
4538,"def _handle_unsubscribe ( self , web_sock ) : <TAB>  index = None <TAB>  with await self . _subscriber_lock : <TAB><TAB>  for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  index = i <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if index is not None : <TAB><TAB><TAB>  del self . _subscribers [ index ] <TAB><TAB>  if not self . _subscribers : <TAB><TAB><TAB>  asyncio . ensure_future ( self . _unregister_subscriptions ( ) ) ",if subscriber_web_sock == web_sock :,if subscriber_web_sock.sock == web_sock:,False,50.75569355223304,98.41079189921226
4539,"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB>  with TimeEncoding ( self . locale ) as encoding : <TAB><TAB>  s = month_name [ themonth ] <TAB><TAB>  if encoding is not None : <TAB><TAB><TAB>  s = s . decode ( encoding ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  s = "" %s %s "" % ( s , theyear ) <TAB><TAB>  return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s ",if withyear :,if withyear:,False,51.84136545027428,100.00000000000004
4540,"def generate_sitemaps ( filename ) : <TAB>  rows = ( line . strip ( ) . split ( "" \t "" ) for line in open ( filename ) ) <TAB>  for sortkey , chunk in itertools . groupby ( rows , lambda row : row [ 0 ] ) : <TAB><TAB>  things = [ ] <TAB><TAB>  _chunk = list ( chunk ) <TAB><TAB>  for segment in _chunk : <TAB><TAB><TAB>  sortkey = segment . pop ( 0 ) <TAB><TAB><TAB>  last_modified = segment . pop ( - 1 ) <TAB><TAB><TAB>  path = "" "" . join ( segment ) <TAB><TAB><TAB>  things . append ( web . storage ( path = path , last_modified = last_modified ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  write ( "" sitemaps/sitemap_ %s .xml.gz "" % sortkey , sitemap ( things ) ) ",if things :,if sortkey == 'sitemap':,False,23.362598316906645,95.88884027423882
4541,"def use_index ( <TAB>  self , term : Union [ str , Index ] , * terms : Union [ str , Index ]  ) - > "" QueryBuilder "" : <TAB>  for t in ( term , * terms ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _use_indexes . append ( t ) <TAB><TAB>  elif isinstance ( t , str ) : <TAB><TAB><TAB>  self . _use_indexes . append ( Index ( t ) ) ","if isinstance ( t , Index ) :","if isinstance(t, Index):",False,49.14722459613674,100.00000000000004
4542,"def get_changed ( self ) : <TAB>  if self . _is_expression ( ) : <TAB><TAB>  result = self . _get_node_text ( self . ast ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  return result <TAB>  else : <TAB><TAB>  collector = codeanalyze . ChangeCollector ( self . source ) <TAB><TAB>  last_end = - 1 <TAB><TAB>  for match in self . matches : <TAB><TAB><TAB>  start , end = match . get_region ( ) <TAB><TAB><TAB>  if start < last_end : <TAB><TAB><TAB><TAB>  if not self . _is_expression ( ) : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  last_end = end <TAB><TAB><TAB>  replacement = self . _get_matched_text ( match ) <TAB><TAB><TAB>  collector . add_change ( start , end , replacement ) <TAB><TAB>  return collector . get_changed ( ) ",if result == self . source :,if result is None:,False,38.56594062329917,96.59129732198663
4543,"def quiet_f ( * args ) : <TAB>  vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB>  value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB>  if expect_list : <TAB><TAB>  if value . has_form ( "" List "" , None ) : <TAB><TAB><TAB>  value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  return value <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  else : <TAB><TAB>  value = extract_pyreal ( value ) <TAB><TAB>  if value is None or isinf ( value ) or isnan ( value ) : <TAB><TAB><TAB>  return None <TAB><TAB>  return value ",if any ( item is None for item in value ) :,if value is None:,False,41.92471820842499,95.46810356933942
4544,"def _reemit_nested_event ( self , event : Event ) : <TAB>  source_index = self . index ( event . source ) <TAB>  for attr in ( "" index "" , "" new_index "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  src_index = ensure_tuple_index ( event . index ) <TAB><TAB><TAB>  setattr ( event , attr , ( source_index , ) + src_index ) <TAB>  if not hasattr ( event , "" index "" ) : <TAB><TAB>  setattr ( event , "" index "" , source_index ) <TAB>  # reemit with this object's EventEmitter of the same type if present <TAB>  # otherwise just emit with the EmitterGroup itself <TAB>  getattr ( self . events , event . type , self . events ) ( event ) ","if hasattr ( event , attr ) :","if hasattr(event, attr):",False,62.166059149980434,100.00000000000004
4545,"def check ( self ) : <TAB>  """"""Perform required checks to conclude if it's safe to operate"""""" <TAB>  if self . interpreter . manual is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . error = self . process . error <TAB><TAB><TAB>  self . tip = self . process . tip <TAB><TAB><TAB>  return False <TAB>  start = time . time ( ) <TAB>  while not self . _status ( ) : <TAB><TAB>  if time . time ( ) - start > = 2 :<TAB># 2s <TAB><TAB><TAB>  self . error = "" can ' t connect to the minserver on  {} : {} "" . format ( <TAB><TAB><TAB><TAB>  self . interpreter . host , self . interpreter . port <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . tip = "" check your vagrant machine is running "" <TAB><TAB><TAB>  return False <TAB><TAB>  time . sleep ( 0.1 ) <TAB>  return True ",if not self . process . healthy :,if self.process:,False,43.142603403964806,95.203620503809
4546,"def apply ( self ) : <TAB>  new_block = self . block . copy ( ) <TAB>  new_block . clear ( ) <TAB>  for inst in self . block . body : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  const_assign = self . _assign_const ( inst ) <TAB><TAB><TAB>  new_block . append ( const_assign ) <TAB><TAB><TAB>  inst = self . _assign_getitem ( inst , index = const_assign . target ) <TAB><TAB>  new_block . append ( inst ) <TAB>  return new_block ","if isinstance ( inst , Assign ) and inst . value in self . getattrs :","if isinstance(inst, (int, int)):",False,45.123244532737246,92.60203624733172
4547,"def _get_orientation ( self ) : <TAB>  if self . state : <TAB><TAB>  rotation = [ 0 ] * 9 <TAB><TAB>  inclination = [ 0 ] * 9 <TAB><TAB>  gravity = [ ] <TAB><TAB>  geomagnetic = [ ] <TAB><TAB>  gravity = self . listener_a . values <TAB><TAB>  geomagnetic = self . listener_m . values <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ff_state = SensorManager . getRotationMatrix ( <TAB><TAB><TAB><TAB>  rotation , inclination , gravity , geomagnetic <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  if ff_state : <TAB><TAB><TAB><TAB>  values = [ 0 , 0 , 0 ] <TAB><TAB><TAB><TAB>  values = SensorManager . getOrientation ( rotation , values ) <TAB><TAB><TAB>  return values ",if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None :,if self.state:,False,34.88852808197826,92.67305358370837
4548,def getFirstSubGraph ( graph ) : <TAB>  if len ( graph ) == 0 : <TAB><TAB>  return None <TAB>  subg = { } <TAB>  todo = [ graph . keys ( ) [ 0 ] ] <TAB>  while len ( todo ) > 0 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  subg [ todo [ 0 ] ] = graph [ todo [ 0 ] ] <TAB><TAB><TAB>  todo . extend ( graph [ todo [ 0 ] ] ) <TAB><TAB><TAB>  del graph [ todo [ 0 ] ] <TAB><TAB>  del todo [ 0 ] <TAB>  return subg ,if todo [ 0 ] in graph . keys ( ) :,if todo[0] in graph:,False,48.44265946790485,96.40034785821153
4549,"def decorated_function ( * args , * * kwargs ) : <TAB>  rv = f ( * args , * * kwargs ) <TAB>  if "" Last-Modified "" not in rv . headers : <TAB><TAB>  try : <TAB><TAB><TAB>  result = date <TAB><TAB><TAB>  if callable ( result ) : <TAB><TAB><TAB><TAB>  result = result ( rv ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  from werkzeug . http import http_date <TAB><TAB><TAB><TAB>  result = http_date ( result ) <TAB><TAB><TAB>  if result : <TAB><TAB><TAB><TAB>  rv . headers [ "" Last-Modified "" ] = result <TAB><TAB>  except Exception : <TAB><TAB><TAB>  logging . getLogger ( __name__ ) . exception ( <TAB><TAB><TAB><TAB>  "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB><TAB><TAB><TAB><TAB>  rv <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return rv ","if not isinstance ( result , basestring ) :","if isinstance(result, datetime):",False,52.83448877485826,98.2558804882648
4550,"def set_invoice_details ( self , row ) : <TAB>  invoice_details = self . invoice_details . get ( row . voucher_no , { } ) <TAB>  if row . due_date : <TAB><TAB>  invoice_details . pop ( "" due_date "" , None ) <TAB>  row . update ( invoice_details ) <TAB>  if row . voucher_type == "" Sales Invoice "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_delivery_notes ( row ) <TAB><TAB>  if self . filters . show_sales_person and row . sales_team : <TAB><TAB><TAB>  row . sales_person = "" ,  "" . join ( row . sales_team ) <TAB><TAB><TAB>  del row [ "" sales_team "" ] ",if self . filters . show_delivery_notes :,if self.filters.show_delivery_notes:,False,50.48512066697668,100.00000000000004
4551,"def process ( output ) : <TAB>  modules = { } <TAB>  for line in output : <TAB><TAB>  name , size , instances , depends , state , _ = line . split ( "" "" , 5 ) <TAB><TAB>  instances = int ( instances ) <TAB><TAB>  module = { <TAB><TAB><TAB>  "" size "" : size , <TAB><TAB><TAB>  "" instances "" : instances , <TAB><TAB><TAB>  "" state "" : state , <TAB><TAB>  } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module [ "" depends "" ] = [ value for value in depends . split ( "" , "" ) if value ] <TAB><TAB>  modules [ name ] = module <TAB>  return modules ","if depends != ""-"" :",if depends:,False,23.73454796977589,96.41769384336753
4552,"def _get_host_from_zc_service_info ( service_info : zeroconf . ServiceInfo ) : <TAB>  """"""Get hostname or IP + port from zeroconf service_info."""""" <TAB>  host = None <TAB>  port = None <TAB>  if ( <TAB><TAB>  service_info <TAB><TAB>  and service_info . port <TAB><TAB>  and ( service_info . server or len ( service_info . addresses ) > 0 ) <TAB>  ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  host = socket . inet_ntoa ( service_info . addresses [ 0 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  host = service_info . server . lower ( ) <TAB><TAB>  port = service_info . port <TAB>  return ( host , port ) ",if len ( service_info . addresses ) > 0 :,if len(service_info.addresses) == 1:,False,34.54213478795309,97.80561361801237
4553,"def _init_weights ( self , module ) : <TAB>  if isinstance ( module , nn . Linear ) : <TAB><TAB>  module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB>  if module . bias is not None : <TAB><TAB><TAB>  module . bias . data . zero_ ( ) <TAB>  elif isinstance ( module , nn . Embedding ) : <TAB><TAB>  module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module . weight . data [ module . padding_idx ] . zero_ ( ) ",if module . padding_idx is not None :,if module.padding_idx is not None:,False,27.487062241097703,100.00000000000004
4554,"def visitFromImport ( self , import_stmt , import_info ) : <TAB>  new_pairs = [ ] <TAB>  if not import_info . is_star_import ( ) : <TAB><TAB>  for name , alias in import_info . names_and_aliases : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  pyname = self . pymodule [ alias or name ] <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  except exceptions . AttributeNotFoundError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  new_pairs . append ( ( name , alias ) ) <TAB>  return importinfo . FromImport ( import_info . module_name , import_info . level , new_pairs ) ","if occurrences . same_pyname ( self . pyname , pyname ) :",if pyname.name == import_info.module_name:,False,31.36836849417704,93.98916352790701
4555,"def _apply_patches ( self ) : <TAB>  try : <TAB><TAB>  s = Subprocess ( <TAB><TAB><TAB>  log = self . logfile , cwd = self . build_dir , verbose = self . options . verbose <TAB><TAB>  ) <TAB><TAB>  for patch in self . patches : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for ed , source in patch . items ( ) : <TAB><TAB><TAB><TAB><TAB>  s . shell ( "" ed -  %s  <  %s "" % ( source , ed ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  s . shell ( "" patch -p0 <  %s "" % patch ) <TAB>  except : <TAB><TAB>  logger . error ( "" Failed to patch ` %s `. \n %s "" % ( self . build_dir , sys . exc_info ( ) [ 1 ] ) ) <TAB><TAB>  sys . exit ( 1 ) ",if type ( patch ) is dict :,if patch.is_executable():,False,22.67972943890884,96.9466020997927
4556,"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB>  filelist = [ ] <TAB>  dirlist = [ "" .. "" ] <TAB>  self . dir = dir <TAB>  self . file = "" "" <TAB>  mask = mask . upper ( ) <TAB>  pattern = self . MakeRegex ( mask ) <TAB>  for i in os . listdir ( dir ) : <TAB><TAB>  if i == "" . "" or i == "" .. "" : <TAB><TAB><TAB>  continue <TAB><TAB>  path = os . path . join ( dir , i ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dirlist . append ( i ) <TAB><TAB><TAB>  continue <TAB><TAB>  path = path . upper ( ) <TAB><TAB>  value = i . upper ( ) <TAB><TAB>  if pattern . match ( value ) is not None : <TAB><TAB><TAB>  filelist . append ( i ) <TAB>  self . files = filelist <TAB>  if with_dirs : <TAB><TAB>  self . dirs = dirlist ",if os . path . isdir ( path ) :,if pattern.match(path):,False,25.670002335947768,97.64337620867066
4557,"def remove_invalid_dirs ( paths , bp_dir , module_name ) : <TAB>  ret = [ ] <TAB>  for path in paths : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret . append ( path ) <TAB><TAB>  else : <TAB><TAB><TAB>  logging . warning ( ' Dir  "" %s ""  of module  "" %s ""  does not exist ' , path , module_name ) <TAB>  return ret ","if os . path . isdir ( os . path . join ( bp_dir , path ) ) :","if os.path.exists(bp_dir, path):",False,47.9106685351822,87.20774178546553
4558,"def update_sockets ( self ) : <TAB>  inputs = self . inputs <TAB>  inputs_n = "" ABabcd "" <TAB>  penta_sockets = pentagon_dict [ self . grid_type ] . input_sockets <TAB>  for socket in inputs_n : <TAB><TAB>  if socket in penta_sockets : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  inputs [ socket ] . hide_safe = False <TAB><TAB>  else : <TAB><TAB><TAB>  inputs [ socket ] . hide_safe = True ",if inputs [ socket ] . hide_safe :,if socket in inputs:,False,36.125706689635706,93.35919913304792
4559,"def __cut ( sentence ) : <TAB>  global emit_P <TAB>  prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB>  begin , nexti = 0 , 0 <TAB>  # print pos_list, sentence <TAB>  for i , char in enumerate ( sentence ) : <TAB><TAB>  pos = pos_list [ i ] <TAB><TAB>  if pos == "" B "" : <TAB><TAB><TAB>  begin = i <TAB><TAB>  elif pos == "" E "" : <TAB><TAB><TAB>  yield sentence [ begin : i + 1 ] <TAB><TAB><TAB>  nexti = i + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield char <TAB><TAB><TAB>  nexti = i + 1 <TAB>  if nexti < len ( sentence ) : <TAB><TAB>  yield sentence [ nexti : ] ","elif pos == ""S"" :",if char in sentence:,False,52.28153883618126,96.19292137911184
4560,"def validate ( self ) : <TAB>  if self . data . get ( "" encrypted "" , True ) : <TAB><TAB>  key = self . data . get ( "" target_key "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise PolicyValidationError ( <TAB><TAB><TAB><TAB>  "" Encrypted snapshot copy requires kms key on  %s "" % ( self . manager . data , ) <TAB><TAB><TAB>  ) <TAB>  return self ",if not key :,if key is None:,False,29.942040753413103,96.16531359700099
4561,"def __init__ ( self , patch_files , patch_directories ) : <TAB>  files = [ ] <TAB>  files_data = { } <TAB>  for filename_data in patch_files : <TAB><TAB>  if isinstance ( filename_data , list ) : <TAB><TAB><TAB>  filename , data = filename_data <TAB><TAB>  else : <TAB><TAB><TAB>  filename = filename_data <TAB><TAB><TAB>  data = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB><TAB>  files . append ( filename ) <TAB><TAB>  if data : <TAB><TAB><TAB>  files_data [ filename ] = data <TAB>  self . files = files <TAB>  self . files_data = files_data <TAB>  self . directories = patch_directories ",if not filename . startswith ( os . sep ) :,if filename not in FakeState.deploy_dir:,False,27.200780729554847,95.66791260506321
4562,"def validate_name_and_description ( body , check_length = True ) : <TAB>  for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB><TAB>  value = body . get ( attribute ) <TAB><TAB>  if value is not None : <TAB><TAB><TAB>  if isinstance ( value , six . string_types ) : <TAB><TAB><TAB><TAB>  body [ attribute ] = value . strip ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  utils . check_string_length ( <TAB><TAB><TAB><TAB><TAB><TAB>  body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  except exception . InvalidInput as error : <TAB><TAB><TAB><TAB><TAB>  raise webob . exc . HTTPBadRequest ( explanation = error . msg ) ",if check_length :,if check_length:,False,51.73773093965948,100.00000000000004
4563,"def pick ( items , sel ) : <TAB>  for x , s in zip ( items , sel ) : <TAB><TAB>  if match ( s ) : <TAB><TAB><TAB>  yield x <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation ) ",elif not x . is_atom ( ) and not s . is_atom ( ) :,if match(x):,False,20.876256239791953,81.42701144329133
4564,"def wait_or_kill ( self ) : <TAB>  """"""Wait for the program to terminate, or kill it after 5s."""""" <TAB>  if self . instance . poll ( ) is None : <TAB><TAB>  # We try one more time to kill gracefully using Ctrl-C. <TAB><TAB>  logger . info ( "" Interrupting  %s  and waiting... "" , self . coord ) <TAB><TAB>  self . instance . send_signal ( signal . SIGINT ) <TAB><TAB>  # FIXME on py3 this becomes self.instance.wait(timeout=5) <TAB><TAB>  t = monotonic_time ( ) <TAB><TAB>  while monotonic_time ( ) - t < 5 : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  logger . info ( "" Terminated  %s . "" , self . coord ) <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  time . sleep ( 0.1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . kill ( ) ",if self . instance . poll ( ) is not None :,if monotonic_time() - t > 5:,False,65.61560662939539,95.7876202759015
4565,"def sort_collection ( self , models , many ) : <TAB>  ordering = self . ordering <TAB>  if not many or not ordering : <TAB><TAB>  return models <TAB>  for key in reversed ( ordering ) : <TAB><TAB>  reverse = key [ 0 ] == "" - "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  key = key [ 1 : ] <TAB><TAB>  models = sorted ( models , key = partial ( deep_getattr , key = key ) , reverse = reverse ) <TAB>  return models ",if reverse :,if reverse:,False,54.30597393862634,100.00000000000004
4566,"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB>  if self . label_map is not None : <TAB><TAB>  # return subset of palette <TAB><TAB>  palette = [ ] <TAB><TAB>  for old_id , new_id in sorted ( self . label_map . items ( ) , key = lambda x : x [ 1 ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  palette . append ( self . PALETTE [ old_id ] ) <TAB><TAB>  palette = type ( self . PALETTE ) ( palette ) <TAB>  elif palette is None : <TAB><TAB>  if self . PALETTE is None : <TAB><TAB><TAB>  palette = np . random . randint ( 0 , 255 , size = ( len ( class_names ) , 3 ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  palette = self . PALETTE <TAB>  return palette ",if new_id != - 1 :,if old_id in class_names:,False,51.54015940016509,96.6875690268462
4567,"def _find_tcl_dir ( ) : <TAB>  lib_dirs = [ os . path . dirname ( _x ) for _x in sys . path if _x . lower ( ) . endswith ( "" lib "" ) ] <TAB>  for lib_dir in lib_dirs : <TAB><TAB>  base_dir = os . path . join ( lib_dir , TclLibrary . FOLDER ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for root , _ , files in os . walk ( base_dir ) : <TAB><TAB><TAB><TAB>  if TclLibrary . INIT_TCL in files : <TAB><TAB><TAB><TAB><TAB>  return root ",if os . path . exists ( base_dir ) :,if os.path.exists(base_dir):,False,52.1538939555524,100.00000000000004
4568,"def __next__ ( self ) : <TAB>  """"""Special paging functionality"""""" <TAB>  if self . iter is None : <TAB><TAB>  self . iter = iter ( self . objs ) <TAB>  try : <TAB><TAB>  return next ( self . iter ) <TAB>  except StopIteration : <TAB><TAB>  self . iter = None <TAB><TAB>  self . objs = [ ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . page + = 1 <TAB><TAB><TAB>  self . _connection . get_response ( self . action , self . params , self . page , self ) <TAB><TAB><TAB>  return next ( self ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ",if int ( self . page ) < int ( self . total_pages ) :,if self.page < len(self.objs):,False,36.36488568258982,93.69082005382465
4569,"def parse ( cls , api , json ) : <TAB>  lst = List ( api ) <TAB>  setattr ( lst , "" _json "" , json ) <TAB>  for k , v in json . items ( ) : <TAB><TAB>  if k == "" user "" : <TAB><TAB><TAB>  setattr ( lst , k , User . parse ( api , v ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  setattr ( lst , k , parse_datetime ( v ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  setattr ( lst , k , v ) <TAB>  return lst ","elif k == ""created_at"" :",if k == 'datetime':,False,50.997934782633635,94.02775144410812
4570,"def real_type ( self ) : <TAB>  # Find the real type representation by updating it as required <TAB>  real_type = self . type <TAB>  if self . flag_indicator : <TAB><TAB>  real_type = "" # "" <TAB>  if self . is_vector : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  real_type = "" Vector< {} > "" . format ( real_type ) <TAB><TAB>  else : <TAB><TAB><TAB>  real_type = "" vector< {} > "" . format ( real_type ) <TAB>  if self . is_generic : <TAB><TAB>  real_type = "" ! {} "" . format ( real_type ) <TAB>  if self . is_flag : <TAB><TAB>  real_type = "" flags. {} ? {} "" . format ( self . flag_index , real_type ) <TAB>  return real_type ",if self . use_vector_id :,if self.is_vector:,False,34.51587261300633,97.39773439147912
4571,"def check_fs ( path ) : <TAB>  with open ( path , "" rb "" ) as f : <TAB><TAB>  code = python_bytes_to_unicode ( f . read ( ) , errors = "" replace "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module = _load_module ( evaluator , path , code ) <TAB><TAB><TAB>  module_name = sys_path . dotted_path_in_sys_path ( <TAB><TAB><TAB><TAB>  evaluator . project . sys_path , path <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  if module_name is not None : <TAB><TAB><TAB><TAB>  add_module ( evaluator , module_name , module ) <TAB><TAB><TAB>  return module ",if name in code :,if code is not None:,False,23.48077699810494,97.27928551851379
4572,"def infoCalendar ( users ) : <TAB>  calendarId = normalizeCalendarId ( sys . argv [ 5 ] , checkPrimary = True ) <TAB>  i = 0 <TAB>  count = len ( users ) <TAB>  for user in users : <TAB><TAB>  i + = 1 <TAB><TAB>  user , cal = buildCalendarGAPIObject ( user ) <TAB><TAB>  if not cal : <TAB><TAB><TAB>  continue <TAB><TAB>  result = gapi . call ( <TAB><TAB><TAB>  cal . calendarList ( ) , "" get "" , soft_errors = True , calendarId = calendarId <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( f "" User:  { user } , Calendar: { display . current_count ( i , count ) } "" ) <TAB><TAB><TAB>  _showCalendar ( result , 1 , 1 ) ",if result :,if result:,False,24.044208664147995,100.00000000000004
4573,"def set_hidestate_input_sockets_to_cope_with_switchnum ( self ) : <TAB>  tndict = get_indices_that_should_be_visible ( self . node_state ) <TAB>  for key , value in tndict . items ( ) : <TAB><TAB>  socket = self . inputs [ key ] <TAB><TAB>  desired_hide_state = not ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  socket . hide_safe = desired_hide_state ",if not socket . hide == desired_hide_state :,if desired_hide_state:,False,37.74413398130392,93.90587857488433
4574,"def get_class_name ( item ) : <TAB>  class_name , module_name = None , None <TAB>  for parent in reversed ( item . listchain ( ) ) : <TAB><TAB>  if isinstance ( parent , pytest . Class ) : <TAB><TAB><TAB>  class_name = parent . name <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module_name = parent . module . __name__ <TAB><TAB><TAB>  break <TAB>  # heuristic: <TAB>  # - better to group gpu and task tests, since tests from those modules <TAB>  #   are likely to share caching more <TAB>  # - split up the rest by class name because slow tests tend to be in <TAB>  #   the same module <TAB>  if class_name and "" .tasks. "" not in module_name : <TAB><TAB>  return "" {} . {} "" . format ( module_name , class_name ) <TAB>  else : <TAB><TAB>  return module_name ","elif isinstance ( parent , pytest . Module ) :","if isinstance(parent, pytest.Class):",False,68.04681431508934,97.87665355650064
4575,"def run ( self ) : <TAB>  versions = versioneer . get_versions ( ) <TAB>  tempdir = tempfile . mkdtemp ( ) <TAB>  generated = os . path . join ( tempdir , "" rundemo "" ) <TAB>  with open ( generated , "" wb "" ) as f : <TAB><TAB>  for line in open ( "" src/rundemo-template "" , "" rb "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  f . write ( ( "" versions =  %r \n "" % ( versions , ) ) . encode ( "" ascii "" ) ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  f . write ( line ) <TAB>  self . scripts = [ generated ] <TAB>  rc = build_scripts . run ( self ) <TAB>  os . unlink ( generated ) <TAB>  os . rmdir ( tempdir ) <TAB>  return rc ","if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :",if line.startswith('#') or line == '':,False,41.11351831218335,92.81446526656165
4576,"def get_user_context ( request , escape = False ) : <TAB>  if isinstance ( request , HttpRequest ) : <TAB><TAB>  user = getattr ( request , "" user "" , None ) <TAB><TAB>  result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . update ( <TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB>  "" email "" : user . email , <TAB><TAB><TAB><TAB><TAB>  "" id "" : user . id , <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  if user . name : <TAB><TAB><TAB><TAB>  result [ "" name "" ] = user . name <TAB>  else : <TAB><TAB>  result = { } <TAB>  return mark_safe ( json . dumps ( result ) ) ",if user and user . is_authenticated ( ) :,if user and (not escape):,False,28.03336217495991,97.04218251786747
4577,"def tokens_to_spans ( ) - > Iterable [ Tuple [ str , Optional [ Style ] ] ] : <TAB>  """"""Convert tokens to spans."""""" <TAB>  tokens = iter ( line_tokenize ( ) ) <TAB>  line_no = 0 <TAB>  _line_start = line_start - 1 <TAB>  # Skip over tokens until line start <TAB>  while line_no < _line_start : <TAB><TAB>  _token_type , token = next ( tokens ) <TAB><TAB>  yield ( token , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line_no + = 1 <TAB>  # Generate spans until line end <TAB>  for token_type , token in tokens : <TAB><TAB>  yield ( token , _get_theme_style ( token_type ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  line_no + = 1 <TAB><TAB><TAB>  if line_no > = line_end : <TAB><TAB><TAB><TAB>  break ","if token . endswith ( ""\n"" ) :",if _token_type == 'line':,False,50.138347118288195,91.60272832392572
4578,"def encode ( self , encodeFun , value , defMode , maxChunkSize ) : <TAB>  substrate , isConstructed = self . encodeValue ( encodeFun , value , defMode , maxChunkSize ) <TAB>  tagSet = value . getTagSet ( ) <TAB>  if tagSet : <TAB><TAB>  <IF-STMT>:<TAB># primitive form implies definite mode <TAB><TAB><TAB>  defMode = 1 <TAB><TAB>  return ( <TAB><TAB><TAB>  self . encodeTag ( tagSet [ - 1 ] , isConstructed ) <TAB><TAB><TAB>  + self . encodeLength ( len ( substrate ) , defMode ) <TAB><TAB><TAB>  + substrate <TAB><TAB><TAB>  + self . _encodeEndOfOctets ( encodeFun , defMode ) <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return substrate<TAB># untagged value ",if not isConstructed :,if tagSet[-1] == 'static':,False,27.99488013001083,90.07117435139273
4579,def _run ( self ) : <TAB>  while True : <TAB><TAB>  request = self . _requests . get ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . shutdown ( ) <TAB><TAB><TAB>  break <TAB><TAB>  self . process ( request ) <TAB><TAB>  self . _requests . task_done ( ) ,if request is None :,if not request:,False,19.98086298955524,95.28029279642453
4580,"def _decode_payload ( self , payload ) : <TAB>  # we need to decrypt it <TAB>  if payload [ "" enc "" ] == "" aes "" : <TAB><TAB>  try : <TAB><TAB><TAB>  payload [ "" load "" ] = self . crypticle . loads ( payload [ "" load "" ] ) <TAB><TAB>  except salt . crypt . AuthenticationError : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  payload [ "" load "" ] = self . crypticle . loads ( payload [ "" load "" ] ) <TAB>  return payload ",if not self . _update_aes ( ) :,if 'load' not in payload:,False,29.995520884682016,93.2006152424365
4581,"def test_row ( self , row ) : <TAB>  for idx , test in self . patterns . items ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  value = row [ idx ] <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  value = "" "" <TAB><TAB>  result = test ( value ) <TAB><TAB>  if self . any_match : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return not self . inverse<TAB># True <TAB><TAB>  else : <TAB><TAB><TAB>  if not result : <TAB><TAB><TAB><TAB>  return self . inverse<TAB># False <TAB>  if self . any_match : <TAB><TAB>  return self . inverse<TAB># False <TAB>  else : <TAB><TAB>  return not self . inverse<TAB># True ",if result :,if result:,False,21.259942845864703,91.77048667123421
4582,"def setup_parameter_node ( self , param_node ) : <TAB>  if param_node . bl_idname == "" SvNumberNode "" : <TAB><TAB>  if self . use_prop or self . get_prop_name ( ) : <TAB><TAB><TAB>  value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB><TAB><TAB>  print ( "" V "" , value ) <TAB><TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB><TAB>  param_node . selected_mode = "" int "" <TAB><TAB><TAB><TAB>  param_node . int_ = value <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  param_node . selected_mode = "" float "" <TAB><TAB><TAB><TAB>  param_node . float_ = value ","elif isinstance ( value , float ) :","if isinstance(value, float):",False,29.80360683289608,98.82484493883118
4583,"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB>  """"""iterate over all modules"""""" <TAB>  clients = None <TAB>  if by_clients : <TAB><TAB>  clients = self . get_clients ( clients_filter ) <TAB><TAB>  if not clients : <TAB><TAB><TAB>  return <TAB>  self . _refresh_modules ( ) <TAB>  for module_name in self . modules : <TAB><TAB>  try : <TAB><TAB><TAB>  module = self . get_module ( module_name ) <TAB><TAB>  except PupyModuleDisabled : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for client in clients : <TAB><TAB><TAB><TAB>  if module . is_compatible_with ( client ) : <TAB><TAB><TAB><TAB><TAB>  yield module <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  yield module ",if clients is not None :,if module is not None:,False,29.281393701969584,99.02244440514939
4584,"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB>  filtered_pricing_rules = [ ] <TAB>  if doc : <TAB><TAB>  for pricing_rule in pricing_rules : <TAB><TAB><TAB>  if pricing_rule . condition : <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  filtered_pricing_rules . append ( pricing_rule ) <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  filtered_pricing_rules . append ( pricing_rule ) <TAB>  else : <TAB><TAB>  filtered_pricing_rules = pricing_rules <TAB>  return filtered_pricing_rules ","if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :",if not is_pricing_rule_based_on_condition(pricing_rule,False,37.338062830583674,91.30558912834395
4585,"def build_query_string ( kv_data , ignore_none = True ) : <TAB>  # {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test"" <TAB>  query_string = "" "" <TAB>  for k , v in kv_data . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if query_string != "" "" : <TAB><TAB><TAB>  query_string + = "" & "" <TAB><TAB>  else : <TAB><TAB><TAB>  query_string = "" ? "" <TAB><TAB>  query_string + = k + "" = "" + str ( v ) <TAB>  return query_string ",if ignore_none is True and kv_data [ k ] is None :,if ignore_none and k == 'a':,False,55.561828922674,93.59820127981453
4586,"def sample ( self , * * config ) : <TAB>  """"""Sample a configuration from this search space."""""" <TAB>  ret = { } <TAB>  ret . update ( self . data ) <TAB>  kwspaces = self . kwspaces <TAB>  kwspaces . update ( config ) <TAB>  striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB>  for k , v in kwspaces . items ( ) : <TAB><TAB>  if k in striped_keys : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sub_config = _strip_config_space ( config , prefix = k ) <TAB><TAB><TAB><TAB>  ret [ k ] = v . sample ( * * sub_config ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  ret [ k ] = v <TAB>  return ret ","if isinstance ( v , NestedSpace ) :",if k.startswith('_strip_'):,False,40.72784482166358,95.42854307048253
4587,"def task_failed ( self , task_id , hostname , reason ) : <TAB>  logger . debug ( "" task  %d  failed with message  %s "" , task_id , str ( reason ) ) <TAB>  if hostname in self . host_dict : <TAB><TAB>  host_status = self . host_dict [ hostname ] <TAB><TAB>  host_status . task_failed ( task_id ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . task_host_failed_dict [ task_id ] = set ( ) <TAB><TAB>  self . task_host_failed_dict [ task_id ] . add ( hostname ) ",if task_id not in self . task_host_failed_dict :,if not self.task_host_failed_dict.has_key(task_id,False,31.400332628510185,93.80148665197042
4588,"def match ( path ) : <TAB>  for pat , _type , _property , default_title in patterns : <TAB><TAB>  m = web . re_compile ( "" ^ "" + pat ) . match ( path ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  prefix = m . group ( ) <TAB><TAB><TAB>  extra = web . lstrips ( path , prefix ) <TAB><TAB><TAB>  tokens = extra . split ( "" / "" , 2 ) <TAB><TAB><TAB>  # `extra` starts with ""/"". So first token is always empty. <TAB><TAB><TAB>  middle = web . listget ( tokens , 1 , "" "" ) <TAB><TAB><TAB>  suffix = web . listget ( tokens , 2 , "" "" ) <TAB><TAB><TAB>  if suffix : <TAB><TAB><TAB><TAB>  suffix = "" / "" + suffix <TAB><TAB><TAB>  return _type , _property , default_title , prefix , middle , suffix <TAB>  return None , None , None , None , None , None ",if m :,if m:,False,56.39019583152477,100.00000000000004
4589,"def _get_cached_resources ( self , ids ) : <TAB>  key = self . get_cache_key ( None ) <TAB>  if self . _cache . load ( ) : <TAB><TAB>  resources = self . _cache . get ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . log . debug ( "" Using cached results for get_resources "" ) <TAB><TAB><TAB>  m = self . get_model ( ) <TAB><TAB><TAB>  id_set = set ( ids ) <TAB><TAB><TAB>  return [ r for r in resources if r [ m . id ] in id_set ] <TAB>  return None ",if resources is not None :,if resources is not None:,False,57.49100972968502,100.00000000000004
4590,"def has_api_behaviour ( self , protocol ) : <TAB>  config = get_config ( ) <TAB>  try : <TAB><TAB>  r = self . session . get ( <TAB><TAB><TAB>  f "" { protocol } :// { self . event . host } : { self . event . port } "" , <TAB><TAB><TAB>  timeout = config . network_timeout , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  except requests . exceptions . SSLError : <TAB><TAB>  logger . debug ( <TAB><TAB><TAB>  f "" { [ protocol ] }  protocol not accepted on  { self . event . host } : { self . event . port } "" <TAB><TAB>  ) <TAB>  except Exception : <TAB><TAB>  logger . debug ( <TAB><TAB><TAB>  f "" Failed probing  { self . event . host } : { self . event . port } "" , exc_info = True <TAB><TAB>  ) ","if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :",if r.status_code == 200:,False,20.533801940600142,89.50962357283422
4591,"def get_file_type ( self , context , parent_context = None ) : <TAB>  file_type = context . get ( self . file_type_name , None ) <TAB>  if file_type == "" "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  file_type = parent_context . get ( self . file_type_name , self . default_file_type ) <TAB><TAB>  else : <TAB><TAB><TAB>  file_type = self . default_file_type <TAB>  return file_type ",if parent_context :,if parent_context:,False,51.09596732700735,100.00000000000004
4592,"def selectionToChunks ( self , remove = False , add = False ) : <TAB>  box = self . selectionBox ( ) <TAB>  if box : <TAB><TAB>  if box == self . level . bounds : <TAB><TAB><TAB>  self . selectedChunks = set ( self . level . allChunks ) <TAB><TAB><TAB>  return <TAB><TAB>  selectedChunks = self . selectedChunks <TAB><TAB>  boxedChunks = set ( box . chunkPositions ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  remove = True <TAB><TAB>  if remove and not add : <TAB><TAB><TAB>  selectedChunks . difference_update ( boxedChunks ) <TAB><TAB>  else : <TAB><TAB><TAB>  selectedChunks . update ( boxedChunks ) <TAB>  self . selectionTool . selectNone ( ) ",if boxedChunks . issubset ( selectedChunks ) :,if boxedChunks:,False,29.011534033040704,96.53235692511355
4593,"def _run_split_on_punc ( self , text , never_split = None ) : <TAB>  """"""Splits punctuation on a piece of text."""""" <TAB>  if never_split is not None and text in never_split : <TAB><TAB>  return [ text ] <TAB>  chars = list ( text ) <TAB>  i = 0 <TAB>  start_new_word = True <TAB>  output = [ ] <TAB>  while i < len ( chars ) : <TAB><TAB>  char = chars [ i ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  output . append ( [ char ] ) <TAB><TAB><TAB>  start_new_word = True <TAB><TAB>  else : <TAB><TAB><TAB>  if start_new_word : <TAB><TAB><TAB><TAB>  output . append ( [ ] ) <TAB><TAB><TAB>  start_new_word = False <TAB><TAB><TAB>  output [ - 1 ] . append ( char ) <TAB><TAB>  i + = 1 <TAB>  return [ "" "" . join ( x ) for x in output ] ",if _is_punctuation ( char ) :,if char in output:,False,34.17750070258682,96.01700187531056
4594,"def _save_images ( notebook ) : <TAB>  if os . getenv ( "" NB_NO_IMAGES "" ) == "" 1 "" : <TAB><TAB>  return <TAB>  logged = False <TAB>  for filename , img_bytes in _iter_notebook_images ( notebook ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  log . info ( "" Saving images "" ) <TAB><TAB><TAB>  logged = True <TAB><TAB>  with open ( filename , "" wb "" ) as f : <TAB><TAB><TAB>  f . write ( img_bytes ) ",if not logged :,if not logged:,False,50.99657142055703,100.00000000000004
4595,"def pickPath ( self , color ) : <TAB>  self . path [ color ] = ( ) <TAB>  currentPos = self . starts [ color ] <TAB>  while True : <TAB><TAB>  minDist = None <TAB><TAB>  minGuide = None <TAB><TAB>  for guide in self . guides [ color ] : <TAB><TAB><TAB>  guideDist = dist ( currentPos , guide ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  minDist = guideDist <TAB><TAB><TAB><TAB>  minGuide = guide <TAB><TAB>  if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB><TAB><TAB>  return <TAB><TAB>  if minGuide == None : <TAB><TAB><TAB>  return <TAB><TAB>  self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB><TAB>  currentPos = minGuide <TAB><TAB>  self . guides [ color ] . remove ( minGuide ) ",if minDist == None or guideDist < minDist :,if guideDist < minDist:,False,37.811524116647554,97.27401798070198
4596,"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out . write ( msg ) <TAB><TAB>  elif tp == "" flush "" : <TAB><TAB><TAB>  out . flush ( ) <TAB><TAB>  elif tp == "" write_flush "" : <TAB><TAB><TAB>  out . write ( msg ) <TAB><TAB><TAB>  out . flush ( ) <TAB><TAB>  elif tp == "" print "" : <TAB><TAB><TAB>  print ( msg , file = out ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" Unsupported type:  "" + tp ) <TAB>  except IOError as e : <TAB><TAB>  logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB><TAB>  pass ","if tp == ""write"" :","if tp == ""write':",False,39.27198295306988,98.54309026474702
4597,"def __new__ ( mcs , name , bases , attrs ) : <TAB>  include_profile = include_trace = include_garbage = True <TAB>  bases = list ( bases ) <TAB>  if name == "" SaltLoggingClass "" : <TAB><TAB>  for base in bases : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  include_trace = False <TAB><TAB><TAB>  if hasattr ( base , "" garbage "" ) : <TAB><TAB><TAB><TAB>  include_garbage = False <TAB>  if include_profile : <TAB><TAB>  bases . append ( LoggingProfileMixin ) <TAB>  if include_trace : <TAB><TAB>  bases . append ( LoggingTraceMixin ) <TAB>  if include_garbage : <TAB><TAB>  bases . append ( LoggingGarbageMixin ) <TAB>  return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs ) ","if hasattr ( base , ""trace"" ) :",if base.profile:,False,26.279576233556966,95.80816709386652
4598,"def generatePidEncryptionTable ( ) : <TAB>  table = [ ] <TAB>  for counter1 in range ( 0 , 0x100 ) : <TAB><TAB>  value = counter1 <TAB><TAB>  for counter2 in range ( 0 , 8 ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = value >> 1 <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  value = value >> 1 <TAB><TAB><TAB><TAB>  value = value ^ 0xEDB88320 <TAB><TAB>  table . append ( value ) <TAB>  return table ",if value & 1 == 0 :,if counter1 == counter2:,False,49.04686042753097,95.37747338881148
4599,"def pytest_collection_modifyitems ( items ) : <TAB>  for item in items : <TAB><TAB>  if item . nodeid . startswith ( "" tests/params "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB>  if "" init "" not in item . keywords : <TAB><TAB><TAB><TAB>  item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if ""stage"" not in item . keywords :","if ""stage"" not in item.keywords:",False,28.420407113655756,100.00000000000004
4600,"def python_value ( self , value ) : <TAB>  if value : <TAB><TAB>  if isinstance ( value , basestring ) : <TAB><TAB><TAB>  pp = lambda x : x . time ( ) <TAB><TAB><TAB>  return format_date_time ( value , self . formats , pp ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return value . time ( ) <TAB>  if value is not None and isinstance ( value , datetime . timedelta ) : <TAB><TAB>  return ( datetime . datetime . min + value ) . time ( ) <TAB>  return value ","elif isinstance ( value , datetime . datetime ) :","if isinstance(value, datetime.datetime):",False,30.982863944545713,98.27267114919535
4601,"def list_interesting_hosts ( self ) : <TAB>  hosts = [ ] <TAB>  targets = self . target [ "" other "" ] <TAB>  for target in targets : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  hosts . append ( <TAB><TAB><TAB><TAB>  { "" ip "" : target . ip , "" description "" : target . domain + ""  /  "" + target . name } <TAB><TAB><TAB>  ) <TAB>  return hosts ",if self . is_interesting ( target ) and target . status and target . status != 400 :,if target.type == 'other':,False,52.19240484294745,84.41139454216317
4602,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . mutable_cost ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . add_version ( d . getVarInt64 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 24 :,if tt == 10:,False,25.979740763142505,98.86228284909593
4603,"def _wait_for_finish ( self ) - > PollExitResponse : <TAB>  while True : <TAB><TAB>  if self . _backend : <TAB><TAB><TAB>  poll_exit_resp = self . _backend . interface . communicate_poll_exit ( ) <TAB><TAB>  logger . info ( "" got exit ret:  %s "" , poll_exit_resp ) <TAB><TAB>  if poll_exit_resp : <TAB><TAB><TAB>  done = poll_exit_resp . done <TAB><TAB><TAB>  pusher_stats = poll_exit_resp . pusher_stats <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _on_finish_progress ( pusher_stats , done ) <TAB><TAB><TAB>  if done : <TAB><TAB><TAB><TAB>  return poll_exit_resp <TAB><TAB>  time . sleep ( 2 ) ",if pusher_stats :,if pusher_stats:,False,49.794398973194085,100.00000000000004
4604,"def listing_items ( method ) : <TAB>  marker = None <TAB>  once = True <TAB>  items = [ ] <TAB>  while once or items : <TAB><TAB>  for i in items : <TAB><TAB><TAB>  yield i <TAB><TAB>  if once or marker : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  items = method ( parms = { "" marker "" : marker } ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  items = method ( ) <TAB><TAB><TAB>  if len ( items ) == 10000 : <TAB><TAB><TAB><TAB>  marker = items [ - 1 ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  marker = None <TAB><TAB><TAB>  once = False <TAB><TAB>  else : <TAB><TAB><TAB>  items = [ ] ",if marker :,if marker:,False,50.88606556260038,98.46458710404859
4605,"def call ( monad , * args ) : <TAB>  for arg , name in izip ( args , ( "" hour "" , "" minute "" , "" second "" , "" microsecond "" ) ) : <TAB><TAB>  if not isinstance ( arg , NumericMixin ) or arg . type is not int : <TAB><TAB><TAB>  throw ( <TAB><TAB><TAB><TAB>  TypeError , <TAB><TAB><TAB><TAB>  "" ' %s '  argument of time(...) function must be of  ' int '  type. Got:  %r "" <TAB><TAB><TAB><TAB>  % ( name , type2str ( arg . type ) ) , <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  throw ( NotImplementedError ) <TAB>  return ConstMonad . new ( time ( * tuple ( arg . value for arg in args ) ) ) ","if not isinstance ( arg , ConstMonad ) :","if not isinstance(arg, (int, long)):",False,29.942976562713998,93.18616498591373
4606,"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB>  sign = None <TAB>  subseq = [ ] <TAB>  for i in seq : <TAB><TAB>  ki = key ( i ) <TAB><TAB>  if sign is None : <TAB><TAB><TAB>  subseq . append ( i ) <TAB><TAB><TAB>  if ki != 0 : <TAB><TAB><TAB><TAB>  sign = ki / abs ( ki ) <TAB><TAB>  else : <TAB><TAB><TAB>  subseq . append ( i ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sign = ki / abs ( ki ) <TAB><TAB><TAB><TAB>  yield subseq <TAB><TAB><TAB><TAB>  subseq = [ i ] <TAB>  if subseq : <TAB><TAB>  yield subseq ",if sign * ki < - slop :,if ki != 0:,False,39.20121513684991,97.18727664527094
4607,"def walk_links ( self ) : <TAB>  link_info_list = [ ] <TAB>  for item in self . content : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  link_info = LinkInfo ( link = item , name = item . name , sections = ( ) ) <TAB><TAB><TAB>  link_info_list . append ( link_info ) <TAB><TAB>  else : <TAB><TAB><TAB>  link_info_list . extend ( item . walk_links ( ) ) <TAB>  return link_info_list ","if isinstance ( item , Link ) :","if isinstance(item, Link):",False,51.312516070924,100.00000000000004
4608,"def get_subkeys ( self , key ) : <TAB>  # TODO: once we revamp the registry emulation, <TAB>  # make this better <TAB>  parent_path = key . get_path ( ) <TAB>  subkeys = [ ] <TAB>  for k in self . keys : <TAB><TAB>  test_path = k . get_path ( ) <TAB><TAB>  if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) : <TAB><TAB><TAB>  sub = test_path [ len ( parent_path ) : ] <TAB><TAB><TAB>  if sub . startswith ( "" \\ "" ) : <TAB><TAB><TAB><TAB>  sub = sub [ 1 : ] <TAB><TAB><TAB>  end_slash = sub . find ( "" \\ "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sub = sub [ : end_slash ] <TAB><TAB><TAB>  if not sub : <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  subkeys . append ( sub ) <TAB>  return subkeys ",if end_slash >= 0 :,if end_slash is not None:,False,30.69542242002865,98.33377936588056
4609,"def load_dict ( dict_path , reverse = False ) : <TAB>  word_dict = { } <TAB>  with open ( dict_path , "" rb "" ) as fdict : <TAB><TAB>  for idx , line in enumerate ( fdict ) : <TAB><TAB><TAB>  line = cpt . to_text ( line ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  word_dict [ idx ] = line . strip ( "" \n "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  word_dict [ line . strip ( "" \n "" ) ] = idx <TAB>  return word_dict ",if reverse :,if reverse:,False,50.94043351850974,100.00000000000004
4610,"def test_network ( coords , feats , model , batch_sizes , forward_only = True ) : <TAB>  for batch_size in batch_sizes : <TAB><TAB>  bcoords = batched_coordinates ( [ coords for i in range ( batch_size ) ] ) <TAB><TAB>  bfeats = torch . cat ( [ feats for i in range ( batch_size ) ] , 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with torch . no_grad ( ) : <TAB><TAB><TAB><TAB>  time , length = forward ( bcoords , bfeats , model ) <TAB><TAB>  else : <TAB><TAB><TAB>  time , length = train ( bcoords , bfeats , model ) <TAB><TAB>  print ( f "" { net . __name__ } \t { voxel_size } \t { batch_size } \t { length } \t { time } "" ) <TAB><TAB>  torch . cuda . empty_cache ( ) ",if forward_only :,if forward_only:,False,41.88527733958751,100.00000000000004
4611,"def markUVs ( self , indices = None ) : <TAB>  if isinstance ( indices , tuple ) : <TAB><TAB>  indices = indices [ 0 ] <TAB>  ntexco = len ( self . texco ) <TAB>  if indices is None : <TAB><TAB>  self . utexc = True <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB><TAB>  if self . utexc is not True : <TAB><TAB><TAB>  self . utexc [ indices ] = True ",if self . utexc is False :,if self.utexc is None:,False,48.578939771357,98.11648427881292
4612,"def has_module ( self , module , version ) : <TAB>  has_module = False <TAB>  for directory in self . directories : <TAB><TAB>  module_directory = join ( directory , module ) <TAB><TAB>  has_module_directory = isdir ( module_directory ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  has_module = has_module_directory or exists ( <TAB><TAB><TAB><TAB>  module_directory <TAB><TAB><TAB>  )<TAB># could be a bare modulefile <TAB><TAB>  else : <TAB><TAB><TAB>  modulefile = join ( module_directory , version ) <TAB><TAB><TAB>  has_modulefile = exists ( modulefile ) <TAB><TAB><TAB>  has_module = has_module_directory and has_modulefile <TAB><TAB>  if has_module : <TAB><TAB><TAB>  break <TAB>  return has_module ",if not version :,if version == 'bare':,False,52.51542301756862,95.62448010154903
4613,"def get_editops ( self ) : <TAB>  if not self . _editops : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _editops = editops ( self . _opcodes , self . _str1 , self . _str2 ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _editops = editops ( self . _str1 , self . _str2 ) <TAB>  return self . _editops ",if self . _opcodes :,if self._opcodes:,False,50.75256331781167,100.00000000000004
4614,"def to_representation ( self , data ) : <TAB>  value = super ( CredentialTypeSerializer , self ) . to_representation ( data ) <TAB>  # translate labels and help_text for credential fields ""managed by Tower"" <TAB>  if value . get ( "" managed_by_tower "" ) : <TAB><TAB>  value [ "" name "" ] = _ ( value [ "" name "" ] ) <TAB><TAB>  for field in value . get ( "" inputs "" , { } ) . get ( "" fields "" , [ ] ) : <TAB><TAB><TAB>  field [ "" label "" ] = _ ( field [ "" label "" ] ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  field [ "" help_text "" ] = _ ( field [ "" help_text "" ] ) <TAB>  return value ","if ""help_text"" in field :",if field['help_text']:,False,59.447013969768605,95.87901794061112
4615,"def sort_nested_dictionary_lists ( d ) : <TAB>  for k , v in d . items ( ) : <TAB><TAB>  if isinstance ( v , list ) : <TAB><TAB><TAB>  for i in range ( 0 , len ( v ) ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB><TAB><TAB><TAB>  d [ k ] = sorted ( v ) <TAB><TAB>  if isinstance ( v , dict ) : <TAB><TAB><TAB>  d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB>  return d ","if isinstance ( v [ i ] , dict ) :","if isinstance(v[i], dict):",False,51.207973474104605,100.00000000000004
4616,"def messageSourceStamps ( self , source_stamps ) : <TAB>  text = "" "" <TAB>  for ss in source_stamps : <TAB><TAB>  source = "" "" <TAB><TAB>  if ss [ "" branch "" ] : <TAB><TAB><TAB>  source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB><TAB>  if ss [ "" revision "" ] : <TAB><TAB><TAB>  source + = str ( ss [ "" revision "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  source + = "" HEAD "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  source + = ""  (plus patch) "" <TAB><TAB>  discriminator = "" "" <TAB><TAB>  if ss [ "" codebase "" ] : <TAB><TAB><TAB>  discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB><TAB>  text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB>  return text ","if ss [ ""patch"" ] is not None :",if ss['patch']:,False,20.76702587490519,95.64276717891336
4617,"def fit_one ( self , x ) : <TAB>  for i , xi in x . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . median [ i ] . update ( xi ) <TAB><TAB>  if self . with_scaling : <TAB><TAB><TAB>  self . iqr [ i ] . update ( xi ) <TAB>  return self ",if self . with_centering :,if self.with_scaling:,False,26.71286837706619,97.30376770503933
4618,"def start_response ( self , status , headers , exc_info = None ) : <TAB>  if exc_info : <TAB><TAB>  try : <TAB><TAB><TAB>  if self . started : <TAB><TAB><TAB><TAB>  six . reraise ( exc_info [ 0 ] , exc_info [ 1 ] , exc_info [ 2 ] ) <TAB><TAB>  finally : <TAB><TAB><TAB>  exc_info = None <TAB>  self . request . status = int ( status [ : 3 ] ) <TAB>  for key , val in headers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . request . set_content_length ( int ( val ) ) <TAB><TAB>  elif key . lower ( ) == "" content-type "" : <TAB><TAB><TAB>  self . request . content_type = val <TAB><TAB>  else : <TAB><TAB><TAB>  self . request . headers_out . add ( key , val ) <TAB>  return self . write ","if key . lower ( ) == ""content-length"" :","if key.lower() == ""content-length':",False,24.490929706268464,98.59004581807793
4619,"def _osp2ec ( self , bytes ) : <TAB>  compressed = self . _from_bytes ( bytes ) <TAB>  y = compressed >> self . _bits <TAB>  x = compressed & ( 1 << self . _bits ) - 1 <TAB>  if x == 0 : <TAB><TAB>  y = self . _curve . b <TAB>  else : <TAB><TAB>  result = self . sqrtp ( <TAB><TAB><TAB>  x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB><TAB>  ) <TAB><TAB>  if len ( result ) == 1 : <TAB><TAB><TAB>  y = result [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  y1 , y2 = result <TAB><TAB><TAB>  y = y1 if ( y1 & 1 == y ) else y2 <TAB><TAB>  else : <TAB><TAB><TAB>  return None <TAB>  return ec . Point ( self . _curve , x , y ) ",elif len ( result ) == 2 :,if y > 0:,False,22.765681200563925,96.26114592286117
4620,"def trace ( self , ee , rname ) : <TAB>  print ( type ( self ) ) <TAB>  self . traceIndent ( ) <TAB>  guess = "" "" <TAB>  if self . inputState . guessing > 0 : <TAB><TAB>  guess = ""  [guessing] "" <TAB>  print ( ( ee + rname + guess ) ) <TAB>  for i in xrange ( 1 , self . k + 1 ) : <TAB><TAB>  if i != 1 : <TAB><TAB><TAB>  print ( "" ,  "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = self . LT ( i ) . getText ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  v = "" null "" <TAB><TAB>  print ( "" LA( %s ) ==  %s "" % ( i , v ) ) <TAB>  print ( "" \n "" ) ",if self . LT ( i ) :,if self.LT(i):,False,51.621176581103455,100.00000000000004
4621,"def _table_schema ( self , table ) : <TAB>  rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB>  # Build list of fields from table information <TAB>  result = { } <TAB>  for _ , name , data_type , not_null , _ , primary_key in rows : <TAB><TAB>  parts = [ data_type ] <TAB><TAB>  if primary_key : <TAB><TAB><TAB>  parts . append ( "" PRIMARY KEY "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parts . append ( "" NOT NULL "" ) <TAB><TAB>  result [ name ] = "" "" . join ( parts ) <TAB>  return result ",if not_null :,if not_null:,False,56.212914044901694,98.02201824717983
4622,"def _parse_csrf ( self , response ) : <TAB>  for d in response : <TAB><TAB>  if d . startswith ( "" Set-Cookie: "" ) : <TAB><TAB><TAB>  for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB><TAB><TAB><TAB>  if c . strip ( ) . startswith ( "" CSRF-Token- "" ) : <TAB><TAB><TAB><TAB><TAB>  self . _CSRFtoken = c . strip ( "" \r \n "" ) <TAB><TAB><TAB><TAB><TAB>  log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break ",if self . _CSRFtoken != None :,if self._CSRFtoken is None:,False,51.151724527310094,98.28626056858597
4623,"def _update_from_item ( self , row , download_item ) : <TAB>  progress_stats = download_item . progress_stats <TAB>  for key in self . columns : <TAB><TAB>  column = self . columns [ key ] [ 0 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Not the best place but we build the playlist status here <TAB><TAB><TAB>  status = "" {0} {1} / {2} "" . format ( <TAB><TAB><TAB><TAB>  progress_stats [ "" status "" ] , <TAB><TAB><TAB><TAB>  progress_stats [ "" playlist_index "" ] , <TAB><TAB><TAB><TAB>  progress_stats [ "" playlist_size "" ] , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  self . SetStringItem ( row , column , status ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . SetStringItem ( row , column , progress_stats [ key ] ) ","if key == ""status"" and progress_stats [ ""playlist_index"" ] :",if column == 'playlist_status':,False,53.216422649250404,93.10355766370145
4624,"def unmarshal_package_repositories ( cls , data : Any ) - > List [ "" PackageRepository "" ] : <TAB>  repositories = list ( ) <TAB>  if data is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( f "" invalid package-repositories:  { data !r} "" ) <TAB><TAB>  for repository in data : <TAB><TAB><TAB>  package_repo = cls . unmarshal ( repository ) <TAB><TAB><TAB>  repositories . append ( package_repo ) <TAB>  return repositories ","if not isinstance ( data , list ) :","if not isinstance(data, (list, tuple)):",False,30.903513183709002,95.26648309441784
4625,"def remove_message ( e = None ) : <TAB>  itop = scanbox . nearest ( 0 ) <TAB>  sel = scanbox . curselection ( ) <TAB>  if not sel : <TAB><TAB>  dialog ( <TAB><TAB><TAB>  root , <TAB><TAB><TAB>  "" No Message To Remove "" , <TAB><TAB><TAB>  "" Please select a message to remove "" , <TAB><TAB><TAB>  "" "" , <TAB><TAB><TAB>  0 , <TAB><TAB><TAB>  "" OK "" , <TAB><TAB>  ) <TAB><TAB>  return <TAB>  todo = [ ] <TAB>  for i in sel : <TAB><TAB>  line = scanbox . get ( i ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  todo . append ( string . atoi ( scanparser . group ( 1 ) ) ) <TAB>  mhf . removemessages ( todo ) <TAB>  rescan ( ) <TAB>  fixfocus ( min ( todo ) , itop ) ",if scanparser . match ( line ) >= 0 :,if line:,False,27.263105984208064,95.64401155362124
4626,"def test_patches ( ) : <TAB>  print ( <TAB><TAB>  "" Botocore version:  {}  aiohttp version:  {} "" . format ( <TAB><TAB><TAB>  botocore . __version__ , aiohttp . __version__ <TAB><TAB>  ) <TAB>  ) <TAB>  success = True <TAB>  for obj , digests in chain ( _AIOHTTP_DIGESTS . items ( ) , _API_DIGESTS . items ( ) ) : <TAB><TAB>  digest = hashlib . sha1 ( getsource ( obj ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" Digest of  {} : {}  not found in:  {} "" . format ( <TAB><TAB><TAB><TAB><TAB>  obj . __qualname__ , digest , digests <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  success = False <TAB>  assert success ",if digest not in digests :,if digest != digest:,False,37.819563694042266,98.18600527294589
4627,"def sample_admin_user ( ) : <TAB>  """"""List of iris messages"""""" <TAB>  with iris_ctl . db_from_config ( sample_db_config ) as ( conn , cursor ) : <TAB><TAB>  cursor . execute ( <TAB><TAB><TAB>  "" SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1 "" <TAB><TAB>  ) <TAB><TAB>  result = cursor . fetchone ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return result [ 0 ] ",if result :,if result:,False,68.39979409886925,100.00000000000004
4628,"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB>  if leftname in kerning : <TAB><TAB>  for rightname in kerning [ leftname ] : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  for rightname2 in groups [ rightname ] : <TAB><TAB><TAB><TAB><TAB>  rightnames . add ( rightname2 ) <TAB><TAB><TAB><TAB><TAB>  if not includeAll : <TAB><TAB><TAB><TAB><TAB><TAB>  # TODO: in this case, pick the one rightname that has the highest <TAB><TAB><TAB><TAB><TAB><TAB>  # ranking in glyphorder <TAB><TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  rightnames . add ( rightname ) ","if rightname [ 0 ] == ""@"" :",if groups[rightname] is not None:,False,59.754905005308586,95.56950180368993
4629,"def build ( self , input_shape ) : <TAB>  if isinstance ( input_shape , list ) and len ( input_shape ) == 2 : <TAB><TAB>  self . data_mode = "" disjoint "" <TAB><TAB>  self . F = input_shape [ 0 ] [ - 1 ] <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . data_mode = "" single "" <TAB><TAB>  else : <TAB><TAB><TAB>  self . data_mode = "" batch "" <TAB><TAB>  self . F = input_shape [ - 1 ] ",if len ( input_shape ) == 2 :,if len(input_shape) == 1:,False,49.98489936040277,94.11734764333106
4630,"def update_ranges ( l , i ) : <TAB>  for _range in l : <TAB><TAB>  # most common case: extend a range <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _range [ 0 ] = i <TAB><TAB><TAB>  merge_ranges ( l ) <TAB><TAB><TAB>  return <TAB><TAB>  elif i == _range [ 1 ] + 1 : <TAB><TAB><TAB>  _range [ 1 ] = i <TAB><TAB><TAB>  merge_ranges ( l ) <TAB><TAB><TAB>  return <TAB>  # somewhere outside of range proximity <TAB>  l . append ( [ i , i ] ) <TAB>  l . sort ( key = lambda x : x [ 0 ] ) ",if i == _range [ 0 ] - 1 :,if i == _range[0] + 1:,False,58.293083976512094,98.66834461262843
4631,"def transform ( a , cmds ) : <TAB>  buf = a . split ( "" \n "" ) <TAB>  for cmd in cmds : <TAB><TAB>  ctype , line , col , char = cmd <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if char != "" \n "" : <TAB><TAB><TAB><TAB>  buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB><TAB><TAB><TAB>  del buf [ line + 1 ] <TAB><TAB>  elif ctype == "" I "" : <TAB><TAB><TAB>  buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB><TAB>  buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB>  return "" \n "" . join ( buf ) ","if ctype == ""D"" :","if ctype == ""D':",False,12.141251439065488,98.63937933483545
4632,"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB>  uris = data . get_uris ( ) <TAB>  files = [ ] <TAB>  for uri in uris : <TAB><TAB>  try : <TAB><TAB><TAB>  uri_tuple = GLib . filename_from_uri ( uri ) <TAB><TAB>  except : <TAB><TAB><TAB>  continue <TAB><TAB>  uri , unused = uri_tuple <TAB><TAB>  if os . path . exists ( uri ) == True : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  files . append ( uri ) <TAB>  if len ( files ) == 0 : <TAB><TAB>  return <TAB>  open_dropped_files ( files ) ",if utils . is_media_file ( uri ) == True :,if uri not in files:,False,21.72500490944909,92.92678282219491
4633,"def __walk_proceed_remote_dir_act ( self , r , args ) : <TAB>  dirjs , filejs = args <TAB>  j = r . json ( ) <TAB>  if "" list "" not in j : <TAB><TAB>  self . pd ( <TAB><TAB><TAB>  "" Key  ' list '  not found in the response of directory listing request: \n {} "" . format ( <TAB><TAB><TAB><TAB>  j <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB><TAB>  return const . ERequestFailed <TAB>  paths = j [ "" list "" ] <TAB>  for path in paths : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dirjs . append ( path ) <TAB><TAB>  else : <TAB><TAB><TAB>  filejs . append ( path ) <TAB>  return const . ENoError ","if path [ ""isdir"" ] :",if path.startswith('/'):,False,31.009289270991903,93.78241868284995
4634,"def TaskUpdatesVerbose ( task , progress ) : <TAB>  if isinstance ( task . info . progress , int ) : <TAB><TAB>  info = task . info <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  progress = "" %d %%  ( %s ) "" % ( info . progress , info . state ) <TAB><TAB>  print ( <TAB><TAB><TAB>  "" Task  %s  (key: %s , desc: %s ) -  %s "" <TAB><TAB><TAB>  % ( info . name . info . name , info . key , info . description , progress ) <TAB><TAB>  ) ","if not isinstance ( progress , str ) :",if info.state:,False,42.854053526097566,94.33477597132726
4635,"def dump_constants ( header ) : <TAB>  output = StringIO . StringIO ( ) <TAB>  output . write ( header ) <TAB>  for attribute in dir ( FSEvents ) : <TAB><TAB>  value = getattr ( FSEvents , attribute ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  output . write ( ""<TAB>  %s  =  %s \n "" % ( attribute , hex ( value ) ) ) <TAB>  content = output . getvalue ( ) <TAB>  output . close ( ) <TAB>  return content ","if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :",if value is not None:,False,24.242607661360267,87.37876554423536
4636,"def _ensure_data_is_loaded ( <TAB>  self , <TAB>  sql_object , <TAB>  input_params , <TAB>  stdin_file , <TAB>  stdin_filename = "" - "" , <TAB>  stop_after_analysis = False ,  ) : <TAB>  data_loads = [ ] <TAB>  # Get each ""table name"" which is actually the file name <TAB>  for filename in sql_object . qtable_names : <TAB><TAB>  data_load = self . _load_data ( <TAB><TAB><TAB>  filename , <TAB><TAB><TAB>  input_params , <TAB><TAB><TAB>  stdin_file = stdin_file , <TAB><TAB><TAB>  stdin_filename = stdin_filename , <TAB><TAB><TAB>  stop_after_analysis = stop_after_analysis , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data_loads . append ( data_load ) <TAB>  return data_loads ",if data_load is not None :,if data_load is not None:,False,63.884755839127536,100.00000000000004
4637,"def _get_instantiation ( self ) : <TAB>  if self . _data is None : <TAB><TAB>  f , l , c , o = c_object_p ( ) , c_uint ( ) , c_uint ( ) , c_uint ( ) <TAB><TAB>  SourceLocation_loc ( self , byref ( f ) , byref ( l ) , byref ( c ) , byref ( o ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  f = File ( f ) <TAB><TAB>  else : <TAB><TAB><TAB>  f = None <TAB><TAB>  self . _data = ( f , int ( l . value ) , int ( c . value ) , int ( c . value ) ) <TAB>  return self . _data ",if f :,"if isinstance(f, File):",False,28.887370808202906,95.99678240327006
4638,"def _get_all_info_lines ( data ) : <TAB>  infos = [ ] <TAB>  for row in data : <TAB><TAB>  splitrow = row . split ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if splitrow [ 0 ] == "" INFO: "" : <TAB><TAB><TAB><TAB>  infos . append ( "" "" . join ( splitrow [ 1 : ] ) ) <TAB>  return infos ",if len ( splitrow ) > 0 :,if len(splitrow) > 1:,False,51.39507385994349,97.6575464491294
4639,"def _brush_modified_cb ( self , settings ) : <TAB>  """"""Updates the brush's base setting adjustments on brush changes"""""" <TAB>  for cname in settings : <TAB><TAB>  adj = self . brush_adjustment . get ( cname , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  value = self . brush . get_base_value ( cname ) <TAB><TAB>  adj . set_value ( value ) ",if adj is None :,if adj is None:,False,61.6404558371789,100.00000000000004
4640,"def migrate_node_facts ( facts ) : <TAB>  """"""Migrate facts from various roles into node"""""" <TAB>  params = { <TAB><TAB>  "" common "" : ( "" dns_ip "" ) , <TAB>  } <TAB>  if "" node "" not in facts : <TAB><TAB>  facts [ "" node "" ] = { } <TAB>  # pylint: disable=consider-iterating-dictionary <TAB>  for role in params . keys ( ) : <TAB><TAB>  if role in facts : <TAB><TAB><TAB>  for param in params [ role ] : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  facts [ "" node "" ] [ param ] = facts [ role ] . pop ( param ) <TAB>  return facts ",if param in facts [ role ] :,if param in facts:,False,50.787469123906334,97.5816113995989
4641,"def serialize_content_range ( value ) : <TAB>  if isinstance ( value , ( tuple , list ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" When setting content_range to a list/tuple, it must  "" <TAB><TAB><TAB><TAB>  "" be length 2 or 3 (not  %r ) "" % value <TAB><TAB><TAB>  ) <TAB><TAB>  if len ( value ) == 2 : <TAB><TAB><TAB>  begin , end = value <TAB><TAB><TAB>  length = None <TAB><TAB>  else : <TAB><TAB><TAB>  begin , end , length = value <TAB><TAB>  value = ContentRange ( begin , end , length ) <TAB>  value = str ( value ) . strip ( ) <TAB>  if not value : <TAB><TAB>  return None <TAB>  return value ","if len ( value ) not in ( 2 , 3 ) :",if len(value) != 3:,False,56.46630180925044,96.42736437579025
4642,"def clean ( self ) : <TAB>  data = super ( ) . clean ( ) <TAB>  if data . get ( "" expires "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data [ "" expires "" ] = make_aware ( <TAB><TAB><TAB><TAB>  datetime . combine ( data [ "" expires "" ] , time ( hour = 23 , minute = 59 , second = 59 ) ) , <TAB><TAB><TAB><TAB>  self . instance . event . timezone , <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  data [ "" expires "" ] = data [ "" expires "" ] . replace ( hour = 23 , minute = 59 , second = 59 ) <TAB><TAB>  if data [ "" expires "" ] < now ( ) : <TAB><TAB><TAB>  raise ValidationError ( _ ( "" The new expiry date needs to be in the future. "" ) ) <TAB>  return data ","if isinstance ( data [ ""expires"" ] , date ) :",if self.instance.event.timezone:,False,53.77906418884451,94.6623508897466
4643,"def _build ( self , obj , stream , context ) : <TAB>  if self . include_name : <TAB><TAB>  name , obj = obj <TAB><TAB>  for sc in self . subcons : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sc . _build ( obj , stream , context ) <TAB><TAB><TAB><TAB>  return <TAB>  else : <TAB><TAB>  for sc in self . subcons : <TAB><TAB><TAB>  stream2 = BytesIO ( ) <TAB><TAB><TAB>  context2 = context . __copy__ ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  sc . _build ( obj , stream2 , context2 ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  context . __update__ ( context2 ) <TAB><TAB><TAB><TAB>  stream . write ( stream2 . getvalue ( ) ) <TAB><TAB><TAB><TAB>  return <TAB>  raise SelectError ( "" no subconstruct matched "" , obj ) ",if sc . name == name :,"if isinstance(sc, Select):",False,49.65899534919419,97.50955200372937
4644,"def records ( account_id ) : <TAB>  """"""Fetch locks data"""""" <TAB>  s = boto3 . Session ( ) <TAB>  table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB>  results = table . scan ( ) <TAB>  for r in results [ "" Items "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB><TAB>  if "" RevisionDate "" in r : <TAB><TAB><TAB>  r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB>  print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) ) ","if ""LockDate"" in r :","if ""LockDate"" in r:",False,29.836102534852714,100.00000000000004
4645,"def visitIf ( self , node , scope ) : <TAB>  for test , body in node . tests : <TAB><TAB>  if isinstance ( test , ast . Const ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if not test . value : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB>  self . visit ( test , scope ) <TAB><TAB>  self . visit ( body , scope ) <TAB>  if node . else_ : <TAB><TAB>  self . visit ( node . else_ , scope ) ",if type ( test . value ) in self . _const_types :,"if isinstance(test, ast.If):",False,23.024884313782916,91.02398578013671
4646,"def validate_max_discount ( self ) : <TAB>  if self . rate_or_discount == "" Discount Percentage "" and self . get ( "" items "" ) : <TAB><TAB>  for d in self . items : <TAB><TAB><TAB>  max_discount = frappe . get_cached_value ( "" Item "" , d . item_code , "" max_discount "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  throw ( <TAB><TAB><TAB><TAB><TAB>  _ ( "" Max discount allowed for item:  {0}  is  {1} % "" ) . format ( <TAB><TAB><TAB><TAB><TAB><TAB>  self . item_code , max_discount <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  ) ",if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,if max_discount != None:,False,51.57654310099971,92.00103229184955
4647,"def has_invalid_cce ( yaml_file , product_yaml = None ) : <TAB>  rule = yaml . open_and_macro_expand ( yaml_file , product_yaml ) <TAB>  if "" identifiers "" in rule and rule [ "" identifiers "" ] is not None : <TAB><TAB>  for i_type , i_value in rule [ "" identifiers "" ] . items ( ) : <TAB><TAB><TAB>  if i_type [ 0 : 3 ] == "" cce "" : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB>  return False ","if not checks . is_cce_value_valid ( ""CCE-"" + str ( i_value ) ) :",if i_type == 'cce':,False,47.48204404906909,86.04117763541943
4648,"def parse_calendar_eras ( data , calendar ) : <TAB>  eras = data . setdefault ( "" eras "" , { } ) <TAB>  for width in calendar . findall ( "" eras/* "" ) : <TAB><TAB>  width_type = NAME_MAP [ width . tag ] <TAB><TAB>  widths = eras . setdefault ( width_type , { } ) <TAB><TAB>  for elem in width . getiterator ( ) : <TAB><TAB><TAB>  if elem . tag == "" era "" : <TAB><TAB><TAB><TAB>  _import_type_text ( widths , elem , type = int ( elem . attrib . get ( "" type "" ) ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  eras [ width_type ] = Alias ( <TAB><TAB><TAB><TAB><TAB>  _translate_alias ( [ "" eras "" , width_type ] , elem . attrib [ "" path "" ] ) <TAB><TAB><TAB><TAB>  ) ","elif elem . tag == ""alias"" :",if type == 'alias':,False,48.23990996318663,96.01840692891041
4649,"def validate_grammar ( ) - > None : <TAB>  for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE : <TAB><TAB>  fn_productions = get_productions ( fn ) <TAB><TAB>  if all ( p . name == fn_productions [ 0 ] . name for p in fn_productions ) : <TAB><TAB><TAB>  # all the production names are the same, ensure that the `convert_` function <TAB><TAB><TAB>  # is named correctly <TAB><TAB><TAB>  production_name = fn_productions [ 0 ] . name <TAB><TAB><TAB>  expected_name = f "" convert_ { production_name } "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB><TAB>  f "" The conversion function for  ' { production_name } ' "" <TAB><TAB><TAB><TAB><TAB>  + f "" must be called  ' { expected_name } ' , not  ' { fn . __name__ } ' . "" <TAB><TAB><TAB><TAB>  ) ",if fn . __name__ != expected_name :,"if not isinstance(expected_name, str):",False,58.10335081298463,95.60539313354337
4650,"def split_ratio ( row ) : <TAB>  if float ( row [ "" Numerator "" ] ) > 0 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n , m = row [ "" Splitratio "" ] . split ( "" : "" ) <TAB><TAB><TAB>  return float ( m ) / float ( n ) <TAB><TAB>  else : <TAB><TAB><TAB>  return eval ( row [ "" Splitratio "" ] ) <TAB>  else : <TAB><TAB>  return 1 ","if "":"" in row [ ""Splitratio"" ] :",if len(row['Splitratio']) == 1:,False,32.42960376177348,91.59751114336738
4651,"def _handle_def_errors ( testdef ) : <TAB>  # If the test generation had an error, raise <TAB>  if testdef . error : <TAB><TAB>  if testdef . exception : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise testdef . exception <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise Exception ( testdef . exception ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( "" Test parse failure "" ) ","if isinstance ( testdef . exception , Exception ) :","if isinstance(testdef.exception, Exception):",False,36.210659074151515,100.00000000000004
4652,"def _get_quota_availability ( self ) : <TAB>  quotas_ok = defaultdict ( int ) <TAB>  qa = QuotaAvailability ( ) <TAB>  qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB>  qa . compute ( now_dt = self . now_dt ) <TAB>  for quota , count in self . _quota_diff . items ( ) : <TAB><TAB>  if count < = 0 : <TAB><TAB><TAB>  quotas_ok [ quota ] = 0 <TAB><TAB><TAB>  break <TAB><TAB>  avail = qa . results [ quota ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  quotas_ok [ quota ] = count <TAB>  return quotas_ok ",if avail [ 1 ] is not None and avail [ 1 ] < count :,if avail:,False,22.223793614352434,93.49667776058419
4653,"def reverse ( self ) : <TAB>  """"""Reverse *IN PLACE*."""""" <TAB>  li = self . leftindex <TAB>  lb = self . leftblock <TAB>  ri = self . rightindex <TAB>  rb = self . rightblock <TAB>  for i in range ( self . len >> 1 ) : <TAB><TAB>  lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB><TAB>  li + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lb = lb . rightlink <TAB><TAB><TAB>  li = 0 <TAB><TAB>  ri - = 1 <TAB><TAB>  if ri < 0 : <TAB><TAB><TAB>  rb = rb . leftlink <TAB><TAB><TAB>  ri = BLOCKLEN - 1 ",if li >= BLOCKLEN :,if li > BLOCKLEN - 1:,False,31.800311987014325,97.85184018657478
4654,"def __manipulate_item ( self , item ) : <TAB>  if self . _Cursor__manipulate : <TAB><TAB>  db = self . _Cursor__collection . database <TAB><TAB>  son = db . _fix_outgoing ( item , self . _Cursor__collection ) <TAB>  else : <TAB><TAB>  son = item <TAB>  if self . __wrap is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return getattr ( self . _Cursor__collection , son [ self . __wrap . type_field ] ) ( son ) <TAB><TAB>  return self . __wrap ( son , collection = self . _Cursor__collection ) <TAB>  else : <TAB><TAB>  return son ",if self . __wrap . type_field in son :,"if isinstance(son, type):",False,49.144540332161,93.47004088878296
4655,"def apply_transforms ( self ) : <TAB>  """"""Apply all of the stored transforms, in priority order."""""" <TAB>  self . document . reporter . attach_observer ( self . document . note_transform_message ) <TAB>  while self . transforms : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Unsorted initially, and whenever a transform is added. <TAB><TAB><TAB>  self . transforms . sort ( ) <TAB><TAB><TAB>  self . transforms . reverse ( ) <TAB><TAB><TAB>  self . sorted = 1 <TAB><TAB>  priority , transform_class , pending , kwargs = self . transforms . pop ( ) <TAB><TAB>  transform = transform_class ( self . document , startnode = pending ) <TAB><TAB>  transform . apply ( * * kwargs ) <TAB><TAB>  self . applied . append ( ( priority , transform_class , pending , kwargs ) ) ",if not self . sorted :,if self.sorted:,False,38.91545618784974,98.84330912535471
4656,"def format_sql ( sql , params ) : <TAB>  rv = [ ] <TAB>  if isinstance ( params , dict ) : <TAB><TAB>  # convert sql with named parameters to sql with unnamed parameters <TAB><TAB>  conv = _FormatConverter ( params ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sql = sql_to_string ( sql ) <TAB><TAB><TAB>  sql = sql % conv <TAB><TAB><TAB>  params = conv . params <TAB><TAB>  else : <TAB><TAB><TAB>  params = ( ) <TAB>  for param in params or ( ) : <TAB><TAB>  if param is None : <TAB><TAB><TAB>  rv . append ( "" NULL "" ) <TAB><TAB>  param = safe_repr ( param ) <TAB><TAB>  rv . append ( param ) <TAB>  return sql , rv ",if params :,if conv.params:,False,61.01364682869232,98.30877369413011
4657,"def on_execution_item ( self , cpath , execution ) : <TAB>  if not isinstance ( execution , dict ) : <TAB><TAB>  return <TAB>  if "" executor "" in execution and execution . get ( "" executor "" ) != "" jmeter "" : <TAB><TAB>  return <TAB>  scenario = execution . get ( "" scenario "" , None ) <TAB>  <IF-STMT>: <TAB><TAB>  return <TAB>  if isinstance ( scenario , str ) : <TAB><TAB>  scenario_name = scenario <TAB><TAB>  scenario = self . get_named_scenario ( scenario_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  scenario = None <TAB><TAB>  scenario_path = Path ( "" scenarios "" , scenario_name ) <TAB>  else : <TAB><TAB>  scenario_path = cpath . copy ( ) <TAB><TAB>  scenario_path . add_component ( "" scenario "" ) <TAB>  if scenario is not None : <TAB><TAB>  self . check_jmeter_scenario ( scenario_path , scenario ) ",if not scenario :,if not scenario:,False,24.59196563122771,98.14104111698232
4658,"def _poll_ipc_requests ( self ) - > None : <TAB>  try : <TAB><TAB>  if self . _ipc_requests . empty ( ) : <TAB><TAB><TAB>  return <TAB><TAB>  while not self . _ipc_requests . empty ( ) : <TAB><TAB><TAB>  args = self . _ipc_requests . get ( ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  for filename in args : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  self . get_editor_notebook ( ) . show_file ( filename ) <TAB><TAB><TAB>  except Exception as e : <TAB><TAB><TAB><TAB>  logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB><TAB>  self . become_active_window ( ) <TAB>  finally : <TAB><TAB>  self . after ( 50 , self . _poll_ipc_requests ) ",if os . path . isfile ( filename ) :,if filename.startswith('.py'):,False,49.191875253732164,97.06605909616496
4659,"def get_scroll_distance_to_element ( driver , element ) : <TAB>  try : <TAB><TAB>  scroll_position = driver . execute_script ( "" return window.scrollY; "" ) <TAB><TAB>  element_location = None <TAB><TAB>  element_location = element . location [ "" y "" ] <TAB><TAB>  element_location = element_location - 130 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  element_location = 0 <TAB><TAB>  distance = element_location - scroll_position <TAB><TAB>  return distance <TAB>  except Exception : <TAB><TAB>  return 0 ",if element_location < 0 :,if element_location < 0:,False,52.74657534641853,100.00000000000004
4660,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  self . set_access_token ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 16 :,if tt == 10:,False,51.36809638600636,98.41504940787179
4661,"def _validate_and_define ( params , key , value ) : <TAB>  ( key , force_generic ) = _validate_key ( _unescape ( key ) ) <TAB>  if key in params : <TAB><TAB>  raise SyntaxError ( f ' duplicate key  "" { key } "" ' ) <TAB>  cls = _class_for_key . get ( key , GenericParam ) <TAB>  emptiness = cls . emptiness ( ) <TAB>  if value is None : <TAB><TAB>  if emptiness == Emptiness . NEVER : <TAB><TAB><TAB>  raise SyntaxError ( "" value cannot be empty "" ) <TAB><TAB>  value = cls . from_value ( value ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  value = cls . from_wire_parser ( dns . wire . Parser ( _unescape ( value ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  value = cls . from_value ( value ) <TAB>  params [ key ] = value ",if force_generic :,if force_generic:,False,26.84754530202791,98.0609335775737
4662,"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB>  exclude_meta = not include_meta <TAB>  for field_name , field in node . _fields . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  field_val = getattr ( node , field_name , _marker ) <TAB><TAB>  if field_val is _marker : <TAB><TAB><TAB>  continue <TAB><TAB>  if exclude_unset : <TAB><TAB><TAB>  if callable ( field . default ) : <TAB><TAB><TAB><TAB>  default = field . default ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  default = field . default <TAB><TAB><TAB>  if field_val == default : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  yield field_name , field_val ",if exclude_meta and field . meta :,if field_name == field_name:,False,32.87818505594108,96.2510065620043
4663,"def tearDown ( self ) : <TAB>  """"""Shutdown the server."""""" <TAB>  try : <TAB><TAB>  if self . server : <TAB><TAB><TAB>  self . server . stop ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB>  self . sl_hdlr . close ( ) <TAB>  finally : <TAB><TAB>  BaseTest . tearDown ( self ) ",if self . sl_hdlr :,if self.sl_hdlr:,False,26.497816028235594,100.00000000000004
4664,"def _wait_for_async_copy ( self , share_name , file_path ) : <TAB>  count = 0 <TAB>  share_client = self . fsc . get_share_client ( share_name ) <TAB>  file_client = share_client . get_file_client ( file_path ) <TAB>  properties = file_client . get_file_properties ( ) <TAB>  while properties . copy . status != "" success "" : <TAB><TAB>  count = count + 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . fail ( "" Timed out waiting for async copy to complete. "" ) <TAB><TAB>  self . sleep ( 6 ) <TAB><TAB>  properties = file_client . get_file_properties ( ) <TAB>  self . assertEqual ( properties . copy . status , "" success "" ) ",if count > 10 :,if count > 6:,False,37.91156894690938,98.70289308045265
4665,"def __new__ ( <TAB>  cls , <TAB>  message_type : OrderBookMessageType , <TAB>  content : Dict [ str , any ] , <TAB>  timestamp : Optional [ float ] = None , <TAB>  * args , <TAB>  * * kwargs ,  ) : <TAB>  if timestamp is None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  "" timestamp must not be None when initializing snapshot messages. "" <TAB><TAB><TAB>  ) <TAB><TAB>  timestamp = int ( time . time ( ) ) <TAB>  return super ( KucoinOrderBookMessage , cls ) . __new__ ( <TAB><TAB>  cls , message_type , content , timestamp = timestamp , * args , * * kwargs <TAB>  ) ",if message_type is OrderBookMessageType . SNAPSHOT :,if timestamp is None:,False,51.92096849617729,95.60984435264146
4666,"def _drop_unique_features ( <TAB>  X : DataFrame , feature_metadata : FeatureMetadata , max_unique_ratio  ) - > list : <TAB>  features_to_drop = [ ] <TAB>  X_len = len ( X ) <TAB>  max_unique_value_count = X_len * max_unique_ratio <TAB>  for column in X : <TAB><TAB>  unique_value_count = len ( X [ column ] . unique ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  features_to_drop . append ( column ) <TAB><TAB>  elif feature_metadata . get_feature_type_raw ( column ) in [ <TAB><TAB><TAB>  R_CATEGORY , <TAB><TAB><TAB>  R_OBJECT , <TAB><TAB>  ] and ( unique_value_count > max_unique_value_count ) : <TAB><TAB><TAB>  features_to_drop . append ( column ) <TAB>  return features_to_drop ",if unique_value_count == 1 :,if feature_metadata.get_feature_type_raw(column) in [R_,False,21.513154954202236,92.31646639335527
4667,"def get_src_findex_by_pad ( s , S , padding_mode , align_corners ) : <TAB>  if padding_mode == "" zero "" : <TAB><TAB>  return get_src_findex_with_zero_pad ( s , S ) <TAB>  elif padding_mode == "" reflect "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return get_src_findex_with_reflect_pad ( s , S , True ) <TAB><TAB>  else : <TAB><TAB><TAB>  sf = get_src_findex_with_reflect_pad ( s , S , False ) <TAB><TAB><TAB>  return get_src_findex_with_repeat_pad ( sf , S ) <TAB>  elif padding_mode == "" repeat "" : <TAB><TAB>  return get_src_findex_with_repeat_pad ( s , S ) ",if align_corners :,"if align_corners == ""reflect':",False,17.009080322108986,97.4195933880953
4668,"def _iterate_self_and_parents ( self , upto = None ) : <TAB>  current = self <TAB>  result = ( ) <TAB>  while current : <TAB><TAB>  result + = ( current , ) <TAB><TAB>  if current . _parent is upto : <TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise sa_exc . InvalidRequestError ( <TAB><TAB><TAB><TAB>  "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  current = current . _parent <TAB>  return result ",elif current . _parent is None :,if not current._parent:,False,29.26801297138671,96.40272259966406
4669,"def __setattr__ ( self , name : str , val : Any ) : <TAB>  if name . startswith ( "" COMPUTED_ "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  old_val = self [ name ] <TAB><TAB><TAB>  if old_val == val : <TAB><TAB><TAB><TAB>  return <TAB><TAB><TAB>  raise KeyError ( <TAB><TAB><TAB><TAB>  "" Computed attributed  ' {} '  already exists  "" <TAB><TAB><TAB><TAB>  "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB><TAB><TAB>  ) <TAB><TAB>  self [ name ] = val <TAB>  else : <TAB><TAB>  super ( ) . __setattr__ ( name , val ) ",if name in self :,if name in self:,False,51.830924252288,100.00000000000004
4670,"def get_fnlist ( bbhandler , pkg_pn , preferred ) : <TAB>  """"""Get all recipe file names"""""" <TAB>  <IF-STMT>: <TAB><TAB>  ( latest_versions , preferred_versions ) = bb . providers . findProviders ( <TAB><TAB><TAB>  bbhandler . config_data , bbhandler . cooker . recipecaches [ "" "" ] , pkg_pn <TAB><TAB>  ) <TAB>  fn_list = [ ] <TAB>  for pn in sorted ( pkg_pn ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fn_list . append ( preferred_versions [ pn ] [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  fn_list . extend ( pkg_pn [ pn ] ) <TAB>  return fn_list ",if preferred :,if preferred:,False,21.385264124380676,97.54188262591686
4671,"def links_extracted ( self , _ , links ) : <TAB>  links_deduped = { } <TAB>  for link in links : <TAB><TAB>  link_fingerprint = link . meta [ FIELD_FINGERPRINT ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  links_deduped [ link_fingerprint ] = link <TAB>  [ <TAB><TAB>  self . _redis_pipeline . hmset ( fingerprint , self . _create_link_extracted ( link ) ) <TAB><TAB>  for ( fingerprint , link ) in links_deduped . items ( ) <TAB>  ] <TAB>  self . _redis_pipeline . execute ( ) ",if link_fingerprint in links_deduped :,if link_fingerprint in links_deduped:,False,51.13231132184028,100.00000000000004
4672,"def __call__ ( self , name , rawtext , text , lineno , inliner , options = None , content = None ) : <TAB>  options = options or { } <TAB>  content = content or [ ] <TAB>  issue_nos = [ each . strip ( ) for each in utils . unescape ( text ) . split ( "" , "" ) ] <TAB>  config = inliner . document . settings . env . app . config <TAB>  ret = [ ] <TAB>  for i , issue_no in enumerate ( issue_nos ) : <TAB><TAB>  node = self . make_node ( name , issue_no , config , options = options ) <TAB><TAB>  ret . append ( node ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  sep = nodes . raw ( text = "" ,  "" , format = "" html "" ) <TAB><TAB><TAB>  ret . append ( sep ) <TAB>  return ret , [ ] ",if i != len ( issue_nos ) - 1 :,if i == len(rawtext):,False,36.53996359355239,95.58096297392999
4673,"def init_messengers ( messengers ) : <TAB>  for messenger in messengers : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  module_path = messenger [ "" type "" ] <TAB><TAB><TAB>  messenger [ "" type "" ] = messenger [ "" type "" ] . split ( "" . "" ) [ - 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  module_path = "" oncall.messengers. "" + messenger [ "" type "" ] <TAB><TAB>  instance = getattr ( importlib . import_module ( module_path ) , messenger [ "" type "" ] ) ( <TAB><TAB><TAB>  messenger <TAB><TAB>  ) <TAB><TAB>  for transport in instance . supports : <TAB><TAB><TAB>  _active_messengers [ transport ] . append ( instance ) ","if ""."" in messenger [ ""type"" ] :",if '.' in messenger['type']:,False,48.98920097997378,94.27628059740013
4674,"def _process_enum_definition ( self , tok ) : <TAB>  fields = [ ] <TAB>  for field in tok . fields : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  expression = self . expression_parser . parse ( field . expression ) <TAB><TAB>  else : <TAB><TAB><TAB>  expression = None <TAB><TAB>  fields . append ( c_ast . CEnumField ( name = field . name . first , value = expression ) ) <TAB>  name = tok . enum_name <TAB>  if name : <TAB><TAB>  name = "" enum  %s "" % tok . enum_name . first <TAB>  else : <TAB><TAB>  name = self . _make_anonymous_type ( "" enum "" ) <TAB>  return c_ast . CTypeDefinition ( <TAB><TAB>  name = name , <TAB><TAB>  type_definition = c_ast . CEnum ( <TAB><TAB><TAB>  attributes = tok . attributes , fields = fields , name = name <TAB><TAB>  ) , <TAB>  ) ",if field . expression :,"if hasattr(field, 'expression'):",False,49.788057588550004,97.06608354030055
4675,def result_iterator ( ) : <TAB>  try : <TAB><TAB>  # reverse to keep finishing order <TAB><TAB>  fs . reverse ( ) <TAB><TAB>  while fs : <TAB><TAB><TAB>  # Careful not to keep a reference to the popped future <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  yield fs . pop ( ) . result ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  yield fs . pop ( ) . result ( end_time - time . time ( ) ) <TAB>  finally : <TAB><TAB>  for future in fs : <TAB><TAB><TAB>  future . cancel ( ) ,if timeout is None :,if end_time == 0:,False,63.30448632472127,95.67053869034544
4676,"def has_encrypted_ssh_key_data ( self ) : <TAB>  try : <TAB><TAB>  ssh_key_data = self . get_input ( "" ssh_key_data "" ) <TAB>  except AttributeError : <TAB><TAB>  return False <TAB>  try : <TAB><TAB>  pem_objects = validate_ssh_private_key ( ssh_key_data ) <TAB><TAB>  for pem_object in pem_objects : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB>  except ValidationError : <TAB><TAB>  pass <TAB>  return False ","if pem_object . get ( ""key_enc"" , False ) :",if pem_object['private_key'].value == ssh_key_data:,False,48.84712181811504,90.99975359322727
4677,"def test_seq_object_transcription_method ( self ) : <TAB>  for nucleotide_seq in test_seqs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( <TAB><TAB><TAB><TAB>  repr ( Seq . transcribe ( nucleotide_seq ) ) , <TAB><TAB><TAB><TAB>  repr ( nucleotide_seq . transcribe ( ) ) , <TAB><TAB><TAB>  ) ","if isinstance ( nucleotide_seq , Seq . Seq ) :",if nucleotide_seq.type == 'Nursor':,False,35.86311984758047,91.28634763694555
4678,"def max_elevation ( self ) : <TAB>  max_el = None <TAB>  for y in xrange ( self . height ) : <TAB><TAB>  for x in xrange ( self . width ) : <TAB><TAB><TAB>  el = self . elevation [ "" data "" ] [ y ] [ x ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  max_el = el <TAB>  return max_el ",if max_el is None or el > max_el :,if el > max_el:,False,41.35989711779188,93.36700810781672
4679,"def stress ( mapping , index ) : <TAB>  for count in range ( OPERATIONS ) : <TAB><TAB>  function = random . choice ( functions ) <TAB><TAB>  function ( mapping , index ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" \r "" , len ( mapping ) , "" "" * 7 , end = "" "" ) <TAB>  print ( ) ",if count % 1000 == 0 :,if len(mapping) > 0:,False,22.06177677284342,93.09813568470857
4680,"def sync_terminology ( self ) : <TAB>  if self . is_source : <TAB><TAB>  return <TAB>  store = self . store <TAB>  missing = [ ] <TAB>  for source in self . component . get_all_sources ( ) : <TAB><TAB>  if "" terminology "" not in source . all_flags : <TAB><TAB><TAB>  continue <TAB><TAB>  try : <TAB><TAB><TAB>  _unit , add = store . find_unit ( source . context , source . source ) <TAB><TAB>  except UnitNotFound : <TAB><TAB><TAB>  add = True <TAB><TAB>  # Unit is already present <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  missing . append ( ( source . context , source . source , "" "" ) ) <TAB>  if missing : <TAB><TAB>  self . add_units ( None , missing ) ",if not add :,if add:,False,51.8178615882915,98.84863661233535
4681,"def get_generators ( self ) : <TAB>  """"""Get a dict with all registered generators, indexed by name"""""" <TAB>  generators = { } <TAB>  for core in self . db . find ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _generators = core . get_generators ( { } ) <TAB><TAB><TAB>  if _generators : <TAB><TAB><TAB><TAB>  generators [ str ( core . name ) ] = _generators <TAB>  return generators ","if hasattr ( core , ""get_generators"" ) :","if hasattr(core, 'get_generators'):",False,62.10652895163826,95.12454305924545
4682,"def act ( self , state ) : <TAB>  if self . body . env . clock . frame < self . training_start_step : <TAB><TAB>  return policy_util . random ( state , self , self . body ) . cpu ( ) . squeeze ( ) . numpy ( ) <TAB>  else : <TAB><TAB>  action = self . action_policy ( state , self , self . body ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  action = self . scale_action ( torch . tanh ( action ) )<TAB># continuous action bound <TAB><TAB>  return action . cpu ( ) . squeeze ( ) . numpy ( ) ",if not self . body . is_discrete :,if action is None:,False,23.82199283094114,92.9258574239736
4683,"def try_open_completions_event ( self , event = None ) : <TAB>  "" (./) Open completion list after pause with no movement. "" <TAB>  lastchar = self . text . get ( "" insert-1c "" ) <TAB>  if lastchar in TRIGGERS : <TAB><TAB>  args = TRY_A if lastchar == "" . "" else TRY_F <TAB><TAB>  self . _delayed_completion_index = self . text . index ( "" insert "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . text . after_cancel ( self . _delayed_completion_id ) <TAB><TAB>  self . _delayed_completion_id = self . text . after ( <TAB><TAB><TAB>  self . popupwait , self . _delayed_open_completions , args <TAB><TAB>  ) ",if self . _delayed_completion_id is not None :,if self._delayed_completion_id:,False,58.962972187260675,97.7281318997009
4684,"def token_is_available ( self ) : <TAB>  if self . token : <TAB><TAB>  try : <TAB><TAB><TAB>  resp = requests . get ( <TAB><TAB><TAB><TAB>  "" https://api.shodan.io/account/profile?key= {0} "" . format ( self . token ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return True <TAB><TAB>  except Exception as ex : <TAB><TAB><TAB>  logger . error ( str ( ex ) ) <TAB>  return False ","if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :",if resp.status_code == 200:,False,20.04495739456876,91.33840927732433
4685,"def next_bar_ ( self , event ) : <TAB>  bars = event . bar_dict <TAB>  self . _current_minute = self . _minutes_since_midnight ( <TAB><TAB>  self . ucontext . now . hour , self . ucontext . now . minute <TAB>  ) <TAB>  for day_rule , time_rule , func in self . _registry : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with ExecutionContext ( EXECUTION_PHASE . SCHEDULED ) : <TAB><TAB><TAB><TAB>  with ModifyExceptionFromType ( EXC_TYPE . USER_EXC ) : <TAB><TAB><TAB><TAB><TAB>  func ( self . ucontext , bars ) <TAB>  self . _last_minute = self . _current_minute ",if day_rule ( ) and time_rule ( ) :,if day_rule == self._current_minute:,False,47.711818741529854,94.95045688933537
4686,"def decoder ( s ) : <TAB>  r = [ ] <TAB>  decode = [ ] <TAB>  for c in s : <TAB><TAB>  if c == "" & "" and not decode : <TAB><TAB><TAB>  decode . append ( "" & "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if len ( decode ) == 1 : <TAB><TAB><TAB><TAB>  r . append ( "" & "" ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB><TAB><TAB>  decode = [ ] <TAB><TAB>  elif decode : <TAB><TAB><TAB>  decode . append ( c ) <TAB><TAB>  else : <TAB><TAB><TAB>  r . append ( c ) <TAB>  if decode : <TAB><TAB>  r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB>  bin_str = "" "" . join ( r ) <TAB>  return ( bin_str , len ( s ) ) ","elif c == ""-"" and decode :",if c == '&':,False,49.92987138310811,96.77455744655833
4687,"def admin_audit_get ( admin_id ) : <TAB>  if settings . app . demo_mode : <TAB><TAB>  resp = utils . demo_get_cache ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return utils . jsonify ( resp ) <TAB>  if not flask . g . administrator . super_user : <TAB><TAB>  return utils . jsonify ( <TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB>  "" error "" : REQUIRES_SUPER_USER , <TAB><TAB><TAB><TAB>  "" error_msg "" : REQUIRES_SUPER_USER_MSG , <TAB><TAB><TAB>  } , <TAB><TAB><TAB>  400 , <TAB><TAB>  ) <TAB>  admin = auth . get_by_id ( admin_id ) <TAB>  resp = admin . get_audit_events ( ) <TAB>  if settings . app . demo_mode : <TAB><TAB>  utils . demo_set_cache ( resp ) <TAB>  return utils . jsonify ( resp ) ",if resp :,if resp:,False,50.5268490508336,100.00000000000004
4688,"def vjp ( self , argnum , outgrad , ans , vs , gvs , args , kwargs ) : <TAB>  try : <TAB><TAB>  return self . vjps [ argnum ] ( outgrad , ans , vs , gvs , * args , * * kwargs ) <TAB>  except KeyError : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  errstr = "" Gradient of  {0}  not yet implemented. "" <TAB><TAB>  else : <TAB><TAB><TAB>  errstr = "" Gradient of  {0}  w.r.t. arg number  {1}  not yet implemented. "" <TAB><TAB>  raise NotImplementedError ( errstr . format ( self . fun . __name__ , argnum ) ) ",if self . vjps == { } :,if argnum == -1:,False,51.262994397751335,95.21493251711158
4689,"def update ( self , * args , * * kwargs ) : <TAB>  assert not self . readonly <TAB>  longest_key = 0 <TAB>  _dict = self . _dict <TAB>  reverse = self . reverse <TAB>  casereverse = self . casereverse <TAB>  for iterable in args + ( kwargs , ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  iterable = iterable . items ( ) <TAB><TAB>  for key , value in iterable : <TAB><TAB><TAB>  longest_key = max ( longest_key , len ( key ) ) <TAB><TAB><TAB>  _dict [ key ] = value <TAB><TAB><TAB>  reverse [ value ] . append ( key ) <TAB><TAB><TAB>  casereverse [ value . lower ( ) ] [ value ] + = 1 <TAB>  self . _longest_key = max ( self . _longest_key , longest_key ) ","if isinstance ( iterable , ( dict , StenoDictionary ) ) :","if isinstance(iterable, dict):",False,25.209200088538296,97.1163643746337
4690,"def update_ui ( self , window ) : <TAB>  view = window . get_active_view ( ) <TAB>  self . set_status ( view ) <TAB>  lang = "" plain_text "" <TAB>  if view : <TAB><TAB>  buf = view . get_buffer ( ) <TAB><TAB>  language = buf . get_language ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lang = language . get_id ( ) <TAB><TAB>  self . setup_smart_indent ( view , lang ) ",if language :,if language:,False,50.62027420852636,100.00000000000004
4691,"def number_operators ( self , a , b , skip = [ ] ) : <TAB>  dict = { "" a "" : a , "" b "" : b } <TAB>  for name , expr in self . binops . items ( ) : <TAB><TAB>  if name not in skip : <TAB><TAB><TAB>  name = "" __ %s __ "" % name <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  res = eval ( expr , dict ) <TAB><TAB><TAB><TAB>  self . binop_test ( a , b , res , expr , name ) <TAB>  for name , expr in self . unops . items ( ) : <TAB><TAB>  if name not in skip : <TAB><TAB><TAB>  name = "" __ %s __ "" % name <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  res = eval ( expr , dict ) <TAB><TAB><TAB><TAB>  self . unop_test ( a , res , expr , name ) ","if hasattr ( a , name ) :","if isinstance(expr, basestring):",False,32.227286574842076,94.39747818967453
4692,"def _getItemHeight ( self , item , ctrl = None ) : <TAB>  """"""Returns the full height of the item to be inserted in the form"""""" <TAB>  if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB><TAB>  return ctrl . size [ 1 ] <TAB>  if type ( ctrl ) == psychopy . visual . Slider : <TAB><TAB>  # Set radio button layout <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return 0.03 + ctrl . labelHeight * 3 <TAB><TAB>  elif item [ "" layout "" ] == "" vert "" : <TAB><TAB><TAB>  # for vertical take into account the nOptions <TAB><TAB><TAB>  return ctrl . labelHeight * len ( item [ "" options "" ] ) ","if item [ ""layout"" ] == ""horiz"" :","if item['layout'] == ""none':",False,62.98337008544814,95.64852939581071
4693,"def test_cleanup_params ( self , body , rpc_mock ) : <TAB>  res = self . _get_resp_post ( body ) <TAB>  self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB>  rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB>  cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB>  for key , value in body . items ( ) : <TAB><TAB>  if key in ( "" disabled "" , "" is_up "" ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  value = value == "" true "" <TAB><TAB>  self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB>  self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json ) ",if value is not None :,"if key == ""is_up':",False,34.87797332734025,96.03655362458737
4694,"def _read_json_content ( self , body_is_optional = False ) : <TAB>  if "" content-length "" not in self . headers : <TAB><TAB>  return self . send_error ( 411 ) if not body_is_optional else { } <TAB>  try : <TAB><TAB>  content_length = int ( self . headers . get ( "" content-length "" ) ) <TAB><TAB>  if content_length == 0 and body_is_optional : <TAB><TAB><TAB>  return { } <TAB><TAB>  request = json . loads ( self . rfile . read ( content_length ) . decode ( "" utf-8 "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return request <TAB>  except Exception : <TAB><TAB>  logger . exception ( "" Bad request "" ) <TAB>  self . send_error ( 400 ) ","if isinstance ( request , dict ) and ( request or body_is_optional ) :",if request:,False,30.17164421125337,91.67630917631564
4695,"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB>  modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB>  for modname , entry in list ( modules . items ( ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  code , tags , used , refname = entry <TAB><TAB>  for fullname in list ( used ) : <TAB><TAB><TAB>  if used [ fullname ] == docname : <TAB><TAB><TAB><TAB>  used . pop ( fullname ) <TAB><TAB>  if len ( used ) == 0 : <TAB><TAB><TAB>  modules . pop ( modname ) ",if entry is False :,if modname == docname:,False,42.391655291351924,96.84164713221789
4696,"def frames ( self ) : <TAB>  """"""an array of all the frames (including iframes) in the current window"""""" <TAB>  from thug . DOM . W3C . HTML . HTMLCollection import HTMLCollection <TAB>  frames = set ( ) <TAB>  for frame in self . _findAll ( [ "" frame "" , "" iframe "" ] ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB><TAB><TAB>  DOMImplementation . createHTMLElement ( self . window . doc , frame ) <TAB><TAB>  frames . add ( frame . _node ) <TAB>  return HTMLCollection ( self . doc , list ( frames ) ) ","if not getattr ( frame , ""_node"" , None ) :",if frame._node is not None:,False,58.53372537767616,92.6558743479333
4697,"def check ( self , * * kw ) : <TAB>  if not kw : <TAB><TAB>  return exists ( self . strpath ) <TAB>  if len ( kw ) == 1 : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB><TAB>  if "" file "" in kw : <TAB><TAB><TAB>  return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB>  return super ( LocalPath , self ) . check ( * * kw ) ","if ""dir"" in kw :","if ""dir"" in kw:",False,21.611923411728867,100.00000000000004
4698,"def __init__ ( self , folders ) : <TAB>  self . folders = folders <TAB>  self . duplicates = { } <TAB>  for folder , path in folders . items ( ) : <TAB><TAB>  duplicates = [ ] <TAB><TAB>  for other_folder , other_path in folders . items ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  if other_path == path : <TAB><TAB><TAB><TAB>  duplicates . append ( other_folder ) <TAB><TAB>  if len ( duplicates ) : <TAB><TAB><TAB>  self . duplicates [ folder ] = duplicates ",if other_folder == folder :,if other_folder == folder:,False,51.26263897866523,100.00000000000004
4699,"def next ( self , buf , pos ) : <TAB>  if pos > = len ( buf ) : <TAB><TAB>  return EOF , "" "" , pos <TAB>  mo = self . tokens_re . match ( buf , pos ) <TAB>  if mo : <TAB><TAB>  text = mo . group ( ) <TAB><TAB>  type , regexp , test_lit = self . tokens [ mo . lastindex - 1 ] <TAB><TAB>  pos = mo . end ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  type = self . literals . get ( text , type ) <TAB><TAB>  return type , text , pos <TAB>  else : <TAB><TAB>  c = buf [ pos ] <TAB><TAB>  return self . symbols . get ( c , None ) , c , pos + 1 ",if test_lit :,if regexp and test_lit:,False,41.840822616578336,98.17660210107306
4700,"def step ( self , action ) : <TAB>  """"""Repeat action, sum reward, and max over last observations."""""" <TAB>  total_reward = 0.0 <TAB>  done = None <TAB>  for i in range ( self . _skip ) : <TAB><TAB>  obs , reward , done , info = self . env . step ( action ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _obs_buffer [ 0 ] = obs <TAB><TAB>  if i == self . _skip - 1 : <TAB><TAB><TAB>  self . _obs_buffer [ 1 ] = obs <TAB><TAB>  total_reward + = reward <TAB><TAB>  if done : <TAB><TAB><TAB>  break <TAB>  # Note that the observation on the done=True frame <TAB>  # doesn't matter <TAB>  max_frame = self . _obs_buffer . max ( axis = 0 ) <TAB>  return max_frame , total_reward , done , info ",if i == self . _skip - 2 :,if reward:,False,54.60498883356517,95.54033225593359
4701,"def convert ( self , ctx , argument ) : <TAB>  arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB>  if arg [ 0 ] == "" # "" : <TAB><TAB>  arg = arg [ 1 : ] <TAB>  try : <TAB><TAB>  value = int ( arg , base = 16 ) <TAB><TAB>  if not ( 0 < = value < = 0xFFFFFF ) : <TAB><TAB><TAB>  raise BadColourArgument ( arg ) <TAB><TAB>  return discord . Colour ( value = value ) <TAB>  except ValueError : <TAB><TAB>  arg = arg . replace ( "" "" , "" _ "" ) <TAB><TAB>  method = getattr ( discord . Colour , arg , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise BadColourArgument ( arg ) <TAB><TAB>  return method ( ) ","if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",if method is None:,False,19.494326355311483,90.14076967015993
4702,"def run ( self , * * inputs ) : <TAB>  if self . inputs . copy_inputs : <TAB><TAB>  self . inputs . subjects_dir = os . getcwd ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  inputs [ "" subjects_dir "" ] = self . inputs . subjects_dir <TAB><TAB>  for originalfile in [ self . inputs . in_file , self . inputs . in_norm ] : <TAB><TAB><TAB>  copy2subjdir ( self , originalfile , folder = "" mri "" ) <TAB>  return super ( SegmentCC , self ) . run ( * * inputs ) ","if ""subjects_dir"" in inputs :",if self.inputs.subjects_dir:,False,19.33380548698754,95.29727885921587
4703,"def get_queryset ( self ) : <TAB>  if not hasattr ( self , "" _queryset "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  qs = self . queryset <TAB><TAB>  else : <TAB><TAB><TAB>  qs = self . model . _default_manager . get_queryset ( ) <TAB><TAB>  # If the queryset isn't already ordered we need to add an <TAB><TAB>  # artificial ordering here to make sure that all formsets <TAB><TAB>  # constructed from this queryset have the same form order. <TAB><TAB>  if not qs . ordered : <TAB><TAB><TAB>  qs = qs . order_by ( self . model . _meta . pk . name ) <TAB><TAB>  # Removed queryset limiting here. As per discussion re: #13023 <TAB><TAB>  # on django-dev, max_num should not prevent existing <TAB><TAB>  # related objects/inlines from being displayed. <TAB><TAB>  self . _queryset = qs <TAB>  return self . _queryset ",if self . queryset is not None :,if self.queryset:,False,66.81337497238792,98.15631587551002
4704,"def visit_simple_stmt ( self , node : Node ) - > Iterator [ Line ] : <TAB>  """"""Visit a statement without nested statements."""""" <TAB>  is_suite_like = node . parent and node . parent . type in STATEMENT <TAB>  if is_suite_like : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield from self . visit_default ( node ) <TAB><TAB>  else : <TAB><TAB><TAB>  yield from self . line ( + 1 ) <TAB><TAB><TAB>  yield from self . visit_default ( node ) <TAB><TAB><TAB>  yield from self . line ( - 1 ) <TAB>  else : <TAB><TAB>  if not self . is_pyi or not node . parent or not is_stub_suite ( node . parent ) : <TAB><TAB><TAB>  yield from self . line ( ) <TAB><TAB>  yield from self . visit_default ( node ) ",if self . is_pyi and is_stub_body ( node ) :,if node.is_suite_like:,False,45.915292415627434,93.16578649372815
4705,"def rawDataReceived ( self , data ) : <TAB>  if self . timeout > 0 : <TAB><TAB>  self . resetTimeout ( ) <TAB>  self . _pendingSize - = len ( data ) <TAB>  if self . _pendingSize > 0 : <TAB><TAB>  self . _pendingBuffer . write ( data ) <TAB>  else : <TAB><TAB>  passon = b "" "" <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  data , passon = data [ : self . _pendingSize ] , data [ self . _pendingSize : ] <TAB><TAB>  self . _pendingBuffer . write ( data ) <TAB><TAB>  rest = self . _pendingBuffer <TAB><TAB>  self . _pendingBuffer = None <TAB><TAB>  self . _pendingSize = None <TAB><TAB>  rest . seek ( 0 , 0 ) <TAB><TAB>  self . _parts . append ( rest . read ( ) ) <TAB><TAB>  self . setLineMode ( passon . lstrip ( b "" \r \n "" ) ) ",if self . _pendingSize < 0 :,if self._pendingSize > 0:,False,24.76714247083557,98.92583505502623
4706,"def handle ( self , * args , * * options ) : <TAB>  app_name = options . get ( "" app_name "" ) <TAB>  job_name = options . get ( "" job_name "" ) <TAB>  # hack since we are using job_name nargs='?' for -l to work <TAB>  if app_name and not job_name : <TAB><TAB>  job_name = app_name <TAB><TAB>  app_name = None <TAB>  if options . get ( "" list_jobs "" ) : <TAB><TAB>  print_jobs ( only_scheduled = False , show_when = True , show_appname = True ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( "" Run a single maintenance job. Please specify the name of the job. "" ) <TAB><TAB><TAB>  return <TAB><TAB>  self . runjob ( app_name , job_name , options ) ",if not job_name :,if not options.get('run_jobs'):,False,59.8087385874554,95.9105005578317
4707,"def _exportReceived ( self , content , error = False , server = None , context = { } , * * kwargs ) : <TAB>  if error : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . error . emit ( content [ "" message "" ] , True ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . error . emit ( "" Can ' t export the project from the server "" , True ) <TAB><TAB>  self . finished . emit ( ) <TAB><TAB>  return <TAB>  self . finished . emit ( ) ",if content :,if content.get('message'):,False,53.76580502741724,91.85168814553671
4708,"def __iter__ ( self ) : <TAB>  n = self . n <TAB>  k = self . k <TAB>  j = int ( np . ceil ( n / k ) ) <TAB>  for i in range ( k ) : <TAB><TAB>  test_index = np . zeros ( n , dtype = bool ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  test_index [ i * j : ( i + 1 ) * j ] = True <TAB><TAB>  else : <TAB><TAB><TAB>  test_index [ i * j : ] = True <TAB><TAB>  train_index = np . logical_not ( test_index ) <TAB><TAB>  yield train_index , test_index ",if i < k - 1 :,if i % 2 == 0:,False,26.081526906541384,96.26851899038972
4709,"def addType ( self , graphene_type ) : <TAB>  meta = get_meta ( graphene_type ) <TAB>  if meta : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _typeMap [ meta . name ] = graphene_type <TAB><TAB>  else : <TAB><TAB><TAB>  raise Exception ( <TAB><TAB><TAB><TAB>  "" Type  {typeName}  already exists in the registry. "" . format ( <TAB><TAB><TAB><TAB><TAB>  typeName = meta . name <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  else : <TAB><TAB>  raise Exception ( "" Cannot add unnamed type or a non-type to registry. "" ) ",if not graphene_type in self . _typeMap :,"if isinstance(meta, type):",False,33.679996350813695,94.40552152285939
4710,"def test_len ( self ) : <TAB>  eq = self . assertEqual <TAB>  eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB>  for size in range ( 15 ) : <TAB><TAB>  if size == 0 : <TAB><TAB><TAB>  bsize = 0 <TAB><TAB>  elif size < = 3 : <TAB><TAB><TAB>  bsize = 4 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  bsize = 8 <TAB><TAB>  elif size < = 9 : <TAB><TAB><TAB>  bsize = 12 <TAB><TAB>  elif size < = 12 : <TAB><TAB><TAB>  bsize = 16 <TAB><TAB>  else : <TAB><TAB><TAB>  bsize = 20 <TAB><TAB>  eq ( base64MIME . base64_len ( "" x "" * size ) , bsize ) ",elif size <= 6 :,if size <= 4:,False,27.963075551222545,97.73217726427006
4711,"def _asStringList ( self , sep = "" "" ) : <TAB>  out = [ ] <TAB>  for item in self . _toklist : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  out . append ( sep ) <TAB><TAB>  if isinstance ( item , ParseResults ) : <TAB><TAB><TAB>  out + = item . _asStringList ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  out . append ( str ( item ) ) <TAB>  return out ",if out and sep :,if sep in item:,False,47.46398014770216,96.36229844862963
4712,"def open_file_input ( cli_parsed ) : <TAB>  files = glob . glob ( os . path . join ( cli_parsed . d , "" *report.html "" ) ) <TAB>  if len ( files ) > 0 : <TAB><TAB>  print ( "" \n [*] Done! Report written in the  "" + cli_parsed . d + ""  folder! "" ) <TAB><TAB>  print ( "" Would you like to open the report now? [Y/n] "" ) <TAB><TAB>  while True : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  response = input ( ) . lower ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  return strtobool ( response ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  print ( "" Please respond with y or n "" ) <TAB>  else : <TAB><TAB>  print ( "" [*] No report files found to open, perhaps no hosts were successful "" ) <TAB><TAB>  return False ","if response == """" :",if response == 'y':,False,65.80913061079272,98.80642756959298
4713,"def init_values ( self ) : <TAB>  config = self . _raw_config <TAB>  for valname , value in self . overrides . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  realvalname , key = valname . split ( "" . "" , 1 ) <TAB><TAB><TAB>  config . setdefault ( realvalname , { } ) [ key ] = value <TAB><TAB>  else : <TAB><TAB><TAB>  config [ valname ] = value <TAB>  for name in config : <TAB><TAB>  if name in self . values : <TAB><TAB><TAB>  self . __dict__ [ name ] = config [ name ] <TAB>  del self . _raw_config ","if ""."" in valname :",if valname.startswith('.'):,False,45.151112307247345,94.79939605657916
4714,"def get_result ( self ) : <TAB>  result_list = [ ] <TAB>  exc_info = None <TAB>  for f in self . children : <TAB><TAB>  try : <TAB><TAB><TAB>  result_list . append ( f . get_result ( ) ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  exc_info = sys . exc_info ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  if not isinstance ( e , self . quiet_exceptions ) : <TAB><TAB><TAB><TAB><TAB>  app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB>  if exc_info is not None : <TAB><TAB>  raise_exc_info ( exc_info ) <TAB>  if self . keys is not None : <TAB><TAB>  return dict ( zip ( self . keys , result_list ) ) <TAB>  else : <TAB><TAB>  return list ( result_list ) ",if exc_info is None :,if exc_info is None:,False,52.33487711430133,100.00000000000004
4715,"def test01e_json ( self ) : <TAB>  "" Testing GeoJSON input/output. "" <TAB>  if not GEOJSON : <TAB><TAB>  return <TAB>  for g in self . geometries . json_geoms : <TAB><TAB>  geom = OGRGeometry ( g . wkt ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( g . json , geom . json ) <TAB><TAB><TAB>  self . assertEqual ( g . json , geom . geojson ) <TAB><TAB>  self . assertEqual ( OGRGeometry ( g . wkt ) , OGRGeometry ( geom . json ) ) ","if not hasattr ( g , ""not_equal"" ) :",if GEOJSON:,False,21.947900441790694,91.17397866315228
4716,"def __init__ ( self , hub = None ) :<TAB># pylint: disable=unused-argument <TAB>  if resolver . _resolver is None : <TAB><TAB>  _resolver = resolver . _resolver = _DualResolver ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _resolver . network_resolver . nameservers [ : ] = config . resolver_nameservers <TAB><TAB>  if config . resolver_timeout : <TAB><TAB><TAB>  _resolver . network_resolver . lifetime = config . resolver_timeout <TAB>  # Different hubs in different threads could be sharing the same <TAB>  # resolver. <TAB>  assert isinstance ( resolver . _resolver , _DualResolver ) <TAB>  self . _resolver = resolver . _resolver ",if config . resolver_nameservers :,if config.resolver_nameservers:,False,47.00897751538455,97.36943262081637
4717,"def __iadd__ ( self , term ) : <TAB>  if isinstance ( term , ( int , long ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _gmp . mpz_add_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( term ) ) <TAB><TAB><TAB>  return self <TAB><TAB>  if - 65535 < term < 0 : <TAB><TAB><TAB>  _gmp . mpz_sub_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( - term ) ) <TAB><TAB><TAB>  return self <TAB><TAB>  term = Integer ( term ) <TAB>  _gmp . mpz_add ( self . _mpz_p , self . _mpz_p , term . _mpz_p ) <TAB>  return self ",if 0 <= term < 65536 :,if term < 0:,False,48.30997432512032,94.22675442401219
4718,"def copy ( dst , src ) : <TAB>  for ( k , v ) in src . iteritems ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d = { } <TAB><TAB><TAB>  dst [ k ] = d <TAB><TAB><TAB>  copy ( d , v ) <TAB><TAB>  else : <TAB><TAB><TAB>  dst [ k ] = v ","if isinstance ( v , dict ) :","if isinstance(v, dict):",False,51.21286633835754,100.00000000000004
4719,"def generator ( self , data ) : <TAB>  self . procs = OrderedDict ( ) <TAB>  for task in data : <TAB><TAB>  self . recurse_task ( task , 0 , 0 , self . procs ) <TAB>  for offset , name , level , pid , ppid , uid , euid , gid in self . procs . values ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield ( <TAB><TAB><TAB><TAB>  0 , <TAB><TAB><TAB><TAB>  [ <TAB><TAB><TAB><TAB><TAB>  Address ( offset ) , <TAB><TAB><TAB><TAB><TAB>  str ( name ) , <TAB><TAB><TAB><TAB><TAB>  str ( level ) , <TAB><TAB><TAB><TAB><TAB>  int ( pid ) , <TAB><TAB><TAB><TAB><TAB>  int ( ppid ) , <TAB><TAB><TAB><TAB><TAB>  int ( uid ) , <TAB><TAB><TAB><TAB><TAB>  int ( gid ) , <TAB><TAB><TAB><TAB><TAB>  int ( euid ) , <TAB><TAB><TAB><TAB>  ] , <TAB><TAB><TAB>  ) ",if offset :,if offset >= 0:,False,50.10327974595177,98.53931034569287
4720,"def apply ( self , db , person ) : <TAB>  families = person . get_parent_family_handle_list ( ) <TAB>  if families == [ ] : <TAB><TAB>  return True <TAB>  for family_handle in person . get_parent_family_handle_list ( ) : <TAB><TAB>  family = db . get_family_from_handle ( family_handle ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  father_handle = family . get_father_handle ( ) <TAB><TAB><TAB>  mother_handle = family . get_mother_handle ( ) <TAB><TAB><TAB>  if not father_handle : <TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB>  if not mother_handle : <TAB><TAB><TAB><TAB>  return True <TAB>  return False ",if family :,if family:,False,50.97372915734153,100.00000000000004
4721,"def _arctic_task_exec ( request ) : <TAB>  request . start_time = time . time ( ) <TAB>  logging . debug ( <TAB><TAB>  "" Executing asynchronous request for  {} / {} "" . format ( <TAB><TAB><TAB>  request . library , request . symbol <TAB><TAB>  ) <TAB>  ) <TAB>  result = None <TAB>  try : <TAB><TAB>  request . is_running = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = mongo_retry ( request . fun ) ( * request . args , * * request . kwargs ) <TAB><TAB>  else : <TAB><TAB><TAB>  result = request . fun ( * request . args , * * request . kwargs ) <TAB>  except Exception as e : <TAB><TAB>  request . exception = e <TAB>  finally : <TAB><TAB>  request . data = result <TAB><TAB>  request . end_time = time . time ( ) <TAB><TAB>  request . is_running = False <TAB>  return result ",if request . mongo_retry :,if request.is_retry:,False,22.843634513901424,98.9949330384878
4722,"def _setup_styles ( self ) : <TAB>  for ttype , ndef in self . style : <TAB><TAB>  escape = EscapeSequence ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  escape . fg = self . _color_index ( ndef [ "" color "" ] ) <TAB><TAB>  if ndef [ "" bgcolor "" ] : <TAB><TAB><TAB>  escape . bg = self . _color_index ( ndef [ "" bgcolor "" ] ) <TAB><TAB>  if self . usebold and ndef [ "" bold "" ] : <TAB><TAB><TAB>  escape . bold = True <TAB><TAB>  if self . useunderline and ndef [ "" underline "" ] : <TAB><TAB><TAB>  escape . underline = True <TAB><TAB>  self . style_string [ str ( ttype ) ] = ( escape . color_string ( ) , escape . reset_string ( ) ) ","if ndef [ ""color"" ] :",if ndef['color']:,False,27.214105736352963,97.8702338961528
4723,"def process_string ( self , remove_repetitions , sequence ) : <TAB>  string = "" "" <TAB>  for i , char in enumerate ( sequence ) : <TAB><TAB>  if char != self . int_to_char [ self . blank_index ] : <TAB><TAB><TAB>  # if this char is a repetition and remove_repetitions=true, <TAB><TAB><TAB>  # skip. <TAB><TAB><TAB>  if remove_repetitions and i != 0 and char == sequence [ i - 1 ] : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  string + = "" "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  string = string + char <TAB>  return string ",elif char == self . labels [ self . space_index ] :,if char == ' ' and remove_repetitions:,False,63.5263991949142,93.38551539340985
4724,"def arith_expr ( self , nodelist ) : <TAB>  node = self . com_node ( nodelist [ 0 ] ) <TAB>  for i in range ( 2 , len ( nodelist ) , 2 ) : <TAB><TAB>  right = self . com_node ( nodelist [ i ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  node = Add ( node , right , lineno = nodelist [ 1 ] . context ) <TAB><TAB>  elif nodelist [ i - 1 ] . type == token . MINUS : <TAB><TAB><TAB>  node = Sub ( node , right , lineno = nodelist [ 1 ] . context ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise ValueError ( "" unexpected token:  %s "" % nodelist [ i - 1 ] [ 0 ] ) <TAB>  return node ",if nodelist [ i - 1 ] . type == token . PLUS :,if nodelist[i - 1].type == token.MINUS:,False,28.111002288151937,98.73569411297849
4725,"def invert_index ( cls , index , length ) : <TAB>  if np . isscalar ( index ) : <TAB><TAB>  return length - index <TAB>  elif isinstance ( index , slice ) : <TAB><TAB>  start , stop = index . start , index . stop <TAB><TAB>  new_start , new_stop = None , None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_stop = length - start <TAB><TAB>  if stop is not None : <TAB><TAB><TAB>  new_start = length - stop <TAB><TAB>  return slice ( new_start - 1 , new_stop - 1 ) <TAB>  elif isinstance ( index , Iterable ) : <TAB><TAB>  new_index = [ ] <TAB><TAB>  for ind in index : <TAB><TAB><TAB>  new_index . append ( length - ind ) <TAB>  return new_index ",if start is not None :,if start is not None:,False,52.60062367013356,100.00000000000004
4726,"def getRoots ( job ) : <TAB>  if job not in visited : <TAB><TAB>  visited . add ( job ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  list ( map ( lambda p : getRoots ( p ) , job . _directPredecessors ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  roots . add ( job ) <TAB><TAB>  # The following call ensures we explore all successor edges. <TAB><TAB>  list ( map ( lambda c : getRoots ( c ) , job . _children + job . _followOns ) ) ",if len ( job . _directPredecessors ) > 0 :,if job._directPredecessors:,False,57.604478822871116,94.17073784501208
4727,"def visit_filter_projection ( self , node , value ) : <TAB>  base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB>  if not isinstance ( base , list ) : <TAB><TAB>  return None <TAB>  comparator_node = node [ "" children "" ] [ 2 ] <TAB>  collected = [ ] <TAB>  for element in base : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB><TAB><TAB>  if current is not None : <TAB><TAB><TAB><TAB>  collected . append ( current ) <TAB>  return collected ","if self . _is_true ( self . visit ( comparator_node , element ) ) :",if comparator_node == element:,False,45.042366585741874,89.69278999499026
4728,"def func ( x , y ) : <TAB>  try : <TAB><TAB>  if x > y : <TAB><TAB><TAB>  z = x + 2 * math . sin ( y ) <TAB><TAB><TAB>  return z * * 2 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return 4 <TAB><TAB>  else : <TAB><TAB><TAB>  return 2 * * 3 <TAB>  except ValueError : <TAB><TAB>  foo = 0 <TAB><TAB>  for i in range ( 4 ) : <TAB><TAB><TAB>  foo + = i <TAB><TAB>  return foo <TAB>  except TypeError : <TAB><TAB>  return 42 <TAB>  else : <TAB><TAB>  return 33 <TAB>  finally : <TAB><TAB>  print ( "" finished "" ) ",elif x == y :,if x < y:,False,41.838969539337114,97.32347837018607
4729,"def set_filter ( self , dataset_opt ) : <TAB>  """"""This function create and set the pre_filter to the obj as attributes"""""" <TAB>  self . pre_filter = None <TAB>  for key_name in dataset_opt . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  new_name = key_name . replace ( "" filters "" , "" filter "" ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  filt = instantiate_filters ( getattr ( dataset_opt , key_name ) ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  log . exception ( <TAB><TAB><TAB><TAB><TAB>  "" Error trying to create  {} ,  {} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB>  new_name , getattr ( dataset_opt , key_name ) <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  setattr ( self , new_name , filt ) ","if ""filter"" in key_name :",if key_name.startswith('filters'):,False,57.22804112585103,97.25890772768041
4730,"def _add_states_to_lookup ( <TAB>  self , trackers_as_states , trackers_as_actions , domain , online = False  ) : <TAB>  """"""Add states to lookup dict"""""" <TAB>  for states in trackers_as_states : <TAB><TAB>  active_form = self . _get_active_form_name ( states [ - 1 ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # modify the states <TAB><TAB><TAB>  states = self . _modified_states ( states ) <TAB><TAB><TAB>  feature_key = self . _create_feature_key ( states ) <TAB><TAB><TAB>  # even if there are two identical feature keys <TAB><TAB><TAB>  # their form will be the same <TAB><TAB><TAB>  # because of `active_form_...` feature <TAB><TAB><TAB>  self . lookup [ feature_key ] = active_form ",if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,if active_form and active_form.is_active():,False,55.760654117327825,91.9015776134788
4731,"def list_loaded_payloads ( self ) : <TAB>  print ( helpers . color ( "" \n  [*] Available Payloads: \n "" ) ) <TAB>  lastBase = None <TAB>  x = 1 <TAB>  for name in sorted ( self . active_payloads . keys ( ) ) : <TAB><TAB>  parts = name . split ( "" / "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( ) <TAB><TAB>  lastBase = parts [ 0 ] <TAB><TAB>  print ( "" \t %s ) \t %s "" % ( x , "" {0: <24} "" . format ( name ) ) ) <TAB><TAB>  x + = 1 <TAB>  print ( "" \n "" ) <TAB>  return ",if lastBase and parts [ 0 ] != lastBase :,if len(parts) == 1:,False,23.409376151656854,94.48110569137322
4732,"def reprSmart ( vw , item ) : <TAB>  ptype = type ( item ) <TAB>  if ptype is int : <TAB><TAB>  if - 1024 < item < 1024 : <TAB><TAB><TAB>  return str ( item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return vw . reprPointer ( item ) <TAB><TAB>  else : <TAB><TAB><TAB>  return hex ( item ) <TAB>  elif ptype in ( list , tuple ) : <TAB><TAB>  return reprComplex ( vw , item )<TAB># recurse <TAB>  elif ptype is dict : <TAB><TAB>  return "" { %s } "" % "" , "" . join ( <TAB><TAB><TAB>  [ "" %s : %s "" % ( reprSmart ( vw , k ) , reprSmart ( vw , v ) ) for k , v in item . items ( ) ] <TAB><TAB>  ) <TAB>  else : <TAB><TAB>  return repr ( item ) ",elif vw . isValidPointer ( item ) :,if ptype is int:,False,22.223630513683055,93.99353587463435
4733,"def ConfigSectionMap ( section ) : <TAB>  config = ConfigParser . RawConfigParser ( ) <TAB>  configurations = config_manager ( )<TAB># Class from mkchromecast.config <TAB>  configf = configurations . configf <TAB>  config . read ( configf ) <TAB>  dict1 = { } <TAB>  options = config . options ( section ) <TAB>  for option in options : <TAB><TAB>  try : <TAB><TAB><TAB>  dict1 [ option ] = config . get ( section , option ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  DebugPrint ( "" skip:  %s "" % option ) <TAB><TAB>  except : <TAB><TAB><TAB>  print ( "" Exception on  %s ! "" % option ) <TAB><TAB><TAB>  dict1 [ option ] = None <TAB>  return dict1 ",if dict1 [ option ] == - 1 :,if not dict1.get(option):,False,16.04798488201449,93.61747260760791
4734,"def on_success ( result ) : <TAB>  subtasks = { } <TAB>  if result : <TAB><TAB>  subtasks = { <TAB><TAB><TAB>  self . nodes_keys . inverse [ s [ "" node_id "" ] ] : s . get ( "" subtask_id "" ) <TAB><TAB><TAB>  for s in result <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB>  } <TAB>  if subtasks : <TAB><TAB>  print ( "" subtask finished "" ) <TAB><TAB>  self . next ( ) <TAB>  else : <TAB><TAB>  print ( "" waiting for a subtask to finish "" ) <TAB><TAB>  time . sleep ( 10 ) ","if s . get ( ""status"" ) == ""Failure""",if s['subtask_id'] == s['subtask_id']:,False,24.9859442508415,91.53271309871481
4735,"def redirect_aware_commmunicate ( p , sys = _sys ) : <TAB>  """"""Variant of process.communicate that works with in process I/O redirection."""""" <TAB>  assert sys is not None <TAB>  out , err = p . communicate ( ) <TAB>  if redirecting_io ( sys = sys ) : <TAB><TAB>  if out : <TAB><TAB><TAB>  # We don't unicodify in Python2 because sys.stdout may be a <TAB><TAB><TAB>  # cStringIO.StringIO object, which does not accept Unicode strings <TAB><TAB><TAB>  out = unicodify ( out ) <TAB><TAB><TAB>  sys . stdout . write ( out ) <TAB><TAB><TAB>  out = None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  err = unicodify ( err ) <TAB><TAB><TAB>  sys . stderr . write ( err ) <TAB><TAB><TAB>  err = None <TAB>  return out , err ",if err :,if err:,False,66.48721833779499,100.00000000000004
4736,"def __exit__ ( self , * args , * * kwargs ) : <TAB>  self . _samples_cache = { } <TAB>  if is_validation_enabled ( ) and isinstance ( self . prior , dict ) : <TAB><TAB>  extra = set ( self . prior ) - self . _param_hits <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  warnings . warn ( <TAB><TAB><TAB><TAB>  "" pyro.module prior did not find params [ ' {} ' ].  "" <TAB><TAB><TAB><TAB>  "" Did you instead mean one of [ ' {} ' ]? "" . format ( <TAB><TAB><TAB><TAB><TAB>  "" ' ,  ' "" . join ( extra ) , "" ' ,  ' "" . join ( self . _param_misses ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  ) <TAB>  return super ( ) . __exit__ ( * args , * * kwargs ) ",if extra :,if extra:,False,53.39283046517477,100.00000000000004
4737,def __download_thread ( self ) : <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . __current_download = self . __queue . get ( ) <TAB><TAB><TAB>  self . __download_file ( self . __current_download ) <TAB><TAB>  time . sleep ( 0.1 ) ,if not self . __queue . empty ( ) :,if self.__current_download is not None:,False,43.23506643820008,90.76161453823386
4738,"def plot_timer_command ( args ) : <TAB>  import nnabla . monitor as M <TAB>  format_unit = dict ( <TAB><TAB>  s = "" seconds "" , <TAB><TAB>  m = "" minutes "" , <TAB><TAB>  h = "" hours "" , <TAB><TAB>  d = "" days "" , <TAB>  ) <TAB>  if not args . ylabel : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  args . ylabel = "" Total elapsed time [ {} ] "" . format ( format_unit [ args . time_unit ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  args . ylabel = "" Elapsed time [ {} /iter] "" . format ( format_unit [ args . time_unit ] ) <TAB>  plot_any_command ( <TAB><TAB>  args , M . plot_time_elapsed , dict ( elapsed = args . elapsed , unit = args . time_unit ) <TAB>  ) <TAB>  return True ",if args . elapsed :,if args.elapsed:,False,46.91826524111728,100.00000000000004
4739,"def resolve_page ( root : ChannelContext [ models . MenuItem ] , info , * * kwargs ) : <TAB>  if root . node . page_id : <TAB><TAB>  requestor = get_user_or_app_from_context ( info . context ) <TAB><TAB>  requestor_has_access_to_all = requestor . is_active and requestor . has_perm ( <TAB><TAB><TAB>  PagePermissions . MANAGE_PAGES <TAB><TAB>  ) <TAB><TAB>  return ( <TAB><TAB><TAB>  PageByIdLoader ( info . context ) <TAB><TAB><TAB>  . load ( root . node . page_id ) <TAB><TAB><TAB>  . then ( <TAB><TAB><TAB><TAB>  lambda page : page <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  else None <TAB><TAB><TAB>  ) <TAB><TAB>  ) <TAB>  return None ",if requestor_has_access_to_all or page . is_visible,if requestor_has_access_to_all:,False,21.38861551239214,96.85649438604162
4740,"def find ( self , pattern ) : <TAB>  """"""Find pages in database."""""" <TAB>  results = self . _search_keyword ( pattern ) <TAB>  pat = re . compile ( "" (.*?)( %s )(.*?)(  \ (.* \ ))?$ "" % re . escape ( pattern ) , re . I ) <TAB>  if results : <TAB><TAB>  for name , keyword , url in results : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  keyword = pat . sub ( <TAB><TAB><TAB><TAB><TAB>  r "" \ 1 \ 033[1;31m \ 2 \ 033[0m \ 3 \ 033[1;33m \ 4 \ 033[0m "" , keyword <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  print ( "" %s  -  %s "" % ( keyword , name ) ) <TAB>  else : <TAB><TAB>  raise RuntimeError ( "" %s : nothing appropriate. "" % pattern ) ",if os . isatty ( sys . stdout . fileno ( ) ) :,if keyword.startswith('\\s*\\s*\\s*\\s*\\,False,32.97010308165981,90.92023446082085
4741,"def _certonly_new_request_common ( self , mock_client , args = None ) : <TAB>  with mock . patch ( <TAB><TAB>  "" certbot._internal.main._find_lineage_for_domains_and_certname "" <TAB>  ) as mock_renewal : <TAB><TAB>  mock_renewal . return_value = ( "" newcert "" , None ) <TAB><TAB>  with mock . patch ( "" certbot._internal.main._init_le_client "" ) as mock_init : <TAB><TAB><TAB>  mock_init . return_value = mock_client <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  args = [ ] <TAB><TAB><TAB>  args + = "" -d foo.bar -a standalone certonly "" . split ( ) <TAB><TAB><TAB>  self . _call ( args ) ",if args is None :,if args is None:,False,48.784315819427206,100.00000000000004
4742,"def __init__ ( self , * args , * * kw ) : <TAB>  if len ( args ) > 1 : <TAB><TAB>  raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB>  if args : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  items = list ( args [ 0 ] . iteritems ( ) ) <TAB><TAB>  elif hasattr ( args [ 0 ] , "" items "" ) : <TAB><TAB><TAB>  items = list ( args [ 0 ] . items ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  items = list ( args [ 0 ] ) <TAB><TAB>  self . _items = items <TAB>  else : <TAB><TAB>  self . _items = [ ] <TAB>  if kw : <TAB><TAB>  self . _items . extend ( kw . items ( ) ) ","if hasattr ( args [ 0 ] , ""iteritems"" ) :","if hasattr(args[0], 'iteritems'):",False,56.81849142945536,97.93853433547565
4743,"def test08_ExceptionTypes ( self ) : <TAB>  self . assertTrue ( issubclass ( db . DBError , Exception ) ) <TAB>  for i , j in db . __dict__ . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertTrue ( issubclass ( j , db . DBError ) , msg = i ) <TAB><TAB><TAB>  if i not in ( "" DBKeyEmptyError "" , "" DBNotFoundError "" ) : <TAB><TAB><TAB><TAB>  self . assertFalse ( issubclass ( j , KeyError ) , msg = i ) <TAB>  # This two exceptions have two bases <TAB>  self . assertTrue ( issubclass ( db . DBKeyEmptyError , KeyError ) ) <TAB>  self . assertTrue ( issubclass ( db . DBNotFoundError , KeyError ) ) ","if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :","if i not in (DBKeyEmptyError, DBNotFoundError):",False,52.81228357364871,91.15560808335262
4744,"def _delegate_to_sinks ( self , value : Any ) - > None : <TAB>  for sink in self . _sinks : <TAB><TAB>  if isinstance ( sink , AgentT ) : <TAB><TAB><TAB>  await sink . send ( value = value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  await cast ( TopicT , sink ) . send ( value = value ) <TAB><TAB>  else : <TAB><TAB><TAB>  await maybe_async ( cast ( Callable , sink ) ( value ) ) ","elif isinstance ( sink , ChannelT ) :","if isinstance(sink, TopicT):",False,24.694219973640593,96.07712645198707
4745,"def _select_block ( str_in , start_tag , end_tag ) : <TAB>  """"""Select first block delimited by start_tag and end_tag"""""" <TAB>  start_pos = str_in . find ( start_tag ) <TAB>  if start_pos < 0 : <TAB><TAB>  raise ValueError ( "" start_tag not found "" ) <TAB>  depth = 0 <TAB>  for pos in range ( start_pos , len ( str_in ) ) : <TAB><TAB>  if str_in [ pos ] == start_tag : <TAB><TAB><TAB>  depth + = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  depth - = 1 <TAB><TAB>  if depth == 0 : <TAB><TAB><TAB>  break <TAB>  sel = str_in [ start_pos + 1 : pos ] <TAB>  return sel ",elif str_in [ pos ] == end_tag :,if str_in[pos] == end_tag:,False,46.52758248063344,98.84118727773192
4746,"def confirm ( request ) : <TAB>  details = request . session . get ( "" reauthenticate "" ) <TAB>  if not details : <TAB><TAB>  return redirect ( "" home "" ) <TAB>  # Monkey patch request <TAB>  request . user = User . objects . get ( pk = details [ "" user_pk "" ] ) <TAB>  if request . method == "" POST "" : <TAB><TAB>  confirm_form = PasswordConfirmForm ( request , request . POST ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  request . session . pop ( "" reauthenticate "" ) <TAB><TAB><TAB>  request . session [ "" reauthenticate_done "" ] = True <TAB><TAB><TAB>  return redirect ( "" social:complete "" , backend = details [ "" backend "" ] ) <TAB>  else : <TAB><TAB>  confirm_form = PasswordConfirmForm ( request ) <TAB>  context = { "" confirm_form "" : confirm_form } <TAB>  context . update ( details ) <TAB>  return render ( request , "" accounts/confirm.html "" , context ) ",if confirm_form . is_valid ( ) :,if confirm_form.validate():,False,50.620095298474865,98.18029620437943
4747,"def verify_credentials ( self ) : <TAB>  if self . enabled : <TAB><TAB>  response = requests . get ( <TAB><TAB><TAB>  "" https://api.exotel.com/v1/Accounts/ {sid} "" . format ( sid = self . account_sid ) , <TAB><TAB><TAB>  auth = ( self . api_key , self . api_token ) , <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  frappe . throw ( _ ( "" Invalid credentials "" ) ) ",if response . status_code != 200 :,if response.status_code != 200:,False,51.62140122392805,100.00000000000004
4748,"def pixbufrenderer ( self , column , crp , model , it ) : <TAB>  tok = model . get_value ( it , 0 ) <TAB>  if tok . type == "" class "" : <TAB><TAB>  icon = "" class "" <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  icon = "" method_priv "" <TAB><TAB>  elif tok . visibility == "" protected "" : <TAB><TAB><TAB>  icon = "" method_prot "" <TAB><TAB>  else : <TAB><TAB><TAB>  icon = "" method "" <TAB>  crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] ) ","if tok . visibility == ""private"" :","if tok.visibility == ""private':",False,15.728674402259077,97.84252860037283
4749,"def _omit_keywords ( self , context ) : <TAB>  omitted_kws = 0 <TAB>  for event , elem in context : <TAB><TAB>  # Teardowns aren't omitted to allow checking suite teardown status. <TAB><TAB>  omit = elem . tag == "" kw "" and elem . get ( "" type "" ) != "" teardown "" <TAB><TAB>  start = event == "" start "" <TAB><TAB>  if omit and start : <TAB><TAB><TAB>  omitted_kws + = 1 <TAB><TAB>  if not omitted_kws : <TAB><TAB><TAB>  yield event , elem <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  elem . clear ( ) <TAB><TAB>  if omit and not start : <TAB><TAB><TAB>  omitted_kws - = 1 ",elif not start :,if omit and start:,False,58.82835399520127,97.64481296572748
4750,"def on_double_click ( self , event ) : <TAB>  # TODO: don't act when the click happens below last item <TAB>  path = self . get_selected_path ( ) <TAB>  kind = self . get_selected_kind ( ) <TAB>  name = self . get_selected_name ( ) <TAB>  if kind == "" file "" : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . open_file ( path ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . open_path_with_system_app ( path ) <TAB>  elif kind == "" dir "" : <TAB><TAB>  self . request_focus_into ( path ) <TAB>  return "" break "" ",if self . should_open_name_in_thonny ( name ) :,"if kind == ""file_path':",False,36.671839993782854,91.59474043717064
4751,"def search_cve ( db : DatabaseInterface , product : Product ) - > dict : <TAB>  result = { } <TAB>  for query_result in db . fetch_multiple ( QUERIES [ "" cve_lookup "" ] ) : <TAB><TAB>  cve_entry = CveDbEntry ( * query_result ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result [ cve_entry . cve_id ] = { <TAB><TAB><TAB><TAB>  "" score2 "" : cve_entry . cvss_v2_score , <TAB><TAB><TAB><TAB>  "" score3 "" : cve_entry . cvss_v3_score , <TAB><TAB><TAB><TAB>  "" cpe_version "" : build_version_string ( cve_entry ) , <TAB><TAB><TAB>  } <TAB>  return result ","if _product_matches_cve ( product , cve_entry ) :",if cve_entry.cve_id not in result:,False,32.54628798374542,93.7764679316579
4752,"def find_go_files_mtime ( app_files ) : <TAB>  files , mtime = [ ] , 0 <TAB>  for f , mt in app_files . items ( ) : <TAB><TAB>  if not f . endswith ( "" .go "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  files . append ( f ) <TAB><TAB>  mtime = max ( mtime , mt ) <TAB>  return files , mtime ",if APP_CONFIG . nobuild_files . match ( f ) :,if f.startswith('.go'):,False,46.45743384949973,91.13598763962142
4753,"def wrapper ( filename ) : <TAB>  mtime = getmtime ( filename ) <TAB>  with lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  old_mtime , result = cache . pop ( filename ) <TAB><TAB><TAB>  if old_mtime == mtime : <TAB><TAB><TAB><TAB>  # Move to the end <TAB><TAB><TAB><TAB>  cache [ filename ] = old_mtime , result <TAB><TAB><TAB><TAB>  return result <TAB>  result = function ( filename ) <TAB>  with lock : <TAB><TAB>  cache [ filename ] = mtime , result<TAB># at the end <TAB><TAB>  if len ( cache ) > max_size : <TAB><TAB><TAB>  cache . popitem ( last = False ) <TAB>  return result ",if filename in cache :,if cache.has_key(filename):,False,50.331102278994244,93.24637210970785
4754,"def Tokenize ( s ) : <TAB>  # type: (str) -> Iterator[Token] <TAB>  for item in TOKEN_RE . findall ( s ) : <TAB><TAB>  # The type checker can't know the true type of item! <TAB><TAB>  item = cast ( TupleStr4 , item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  typ = "" number "" <TAB><TAB><TAB>  val = item [ 0 ] <TAB><TAB>  elif item [ 1 ] : <TAB><TAB><TAB>  typ = "" name "" <TAB><TAB><TAB>  val = item [ 1 ] <TAB><TAB>  elif item [ 2 ] : <TAB><TAB><TAB>  typ = item [ 2 ] <TAB><TAB><TAB>  val = item [ 2 ] <TAB><TAB>  elif item [ 3 ] : <TAB><TAB><TAB>  typ = item [ 3 ] <TAB><TAB><TAB>  val = item [ 3 ] <TAB><TAB>  yield Token ( typ , val ) ",if item [ 0 ] :,if item[0] is not None:,False,33.451589229364096,98.18600527294589
4755,"def _show_encoders ( self , * args , * * kwargs ) : <TAB>  if issubclass ( self . current_module . __class__ , BasePayload ) : <TAB><TAB>  encoders = self . current_module . get_encoders ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  headers = ( "" Encoder "" , "" Name "" , "" Description "" ) <TAB><TAB><TAB>  print_table ( headers , * encoders , max_column_length = 100 ) <TAB><TAB><TAB>  return <TAB>  print_error ( "" No encoders available "" ) ",if encoders :,if encoders:,False,48.540940574691625,100.00000000000004
4756,"def __init__ ( self ) : <TAB>  Builder . __init__ ( self , commandName = "" VCExpress.exe "" , formatName = "" msvcProject "" ) <TAB>  for key in [ "" VS90COMNTOOLS "" , "" VC80COMNTOOLS "" , "" VC71COMNTOOLS "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . programDir = os . path . join ( os . environ [ key ] , "" .. "" , "" IDE "" ) <TAB>  if self . programDir is None : <TAB><TAB>  for version in [ "" 9.0 "" , "" 8 "" , "" .NET 2003 "" ] : <TAB><TAB><TAB>  msvcDir = ( <TAB><TAB><TAB><TAB>  "" C: \\ Program Files \\ Microsoft Visual Studio  %s \\ Common7 \\ IDE "" % version <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  if os . path . exists ( msvcDir ) : <TAB><TAB><TAB><TAB>  self . programDir = msvcDir ",if os . environ . has_key ( key ) :,if key in os.environ:,False,27.66218242854923,95.85704274486018
4757,"def _inner ( * args , * * kwargs ) : <TAB>  component_manager = args [ 0 ] . component_manager <TAB>  for condition_name in condition_names : <TAB><TAB>  condition_result , err_msg = component_manager . evaluate_condition ( condition_name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ComponentStartConditionNotMetError ( err_msg ) <TAB>  if not component_manager . all_components_running ( * components ) : <TAB><TAB>  raise ComponentsNotStartedError ( <TAB><TAB><TAB>  f "" the following required components have not yet started:  { json . dumps ( components ) } "" <TAB><TAB>  ) <TAB>  return method ( * args , * * kwargs ) ",if not condition_result :,if condition_result is None:,False,26.088214830857304,97.03207984201357
4758,"def _gridconvvalue ( self , value ) : <TAB>  if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB><TAB>  try : <TAB><TAB><TAB>  svalue = str ( value ) <TAB><TAB><TAB>  if not svalue : <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return self . tk . getdouble ( svalue ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  return self . tk . getint ( svalue ) <TAB><TAB>  except ( ValueError , TclError ) : <TAB><TAB><TAB>  pass <TAB>  return value ","elif ""."" in svalue :","if isinstance(svalue, _tkinter.Tcl_Double):",False,21.74830449506997,92.78516437088456
4759,"def check_songs ( ) : <TAB>  desc = numeric_phrase ( "" %d  song "" , "" %d  songs "" , len ( songs ) ) <TAB>  with Task ( _ ( "" Rescan songs "" ) , desc ) as task : <TAB><TAB>  task . copool ( check_songs ) <TAB><TAB>  for i , song in enumerate ( songs ) : <TAB><TAB><TAB>  song = song . _song <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  app . library . reload ( song ) <TAB><TAB><TAB>  task . update ( ( float ( i ) + 1 ) / len ( songs ) ) <TAB><TAB><TAB>  yield ",if song in app . library :,if song:,False,32.003807085907496,96.72214847287279
4760,"def initialize ( self ) : <TAB>  nn . init . xavier_uniform_ ( self . linear . weight . data ) <TAB>  if self . linear . bias is not None : <TAB><TAB>  self . linear . bias . data . uniform_ ( - 1.0 , 1.0 ) <TAB>  if self . self_layer : <TAB><TAB>  nn . init . xavier_uniform_ ( self . linear_self . weight . data ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . linear_self . bias . data . uniform_ ( - 1.0 , 1.0 ) ",if self . linear_self . bias is not None :,if self.linear_self.bias is not None:,False,28.215526622085267,94.95468534130028
4761,"def test_row ( self , row ) : <TAB>  for idx , test in self . patterns . items ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  value = row [ idx ] <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  value = "" "" <TAB><TAB>  result = test ( value ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if result : <TAB><TAB><TAB><TAB>  return not self . inverse<TAB># True <TAB><TAB>  else : <TAB><TAB><TAB>  if not result : <TAB><TAB><TAB><TAB>  return self . inverse<TAB># False <TAB>  <IF-STMT>: <TAB><TAB>  return self . inverse<TAB># False <TAB>  else : <TAB><TAB>  return not self . inverse<TAB># True ",if self . any_match :,if self.is_special:,False,21.269202671300345,87.51225250358883
4762,"def toterminal ( self , tw ) : <TAB>  for element in self . chain : <TAB><TAB>  element [ 0 ] . toterminal ( tw ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tw . line ( "" "" ) <TAB><TAB><TAB>  tw . line ( element [ 2 ] , yellow = True ) <TAB>  super ( ExceptionChainRepr , self ) . toterminal ( tw ) ",if element [ 2 ] is not None :,if len(element) == 3:,False,23.50190671902076,91.59280833372493
4763,"def runMainLoop ( self ) : <TAB>  """"""The curses gui main loop."""""" <TAB>  # pylint: disable=no-member <TAB>  # <TAB>  # Do NOT change g.app! <TAB>  self . curses_app = LeoApp ( ) <TAB>  stdscr = curses . initscr ( ) <TAB>  if 1 :<TAB># Must follow initscr. <TAB><TAB>  self . dump_keys ( ) <TAB>  try : <TAB><TAB>  self . curses_app . run ( ) <TAB><TAB>  # run calls CApp.main(), which calls CGui.run(). <TAB>  finally : <TAB><TAB>  curses . nocbreak ( ) <TAB><TAB>  stdscr . keypad ( 0 ) <TAB><TAB>  curses . echo ( ) <TAB><TAB>  curses . endwin ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  g . pr ( "" Exiting Leo... "" ) ","if ""shutdown"" in g . app . debug :",if 1:,False,56.84318821932053,94.53696113231682
4764,"def test_chunkcoding ( self ) : <TAB>  for native , utf8 in zip ( * [ StringIO ( f ) . readlines ( ) for f in self . tstring ] ) : <TAB><TAB>  u = self . decode ( native ) [ 0 ] <TAB><TAB>  self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( native , self . encode ( u ) [ 0 ] ) ",if self . roundtriptest :,if u == u:,False,24.309749306153208,95.00593508673805
4765,"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB>  self . sanitize_allowlist = [ ] <TAB>  try : <TAB><TAB>  with open ( self . sanitize_allowlist_file ) as f : <TAB><TAB><TAB>  for line in f . readlines ( ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  self . sanitize_allowlist . append ( line . strip ( ) ) <TAB>  except OSError : <TAB><TAB>  if explicit : <TAB><TAB><TAB>  log . warning ( <TAB><TAB><TAB><TAB>  "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB><TAB><TAB><TAB>  self . sanitize_allowlist_file , <TAB><TAB><TAB>  ) ","if not line . startswith ( ""#"" ) :",if line.startswith('--'):,False,60.207498848580556,95.48837753424671
4766,"def get_all_extensions ( subtree = None ) : <TAB>  if subtree is None : <TAB><TAB>  subtree = full_extension_tree ( ) <TAB>  result = [ ] <TAB>  if isinstance ( subtree , dict ) : <TAB><TAB>  for value in subtree . values ( ) : <TAB><TAB><TAB>  if isinstance ( value , dict ) : <TAB><TAB><TAB><TAB>  result + = get_all_extensions ( value ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  result + = value . extensions <TAB><TAB><TAB>  elif isinstance ( value , ( list , tuple ) ) : <TAB><TAB><TAB><TAB>  result + = value <TAB>  elif isinstance ( subtree , ( ContentTypeMapping , ContentTypeDetector ) ) : <TAB><TAB>  result = subtree . extensions <TAB>  elif isinstance ( subtree , ( list , tuple ) ) : <TAB><TAB>  result = subtree <TAB>  return result ","elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :","if isinstance(value, ContentTypeMapping):",False,32.69510969528858,96.30087636375723
4767,"def _configuration_dict_to_commandlist ( name , config_dict ) : <TAB>  command_list = [ "" config: %s "" % name ] <TAB>  for key , value in config_dict . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  b = "" true "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  b = "" false "" <TAB><TAB><TAB>  command_list . append ( "" %s : %s "" % ( key , b ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  command_list . append ( "" %s : %s "" % ( key , value ) ) <TAB>  return command_list ",if type ( value ) is bool :,if key.startswith('config'):,False,48.42544464260786,96.35306414800232
4768,"def _RewriteModinfo ( <TAB>  self , <TAB>  modinfo , <TAB>  obj_kernel_version , <TAB>  this_kernel_version , <TAB>  info_strings = None , <TAB>  to_remove = None ,  ) : <TAB>  new_modinfo = "" "" <TAB>  for line in modinfo . split ( "" \x00 "" ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB><TAB><TAB>  continue <TAB><TAB>  if info_strings is not None : <TAB><TAB><TAB>  info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB><TAB>  if line . startswith ( "" vermagic "" ) : <TAB><TAB><TAB>  line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB><TAB>  new_modinfo + = line + "" \x00 "" <TAB>  return new_modinfo ",if not line :,if line.startswith('#') or line == '':,False,35.95849008147777,94.35181171836578
4769,"def zip_random_open_test ( self , f , compression ) : <TAB>  self . make_test_archive ( f , compression ) <TAB>  # Read the ZIP archive <TAB>  with zipfile . ZipFile ( f , "" r "" , compression ) as zipfp : <TAB><TAB>  zipdata1 = [ ] <TAB><TAB>  with zipfp . open ( TESTFN ) as zipopen1 : <TAB><TAB><TAB>  while True : <TAB><TAB><TAB><TAB>  read_data = zipopen1 . read ( randint ( 1 , 1024 ) ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB><TAB>  zipdata1 . append ( read_data ) <TAB><TAB>  testdata = "" "" . join ( zipdata1 ) <TAB><TAB>  self . assertEqual ( len ( testdata ) , len ( self . data ) ) <TAB><TAB>  self . assertEqual ( testdata , self . data ) ",if not read_data :,if not read_data:,False,51.46791990813053,100.00000000000004
4770,"def _memoized ( * args ) : <TAB>  now = time . time ( ) <TAB>  try : <TAB><TAB>  value , last_update = self . cache [ args ] <TAB><TAB>  age = now - last_update <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _call_count = 0 <TAB><TAB><TAB>  raise AttributeError <TAB><TAB>  if self . ctl : <TAB><TAB><TAB>  self . _call_count + = 1 <TAB><TAB>  return value <TAB>  except ( KeyError , AttributeError ) : <TAB><TAB>  value = func ( * args ) <TAB><TAB>  if value : <TAB><TAB><TAB>  self . cache [ args ] = ( value , now ) <TAB><TAB>  return value <TAB>  except TypeError : <TAB><TAB>  return func ( * args ) ",if self . _call_count > self . ctl or age > self . ttl :,if age < self._call_count:,False,22.5049050003161,94.16381728823346
4771,"def on_data ( res ) : <TAB>  if terminate . is_set ( ) : <TAB><TAB>  return <TAB>  if args . strings and not args . no_content : <TAB><TAB>  if type ( res ) == tuple : <TAB><TAB><TAB>  f , v = res <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  f = f . encode ( "" utf-8 "" ) <TAB><TAB><TAB>  if type ( v ) == unicode : <TAB><TAB><TAB><TAB>  v = v . encode ( "" utf-8 "" ) <TAB><TAB><TAB>  self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB><TAB>  elif not args . content_only : <TAB><TAB><TAB>  self . success ( res ) <TAB>  else : <TAB><TAB>  self . success ( res ) ",if type ( f ) == unicode :,if type(f) == unicode:,False,50.9997232722221,100.00000000000004
4772,"def _finalize_setup_keywords ( self ) : <TAB>  for ep in pkg_resources . iter_entry_points ( "" distutils.setup_keywords "" ) : <TAB><TAB>  value = getattr ( self , ep . name , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ep . require ( installer = self . fetch_build_egg ) <TAB><TAB><TAB>  ep . load ( ) ( self , ep . name , value ) ",if value is not None :,if value is not None:,False,52.99347651608646,100.00000000000004
4773,"def test_attributes_types ( self ) : <TAB>  if not self . connection . strategy . pooled : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . connection . refresh_server_info ( ) <TAB><TAB>  self . assertEqual ( <TAB><TAB><TAB>  type ( self . connection . server . schema . attribute_types [ "" cn "" ] ) , AttributeTypeInfo <TAB><TAB>  ) ",if not self . connection . server . info :,if self.connection.server.server_info is not None:,False,39.58519605855887,92.09531781313753
4774,"def to_key ( literal_or_identifier ) : <TAB>  """"""returns string representation of this object"""""" <TAB>  if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB>  return literal_or_identifier [ "" name "" ] <TAB>  elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB>  k = literal_or_identifier [ "" value "" ] <TAB><TAB>  if isinstance ( k , float ) : <TAB><TAB><TAB>  return unicode ( float_repr ( k ) ) <TAB><TAB>  elif "" regex "" in literal_or_identifier : <TAB><TAB><TAB>  return compose_regex ( k ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" true "" if k else "" false "" <TAB><TAB>  elif k is None : <TAB><TAB><TAB>  return "" null "" <TAB><TAB>  else : <TAB><TAB><TAB>  return unicode ( k ) ","elif isinstance ( k , bool ) :","if isinstance(k, bool):",False,54.17528095954469,98.97850561577883
4775,"def list2rec ( x , test = False ) : <TAB>  if test : <TAB><TAB>  vid = "" {} _ {:06d} _ {:06d} "" . format ( x [ 0 ] , int ( x [ 1 ] ) , int ( x [ 2 ] ) ) <TAB><TAB>  label = - 1<TAB># label unknown <TAB><TAB>  return vid , label <TAB>  else : <TAB><TAB>  vid = "" {} _ {:06d} _ {:06d} "" . format ( x [ 1 ] , int ( x [ 2 ] ) , int ( x [ 3 ] ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vid = "" {} / {} "" . format ( convert_label ( x [ 0 ] ) , vid ) <TAB><TAB>  else : <TAB><TAB><TAB>  assert level == 1 <TAB><TAB>  label = class_mapping [ convert_label ( x [ 0 ] ) ] <TAB><TAB>  return vid , label ",if level == 2 :,if level == 0:,False,21.56468124084343,96.18512202268568
4776,"def _expand_env ( self , snapcraft_yaml ) : <TAB>  environment_keys = [ "" name "" , "" version "" ] <TAB>  for key in snapcraft_yaml : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  replacements = environment_to_replacements ( <TAB><TAB><TAB>  get_snapcraft_global_environment ( self . project ) <TAB><TAB>  ) <TAB><TAB>  snapcraft_yaml [ key ] = replace_attr ( snapcraft_yaml [ key ] , replacements ) <TAB>  return snapcraft_yaml ",if any ( ( key == env_key for env_key in environment_keys ) ) :,if key in environment_keys:,False,43.8786541794376,88.26157826719516
4777,"def enableCtrls ( self ) : <TAB>  # Check if each ctrl has a requirement or an incompatibility, <TAB>  # look it up, and enable/disable if so <TAB>  for data in self . storySettingsData : <TAB><TAB>  name = data [ "" name "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if "" requires "" in data : <TAB><TAB><TAB><TAB>  set = self . getSetting ( data [ "" requires "" ] ) <TAB><TAB><TAB><TAB>  for i in self . ctrls [ name ] : <TAB><TAB><TAB><TAB><TAB>  i . Enable ( set not in [ "" off "" , "" false "" , "" 0 "" ] ) ",if name in self . ctrls :,if name in self.ctrls:,False,38.59455119916727,100.00000000000004
4778,"def __init__ ( self , * args , * * kwargs ) : <TAB>  super ( ChallengePhaseCreateSerializer , self ) . __init__ ( * args , * * kwargs ) <TAB>  context = kwargs . get ( "" context "" ) <TAB>  if context : <TAB><TAB>  challenge = context . get ( "" challenge "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  kwargs [ "" data "" ] [ "" challenge "" ] = challenge . pk <TAB><TAB>  test_annotation = context . get ( "" test_annotation "" ) <TAB><TAB>  if test_annotation : <TAB><TAB><TAB>  kwargs [ "" data "" ] [ "" test_annotation "" ] = test_annotation ",if challenge :,if challenge:,False,46.625700672080036,100.00000000000004
4779,def set_inactive ( self ) : <TAB>  for title in self . gramplet_map : <TAB><TAB>  if self . gramplet_map [ title ] . pui : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . gramplet_map [ title ] . pui . active = False ,"if self . gramplet_map [ title ] . gstate != ""detached"" :",if title in self.gramplet_map:,False,40.11696804538432,85.25940006711738
4780,"def authenticate ( username , password ) : <TAB>  try : <TAB><TAB>  u = User . objects . get ( username = username ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  userLogger . info ( "" User logged in :  %s "" , username ) <TAB><TAB><TAB>  return u <TAB><TAB>  else : <TAB><TAB><TAB>  userLogger . warn ( "" Attempt to log in to :  %s "" , username ) <TAB><TAB><TAB>  return False <TAB>  except DoesNotExist : <TAB><TAB>  return False ","if check_password_hash ( u . password , password ) :",if u.check_password(password):,False,28.20739227554716,93.66983302283921
4781,def _check_date ( self ) : <TAB>  if not self . value : <TAB><TAB>  return None <TAB>  if not self . allow_date_in_past : <TAB><TAB>  if self . value < self . date_or_datetime ( ) . today ( ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . value = self . date_or_datetime ( ) . today ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . value = self . date_or_datetime ( ) . today ( ) + datetime . timedelta ( 1 ) ,if self . allow_todays_date :,if self.allow_date_in_past:,False,50.617471801039926,96.40133002774644
4782,"def update ( self , E = None , * * F ) : <TAB>  if E : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Update with `E` dictionary <TAB><TAB><TAB>  for k in E : <TAB><TAB><TAB><TAB>  self [ k ] = E [ k ] <TAB><TAB>  else : <TAB><TAB><TAB>  # Update with `E` items <TAB><TAB><TAB>  for ( k , v ) in E : <TAB><TAB><TAB><TAB>  self [ k ] = v <TAB>  # Update with `F` dictionary <TAB>  for k in F : <TAB><TAB>  self [ k ] = F [ k ] ","if hasattr ( E , ""keys"" ) :",if F:,False,34.68982901248589,94.62833092246419
4783,"def _get_quota_availability ( self ) : <TAB>  quotas_ok = defaultdict ( int ) <TAB>  qa = QuotaAvailability ( ) <TAB>  qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB>  qa . compute ( now_dt = self . now_dt ) <TAB>  for quota , count in self . _quota_diff . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  quotas_ok [ quota ] = 0 <TAB><TAB><TAB>  break <TAB><TAB>  avail = qa . results [ quota ] <TAB><TAB>  if avail [ 1 ] is not None and avail [ 1 ] < count : <TAB><TAB><TAB>  quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  quotas_ok [ quota ] = count <TAB>  return quotas_ok ",if count <= 0 :,if count == 0:,False,54.11792804827286,98.89740890659164
4784,"def gen_env_vars ( ) : <TAB>  for fd_id , fd in zip ( STDIO_DESCRIPTORS , ( stdin , stdout , stderr ) ) : <TAB><TAB>  is_atty = fd . isatty ( ) <TAB><TAB>  yield ( cls . TTY_ENV_TMPL . format ( fd_id ) , cls . encode_env_var_value ( int ( is_atty ) ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield ( cls . TTY_PATH_ENV . format ( fd_id ) , os . ttyname ( fd . fileno ( ) ) or b "" "" ) ",if is_atty :,if is_atty:,False,21.090829368342895,100.00000000000004
4785,"def _convertDict ( self , d ) : <TAB>  r = { } <TAB>  for k , v in d . items ( ) : <TAB><TAB>  if isinstance ( v , bytes ) : <TAB><TAB><TAB>  v = str ( v , "" utf-8 "" ) <TAB><TAB>  elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB><TAB><TAB>  v = self . _convertList ( v ) <TAB><TAB>  elif isinstance ( v , dict ) : <TAB><TAB><TAB>  v = self . _convertDict ( v ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  k = str ( k , "" utf-8 "" ) <TAB><TAB>  r [ k ] = v <TAB>  return r ","if isinstance ( k , bytes ) :","if isinstance(k, unicode):",False,50.10287079040564,98.62437671704521
4786,"def get_attribute_value ( self , nodeid , attr ) : <TAB>  with self . _lock : <TAB><TAB>  self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB><TAB>  if nodeid not in self . _nodes : <TAB><TAB><TAB>  dv = ua . DataValue ( ) <TAB><TAB><TAB>  dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB><TAB><TAB>  return dv <TAB><TAB>  node = self . _nodes [ nodeid ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dv = ua . DataValue ( ) <TAB><TAB><TAB>  dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB><TAB><TAB>  return dv <TAB><TAB>  attval = node . attributes [ attr ] <TAB><TAB>  if attval . value_callback : <TAB><TAB><TAB>  return attval . value_callback ( ) <TAB><TAB>  return attval . value ",if attr not in node . attributes :,if node is None:,False,24.78220450799522,97.05420123257834
4787,"def conninfo_parse ( dsn ) : <TAB>  ret = { } <TAB>  length = len ( dsn ) <TAB>  i = 0 <TAB>  while i < length : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  i + = 1 <TAB><TAB><TAB>  continue <TAB><TAB>  param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB><TAB>  if not param_match : <TAB><TAB><TAB>  return <TAB><TAB>  param = param_match . group ( 1 ) <TAB><TAB>  i + = param_match . end ( ) <TAB><TAB>  if i > = length : <TAB><TAB><TAB>  return <TAB><TAB>  value , end = read_param_value ( dsn [ i : ] ) <TAB><TAB>  if value is None : <TAB><TAB><TAB>  return <TAB><TAB>  i + = end <TAB><TAB>  ret [ param ] = value <TAB>  return ret ",if dsn [ i ] . isspace ( ) :,if dsn[i] == 'conninfo':,False,34.32873306241937,97.73964682647596
4788,"def connect ( self , buttons ) : <TAB>  for button in buttons : <TAB><TAB>  assert button is not None <TAB><TAB>  handled = False <TAB><TAB>  for handler_idx in range ( 0 , len ( self . __signal_handlers ) ) : <TAB><TAB><TAB>  ( obj_class , signal , handler , handler_id ) = self . __signal_handlers [ <TAB><TAB><TAB><TAB>  handler_idx <TAB><TAB><TAB>  ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  handler_id = button . connect ( signal , handler ) <TAB><TAB><TAB><TAB>  handled = True <TAB><TAB><TAB>  self . __signal_handlers [ handler_idx ] = ( <TAB><TAB><TAB><TAB>  obj_class , <TAB><TAB><TAB><TAB>  signal , <TAB><TAB><TAB><TAB>  handler , <TAB><TAB><TAB><TAB>  handler_id , <TAB><TAB><TAB>  ) <TAB><TAB>  assert handled ","if isinstance ( button , obj_class ) :",if handler_id is None:,False,43.46302815322141,96.65091106299353
4789,"def _parse_display ( display ) : <TAB>  """"""Parse an X11 display value"""""" <TAB>  try : <TAB><TAB>  host , dpynum = display . rsplit ( "" : "" , 1 ) <TAB><TAB>  if host . startswith ( "" [ "" ) and host . endswith ( "" ] "" ) : <TAB><TAB><TAB>  host = host [ 1 : - 1 ] <TAB><TAB>  idx = dpynum . find ( "" . "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  screen = int ( dpynum [ idx + 1 : ] ) <TAB><TAB><TAB>  dpynum = dpynum [ : idx ] <TAB><TAB>  else : <TAB><TAB><TAB>  screen = 0 <TAB>  except ( ValueError , UnicodeEncodeError ) : <TAB><TAB>  raise ValueError ( "" Invalid X11 display "" ) from None <TAB>  return host , dpynum , screen ",if idx >= 0 :,if idx >= 0:,False,51.57647339789682,98.3329413648551
4790,"def delete_all ( path ) : <TAB>  ppath = os . getcwd ( ) <TAB>  os . chdir ( path ) <TAB>  for fn in glob . glob ( "" * "" ) : <TAB><TAB>  fn_full = os . path . join ( path , fn ) <TAB><TAB>  if os . path . isdir ( fn ) : <TAB><TAB><TAB>  delete_all ( fn_full ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB><TAB>  elif fn . endswith ( "" .md "" ) : <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB><TAB>  elif DELETE_ALL_OLD : <TAB><TAB><TAB>  os . remove ( fn_full ) <TAB>  os . chdir ( ppath ) <TAB>  os . rmdir ( path ) ","elif fn . endswith ( "".png"" ) :",if fn.endswith('.pyc'):,False,26.18019020561061,96.28813324001851
4791,"def _sync_get ( self , identifier , * args , * * kw ) : <TAB>  self . _mutex . acquire ( ) <TAB>  try : <TAB><TAB>  try : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return self . _values [ identifier ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB><TAB><TAB><TAB>  return value <TAB><TAB>  except KeyError : <TAB><TAB><TAB>  self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB><TAB><TAB>  return value <TAB>  finally : <TAB><TAB>  self . _mutex . release ( ) ",if identifier in self . _values :,if identifier in self._values:,False,46.39651735996744,100.00000000000004
4792,"def _query_fd ( self ) : <TAB>  if self . stream is None : <TAB><TAB>  self . _last_stat = None , None <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  st = os . stat ( self . _filename ) <TAB><TAB>  except OSError : <TAB><TAB><TAB>  e = sys . exc_info ( ) [ 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise <TAB><TAB><TAB>  self . _last_stat = None , None <TAB><TAB>  else : <TAB><TAB><TAB>  self . _last_stat = st [ stat . ST_DEV ] , st [ stat . ST_INO ] ",if e . errno != errno . ENOENT :,if e.errno != errno.EINVAL:,False,50.88045976199908,98.66834461262843
4793,"def get_place_name ( self , place_handle ) : <TAB>  """"""Obtain a place name"""""" <TAB>  text = "" "" <TAB>  if place_handle : <TAB><TAB>  place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  place_title = place_displayer . display ( self . dbstate . db , place ) <TAB><TAB><TAB>  if place_title != "" "" : <TAB><TAB><TAB><TAB>  if len ( place_title ) > 25 : <TAB><TAB><TAB><TAB><TAB>  text = place_title [ : 24 ] + "" ... "" <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  text = place_title <TAB>  return text ",if place :,if place:,False,50.89683109536127,100.00000000000004
4794,"def test_decoder_state ( self ) : <TAB>  # Check that getstate() and setstate() handle the state properly <TAB>  u = "" abc123 "" <TAB>  for encoding in all_unicode_encodings : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . check_state_handling_decode ( encoding , u , u . encode ( encoding ) ) <TAB><TAB><TAB>  self . check_state_handling_encode ( encoding , u , u . encode ( encoding ) ) ",if encoding not in broken_unicode_with_stateful :,if encoding != 'abc123':,False,36.31161971583373,91.42773933171559
4795,"def cleanup ( self ) : <TAB>  if os . path . exists ( self . meta_gui_dir ) : <TAB><TAB>  for f in os . listdir ( self . meta_gui_dir ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  os . remove ( os . path . join ( self . meta_gui_dir , f ) ) ","if os . path . splitext ( f ) [ 1 ] == "".desktop"" :",if f.startswith('.py') and f.endswith('.py') and,False,20.534111699229026,82.99601418573343
4796,"def _have_applied_incense ( self ) : <TAB>  for applied_item in inventory . applied_items ( ) . all ( ) : <TAB><TAB>  self . logger . info ( applied_item ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  mins = format_time ( applied_item . expire_ms * 1000 ) <TAB><TAB><TAB>  self . logger . info ( <TAB><TAB><TAB><TAB>  "" Not applying incense, currently active:  %s ,  %s  minutes remaining "" , <TAB><TAB><TAB><TAB>  applied_item . item . name , <TAB><TAB><TAB><TAB>  mins , <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  self . logger . info ( "" "" ) <TAB><TAB><TAB>  return False <TAB>  return False ",if applied_item . expire_ms > 0 :,if applied_item.item.name == applied_item.item.name:,False,36.71741892007292,94.36835953863539
4797,"def get_closest_point ( self , point ) : <TAB>  point = to_point ( point ) <TAB>  cp , cd = None , None <TAB>  for p0 , p1 in iter_pairs ( self . pts , self . connected ) : <TAB><TAB>  diff = p1 - p0 <TAB><TAB>  l = diff . length <TAB><TAB>  d = diff / l <TAB><TAB>  pp = p0 + d * max ( 0 , min ( l , ( point - p0 ) . dot ( d ) ) ) <TAB><TAB>  dist = ( point - pp ) . length <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cp , cd = pp , dist <TAB>  return cp ",if not cp or dist < cd :,if dist > 0:,False,30.43837473957996,95.6614718314522
4798,"def process_return ( lines ) : <TAB>  for line in lines : <TAB><TAB>  m = re . fullmatch ( r "" (?P<param> \ w+) \ s+: \ s+(?P<type>[ \ w.]+) "" , line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Once this is in scanpydoc, we can use the fancy hover stuff <TAB><TAB><TAB>  yield f ' ** { m [ "" param "" ] } ** : :class:`~ { m [ "" type "" ] } ` ' <TAB><TAB>  else : <TAB><TAB><TAB>  yield line ",if m :,if m:,False,58.12812326445553,97.71160249347234
4799,"def _classify ( nodes_by_level ) : <TAB>  missing , invalid , downloads = [ ] , [ ] , [ ] <TAB>  for level in nodes_by_level : <TAB><TAB>  for node in level : <TAB><TAB><TAB>  if node . binary == BINARY_MISSING : <TAB><TAB><TAB><TAB>  missing . append ( node ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  invalid . append ( node ) <TAB><TAB><TAB>  elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) : <TAB><TAB><TAB><TAB>  downloads . append ( node ) <TAB>  return missing , invalid , downloads ",elif node . binary == BINARY_INVALID :,"if node.binary in (BINARY_INVALID, BINARY_DOWNLOAD):",False,50.771548306870926,93.0046427074172
4800,"def safe_parse_date ( date_hdr ) : <TAB>  """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB><TAB>  msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB><TAB>  if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) : <TAB><TAB><TAB>  return None <TAB><TAB>  else : <TAB><TAB><TAB>  return msg_ts <TAB>  except ( ValueError , TypeError , OverflowError ) : <TAB><TAB>  return None ","if "";"" in date_hdr :",if date_hdr:,False,30.00729584172564,95.93594851815813
4801,"def _on_change ( self ) : <TAB>  changed = False <TAB>  self . save ( ) <TAB>  for key , value in self . data . items ( ) : <TAB><TAB>  if isinstance ( value , bool ) : <TAB><TAB><TAB>  if value : <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  if isinstance ( value , int ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  changed = True <TAB><TAB><TAB><TAB>  break <TAB><TAB>  elif value is None : <TAB><TAB><TAB>  continue <TAB><TAB>  elif len ( value ) != 0 : <TAB><TAB><TAB>  changed = True <TAB><TAB><TAB>  break <TAB>  self . _reset_button . disabled = not changed ",if value != 1 :,if value < 0:,False,50.420113183927306,97.95722054256035
4802,"def _rewrite_prepend_append ( self , string , prepend , append = None ) : <TAB>  if append is None : <TAB><TAB>  append = prepend <TAB>  if not isinstance ( string , StringElem ) : <TAB><TAB>  string = StringElem ( string ) <TAB>  string . sub . insert ( 0 , prepend ) <TAB>  if unicode ( string ) . endswith ( u "" \n "" ) : <TAB><TAB>  # Try and remove the last character from the tree <TAB><TAB>  try : <TAB><TAB><TAB>  lastnode = string . flatten ( ) [ - 1 ] <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  lastnode . sub [ - 1 ] = lastnode . sub [ - 1 ] . rstrip ( u "" \n "" ) <TAB><TAB>  except IndexError : <TAB><TAB><TAB>  pass <TAB><TAB>  string . sub . append ( append + u "" \n "" ) <TAB>  else : <TAB><TAB>  string . sub . append ( append ) <TAB>  return string ","if isinstance ( lastnode . sub [ - 1 ] , unicode ) :",if lastnode.sub:,False,54.192398292058094,92.59923787605962
4803,"def parse_indentless_sequence_entry ( self ) : <TAB>  if self . check_token ( BlockEntryToken ) : <TAB><TAB>  token = self . get_token ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . states . append ( self . parse_indentless_sequence_entry ) <TAB><TAB><TAB>  return self . parse_block_node ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . state = self . parse_indentless_sequence_entry <TAB><TAB><TAB>  return self . process_empty_scalar ( token . end_mark ) <TAB>  token = self . peek_token ( ) <TAB>  event = SequenceEndEvent ( token . start_mark , token . start_mark ) <TAB>  self . state = self . states . pop ( ) <TAB>  return event ","if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :",if token.start_mark == token.start_mark:,False,24.35980168276312,92.46978669468706
4804,"def walk_directory ( directory , verbose = False ) : <TAB>  """"""Iterates a directory's text files and their contents."""""" <TAB>  for dir_path , _ , filenames in os . walk ( directory ) : <TAB><TAB>  for filename in filenames : <TAB><TAB><TAB>  file_path = os . path . join ( dir_path , filename ) <TAB><TAB><TAB>  if os . path . isfile ( file_path ) and not filename . startswith ( "" . "" ) : <TAB><TAB><TAB><TAB>  with io . open ( file_path , "" r "" , encoding = "" utf-8 "" ) as file : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  print ( "" Reading  {} "" . format ( filename ) ) <TAB><TAB><TAB><TAB><TAB>  doc_text = file . read ( ) <TAB><TAB><TAB><TAB><TAB>  yield filename , doc_text ",if verbose :,if verbose:,False,56.38757151391198,100.00000000000004
4805,"def set_bounds ( self , x , y , width , height ) : <TAB>  if self . native : <TAB><TAB>  # Root level widgets may require vertical adjustment to <TAB><TAB>  # account for toolbars, etc. <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vertical_shift = self . frame . vertical_shift <TAB><TAB>  else : <TAB><TAB><TAB>  vertical_shift = 0 <TAB><TAB>  self . native . Size = Size ( width , height ) <TAB><TAB>  self . native . Location = Point ( x , y + vertical_shift ) ",if self . interface . parent is None :,if self.frame:,False,58.535513798666216,95.57520388850797
4806,"def _check_x11 ( self , command = None , * , exc = None , exit_status = None , * * kwargs ) : <TAB>  """"""Check requesting X11 forwarding"""""" <TAB>  with ( yield from self . connect ( ) ) as conn : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with self . assertRaises ( exc ) : <TAB><TAB><TAB><TAB>  yield from _create_x11_process ( conn , command , * * kwargs ) <TAB><TAB>  else : <TAB><TAB><TAB>  proc = yield from _create_x11_process ( conn , command , * * kwargs ) <TAB><TAB><TAB>  yield from proc . wait ( ) <TAB><TAB><TAB>  self . assertEqual ( proc . exit_status , exit_status ) <TAB>  yield from conn . wait_closed ( ) ",if exc :,if exc is not None:,False,46.9961727089111,97.76195587322613
4807,"def repr ( self ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  from infogami . infobase . utils import prepr <TAB><TAB><TAB>  return prepr ( self . obj ) <TAB><TAB>  else : <TAB><TAB><TAB>  return repr ( self . obj ) <TAB>  except : <TAB><TAB>  return "" failed "" <TAB>  return render_template ( "" admin/memory/object "" , self . obj ) ","if isinstance ( self . obj , ( dict , web . threadeddict ) ) :","if hasattr(infogami, 'infobase'):",False,47.684320325132724,88.51152113013809
4808,"def add ( self , tag , values ) : <TAB>  if tag not in self . different : <TAB><TAB>  if tag not in self : <TAB><TAB><TAB>  self [ tag ] = values <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . different . add ( tag ) <TAB><TAB><TAB>  self [ tag ] = [ "" "" ] <TAB>  self . counts [ tag ] + = 1 ",elif self [ tag ] != values :,if tag not in self.different:,False,24.601512737110227,91.67762097430736
4809,"def _on_geturl ( self , event ) : <TAB>  selected = self . _status_list . get_selected ( ) <TAB>  if selected != - 1 : <TAB><TAB>  object_id = self . _status_list . GetItemData ( selected ) <TAB><TAB>  download_item = self . _download_list . get_item ( object_id ) <TAB><TAB>  url = download_item . url <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  clipdata = wx . TextDataObject ( ) <TAB><TAB><TAB>  clipdata . SetText ( url ) <TAB><TAB><TAB>  wx . TheClipboard . Open ( ) <TAB><TAB><TAB>  wx . TheClipboard . SetData ( clipdata ) <TAB><TAB><TAB>  wx . TheClipboard . Close ( ) ",if not wx . TheClipboard . IsOpened ( ) :,if url != None:,False,30.366794651114997,93.68593880618594
4810,"def escape2null ( text ) : <TAB>  """"""Return a string with escape-backslashes converted to nulls."""""" <TAB>  parts = [ ] <TAB>  start = 0 <TAB>  while True : <TAB><TAB>  found = text . find ( "" \\ "" , start ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  parts . append ( text [ start : ] ) <TAB><TAB><TAB>  return "" "" . join ( parts ) <TAB><TAB>  parts . append ( text [ start : found ] ) <TAB><TAB>  parts . append ( "" \x00 "" + text [ found + 1 : found + 2 ] ) <TAB><TAB>  start = found + 2<TAB># skip character after escape ",if found == - 1 :,if found == -1:,False,32.84795245589596,97.3539630394431
4811,def _process_inner_views ( self ) : <TAB>  for view in self . baseviews : <TAB><TAB>  for inner_class in view . get_uninit_inner_views ( ) : <TAB><TAB><TAB>  for v in self . baseviews : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  view . get_init_inner_views ( ) . append ( v ) ,"if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :",if inner_class.is_visible(v):,False,23.31793995658164,83.12964257010934
4812,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  self . set_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 26 : <TAB><TAB><TAB>  self . set_method ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 34 : <TAB><TAB><TAB>  self . set_queue ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 18 :,if tt == 13:,False,51.21886122345749,98.97431450598246
4813,"def test_sample_output ( ) : <TAB>  comment = "" SAMPLE OUTPUT "" <TAB>  skip_files = [ "" __init__.py "" ] <TAB>  errors = [ ] <TAB>  for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB><TAB>  if _file . suffix == "" .py "" and _file . name not in skip_files : <TAB><TAB><TAB>  with _file . open ( ) as f : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  errors . append ( ( comment , _file ) ) <TAB>  if errors : <TAB><TAB>  line = "" Missing sample error(s) detected! \n \n "" <TAB><TAB>  for error in errors : <TAB><TAB><TAB>  line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB><TAB>  print ( line [ : - 1 ] ) <TAB><TAB>  assert False ",if comment not in f . read ( ) :,if f.read() == comment:,False,34.579411521110245,96.28918812356662
4814,"def _get_planner ( name , path , source ) : <TAB>  for klass in _planners : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  LOG . debug ( "" %r  accepted  %r  (filename  %r ) "" , klass , name , path ) <TAB><TAB><TAB>  return klass <TAB><TAB>  LOG . debug ( "" %r  rejected  %r "" , klass , name ) <TAB>  raise ansible . errors . AnsibleError ( NO_METHOD_MSG + repr ( invocation ) ) ","if klass . detect ( path , source ) :","if klass is not None and klass.accept(path, source):",False,24.66646350183407,93.70529517935849
4815,"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB>  if verbose : <TAB><TAB>  ostream . write ( ""  ,  "" ) <TAB>  else : <TAB><TAB>  hasConst = not ( <TAB><TAB><TAB>  self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  idx - = 1 <TAB><TAB>  _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB><TAB>  _lt = _l . __class__ <TAB><TAB>  if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) : <TAB><TAB><TAB>  ostream . write ( ""  -  "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  ostream . write ( ""  +  "" ) ",if hasConst :,if hasConst:,False,42.34029527786052,100.00000000000004
4816,"def cluster_info_query ( self ) : <TAB>  if self . _major_version > = 90600 : <TAB><TAB>  extra = ( <TAB><TAB><TAB>  "" , CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END, "" <TAB><TAB><TAB>  ""  slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver() "" <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  extra = "" timeline_id "" + extra + "" , pg_catalog.pg_control_checkpoint() "" <TAB><TAB>  else : <TAB><TAB><TAB>  extra = "" 0 "" + extra <TAB>  else : <TAB><TAB>  extra = "" 0, NULL, NULL, NULL "" <TAB>  return ( "" SELECT  "" + self . TL_LSN + "" ,  {2} "" ) . format ( <TAB><TAB>  self . wal_name , self . lsn_name , extra <TAB>  ) ","if self . role == ""standby_leader"" :",if self._major_version < 90600:,False,54.31272220873624,96.21361190938681
4817,"def __init__ ( self , * args , * * kwargs ) : <TAB>  self . country = kwargs . pop ( "" country "" ) <TAB>  self . fields_needed = kwargs . pop ( "" fields_needed "" , [ ] ) <TAB>  super ( DynamicManagedAccountForm , self ) . __init__ ( * args , * * kwargs ) <TAB>  # build our form using the country specific fields and falling <TAB>  # back to our default set <TAB>  for f in self . fields_needed : <TAB><TAB>  <IF-STMT>:<TAB># pragma: no branch <TAB><TAB><TAB>  field_name , field = FIELDS_BY_COUNTRY [ self . country ] [ f ] <TAB><TAB><TAB>  self . fields [ field_name ] = field ","if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :",if f not in FIELDS_BY_COUNTRY:,False,54.550080771126716,92.62303447042834
4818,"def delete_map ( self , query = None ) : <TAB>  query_map = self . interpolated_map ( query = query ) <TAB>  for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB><TAB>  for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB><TAB><TAB>  for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB><TAB><TAB>  if not query_map [ alias ] [ driver ] : <TAB><TAB><TAB><TAB>  query_map [ alias ] . pop ( driver ) <TAB><TAB>  if not query_map [ alias ] : <TAB><TAB><TAB>  query_map . pop ( alias ) <TAB>  return query_map ","if vm_details == ""Absent"" :",if vm_details.name == alias and vm_details.name == driver:,False,49.3794803026664,93.96009733755768
4819,"def on_strokes_edited ( self ) : <TAB>  strokes = self . _strokes ( ) <TAB>  if strokes : <TAB><TAB>  translation = self . _engine . raw_lookup ( strokes ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fmt = _ ( "" {strokes}  maps to  {translation} "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  fmt = _ ( "" {strokes}  is not in the dictionary "" ) <TAB><TAB>  info = self . _format_label ( fmt , ( strokes , ) , translation ) <TAB>  else : <TAB><TAB>  info = "" "" <TAB>  self . strokes_info . setText ( info ) ",if translation is not None :,if translation:,False,28.823420628493544,97.25731928996488
4820,"def release ( self ) : <TAB>  tid = _thread . get_ident ( ) <TAB>  with self . lock : <TAB><TAB>  if self . owner != tid : <TAB><TAB><TAB>  raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB><TAB>  assert self . count > 0 <TAB><TAB>  self . count - = 1 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . owner = None <TAB><TAB><TAB>  if self . waiters : <TAB><TAB><TAB><TAB>  self . waiters - = 1 <TAB><TAB><TAB><TAB>  self . wakeup . release ( ) ",if self . count == 0 :,if self.owner is not None:,False,30.47968140854232,96.58681762467396
4821,"def _cat_blob ( self , gcs_uri ) : <TAB>  """""":py:meth:`cat_file`, minus decompression."""""" <TAB>  blob = self . _get_blob ( gcs_uri ) <TAB>  if not blob : <TAB><TAB>  return<TAB># don't cat nonexistent files <TAB>  start = 0 <TAB>  while True : <TAB><TAB>  end = start + _CAT_CHUNK_SIZE <TAB><TAB>  try : <TAB><TAB><TAB>  chunk = blob . download_as_string ( start = start , end = end ) <TAB><TAB>  except google . api_core . exceptions . RequestRangeNotSatisfiable : <TAB><TAB><TAB>  return <TAB><TAB>  yield chunk <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  start = end ",if len ( chunk ) < _CAT_CHUNK_SIZE :,"if chunk.read(0, len(chunk) == _CAT_CHUNK_SIZE:",False,28.67593376174995,92.8978641774554
4822,"def device_iter ( * * kwargs ) : <TAB>  for dev in backend . enumerate_devices ( ) : <TAB><TAB>  d = Device ( dev , backend ) <TAB><TAB>  tests = ( val == _try_getattr ( d , key ) for key , val in kwargs . items ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  yield d ",if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,if tests:,False,16.881974975748324,76.29484788463712
4823,"def _get_vtkjs ( self ) : <TAB>  if self . _vtkjs is None and self . object is not None : <TAB><TAB>  if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB><TAB><TAB>  if isfile ( self . object ) : <TAB><TAB><TAB><TAB>  with open ( self . object , "" rb "" ) as f : <TAB><TAB><TAB><TAB><TAB>  vtkjs = f . read ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  data_url = urlopen ( self . object ) <TAB><TAB><TAB><TAB>  vtkjs = data_url . read ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  vtkjs = self . object . read ( ) <TAB><TAB>  self . _vtkjs = vtkjs <TAB>  return self . _vtkjs ","elif hasattr ( self . object , ""read"" ) :","if isinstance(vtkjs, str):",False,37.45888429218654,95.21669856698166
4824,"def _execute_with_error ( command , error , message ) : <TAB>  try : <TAB><TAB>  cli . invocation = cli . invocation_cls ( <TAB><TAB><TAB>  cli_ctx = cli , <TAB><TAB><TAB>  parser_cls = cli . parser_cls , <TAB><TAB><TAB>  commands_loader_cls = cli . commands_loader_cls , <TAB><TAB><TAB>  help_cls = cli . help_cls , <TAB><TAB>  ) <TAB><TAB>  cli . invocation . execute ( command . split ( ) ) <TAB>  except CLIError as ex : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise AssertionError ( <TAB><TAB><TAB><TAB>  "" {} \n Expected:  {} \n Actual:  {} "" . format ( message , error , ex ) <TAB><TAB><TAB>  ) <TAB><TAB>  return <TAB>  except Exception as ex : <TAB><TAB>  raise ex <TAB>  raise AssertionError ( "" exception not raised for  ' {0} ' "" . format ( message ) ) ",if error not in str ( ex ) :,if error:,False,29.987042761511184,95.20261811334576
4825,"def ray_intersection ( self , p , line ) : <TAB>  p = Vector ( center ( line . sites ) ) <TAB>  min_r = BIG_FLOAT <TAB>  nearest = None <TAB>  for v_i , v_j in self . edges : <TAB><TAB>  bound = LineEquation2D . from_two_points ( v_i , v_j ) <TAB><TAB>  intersection = bound . intersect_with_line ( line ) <TAB><TAB>  if intersection is not None : <TAB><TAB><TAB>  r = ( p - intersection ) . length <TAB><TAB><TAB>  # info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  nearest = intersection <TAB><TAB><TAB><TAB>  min_r = r <TAB>  return nearest ",if r < min_r :,if r < min_r:,False,62.134942014921194,100.00000000000004
4826,"def CalculateChecksum ( data ) : <TAB>  # The checksum is just a sum of all the bytes. I swear. <TAB>  if isinstance ( data , bytearray ) : <TAB><TAB>  total = sum ( data ) <TAB>  elif isinstance ( data , bytes ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Python 2 bytes (str) index as single-character strings. <TAB><TAB><TAB>  total = sum ( map ( ord , data ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  # Python 3 bytes index as numbers (and PY2 empty strings sum() to 0) <TAB><TAB><TAB>  total = sum ( data ) <TAB>  else : <TAB><TAB>  # Unicode strings (should never see?) <TAB><TAB>  total = sum ( map ( ord , data ) ) <TAB>  return total & 0xFFFFFFFF ","if data and isinstance ( data [ 0 ] , bytes ) :","if isinstance(data, str):",False,44.01601567752832,95.3424550953858
4827,"def __mul__ ( self , other : Union [ "" Tensor "" , float ] ) - > "" Tensor "" : <TAB>  if isinstance ( other , Tensor ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  errstr = ( <TAB><TAB><TAB><TAB>  f "" Given backens are inconsistent. Found  ' { self . backend . name } ' "" <TAB><TAB><TAB><TAB>  f "" and  ' { other . backend . name } ' "" <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  raise ValueError ( errstr ) <TAB><TAB>  other = other . array <TAB>  array = self . backend . multiply ( self . array , other ) <TAB>  return Tensor ( array , backend = self . backend ) ",if self . backend . name != other . backend . name :,if self.index != other.index:,False,28.44615984890573,95.20517367117557
4828,"def next_item ( self , direction ) : <TAB>  """"""Selects next menu item, based on self._direction"""""" <TAB>  start , i = - 1 , 0 <TAB>  try : <TAB><TAB>  start = self . items . index ( self . _selected ) <TAB><TAB>  i = start + direction <TAB>  except : <TAB><TAB>  pass <TAB>  while True : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Cannot find valid menu item <TAB><TAB><TAB>  self . select ( start ) <TAB><TAB><TAB>  break <TAB><TAB>  if i > = len ( self . items ) : <TAB><TAB><TAB>  i = 0 <TAB><TAB><TAB>  continue <TAB><TAB>  if i < 0 : <TAB><TAB><TAB>  i = len ( self . items ) - 1 <TAB><TAB><TAB>  continue <TAB><TAB>  if self . select ( i ) : <TAB><TAB><TAB>  break <TAB><TAB>  i + = direction <TAB><TAB>  if start < 0 : <TAB><TAB><TAB>  start = 0 ",if i == start :,if i == -1:,False,53.38566917430661,98.03059467960648
4829,"def resolve_none ( self , data ) : <TAB>  # replace None to '_' <TAB>  for tok_idx in range ( len ( data ) ) : <TAB><TAB>  for feat_idx in range ( len ( data [ tok_idx ] ) ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data [ tok_idx ] [ feat_idx ] = "" _ "" <TAB>  return data ",if data [ tok_idx ] [ feat_idx ] is None :,if data[tok_idx][feat_idx] == None:,False,27.776694130906794,96.95490931243769
4830,"def distinct ( expr , * on ) : <TAB>  fields = frozenset ( expr . fields ) <TAB>  _on = [ ] <TAB>  append = _on . append <TAB>  for n in on : <TAB><TAB>  if isinstance ( n , Field ) : <TAB><TAB><TAB>  if n . _child . isidentical ( expr ) : <TAB><TAB><TAB><TAB>  n = n . _name <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB>  if not isinstance ( n , _strtypes ) : <TAB><TAB><TAB>  raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB>  append ( n ) <TAB>  return Distinct ( expr , tuple ( _on ) ) ",elif n not in fields :,"if not isinstance(n, _Field):",False,31.130922013280387,96.21366324347862
4831,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . mutable_cost ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 24 : <TAB><TAB><TAB>  self . add_version ( d . getVarInt64 ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 0 : <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 10 :,if tt == 16:,False,50.97974076314251,98.86228284909593
4832,"def func_std_string ( func_name ) :<TAB># match what old profile produced <TAB>  if func_name [ : 2 ] == ( "" ~ "" , 0 ) : <TAB><TAB>  # special case for built-in functions <TAB><TAB>  name = func_name [ 2 ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" { %s } "" % name [ 1 : - 1 ] <TAB><TAB>  else : <TAB><TAB><TAB>  return name <TAB>  else : <TAB><TAB>  return "" %s : %d ( %s ) "" % func_name ","if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :",if name.endswith('.'):,False,15.046627522151345,89.11333418079623
4833,"def f ( ) : <TAB>  try : <TAB><TAB>  # Intra-buffer read then buffer-flushing read <TAB><TAB>  for n in cycle ( [ 1 , 19 ] ) : <TAB><TAB><TAB>  s = bufio . read ( n ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  # list.append() is atomic <TAB><TAB><TAB>  results . append ( s ) <TAB>  except Exception as e : <TAB><TAB>  errors . append ( e ) <TAB><TAB>  raise ",if not s :,if s == '\n':,False,55.89743911108901,94.96872983675031
4834,"def stop ( self ) : <TAB>  # Try to shut the connection down, but if we get any sort of <TAB>  # errors, go ahead and ignore them.. as we're shutting down anyway <TAB>  try : <TAB><TAB>  self . rpcserver . stop ( ) <TAB><TAB>  if self . backend_rpcserver : <TAB><TAB><TAB>  self . backend_rpcserver . stop ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . cluster_rpcserver . stop ( ) <TAB>  except Exception : <TAB><TAB>  pass <TAB>  if self . coordination : <TAB><TAB>  try : <TAB><TAB><TAB>  coordination . COORDINATOR . stop ( ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  pass <TAB>  super ( Service , self ) . stop ( graceful = True ) ",if self . cluster_rpcserver :,if self.cluster_rpcserver:,False,45.41329588701359,100.00000000000004
4835,"def download ( cls , architecture , path = "" ./ "" ) : <TAB>  if cls . sanity_check ( architecture ) : <TAB><TAB>  architecture_file = download_file ( <TAB><TAB><TAB>  cls . architecture_map [ architecture ] , directory = path <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return None <TAB><TAB>  print ( "" Coreml model  {}  is saved in [ {} ] "" . format ( architecture , path ) ) <TAB><TAB>  return architecture_file <TAB>  else : <TAB><TAB>  return None ",if not architecture_file :,if architecture_file is None:,False,30.50424497473957,96.51476732235263
4836,"def opps_output_converter ( kpt_list ) : <TAB>  kpts = [ ] <TAB>  mpii_keys = to_opps_converter . keys ( ) <TAB>  for mpii_idx in range ( 0 , 16 ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  model_idx = to_opps_converter [ mpii_idx ] <TAB><TAB><TAB>  x , y = kpt_list [ model_idx ] <TAB><TAB><TAB>  if x < 0 or y < 0 : <TAB><TAB><TAB><TAB>  kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  kpts + = [ x , y , 1.0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB>  return kpts ",if mpii_idx in mpii_keys :,if mpii_idx in mpii_keys:,False,53.345423437223126,96.72527081904161
4837,"def _get_headers ( self , headers = None ) : <TAB>  request_headers = headers or { } <TAB>  # Auth headers if access_token is present <TAB>  if self . _client . client . config : <TAB><TAB>  config = self . _client . client . config <TAB><TAB>  if "" Authorization "" not in request_headers and config . token : <TAB><TAB><TAB>  request_headers . update ( <TAB><TAB><TAB><TAB>  { <TAB><TAB><TAB><TAB><TAB>  "" Authorization "" : "" {} {} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB>  config . authentication_type , config . token <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  } <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  request_headers . update ( { config . header : config . header_service } ) <TAB>  return request_headers ",if config . header and config . header_service :,if config.header_service:,False,58.27750320891477,98.43753203866275
4838,"def get_last_traded_prices ( cls , trading_pairs : List [ str ] ) - > Dict [ str , float ] : <TAB>  results = dict ( ) <TAB>  async with aiohttp . ClientSession ( ) as client : <TAB><TAB>  resp = await client . get ( f "" { constants . REST_URL } /tickers "" ) <TAB><TAB>  resp_json = await resp . json ( ) <TAB><TAB>  for trading_pair in trading_pairs : <TAB><TAB><TAB>  resp_record = [ <TAB><TAB><TAB><TAB>  o <TAB><TAB><TAB><TAB>  for o in resp_json <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ] [ 0 ] <TAB><TAB><TAB>  results [ trading_pair ] = float ( resp_record [ "" price "" ] ) <TAB>  return results ","if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )",if o['trading_pair'] == trading_pair:,False,20.57390555945829,91.99628190347198
4839,"def reset_two_factor_hotp ( ) : <TAB>  uid = request . form [ "" uid "" ] <TAB>  otp_secret = request . form . get ( "" otp_secret "" , None ) <TAB>  if otp_secret : <TAB><TAB>  user = Journalist . query . get ( uid ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid ) <TAB><TAB>  db . session . commit ( ) <TAB><TAB>  return redirect ( url_for ( "" admin.new_user_two_factor "" , uid = uid ) ) <TAB>  else : <TAB><TAB>  return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid ) ","if not validate_hotp_secret ( user , otp_secret ) :",if user:,False,21.044836273795752,92.48415867117409
4840,"def ctx_for_video ( self , vurl ) : <TAB>  "" Get a context dict for a given video URL "" <TAB>  ctx = self . get_context_dict ( ) <TAB>  for portal , match , context_fn in self . PORTALS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  ctx . update ( context_fn ( vurl ) ) <TAB><TAB><TAB><TAB>  ctx [ "" portal "" ] = portal <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  continue <TAB>  return ctx ",if match . search ( vurl ) :,if match(vurl):,False,54.56544833437727,97.88178009411185
4841,"def get ( self ) : <TAB>  name = request . args . get ( "" filename "" ) <TAB>  if name is not None : <TAB><TAB>  opts = dict ( ) <TAB><TAB>  opts [ "" type "" ] = "" episode "" <TAB><TAB>  result = guessit ( name , options = opts ) <TAB><TAB>  res = dict ( ) <TAB><TAB>  if "" episode "" in result : <TAB><TAB><TAB>  res [ "" episode "" ] = result [ "" episode "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  res [ "" episode "" ] = 0 <TAB><TAB>  if "" season "" in result : <TAB><TAB><TAB>  res [ "" season "" ] = result [ "" season "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  res [ "" season "" ] = 0 <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB><TAB>  return jsonify ( data = res ) <TAB>  else : <TAB><TAB>  return "" "" , 400 ","if ""subtitle_language"" in result :",if result.has_key('subtitle_language'):,False,23.314538428904502,96.04518899905305
4842,"def package_files ( package_path , directory_name ) : <TAB>  paths = [ ] <TAB>  directory_path = os . path . join ( package_path , directory_name ) <TAB>  for ( path , directories , filenames ) in os . walk ( directory_path ) : <TAB><TAB>  relative_path = os . path . relpath ( path , package_path ) <TAB><TAB>  for filename in filenames : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  paths . append ( os . path . join ( relative_path , filename ) ) <TAB>  return paths ","if filename [ 0 ] == ""."" :",if filename.startswith('.py') or filename.startswith('.py') or,False,20.56105368468867,89.02753567311102
4843,"def parse_simple ( d , data ) : <TAB>  units = { } <TAB>  for v in data [ d ] : <TAB><TAB>  key = v [ "" name "" ] <TAB><TAB>  if not key : <TAB><TAB><TAB>  continue <TAB><TAB>  key_to_insert = make_key ( key ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  index = 2 <TAB><TAB><TAB>  tmp = f "" { key_to_insert } _ { index } "" <TAB><TAB><TAB>  while tmp in units : <TAB><TAB><TAB><TAB>  index + = 1 <TAB><TAB><TAB><TAB>  tmp = f "" { key_to_insert } _ { index } "" <TAB><TAB><TAB>  key_to_insert = tmp <TAB><TAB>  units [ key_to_insert ] = v [ "" id "" ] <TAB>  return units ",if key_to_insert in units :,if key_to_insert not in units:,False,20.492991057402378,98.91652394992484
4844,"def parse_clademodelc ( branch_type_no , line_floats , site_classes ) : <TAB>  """"""Parse results specific to the clade model C."""""" <TAB>  if not site_classes or len ( line_floats ) == 0 : <TAB><TAB>  return <TAB>  for n in range ( len ( line_floats ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  site_classes [ n ] [ "" branch types "" ] = { } <TAB><TAB>  site_classes [ n ] [ "" branch types "" ] [ branch_type_no ] = line_floats [ n ] <TAB>  return site_classes ","if site_classes [ n ] . get ( ""branch types"" ) is None :","if site_classes[n][""branch types""][branch_type_no] ==",False,49.31761578114344,91.72106129653996
4845,"def track_modules ( self , * modules ) : <TAB>  """"""Add module names to the tracked list."""""" <TAB>  already_tracked = self . session . GetParameter ( "" autodetect_build_local_tracked "" ) or [ ] <TAB>  needed = set ( modules ) <TAB>  if not needed . issubset ( already_tracked ) : <TAB><TAB>  needed . update ( already_tracked ) <TAB><TAB>  with self . session as session : <TAB><TAB><TAB>  session . SetParameter ( "" autodetect_build_local_tracked "" , needed ) <TAB><TAB><TAB>  for module_name in modules : <TAB><TAB><TAB><TAB>  module_obj = self . GetModuleByName ( module_name ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  # Clear the module's profile. This will force it to <TAB><TAB><TAB><TAB><TAB>  # reload a new profile. <TAB><TAB><TAB><TAB><TAB>  module_obj . profile = None ",if module_obj :,if module_obj:,False,61.19886607813135,100.00000000000004
4846,"def set_job_on_hold ( self , value , blocking = True ) : <TAB>  trigger = False <TAB>  # don't run any locking code beyond this... <TAB>  if not self . _job_on_hold . acquire ( blocking = blocking ) : <TAB><TAB>  return False <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _job_on_hold . set ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . _job_on_hold . clear ( ) <TAB><TAB><TAB>  if self . _job_on_hold . counter == 0 : <TAB><TAB><TAB><TAB>  trigger = True <TAB>  finally : <TAB><TAB>  self . _job_on_hold . release ( ) <TAB>  # locking code is now safe to run again <TAB>  if trigger : <TAB><TAB>  self . _continue_sending ( ) <TAB>  return True ",if value :,if value:,False,61.608911589607864,100.00000000000004
4847,"def moveToThreadNext ( self ) : <TAB>  """"""Move a position to threadNext position."""""" <TAB>  p = self <TAB>  if p . v : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  p . moveToFirstChild ( ) <TAB><TAB>  elif p . hasNext ( ) : <TAB><TAB><TAB>  p . moveToNext ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  p . moveToParent ( ) <TAB><TAB><TAB>  while p : <TAB><TAB><TAB><TAB>  if p . hasNext ( ) : <TAB><TAB><TAB><TAB><TAB>  p . moveToNext ( ) <TAB><TAB><TAB><TAB><TAB>  break<TAB># found <TAB><TAB><TAB><TAB>  p . moveToParent ( ) <TAB><TAB><TAB>  # not found. <TAB>  return p ",if p . v . children :,if p.hasNext():,False,52.019167984526625,95.85092964627822
4848,"def best_image ( width , height ) : <TAB>  # A heuristic for finding closest sized image to required size. <TAB>  image = images [ 0 ] <TAB>  for img in images : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Exact match always used <TAB><TAB><TAB>  return img <TAB><TAB>  elif img . width > = width and img . width * img . height > image . width * image . height : <TAB><TAB><TAB>  # At least wide enough, and largest area <TAB><TAB><TAB>  image = img <TAB>  return image ",if img . width == width and img . height == height :,if img.width == width and img.height == height:,False,40.66700548353493,100.00000000000004
4849,"def _check_input_types ( self ) : <TAB>  if len ( self . base_features ) == 0 : <TAB><TAB>  return True <TAB>  input_types = self . primitive . input_types <TAB>  if input_types is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  input_types = [ input_types ] <TAB><TAB>  for t in input_types : <TAB><TAB><TAB>  zipped = list ( zip ( t , self . base_features ) ) <TAB><TAB><TAB>  if all ( [ issubclass ( f . variable_type , v ) for v , f in zipped ] ) : <TAB><TAB><TAB><TAB>  return True <TAB>  else : <TAB><TAB>  return True <TAB>  return False ",if type ( input_types [ 0 ] ) != list :,"if isinstance(input_types, basestring):",False,46.20932339076149,94.53512963486205
4850,"def get_result ( self ) : <TAB>  result_list = [ ] <TAB>  exc_info = None <TAB>  for f in self . children : <TAB><TAB>  try : <TAB><TAB><TAB>  result_list . append ( f . get_result ( ) ) <TAB><TAB>  except Exception as e : <TAB><TAB><TAB>  if exc_info is None : <TAB><TAB><TAB><TAB>  exc_info = sys . exc_info ( ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB>  if exc_info is not None : <TAB><TAB>  raise_exc_info ( exc_info ) <TAB>  if self . keys is not None : <TAB><TAB>  return dict ( zip ( self . keys , result_list ) ) <TAB>  else : <TAB><TAB>  return list ( result_list ) ","if not isinstance ( e , self . quiet_exceptions ) :",if e.args[0] != 1:,False,41.93787294330637,95.40669901231017
4851,"def _update_learning_params ( self ) : <TAB>  model = self . model <TAB>  hparams = self . hparams <TAB>  fd = self . runner . feed_dict <TAB>  step_num = self . step_num <TAB>  if hparams . model_type == "" resnet_tf "" : <TAB><TAB>  if step_num < hparams . lrn_step : <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn / 10 <TAB><TAB>  elif step_num < 35000 : <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn / 100 <TAB><TAB>  else : <TAB><TAB><TAB>  lrn_rate = hparams . mom_lrn / 1000 <TAB><TAB>  fd [ model . lrn_rate ] = lrn_rate ",elif step_num < 30000 :,if step_num < 10000:,False,36.48105762448115,97.64678040238913
4852,"def topic_exists ( self , arn ) : <TAB>  response = self . _conn . get_all_topics ( ) <TAB>  topics = response [ "" ListTopicsResponse "" ] [ "" ListTopicsResult "" ] [ "" Topics "" ] <TAB>  current_topics = [ ] <TAB>  if len ( topics ) > 0 : <TAB><TAB>  for topic in topics : <TAB><TAB><TAB>  topic_arn = topic [ "" TopicArn "" ] <TAB><TAB><TAB>  current_topics . append ( topic_arn ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  return False ",if arn in current_topics :,if current_topics == current_topics:,False,25.900046022169803,95.58394390570236
4853,"def assertStartsWith ( self , expectedPrefix , text , msg = None ) : <TAB>  if not text . startswith ( expectedPrefix ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  text = text [ : len ( expectedPrefix ) + 5 ] + "" ... "" <TAB><TAB>  standardMsg = "" {}  not found at the start of  {} "" . format ( <TAB><TAB><TAB>  repr ( expectedPrefix ) , repr ( text ) <TAB><TAB>  ) <TAB><TAB>  self . fail ( self . _formatMessage ( msg , standardMsg ) ) ",if len ( expectedPrefix ) + 5 < len ( text ) :,if len(text) + 5 < len(text):,False,57.01074940951172,98.18487054407757
4854,"def validate_memory ( self , value ) : <TAB>  for k , v in value . viewitems ( ) : <TAB><TAB>  <IF-STMT>:<TAB># use NoneType to unset a value <TAB><TAB><TAB>  continue <TAB><TAB>  if not re . match ( PROCTYPE_MATCH , k ) : <TAB><TAB><TAB>  raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB><TAB>  if not re . match ( MEMLIMIT_MATCH , str ( v ) ) : <TAB><TAB><TAB>  raise serializers . ValidationError ( <TAB><TAB><TAB><TAB>  "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB><TAB><TAB>  ) <TAB>  return value ",if v is None :,if v is None:,False,36.192773677786164,97.52838020662412
4855,"def open ( self ) - > "" KeyValueJsonDb "" : <TAB>  """"""Create a new data base or open existing one"""""" <TAB>  if os . path . exists ( self . _name ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB><TAB>  try : <TAB><TAB><TAB>  with open ( self . _name , "" r "" ) as _in : <TAB><TAB><TAB><TAB>  self . set_records ( json . load ( _in ) ) <TAB><TAB>  except json . JSONDecodeError : <TAB><TAB><TAB>  # file corrupted, reset it. <TAB><TAB><TAB>  self . commit ( ) <TAB>  else : <TAB><TAB>  # make sure path exists <TAB><TAB>  mkpath ( os . path . dirname ( self . _name ) ) <TAB><TAB>  self . commit ( ) <TAB>  return self ",if not os . path . isfile ( self . _name ) :,if not os.path.exists(self._name):,False,57.207666254561964,98.97008886139643
4856,"def _calculate ( self ) : <TAB>  before = self . before . data <TAB>  after = self . after . data <TAB>  self . deleted = { } <TAB>  self . updated = { } <TAB>  self . created = after . copy ( ) <TAB>  for path , f in before . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . deleted [ path ] = f <TAB><TAB><TAB>  continue <TAB><TAB>  del self . created [ path ] <TAB><TAB>  if f . mtime < after [ path ] . mtime : <TAB><TAB><TAB>  self . updated [ path ] = after [ path ] ",if path not in after :,if path not in self.created:,False,37.73429168302642,97.20609073682621
4857,"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB>  function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB>  # First, get list of accounts <TAB>  accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB>  # Second, call tasks to enumerate all the roles across all accounts <TAB>  for account_id in accounts_d . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cache_sqs_queues_for_account . delay ( account_id ) <TAB><TAB>  else : <TAB><TAB><TAB>  if account_id in config . get ( "" celery.test_account_ids "" , [ ] ) : <TAB><TAB><TAB><TAB>  cache_sqs_queues_for_account . delay ( account_id ) <TAB>  stats . count ( f "" { function } .success "" ) <TAB>  return True ","if config . get ( ""environment"" ) == ""prod"" :","if account_id in config.get(""celery.test_account_ids"", []",False,47.28065115352511,93.17623311668355
4858,"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB>  if not path : <TAB><TAB>  if error_on_path : <TAB><TAB><TAB>  raise NoSuchSettingsPath ( ) <TAB><TAB>  return <TAB>  if config is not None or defaults is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  config = self . _config <TAB><TAB>  if defaults is None : <TAB><TAB><TAB>  defaults = dict ( self . _map . parents ) <TAB><TAB>  chain = HierarchicalChainMap ( config , defaults ) <TAB>  else : <TAB><TAB>  chain = self . _map <TAB>  try : <TAB><TAB>  chain . del_by_path ( path ) <TAB><TAB>  self . _mark_dirty ( ) <TAB>  except KeyError : <TAB><TAB>  if error_on_path : <TAB><TAB><TAB>  raise NoSuchSettingsPath ( ) <TAB><TAB>  pass ",if config is None :,if config is None:,False,58.252497956515704,100.00000000000004
4859,"def PopulateProjectId ( project_id = None ) : <TAB>  """"""Fills in a project_id from the boto config file if one is not provided."""""" <TAB>  if not project_id : <TAB><TAB>  default_id = boto . config . get_value ( "" GSUtil "" , "" default_project_id "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProjectIdException ( "" MissingProjectId "" ) <TAB><TAB>  return default_id <TAB>  return project_id ",if not default_id :,if default_id is None:,False,38.10330766941951,95.77896144061073
4860,"def set ( self , name , value ) : <TAB>  with self . _object_cache_lock : <TAB><TAB>  old_value = self . _object_cache . get ( name ) <TAB><TAB>  ret = not old_value or int ( old_value . metadata . resource_version ) < int ( <TAB><TAB><TAB>  value . metadata . resource_version <TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _object_cache [ name ] = value <TAB>  return ret , old_value ",if ret :,if ret is not None:,False,28.276403083297414,96.64331377240634
4861,"def remove ( self , url ) : <TAB>  try : <TAB><TAB>  i = self . items . index ( url ) <TAB>  except ( ValueError , IndexError ) : <TAB><TAB>  pass <TAB>  else : <TAB><TAB>  was_selected = i in self . selectedindices ( ) <TAB><TAB>  self . list . delete ( i ) <TAB><TAB>  del self . items [ i ] <TAB><TAB>  if not self . items : <TAB><TAB><TAB>  self . mp . hidepanel ( self . name ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if i > = len ( self . items ) : <TAB><TAB><TAB><TAB>  i = len ( self . items ) - 1 <TAB><TAB><TAB>  self . list . select_set ( i ) ",elif was_selected :,if was_selected:,False,30.42821042293447,98.7227748200473
4862,"def add_directory_csv_files ( dir_path , paths = None ) : <TAB>  if not paths : <TAB><TAB>  paths = [ ] <TAB>  for p in listdir ( dir_path ) : <TAB><TAB>  path = join ( dir_path , p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # call recursively for each dir <TAB><TAB><TAB>  paths = add_directory_csv_files ( path , paths ) <TAB><TAB>  elif isfile ( path ) and path . endswith ( "" .csv "" ) : <TAB><TAB><TAB>  # add every file to the list <TAB><TAB><TAB>  paths . append ( path ) <TAB>  return paths ",if isdir ( path ) :,if isdir(path):,False,57.87423189348046,100.00000000000004
4863,"def _get_client ( rp_mapping , resource_provider ) : <TAB>  for key , value in rp_mapping . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if isinstance ( value , dict ) : <TAB><TAB><TAB><TAB>  return GeneralPrivateEndpointClient ( <TAB><TAB><TAB><TAB><TAB>  key , <TAB><TAB><TAB><TAB><TAB>  value [ "" api_version "" ] , <TAB><TAB><TAB><TAB><TAB>  value [ "" support_list_or_not "" ] , <TAB><TAB><TAB><TAB><TAB>  value [ "" resource_get_api_version "" ] , <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB>  return value ( ) <TAB>  raise CLIError ( <TAB><TAB>  "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB>  ) ",if str . lower ( key ) == str . lower ( resource_provider ) :,if key in resource_provider.resources:,False,53.365602467859844,93.80731532234483
4864,"def compute_rule_hash ( self , rule ) : <TAB>  buf = "" %d - %d - %s - "" % ( <TAB><TAB>  rule . get ( "" FromPort "" , 0 ) or 0 , <TAB><TAB>  rule . get ( "" ToPort "" , 0 ) or 0 , <TAB><TAB>  rule . get ( "" IpProtocol "" , "" -1 "" ) or "" -1 "" , <TAB>  ) <TAB>  for a , ke in self . RULE_ATTRS : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  ev = [ e [ ke ] for e in rule [ a ] ] <TAB><TAB>  ev . sort ( ) <TAB><TAB>  for e in ev : <TAB><TAB><TAB>  buf + = "" %s - "" % e <TAB>  # mask to generate the same numeric value across all Python versions <TAB>  return zlib . crc32 ( buf . encode ( "" ascii "" ) ) & 0xFFFFFFFF ",if a not in rule :,if not rule[a] and ke == a:,False,43.90014640032689,89.91709016046744
4865,"def analysis_sucess_metrics ( analysis_time : float , allow_exception = False ) : <TAB>  try : <TAB><TAB>  anchore_engine . subsys . metrics . counter_inc ( name = "" anchore_analysis_success "" ) <TAB><TAB>  anchore_engine . subsys . metrics . histogram_observe ( <TAB><TAB><TAB>  "" anchore_analysis_time_seconds "" , <TAB><TAB><TAB>  analysis_time , <TAB><TAB><TAB>  buckets = ANALYSIS_TIME_SECONDS_BUCKETS , <TAB><TAB><TAB>  status = "" success "" , <TAB><TAB>  ) <TAB>  except : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB><TAB>  else : <TAB><TAB><TAB>  logger . exception ( <TAB><TAB><TAB><TAB>  "" Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing "" <TAB><TAB><TAB>  ) ",if allow_exception :,if allow_exception:,False,68.8014201121201,100.00000000000004
4866,"def decide_file_icon ( file ) : <TAB>  if file . state == File . ERROR : <TAB><TAB>  return FileItem . icon_error <TAB>  elif isinstance ( file . parent , Track ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return FileItem . icon_saved <TAB><TAB>  elif file . state == File . PENDING : <TAB><TAB><TAB>  return FileItem . match_pending_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB><TAB>  else : <TAB><TAB><TAB>  return FileItem . match_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB>  elif file . state == File . PENDING : <TAB><TAB>  return FileItem . icon_file_pending <TAB>  else : <TAB><TAB>  return FileItem . icon_file ",if file . state == File . NORMAL :,if file.state == File.Saved:,False,27.12276007532593,98.75459029433388
4867,"def deleteMenu ( self , menuName ) : <TAB>  try : <TAB><TAB>  menu = self . getMenu ( menuName ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . destroy ( menu ) <TAB><TAB><TAB>  self . destroyMenu ( menuName ) <TAB><TAB>  else : <TAB><TAB><TAB>  g . es ( "" can ' t delete menu: "" , menuName ) <TAB>  except Exception : <TAB><TAB>  g . es ( "" exception deleting "" , menuName , "" menu "" ) <TAB><TAB>  g . es_exception ( ) ",if menu :,if menu:,False,50.664428027916195,96.69266300094904
4868,"def parser ( cls , buf ) : <TAB>  ( type_ , code , csum ) = struct . unpack_from ( cls . _PACK_STR , buf ) <TAB>  msg = cls ( type_ , code , csum ) <TAB>  offset = cls . _MIN_LEN <TAB>  if len ( buf ) > offset : <TAB><TAB>  cls_ = cls . _ICMPV6_TYPES . get ( type_ , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  msg . data = cls_ . parser ( buf , offset ) <TAB><TAB>  else : <TAB><TAB><TAB>  msg . data = buf [ offset : ] <TAB>  return msg , None , None ",if cls_ :,if cls_:,False,50.385744058631765,100.00000000000004
4869,"def _load_dataset_area ( self , dsid , file_handlers , coords ) : <TAB>  """"""Get the area for *dsid*."""""" <TAB>  try : <TAB><TAB>  return self . _load_area_def ( dsid , file_handlers ) <TAB>  except NotImplementedError : <TAB><TAB>  if any ( x is None for x in coords ) : <TAB><TAB><TAB>  logger . warning ( "" Failed to load coordinates for  ' {} ' "" . format ( dsid ) ) <TAB><TAB><TAB>  return None <TAB><TAB>  area = self . _make_area_from_coords ( coords ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( "" No coordinates found for  %s "" , str ( dsid ) ) <TAB><TAB>  return area ",if area is None :,if area is None:,False,58.641636434605985,100.00000000000004
4870,"def __getattr__ ( self , name ) : <TAB>  if Popen . verbose : <TAB><TAB>  sys . stdout . write ( "" Getattr:  %s ... "" % name ) <TAB>  if name in Popen . __slots__ : <TAB><TAB>  return object . __getattribute__ ( self , name ) <TAB>  else : <TAB><TAB>  if self . popen is not None : <TAB><TAB><TAB>  if Popen . verbose : <TAB><TAB><TAB><TAB>  print ( "" from Popen "" ) <TAB><TAB><TAB>  return getattr ( self . popen , name ) <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return self . emu_wait <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  raise Exception ( "" subprocess emulation: not implemented:  %s "" % name ) ","if name == ""wait"" :",if self.emu_wait is not None:,False,25.33816008185539,95.96403464726717
4871,"def update ( self , time_delta ) : <TAB>  super ( ) . update ( time_delta ) <TAB>  n = self . menu . selected_option <TAB>  if n == self . last : <TAB><TAB>  return <TAB>  self . last = n <TAB>  s = "" "" <TAB>  for i in range ( len ( self . files ) ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  for l in open ( self . files [ i ] [ 1 ] ) : <TAB><TAB><TAB><TAB>  x = l . strip ( ) <TAB><TAB><TAB><TAB>  if len ( x ) > 1 and x [ 0 ] == "" # "" : <TAB><TAB><TAB><TAB><TAB>  x = "" <b><u> "" + x [ 1 : ] + ""  </u></b> "" <TAB><TAB><TAB><TAB>  s + = x + "" <br> "" <TAB>  self . set_text ( s ) ",if self . files [ i ] [ 0 ] == n :,if self.files[i][0] == n:,False,50.572721439417734,100.00000000000004
4872,"def wrapper ( * args , * * kwargs ) : <TAB>  list_args , empty = _apply_defaults ( func , args , kwargs ) <TAB>  if len ( dimensions ) > len ( list_args ) : <TAB><TAB>  raise TypeError ( <TAB><TAB><TAB>  "" %s  takes  %i  parameters, but  %i  dimensions were passed "" <TAB><TAB><TAB>  % ( func . __name__ , len ( list_args ) , len ( dimensions ) ) <TAB><TAB>  ) <TAB>  for dim , value in zip ( dimensions , list_args ) : <TAB><TAB>  if dim is None : <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val_dim = ureg . get_dimensionality ( value ) <TAB><TAB><TAB>  raise DimensionalityError ( value , "" a quantity of "" , val_dim , dim ) <TAB>  return func ( * args , * * kwargs ) ",if not ureg . Quantity ( value ) . check ( dim ) :,if dim == 0:,False,51.02638837781861,94.30882815464571
4873,"def _check ( self , name , size = None , * extra ) : <TAB>  func = getattr ( imageop , name ) <TAB>  for height in VALUES : <TAB><TAB>  for width in VALUES : <TAB><TAB><TAB>  strlen = abs ( width * height ) <TAB><TAB><TAB>  if size : <TAB><TAB><TAB><TAB>  strlen * = size <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  data = "" A "" * strlen <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  data = AAAAA <TAB><TAB><TAB>  if size : <TAB><TAB><TAB><TAB>  arguments = ( data , size , width , height ) + extra <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  arguments = ( data , width , height ) + extra <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  func ( * arguments ) <TAB><TAB><TAB>  except ( ValueError , imageop . error ) : <TAB><TAB><TAB><TAB>  pass ",if strlen < MAX_LEN :,if strlen:,False,26.935440364373616,98.03426780084908
4874,"def wait_send_all_might_not_block ( self ) - > None : <TAB>  with self . _send_conflict_detector : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise trio . ClosedResourceError ( "" file was already closed "" ) <TAB><TAB>  try : <TAB><TAB><TAB>  await trio . lowlevel . wait_writable ( self . _fd_holder . fd ) <TAB><TAB>  except BrokenPipeError as e : <TAB><TAB><TAB>  # kqueue: raises EPIPE on wait_writable instead <TAB><TAB><TAB>  # of sending, which is annoying <TAB><TAB><TAB>  raise trio . BrokenResourceError from e ",if self . _fd_holder . closed :,if self._fd_holder.fd == self._fd_holder.fd:,False,43.75849627316792,92.78836480778948
4875,"def parse_win_proxy ( val ) : <TAB>  proxies = [ ] <TAB>  for p in val . split ( "" ; "" ) : <TAB><TAB>  if "" = "" in p : <TAB><TAB><TAB>  tab = p . split ( "" = "" , 1 ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tab [ 0 ] = "" SOCKS4 "" <TAB><TAB><TAB>  proxies . append ( <TAB><TAB><TAB><TAB>  ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB><TAB><TAB>  )<TAB># type, addr:port, username, password <TAB><TAB>  else : <TAB><TAB><TAB>  proxies . append ( ( "" HTTP "" , p , None , None ) ) <TAB>  return proxies ","if tab [ 0 ] == ""socks"" :",if len(tab) == 2:,False,31.264063491534323,94.19336881497122
4876,"def _super_function ( args ) : <TAB>  passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB>  if passed_self is None : <TAB><TAB>  return passed_class <TAB>  else : <TAB><TAB>  # pyclass = passed_self.get_type() <TAB><TAB>  pyclass = passed_class <TAB><TAB>  if isinstance ( pyclass , pyobjects . AbstractClass ) : <TAB><TAB><TAB>  supers = pyclass . get_superclasses ( ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return pyobjects . PyObject ( supers [ 0 ] ) <TAB><TAB>  return passed_self ",if supers :,if supers:,False,51.19871348967722,100.00000000000004
4877,"def update_output_mintime ( job ) : <TAB>  try : <TAB><TAB>  return output_mintime [ job ] <TAB>  except KeyError : <TAB><TAB>  for job_ in chain ( [ job ] , self . depending [ job ] ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  t = output_mintime [ job_ ] <TAB><TAB><TAB>  except KeyError : <TAB><TAB><TAB><TAB>  t = job_ . output_mintime <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  output_mintime [ job ] = t <TAB><TAB><TAB><TAB>  return <TAB><TAB>  output_mintime [ job ] = None ",if t is not None :,if t is not None:,False,52.50586322088413,100.00000000000004
4878,"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB>  result = [ ] <TAB>  if len ( notifications_list ) > 0 : <TAB><TAB>  for x in notifications_list : <TAB><TAB><TAB>  split_provider_id = x . split ( "" : "" )<TAB># email:id <TAB><TAB><TAB>  if len ( split_provider_id ) == 2 : <TAB><TAB><TAB><TAB>  _id = split_provider_id [ 1 ] <TAB><TAB><TAB><TAB>  cursor = self . get_by_id ( _id ) <TAB><TAB><TAB><TAB>  <IF-STMT>:<TAB># Append if exists <TAB><TAB><TAB><TAB><TAB>  result . append ( cursor ) <TAB>  return result ",if cursor :,if cursor:,False,36.88133014476422,95.56462401460304
4879,"def stop ( self ) : <TAB>  with self . lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return <TAB><TAB>  self . task_queue . put ( None ) <TAB><TAB>  self . result_queue . put ( None ) <TAB><TAB>  process = self . process <TAB><TAB>  self . process = None <TAB><TAB>  self . task_queue = None <TAB><TAB>  self . result_queue = None <TAB>  process . join ( timeout = 0.1 ) <TAB>  if process . exitcode is None : <TAB><TAB>  os . kill ( process . pid , signal . SIGKILL ) <TAB><TAB>  process . join ( ) ",if not self . process :,if self.process is None:,False,43.77928902759029,96.95988293960826
4880,"def on_api_command ( self , command , data ) : <TAB>  if command == "" select "" : <TAB><TAB>  if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB><TAB><TAB>  return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return flask . abort ( 409 , "" No active prompt "" ) <TAB><TAB>  choice = data [ "" choice "" ] <TAB><TAB>  if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) : <TAB><TAB><TAB>  return flask . abort ( <TAB><TAB><TAB><TAB>  400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB><TAB><TAB>  ) <TAB><TAB>  self . _answer_prompt ( choice ) ",if self . _prompt is None :,if not data:,False,35.181341231321404,96.54345810679052
4881,"def application_openFiles_ ( self , nsapp , filenames ) : <TAB>  # logging.info('[osx] file open') <TAB>  # logging.info('[osx] file : %s' % (filenames)) <TAB>  for filename in filenames : <TAB><TAB>  logging . info ( "" [osx] receiving from macOS :  %s "" , filename ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES : <TAB><TAB><TAB><TAB>  sabnzbd . add_nzbfile ( filename , keep = True ) ",if os . path . exists ( filename ) :,if filename.startswith('.mac'):,False,34.95605329289507,94.98708039317214
4882,"def test_error_through_destructor ( self ) : <TAB>  # Test that the exception state is not modified by a destructor, <TAB>  # even if close() fails. <TAB>  rawio = self . CloseFailureIO ( ) <TAB>  with support . catch_unraisable_exception ( ) as cm : <TAB><TAB>  with self . assertRaises ( AttributeError ) : <TAB><TAB><TAB>  self . tp ( rawio ) . xyzzy <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertIsNone ( cm . unraisable ) <TAB><TAB>  elif cm . unraisable is not None : <TAB><TAB><TAB>  self . assertEqual ( cm . unraisable . exc_type , OSError ) ",if not IOBASE_EMITS_UNRAISABLE :,if sys.platform == 'win32':,False,37.82601589039684,95.37694615203544
4883,"def http_wrapper ( self , url , postdata = { } ) : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  f = urllib . urlopen ( url , postdata ) <TAB><TAB>  else : <TAB><TAB><TAB>  f = urllib . urlopen ( url ) <TAB><TAB>  response = f . read ( ) <TAB>  except : <TAB><TAB>  import traceback <TAB><TAB>  import logging , sys <TAB><TAB>  cla , exc , tb = sys . exc_info ( ) <TAB><TAB>  logging . error ( url ) <TAB><TAB>  if postdata : <TAB><TAB><TAB>  logging . error ( "" with post data "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  logging . error ( "" without post data "" ) <TAB><TAB>  logging . error ( exc . args ) <TAB><TAB>  logging . error ( traceback . format_tb ( tb ) ) <TAB><TAB>  response = "" "" <TAB>  return response ",if postdata != { } :,"if isinstance(url, str):",False,48.65774046277289,96.95415721116967
4884,"def check_single_file ( fn , fetchuri ) : <TAB>  """"""Determine if a single downloaded file is something we can't handle"""""" <TAB>  with open ( fn , "" r "" , errors = "" surrogateescape "" ) as f : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . error ( <TAB><TAB><TAB><TAB>  ' Fetching  "" %s ""  returned a single HTML page - check the URL is correct and functional ' <TAB><TAB><TAB><TAB>  % fetchuri <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  sys . exit ( 1 ) ","if ""<html"" in f . read ( 100 ) . lower ( ) :",if f.read(fetchuri) != f.read(fetchuri):,False,40.68849645414222,88.31496085302763
4885,"def update_properties ( self , update_dict ) : <TAB>  signed_attribute_changed = False <TAB>  for k , value in update_dict . items ( ) : <TAB><TAB>  if getattr ( self , k ) != value : <TAB><TAB><TAB>  setattr ( self , k , value ) <TAB><TAB><TAB>  signed_attribute_changed = signed_attribute_changed or ( <TAB><TAB><TAB><TAB>  k in self . payload_arguments <TAB><TAB><TAB>  ) <TAB>  if signed_attribute_changed : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . status = UPDATED <TAB><TAB>  self . timestamp = clock . tick ( ) <TAB><TAB>  self . sign ( ) <TAB>  return self ",if self . status != NEW :,if self.status == UPDATED:,False,50.65615364025452,97.76130857278173
4886,"def clean_items ( event , items , variations ) : <TAB>  for item in items : <TAB><TAB>  if event != item . event : <TAB><TAB><TAB>  raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB><TAB>  if item . has_variations : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  raise ValidationError ( <TAB><TAB><TAB><TAB><TAB>  _ ( <TAB><TAB><TAB><TAB><TAB><TAB>  "" One or more items has variations but none of these are in the variations list. "" <TAB><TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  ) ",if not any ( var . item == item for var in variations ) :,if not len(variations) > 1:,False,43.56065848768436,93.0804796198122
4887,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . add_status ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  if tt == 18 : <TAB><TAB><TAB>  self . add_doc_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 11:,False,49.590851874253616,98.87254519239598
4888,"def connections ( self ) : <TAB>  # Connections look something like this: <TAB>  # socket:[102422] <TAB>  fds = self . open_files <TAB>  socket = "" socket:[ "" <TAB>  result = [ ] <TAB>  functions = [ pwndbg . net . tcp , pwndbg . net . unix , pwndbg . net . netlink ] <TAB>  for fd , path in fds . items ( ) : <TAB><TAB>  if socket not in path : <TAB><TAB><TAB>  continue <TAB><TAB>  inode = path [ len ( socket ) : - 1 ] <TAB><TAB>  inode = int ( inode ) <TAB><TAB>  for func in functions : <TAB><TAB><TAB>  for x in func ( ) : <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  x . fd = fd <TAB><TAB><TAB><TAB><TAB>  result . append ( x ) <TAB>  return tuple ( result ) ",if x . inode == inode :,if x.inode == inode:,False,29.118558724049375,98.51664835586153
4889,"def _movement_finished ( self ) : <TAB>  if self . in_ship_map : <TAB><TAB>  # if the movement somehow stops, the position sticks, and the unit isn't at next_target any more <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ship = self . session . world . ship_map . get ( self . _next_target . to_tuple ( ) ) <TAB><TAB><TAB>  if ship is not None and ship ( ) is self : <TAB><TAB><TAB><TAB>  del self . session . world . ship_map [ self . _next_target . to_tuple ( ) ] <TAB>  super ( ) . _movement_finished ( ) ",if self . _next_target is not None :,if self._next_target is not None:,False,69.96479930185221,100.00000000000004
4890,"def print_addresses ( self ) : <TAB>  p = 3 <TAB>  tmp_str = "" [ "" <TAB>  if self . get_len ( ) > = 7 :<TAB># at least one complete IP address <TAB><TAB>  while 1 : <TAB><TAB><TAB>  if p + 1 == self . get_ptr ( ) : <TAB><TAB><TAB><TAB>  tmp_str + = "" # "" <TAB><TAB><TAB>  tmp_str + = self . get_ip_address ( p ) <TAB><TAB><TAB>  p + = 4 <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  tmp_str + = "" ,  "" <TAB>  tmp_str + = "" ]  "" <TAB>  if self . get_ptr ( ) % 4 :<TAB># ptr field should be a multiple of 4 <TAB><TAB>  tmp_str + = "" nonsense ptr field:  %d "" % self . get_ptr ( ) <TAB>  return tmp_str ",if p >= self . get_len ( ) :,if p == 7:,False,53.268920505168694,95.10305086427834
4891,"def source_shapes ( self ) : <TAB>  """"""Prints debug information about the sources in this provider."""""" <TAB>  if logger . isEnabledFor ( logging . DEBUG ) : <TAB><TAB>  for i , source in enumerate ( self . sources ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  name = "" anonymous "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  name = self . keys [ i ] <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  shape = source . shape ( ) <TAB><TAB><TAB>  except NotImplementedError : <TAB><TAB><TAB><TAB>  shape = "" N/A "" <TAB><TAB><TAB>  logger . debug ( <TAB><TAB><TAB><TAB>  ' Data source  "" %s "" : entries= %s , shape= %s ' , name , len ( source ) , shape <TAB><TAB><TAB>  ) ",if self . keys is None :,if i == 0:,False,55.559985948891,94.8284356400914
4892,def swap_actions ( actions ) : <TAB>  for mutexgroup in mutex_groups : <TAB><TAB>  mutex_actions = mutexgroup . _group_actions <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # make a best guess as to where we should store the group <TAB><TAB><TAB>  targetindex = actions . index ( mutexgroup . _group_actions [ 0 ] ) <TAB><TAB><TAB>  # insert the _ArgumentGroup container <TAB><TAB><TAB>  actions [ targetindex ] = mutexgroup <TAB><TAB><TAB>  # remove the duplicated individual actions <TAB><TAB><TAB>  actions = [ action for action in actions if action not in mutex_actions ] <TAB>  return actions ,"if contains_actions ( mutex_actions , actions ) :",if actions:,False,57.33733748216277,93.37865503955187
4893,"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB>  deps = cnt [ "" _deps "" ] <TAB>  for dep in deps . copy ( ) : <TAB><TAB>  dep_cnts = services . get ( dep ) <TAB><TAB>  if not dep_cnts : <TAB><TAB><TAB>  continue <TAB><TAB>  dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB><TAB>  if dep_cnt : <TAB><TAB><TAB>  # TODO: avoid creating loops, A->B->A <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB><TAB><TAB>  deps . update ( new_deps ) <TAB>  return deps ","if init_service and init_service in dep_cnt [ ""_deps"" ] :",if dep_cnt == 0:,False,53.54452555448107,92.63055763106826
4894,"def make_dump_list_by_name_list ( name_list ) : <TAB>  info_list = [ ] <TAB>  for info_name in name_list : <TAB><TAB>  info = next ( ( x for x in DUMP_LIST if x . info_name == info_name ) , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RuntimeError ( ' Unknown info name:  "" {} "" ' . format ( info_name ) ) <TAB><TAB>  info_list . append ( info ) <TAB>  return info_list ",if not info :,if info is None:,False,27.483228270710004,94.11300644069439
4895,"def create ( self , private = False ) : <TAB>  try : <TAB><TAB>  if private : <TAB><TAB><TAB>  log . info ( "" Creating private channel  %s . "" , self ) <TAB><TAB><TAB>  self . _bot . api_call ( <TAB><TAB><TAB><TAB>  "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  log . info ( "" Creating channel  %s . "" , self ) <TAB><TAB><TAB>  self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB>  except SlackAPIResponseError as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  raise RoomError ( e ) ","if e . error == ""user_is_bot"" :",if e.code == SlackAPIResponseError.ERROR:,False,48.63936991293809,95.83226617504091
4896,"def talk ( self , words ) : <TAB>  if self . writeSentence ( words ) == 0 : <TAB><TAB>  return <TAB>  r = [ ] <TAB>  while 1 : <TAB><TAB>  i = self . readSentence ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  reply = i [ 0 ] <TAB><TAB>  attrs = { } <TAB><TAB>  for w in i [ 1 : ] : <TAB><TAB><TAB>  j = w . find ( "" = "" , 1 ) <TAB><TAB><TAB>  if j == - 1 : <TAB><TAB><TAB><TAB>  attrs [ w ] = "" "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB><TAB>  r . append ( ( reply , attrs ) ) <TAB><TAB>  if reply == "" !done "" : <TAB><TAB><TAB>  return r ",if len ( i ) == 0 :,if i == []:,False,23.462715603969748,96.00971251609634
4897,"def _load_logfile ( self , lfn ) : <TAB>  enc_key = self . decryption_key_func ( ) <TAB>  with open ( os . path . join ( self . logdir , lfn ) ) as fd : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  with DecryptingStreamer ( <TAB><TAB><TAB><TAB>  fd , mep_key = enc_key , name = "" EventLog/DS( %s ) "" % lfn <TAB><TAB><TAB>  ) as streamer : <TAB><TAB><TAB><TAB>  lines = streamer . read ( ) <TAB><TAB><TAB><TAB>  streamer . verify ( _raise = IOError ) <TAB><TAB>  else : <TAB><TAB><TAB>  lines = fd . read ( ) <TAB><TAB>  if lines : <TAB><TAB><TAB>  for line in lines . splitlines ( ) : <TAB><TAB><TAB><TAB>  event = Event . Parse ( line . strip ( ) ) <TAB><TAB><TAB><TAB>  self . _events [ event . event_id ] = event ",if enc_key :,if os.path.exists(fd):,False,49.54569310312157,96.39181912805248
4898,"def set_ok_port ( self , cookie , request ) : <TAB>  if cookie . port_specified : <TAB><TAB>  req_port = request_port ( request ) <TAB><TAB>  if req_port is None : <TAB><TAB><TAB>  req_port = "" 80 "" <TAB><TAB>  else : <TAB><TAB><TAB>  req_port = str ( req_port ) <TAB><TAB>  for p in cookie . port . split ( "" , "" ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  int ( p ) <TAB><TAB><TAB>  except ValueError : <TAB><TAB><TAB><TAB>  debug ( ""<TAB>bad port  %s  (not numeric) "" , p ) <TAB><TAB><TAB><TAB>  return False <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  else : <TAB><TAB><TAB>  debug ( ""<TAB>request port ( %s ) not found in  %s "" , req_port , cookie . port ) <TAB><TAB><TAB>  return False <TAB>  return True ",if p == req_port :,if int(p) == 0:,False,24.023198952449686,94.26145317348157
4899,"def get_attribute_value ( self , nodeid , attr ) : <TAB>  with self . _lock : <TAB><TAB>  self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dv = ua . DataValue ( ) <TAB><TAB><TAB>  dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB><TAB><TAB>  return dv <TAB><TAB>  node = self . _nodes [ nodeid ] <TAB><TAB>  if attr not in node . attributes : <TAB><TAB><TAB>  dv = ua . DataValue ( ) <TAB><TAB><TAB>  dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB><TAB><TAB>  return dv <TAB><TAB>  attval = node . attributes [ attr ] <TAB><TAB>  if attval . value_callback : <TAB><TAB><TAB>  return attval . value_callback ( ) <TAB><TAB>  return attval . value ",if nodeid not in self . _nodes :,if nodeid not in self._nodes:,False,52.26622032723919,100.00000000000004
4900,"def data_logging_status ( self , trail_name , trail_details , api_client ) : <TAB>  for es in api_client . get_event_selectors ( TrailName = trail_name ) [ "" EventSelectors "" ] : <TAB><TAB>  has_wildcard = { <TAB><TAB><TAB>  u "" Values "" : [ u "" arn:aws:s3::: "" ] , <TAB><TAB><TAB>  u "" Type "" : u "" AWS::S3::Object "" , <TAB><TAB>  } in es [ "" DataResources "" ] <TAB><TAB>  is_logging = trail_details [ "" IsLogging "" ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  return False ",if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,"if is_logging and has_wildcard(has_wildcard, has_wildcard):",False,32.781170558556525,92.58443458398119
4901,"def pytest_deselected ( items ) : <TAB>  if sb_config . dashboard : <TAB><TAB>  sb_config . item_count - = len ( items ) <TAB><TAB>  for item in items : <TAB><TAB><TAB>  test_id , display_id = _get_test_ids_ ( item ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  sb_config . _results . pop ( test_id ) ",if test_id in sb_config . _results . keys ( ) :,if display_id:,False,17.706977660165617,87.74540227707259
4902,"def _visit ( self , func ) : <TAB>  fname = func [ 0 ] <TAB>  if fname in self . _flags : <TAB><TAB>  if self . _flags [ fname ] == 1 : <TAB><TAB><TAB>  logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB><TAB><TAB>  import sys <TAB><TAB><TAB>  sys . exit ( - 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  return <TAB>  else : <TAB><TAB>  if fname not in self . _flags : <TAB><TAB><TAB>  self . _flags [ fname ] = 1 <TAB><TAB>  for output in func [ 3 ] : <TAB><TAB><TAB>  for f in self . _orig : <TAB><TAB><TAB><TAB>  for input in f [ 2 ] : <TAB><TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB><TAB>  self . _visit ( f ) <TAB>  self . _flags [ fname ] = 2 <TAB>  self . _sorted . insert ( 0 , func ) ",if output == input :,if input == output:,False,54.47986821785834,97.17174634530237
4903,"def printWiki ( ) : <TAB>  firstHeading = False <TAB>  for m in protocol : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if firstHeading : <TAB><TAB><TAB><TAB>  output ( "" |} "" ) <TAB><TAB><TAB>  __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB><TAB><TAB>  firstHeading = True <TAB><TAB>  else : <TAB><TAB><TAB>  output ( "" |- "" ) <TAB><TAB><TAB>  output ( <TAB><TAB><TAB><TAB>  ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB><TAB><TAB><TAB>  + m [ 0 ] <TAB><TAB><TAB><TAB>  + "" </tt></span> || ||  "" <TAB><TAB><TAB><TAB>  + m [ 1 ] <TAB><TAB><TAB>  ) <TAB>  output ( "" |} "" ) ","if m [ 0 ] == """" :",if m[0] == 'header':,False,51.158629237268805,98.56695260176198
4904,"def test_getitem ( self ) : <TAB>  n = 200 <TAB>  d = deque ( range ( n ) ) <TAB>  l = list ( range ( n ) ) <TAB>  for i in range ( n ) : <TAB><TAB>  d . popleft ( ) <TAB><TAB>  l . pop ( 0 ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d . append ( i ) <TAB><TAB><TAB>  l . append ( i ) <TAB><TAB>  for j in range ( 1 - len ( l ) , len ( l ) ) : <TAB><TAB><TAB>  assert d [ j ] == l [ j ] <TAB>  d = deque ( "" superman "" ) <TAB>  self . assertEqual ( d [ 0 ] , "" s "" ) <TAB>  self . assertEqual ( d [ - 1 ] , "" n "" ) <TAB>  d = deque ( ) <TAB>  self . assertRaises ( IndexError , d . __getitem__ , 0 ) <TAB>  self . assertRaises ( IndexError , d . __getitem__ , - 1 ) ",if random . random ( ) < 0.5 :,if i not in d:,False,28.688480505145748,94.86005668934335
4905,"def get_num ( line , char_ptr , num_chars ) : <TAB>  char_ptr = char_ptr + 1 <TAB>  numstr = "" "" <TAB>  good = "" -.0123456789 "" <TAB>  while char_ptr < num_chars : <TAB><TAB>  digit = line [ char_ptr ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  numstr = numstr + digit <TAB><TAB><TAB>  char_ptr = char_ptr + 1 <TAB><TAB>  else : <TAB><TAB><TAB>  break <TAB>  return numstr ",if good . find ( digit ) != - 1 :,if digit in good:,False,21.494184397166826,92.86922759861547
4906,"def read_digits ( source , start , first_code ) : <TAB>  body = source . body <TAB>  position = start <TAB>  code = first_code <TAB>  if code is not None and 48 < = code < = 57 :<TAB># 0 - 9 <TAB><TAB>  while True : <TAB><TAB><TAB>  position + = 1 <TAB><TAB><TAB>  code = char_code_at ( body , position ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  return position <TAB>  raise GraphQLSyntaxError ( <TAB><TAB>  source , <TAB><TAB>  position , <TAB><TAB>  u "" Invalid number, expected digit but got:  {} . "" . format ( print_char_code ( code ) ) , <TAB>  ) ",if not ( code is not None and 48 <= code <= 57 ) :,if code is None:,False,49.54850990152283,91.71795410331815
4907,"def get_aws_metadata ( headers , provider = None ) : <TAB>  if not provider : <TAB><TAB>  provider = boto . provider . get_default ( ) <TAB>  metadata_prefix = provider . metadata_prefix <TAB>  metadata = { } <TAB>  for hkey in headers . keys ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  val = urllib . unquote_plus ( headers [ hkey ] ) <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  metadata [ hkey [ len ( metadata_prefix ) : ] ] = unicode ( val , "" utf-8 "" ) <TAB><TAB><TAB>  except UnicodeDecodeError : <TAB><TAB><TAB><TAB>  metadata [ hkey [ len ( metadata_prefix ) : ] ] = val <TAB><TAB><TAB>  del headers [ hkey ] <TAB>  return metadata ",if hkey . lower ( ) . startswith ( metadata_prefix ) :,if hkey.startswith(metadata_prefix):,False,48.53837530901636,97.75756056419925
4908,"def _process_rtdest ( self ) : <TAB>  LOG . debug ( "" Processing RT NLRI destination... "" ) <TAB>  if self . _rtdest_queue . is_empty ( ) : <TAB><TAB>  return <TAB>  else : <TAB><TAB>  processed_any = False <TAB><TAB>  while not self . _rtdest_queue . is_empty ( ) : <TAB><TAB><TAB>  # We process the first destination in the queue. <TAB><TAB><TAB>  next_dest = self . _rtdest_queue . pop_first ( ) <TAB><TAB><TAB>  if next_dest : <TAB><TAB><TAB><TAB>  next_dest . process ( ) <TAB><TAB><TAB><TAB>  processed_any = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Since RT destination were updated we update RT filters <TAB><TAB><TAB>  self . _core_service . update_rtfilters ( ) ",if processed_any :,if processed_any:,False,64.05098301179949,100.00000000000004
4909,"def _get_header ( self , requester , header_name ) : <TAB>  hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB>  self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB>  for url , headers in requester . requests : <TAB><TAB>  if header_name in headers : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB><TAB><TAB>  return headers . get ( header_name ) ",if self . revs_enabled :,if self.revs_enabled:,False,52.12393996654428,100.00000000000004
4910,"def add_external_deps ( self , deps ) : <TAB>  for dep in deps : <TAB><TAB>  if hasattr ( dep , "" el "" ) : <TAB><TAB><TAB>  dep = dep . el <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise InvalidArguments ( "" Argument is not an external dependency "" ) <TAB><TAB>  self . external_deps . append ( dep ) <TAB><TAB>  if isinstance ( dep , dependencies . Dependency ) : <TAB><TAB><TAB>  self . process_sourcelist ( dep . get_sources ( ) ) ","if not isinstance ( dep , dependencies . Dependency ) :","if not isinstance(dep, dependencies.Dependency):",False,55.528465815263786,100.00000000000004
4911,"def _consume_msg ( self ) : <TAB>  ws = self . _ws <TAB>  try : <TAB><TAB>  while True : <TAB><TAB><TAB>  r = await ws . recv ( ) <TAB><TAB><TAB>  if isinstance ( r , bytes ) : <TAB><TAB><TAB><TAB>  r = r . decode ( "" utf-8 "" ) <TAB><TAB><TAB>  msg = json . loads ( r ) <TAB><TAB><TAB>  stream = msg . get ( "" stream "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  await self . _dispatch ( stream , msg ) <TAB>  except websockets . WebSocketException as wse : <TAB><TAB>  logging . warn ( wse ) <TAB><TAB>  await self . close ( ) <TAB><TAB>  asyncio . ensure_future ( self . _ensure_ws ( ) ) ",if stream is not None :,if stream:,False,25.250746112229507,97.89793818599038
4912,"def generate_and_check_random ( ) : <TAB>  random_size = 256 <TAB>  while True : <TAB><TAB>  random = os . urandom ( random_size ) <TAB><TAB>  a = int . from_bytes ( random , "" big "" ) <TAB><TAB>  A = pow ( g , a , p ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  a_for_hash = big_num_for_hash ( A ) <TAB><TAB><TAB>  u = int . from_bytes ( sha256 ( a_for_hash , b_for_hash ) , "" big "" ) <TAB><TAB><TAB>  if u > 0 : <TAB><TAB><TAB><TAB>  return ( a , a_for_hash , u ) ","if is_good_mod_exp_first ( A , p ) :",if A > 0:,False,21.772799810730003,92.11940966417559
4913,"def write ( self , datagram , address ) : <TAB>  """"""Write a datagram."""""" <TAB>  try : <TAB><TAB>  return self . socket . sendto ( datagram , address ) <TAB>  except OSError as se : <TAB><TAB>  no = se . args [ 0 ] <TAB><TAB>  if no == EINTR : <TAB><TAB><TAB>  return self . write ( datagram , address ) <TAB><TAB>  elif no == EMSGSIZE : <TAB><TAB><TAB>  raise error . MessageLengthError ( "" message too long "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # oh, well, drop the data. The only difference from UDP <TAB><TAB><TAB>  # is that UDP won't ever notice. <TAB><TAB><TAB>  # TODO: add TCP-like buffering <TAB><TAB><TAB>  pass <TAB><TAB>  else : <TAB><TAB><TAB>  raise ",elif no == EAGAIN :,if no == EAGAIN:,False,61.54288172868221,98.87254519239598
4914,"def doDir ( elem ) : <TAB>  for child in elem . childNodes : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if child . tagName == "" Directory "" : <TAB><TAB><TAB>  doDir ( child ) <TAB><TAB>  elif child . tagName == "" Component "" : <TAB><TAB><TAB>  for grandchild in child . childNodes : <TAB><TAB><TAB><TAB>  if not isinstance ( grandchild , minidom . Element ) : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  if grandchild . tagName != "" File "" : <TAB><TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB><TAB>  files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if not isinstance ( child , minidom . Element ) :","if not isinstance(child, minidom.Element):",False,26.121954572327827,100.00000000000004
4915,"def add_reversed_tensor ( i , X , reversed_X ) : <TAB>  # Do not keep tensors that should stop the mapping. <TAB>  if X in stop_mapping_at_tensors : <TAB><TAB>  return <TAB>  if X not in reversed_tensors : <TAB><TAB>  reversed_tensors [ X ] = { "" id "" : ( nid , i ) , "" tensor "" : reversed_X } <TAB>  else : <TAB><TAB>  tmp = reversed_tensors [ X ] <TAB><TAB>  if "" tensor "" in tmp and "" tensors "" in tmp : <TAB><TAB><TAB>  raise Exception ( "" Wrong order, tensors already aggregated! "" ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  tmp [ "" tensors "" ] = [ tmp [ "" tensor "" ] , reversed_X ] <TAB><TAB><TAB>  del tmp [ "" tensor "" ] <TAB><TAB>  else : <TAB><TAB><TAB>  tmp [ "" tensors "" ] . append ( reversed_X ) ","if ""tensor"" in tmp :","if isinstance(tmp, tuple):",False,33.53593629296384,96.98054452980384
4916,"def walk ( source , path , default , delimiter = "" . "" ) : <TAB>  """"""Walk the sourch hash given the path and return the value or default if not found"""""" <TAB>  if not isinstance ( source , dict ) : <TAB><TAB>  raise RuntimeError ( <TAB><TAB><TAB>  "" The source is not a walkable dict:  {}  path:  {} "" . format ( source , path ) <TAB><TAB>  ) <TAB>  keys = path . split ( delimiter ) <TAB>  max_depth = len ( keys ) <TAB>  cur_depth = 0 <TAB>  while cur_depth < max_depth : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  source = source [ keys [ cur_depth ] ] <TAB><TAB><TAB>  cur_depth = cur_depth + 1 <TAB><TAB>  else : <TAB><TAB><TAB>  return default <TAB>  return source ",if keys [ cur_depth ] in source :,if cur_depth < max_depth:,False,61.80245567943705,96.34649656589674
4917,"def _from_txt_get_vulns ( self ) : <TAB>  file_vulns = [ ] <TAB>  vuln_regex = ( <TAB><TAB>  ' SQL injection in a .*? was found at:  "" (.*?) "" ' <TAB><TAB>  ' , using HTTP method (.*?). The sent .*?data was:  "" (.*?) "" ' <TAB>  ) <TAB>  vuln_re = re . compile ( vuln_regex ) <TAB>  for line in file ( self . OUTPUT_FILE ) : <TAB><TAB>  mo = vuln_re . search ( line ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  v = MockVuln ( "" TestCase "" , None , "" High "" , 1 , "" plugin "" ) <TAB><TAB><TAB>  v . set_url ( URL ( mo . group ( 1 ) ) ) <TAB><TAB><TAB>  v . set_method ( mo . group ( 2 ) ) <TAB><TAB><TAB>  file_vulns . append ( v ) <TAB>  return file_vulns ",if mo :,if mo:,False,62.07279150758368,98.57696181855361
4918,"def __get__ ( self , instance , instance_type = None ) : <TAB>  if instance : <TAB><TAB>  if self . att_name not in instance . _obj_cache : <TAB><TAB><TAB>  rel_obj = self . get_obj ( instance ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  instance . _obj_cache [ self . att_name ] = rel_obj <TAB><TAB>  return instance . _obj_cache . get ( self . att_name ) <TAB>  return self ",if rel_obj :,if rel_obj is not None:,False,44.65281015054903,96.71679735406703
4919,"def get_ranges_from_func_set ( support_set ) : <TAB>  pos_start = 0 <TAB>  pos_end = 0 <TAB>  ranges = [ ] <TAB>  for pos , func in enumerate ( network . function ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  pos_end = pos <TAB><TAB>  else : <TAB><TAB><TAB>  if pos_end > = pos_start : <TAB><TAB><TAB><TAB>  ranges . append ( ( pos_start , pos_end ) ) <TAB><TAB><TAB>  pos_start = pos + 1 <TAB>  if pos_end > = pos_start : <TAB><TAB>  ranges . append ( ( pos_start , pos_end ) ) <TAB>  return ranges ",if func . type in support_set :,if func.is_set_support_set(support_set):,False,40.077169214421474,93.8477445078237
4920,"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB>  """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB>  all_plugins = [ ] <TAB>  for name in self . plugins_callback_order : <TAB><TAB>  # None is a placeholder for any plugin not having a defined order <TAB><TAB>  if name is None : <TAB><TAB><TAB>  all_plugins + = [ <TAB><TAB><TAB><TAB>  plugin <TAB><TAB><TAB><TAB>  for name , plugin in self . plugins . items ( ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ] <TAB><TAB>  else : <TAB><TAB><TAB>  plugin = self . plugins [ name ] <TAB><TAB><TAB>  if plugin . is_activated : <TAB><TAB><TAB><TAB>  all_plugins . append ( plugin ) <TAB>  return all_plugins ",if name not in self . plugins_callback_order and plugin . is_activated,if name == 'plugin':,False,58.44187482808948,93.39435037246731
4921,"def render_token_list ( self , tokens ) : <TAB>  result = [ ] <TAB>  vars = [ ] <TAB>  for token in tokens : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB><TAB>  elif token . token_type == TOKEN_VAR : <TAB><TAB><TAB>  result . append ( "" %% ( %s )s "" % token . contents ) <TAB><TAB><TAB>  vars . append ( token . contents ) <TAB>  msg = "" "" . join ( result ) <TAB>  if self . trimmed : <TAB><TAB>  msg = translation . trim_whitespace ( msg ) <TAB>  return msg , vars ",if token . token_type == TOKEN_TEXT :,if token.token_type == TOKEN_COMMENT:,False,50.918016088963554,98.63935179707366
4922,"def test_build_root_config_overwrite ( self ) : <TAB>  cfg = build_root_config ( "" tests.files.settings_overwrite "" ) <TAB>  for key , val in DEFAULT_SPIDER_GLOBAL_CONFIG . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . assertEqual ( cfg [ "" global "" ] [ key ] , [ "" zzz "" ] ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . assertEqual ( cfg [ "" global "" ] [ key ] , val ) ","if key == ""spider_modules"" :",if val is None:,False,48.82875559139403,92.73606709244523
4923,"def get_limit ( self , request ) : <TAB>  if self . limit_query_param : <TAB><TAB>  try : <TAB><TAB><TAB>  limit = int ( request . query_params [ self . limit_query_param ] ) <TAB><TAB><TAB>  if limit < 0 : <TAB><TAB><TAB><TAB>  raise ValueError ( ) <TAB><TAB><TAB>  # Enforce maximum page size, if defined <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  if limit == 0 : <TAB><TAB><TAB><TAB><TAB>  return settings . MAX_PAGE_SIZE <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  return min ( limit , settings . MAX_PAGE_SIZE ) <TAB><TAB><TAB>  return limit <TAB><TAB>  except ( KeyError , ValueError ) : <TAB><TAB><TAB>  pass <TAB>  return self . default_limit ",if settings . MAX_PAGE_SIZE :,if self.default_limit is None:,False,55.95757630468743,96.76130900540389
4924,"def track_handler ( handler ) : <TAB>  tid = handler . request . tid <TAB>  for event in events_monitored : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  e = Event ( event , handler . request . execution_time ) <TAB><TAB><TAB>  State . tenant_state [ tid ] . RecentEventQ . append ( e ) <TAB><TAB><TAB>  State . tenant_state [ tid ] . EventQ . append ( e ) <TAB><TAB><TAB>  break ","if event [ ""handler_check"" ] ( handler ) :",if event.type == 'event':,False,48.03049005721233,90.86645409198078
4925,"def TryMerge ( self , d ) : <TAB>  while d . avail ( ) > 0 : <TAB><TAB>  tt = d . getVarInt32 ( ) <TAB><TAB>  if tt == 10 : <TAB><TAB><TAB>  length = d . getVarInt32 ( ) <TAB><TAB><TAB>  tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB>  d . skip ( length ) <TAB><TAB><TAB>  self . add_subscription ( ) . TryMerge ( tmp ) <TAB><TAB><TAB>  continue <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB>  d . skipData ( tt ) ",if tt == 0 :,if tt == 0:,False,50.97682883708774,100.00000000000004
4926,"def GetCreateInstanceBinder ( self , info ) : <TAB>  with self . _lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return self . _createInstanceBinders [ info ] <TAB><TAB>  b = runtime . SymplCreateInstanceBinder ( info ) <TAB><TAB>  self . _createInstanceBinders [ info ] = b <TAB>  return b ",if self . _createInstanceBinders . ContainsKey ( info ) :,if info in self._createInstanceBinders:,False,45.73474487770221,90.61991348684401
4927,"def process_task ( self , body , message ) : <TAB>  if "" control "" in body : <TAB><TAB>  try : <TAB><TAB><TAB>  return self . control ( body , message ) <TAB><TAB>  except Exception : <TAB><TAB><TAB>  logger . exception ( "" Exception handling control message: "" ) <TAB><TAB><TAB>  return <TAB>  if len ( self . pool ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  queue = UUID ( body [ "" uuid "" ] ) . int % len ( self . pool ) <TAB><TAB><TAB>  except Exception : <TAB><TAB><TAB><TAB>  queue = self . total_messages % len ( self . pool ) <TAB><TAB>  else : <TAB><TAB><TAB>  queue = self . total_messages % len ( self . pool ) <TAB>  else : <TAB><TAB>  queue = 0 <TAB>  self . pool . write ( queue , body ) <TAB>  self . total_messages + = 1 <TAB>  message . ack ( ) ","if ""uuid"" in body and body [ ""uuid"" ] :","if isinstance(body, dict):",False,46.84441023636685,95.17524553421381
4928,"def is_defined_in_base_class ( self , var : Var ) - > bool : <TAB>  if var . info : <TAB><TAB>  for base in var . info . mro [ 1 : ] : <TAB><TAB><TAB>  if base . get ( var . name ) is not None : <TAB><TAB><TAB><TAB>  return True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return True <TAB>  return False ",if var . info . fallback_to_any :,if var.name in self.base_class_names:,False,24.044480398545847,91.66259454719922
4929,"def ant_map ( m ) : <TAB>  tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB>  players = { } <TAB>  for row in m : <TAB><TAB>  tmp + = "" m  "" <TAB><TAB>  for col in row : <TAB><TAB><TAB>  if col == LAND : <TAB><TAB><TAB><TAB>  tmp + = "" . "" <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  tmp + = "" % "" <TAB><TAB><TAB>  elif col == FOOD : <TAB><TAB><TAB><TAB>  tmp + = "" * "" <TAB><TAB><TAB>  elif col == UNSEEN : <TAB><TAB><TAB><TAB>  tmp + = "" ? "" <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  players [ col ] = True <TAB><TAB><TAB><TAB>  tmp + = chr ( col + 97 ) <TAB><TAB>  tmp + = "" \n "" <TAB>  tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB>  return tmp ",elif col == BARRIER :,if col == QUIT:,False,18.313708441148606,97.13191052185874
4930,"def prompt_for_resume ( config ) : <TAB>  logger = logging . getLogger ( "" changeme "" ) <TAB>  logger . error ( <TAB><TAB>  "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB>  ) <TAB>  answer = "" "" <TAB>  while not ( answer == "" R "" or answer == "" F "" ) : <TAB><TAB>  prompt = "" (R/F)>  "" <TAB><TAB>  answer = "" "" <TAB><TAB>  try : <TAB><TAB><TAB>  answer = raw_input ( prompt ) <TAB><TAB>  except NameError : <TAB><TAB><TAB>  answer = input ( prompt ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logger . debug ( "" Forcing a fresh scan "" ) <TAB><TAB>  elif answer . upper ( ) == "" R "" : <TAB><TAB><TAB>  logger . debug ( "" Resuming previous scan "" ) <TAB><TAB><TAB>  config . resume = True <TAB>  return config . resume ","if answer . upper ( ) == ""F"" :","if answer == ""F"" or answer == ""F"" or answer == ""F"" or",False,34.89923209761467,93.238104499346
4931,"def f ( view , s ) : <TAB>  if mode == modes . INTERNAL_NORMAL : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if view . line ( s . b ) . size ( ) > 0 : <TAB><TAB><TAB><TAB>  eol = view . line ( s . b ) . b <TAB><TAB><TAB><TAB>  return R ( s . b , eol ) <TAB><TAB><TAB>  return s <TAB>  return s ",if count == 1 :,if mode == modes.NORMAL:,False,48.79600690132119,94.32159826154711
4932,"def flush ( self ) : <TAB>  if not self . cuts : <TAB><TAB>  return <TAB>  for move , ( x , y , z ) , cent in douglas ( self . cuts , self . tolerance , self . plane ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . write ( "" %s  X %.4f  Y %.4f  Z %.4f %s "" % ( move , x , y , z , cent ) ) <TAB><TAB><TAB>  self . lastgcode = None <TAB><TAB><TAB>  self . lastx = x <TAB><TAB><TAB>  self . lasty = y <TAB><TAB><TAB>  self . lastz = z <TAB><TAB>  else : <TAB><TAB><TAB>  self . move_common ( x , y , z , gcode = "" G1 "" ) <TAB>  self . cuts = [ ] ",if cent :,if move:,False,50.562739870762805,98.77292991777081
4933,"def copy_shell ( self ) : <TAB>  cls = self . __class__ <TAB>  old_id = cls . id <TAB>  new_i = cls ( )<TAB># create a new group <TAB>  new_i . id = self . id<TAB># with the same id <TAB>  cls . id = old_id<TAB># Reset the Class counter <TAB>  # Copy all properties <TAB>  for prop in cls . properties : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  if self . has ( prop ) : <TAB><TAB><TAB><TAB>  val = getattr ( self , prop ) <TAB><TAB><TAB><TAB>  setattr ( new_i , prop , val ) <TAB>  # but no members <TAB>  new_i . members = [ ] <TAB>  return new_i ","if prop is not ""members"" :",if prop.name == 'shell':,False,17.2374310822026,89.93269271401213
4934,"def find_region_by_value ( key , value ) : <TAB>  for region in cognitoidp_backends : <TAB><TAB>  backend = cognitoidp_backends [ region ] <TAB><TAB>  for user_pool in backend . user_pools . values ( ) : <TAB><TAB><TAB>  if key == "" client_id "" and value in user_pool . clients : <TAB><TAB><TAB><TAB>  return region <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return region <TAB>  # If we can't find the `client_id` or `access_token`, we just pass <TAB>  # back a default backend region, which will raise the appropriate <TAB>  # error message (e.g. NotAuthorized or NotFound). <TAB>  return list ( cognitoidp_backends ) [ 0 ] ","if key == ""access_token"" and value in user_pool . access_tokens :",if key == 'access_token' and value in cognitoidp_backends,False,64.86998255274905,92.55209211099286
4935,"def __init__ ( <TAB>  self , fixed : MQTTFixedHeader = None , variable_header : PacketIdVariableHeader = None  ) : <TAB>  if fixed is None : <TAB><TAB>  header = MQTTFixedHeader ( PUBREL , 0x02 )<TAB># [MQTT-3.6.1-1] <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise HBMQTTException ( <TAB><TAB><TAB><TAB>  "" Invalid fixed packet type  %s  for PubrelPacket init "" % fixed . packet_type <TAB><TAB><TAB>  ) <TAB><TAB>  header = fixed <TAB>  super ( ) . __init__ ( header ) <TAB>  self . variable_header = variable_header <TAB>  self . payload = None ",if fixed . packet_type is not PUBREL :,"if fixed.packet_type not in (MQTTFixedHeader, MQTTFixedHeader):",False,37.55558029973597,92.75443848240145
4936,"def _on_event_MetadataStatisticsUpdated ( self , event , data ) : <TAB>  with self . _selectedFileMutex : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . _setJobData ( <TAB><TAB><TAB><TAB>  self . _selectedFile [ "" filename "" ] , <TAB><TAB><TAB><TAB>  self . _selectedFile [ "" filesize "" ] , <TAB><TAB><TAB><TAB>  self . _selectedFile [ "" sd "" ] , <TAB><TAB><TAB><TAB>  self . _selectedFile [ "" user "" ] , <TAB><TAB><TAB>  ) ",if self . _selectedFile :,if self._selectedFile:,False,51.41214833141855,100.00000000000004
4937,"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB>  """"""Placeholder docstring"""""" <TAB>  for ( <TAB><TAB>  parameter_range_key , <TAB><TAB>  parameter_range_value , <TAB>  ) in parameter_range . __dict__ . items ( ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  # Categorical ranges <TAB><TAB>  if isinstance ( parameter_range_value , list ) : <TAB><TAB><TAB>  for categorical_value in parameter_range_value : <TAB><TAB><TAB><TAB>  value_hp . validate ( categorical_value ) <TAB><TAB>  # Continuous, Integer ranges <TAB><TAB>  else : <TAB><TAB><TAB>  value_hp . validate ( parameter_range_value ) ","if parameter_range_key == ""scaling_type"" :",if parameter_range_key == parameter_range_key:,False,33.21823909254914,97.09367373586848
4938,"def visit_filter_projection ( self , node , value ) : <TAB>  base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB>  if not isinstance ( base , list ) : <TAB><TAB>  return None <TAB>  comparator_node = node [ "" children "" ] [ 2 ] <TAB>  collected = [ ] <TAB>  for element in base : <TAB><TAB>  if self . _is_true ( self . visit ( comparator_node , element ) ) : <TAB><TAB><TAB>  current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  collected . append ( current ) <TAB>  return collected ",if current is not None :,if current is not None:,False,51.753307886505574,100.00000000000004
4939,"def _getSubstrings ( self , va , size , ltyp ) : <TAB>  # rip through the desired memory range to populate any substrings <TAB>  subs = set ( ) <TAB>  end = va + size <TAB>  for offs in range ( va , end , 1 ) : <TAB><TAB>  loc = self . getLocation ( offs , range = True ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  subs . add ( ( loc [ L_VA ] , loc [ L_SIZE ] ) ) <TAB><TAB><TAB>  if loc [ L_TINFO ] : <TAB><TAB><TAB><TAB>  subs = subs . union ( set ( loc [ L_TINFO ] ) ) <TAB>  return list ( subs ) ",if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,if loc:,False,33.390306268351864,87.37828272667355
4940,"def run ( self ) : <TAB>  while not self . _stopped : <TAB><TAB>  try : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  test_name = next ( self . pending ) <TAB><TAB><TAB>  except StopIteration : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  mp_result = self . _runtest ( test_name ) <TAB><TAB><TAB>  self . output . put ( ( False , mp_result ) ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  break <TAB><TAB>  except ExitThread : <TAB><TAB><TAB>  break <TAB><TAB>  except BaseException : <TAB><TAB><TAB>  self . output . put ( ( True , traceback . format_exc ( ) ) ) <TAB><TAB><TAB>  break ","if must_stop ( mp_result . result , self . ns ) :",if mp_result is None:,False,22.268519165190547,93.81215224304708
4941,"def get_in_inputs ( key , data ) : <TAB>  if isinstance ( data , dict ) : <TAB><TAB>  for k , v in data . items ( ) : <TAB><TAB><TAB>  if k == key : <TAB><TAB><TAB><TAB>  return v <TAB><TAB><TAB>  elif isinstance ( v , ( list , tuple , dict ) ) : <TAB><TAB><TAB><TAB>  out = get_in_inputs ( key , v ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  return out <TAB>  elif isinstance ( data , ( list , tuple ) ) : <TAB><TAB>  out = [ get_in_inputs ( key , x ) for x in data ] <TAB><TAB>  out = [ x for x in out if x ] <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return out [ 0 ] ",if out :,if out:,False,35.20347177286102,98.00946692295871
4942,"def act_mapping ( self , items , actions , mapping ) : <TAB>  """"""Executes all the actions on the list of pods."""""" <TAB>  success = True <TAB>  for action in actions : <TAB><TAB>  for key , method in mapping . items ( ) : <TAB><TAB><TAB>  if key in action : <TAB><TAB><TAB><TAB>  params = action . get ( key ) <TAB><TAB><TAB><TAB>  ret = method ( items , params ) <TAB><TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB><TAB>  success = False <TAB>  return success ",if not ret :,if ret is not None:,False,36.05975883064373,96.8097189290435
4943,"def _apply ( self , plan ) : <TAB>  desired = plan . desired <TAB>  changes = plan . changes <TAB>  self . log . debug ( "" _apply: zone= %s , len(changes)= %d "" , desired . name , len ( changes ) ) <TAB>  domain_name = desired . name [ : - 1 ] <TAB>  try : <TAB><TAB>  nsone_zone = self . _client . loadZone ( domain_name ) <TAB>  except ResourceException as e : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise <TAB><TAB>  self . log . debug ( "" _apply:   no matching zone, creating "" ) <TAB><TAB>  nsone_zone = self . _client . createZone ( domain_name ) <TAB>  for change in changes : <TAB><TAB>  class_name = change . __class__ . __name__ <TAB><TAB>  getattr ( self , "" _apply_ {} "" . format ( class_name ) ) ( nsone_zone , change ) ",if e . message != self . ZONE_NOT_FOUND_MESSAGE :,if e.errno == errno.EADDRINUSE:,False,40.232641906134944,93.6906995542001
4944,"def split_artists ( self , json ) : <TAB>  if len ( json ) == 0 : <TAB><TAB>  ( [ ] , [ ] ) <TAB>  elif len ( json ) == 1 : <TAB><TAB>  artist = Artist . query . filter_by ( name = json [ 0 ] [ "" name "" ] ) . first ( ) <TAB><TAB>  return ( [ artist ] , [ ] ) <TAB>  my_artists = [ ] <TAB>  other_artists = [ ] <TAB>  for artist_dict in json : <TAB><TAB>  artist = Artist . query . filter_by ( name = artist_dict [ "" name "" ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  my_artists . append ( artist . first ( ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  del artist_dict [ "" thumb_url "" ] <TAB><TAB><TAB>  other_artists . append ( artist_dict ) <TAB>  return ( my_artists , other_artists ) ",if artist . count ( ) :,if artist:,False,23.415281813636568,97.7158870691613
4945,"def update_metadata ( self ) : <TAB>  for attrname in dir ( self ) : <TAB><TAB>  if attrname . startswith ( "" __ "" ) : <TAB><TAB><TAB>  continue <TAB><TAB>  attrvalue = getattr ( self , attrname , None ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  if attrname == "" salt_version "" : <TAB><TAB><TAB>  attrname = "" version "" <TAB><TAB>  if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB>  getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB>  elif hasattr ( self . metadata , attrname ) : <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB>  except AttributeError : <TAB><TAB><TAB><TAB>  pass ",if attrvalue == 0 :,if attrvalue is None:,False,24.3414863424566,98.15792581012488
4946,"def close ( self , code = errno . ECONNRESET ) : <TAB>  with self . shutdown_lock : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  super ( RemoteIPRoute , self ) . close ( code = code ) <TAB><TAB><TAB>  self . closed = True <TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB>  self . _mitogen_call . get ( ) <TAB><TAB><TAB>  except mitogen . core . ChannelError : <TAB><TAB><TAB><TAB>  pass <TAB><TAB><TAB>  if self . _mitogen_broker is not None : <TAB><TAB><TAB><TAB>  self . _mitogen_broker . shutdown ( ) <TAB><TAB><TAB><TAB>  self . _mitogen_broker . join ( ) ",if not self . closed :,if self.closed:,False,41.33490387763044,98.71221610720457
4947,"def untokenize ( self , iterable ) : <TAB>  for t in iterable : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . compat ( t , iterable ) <TAB><TAB><TAB>  break <TAB><TAB>  tok_type , token , start , end , line = t <TAB><TAB>  self . add_whitespace ( start ) <TAB><TAB>  self . tokens . append ( token ) <TAB><TAB>  self . prev_row , self . prev_col = end <TAB><TAB>  if tok_type in ( NEWLINE , NL ) : <TAB><TAB><TAB>  self . prev_row + = 1 <TAB><TAB><TAB>  self . prev_col = 0 <TAB>  return "" "" . join ( self . tokens ) ",if len ( t ) == 2 :,"if isinstance(t, (tuple, list)):",False,43.800101111129614,94.4143035656256
4948,"def __call__ ( self , x , uttid = None ) : <TAB>  if self . utt2spk is not None : <TAB><TAB>  spk = self . utt2spk [ uttid ] <TAB>  else : <TAB><TAB>  spk = uttid <TAB>  if not self . reverse : <TAB><TAB>  if self . norm_means : <TAB><TAB><TAB>  x = np . add ( x , self . bias [ spk ] ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = np . multiply ( x , self . scale [ spk ] ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  x = np . divide ( x , self . scale [ spk ] ) <TAB><TAB>  if self . norm_means : <TAB><TAB><TAB>  x = np . subtract ( x , self . bias [ spk ] ) <TAB>  return x ",if self . norm_vars :,if self.norm_means:,False,27.36844949231688,95.45401357651029
4949,"def get_party_total ( self , args ) : <TAB>  self . party_total = frappe . _dict ( ) <TAB>  for d in self . receivables : <TAB><TAB>  self . init_party_total ( d ) <TAB><TAB>  # Add all amount columns <TAB><TAB>  for k in list ( self . party_total [ d . party ] ) : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . party_total [ d . party ] [ k ] + = d . get ( k , 0.0 ) <TAB><TAB>  # set territory, customer_group, sales person etc <TAB><TAB>  self . set_party_details ( d ) ","if k not in [ ""currency"" , ""sales_person"" ] :",if k not in self.party_total[d.party]:,False,57.88759183767187,93.82778157262057
4950,"def get_databases ( request ) : <TAB>  dbs = { } <TAB>  global_env = globals ( ) <TAB>  for ( key , value ) in global_env . items ( ) : <TAB><TAB>  try : <TAB><TAB><TAB>  cond = isinstance ( value , GQLDB ) <TAB><TAB>  except : <TAB><TAB><TAB>  cond = isinstance ( value , SQLDB ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  dbs [ key ] = value <TAB>  return dbs ",if cond :,if cond:,False,50.555099429675224,100.00000000000004
4951,"def check_twobit_file ( dbkey , GALAXY_DATA_INDEX_DIR ) : <TAB>  twobit_file = "" %s /twobit.loc "" % GALAXY_DATA_INDEX_DIR <TAB>  twobit_path = "" "" <TAB>  twobits = { } <TAB>  for i , line in enumerate ( open ( twobit_file ) ) : <TAB><TAB>  line = line . rstrip ( "" \r \n "" ) <TAB><TAB>  if line and not line . startswith ( "" # "" ) : <TAB><TAB><TAB>  fields = line . split ( "" \t "" ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  continue <TAB><TAB><TAB>  twobits [ ( fields [ 0 ] ) ] = fields [ 1 ] <TAB>  if dbkey in twobits : <TAB><TAB>  twobit_path = twobits [ ( dbkey ) ] <TAB>  return twobit_path ",if len ( fields ) < 2 :,if len(fields) == 0:,False,29.30947423196695,97.91733651511005
4952,"def action ( scheduler , _ ) : <TAB>  nonlocal state <TAB>  nonlocal has_result <TAB>  nonlocal result <TAB>  nonlocal first <TAB>  nonlocal time <TAB>  <IF-STMT>: <TAB><TAB>  observer . on_next ( result ) <TAB>  try : <TAB><TAB>  if first : <TAB><TAB><TAB>  first = False <TAB><TAB>  else : <TAB><TAB><TAB>  state = iterate ( state ) <TAB><TAB>  has_result = condition ( state ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = state <TAB><TAB><TAB>  time = time_mapper ( state ) <TAB>  except Exception as e :<TAB># pylint: disable=broad-except <TAB><TAB>  observer . on_error ( e ) <TAB><TAB>  return <TAB>  <IF-STMT>: <TAB><TAB>  mad . disposable = scheduler . schedule_relative ( time , action ) <TAB>  else : <TAB><TAB>  observer . on_completed ( ) ",if has_result :,if has_result:,False,47.60973753267999,94.36939286643965
4953,def orthogonalEnd ( self ) : <TAB>  if self . type == Segment . LINE : <TAB><TAB>  O = self . AB . orthogonal ( ) <TAB><TAB>  O . norm ( ) <TAB><TAB>  return O <TAB>  else : <TAB><TAB>  O = self . B - self . C <TAB><TAB>  O . norm ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return - O <TAB><TAB>  else : <TAB><TAB><TAB>  return O ,if self . type == Segment . CCW :,if O < 0:,False,21.57030239179873,90.61640844946196
4954,"def remove ( self , values ) : <TAB>  if not isinstance ( values , ( list , tuple , set ) ) : <TAB><TAB>  values = [ values ] <TAB>  for v in values : <TAB><TAB>  v = str ( v ) <TAB><TAB>  if isinstance ( self . _definition , dict ) : <TAB><TAB><TAB>  self . _definition . pop ( v , None ) <TAB><TAB>  elif self . _definition == "" ANY "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . _definition = [ ] <TAB><TAB>  elif v in self . _definition : <TAB><TAB><TAB>  self . _definition . remove ( v ) <TAB>  if ( <TAB><TAB>  self . _value is not None <TAB><TAB>  and self . _value not in self . _definition <TAB><TAB>  and self . _not_any ( ) <TAB>  ) : <TAB><TAB>  raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) ) ","if v == ""ANY"" :",if self._definition is None:,False,45.376152199410086,97.16165136384701
4955,"def __enter__ ( self ) - > None : <TAB>  try : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  signal . signal ( signal . SIGALRM , self . handle_timeout ) <TAB><TAB><TAB>  signal . alarm ( self . seconds ) <TAB>  except ValueError as ex : <TAB><TAB>  logger . warning ( "" timeout can ' t be used in the current context "" ) <TAB><TAB>  logger . exception ( ex ) ",if threading . current_thread ( ) == threading . main_thread ( ) :,if self.seconds > 0:,False,27.55172008455252,83.52773475278147
4956,"def __init__ ( self , fixed : MQTTFixedHeader = None ) : <TAB>  if fixed is None : <TAB><TAB>  header = MQTTFixedHeader ( PINGRESP , 0x00 ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise HBMQTTException ( <TAB><TAB><TAB><TAB>  "" Invalid fixed packet type  %s  for PingRespPacket init "" <TAB><TAB><TAB><TAB>  % fixed . packet_type <TAB><TAB><TAB>  ) <TAB><TAB>  header = fixed <TAB>  super ( ) . __init__ ( header ) <TAB>  self . variable_header = None <TAB>  self . payload = None ",if fixed . packet_type is not PINGRESP :,"if fixed.packet_type not in (PACKET_TYPE_PACKET, PING",False,27.90279574632899,93.31290839788599
4957,"def _put_nowait ( self , data , * , sender ) : <TAB>  if not self . _running : <TAB><TAB>  logger . warning ( "" Pub/Sub listener message after stop:  %r ,  %r "" , sender , data ) <TAB><TAB>  return <TAB>  self . _queue . put_nowait ( ( sender , data ) ) <TAB>  if self . _waiter is not None : <TAB><TAB>  fut , self . _waiter = self . _waiter , None <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  assert fut . cancelled ( ) , ( "" Waiting future is in wrong state "" , self , fut ) <TAB><TAB><TAB>  return <TAB><TAB>  fut . set_result ( None ) ",if fut . done ( ) :,if fut.cancelled():,False,55.751908876781876,98.57740601266778
4958,"def OnAssignBuiltin ( self , cmd_val ) : <TAB>  # type: (cmd_value__Assign) -> None <TAB>  buf = self . _ShTraceBegin ( ) <TAB>  if not buf : <TAB><TAB>  return <TAB>  for i , arg in enumerate ( cmd_val . argv ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  buf . write ( "" "" ) <TAB><TAB>  buf . write ( arg ) <TAB>  for pair in cmd_val . pairs : <TAB><TAB>  buf . write ( "" "" ) <TAB><TAB>  buf . write ( pair . var_name ) <TAB><TAB>  buf . write ( "" = "" ) <TAB><TAB>  if pair . rval : <TAB><TAB><TAB>  _PrintShValue ( pair . rval , buf ) <TAB>  buf . write ( "" \n "" ) <TAB>  self . f . write ( buf . getvalue ( ) ) ",if i != 0 :,if i == 0:,False,26.981474979760904,98.85183195908576
4959,"def convertDict ( obj ) : <TAB>  obj = dict ( obj ) <TAB>  for k , v in obj . items ( ) : <TAB><TAB>  del obj [ k ] <TAB><TAB>  if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) : <TAB><TAB><TAB>  k = dumps ( k ) <TAB><TAB><TAB>  # Keep track of which keys need to be decoded when loading. <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  obj [ Types . KEYS ] = [ ] <TAB><TAB><TAB>  obj [ Types . KEYS ] . append ( k ) <TAB><TAB>  obj [ k ] = convertObjects ( v ) <TAB>  return obj ",if Types . KEYS not in obj :,if not obj.has_key(Types.KEYS):,False,60.07589833574236,94.22218160287751
4960,"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB>  """"""Check if the function argument list has a dictionary as an arg."""""" <TAB>  if _IsArgumentToFunction ( token ) : <TAB><TAB>  while token : <TAB><TAB><TAB>  if token . value == "" { "" : <TAB><TAB><TAB><TAB>  length = token . matching_bracket . total_length - token . total_length <TAB><TAB><TAB><TAB>  return length + self . stack [ - 2 ] . indent > self . column_limit <TAB><TAB><TAB>  if token . ClosesScope ( ) : <TAB><TAB><TAB><TAB>  break <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  token = token . matching_bracket <TAB><TAB><TAB>  token = token . next_token <TAB>  return False ",if token . OpensScope ( ) :,"if token.value == '""':",False,59.825332795207196,94.86019509347283
4961,"def get_editable_dict ( self ) : <TAB>  ret = { } <TAB>  for ref , ws_package in self . _workspace_packages . items ( ) : <TAB><TAB>  path = ws_package . root_folder <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  path = os . path . join ( path , CONANFILE ) <TAB><TAB>  ret [ ref ] = { "" path "" : path , "" layout "" : ws_package . layout } <TAB>  return ret ",if os . path . isdir ( path ) :,if os.path.exists(path):,False,50.97848805293663,97.92923878387349
4962,"def serialize ( self , name = None ) : <TAB>  data = super ( WebLink , self ) . serialize ( name ) <TAB>  data [ "" contentType "" ] = self . contentType <TAB>  if self . width : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise InvalidWidthException ( self . width ) <TAB><TAB>  data [ "" inputOptions "" ] = { } <TAB><TAB>  data [ "" width "" ] = self . width <TAB>  data . update ( { "" content "" : { "" url "" : self . linkUrl , "" text "" : self . linkText } } ) <TAB>  return data ","if self . width not in [ 100 , 50 , 33 , 25 ] :",if self.width < 0:,False,46.22970918263086,91.56847057978085
4963,"def callback ( lexer , match , context ) : <TAB>  text = match . group ( ) <TAB>  extra = "" "" <TAB>  if start : <TAB><TAB>  context . next_indent = len ( text ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  while context . next_indent < context . indent : <TAB><TAB><TAB><TAB>  context . indent = context . indent_stack . pop ( ) <TAB><TAB><TAB>  if context . next_indent > context . indent : <TAB><TAB><TAB><TAB>  extra = text [ context . indent : ] <TAB><TAB><TAB><TAB>  text = text [ : context . indent ] <TAB>  else : <TAB><TAB>  context . next_indent + = len ( text ) <TAB>  if text : <TAB><TAB>  yield match . start ( ) , TokenClass , text <TAB>  if extra : <TAB><TAB>  yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB>  context . pos = match . end ( ) ",if context . next_indent < context . indent :,if context.indent_stack:,False,24.742057902344445,97.06734827751802
4964,"def _handle_unsubscribe ( self , web_sock ) : <TAB>  index = None <TAB>  with await self . _subscriber_lock : <TAB><TAB>  for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB><TAB><TAB>  if subscriber_web_sock == web_sock : <TAB><TAB><TAB><TAB>  index = i <TAB><TAB><TAB><TAB>  break <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del self . _subscribers [ index ] <TAB><TAB>  if not self . _subscribers : <TAB><TAB><TAB>  asyncio . ensure_future ( self . _unregister_subscriptions ( ) ) ",if index is not None :,if index is not None:,False,52.1132530676677,100.00000000000004
4965,"def test_missing_dict_param ( ) : <TAB>  expected_err = "" params dictionary did not contain value for placeholder "" <TAB>  try : <TAB><TAB>  substitute_params ( <TAB><TAB><TAB>  "" SELECT * FROM cust WHERE salesrep =  %(name)s "" , { "" foobar "" : "" John Doe "" } <TAB><TAB>  ) <TAB><TAB>  assert False , "" expected exception b/c dict did not contain replacement value "" <TAB>  except ValueError as exc : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  raise ",if expected_err not in str ( exc ) :,if exc.args[0] != expected_err:,False,62.06245352194769,92.36881906451696
4966,"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB>  n , r = 0 , 0 <TAB>  for op in _gen_opnds ( ii ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  n + = 1 <TAB><TAB>  elif op_gprv ( op ) : <TAB><TAB><TAB>  r + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  return False <TAB>  return n == 1 and r == 1 ","if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ ""v"" ] ) :",if op_gprv(op):,False,51.94669043909278,83.73458436258262
4967,"def on_enter ( self ) : <TAB>  """"""Fired when mouse enter the bbox of the widget."""""" <TAB>  if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB><TAB>  if hasattr ( self , "" theme_cls "" ) and not self . focus_color : <TAB><TAB><TAB>  self . md_bg_color = self . theme_cls . bg_normal <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  self . md_bg_color = self . focus_color ",if not self . focus_color :,if self.theme_cls:,False,32.202942784657715,96.69772273840837
4968,"def __init__ ( self , * args , * * kwargs ) : <TAB>  BaseCellExporter . __init__ ( self , * args , * * kwargs ) <TAB>  self . comment = "" # "" <TAB>  for key in [ "" cell_marker "" ] : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . metadata [ key ] = self . unfiltered_metadata [ key ] <TAB>  if self . fmt . get ( "" rst2md "" ) : <TAB><TAB>  raise ValueError ( <TAB><TAB><TAB>  "" The  ' rst2md '  option is a read only option. The reverse conversion is not  "" <TAB><TAB><TAB>  "" implemented. Please either deactivate the option, or save to another format. "" <TAB><TAB>  )<TAB># pragma: no cover ",if key in self . unfiltered_metadata :,if key in self.unfiltered_metadata:,False,60.90045396050652,95.23586887400039
4969,"def sendQueryQueueByAfterNate ( self ) : <TAB>  for i in range ( 10 ) : <TAB><TAB>  queryQueueByAfterNateRsp = self . session . httpClint . send ( urls . get ( "" queryQueue "" ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  print ( <TAB><TAB><TAB><TAB>  "" "" . join ( queryQueueByAfterNateRsp . get ( "" messages "" ) ) <TAB><TAB><TAB><TAB>  or queryQueueByAfterNateRsp . get ( "" validateMessages "" ) <TAB><TAB><TAB>  ) <TAB><TAB><TAB>  time . sleep ( 1 ) <TAB><TAB>  else : <TAB><TAB><TAB>  sendEmail ( ticket . WAIT_ORDER_SUCCESS ) <TAB><TAB><TAB>  sendServerChan ( ticket . WAIT_ORDER_SUCCESS ) <TAB><TAB><TAB>  raise ticketIsExitsException ( ticket . WAIT_AFTER_NATE_SUCCESS ) ","if not queryQueueByAfterNateRsp . get ( ""status"" ) :",if queryQueueByAfterNateRsp.get('messages'):,False,48.56250241188697,96.63074959792235
4970,"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB>  real_errors : List [ str ] = list ( ) <TAB>  current_file = __file__ <TAB>  current_path = os . path . split ( current_file ) <TAB>  for line in errors : <TAB><TAB>  line = line . strip ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  continue <TAB><TAB>  fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB><TAB>  if fn is not None : <TAB><TAB><TAB>  _path = os . path . split ( fn ) <TAB><TAB><TAB>  if _path [ - 1 ] != current_path [ - 1 ] : <TAB><TAB><TAB><TAB>  continue <TAB><TAB>  real_errors . append ( line ) <TAB>  return real_errors ",if not line :,if line.startswith('#') or line == '':,False,25.48231692717507,90.79801283206457
4971,"def pretty ( self , n , comment = True ) : <TAB>  if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB><TAB>  r = repr ( n ) <TAB><TAB>  if not comment :<TAB># then it can be inside a comment! <TAB><TAB><TAB>  r = r . replace ( "" */ "" , r "" \ x2a/ "" ) <TAB><TAB>  return r <TAB>  if not isinstance ( n , six . integer_types ) : <TAB><TAB>  return n <TAB>  if isinstance ( n , constants . Constant ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return "" %s  /*  %s  */ "" % ( n , self . pretty ( int ( n ) ) ) <TAB><TAB>  else : <TAB><TAB><TAB>  return "" %s  ( %s ) "" % ( n , self . pretty ( int ( n ) ) ) <TAB>  elif abs ( n ) < 10 : <TAB><TAB>  return str ( n ) <TAB>  else : <TAB><TAB>  return hex ( n ) ",if comment :,"if isinstance(n, int):",False,51.54370574774519,95.63013349811507
4972,"def get_pricings ( self , subscription_id : str ) : <TAB>  try : <TAB><TAB>  client = self . get_client ( subscription_id ) <TAB><TAB>  pricings_list = await run_concurrently ( lambda : client . pricings . list ( ) ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  return pricings_list . value <TAB><TAB>  else : <TAB><TAB><TAB>  return [ ] <TAB>  except Exception as e : <TAB><TAB>  print_exception ( f "" Failed to retrieve pricings:  { e } "" ) <TAB><TAB>  return [ ] ","if hasattr ( pricings_list , ""value"" ) :",if pricings_list:,False,19.42625278391181,93.36060247665057
4973,"def add_doc ( target , variables , body_lines ) : <TAB>  if isinstance ( target , ast . Name ) : <TAB><TAB>  # if it is a variable name add it to the doc <TAB><TAB>  name = target . id <TAB><TAB>  if name not in variables : <TAB><TAB><TAB>  doc = find_doc_for ( target , body_lines ) <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  variables [ name ] = doc <TAB>  elif isinstance ( target , ast . Tuple ) : <TAB><TAB>  # if it is a tuple then iterate the elements <TAB><TAB>  # this can happen like this: <TAB><TAB>  # a, b = 1, 2 <TAB><TAB>  for e in target . elts : <TAB><TAB><TAB>  add_doc ( e , variables , body_lines ) ",if doc is not None :,if doc:,False,64.77261690516924,97.87811371702125
4974,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB>  right = left = index <TAB>  done = False <TAB>  while not done : <TAB><TAB>  if left == 0 : <TAB><TAB><TAB>  done = True <TAB><TAB>  elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB><TAB><TAB>  left - = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  done = False <TAB>  while not done : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  done = True <TAB><TAB>  elif not self . word_boundary_char ( text [ right ] ) : <TAB><TAB><TAB>  right + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  return left , right ",if right == len ( text ) :,if right == left:,False,22.856965958039087,97.5017042594688
4975,"def pxrun_nodes ( self , * args , * * kwargs ) : <TAB>  cell = self . _px_cell <TAB>  if re . search ( r "" ^ \ s* %a utopx \ b "" , cell ) : <TAB><TAB>  self . _disable_autopx ( ) <TAB><TAB>  return False <TAB>  else : <TAB><TAB>  try : <TAB><TAB><TAB>  result = self . view . execute ( cell , silent = False , block = False ) <TAB><TAB>  except : <TAB><TAB><TAB>  self . shell . showtraceback ( ) <TAB><TAB><TAB>  return True <TAB><TAB>  else : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  try : <TAB><TAB><TAB><TAB><TAB>  result . get ( ) <TAB><TAB><TAB><TAB>  except : <TAB><TAB><TAB><TAB><TAB>  self . shell . showtraceback ( ) <TAB><TAB><TAB><TAB><TAB>  return True <TAB><TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB><TAB>  result . display_outputs ( ) <TAB><TAB><TAB>  return False ",if self . view . block :,if result is not None:,False,21.821712786101763,97.01911995668988
4976,"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB>  s = self <TAB>  if Symbol . debug_lookup : <TAB><TAB>  Symbol . debug_print ( "" searching in self: "" ) <TAB><TAB>  print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB>  while True : <TAB><TAB>  if matchSelf : <TAB><TAB><TAB>  yield s <TAB><TAB>  if recurseInAnon : <TAB><TAB><TAB>  yield from s . children_recurse_anon <TAB><TAB>  else : <TAB><TAB><TAB>  yield from s . _children <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  break <TAB><TAB>  s = s . siblingAbove <TAB><TAB>  if Symbol . debug_lookup : <TAB><TAB><TAB>  Symbol . debug_print ( "" searching in sibling: "" ) <TAB><TAB><TAB>  print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) ",if s . siblingAbove is None :,if s.siblingAbove is None:,False,36.15967001294956,100.00000000000004
4977,"def decTaskGen ( ) : <TAB>  cnt = intbv ( 0 , min = - n , max = n ) <TAB>  while 1 : <TAB><TAB>  yield clock . posedge , reset . negedge <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  cnt [ : ] = 0 <TAB><TAB><TAB>  count . next = 0 <TAB><TAB>  else : <TAB><TAB><TAB>  # print count <TAB><TAB><TAB>  decTaskFunc ( cnt , enable , reset , n ) <TAB><TAB><TAB>  count . next = cnt ",if reset == ACTIVE_LOW :,if count.next == 0:,False,48.63328494947337,92.49951554745176
4978,"def __call__ ( self , * args , * * kwargs ) : <TAB>  if not NET_INITTED : <TAB><TAB>  return self . raw ( * args , * * kwargs ) <TAB>  for stack in traceback . walk_stack ( None ) : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB><TAB><TAB>  if layer in layer_names : <TAB><TAB><TAB><TAB>  log . pytorch_layer_name = layer_names [ layer ] <TAB><TAB><TAB><TAB>  print ( layer_names [ layer ] ) <TAB><TAB><TAB><TAB>  break <TAB>  out = self . obj ( self . raw , * args , * * kwargs ) <TAB>  # if isinstance(out,Variable): <TAB>  #<TAB> out=[out] <TAB>  return out ","if ""self"" in stack [ 0 ] . f_locals :",if stack:,False,42.24592382293568,94.05909774562629
4979,"def to_json_dict ( self ) : <TAB>  d = super ( ) . to_json_dict ( ) <TAB>  d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB>  if self . header is not None : <TAB><TAB>  if isinstance ( self . header , RenderedContent ) : <TAB><TAB><TAB>  d [ "" header "" ] = self . header . to_json_dict ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  d [ "" header "" ] = self . header <TAB>  if self . subheader is not None : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB><TAB>  else : <TAB><TAB><TAB>  d [ "" subheader "" ] = self . subheader <TAB>  return d ","if isinstance ( self . subheader , RenderedContent ) :","if isinstance(self.subheader, RenderedContent):",False,50.9134467509553,100.00000000000004
4980,"def add ( request ) : <TAB>  form_type = "" servers "" <TAB>  if request . method == "" POST "" : <TAB><TAB>  form = BookMarkForm ( request . POST ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  form_type = form . save ( ) <TAB><TAB><TAB>  messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  messages . add_message ( request , messages . INFO , form . errors ) <TAB><TAB>  if form_type == "" server "" : <TAB><TAB><TAB>  url = reverse ( "" servers "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  url = reverse ( "" metrics "" ) <TAB><TAB>  return redirect ( url ) <TAB>  else : <TAB><TAB>  return redirect ( reverse ( "" servers "" ) ) ",if form . is_valid ( ) :,if form.validate():,False,23.04310617835592,97.98469818368231
4981,"def fee_amount_in_quote ( self , trading_pair : str , price : Decimal , order_amount : Decimal ) : <TAB>  fee_amount = Decimal ( "" 0 "" ) <TAB>  if self . percent > 0 : <TAB><TAB>  fee_amount = ( price * order_amount ) * self . percent <TAB>  base , quote = trading_pair . split ( "" - "" ) <TAB>  for flat_fee in self . flat_fees : <TAB><TAB>  if interchangeable ( flat_fee [ 0 ] , base ) : <TAB><TAB><TAB>  fee_amount + = flat_fee [ 1 ] * price <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fee_amount + = flat_fee [ 1 ] <TAB>  return fee_amount ","elif interchangeable ( flat_fee [ 0 ] , quote ) :",if quote == '0':,False,46.99961373633705,92.9244719452185
4982,"def load_batch ( fpath ) : <TAB>  with open ( fpath , "" rb "" ) as f : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Python3 <TAB><TAB><TAB>  d = pickle . load ( f , encoding = "" latin1 "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  # Python2 <TAB><TAB><TAB>  d = pickle . load ( f ) <TAB>  data = d [ "" data "" ] <TAB>  labels = d [ "" labels "" ] <TAB>  return data , labels ","if sys . version_info > ( 3 , 0 ) :",if os.name == 'nt':,False,45.26197918225464,91.17890786644917
4983,"def clear_entries ( options ) : <TAB>  """"""Clear pending entries"""""" <TAB>  with Session ( ) as session : <TAB><TAB>  query = session . query ( db . PendingEntry ) . filter ( db . PendingEntry . approved == False ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  query = query . filter ( db . PendingEntry . task_name == options . task_name ) <TAB><TAB>  deleted = query . delete ( ) <TAB><TAB>  console ( "" Successfully deleted  %i  pending entries "" % deleted ) ",if options . task_name :,if options.task_name:,False,51.855557660133876,100.00000000000004
4984,"def attribute_table ( self , attribute ) : <TAB>  """"""Return a tuple (schema, table) for attribute."""""" <TAB>  dimension = attribute . dimension <TAB>  if dimension : <TAB><TAB>  schema = self . naming . dimension_schema or self . naming . schema <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  table = self . fact_name <TAB><TAB>  else : <TAB><TAB><TAB>  table = self . naming . dimension_table_name ( dimension ) <TAB>  else : <TAB><TAB>  table = self . fact_name <TAB><TAB>  schema = self . naming . schema <TAB>  return ( schema , table ) ",if dimension . is_flat and not dimension . has_details :,if dimension == 0:,False,28.873892527723672,92.59454571387316
4985,"def remove_rating ( self , songs , librarian ) : <TAB>  count = len ( songs ) <TAB>  if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB><TAB>  parent = qltk . get_menu_item_top_parent ( self ) <TAB><TAB>  dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB><TAB>  if dialog . run ( ) != Gtk . ResponseType . YES : <TAB><TAB><TAB>  return <TAB>  reset = [ ] <TAB>  for song in songs : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  del song [ "" ~#rating "" ] <TAB><TAB><TAB>  reset . append ( song ) <TAB>  librarian . changed ( reset ) ","if ""~#rating"" in song :",if '~#rating' in song:,False,53.577872332410394,97.02003120042518
4986,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB>  right = left = index <TAB>  done = False <TAB>  while not done : <TAB><TAB>  if left == 0 : <TAB><TAB><TAB>  done = True <TAB><TAB>  elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB><TAB><TAB>  left - = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  done = False <TAB>  while not done : <TAB><TAB>  if right == len ( text ) : <TAB><TAB><TAB>  done = True <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  right + = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  done = True <TAB>  return left , right ",elif not self . word_boundary_char ( text [ right ] ) :,if allowed_chars[right] in text:,False,23.163594905423757,93.38948387347362
4987,"def handle_read ( self ) : <TAB>  """"""Called when there is data waiting to be read."""""" <TAB>  try : <TAB><TAB>  chunk = self . recv ( self . ac_in_buffer_size ) <TAB>  except RetryError : <TAB><TAB>  pass <TAB>  except socket . error : <TAB><TAB>  self . handle_error ( ) <TAB>  else : <TAB><TAB>  self . tot_bytes_received + = len ( chunk ) <TAB><TAB>  if not chunk : <TAB><TAB><TAB>  self . transfer_finished = True <TAB><TAB><TAB>  # self.close()  # <-- asyncore.recv() already do that... <TAB><TAB><TAB>  return <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  chunk = self . _data_wrapper ( chunk ) <TAB><TAB>  try : <TAB><TAB><TAB>  self . file_obj . write ( chunk ) <TAB><TAB>  except OSError as err : <TAB><TAB><TAB>  raise _FileReadWriteError ( err ) ",if self . _data_wrapper is not None :,if self._data_wrapper:,False,57.28462361521276,98.30238051868764
4988,"def toggle ( self , event = None ) : <TAB>  if self . absolute : <TAB><TAB>  if self . save == self . split : <TAB><TAB><TAB>  self . save = 100 <TAB><TAB>  if self . split > 20 : <TAB><TAB><TAB>  self . save = self . split <TAB><TAB><TAB>  self . split = 1 <TAB><TAB>  else : <TAB><TAB><TAB>  self . split = self . save <TAB>  else : <TAB><TAB>  if self . save == self . split : <TAB><TAB><TAB>  self . save = 0.3 <TAB><TAB>  if self . split < = self . min or self . split > = self . max : <TAB><TAB><TAB>  self . split = self . save <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  self . split = self . min <TAB><TAB>  else : <TAB><TAB><TAB>  self . split = self . max <TAB>  self . placeChilds ( ) ",elif self . split < 0.5 :,if self.split < self.min:,False,25.392675078447812,97.21960063000316
4989,"def readAtOffset ( self , offset , size , shortok = False ) : <TAB>  ret = b "" "" <TAB>  self . fd . seek ( offset ) <TAB>  while len ( ret ) != size : <TAB><TAB>  rlen = size - len ( ret ) <TAB><TAB>  x = self . fd . read ( rlen ) <TAB><TAB>  if x == b "" "" : <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  return None <TAB><TAB><TAB>  return ret <TAB><TAB>  ret + = x <TAB>  return ret ",if not shortok :,if shortok:,False,23.011797511620923,98.21587739242793
4990,"def webfinger ( environ , start_response , _ ) : <TAB>  query = parse_qs ( environ [ "" QUERY_STRING "" ] ) <TAB>  try : <TAB><TAB>  rel = query [ "" rel "" ] <TAB><TAB>  resource = query [ "" resource "" ] [ 0 ] <TAB>  except KeyError : <TAB><TAB>  resp = BadRequest ( "" Missing parameter in request "" ) <TAB>  else : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  resp = BadRequest ( "" Bad issuer in request "" ) <TAB><TAB>  else : <TAB><TAB><TAB>  wf = WebFinger ( ) <TAB><TAB><TAB>  resp = Response ( wf . response ( subject = resource , base = OAS . baseurl ) ) <TAB>  return resp ( environ , start_response ) ",if rel != [ OIC_ISSUER ] :,if rel == 'issubset':,False,47.15052307441601,95.65607785659434
4991,"def _tokenize ( self , text ) : <TAB>  if format_text ( text ) == EMPTY_TEXT : <TAB><TAB>  return [ self . additional_special_tokens [ 0 ] ] <TAB>  split_tokens = [ ] <TAB>  if self . do_basic_tokenize : <TAB><TAB>  for token in self . basic_tokenizer . tokenize ( <TAB><TAB><TAB>  text , never_split = self . all_special_tokens <TAB><TAB>  ) : <TAB><TAB><TAB>  # If the token is part of the never_split set <TAB><TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB><TAB>  split_tokens . append ( token ) <TAB><TAB><TAB>  else : <TAB><TAB><TAB><TAB>  split_tokens + = self . wordpiece_tokenizer . tokenize ( token ) <TAB>  else : <TAB><TAB>  split_tokens = self . wordpiece_tokenizer . tokenize ( text ) <TAB>  return split_tokens ",if token in self . basic_tokenizer . never_split :,if token.token_type == token.token_type:,False,58.66913086591866,95.28532030329109
4992,"def send_packed_command ( self , command , check_health = True ) : <TAB>  if not self . _sock : <TAB><TAB>  self . connect ( ) <TAB>  try : <TAB><TAB>  if isinstance ( command , str ) : <TAB><TAB><TAB>  command = [ command ] <TAB><TAB>  for item in command : <TAB><TAB><TAB>  self . _sock . sendall ( item ) <TAB>  except socket . error as e : <TAB><TAB>  self . disconnect ( ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB><TAB>  else : <TAB><TAB><TAB>  _errno , errmsg = e . args <TAB><TAB>  raise ConnectionError ( <TAB><TAB><TAB>  "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB><TAB>  ) <TAB>  except Exception : <TAB><TAB>  self . disconnect ( ) <TAB><TAB>  raise ",if len ( e . args ) == 1 :,if check_health:,False,46.79793192121043,95.87387130012725
4993,"def to_value ( self , value ) : <TAB>  # Tip: 'value' is the object returned by <TAB>  #<TAB>  taiga.projects.history.models.HistoryEntry.values_diff() <TAB>  ret = { } <TAB>  for key , val in value . items ( ) : <TAB><TAB>  if key in [ "" attachments "" , "" custom_attributes "" , "" description_diff "" ] : <TAB><TAB><TAB>  ret [ key ] = val <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  ret [ key ] = { k : { "" from "" : v [ 0 ] , "" to "" : v [ 1 ] } for k , v in val . items ( ) } <TAB><TAB>  else : <TAB><TAB><TAB>  ret [ key ] = { "" from "" : val [ 0 ] , "" to "" : val [ 1 ] } <TAB>  return ret ","elif key == ""points"" :",if key == 'tags':,False,30.67981398778362,96.69652660115156
4994,"def to_child ( cls , key = None , process = None ) : <TAB>  if process is not None : <TAB><TAB>  if type ( process ) is not dict : <TAB><TAB><TAB>  raise ValueError ( <TAB><TAB><TAB><TAB>  ' Invalid value provided for  "" process ""  parameter, expected a dictionary ' <TAB><TAB><TAB>  ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  # Merge class `__process__` parameters with provided parameters <TAB><TAB><TAB>  result = { } <TAB><TAB><TAB>  result . update ( deepcopy ( cls . __process__ ) ) <TAB><TAB><TAB>  result . update ( process ) <TAB><TAB><TAB>  process = result <TAB>  class Child ( cls ) : <TAB><TAB>  __key__ = key <TAB><TAB>  __process__ = process <TAB><TAB>  __root__ = False <TAB>  Child . __name__ = cls . __name__ <TAB>  return Child ",if cls . __process__ :,if process is not None:,False,32.897789703604104,94.83829381131315
4995,"def _super_function ( args ) : <TAB>  passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB>  if passed_self is None : <TAB><TAB>  return passed_class <TAB>  else : <TAB><TAB>  # pyclass = passed_self.get_type() <TAB><TAB>  pyclass = passed_class <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  supers = pyclass . get_superclasses ( ) <TAB><TAB><TAB>  if supers : <TAB><TAB><TAB><TAB>  return pyobjects . PyObject ( supers [ 0 ] ) <TAB><TAB>  return passed_self ","if isinstance ( pyclass , pyobjects . AbstractClass ) :",if pyclass is not None:,False,51.21073489858682,94.42705312339791
4996,"def get_data ( row ) : <TAB>  data = [ ] <TAB>  for field_name , field_xpath in fields : <TAB><TAB>  result = row . xpath ( field_xpath ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  result = "" "" . join ( <TAB><TAB><TAB><TAB>  text <TAB><TAB><TAB><TAB>  for text in map ( <TAB><TAB><TAB><TAB><TAB>  six . text_type . strip , map ( six . text_type , map ( unescape , result ) ) <TAB><TAB><TAB><TAB>  ) <TAB><TAB><TAB><TAB>  if text <TAB><TAB><TAB>  ) <TAB><TAB>  else : <TAB><TAB><TAB>  result = None <TAB><TAB>  data . append ( result ) <TAB>  return data ",if result :,if result:,False,51.12791567828487,100.00000000000004
4997,"def say ( jarvis , s ) : <TAB>  """"""Reads what is typed."""""" <TAB>  if not s : <TAB><TAB>  jarvis . say ( "" What should I say? "" ) <TAB>  else : <TAB><TAB>  voice_state = jarvis . is_voice_enabled ( ) <TAB><TAB>  jarvis . enable_voice ( ) <TAB><TAB>  jarvis . say ( s ) <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  jarvis . disable_voice ( ) ",if not voice_state :,if voice_state:,False,22.09053270837614,97.95285238424324
4998,"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB>  module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB>  if fromlist and module . __name__ in modules : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  fromlist = list ( fromlist ) <TAB><TAB><TAB>  fromlist . remove ( "" * "" ) <TAB><TAB><TAB>  fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB><TAB>  for x in fromlist : <TAB><TAB><TAB>  if isinstance ( getattr ( module , x , None ) , types . ModuleType ) : <TAB><TAB><TAB><TAB>  from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB><TAB><TAB><TAB>  if from_name in modules : <TAB><TAB><TAB><TAB><TAB>  importlib . import_module ( from_name ) <TAB>  return module ","if ""*"" in fromlist :",if '*' in fromlist:,False,36.61723112240972,98.36442680514078
4999,"def _read_pricing_file ( self , region = None , pricing_file = None ) : <TAB>  if not self . __pricing_file_cache : <TAB><TAB>  <IF-STMT>: <TAB><TAB><TAB>  logging . info ( "" Reading pricing file... "" ) <TAB><TAB><TAB>  with open ( pricing_file ) as data_file : <TAB><TAB><TAB><TAB>  self . __pricing_file_cache = json . load ( data_file ) <TAB><TAB>  else : <TAB><TAB><TAB>  self . __pricing_file_cache = self . _download_pricing_file ( region ) <TAB>  return self . __pricing_file_cache ",if pricing_file :,if pricing_file:,False,50.614273546433665,100.00000000000004
